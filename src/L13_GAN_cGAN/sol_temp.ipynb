{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyVIPgJxun3F"
   },
   "source": [
    "## Задание 1. Исследовать GAN для генерации точек на параболе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gywvQYkYun3G"
   },
   "source": [
    "1.1\n",
    "* Посмотреть что будет если подавать в качестве шума uniform распределение\n",
    "    * **Должно стать чуть хуже, парабола получится за N=5 эпох менее гладкой**\n",
    "* Попробовать избавится от линейности на параболе (любыми известными методами)\n",
    "    * **Делается это заменой ReLU на SiLU (или любую гладкую вроде tanh)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvTcER-IBjfe"
   },
   "source": [
    "1.2\n",
    "* Сделать генерацию фигуры более сложной формы, например круга\n",
    "    * **Нужно изменить функцию генерирующую пару точек x,y**\n",
    "* Добится сходимости\n",
    "    * **Если не сиьно менять параметры, то получится довольно быстро**\n",
    "* Желательно сделать гиф-анимацию/видео какие точки выдаёт в процессе обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01-A2fCpBjfe"
   },
   "source": [
    "1.3\n",
    "* Предобучить только дискриминатор (сделать его сильным критиком).\n",
    "* Обучать только генератор (если критик достаточно сильный, то генератор не будет учиться)\n",
    "\n",
    "    * **В зависимости от того, сколько эпох учился дискриминатор могут получиться следующие результаты:**\n",
    "        * **Если дискриминатор получился сильным, то генератору будет сложно и фигура долго не будет сходится. То есть генератор не может побороть слишком хороший дискриминатор.**\n",
    "        * **Если дискриминатор получился недостаточно сильным, то это может помочь сходимости и фигура может сойтись даже быстрее, чем при одновременном обучении D и G с самого начала.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsQCZk5FBjff"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import Dataset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR-b3nX4Bjfg"
   },
   "source": [
    "Определяем модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLCQbyS4Bjfh"
   },
   "outputs": [],
   "source": [
    "class GenModel(nn.Module):\n",
    "    def __init__(self, latent_space):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_space, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unb1WYohBjfi"
   },
   "outputs": [],
   "source": [
    "class DisModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 15),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15,1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDrvqHZtBjfj"
   },
   "outputs": [],
   "source": [
    "def get_g_batch(batch_size, latent_dim):\n",
    "    g_input = torch.randn(size=(batch_size, latent_dim)).to(device)\n",
    "    # g_input = torch.rand(size=(batch_size, latent_dim)).to(device)\n",
    "    labels = torch.ones(size=(batch_size,)).to(device)\n",
    "    return g_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7oEQdYlEqlI"
   },
   "outputs": [],
   "source": [
    "def make_r(a=0.81, b=0.14, c=2, phi=torch.linspace(0, 2*np.pi, 100), n=1):\n",
    "    r = 0.1 + 1/c * torch.sqrt(-torch.log(2*np.exp(-a**2) - torch.exp(-b**2 * torch.sin((phi-np.pi/2)*n/2)**2)))\n",
    "    x = r*torch.cos(phi)\n",
    "    y = r*torch.sin(phi)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tldKxqChBjfk"
   },
   "outputs": [],
   "source": [
    "def get_mix_batch_normal(batch_size, latent_dim, netG):\n",
    "    types_of_points = []\n",
    "    \n",
    "    # Generate true pairs and true labels\n",
    "    x = torch.distributions.Uniform(-1, +1).sample((batch_size,)).to(device)\n",
    "    true_pair = torch.vstack((x, x*x)).T.to(device)\n",
    "    \n",
    "    true_labels = torch.ones(size=(batch_size,)).unsqueeze(1).to(device)\n",
    "    types_of_points.append(torch.hstack((true_pair, true_labels)))\n",
    "    \n",
    "    # Generate fake uniform pairs and fake labels\n",
    "    x_fake = torch.distributions.Uniform(-1, +1).sample((batch_size,)).to(device)\n",
    "    y_fake = torch.distributions.Uniform(-1, +1).sample((batch_size,)).to(device)\n",
    "    fake_pair = torch.vstack((x_fake, y_fake)).T\n",
    "    fake_labels = torch.zeros(size=(batch_size,)).unsqueeze(1).to(device)\n",
    "    types_of_points.append(torch.hstack((fake_pair, fake_labels)))\n",
    "\n",
    "    # Generate points from generator and set labels as fake\n",
    "    gan_pair = netG(torch.randn(size=(batch_size, latent_dim)).to(device)) # Normal distribution\n",
    "    gan_labels = torch.zeros(size=(batch_size,)).unsqueeze(1).to(device)\n",
    "    types_of_points.append(torch.hstack((gan_pair, gan_labels)))\n",
    "    \n",
    "    # Stack all types of points\n",
    "    z = torch.vstack(types_of_points)\n",
    "    # Shuffle\n",
    "    z=z[torch.randperm(z.size()[0])]\n",
    "    \n",
    "    # Split back to samples and labels\n",
    "    mixed_pairs = z[:, :2]\n",
    "    mixed_labels = z[:, 2]\n",
    "    return mixed_pairs, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXD4qyU_Bjfk"
   },
   "outputs": [],
   "source": [
    "def get_test_loss(model,test_loader,loss_function):\n",
    "    with torch.no_grad():\n",
    "        loss_test_total = 0\n",
    "        for samples, labels in test_loader:\n",
    "            outputs = model(samples.to(device))\n",
    "            loss = loss_function(outputs, labels.to(device))\n",
    "            loss_test_total += loss.item()\n",
    "        return loss_test_total/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTa8KS0JBjfl"
   },
   "outputs": [],
   "source": [
    "def netD_step(netD, batchD, loss_func, optimizer):\n",
    "    samples, labels = batchD\n",
    "    optimizer.zero_grad()\n",
    "    outputs = netD(samples.to(device))\n",
    "    loss = loss_func(outputs.to(device), labels.unsqueeze(1).detach().to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGoRfcqPBjfl"
   },
   "outputs": [],
   "source": [
    "def netG_step(netD, netG, batchG, loss_func, optimizer):\n",
    "    samples, labels = batchG\n",
    "    optimizer.zero_grad()\n",
    "    outputs = netD(netG(samples.to(device)))\n",
    "    loss = loss_func(outputs.to(device), labels.unsqueeze(1).detach().to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g50waYAiBjfm"
   },
   "outputs": [],
   "source": [
    "def plot_gen(netG, epoch=\"Not provided\", title = '', limits=[-1,1,-1,1]):\n",
    "    Gin, _ = get_g_batch(1000, latent_dim)\n",
    "    out = netG(Gin).cpu()\n",
    "    plt.scatter(out.detach().numpy()[:, 0], out.detach().numpy()[:, 1], color=\"blue\", s=1)\n",
    "    plt.title(f'[Epoch={epoch+1}] {title}', fontsize=10)\n",
    "    plt.axis([-1,1,-1,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wj-5o9RhBjfn"
   },
   "outputs": [],
   "source": [
    "def train(netD, netG, batch_per_epoch, batch_size, latent_dim, epochs, loss_func, optD, optG):\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(batch_per_epoch):\n",
    "            batchG = get_g_batch(batch_size, latent_dim)\n",
    "            batchD = get_mix_batch(batch_size, latent_dim, netG)\n",
    "            \n",
    "            netD.train(True)\n",
    "            netG.train(False)\n",
    "            netD_step(netD, batchD, loss_func, optD)\n",
    "            \n",
    "            netD.train(False)\n",
    "            netG.train(True)\n",
    "            netG_step(netD, netG, batchG, loss_func, optG)\n",
    "            \n",
    "        # clear_output()\n",
    "        plot_gen(netG, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAgevW2pBjfn"
   },
   "source": [
    "### 1.1 Решение:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотреть что будет если подавать в качестве шума uniform распределение**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4WC20fVuBjfo",
    "outputId": "d13afff7-885a-481e-8881-4fc662529798"
   },
   "outputs": [],
   "source": [
    "def get_mix_batch_uniform(batch_size, latent_dim, netG):\n",
    "    types_of_points = []\n",
    "    \n",
    "    # Generate true pairs and true labels\n",
    "    x = torch.distributions.Uniform(-1, +1).sample((batch_size,)).to(device)\n",
    "    true_pair = torch.vstack((x, x*x)).T.to(device)\n",
    "\n",
    "    true_labels = torch.ones(size=(batch_size,)).unsqueeze(1).to(device)\n",
    "    types_of_points.append(torch.hstack((true_pair, true_labels)))\n",
    "    \n",
    "    # Generate fake uniform pairs and fake labels\n",
    "    x_fake = torch.distributions.Uniform(-1, +1).sample((batch_size,)).to(device)\n",
    "    y_fake = torch.distributions.Uniform(-1, +1).sample((batch_size,)).to(device)\n",
    "    fake_pair = torch.vstack((x_fake, y_fake)).T\n",
    "    fake_labels = torch.zeros(size=(batch_size,)).unsqueeze(1).to(device)\n",
    "    types_of_points.append(torch.hstack((fake_pair, fake_labels)))\n",
    "\n",
    "    # Generate points from generator and set labels as fake\n",
    "    gan_pair = netG(torch.rand(size=(batch_size, latent_dim)).to(device)) # Меняем randn на rand\n",
    "    gan_labels = torch.zeros(size=(batch_size,)).unsqueeze(1).to(device)\n",
    "    types_of_points.append(torch.hstack((gan_pair, gan_labels)))\n",
    "    \n",
    "    # Stack all types of points\n",
    "    z = torch.vstack(types_of_points)\n",
    "    # Shuffle\n",
    "    z=z[torch.randperm(z.size()[0])]\n",
    "    \n",
    "    # Split back to samples and labels\n",
    "    mixed_pairs = z[:, :2]\n",
    "    mixed_labels = z[:, 2]\n",
    "    return mixed_pairs, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQYGsgG5Bjfn"
   },
   "outputs": [],
   "source": [
    "latent_dim = 5\n",
    "batch_size = 128\n",
    "batch_per_epoch = 1000\n",
    "epochs = 5\n",
    "\n",
    "netG = GenModel(latent_dim).to(device)\n",
    "netD = DisModel().to(device)\n",
    "loss_func = nn.BCELoss().to(device)\n",
    "optD = torch.optim.Adam(netD.parameters(), lr=0.001)\n",
    "optG = torch.optim.Adam(netG.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "21z206yBng2d",
    "outputId": "a03b8318-055e-4583-8dfc-13a50ebb92df"
   },
   "outputs": [],
   "source": [
    "get_mix_batch = get_mix_batch_uniform\n",
    "train(netD, netG, batch_per_epoch, batch_size, latent_dim, epochs, loss_func, optD, optG)\n",
    "get_mix_batch = get_mix_batch_normal # Back to normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Попробовать избавится от линейности на параболе (любыми известными методами)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CXdCA2FFPF7Q",
    "outputId": "6a1eec6e-3b64-41fa-8710-9154e38908f6"
   },
   "outputs": [],
   "source": [
    "# Меняем активации на гладкие\n",
    "class GenModelSiLU(nn.Module):\n",
    "    def __init__(self, latent_space):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_space, 50),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(50,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class DisModelSiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 25),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(25, 15),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(15,1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 5\n",
    "batch_size = 128\n",
    "batch_per_epoch = 1000\n",
    "epochs = 6\n",
    "\n",
    "netG = GenModelSiLU(latent_dim).to(device)\n",
    "netD = DisModelSiLU().to(device)\n",
    "loss_func = nn.BCELoss().to(device)\n",
    "optD = torch.optim.Adam(netD.parameters(), lr=0.001)\n",
    "optG = torch.optim.Adam(netG.parameters(), lr=0.001)\n",
    "\n",
    "train(netD, netG, batch_per_epoch, batch_size, latent_dim, epochs, loss_func, optD, optG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe7qSC4PBjfo"
   },
   "source": [
    "### 1.2 Решение:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделать генерацию фигуры более сложной формы, например круга**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_batch_figure(batch_size, latent_dim, netG):\n",
    "    types_of_points = []\n",
    "    \n",
    "    # Generate true pairs and true labels\n",
    "    # Создаем новую форму (Круг)\n",
    "    t = torch.distributions.Uniform(0, 2*math.pi).sample((batch_size,))\n",
    "    x = torch.sin(t)\n",
    "    y = torch.cos(t)\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    true_pair = torch.vstack((x, y)).T\n",
    "    \n",
    "    true_labels = torch.ones(size=(batch_size,)).unsqueeze(1).to(device)\n",
    "    types_of_points.append(torch.hstack((true_pair, true_labels)))\n",
    "    \n",
    "    # Generate fake uniform pairs and fake labels\n",
    "    if True:\n",
    "        x_fake = torch.distributions.Uniform(-1, +1).sample((batch_size,)).to(device)\n",
    "        y_fake = torch.distributions.Uniform(-1, +1).sample((batch_size,)).to(device)\n",
    "        fake_pair = torch.vstack((x_fake, y_fake)).T\n",
    "        fake_labels = torch.zeros(size=(batch_size,)).unsqueeze(1).to(device)\n",
    "        types_of_points.append(torch.hstack((fake_pair, fake_labels)))\n",
    "\n",
    "    # Generate points from generator and set labels as fake\n",
    "    if True:\n",
    "        gan_pair = netG(torch.randn(size=(batch_size, latent_dim)).to(device))\n",
    "        gan_labels = torch.zeros(size=(batch_size,)).unsqueeze(1).to(device)\n",
    "        types_of_points.append(torch.hstack((gan_pair, gan_labels)))\n",
    "    \n",
    "    # Stack all types of points\n",
    "    z = torch.vstack(types_of_points)\n",
    "    # Shuffle\n",
    "    z=z[torch.randperm(z.size()[0])]\n",
    "    \n",
    "    # Split back to samples and labels\n",
    "    mixed_pairs = z[:, :2]\n",
    "    mixed_labels = z[:, 2]\n",
    "    return mixed_pairs, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2foY-BmbBjfo",
    "outputId": "55a24ecc-abc3-4b4a-e249-5e0c6ae56418",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 5\n",
    "batch_size = 128\n",
    "batch_per_epoch = 1000\n",
    "epochs = 12\n",
    "\n",
    "netG = GenModel(latent_dim).to(device)\n",
    "netD = DisModel().to(device)\n",
    "loss_func = nn.BCELoss().to(device)\n",
    "optD = torch.optim.Adam(netD.parameters(), lr=0.001)\n",
    "optG = torch.optim.Adam(netG.parameters(), lr=0.001)\n",
    "\n",
    "get_mix_batch = get_mix_batch_figure\n",
    "train(netD, netG, batch_per_epoch, batch_size, latent_dim, epochs, loss_func, optD, optG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Гиф-анимация генерируемых точек в процессе обучения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "017UPL02UKFp"
   },
   "outputs": [],
   "source": [
    "!apt install imagemagick #Ставим imagemagick\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bmukgM6Bjfo"
   },
   "source": [
    "### 1.3 Решение:\n",
    "\n",
    "**Предобучить только дискриминатор (сделать его сильным критиком) и посмотреть будет ли сходится генератор**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oGBvFIFbBjfp",
    "outputId": "7fc73710-a7e4-41ae-da6c-bd95320df15d"
   },
   "outputs": [],
   "source": [
    "def train(netD, netG, batch_per_epoch, batch_size, latent_dim, epochs, loss_func, optD, optG, learn_only_D=False, learn_only_G=False):\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(batch_per_epoch):\n",
    "            if not learn_only_G:\n",
    "                batchD = get_mix_batch(batch_size, latent_dim, netG)\n",
    "                netD.train(True)\n",
    "                netG.train(False)\n",
    "                netD_step(netD, batchD, loss_func, optD)\n",
    "            \n",
    "            if not learn_only_D:\n",
    "                batchG = get_g_batch(batch_size, latent_dim)\n",
    "                netD.train(False)\n",
    "                netG.train(True)\n",
    "                netG_step(netD, netG, batchG, loss_func, optG)\n",
    "                \n",
    "        if learn_only_D:\n",
    "            clear_output()\n",
    "            print(f'Current epoch={epoch}')\n",
    "        if learn_only_G:\n",
    "            plot_gen(netG, epoch, title = f\"learn_only_G = {learn_only_G}\")\n",
    "\n",
    "netG = GenModel(latent_dim).to(device)\n",
    "netD = DisModel().to(device)\n",
    "loss_func = nn.BCELoss().to(device)\n",
    "optD = torch.optim.Adam(netD.parameters(), lr=0.001)\n",
    "optG = torch.optim.Adam(netG.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "get_mix_batch = get_mix_batch_normal\n",
    "# Обучаем только дискриминатор, делая его сильным\n",
    "train(netD, netG, batch_per_epoch, batch_size, latent_dim, 50,\n",
    "      loss_func, optD, optG, learn_only_D=True, learn_only_G=False)\n",
    "# Продолжаем обучать в обычном режиме\n",
    "train(netD, netG, batch_per_epoch, batch_size, latent_dim, 10,\n",
    "      loss_func, optD, optG, learn_only_D=False, learn_only_G=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z0rj196a0rN"
   },
   "source": [
    "## Задание 2. cGAN на датасете Fashion mnist (или MNIST)\n",
    "\n",
    "Напишите полносвязный GAN с условием. Условием в данном случае будет являтся lablel (номер класса) цифры или вещи.\n",
    "\n",
    "1. Сделайте эмбединг для лэйблов внутри модели\n",
    "2. С помощью torch.cat добавьте этот эмбединг ко входу генератора и дискриминатора\n",
    "3. Используйте такие параметры для генератора:\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(?, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "4. Используйте такую архитектуру для дискриминатора:\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(?, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "pkqpMsLsBjfp"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(110, 196),\n",
    "            nn.Tanh()\n",
    "            \n",
    "            \n",
    "#             nn.Linear(256, 512),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Linear(512, 1024),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Linear(1024, 784),\n",
    "#             nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=1, out_channels=5, kernel_size=3),\n",
    "            nn.ConvTranspose2d(in_channels=5, out_channels=16, kernel_size=3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        z = z.view(z.size(0), 100)\n",
    "        c = self.label_emb(labels)\n",
    "        \n",
    "        dense_in = torch.cat([z, c], 1)\n",
    "        x = self.dense(dense_in)\n",
    "        print(x.shape)\n",
    "        \n",
    "        deconv_in = x.view(x.size(0), 14, 14).unsqueeze(1)\n",
    "        out = self.deconv(deconv_in)\n",
    "        print(out.shape)\n",
    "        \n",
    "        return out.view(x.size(0), 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "3-_TJAM8Bjfq"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Делаем эмбед label\n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(794, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        x = x.view(x.size(0), 784)\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o57bE4qZBjfq"
   },
   "source": [
    "Код ниже желательно не изменять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "dPcmJrN7Bjfq"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "])\n",
    "\n",
    "dataset = FashionMNIST(root ='/content/',\n",
    "                       train = True,\n",
    "                       transform = transform, \n",
    "                       target_transform = None, \n",
    "                       download = True)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "-pimf-qPBjfq"
   },
   "outputs": [],
   "source": [
    "def get_class_name(num):\n",
    "    \"\"\"Вспомогательная функция возвращающая название класса по его индексу\n",
    "    num - численный индекс класса\"\"\"\n",
    "    class_names = dataset.class_to_idx #{название класса : индекс класса}\n",
    "\n",
    "    key_list = list(class_names.keys())\n",
    "    val_list = list(class_names.values())\n",
    "    \n",
    "    # print key with val 100\n",
    "    position = val_list.index(num)\n",
    "    print(key_list[position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "ljo8TfpLBjfr"
   },
   "outputs": [],
   "source": [
    "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
    "    g_optimizer.zero_grad()\n",
    "    z = torch.randn(batch_size, 100).to(device)\n",
    "    fake_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).to(device)\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    validity = discriminator(fake_images, fake_labels)\n",
    "    g_loss = criterion(validity, torch.ones(batch_size)).to(device)\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss\n",
    "\n",
    "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
    "    d_optimizer.zero_grad()\n",
    "\n",
    "    # train with real images\n",
    "    real_validity = discriminator(real_images, labels)\n",
    "    real_loss = criterion(real_validity, torch.ones(batch_size).to(device))\n",
    "    # train with fake images\n",
    "    z = torch.randn(batch_size, 100).to(device)\n",
    "    fake_labels = torch.LongTensor(np.random.randint(0, 10, batch_size)).to(device)\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    fake_validity = discriminator(fake_images, fake_labels)\n",
    "    fake_loss = criterion(fake_validity, torch.zeros(batch_size).to(device))\n",
    "\n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "rKW7oRflBjfr"
   },
   "outputs": [],
   "source": [
    "betas = (0.5, 0.999)\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "lr = 1e-4\n",
    "\n",
    "criterion = nn.BCELoss().to(device)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BFc38I0bBjfr",
    "outputId": "dff482d0-2627-4fd0-8848-61c7f40f6f07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0...\n",
      "torch.Size([64, 196])\n",
      "torch.Size([64, 16, 18, 18])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[64, 28, 28]' is invalid for input of size 331776",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-e7d40d9f0908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         d_loss = discriminator_train_step(len(real_images), discriminator,\n\u001b[0;32m     14\u001b[0m                                           \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                                           real_images, labels)\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-128-683a1aea3bfe>\u001b[0m in \u001b[0;36mdiscriminator_train_step\u001b[1;34m(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mfake_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mfake_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mfake_validity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mfake_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_validity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-124-47aeb5cdcba0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, z, labels)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[64, 28, 28]' is invalid for input of size 331776"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "n_critic = 5\n",
    "display_step = 300\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Starting epoch {}...'.format(epoch))\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        \n",
    "        real_images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        generator.train()\n",
    "        batch_size = real_images.size(0)\n",
    "        d_loss = discriminator_train_step(len(real_images), discriminator,\n",
    "                                          generator, d_optimizer, criterion,\n",
    "                                          real_images, labels)\n",
    "        \n",
    "\n",
    "        g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
    "\n",
    "    generator.eval()\n",
    "    print('g_loss: {}, d_loss: {}'.format(g_loss, d_loss))\n",
    "    z = Variable(torch.randn(9, 100)).cuda()\n",
    "    labels = torch.LongTensor(np.arange(9)).to(device)\n",
    "    \n",
    "    sample_images = generator(z, labels).unsqueeze(1).data.cpu()\n",
    "        \n",
    "    grid = make_grid(sample_images, nrow=3, normalize=True).permute(1,2,0).numpy()\n",
    "    plt.imshow(grid)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EX13_GAN_cGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
