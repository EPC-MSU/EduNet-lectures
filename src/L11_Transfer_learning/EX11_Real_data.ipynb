{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VWFkJurvh7_",
    "outputId": "c7828960-9359-42a9-c9a4-77b9d164b657"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GInuTprfv0np"
   },
   "source": [
    "# 1. Transfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa42kdcwwBnT"
   },
   "source": [
    "1.1 Возьмите датасет Cifar10 и ResNet\n",
    "\n",
    "1.2 Замените у Resnet послежний слой\n",
    "\n",
    "1.3 Проведите эксперимент: обучите ResNet на Cifar10 без аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHzFXo732MYI"
   },
   "outputs": [],
   "source": [
    "batch_size = 128*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h17BM-1etrbY",
    "outputId": "792fe0df-cb03-4e88-dc84-a6bd061ab5e6"
   },
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.ToTensor() # не используем аугментацию\n",
    "\n",
    "cifar_train = CIFAR10(root = \"/content\", train=True, download = True, transform=transforms)\n",
    "train_loader = torch.utils.data.DataLoader(cifar_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "cifar_test = CIFAR10(root = \"/content\", train=False, download = True, transform=transforms)\n",
    "test_loader = torch.utils.data.DataLoader(cifar_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "cifar = CIFAR10(root = \"/content\", train=True, download = True)\n",
    "\n",
    "y = cifar.targets\n",
    "X = cifar.data\n",
    "\n",
    "X_mean = torch.Tensor(np.mean(X,0))\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3K9OpMJnfw8n",
    "outputId": "4117146a-f54b-4daa-c35b-b22c35796dd4"
   },
   "outputs": [],
   "source": [
    "# Посмотрим на распределение данных в классах\n",
    "keys = list(cifar.class_to_idx.keys())\n",
    "#for i in range(len(keys)):\n",
    "#    print(Counter(y)[i], cifar10.class_to_idx[keys[i]], keys[i])\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "Mms4xvILfw5o",
    "outputId": "3cdb1df0-a5ac-4876-93b5-dee3b862e83c"
   },
   "outputs": [],
   "source": [
    "def show_example(X, y, label, grid = (3,3)):\n",
    "    y_label = [i for i, tag in enumerate(y) if label == tag]\n",
    "    random.shuffle(y_label)\n",
    "    \n",
    "    rows = grid[0]\n",
    "    columns = grid[1]\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, columns)\n",
    "    fig.set_figheight(7)\n",
    "    fig.set_figwidth(7)\n",
    " \n",
    "    for row in axes:\n",
    "        for col in row: col.imshow(X[y_label.pop()])\n",
    "    plt.show()\n",
    "\n",
    "#airplane\n",
    "show_example(X, y, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFMfCyG0uwaR"
   },
   "source": [
    "## 1.1 Обучение ResNet на Cifar10 без аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oae2n4W6L9F-"
   },
   "outputs": [],
   "source": [
    "net = models.resnet18(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmMFu4l9qGYG",
    "outputId": "2c5b0293-6da9-4143-a731-30ccc277e42f"
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjpbjM3wsGpZ"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "num_ftrs = net.fc.in_features # заменили у ResNet последний слой\n",
    "net.fc = nn.Linear(num_ftrs, len(keys)).to(device)\n",
    "#net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AspzP1WtrXM",
    "outputId": "c1a58b1e-4100-49f4-bc85-738eb452953b"
   },
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "print_every = 10\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    print(f'Epoch {epoch}')\n",
    "    for batch_idx, (data_, target_) in enumerate(train_loader):\n",
    "        data_, target_ = data_.to(device), target_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(data_)\n",
    "        loss = criterion(outputs, target_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==target_).item()\n",
    "        total += target_.size(0)\n",
    "        #if (batch_idx) % 20 == 0:\n",
    "        #    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        #           .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'train-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for data_t, target_t in (test_loader):\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = net(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(test_loader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "\n",
    "# =============================== пример сохранения лучшей модели ==================\n",
    "        #if network_learned:\n",
    "        #    valid_loss_min = batch_loss\n",
    "        #    torch.save(net.state_dict(), 'resnet.pt')\n",
    "        #    print('Improvement-Detected, save-model')\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "f-yGzXnUtrS2",
    "outputId": "de38208c-83f1-4226-91b8-3da5a261ce6c"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.title(\"Train-Validation Accuracy\")\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('accuracy', fontsize=12)\n",
    "plt.grid()\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUIh0yqzu7f9"
   },
   "source": [
    "## 1.2 Обучение ResNet на Cifar10 с аугментацией\n",
    "\n",
    "1.1 Возьмите датасет ResNet из предыдущего задания\n",
    "\n",
    "1.2 Проведите эксперимент: обучите ResNet на Cifar10 с аугментацией\n",
    "\n",
    "1.3 Сделайте выводы, сравнив обучения в 1м и 2м заданиях\n",
    "\n",
    "[How Data Augmentation Improves your CNN performance? — An Experiment in PyTorch and Torchvision](https://medium.com/swlh/how-data-augmentation-improves-your-cnn-performance-an-experiment-in-pytorch-and-torchvision-e5fb36d038fb)\n",
    "\n",
    "Возможные трансформации можно взять в руководстве [TORCHVISION.TRANSFORMS](https://pytorch.org/vision/stable/transforms.html?highlight=augmentation%20examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SL44oW2eLuhB",
    "outputId": "824d75c0-45c6-4d9e-e0bf-1d203a644707"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-9eL1VR3d7K"
   },
   "outputs": [],
   "source": [
    "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.GaussianBlur(7, sigma=(0.1, 2.0)),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    #normalize,\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([ # тестовую выборку не аугментируют!!\n",
    "    transforms.ToTensor(),\n",
    "    #normalize,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgIRUdsXfpAg",
    "outputId": "e43dacfa-db47-446a-d061-e347fb7dafa8"
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LBphbfUNOgS",
    "outputId": "3ab3a409-72c9-4503-c8ef-b1b21d9d9574"
   },
   "outputs": [],
   "source": [
    "# Посмотрим на распределение данных в классах\n",
    "keys = list(cifar.class_to_idx.keys())\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-OTRTR80SAk"
   },
   "outputs": [],
   "source": [
    "net = models.resnet18(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NC6NQTmh2hYa"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "num_ftrs = net.fc.in_features # заменили у ResNet последний слой\n",
    "net.fc = nn.Linear(num_ftrs, len(keys)).to(device)\n",
    "#net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEaAHvrRshR2",
    "outputId": "3a733927-0557-4966-aeac-f1d9a92a2aea"
   },
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "print_every = 10\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    print(f'Epoch {epoch}')\n",
    "    for batch_idx, (data_, target_) in enumerate(train_loader):\n",
    "        data_, target_ = data_.to(device), target_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(data_)\n",
    "        loss = criterion(outputs, target_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==target_).item()\n",
    "        total += target_.size(0)\n",
    "        #if (batch_idx) % 20 == 0:\n",
    "        #    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        #           .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'train-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for data_t, target_t in (test_loader):\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = net(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(test_loader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "dj1EbDt6svCP",
    "outputId": "bdbce187-0ff6-4b14-cce4-049d4b089dbf"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.title(\"Train-Validation Accuracy\")\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('accuracy', fontsize=12)\n",
    "plt.grid()\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6E1J6-tDjf-"
   },
   "source": [
    "*Примечание:*\n",
    "- обратите внимание, что кривые `train` и  `test` после аугментации идут параллельно, а значит модель не переучивается\n",
    "- если у студентов качество с аугментацией будет хуже, чем без нее, про проблема в том, что Аугментациию нужно применять с умом!! не на каждом датасете она улучшит качество обучения\n",
    "- впрроченм, сейчас задача просто научиться аугментировать датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3GVZB2a_IVb"
   },
   "source": [
    "# 3. Если нужно, то добавлю задание еще для одного датасета с пчелами и муравьями - transfer learning в resnet\n",
    "---\n",
    "но, кажется, изза скорости обучения, и так много времени займут первые 2 задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CP4oWYuNv7gq"
   },
   "source": [
    "# 2. One-Shot Learning\n",
    "Решим задачу с Kaggle:\n",
    "\n",
    "Необходимо обучить сиамскую можель распознават подписи из [kaggle signature verification dataset](https://www.kaggle.com/robinreni/signature-verification-dataset) - отсюда нужно скачать датасет и перенести на свой гугл диск\n",
    "\n",
    "[Do More With Less Data! — One-shot Learning with Siamese Neural Networks](https://medium.com/sfu-cspmp/do-more-with-less-data-one-shot-learning-with-siamese-neural-networks-760357a2f5cc) - подписи\n",
    "\n",
    "[SigNet: Convolutional Siamese Network for Writer Independent Offline Signature Verification](https://arxiv.org/pdf/1707.02131.pdf) - статья\n",
    "\n",
    "[Siamese-Network-for-Signature-Verification](https://github.com/gskdhiman/Siamese-Network-for-Signature-Verification/blob/master/siamese-network-for-signature-verification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_ph-U16SkUG"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/EX2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDMURKIHPI7E"
   },
   "source": [
    "**Siamese Neural Network**\n",
    "\n",
    "Сиамская нейронная сеть - это класс архитектур нейронных сетей, которые содержат две или более идентичных подсетей.\n",
    "\n",
    "«Идентичные» здесь означает, что они имеют одинаковую конфигурацию с одинаковыми параметрами и весом.\n",
    "\n",
    "Обновление параметров зеркально отражается в обеих подсетях и используется для поиска сходства входных данных путем сравнения их векторов признаков.\n",
    "\n",
    "----\n",
    "В этом задании Вам надо, скачав готовый датасет, реализовать задачу One-Shot Learning для распознавания оригиналиных и поддельных подписей. По аналогии с примером с лицами в лекции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCw233eeTHF5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/EX1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLqOxtMiPgSJ"
   },
   "source": [
    "### План\n",
    "\n",
    "\n",
    "1.   **Data Preprocessing**\n",
    "2.   **Define the Siamese Network**\n",
    "3.   **Feature Vector Extraction**\n",
    "4.   **Similarity Score Calculation**\n",
    "5.   **Defininf Loss Function**\n",
    "6.   **Optimizer**\n",
    "7.   **Testing using One-Shot Learnig**\n",
    "8.   **Making Predictions**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwVjRxLM7_3A"
   },
   "source": [
    "### Import and Install all the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "esGrw0waQlwP"
   },
   "outputs": [],
   "source": [
    "# Import all the necessary Library \n",
    "import torchvision\n",
    "import torch.utils.data as utils\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd \n",
    "\n",
    "from IPython.display import clear_output\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5DjnCpaz0-Z"
   },
   "outputs": [],
   "source": [
    "# архив с подписями находится тут:\n",
    "# hhttps://drive.google.com/file/d/14DzmqKJmSzt1KMn6AB0DZ9yvSzkeo8BK/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5gCKXjTPut2",
    "outputId": "7736a216-a31b-478a-a515-e04eefa7adb8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmRRnTkx8Gdf"
   },
   "source": [
    "### Additional Utility Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lbUsE940bz1"
   },
   "outputs": [],
   "source": [
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5NvCZbZeh4A"
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    training_dir = \"/content/sign_data_mini/train\"\n",
    "    testing_dir = \"/content/sign_data_mini/test\"\n",
    "    train_batch_size = 32\n",
    "    train_number_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSceosT-QYVv"
   },
   "source": [
    "### Load Dataset :\n",
    "\n",
    "Datasets может быть загружен по ссылке:  https://drive.google.com/file/d/14DzmqKJmSzt1KMn6AB0DZ9yvSzkeo8BK/view?usp=sharing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3q_b_lZPup_",
    "outputId": "d549390c-ed1f-4201-f6b1-ae8d94762382"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/МГУ/L11 Transfer Learning/data/sign_data_mini.zip\" .\n",
    "!unzip sign_data_mini.zip\n",
    "clear_output()\n",
    "!ls /content/sign_data_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFbF-KBzDWNW"
   },
   "outputs": [],
   "source": [
    "training_dir=\"/content/sign_data_mini/train\"\n",
    "training_csv=\"/content/sign_data_mini/train_data.csv\"\n",
    "testing_csv=\"/content/sign_data_mini/test_data.csv\"\n",
    "testing_dir=\"/content/sign_data_mini/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBOpcs9KRjWm"
   },
   "source": [
    "### Preprocessing and Loading Dataset\n",
    "\n",
    "We preprocessed all the images and loaded them as .npy files which is easy to transfer . You can follow your own preprocessing steps .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VC5JhgpcPmP6"
   },
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset():\n",
    "    \n",
    "    def __init__(self,training_csv=None,training_dir=None,transform=None):\n",
    "        # used to prepare the labels and images path\n",
    "        self.training_df=pd.read_csv(training_csv)\n",
    "        self.training_df.columns =[\"image1\",\"image2\",\"label\"]\n",
    "        self.training_dir = training_dir    \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        # getting the image path\n",
    "        image1_path=os.path.join(self.training_dir,self.training_df.iat[index,0])\n",
    "        image2_path=os.path.join(self.training_dir,self.training_df.iat[index,1])\n",
    "        \n",
    "        \n",
    "        # Loading the image\n",
    "        img0 = Image.open(image1_path)\n",
    "        img1 = Image.open(image2_path)\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "        \n",
    "        # Apply image transformations\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1 , torch.from_numpy(np.array([int(self.training_df.iat[index,2])],dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ws1NipMUQaI3"
   },
   "outputs": [],
   "source": [
    "# Load the the dataset from raw image folders\n",
    "siamese_dataset = SiameseNetworkDataset(training_csv,training_dir,\n",
    "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ])\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "eTpprbksZS80",
    "outputId": "463f2088-4865-4573-aab8-43f34a76e672"
   },
   "outputs": [],
   "source": [
    "# Viewing the sample of images and to check whether its loading properly\n",
    "print('\"0\" - подписи идентичны, \"1\" - подделка')\n",
    "vis_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        batch_size=8)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "\n",
    "example_batch = next(dataiter)\n",
    "concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xhlmF-nj6_v"
   },
   "source": [
    "## Siamese Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjkBkyTomlU6"
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Defining the fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(30976, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(128,2))\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        # Forward pass \n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # forward pass of input 1\n",
    "        output1 = self.forward_once(input1)\n",
    "        # forward pass of input 2\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xaKRzCV-vBD"
   },
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBjCIlhWk2MT"
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyGA_GUt-0xp"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xO9uIznkXiB0"
   },
   "outputs": [],
   "source": [
    "# Load the dataset as pytorch tensors using dataloader\n",
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        batch_size=Config.train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPnzoTXfE5cX"
   },
   "outputs": [],
   "source": [
    "# Declare Siamese Network\n",
    "net = SiameseNetwork().cuda()\n",
    "# Decalre Loss Function\n",
    "criterion = ContrastiveLoss()\n",
    "# Declare Optimizer\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=1e-4, alpha=0.99, eps=1e-8, weight_decay=0.0005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aUJOhkrFfu9"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    counter = []\n",
    "    loss_history = [] \n",
    "    iteration_number= 0\n",
    "    \n",
    "    for epoch in range(0,Config.train_number_epochs):\n",
    "        for i, data in enumerate(train_dataloader,0):\n",
    "            img0, img1 , label = data\n",
    "            img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output1,output2 = net(img0,img1)\n",
    "            loss_contrastive = criterion(output1,output2,label)\n",
    "            loss_contrastive.backward()\n",
    "            optimizer.step()\n",
    "            if i %200 == 0 :\n",
    "                print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "                iteration_number +=10\n",
    "                counter.append(iteration_number)\n",
    "                loss_history.append(loss_contrastive.item())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDx471-mBDGD",
    "outputId": "52140989-2cbc-4d3c-bf4a-eb56ad454fe8"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = train()\n",
    "torch.save(model.state_dict(), \"/content/model.pt\")\n",
    "print(\"Model Saved Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EH_2bML3v2W",
    "outputId": "7aa5de40-28fd-4dbd-d31c-a6ffa2902f49"
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SiameseNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"/content/model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYS8IFa9FD2C"
   },
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_dataset = SiameseNetworkDataset(training_csv=testing_csv,training_dir=testing_dir,\n",
    "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ])\n",
    "                                       )\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Zy5GPKz5vvxO",
    "outputId": "09e82668-8135-4ead-e01d-48ab192170f9"
   },
   "outputs": [],
   "source": [
    "# Print the sample outputs to view its dissimilarity\n",
    "counter=0\n",
    "list_0 = torch.FloatTensor([[0]])\n",
    "list_1 = torch.FloatTensor([[1]])\n",
    "for i, data in enumerate(test_dataloader,0): \n",
    "  x0, x1 , label = data\n",
    "  concatenated = torch.cat((x0,x1),0)\n",
    "  output1,output2 = model(x0.to(device),x1.to(device))\n",
    "  eucledian_distance = F.pairwise_distance(output1, output2)\n",
    "  if label==list_0:\n",
    "    label=\"Orginial\"\n",
    "  else:\n",
    "    label=\"Forged\"\n",
    "  imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f} Label: {}'.format(eucledian_distance.item(),label))\n",
    "  counter=counter+1\n",
    "  if counter ==20:\n",
    "     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lo5Jl-txHNHX"
   },
   "source": [
    "### Accuracy Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HxlxqLiDBLq",
    "outputId": "c8333062-d246-4433-9766-2462dc10fe8b"
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,batch_size=1,shuffle=True)\n",
    "accuracy=0\n",
    "counter=0\n",
    "correct=0\n",
    "for i, data in enumerate(test_dataloader,0): \n",
    "  x0, x1 , label = data\n",
    "  # onehsot applies in the output of 128 dense vectors which is then converted to 2 dense vectors\n",
    "  output1,output2 = model(x0.to(device),x1.to(device))\n",
    "  res=torch.abs(output1.cuda() - output2.cuda())\n",
    "  label=label[0].tolist()\n",
    "  label=int(label[0])\n",
    "  result=torch.max(res,1)[1].data[0].tolist()\n",
    "  if label == result:\n",
    "    correct=correct+1\n",
    "  counter=counter+1\n",
    "#   if counter ==20:\n",
    "#      break\n",
    "    \n",
    "accuracy=(correct/len(test_dataloader))*100\n",
    "print(\"Accuracy:{}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYEKwMzKDhjf"
   },
   "source": [
    "### **ВЫВОД:**\n",
    "Мы видим эффективность такого полхода, так как даже при низком `accuracy`, мы достигаем высокое качество распознавания поддельных подписей.\n",
    "\n",
    "Вопрос: можно ли тут верить `accurary`? Или нет, тк у нас не сбалансированный датасет"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "GInuTprfv0np",
    "kFMfCyG0uwaR",
    "rUIh0yqzu7f9"
   ],
   "name": "EX_11_Обучение на реальных данных_sol.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
