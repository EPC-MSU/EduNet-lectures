Программа курса 

Лекция 1 “Вводная”

 ML и DL и AI в Computer Science. Связь DL с наукой. История развития DL. Сферы применения и технологии. Причины успехов технологий на основе DL. ML — Подход к научным проблемам. Базовые задачи. Данные. Примеры датасетов. Оценка результата. Демонстрация работы с данными. Табличные данные. Последовательности. Обзор контейнеров. Предобработка данных. Обзор видов связности данных. Работа с изображениями.

Лекция 2 “Линейный классификатор”

Ограничения алгоритма k-nearest neighbors (kNN). kNN для классификации. Практические аспекты работы с классификаторами. Линейный классификатор. Переход к сравнению с шаблоном. Переход к весам. Математическая запись. Support Vector Machine (метод опорных векторов). Функция потерь SVM-loss. Вычисление SVM loss. Обновления весов методом градиентного спуска. Градиент loss функции. Численный расчет производной. Аналитический расчет производной от SVM Loss. Выбор шага обучения. Выбор размера батча. Регуляризация. Cross-entropy Loss. Переход к вероятностям. Кросс-энтропия. Градиент Cross Entropy Loss. Практическое вычисление SoftMax

Лекция 3 “Классическое машинное обучение”

Введение. Экспертные системы (Rule-based systems). Классическое машинное обучение. Глубокое машинное обучение. Необходимость методов классического машинного обучения. Деревья решений. Принцип работы дерева решений. Деревья решений (классификация). Деревья решений (Регрессия). Деревья решений и работа с пропущенными значениями. Преимущества и недостатки деревьев решений. Bias, Variance, Irreducible error. Бутстрэп. Корреляция и построение доверительного интервала для нее. Построение доверительного интервала для качества метрики. Ансамбли. Корректирующий код. Постановка задачи. Простое голосование. Bagging = Bootstrap aggregation. Метод случайных подпространств (RSM, random subspace method). Комбинация RSM и Bagging. Случайный лес. Boosting. AdaBoost (Freund & Schapire, 1996). Gradient boosting (градиентный бустинг). Модификации градиентного бустинга. Блендинг и Стэкинг. Применение нейронных сетей к табличным данным. Ссылки на материалы для самостоятельного изучения. Общие источники. 

Лекция 4 “Feature Engineering”

Подготовка данных. Генерация признаков. Типы признаков. Преобразования. Практическое применение. Примеры данных которые нецелесообразно отправлять в модель в сыром виде. Отбор признаков. Зачем отбирать признаки? Полный перебор. Одномерный отбор признаков. Жадный отбор признаков. Отбор признаков на основе моделей. Отбор признаков - это тоже выбор гиперпарметров. Задача понижения размерности. Manifold assumption. PCA (Метод главных компонент). Kernel PCA Ядровой (нелинейный) метод главных компонент. Методы, основанные на сохранении расстояний. tSNE (t-distributed stochastic neighbor embedding). UMAP. tSNE и UMAP на цифрах.

Лекция 5 “Нейронные сети”

Ограничения Линейного классификатора. ХОR — проблема. Проблемы классификации более сложных объектов. Переход от линейного классификатора к прецептрону. Перцептрон - нейросеть с одним скрытым слоем. Многослойные сети. Функции потерь (loss functions). Функции активации. Обучение нейронной сети. Прямое распространение. Веса сети. Метод обратного распространения ошибки. Backpropagation - метод обратного распространения ошибки. Основная идея метода. Граф вычислений. Преимущества и недостатки. Пример простой сети на датасете mnist. Ссылки

Лекция 6 “Сверточные нейронные сети”

Введение в сверточные нейронные сети. Полносвязная нейронная сеть. Нарушение связей между соседними пикселями. Свертка с фильтром. Примеры 'hancrafted' фильтров. Сверточный слой нейросети. Основные параметры свёртки. Использование свёрточных слоёв. Пример сверточной сети. Визуализация. Визуализация весов. Визуализация фильтров промежуточных слоев. Feature extractor. Визуализация карт активаций. 

Лекция 7 “Улучшение сходимости нейросетей и борьба с переобучением”

Сигмоида затухает и теоретически и практически. Затухание градиента. Инициализация весов. Инициализация Ксавьера (Xavier, Glorot). He-инициализация (Kaiming). Важность инициализации весов. Обобщение инициализаций Ксавьера и He-инициализации. Ортогональная инициализация. Инициализация весов в Pytorch. Регуляризация. L1, L2 регуляризации. Dropout. Dropconnect. DropBlock. Нормализация. Нормализация входных данных. Covariate shift(Ковариантный сдвиг). Internal covariate shift. BatchNormalization. Другие Normalization. Оптимизация весов нейросетей. Обзор популярных оптимизаторов. Сравнение оптимизаторов. Режимы обучения. Ранняя остановка. Домножать learning rate на gamma каждую эпоху. Cyclical learning schedule. Neural Network WarmUp. Ссылки

Лекция 8 “Рекуррентные нейронные сети (RNN)”

Особенности. Примеры задач. Базовый RNN блок. RNNCell. Пример обработки временного ряда. Подготовка данных. Создание и обучение модели. Посимвольная генерация текстов. Подготовка данных. Создание и обучение модели. LSTM. Gates (Врата). LSTMCell. LSTM in Pytorch. Модификации LSTM. Sequence-to-Sequence with RNNs. Attention. Sequence-to-Sequence with RNNs and Attention mechanism. Проблема attention. Image Captioning with RNNs and Attention. Key, query, value. Attention Layer. Self-Attention Layer. Multihead Self-Attention Layer. Attention is all you need. Decoder. Примеры применений Transformer. Перевод текста. BERT (Bidirectional Encoder Representations from Transformers ). GPT (Generative Pretrained Transformer ). Хорошие источники

Лекция 9 “Архитектуры CNN”

Базовые компоненты сверточных сетей. ImageNet Large Scale Visual Recognition Challenge. Обзор сети AlexNet(2012 г.). Обзор сети VGGNet(2014 г.). Ресурсы. Размер рецептивного поля. Оценка памяти занимаемой моделью. Обзор сети GoogleNet(2014 г.). Inception module. 1x1 Convolution. "Stem network". Global Average Pooling. Затухание градиента. Появление "глубоких" моделей (deep models). Обзор сети ResNet(2015 г.). Resudial connection. Архитектура ResNet. ResNet: bottleneck layer. ResNet реализация в Pytorch. Обучение ResNet. Обзор сети ResNeXt(2016 г.). Groupped Convolution. Grouped convolution in Pytorch. ResNext, Inception, grouped conv. Feature extraction. Сравнение моделей. Обзор сети DenseNet(2016 г.). Архитектура SENet(2017 г.). Обзор сети MobileNet(2017 г.). Swish. Depthwise separable convolution. Shuffled Grouped Convolution. Neural Architecture Search. 
Обзор сети EfficientNet(2019 г.). Обзор Visual Transformers(2020 г.). Архитектура ViT. Предсказание с помощью ViT. Обзор сети MLP-Mixer(2020 г.). Бонус: Практические аспекты работы с размерностью данных. Список использованной литературы.

Лекция 10 “Explainability”

Общая идея. Поиск ошибок. Доверие пользователей. Публикации в научных журналах. Explainability & Interpretability. Оценка важности признаков в простых случаях. Оценка важности признака для дерева. Randomization/Permutation. Dropped variable importance. Библиотеки для реализации explanation. SHAP (SHapley Additive exPlanations). LIME. Boruta. Другие библиотеки. Примеры explanations для разных видов данных. Табличные данные. NLP: Пример абстрактного обобщения текста. Изображения. Заключение. Список литературы. Статьи.

Лекция 11 “Обучение на реальных данных”

Проблемы при работе с реальной задачей машинного обучения. Как решить проблему малого количества данных. Работа с несбалансированным датасетом. Аугментация. Изображения. Аудио. Текст. Transfer Learning. Структурные компоненты. Обучение модели. Модель. Few-Shot learning. One-Shot learning. Few-shots learning в GPT. Оптимизация гиперпараметров. Заключение. Литература.


Лекция 12 “Задачи компьютерного зрения”

Задачи компьютерного зрения. Dataset COCO - Common Objects in COntext. Семантическая сегментация (Semantic segmentation). Способы решения. Автокодировщик. U-Net: Convolutional Networks for Biomedical Image Segmentation. Мультиклассовая сегментация. Обзор Fully Convolutional Network(2014). Обзор DeepLabv3+(2018). Детектирование (Object detection). Детектирование нескольких объектов. Нard Example Mining. Instance Segmentation. ROI Align. Оценка качества детекции. mAP - mean Average Precision. DINO - Self-supervised representation learning (with segmentation capabilities). Результаты DINO. Как работает. Сегментация изображений. Сегментация видео. Кластеризация. Список использованной литературы.

Лекция 13 “Генеративно-состязательные нейронные сети”

Введение в генеративно-состязательные нейронные сети. Поставим задачу генерации. Latent space. Наивный подход. Дискриминатор. Generative adversarial network (GAN). DCGAN - Генерация изображений. cGAN - GAN с условием. Wasserstein GAN. ProGAN -> StyleGAN -> StyleGAN2 -> Alias-Free GAN. Тонкости обучения GANов. Частые/простые ошибки. Попробуйте дать преимущество дискриминатору. Используйте ADAM. Top K Training. Краткое описание примечательных моделей GAN. GAN для решения задачи распознавания капчи. BigGAN. Domain transfer network. SRGAN и StackGANs. Pix2Pix. Семантическая генерация. Text to image. Задача переноса стиля. Image-to-Image Translation. Заключение. Использованная литература. Ссылки

Лекция 14 “Автоэнкодеры”

Автоэнкодеры (AE). Unsupervised learning. Representation learning. Снижение размерности. Автоэнкодер. Сжатие информации и потери. Manifold assumption. Метод главных компонент (PCA). Аналогия AE и PCA. Очищение изображения от шумов. PCA для избавления от шума. Реализация автоэнкодера. Разреженный автоэнкодер. Автоэнкодер как генератор и его ограничения. Плавная интерполяция. Вариационные автоэнкодеры (VAE). Мотивация. Неудачная попытка: регуляризация. Вариационный автоэнкодер. Почему KL(Q||P)?. Проблемы «ванильного» VAE. Автоэнкодеры с условием(CAE). Условные вариационные автоэнкодеры (CVAE). Вариационные автоэнкодеры с условиями, CVAE. Состязательные автокодировщики (AAE = AE + GAN). Разделение (disentangling) стиля и метки. Semisupervised AAE. Полезные материалы. Примеры практического применения. 

Лекция 15 “Обучение с подкреплением”

Обучение с учителем. Обучение без учителя. Обучение с подкреплением. Терминология: агент, функция награды, состояние среды. Различные подходы в обучении Нейронных сетей. Отличие от supervised learning. Классические примеры задач RL. Особенности RL. Сложности. Состояние (State). Markov property. Markov process. Матрица состояний. Награда (Reward). Суммарная награда (Return). Уравнение Беллмана. Марковский процесс принятия решений. Добавляем действия, но убираем случайность. Возвращаем случайность. Формальное описание Markov decision process. Постановка задачи. Нахождение оптимальной политики Беллмана. Q – Learning. Exploration vs exploitation. Пример c CartPole DQN. Дальнейшие идеи. Другие улучшения DQN. Альтернативные подходы. Рекомендованная литература.

	


