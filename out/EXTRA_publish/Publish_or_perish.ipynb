{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как избежать \"подводных камней\" машинного обучения: руководство для академических исследователей**\n",
    "\n",
    "[How to avoid machine learning pitfalls: a guide for academic researchers (Lones, 2021)](https://arxiv.org/abs/2108.02497)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой лекции дается краткое описание некоторых распространенных ошибок, возникающих при использовании методов машинного обучения, и руководство к тому, как их избежать. Лекция предназначена в первую очередь как руководство для студентов-исследователей и посвящена вопросам, которые особенно актуальны в академических исследованиях, например, необходимости проводить строгие сравнения и делать обоснованные выводы. Однако большинство выводов применимо и к более широкому использованию ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прежде чем приступить к созданию моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это нормально, что вам хочется сразу же начать обучение и оценку моделей. Но начинать надо не с этого - подумайте о целях проекта; полностью поймите данные, которые будут использоваться для достижения этих целей; рассмотрите любые ограничения данных, которые необходимо устранить; и поймите, что в вашей области уже было сделано. Если этого не сделать, есть риск получить результаты, которые трудно опубликовать, и/или модели, которые не подходят для решения поставленной задачи.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разберитесь с тем, какую задачу/проблему вы хотите решить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При оценке того, является ли задача решаемой, стоит сначала спросить себя: а нужно ли ее решать? И если да, то нужно ли ее решать с помощью машинного обучения?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изучите литературу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала работы важно понимать, что **было сделано и что не было сделано ранее**. Другие люди работали над той же проблемой - и это хорошо; академический прогресс обычно представляет собой итерационный процесс, в котором каждое последующее исследование опирается на предыдущее. Может быть неприятно обнаружить, что кто-то уже исследовал вашу замечательную идею, но, скорее всего, они задали много направлений для дальнейшей работы. \n",
    "\n",
    "**Игнорировать предыдущие исследования - значит потенциально упустить ценную информацию**. Например, возможно, кто-то уже пробовал предложенный вами подход и нашел фундаментальные причины, по которым он не сработает (и тем самым избавил вас от нескольких лет разочарования), или же частично решил проблему таким образом, что вы сможете от этого решения оттолкнуться.\n",
    "\n",
    "Важно **провести обзор литературы до начала работы**; если вы сделаете это слишком поздно - возможно придется объяснять, почему вы повторяете ту же самую тему или не опираетесь на существующие знания.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как искать статьи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Выделите ключевые слова (на английском) по которым вы будете искать похожие исследования\n",
    "2. Вбейте их в [Google Scholar](https://scholar.google.com/)\n",
    "3. Изучите релевантные статьи\n",
    "4. Внимательно почитайте вводную часть, возможно там есть ссылки на похожие исследования\n",
    "5. Выпишите ключевые идеи и достижения, добавьте ссылки на статьи в свои личные архивы. Они вам еще понадобятся для своего собственного введения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же существует множество агрегаторов, которые мониторят свежевыходящие статьи и публикуют обзоры/ссылки на самые интересные каждый день (например Twitter [@ak92501](https://twitter.com/ak92501), YouTube [Yannic Kilcher](https://www.youtube.com/c/YannicKilcher) и многие другие)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><table><tr>\n",
    "<td> <img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/Yannic_Kilcher.jpg\" width=\"800\"> </td>\n",
    "<td> <img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/twitter_ak92501.jpg\" width=\"250\"> </td>\n",
    "<td> <img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/scholar.jpg\" > </td>\n",
    "</tr></table></center>\n",
    "\n",
    "<center><i>Примеры ресурсов, на которых можно поискать исследования</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как искать готовые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поиска готовых моделей с опубликованным кодом существует отличный ресурс - [Papers With Code](https://paperswithcode.com/). На нем можно искать модели по типам задач (например [Object Detection](https://paperswithcode.com/task/object-detection) или [Visual Reasoning](https://paperswithcode.com/task/visual-reasoning)).\n",
    "\n",
    "Отличительной особенностью ресурса является то, что все модели сравниваются между собой на бэнчмарках (сразу видно какая модель работает лучше всего на каком-то конкретном датасете). Помимо поиска по задачам, существует так же и поиск [по методам](https://paperswithcode.com/methods) (например [Attention](https://paperswithcode.com/methods/category/attention-mechanisms) или [Graph Embeddings](https://paperswithcode.com/methods/category/graph-embeddings)) и [по датасетам](https://paperswithcode.com/datasets) (например [CelebA](https://paperswithcode.com/dataset/celeba) или [PubMed](https://paperswithcode.com/dataset/pubmed))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/Papers_With_Code.jpg\" ></center>\n",
    "<center><i>Пример работы с Papers With Code</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Потратьте время на понимание своих данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конечном итоге вы захотите опубликовать свою работу. Публиковать работы основанные на данных из надежного источника (собранных с использованием надежной методологии) значительно проще.\n",
    "\n",
    "Если вы используете данные, скачанные с интернет-ресурса, **убедитесь, что вы знаете, откуда они взяты** (описаны ли они в статье? Если да, посмотрите на документ; убедитесь, что он был опубликован в авторитетном месте, и проверьте, упоминают ли авторы какие-либо ограничения данных).\n",
    "\n",
    "Не предполагайте, что если набор данных использовался в ряде работ, то он хорошего качества - иногда данные используются только потому, что их легко достать, а некоторые широко используемые наборы данных, как известно, имеют существенные ограничения (см. [Paullada et al., 2020]((https://arxiv.org/abs/2012.05345))). **Например**, при исследовании категории `faces` в ImageNet ([Deng et al., 2009](https://ieeexplore.ieee.org/document/5206848), [Crawford & Paglen, 2019](https://excavating.ai/) ) обнаружили миллионы изображений людей, которые были помечены оскорбительными категориями, включая расистские и унизительные фразы. В ответ на эту работу, большая часть набора данных ImageNet была удалена ([Yang et al., 2020](https://dl.acm.org/doi/abs/10.1145/3351095.3375709))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы обучаете свою модель на плохих данных, то, скорее всего, у вас получится плохая модель: процесс, известный как **garbage in garbage out** (чушь на входе - чушь на выходе). Поэтому всегда начинайте с проверки, что ваши **данные имеют смысл**. \n",
    "\n",
    "Проведите **эксплораторный анализ данных** (см. [Cox, 2017](https://www.oreilly.com/library/view/translating-statistics-to/9781484222560/A426308_1_En_3_Chapter.html)). Ищите недостающие или непоследовательные записи. Гораздо проще сделать это сейчас, до обучения модели, чем потом, когда вы будете пытаться объяснить рецензентам, почему вы использовали плохие данные. \n",
    "\n",
    "Анализ важно провести независимо от того, используете ли вы существующие наборы данных или генерируете новые данные в рамках своего исследования (в этом случае учитывайте, что исследовательский анализ может быть ценен сам по себе, а результаты этого анализа могут стать важной частью вашей статьи).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельным пунктом, хочется отметить, что помимо \"содержания\", важна и \"форма\" данных. **Формат хранения** ваших данных повлияет на **скорость, с которой вы сможете завершить свое исследование**. **Например**, у вас есть массив, который называется `ID` и в нем хранятся следующие данные `[1,30,111,221,234]` в формате `float64`. Проверьте, а точно ли тут нужен `float64`, возможно, ваши данные представлены целыми положительными числами, и для их хранения будет достаточно формата `uint32` или даже `uint16` (см. подробный обзор форматов данных в [Understanding Data Types](https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разберем на конкретном примере"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем датасет: **\"Когда и где кого-то покусала собака в NYC\"** и загрузим его в `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "!wget https://data.cityofnewyork.us/api/views/rsgh-akpg/rows.csv?accessType=DOWNLOAD -O dogs.csv\n",
    "\n",
    "# Load into pandas and display a sample\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('dogs.csv')\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим есть ли **дупликаты**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dataset) == len(dataset.drop_duplicates()):\n",
    "    print('Очевидных дупликатов нет')\n",
    "else:\n",
    "    print('%.2f процентов данных являются дупликатами' % len(dataset.drop_duplicates())/len(dataset) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть колонки: `UniqueID`, `DateOfBite`, `Species`,\t`Breed`, `Age`, `Gender`, `SpayNeuter`, `Borough`, `ZipCode`, давайте проверим все ли с ними в порядке. Начнем с того, что определим в каком виде хранятся наши данные в памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Object` - это далеко не самая эффективная форма хранения информации в `Pandas-DataFrame` и, как правило, отличный индикатор того, что с данными, что-то не так. Давайте разберемся с каждой колонкой по отдельности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `UniqueID`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы ожидаем, что в этой колонке каждому объявлению был присвоен уникальный ID. Судя по сэмплу, это просто порядковый номер начинающийся с 1. Можем визуализировать эту колонку, что бы убедиться что там никаких сюрпризов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(len(dataset))\n",
    "plt.scatter(x, dataset['UniqueID'], s=0.1)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('UniqueID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что уникальных идентификаторов меньше чем строк в датафрейме. Давайте убедимся:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['UniqueID'].max(), len(dataset['UniqueID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть ID повторяются?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sort_values('UniqueID').head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по всему, в какой-то момент времени нумерация была запущена заново. А значит ID совсем даже не unique => использовать эту колонку как уникальный идентификатор мы не можем. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каком формате хранятся данные в этой колонке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['UniqueID'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `int64` можно записывать целые числа в диапазоне от `-9223372036854775808` до `9223372036854775807`. Мы уже по графику видим, что знак нам не нужен, и что наше максимальное значение явно меньше. Определим какой у нас максимум."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['UniqueID'].min(), dataset['UniqueID'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значит нам подойдет `uint16` целое число без знака в диапазоне от  `0` до `65535`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered = dataset.copy()\n",
    "dataset_filtered['UniqueID'] = dataset['UniqueID'].astype('uint16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Узнаем сколько памяти мы выиграли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resources_gain(column = 'UniqueID', orig_dataset=dataset, filtered_dataset=dataset_filtered):\n",
    "    original_memory = orig_dataset[column].memory_usage(deep=True)\n",
    "    memory_after_conversion = filtered_dataset[column].memory_usage(deep=True)\n",
    "\n",
    "    return original_memory/memory_after_conversion\n",
    "\n",
    "resources_gain(column='UniqueID', orig_dataset=dataset, filtered_dataset=dataset_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь колонка `UniqueID` занимает в 4 раза меньше места (а значит и обрабатывается быстрее)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DateOfBite`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `DateOfBite` судя по всему записано время укуса, но в формате `str`. Нам было бы удобнее работать с `timestamps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['DateOfBite'] = pd.to_datetime(dataset['DateOfBite'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим выигрыш в ресурсах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_gain(column='DateOfBite', orig_dataset=dataset, filtered_dataset=dataset_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим нет ли каких-то странных дат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['DateOfBite'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С датами все в порядке, кстати можно заметить, что во время Ковида собакам было явно меньше кого кусать =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Species`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы ожидаем, что в этом отчете сообщается только об укусах собак, убедимся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас целая колонка в которой исключительно значение `DOG`, то зачем нам эта колонка? Правильно. Удаляем ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_filtered['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Breed`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, какие значения есть в этой колонке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Breed'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что тип нашего массива - `object`. Обычно так бывает, когда в массиве есть несколько разных типов данных (например `float` и `str`). Давайте найдем все значения, которые str не являются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Breed'][dataset['Breed'].apply(lambda x: type(x) != str)].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ага - `NaN`. А выше мы уже видели что есть категория `UNKOWN`. Давайте поправим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['Breed'][dataset['Breed'].apply(lambda x: type(x) != str)] = 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на поправленный список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dataset_filtered['Breed'].unique()).tolist()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу видно, что категории часто повторяются с опечатками. Править это придется в ручную (чем мы заниматься на этой лекции конечно не будем). Но для примера поправим опечатку в `ALASKAN MALMUTE` (заменим на `ALASKAN MALAMUTE`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['Breed'][dataset['Breed'] == 'ALASKAN MALMUTE'] = 'ALASKAN MALAMUTE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть ограниченное (хоть и большое) количество пород, с точки зрения памяти, их выгоднее хранить как категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['Breed'] = dataset_filtered['Breed'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим выигрыш в производительности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_gain(column='Breed', orig_dataset=dataset, filtered_dataset=dataset_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках примера, будем считать что колонку почистили"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Age`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаем, что колонка будет в числовом формате, на деле видим `object`, давайте разбираться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Age'].unique()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну тут только руками... Нам надо выбрать единую единицу измерения (например месяцы) и все привести к ней. Там где непонятно будем писать `NaN` (хотя лучше бы выяснить конечно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['Age'][ (dataset['Age'] == '4') | \n",
    "                        (dataset['Age'] == '7') |\n",
    "                        (dataset['Age'] == '6') |\n",
    "                        (dataset['Age'] == '5') |\n",
    "                        (dataset['Age'] == '8') |\n",
    "                        (dataset['Age'] == '11') |\n",
    "                        (dataset['Age'] == '3')] = np.nan #так как не понятно 4 чего\n",
    "dataset_filtered['Age'][dataset['Age'] == '4Y'] = 4*12\n",
    "dataset_filtered['Age'][dataset['Age'] == '5Y'] = 5*12\n",
    "dataset_filtered['Age'][dataset['Age'] == '3Y'] = 3*12\n",
    "#ну и так далее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Gender`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим какие есть варианты пола собаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну хоть тут без сюрпризов, но для увеличения производительности тоже сконвертируем данные в категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['Gender'] = dataset['Gender'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_gain(column='Gender', orig_dataset=dataset, filtered_dataset=dataset_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кто чаще кусается?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['Gender'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `SpayNeuter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Spay/Neutter` - это была ли собака стерилизована. Мы ожидаем только True и False (хотя удивительно, что не колонки unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['SpayNeuter'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А формат у нас и так уже `bool`, который занимает мало места. Значит с этой колонкой закончили"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Borough`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boroughs - это что-то типа наших округов (например ЮЗАО)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Borough'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тоже переведем в категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['Borough'] = dataset['Borough'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['Borough'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_gain(column='Borough', orig_dataset=dataset, filtered_dataset=dataset_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ZipCode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ZipCode'].unique()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что есть категории `?` и `NaN`. Их можно объединить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['ZipCode'][dataset['ZipCode'] == np.nan] = '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остальные значения тоже пусть будут категориальными (у многих значений есть 0 в начале, пусть  остается, что бы не вводить дополнительную путаницу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered['ZipCode'] = dataset['ZipCode'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим насколько меньше места теперь занимает **весь** датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.memory_usage(deep=True).sum()/dataset_filtered.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом можем считать нашу чистку завершенной. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Правильно делайте разбиения\n",
    "\n",
    "Что бы обучить модель, нам понадобиться разбить свои данные на несколько частей (`train-val-test`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте создадим датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset_size = 1000\n",
    "n_features = 2\n",
    "\n",
    "# Создадим рандомный датасет\n",
    "X = np.random.normal(size=(dataset_size,n_features))\n",
    "y = np.random.normal(size=(dataset_size,)) \n",
    "print('Размерность X', X.shape)\n",
    "print('Размерность y', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И разделим его на `train`, `val` и `test`. Если вы применяете случайное разбиение (как в следующем блоке кода), не забудьте зафиксировать random state, что бы в следующий раз вы получили ровно такую же тестовую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, random_state=42)\n",
    "\n",
    "print('Размерность X_train', X_train.shape)\n",
    "print('Размерность X_val', X_val.shape)\n",
    "print('Размерность X_test', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,0], X_train[:,1], color='red', alpha=0.5, label='Train')\n",
    "plt.scatter(X_val[:,0], X_val[:,1], color='green', alpha=0.5, label='Val')\n",
    "plt.scatter(X_test[:,0], X_test[:,1], color='blue', alpha=0.5, label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующий раз вам стоит воспользоваться тестом только уже при проверке обученной модели. А вот валидационный (*validation set*) нам понадобиться при обучении модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе обучения модели, мы вообще-то хотели бы знать насколько хорошо она справляется с поставленной задачей. Если для оценки модели на каждой итерации (работы над моделью) мы будем использовать тестовый сет, мы просто оптимизируем модель к этому конкретному (тестовому) разбиению и потерям возможность объективно оценивать обобщающую способность модели (тестовое множество станет неявной частью процесса обучения [Cawley, 2010](https://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf)). Вместо этого для измерения качества модели (и \"руководством над процессом обучения\") мы можем использовать отдельный (третий) набор для проверки - *validation/val set*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще одним преимуществом наличия валидационного набора является то, что вы можете сделать **раннюю остановку** (*early stopping*), когда во время обучения одной модели, модель оценивается по валидационному набору на каждой итерации процесса обучения. Обучение прекращается, когда результат валидации начинает снижаться, так как это указывает на то, что модель начинает переобучаться на *train set*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не смотрите на *все* свои данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда вы начнете действительно изучать свои данные, вы скоре всего заметите в них какие-то закономерности. Так или иначе, эти закономерности будут направлять вашу дальнейшую работу. Однако важно, чтобы вы не делали **непроверяемых** предположений, которые впоследствии будут использованы в вашей модели. Например, проанализировав датасет с собаками, можно решить что в 2020 и 2021 году собаки стали воспитаннее и перестали так часто кусать прохожих. Но это же не так! На самом деле просто людей на улицах было меньше + меньше людей хотели/могли обращаться в полицию (из-за ковидных ограничений).\n",
    "\n",
    "Вообще делать предположения - это нормально, но они должны использоваться только для обучения модели, а не для ее тестирования. \n",
    "\n",
    "Следует избегать пристального изучения любых тестовых данных на начальном этапе исследовательского анализа. В противном случае вы можете сознательно или бессознательно сделать выводы, которые ограничат обобщающую способность вашей модели не поддающимся тестированию способом. К этой теме мы будем возвращаться еще не раз, поскольку утечка информации из тестового набора в процесс обучения является распространенной причиной плохой обобщаемости ML моделей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не допускайте утечки тестовых данных в процесс обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно иметь данные, которые можно использовать для измерения обобщающей способности вашей модели. Распространенная проблема заключается в том, что информация об этих данных просачивается в конфигурацию, обучение или выбор моделей. Когда это происходит, данные перестают быть надежной мерой обобщения, что в свою очередь ведет к тому, что опубликованные модели ML часто не демонстрируют хороших результатов на реальных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует несколько способов утечки информации из тестового набора. Некоторые из них кажутся вполне безобидными. **Например**, при подготовке данных используется информация о средних диапазонах переменных во всем наборе данных для масштабирования переменных - чтобы предотвратить утечку информации, такие вещи следует делать только с обучающими данными. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример нормализации данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим искусственный датасет и посмотрим на него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=42)\n",
    "plt.scatter(dataset[0][:,0], dataset[0][:,1], c=dataset[1])\n",
    "plt.title('Full dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные нужно нормализовать. И очень хочется это сделать сразу со всеми данными, но это приведет к *data leakage* (утечке данных из тестовой выборки). Давайте все равно это сделаем и временно отложим наш неправильно нормализованный датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(dataset[0])\n",
    "dataset_wrong_data = scaler.transform(dataset[0])\n",
    "dataset_wrong = (dataset_wrong_data, dataset[1])\n",
    "\n",
    "plt.scatter(dataset_wrong[0][:,0], dataset_wrong[0][:,1], c=dataset_wrong[1])\n",
    "plt.title('Неправильно нормализованный датасет')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разобьем наш исходный датасет на `train` и `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[0], dataset[1], test_size=0.2, random_state=42)\n",
    "\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train, label='Train', alpha=0.2)\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c=y_test, marker='x', label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы хотим нормализовать данные. Напрашивается идея, применить нормализацию к `train`, и применить нормализацию к `test`.  Это тоже неправильная идея."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_train = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "scaler_train.fit(X_train)\n",
    "scaler_test.fit(X_test)\n",
    "\n",
    "X_train_wrong = scaler_train.transform(X_train)\n",
    "X_test_wrong = scaler_test.transform(X_test)\n",
    "\n",
    "plt.scatter(X_train_wrong[:,0], X_train_wrong[:,1], c=y_train, label='Train', alpha=0.2)\n",
    "plt.scatter(X_test_wrong[:,0], X_test_wrong[:,1], c=y_test, marker='x', label='Test')\n",
    "plt.title('Еще один не правильно нормализованный датасет')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Правильно будет использовать тот же скейлер для `test`, что и для `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_train = MinMaxScaler()\n",
    "\n",
    "scaler_train.fit(X_train)\n",
    "scaler_train.fit(X_test)\n",
    "\n",
    "X_train_norm = scaler_train.transform(X_train)\n",
    "X_test_norm = scaler_train.transform(X_test)\n",
    "\n",
    "plt.scatter(X_train_norm[:,0], X_train_norm[:,1], c=y_train, label='Train', alpha=0.2)\n",
    "plt.scatter(X_test_norm[:,0], X_test_norm[:,1], c=y_test, marker='x', label='Test')\n",
    "plt.title('Правильно нормализованный датасет')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним все вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset_wrong[0][:,0], dataset_wrong[0][:,1], color='blue', alpha=0.1, label='Full wrong')\n",
    "\n",
    "plt.scatter(X_train_wrong[:,0], X_train_wrong[:,1], color='red', alpha=0.1, label='Train-test wrong')\n",
    "plt.scatter(X_test_wrong[:,0], X_test_wrong[:,1], color='red', alpha=0.1, marker='x')\n",
    "\n",
    "plt.scatter(X_train_norm[:,0], X_train_norm[:,1], color='green', alpha=0.2, label='Train-test correct')\n",
    "plt.scatter(X_test_norm[:,0], X_test_norm[:,1], color='green', alpha=0.2, marker='x')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другие распространенные примеры утечки информации: выбор признаков (*feature selection*, см. [Cai et al., 2018](https://www.sciencedirect.com/science/article/pii/S0925231218302911)) до разбиения данных. Обычно при наличии большого количества признаков проводится их фильтрация определенным образом. В геномике это часто означает отфильтровывание генов, которые являются в каком-то смысле \"низкокачественными\". **Например**, мы можем захотеть отфильтровать гены с высокой разреженностью, т.е. имеющие значение 0 для большого числа пациентов. Поскольку критерии для отсеивания таких генов/функций определяются на основе данных, важно, чтобы рассматривался только `train set`, а не весь набор данных, чтобы определить, нужно ли отсеивать функцию или нет. Поэтому следует вычислять разреженность каждого гена среди обучающих выборок, а не среди всех выборок. В противном случае для отбора признаков будет использована информация, полученная из тестового набора.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее, что вы можете сделать для предотвращения этих проблем, это **разделить подмножество ваших данных в самом начале проекта**, и использовать независимый тестовый набор только один раз для измерения генерализации модели в конце проекта (см. [Cawley, 2010](https://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf) и [Kaufman et al., 2012](https://dl.acm.org/doi/10.1145/2382577.2382579) для более обширного обсуждения этого вопроса. А так же можно обратится к [блог-посту Brownlee](https://machinelearningmastery.com/data-preparation-without-data-leakage/), в котором очень подробно разбираются часто встречающиеся ошибки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Убедитесь, что у вас достаточно данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у вас недостаточно данных, то обучение хорошей обобщающей модели может оказаться невозможным. Понять Ваш ли это случай сложно, пока Вы не начнете строить модели: все зависит от отношения сигнал/шум в наборе данных. Если сигнал сильный, то можно обойтись меньшим количеством данных; если слабый, то данных потребуется больше. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перекрестная валидация (*cross-validation*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы не можете получить больше данных - то вы можете более эффективно использовать уже имеющиеся, используя перекрестную валидацию (*cross validation*). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще говоря, кросс-валидация используется для более точной оценки модели. Одна оценка модели может быть ненадежной и может либо недооценить, либо переоценить истинный потенциал модели. По этой причине обычно проводится несколько оценок. Существует несколько способов провести множественную оценку модели, и большинство из них предполагает многократное обучение модели с использованием различных подмножеств обучающих данных. **Перекрсная валидация** (CV) особенно популярна и имеет множество разновидностей [Arlot et al., 2010](https://projecteuclid.org/journals/statistics-surveys/volume-4/issue-none/A-survey-of-cross-validation-procedures-for-model-selection/10.1214/09-SS054.full)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перекрсная валидация** в машинном обучении подразумеват, что вместо того, чтобы разделить наш набор данных на две части, одну для обучения (`train`), а другую для тестирования (`test`), мы разбиваем наш набор данных на несколько частей, обучаем на некоторых из них, а остальные используем для тестирования. Затем мы используем другие части для обучения и тестирования нашей модели. Это гарантирует, что наша модель обучается и тестируется на новых данных на каждом новом шаге.\n",
    "\n",
    "Чаще всего используют десятикратную прекресную валидацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разберем на примере"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.3, random_state=42)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И разделим его на 10 (*K*) складок (*folds*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "X, y = make_moons(noise=0.3, random_state=42, n_samples=1000)\n",
    "\n",
    "scores = []\n",
    "\n",
    "# Lets test 100 times\n",
    "for i in range(0,100):\n",
    "    # For each experiment lets choose a different random state for splitting\n",
    "    random_state = np.random.randint(0,2**32)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.4, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # normalize data\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # predict using each classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    scores.append([random_state, classifier.score(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Split data intto 10 folds\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "#Define scaler and classifier\n",
    "scaler = MinMaxScaler()\n",
    "clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "\n",
    "#Define figure space\n",
    "fig,ax = plt.subplots(nrows=2, ncols=5, figsize=(10,4))\n",
    "\n",
    "row = 0\n",
    "scores = []\n",
    "\n",
    "#Itterate over folds\n",
    "for col, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    #Split\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #Normalize\n",
    "    scaler.fit(X_train)\n",
    "    scaler.fit(X_test)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    #Classify\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Gauge performance\n",
    "    score = clf.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "    #Plot figure\n",
    "    if col > 4:\n",
    "        col-=5\n",
    "        row=1\n",
    "\n",
    "    ax[row, col].scatter(X_train[:,0], X_train[:,1], c=y_train, alpha=0.05)\n",
    "    ax[row, col].scatter(X_test[:,0], X_test[:,1], c=y_test, marker='x')\n",
    "    ax[row, col].set_title(score)\n",
    "    ax[row, col].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результирующую точность модели мы определим как среднее от всех складок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Финальная точность = %.2f ± %.2f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для б**о**льшей надежности можно использовать метод **вложенной перекрестной валидации** (также известный как двойная кросс-валидация, (см. [Cawley, 2010](https://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf) и [Wainer et al., 2021](https://research-portal.uea.ac.uk/en/publications/nested-cross-validation-when-selecting-classifiers-is-overzealous))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аугментация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы также можете использовать методы **аугментации** данных (например, см. [Wong et al., 2016](https://arxiv.org/abs/1609.08764), [Shorten et al., 2019](https://link.springer.com/article/10.1186/s40537-019-0197-0?code=a6ae644c-3bfc-43d9-b292-82d77d5890d5)), и они могут быть весьма эффективны для \"расширения\" небольших датасетов. \n",
    "\n",
    "<!-- На случай если решим не вставлять следующий блок кода -->\n",
    "<!-- Причем, с аугментацией есть и свои *фишки*. Так в работе [Fort et al., 2021](https://arxiv.org/abs/2105.13343) было показано, что если для каждого сэмпла делать не одну аугментацию, а несколько (в рамках одного и того же батча) то увеличивается точность на тесте. При этом этот метод работает как при обучении на малых, так и на больших батчах, несмотря на уменьшение количества уникальных обучающих примеров в каждом мини-батче. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyploy as plt\n",
    "\n",
    "#Define augmentations\n",
    "transform = A.Compose([\n",
    "    A.Resize(width=512, height=512),\n",
    "    A.HorizontalFlip(p=1),\n",
    "    A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download image\n",
    "!wget https://wallpaperaccess.com/full/3842851.jpg\n",
    "\n",
    "#Read image\n",
    "image = cv2.imread(\"3842851.jpg\")\n",
    "\n",
    "#Display\n",
    "plt.imshow(image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply transformation\n",
    "transformed = transform(image=image)\n",
    "transformed_image = transformed[\"image\"]\n",
    "\n",
    "#Display original and transformed\n",
    "fig,ax = plt.subplots(ncols=2, figsize=(10,5))\n",
    "\n",
    "ax[0].imshow(image)\n",
    "ax[1].imshow(transformed_image)\n",
    "\n",
    "ax[0].set_title('Original')\n",
    "ax[1].set_title('Augmented')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Несколько аугментаций лучше чем одна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До 2021 года была принято проводить аугментации следующим образом: берем сэмпл, применяем к нему набор аугментаций с некоторой вероятностью (например p=0.5) и отправляем этот сэмпл в модель на обучение. В статье [Fort et al., 2021](https://arxiv.org/abs/2105.13343) предлагается способ, который работает лучше: берем сэмпл, дублируем его N раз и к каждому из дублей применяем свою аугментацию. \n",
    "\n",
    "Казалось бы, в каждом мини-батче становится меньше уникальных примеров, что должно бы негативно сказаться на способности к обобщению, но нет. Точность на тесте только увеличивается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/Fort_et_al_2021.jpg\"></center>\n",
    "<center><i>Пример двойной аугментации (Fort el al., 2021)</center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дисбаланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличение данных также полезно в ситуациях, когда определенных частях датасета данные ограничены, например, в задачах классификации, часто бывает, что в одних классах, сэмплов меньше чем, чем в других - ситуация. Такая проблема известна как **дисбаланс классов** (см. [Haixiang et al., 2017](https://www.sciencedirect.com/science/article/abs/pii/S0957417416307175) для обзора методов решения этой проблемы). Мы уже разбирали эту проблему в L11 в основном курсе. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/EXTRA_publish/img_license/undersampling_scheme.png\" width=\"400\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer-learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решить проблему недостаточного количества данных, частично можно при помощи transfer-learning - использования моделей, обученных на задачах близких к вашей. Эту проблему мы тоже разбирали подробно в L11 в основном курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, следует учитывать, что если количество данных ограничено, то, скорее всего, вам также придется ограничить сложность используемых моделей ML, поскольку модели с большим количеством параметров, например, глубокие нейронные сети, могут легко переобучаться на небольших датасетах. В любом случае важно выявить эту проблему на ранней стадии и разработать подходящую (и обоснованную) стратегию для ее решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/EXTRA_publish/img_license/transfer_learning.gif\" ></center>\n",
    "<center><i>Схематическое объяснение Transfer Learning. Сначала обучается модель на большом датасете, у нее замораживаются все веса кроме последнего слоя, далее последний слой обучается на интересующем  нас маленьком датасете.</center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обращайтесь к экспертам в своей области"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эксперты в области вашего исследования могут быть очень ценным источником данных, знаний и навыков. Они помогут вам понять, какие проблемы решать полезно, как выбрать наиболее подходящий набор данных и модель ML, а также как определить в каком журнале публиковать статью (аудитория какого журнала будет наиболее подходящей). Если не учитывать мнение экспертов, вы рискуете тем, что ваш проект не будет решать полезные проблемы или будет решать проблему неоптимальным или даже вредным способом (**например** использование неинтерпретирумой ML-модели для решения проблемы, в которой интерпретируемость критически важна, например, при принятии медицинских или финансовых решений, см. [Rudin, 2019](https://www.nature.com/articles/s42256-019-0048-x)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подумайте о том, как (и где) будет развернута ваша модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для чего вам модель ML? Как вы будете ее использовать? Это важные вопросы, и ответ них него должен повлиять на процесс разработки модели. Многие академические исследования по своей сути не подходят для создания моделей, которые будут использоваться в реальном мире (и это не беда, поскольку процесс построения и анализа моделей сам по себе может дать очень полезное понимание проблемы). Однако, у статей, в которых описываются модели, которые можно применять в реальных ситуациях, обычно, значительно выше цитирование. Так что, стоит заранее подумать о том, как и где ваша модель будет применяться.\n",
    "\n",
    "Например, если модель будет развернута в среде с ограниченными ресурсами, например, на датчике или роботе, это следует учитывать при разработке модели (на устройстве с маленьким объемом памяти запустить огромный трансформер просто не получится. Или например, если классификация сигнала должна быть выполнена в течение миллисекунд следует обратить особое внимание на потенциальную скорость инференса модели)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/robot.jpg\" width=\"500\"></center>\n",
    "<center><i>Пример среды с ограниченными ресурсами и требованиями к скорости работы</center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще одним нюансом может являться контекст того, как ваша модель будет связана с более широкой программной системой, в которой она будет развернута. Эта процедура зачастую далеко не проста (см. [Sculley et al., 2015](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)). Однако новые подходы, такие как [**ML Ops**](https://ml-ops.org/), направлены на решение некоторых трудностей (см. [Tamburri et al., 2020](https://research.tue.nl/en/publications/sustainable-mlops-trends-and-challenges))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как надежно строить модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение моделей - одна из самых приятных частей ML. С современными ML-фреймворками легко использовать всевозможные подходы к данным и смотреть, какая модель лучше всего решает поставленную задачу. Однако это может закончиться неорганизованным беспорядком экспериментов, которые потом сложно обосновать и о которых сложно написать статью. Поэтому важно подходить к построению моделей организованно, убедившись, что данные используются правильно, и что выбору модели уделено должное внимание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуйте различные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще говоря, не существует такой вещи, как единственная лучшая модель ML. Существует даже доказательство этого в виде теоремы **No Free Lunch**, которая показывает, что ни один подход ML не лучше другого, если рассматривать все возможные проблемы (см. [Wolpert, 2002](https://link.springer.com/chapter/10.1007/978-1-4471-0123-9_3)). \n",
    "\n",
    "Таким образом, ваша задача - найти модель ML, которая хорошо работает для вашей конкретной проблемы. Возможно, у вас есть некоторые *априорные* знания о том, какая модель подойдет лучше всего (например, в виде качественных исследований по схожим темам), но большую часть времени вам придется *работать в темноте*. К счастью, современные библиотеки ML в Python и т.д. позволяют опробовать несколько моделей с небольшими изменениями в коде, поэтому нет причин не опробовать несколько моделей и не выяснить для себя, какая из них работает лучше. \n",
    "<!-- \n",
    "В свете принципа \"бесплатного обеда\" важно избегать синдрома \"не здесь придумано\", т.е. использовать только те модели, которые были придуманы в вашем институте, такой подход скорее всего приведет к тому, что вы упустите лучшую модель для конкретной проблемы. -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не используйте неподходящие модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снижая барьер для имплементации, современные библиотеки ML также облегчают применение неподходящих моделей к вашим данным. В качестве примера можно привести применение моделей, предполагающих категориальные признаки, к набору данных, состоящему из числовых признаков, или попытку применить модель, предполагающую отсутствие зависимостей между переменными, к данным временного ряда. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это особенно важно учитывать в свете публикации, поскольку представление результатов, полученных с помощью несоответствующих моделей, создаст у рецензентов плохое впечатление о вашей работе. Другой пример - использование неоправданно сложной модели. Например, глубокая нейронная сеть - не лучший выбор, если у вас мало данных, и общие знания об области предполагают, что лежащая в основе модель довольно проста, или если модель должна быть интерпретируемой. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, не используйте \"современность\" модели в качестве оправдания для ее выбора: старые, проверенные модели часто работают лучше, чем новые."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Какие есть доступные ресурсы для обучения на GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU - крайне эффективный и ооооочень дорогой способ обучать модели. К счастью для вас - вы относитесь к привилегированному классу разработчиков машинного обучения - к классу исследователей, которым за GPU обычно платить не надо. Если вы можете обосновать зачем вам GPU - многие корпорации с удовольствием предоставят его бесплатно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Google Colab - в базовой версии - **бесплатный** способ обучать модели на GPU, но про него вы уже все знаете.\n",
    "*   [Kaggle](https://www.kaggle.com/code) - похожим на Colab образом работают и Kaggle Kernels. Бесплатно и без особенных бумажек (GPU goes brrrrrrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо бесплатных Colab и Kaggle, есть возможность получить доступ к серьезным ресурсам (несколько тысяч долларов на вычисления). У каждой программы немного свои правила, но в целом схема такая: пишете заявку, где рассказываете о своих исследованиях и объясняете зачем вам GPU. Затем отправляете заявку с официального университетского/институтского аккаунта и в течение месяца получаете свои кредиты.\n",
    "\n",
    "Основные программы:\n",
    "* [Google Research Credits](https://edu.google.com/programs/credits/research/?modal_active=none)\n",
    "* [Nvidia Research Grants](https://mynvidia.force.com/HardwareGrant/s/Application?ncid=so-twit-867980-vt16#cid=ix01_so-twit_en-us)\n",
    "* [Yandex Research Grants](https://cloud.yandex.ru/promo/datasphere-education)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Советы](https://mobile.twitter.com/artsiom_s/status/1434125597018632193?s=28) по использованию GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `DataLoader` по умолчанию имеет плохие настройки. Поменяйте `num_workers > 0` (например в Colab используйте 2 workers, в ColabPro с большим ОЗУ - 4)\n",
    "* Используйте `torch.backends.cudnn.benchmark = True` для тюнинга cuda kernels\n",
    "* Если применение позволяет - максимизируйте размер батча для максимальной нагрузки на GPU\n",
    "* Перед слоями нормализации не забывайте отключать bias (`bias=False`) - в этом случае, это лишний параметр, который только раздувает размер модели\n",
    "* Если вы работаете на нескольких GPU, используйте `DistributedDataParallel` даже если на самом деле ваши GPU не distributed\n",
    "* Обучайте с `float16`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оптимизируйте гиперпараметры вашей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многие модели имеют **гиперпараметры** - то есть числа или параметры, которые влияют на конфигурацию модели. Примерами могут служить: функция ядра, используемая в SVM; количество деревьев в случайном лесу и архитектура нейронной сети. Многие из этих гиперпараметров существенно влияют на производительность модели, и, как правило, универсальных гиперпараметров (таких, которые были бы оптимальны для всех возможных задач) не существует.\n",
    "\n",
    "То есть, чтобы получить максимальную отдачу от модели, гииперпараметры нужно подбирать под конкретный набор данных. Хотя может возникнуть соблазн возиться с гиперпараметрами до тех пор, пока вы не найдете что-то подходящее, такой подход, скорее всего, не будет оптимальным. Гораздо лучше использовать какую-то стратегию **оптимизации гиперпараметров** (в качестве бонуса, обоснованная стратегия, в публикации смотрится значительно лучше, чем что-то в стиле *hyperparameters were chosen by chance*). Базовые стратегии включают случайный поиск и поиск по сетке, но они не очень хорошо масштабируются для большого количества гиперпараметров или для моделей, которые дорого обучать, поэтому стоит использовать инструменты, которые ищут оптимальные конфигурации более интеллектуальным способом (исследовано в [Yang et al., 2020](https://arxiv.org/abs/2007.15745))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Библиотеки для оптимизации гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует довольно много библиотек для оптимизации гиперпараметров. Ключевыми являются [Ray-tune](https://docs.ray.io/en/latest/tune/index.html), [Optuna](https://optuna.readthedocs.io/en/stable/) и [Hyperopt](https://github.com/hyperopt/hyperopt). В целом они друг от друга принципиально не отличаются, так что скорее это вопрос вкуса. В качестве примера (и для разнообразия) рассмотрим библиотеку `Ray-Tune`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ray-Tune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ray[tune] tune-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.sklearn import TuneGridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state = 14)\n",
    "\n",
    "# Example parameters to tune from SGDClassifier\n",
    "parameter_grid = {\"alpha\": [1e-4, 1e-1, 1], \"epsilon\": [0.01, 0.1]}\n",
    "\n",
    "tune_search = TuneGridSearchCV(\n",
    "    SGDClassifier(),\n",
    "    parameter_grid,\n",
    "    early_stopping=True,\n",
    "    max_iters=10)\n",
    "\n",
    "tune_search.fit(x_train, y_train)\n",
    "\n",
    "#best set of perameter\n",
    "print(tune_search.best_params_)\n",
    "\n",
    "#best score with best set of perameters\n",
    "print(tune_search.best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запомните, когда вы оптимизируете гиперпараметры или признаки, используемые моделью, для их отбора нужно использовать отдельный, валидационный датасет, или же кросс-валидацию. Вы **НЕ должны подбирать модель или ее гиперпараметры на тесте**.\n",
    "\n",
    "Также можно использовать методы **AutoML** для оптимизации выбора модели и ее гиперпараметров (см. обзор в [He et al., 2021](https://arxiv.org/abs/1908.00709))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используйте систему для контроля за своими экспериментами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учитывая все сказанное выше, легко представить какой хаос будет твориться в процессе ваших экспериментов. Что бы этого избежать имеет смысл каким-то образом систематизировать экспериментальную фазу.\n",
    "\n",
    "В простейшем виде можно завести *git* репозиторий. Каждый раз когда вы меняете что-то в модели, делайте *commit*. Таким образом если что-то пойдет не так - у вас будет возможность откатить все назад.\n",
    "\n",
    "Отличной идеей будет использовать инструменты контроля типа [Tensorboard](https://www.tensorflow.org/tensorboard) или [Weights&Biases](https://wandb.ai/site), которые помимо прочего позволяют визуально сравнивать модели и их результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><table><tr>\n",
    "<td> <img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/tensorboard.gif\" width=\"970\"> </td>\n",
    "<td> <img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/weights_and_biases.jpeg\" > </td>\n",
    "</tr></table></center>\n",
    "\n",
    "<center><i>Примеры решений для организации эксперементов. Tensorboard и W&B</center></i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как надежно оценить модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достоверные результаты работы способствуют научному прогрессу в вашей области. К сожалению, переоценить возможности своей ML модели - очень легко. Поэтому тщательно продумайте, как именно вы собираетесь использовать данные в своих экспериментах, как вы собираетесь измерять истинную производительность ваших моделей и как вы собираетесь сообщать об этой производительности в содержательной и информативной форме.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используйте соответствующий тестовый датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде всего, всегда используйте тестовый набор для измерения обобщающей способности модели ML. То, насколько хорошо модель работает на обучающем множестве (*train set*), на практике не имеет никакого значения, и достаточно сложная модель может на нем полностью переобучится, но так и не научится обобщать тестовые данные. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/EXTRA_publish/img_license/early_stopping.png\" width=\"550\"></center>\n",
    "<center><i>Переобучение модели</center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также важно убедиться, что данные в тестовом наборе на самом деле подходят. То есть, они не должны пересекаться с обучающим набором и в то же время в достаточной степени отражать реальные данные. **Например**, рассмотрим датасет фотографий объектов, где изображения в обучающем и тестовом наборе были получены на открытом воздухе в солнечный день. Наличие одинаковых погодных условий означает, что тестовое множество не будет независимым, а поскольку оно не охватывает более широкий спектр погодных условий, оно также не будет репрезентативным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/EXTRA_publish/img_license/husky.png\" width=\"850\"></center>\n",
    "<center><i>Первая строка - обучающие данные (обратите внимания, что все хаски были сфотографированы летом, а волки зимой). Вторая строка - тестовые данные (нейросеть выучила, что лето - это признак хасок, по этому она не правильно предсказывает класс волков).</center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичные ситуации могут возникать, когда для сбора обучающих и тестовых данных используется разное оборудование. **Например**, для обучения вы используете томограф из одного госпиталя, а оценку качества модели проводите на томографе из другого госпиталя. Если модель не учитывает характеристики оборудования, она, скорее всего, не будет обобщаться на томограф из второй больницы (при этом на своем собственном датасете из первого госпиталя, эту ошибку вы отловить не сможете)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фиксируйте случайные состояния"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многие модели ML нестабильны. То есть, если вы обучаете их несколько раз, или если вы вносите небольшие изменения в обучающие данные, их производительность может значительно измениться. С этим можно и нужно бороться путем фиксации всех *random seeds* и переводом модели на детерминистические операции. Такая внимательность к деталям так же позволит другим исследователям *на самом деле* воспроизвести ваши результаты.\n",
    "\n",
    "Что бы зафиксировать все *random states* можно использовать следующий кусок кода исполняемый в начале файла/блокнота."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используйте метрики подходящие задаче"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будьте внимательны к тому, какие метрики вы используете для оценки моделей ML. Например, в случае моделей классификации наиболее часто используемой метрикой является точность (*accuracy*), которая представляет собой долю образцов в наборе данных, которые были правильно классифицированы моделью. Точность хорошо работает, если ваши классы сбалансированы, т.е. если каждый класс представлен примерно одинаковым количеством образцов в наборе данных. Но многие наборы данных не сбалансированы, и в этом случае точность может быть очень обманчивой метрикой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим набор данных в котором 90\\% образцов представляют один класс, а 10\\% образцов - другой класс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=42, cluster_std=7)\n",
    "plt.scatter(X[:,0], X[:,1],c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И искусственно создадим в нем дисбаланс классов (мы хотим получить распределение 90\\% и 10\\%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_0, y_0 = X[y==0], y[y==0]\n",
    "X_1, y_1 = X[y==1], y[y==1]\n",
    "\n",
    "rnd_indx = np.random.choice(range(len(X_1)), int(len(X_1)*0.1), replace=False)\n",
    "\n",
    "X_new, y_new = np.vstack([X_0, X_1[rnd_indx]]), np.hstack([y_0, y_1[rnd_indx]])\n",
    "\n",
    "plt.scatter(X_new[:,0], X_new[:,1],c=y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь попробуем классифицировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_new, y_new, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# normalize data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# predict using each classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(\"Точность классификации = %.2f процентов\" % (score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какая замечательная точность! Но, бинарный классификатор, который всегда выдает первый класс, независимо от его входа, будет иметь точность около 90\\%, несмотря на то, что он совершенно бесполезен."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В такой ситуации предпочтительнее использовать такие метрики, как коэффициент каппа Коэна ($\\kappa$) или коэффициент корреляции Мэтьюса (MCC), которые относительно нечувствительны к дисбалансу размеров классов. Более широкий обзор методов работы с несбалансированными данными см. в [Haixiang et al., 2017](https://www.sciencedirect.com/science/article/abs/pii/S0957417416307175) и в блоге [Дьяконова](https://dyakonov.org/2021/05/27/imbalance/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепроверим результаты с помощью MCC. Коэффициент корреляции Мэтьюса учитывает истинные и ложные положительные и отрицательные результаты и обычно считается сбалансированной мерой, которую можно использовать, даже если классы сильно отличаются друг от друга. По сути, MCC - это значение коэффициента корреляции между -1 и +1. Коэффициент +1 представляет собой идеальное предсказание, 0 - среднее случайное предсказание, а -1 - обратное предсказание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print('MCC=%.2f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так себе результаты, неправда ли?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если данных какого-то конкретного класса мало, можно, например, провести **стратификацию**, которая гарантирует, что каждый класс будет адекватно представлен в каждой складке/выборке (например с помощью метода [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) в библиотеке `sklearn`). А так же учеесть баланс классов в самом классификатор (или в случае с нейросетью в DataLoader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Split data into 5 folds\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "kf.get_n_splits(X_new, y_new)\n",
    "\n",
    "mcc_scores = []\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=5, n_estimators=10, \n",
    "                                    max_features=1, class_weight = \"balanced\", \n",
    "                                    random_state=42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Itterate over folds\n",
    "for train_index, test_index in kf.split(X_new, y_new):\n",
    "    #Split\n",
    "    X_train, X_test = X_new[train_index], X_new[test_index]\n",
    "    y_train, y_test = y_new[train_index], y_new[test_index]\n",
    "\n",
    "    #Normalize\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    #Classify\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    #Gauge performance\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    mcc_score = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    mcc_scores.append(mcc_score)\n",
    "\n",
    "print('Average MCC on stratified 5-fold = %.2f ± %.2f' % (np.mean(mcc_scores), np.std(mcc_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как справедливо сравнивать модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение моделей является основой академических исследований, но сделать его правильно - сложно. Нечестно проведенное и опубликованное сравнение может ввести в заблуждение других исследователей. Что бы этого избежать, убедитесь, что вы оцениваете различные модели в одном и том же контексте, учитываете несколько точек зрения и правильно используйте статистические тесты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Не думайте, что большее число означает лучшую модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не редкость, когда в статье говорится что-то вроде \"В предыдущих исследованиях сообщалось о точности до 94\\%. Наша модель достигла 95\\%, и поэтому она лучше.\" Существуют различные причины, по которым более высокий показатель не всегда означает лучшую модель. **Например**, если модели обучались или оценивались на разных разделах одного и того же набора данных, то небольшие различия в производительности могут быть вызваны этим. Или, если вы использовали совершенно разные наборы данных при сравнении - возможно большие различия в производительности объясняются именно данными. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой причиной несправедливого сравнения является неспособность провести одинаковый объем оптимизации гиперпараметров при сравнении моделей; например, если одна модель тестируется с настройками по умолчанию, а другая была дополнительно оптимизирована, то сравнение не будет справедливым. **Например** в статье [Csordás et al., 2021](https://arxiv.org/abs/2108.12284) авторы демонстрируют, что, просто пересмотрев такие базовые конфигурации модели, как масштабирование эмбедингов, early stopping, relative positional embeddings и другие гиперпараметры, можно значительно улучшить обобщающую способность трансформеров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому, к сравнениям, основанным на опубликованных цифрах, всегда следует относиться с осторожностью. Чтобы действительно быть уверенным в справедливости сравнения двух подходов, вам следует заново реализовать все сравниваемые модели, оптимизировать каждую из них в одинаковой степени, провести множественные оценки, а затем использовать статистические тесты, чтобы определить, являются ли различия в производительности значительными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, ничего страшного, если точность вашей модели сравнима или чуть хуже, чем существующие методы. Возможно у вашей модели выше скорость инференса? Или может быть, она интерпретируема? Подумайте об этом и изложите свои заключения в четкой и ясной форме в статье."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используйте статистические тесты при сравнении моделей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите убедить людей в том, что ваша модель лучше, чем чья-то другая, то статистический тест - очень полезный инструмент. В широком смысле существует две категории тестов для сравнения отдельных моделей ML.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестирование Макнемара\n",
    "\n",
    "Первая категория тестов используется для сравнения отдельных моделей (например, двух обученных деревьев решений). Рассмотрим *McNemar's test*, который является довольно распространенным выбором для сравнения двух классификаторов, и работает путем сравнения выходных меток классификаторов для каждой выборки в тестовом наборе (поэтому не забудьте записать их). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "names = [\n",
    "    \"Linear SVM\",\n",
    "    \"Random Forest\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "]\n",
    "\n",
    "X, y = make_moons(noise=0.3, random_state=42, n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess dataset, split into training and test part\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# normalize data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# predict using each classifier\n",
    "predictions, scores = [], []\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    correct_prediction = clf.predict(X_test) == y_test\n",
    "    predictions.append(correct_prediction)\n",
    "    scores.append([name, clf.score(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим *contingency table*, которая будет иметь следующую структуру:\n",
    "\n",
    "|   | Classifier 2 correct  | Classifier 2 incorrect  |\n",
    "|---|---|---|\n",
    "|Classifier 1 correct|??|??|\n",
    "|Classifier 1 incorrect|??|??|\n",
    "\n",
    "В случае с первой ячейкой таблицы мы должны просуммировать общее количество тестовых случаев, которые Classifier 1 предсказал правильно, и Classifier 2 тоже предсказал правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим в каких индексах Classifier 1 и Classifier 2 правильно предсказали класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls1_correct_index = np.where(predictions[0] == True)[0]\n",
    "cls2_correct_index = np.where(predictions[1] == True)[0]\n",
    "\n",
    "cls1_correct_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем сколько сэмплов оба классификатора посчитали правильно (длинна Union между ними) - это и будет наша первая ячейка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row_first_column = len(np.union1d(cls1_correct_index, cls2_correct_index))\n",
    "first_row_first_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим операцию для остальных ячеек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls1_incorrect_index = np.where(predictions[0] == False)[0]\n",
    "cls2_incorrect_index = np.where(predictions[1] == False)[0]\n",
    "\n",
    "second_row_first_column = len(np.union1d(cls1_incorrect_index, cls2_correct_index))\n",
    "first_row_second_column = len(np.union1d(cls1_correct_index, cls2_incorrect_index))\n",
    "second_row_second_column = len(np.union1d(cls1_incorrect_index, cls2_incorrect_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим нашу *contingency table*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[first_row_first_column, second_row_first_column],\n",
    "                 [first_row_second_column, second_row_second_column]])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем тестирование Макнемара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import pandas.util.testing as tm\n",
    "\n",
    "result = mcnemar(data, exact=True)\n",
    "# summarize the finding\n",
    "print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n",
    "\n",
    "# interpret the p-value\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "\tprint('Same proportions of errors (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как интерпретировать результат? Два термина, используемые при расчете теста Макнемара, отражают ошибки, допущенные обеими моделями. В частности, ячейки \"Нет/Да\" и \"Да/Нет\" в таблице случайностей. Тест проверяет, существует ли значительная разница между подсчетами в этих двух ячейках. Вот и все.\n",
    "\n",
    "Если эти ячейки имеют одинаковые значения, это говорит о том, что обе модели допускают ошибки в одинаковой пропорции, просто на разных экземплярах тестового набора. В этом случае результат теста не будет значимым, и нулевая гипотеза не будет отвергнута (Согласно нулевой гипотезе, оба алгоритма должны иметь одинаковый коэффициент ошибок ...)\n",
    "\n",
    "Если в этих ячейках подсчеты не совпадают, это показывает, что обе модели не только совершают разные ошибки, но и фактически имеют разную относительную долю ошибок на тестовом множестве. В этом случае результат теста будет значимым, и мы отвергнем нулевую гипотезу.\n",
    "\n",
    "Таким образом, мы можем отвергнуть нулевую гипотезу в пользу гипотезы о том, что два алгоритма имеют разную производительность при обучении на конкретном обучающем множестве.\n",
    "\n",
    "В нашем случае получили, что обе модели делают похожее количество ошибок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом если мы посмотрим на точность обоих классификаторов мы обнаружим, что один из них работает лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем сделать обоснованный вывод, что Random Forest справляется с задачей лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Т-тест Стьюдента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая категория тестов используется для более общего сравнения двух моделей, например, для определения того, какое дерево решений или нейронная сеть лучше подходит для данных. Они требуют множественных оценок каждой модели, которые можно получить с помощью кросс-валидации или повторной выборки (или, если алгоритм обучения стохастический, многократных повторений на одних и тех же данных). Затем тест сравнивает два результирующих распределения. *T-тест Стьюдента* является распространенным выбором для такого сравнения, но он надежен только в случае нормального распределения, что часто бывает не так. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сделайте поправку на множественное сравнение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все становится немного сложнее, когда вы хотите использовать статистические тесты для сравнения более чем двух моделей, поскольку проведение нескольких парных тестов сродни многократному использованию тестового набора - оно может привести к слишком оптимистичным интерпретациям значимости. В принципе, каждый раз, когда вы проводите сравнение двух моделей с помощью статистического теста, существует вероятность того, что он обнаружит значимые различия там, где их нет. Это отраженно в доверительных интервалах теста, который обычно устанавливается на уровне 95\\%: это означает, что в 1 случае из 20 тест даст ложный результат. Для единичного сравнения такой доверительный интервал может быть уровнем неопределенности, с которым можно смириться. Однако неопределенность накапливается. То есть, если вы проведете 20 парных тестов с уровнем достоверности 95\\%, один из них, скорее всего, даст вам неверный ответ. Такой эффект называется **эффектом множественности**, и является примером более широкой проблемы в науке о данных, известной как **выкапывание данных** (*data dredging*) или **p-хакинг** ([Head et a., 2015](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002106)). \n",
    "\n",
    "Один из самых известных случаев связанных с эффектом множественности был даже награжден Шнобеелевской премией в 2012 году. Группа ученых [обнаружила](https://teenspecies.github.io/pdfs/NeuralCorrelates.pdf) значительную мозговую активность у мертвого лосося. В этом исследовании авторы изучали активность мозга на 130 000 вокселей в типичном объеме фМРТ. Из-за большого количества тестов, вероятность получения как минимум одного ложноположительного результата была почти стопроцентной (так и произошло)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Чтобы решить эту проблему, можно применить поправку на множественные тесты. Наиболее распространенным подходом является поправка Бонферрони, очень простой метод, который снижает порог значимости в зависимости от количества проводимых тестов (см. [Salzberg, 1997](https://link.springer.com/article/10.1023/A:1009752403260) и [конкретный пример на Python](https://towardsdatascience.com/an-overview-of-the-multiple-comparison-problem-166aa5fcaac5)). \n",
    "\n",
    "Вообще, для решения проблемы эффекта множественности существует множество разных подходов, а споры о том, когда и где следует применять эти поправки ведутся до сих пор (доступный обзор см. в [Streiner et al., 2015](https://academic.oup.com/ajcn/article/102/4/721/4564678)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не доверяйте результатам community benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В некоторых проблемных областях стало обычным делом использовать эталонные наборы данных (*benchmarks*) для оценки новых моделей ML. Кажется, что, поскольку все используют одни и те же данные для обучения и тестирования своих моделей, сравнения будут более прозрачными. К сожалению, этот подход имеет ряд существенных недостатков. Во-первых, если доступ к тестовому набору неограничен, то стоит исходить из предположения, что люди использовали его в процессе обучения, что приводит к data leakage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более тонкая проблема заключается в том, что даже если каждый, кто использует данные, использует тестовый набор только один раз, в совокупности, тестовый набор используется сообществом много раз. В результате сравнивая множество моделей на одном и том же тестовом наборе, становится все более вероятным, что лучшая модель просто слишком хорошо подходит к тестовому набору и необязательно обладает более высокой обобщающей способностью, чем другие модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По этой и другим причинам следует внимательно относиться к результатам, полученным с помощью эталонного набора данных, и не считать, что небольшое увеличение производительности является значительным. См. [Paullada et al., 2020](https://arxiv.org/abs/2012.05345) для более обширного обсуждения вопросов, связанных с использованием общих наборов данных.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рассмотрите комбинации моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотя этот раздел и посвящен сравнению моделей, полезно держать в голове, что процесс машинного обучения не всегда заключается в выборе между различными моделями. Часто имеет смысл использовать комбинации моделей. Различные модели исследуют различные компромиссы; комбинируя их, вы можете иногда компенсировать слабые стороны одной модели за счет использования сильных сторон другой модели, и наоборот. Такие комбинированные модели известны как **ансамбли**, а процесс их создания известен как **обучение ансамблей** (см. обзор подходов к обучению ансамблей в [Dong et al., 2019](https://link.springer.com/article/10.1007/s11704-019-8208-z)). \n",
    "\n",
    "Общее соображение в обучении ансамблей заключается в том, как объединить различные базовые модели; подходы к этому варьируются от очень простых методов, таких как голосование или взвешенное голосование, до более сложных подходов, которые используют другую модель ML для объединения выходов базовых моделей. Этот последний подход часто называют **стекинг**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как сообщать о результатах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы внести эффективный вклад в научное знание, вам необходимо предоставить полную картину вашей работы, охватывающую как то, что получилось, так и то, что не получилось. ML часто связан с компромиссами - очень редко бывает, что одна модель лучше другой во всех отношениях, и вы должны постараться отразить это, используя тонкий и взвешенный подход к изложению результатов и выводов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Будьте прозрачны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде всего, всегда старайтесь быть прозрачным в отношении того, что вы сделали и что обнаружили, так как это облегчит другим людям использование ваших наработок. В частности, хорошая практика - делиться своими моделями в доступной форме. Например, если вы использовали скрипт для проведения всех экспериментов, опубликуйте этот скрипт после публикации результатов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Хорошим примером** воспроизводимых исследований может служить [AlphaFold](https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb) - блокнот в Colab сопровождающий статью [Highly accurate protein structure prediction with AlphaFold (Jumper et al., 2021)](https://www.nature.com/articles/s41586-021-03819-2). В этом блокноте одновременно присутствует несколько вещей - во-первых, для того что бы им пользоваться не нужно ничего устанавливать; во-вторых, он снабжен более менее приличным графическим интерфейсом, что сильно упрощает использование для не-програмистов; ну и в третьих, при желании, код можно посмотреть \"не отходя от кассы\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно, что бы другие люди могли легко повторить ваши эксперименты. Воспроизводимость придает убедительности вашей работе. Она также значительно облегчает людям сравнение моделей, поскольку им больше не придется все реализовывать с нуля (чтобы обеспечить справедливое сравнение). Само по себе знание того, что вам придется поделиться своей работой, также может побудить вас быть более осторожными, хорошо документировать свои эксперименты и писать чистый код. \n",
    "\n",
    "Стоит также отметить, что в ближайшем будущем вы, возможно, не сможете опубликовать работу, если ваш рабочий процесс не был надлежащим образом задокументирован и распространен - например, см. [Pineau et al., 2020](https://arxiv.org/abs/2003.12206).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сообщайте о результатах работы различными способами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из способов достижения большей строгости при оценке и сравнении моделей является использование нескольких наборов данных. Это помогает преодолеть любые недостатки, связанные с отдельными наборами данных, и позволяет представить более полную картину работы вашей модели. Также хорошей практикой является представление нескольких метрик для каждого набора данных, поскольку разные метрики могут представить различные точки зрения на результаты и повысить прозрачность вашей работы. **Например**, если вы используете точность, то нелишним будет включить метрики, которые менее чувствительны к дисбалансу классов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы используете частичную метрику, такую как precision, recall, sensitivity или specificity, также включите метрику, которая дает более полное представление об уровне ошибок вашей модели. Убедитесь, что понятно, какие метрики вы используете. Например, если вы сообщаете F-score, уточните, идет ли речь о F1 или о каком-то другом балансе между precision и recall. Если вы сообщаете AUC, укажите, является ли это площадью под кривой ROC или кривой PR. Для более широкого обсуждения смотрите [Blagec et al., 2020](https://arxiv.org/abs/2008.02577).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не делайте обобщений, выходящих за рамки данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно не представлять недействительные выводы, поскольку это может сбить с пути других исследователей. Распространенная ошибка - делать общие заявления, которые не подтверждаются данными, использованными для обучения и оценки моделей. **Например**, если ваша модель действительно хорошо работает на одном наборе данных, это не означает, что она будет хорошо работать и на других наборах данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотя вы можете получить более надежные выводы, используя несколько наборов данных, всегда существуют ограничения на выводы из любого экспериментального исследования. Этому есть множество причин (см. [Paullada et al., 2020](https://arxiv.org/abs/2012.05345)), многие из которых связаны с тем, как составлены наборы данных. Одной из распространенных проблем является предвзятость, или **ошибка выборки**: данные недостаточно репрезентативны для реального мира. Другая проблема - дублирование: несколько наборов данных могут не быть независимыми и иметь схожие предубеждения (*biases*). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует также проблема качества: она особенно актуальна для наборов данных глубокого обучения, где необходимость в количестве данных ограничивает объем проверки качества, которую можно провести. Короче говоря, не преувеличивайте свои результаты и помните об их ограничениях.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Будьте осторожны, сообщая о статистической значимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже обсуждали статистические тесты, и как их можно использовать для определения различий между ML-моделями. Однако статистические тесты не совершенны. Некоторые из них консервативны и склонны занижать значимость, другие либеральны и склонны значимость наоборот завышать. Таким образом, положительный тест не всегда означает, что что-то является значимым, а отрицательный тест не обязательно означает, что что-то значимым не является. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, существует проблема использования порога для определения значимости; например, 95\\% доверительный порог (т.е. p-значение $<$ 0.05) означает, что 1 из 20 случаев разница, отмеченная как значимая, не будет значимой. На самом деле, статистики все чаще утверждают, что лучше не использовать пороговые значения, а вместо этого просто сообщать p-значения и предоставить читателю самому их интерпретировать. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо статистической значимости, необходимо также учитывать, действительно ли разница между двумя моделями важна. Если у вас достаточно данных, вы всегда можете найти значительные различия, даже если фактическая разница в производительности ничтожна. Чтобы лучше понять, является ли что-то важным, можно измерить **размер эффекта** (*effect size*). Для этого используется целый ряд подходов: $d$ статистика Коэна, вероятно, самая распространенная, но более надежные подходы, такие как Колмогорова-Смирнова, предпочтительнее. Подробнее об этом см. в [Betensky, 2019](https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1529624)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрите на свои модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обученные модели содержат много полезной информации. К сожалению, многие авторы просто сообщают показатели эффективности обученной модели, не давая никакого объяснения тому, чему она на самом деле научилась. Помните, что цель исследования не в том, чтобы добиться чуть более высокой точности, чем все остальные. Скорее, она заключается в том, чтобы генерировать знания и понимание и делиться ими с исследовательским сообществом. Если вы сможете это сделать, то вероятность того, что ваша работа получит достойную публикацию, значительно возрастет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошим **примером** может служить недавняя статья [Causal ImageNet: How to discover spurious features in Deep Learning? (Singla et al., 2021)](https://arxiv.org/abs/2110.04301), в которой очень подробно разбираются *причинные* и *ложные* признаки, на основании которых модель делает предсказания относительно содержания картинок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><i><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/Singla_et_al_2021.jpg\" width=\"750\" ></center></i>\n",
    "\n",
    "<center><i>Пример ложных признаков (Singla et al., 2021)</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Попробуйте \"заглянуть внутрь\" своей итоговой модели.** Для относительно простых моделей, таких как деревья решений, также может быть полезно предоставить визуализацию ваших моделей (в большинстве библиотек есть функции, которые сделают это за вас). Для сложных моделей, таких как глубокие нейронные сети, рассмотрите возможность использования методов **объяснимого ИИ** (Explainable AI - XAI, рассмотрено в [Belle et al., 2021](https://www.frontiersin.org/articles/10.3389/fdata.2021.688969/full)); они вряд ли расскажут, что именно делает модель, но могут дать вам некоторые полезные идеи. Имейте в виду, с XAI - тоже не все так радужно, и в нем есть подводные камни (см. разбор в [Eshan et al., 2021](https://arxiv.org/abs/2109.12480))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><i><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/Rudin_2019.jpg\" width=\"850\" ></center></i>\n",
    "\n",
    "<center><i>Свидетельства того, что на изображении Сибирская хаски и флейта (Rudin, 2019)</center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент известно множество подходов для интерпретации предсказаний моделей, в том числе сложных моделей типа нейронных сетей. \n",
    "К таким относятся [SHAP](https://github.com/slundberg/shap), [LIME](https://github.com/marcotcr/lime), [Grad-Cam](https://github.com/jacobgil/pytorch-grad-cam) и многие другие. Существуют и методы, дающие более точную интерпретацию, но для конкретных моделей. \n",
    "\n",
    "Если вы сможете изучить на что обращает внимание ваши модели - вы сможете: понять, какая модель обращает внимание на более разумные признаки; насколько устойчиво то, на какие признаки обращают внимание модели; найти уже упомянутые артефакты в данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проведите абляционные исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эксперименты, выявляющие артефакты данных и моделей, или *абляционные исследования*, как их называет [Heinzerling, 2019](https://thegradient.pub/nlps-clever-hans-moment-has-arrived/), можно рассматривать, как часть процесса интерпретации модели. Они включают в себя простые или бессмысленные *baselines*.\n",
    "\n",
    "**Например**, в статье [Ishaq, 2016](https://journals.sagepub.com/doi/full/10.1177/1087057116667894?journalCode=jbxb) авторы классифицировали рыб по изображению. Для того, что бы провести абляционное исследование, они **маскировали разные части** рыб в обучающей выборке (ну точнее сам сэт-ап эксперимента позволял находить такие кадры, где видна только голова или только хвост рыбы). В процессе экспериментов, они заметили, что классификатор, в большей степени, основывает свои предсказания на форме рыбьих голов, чем на форме их хвостов.\n",
    "\n",
    "Еще в качестве абляции можно попробовать обучить модель на бессмысленных признаках полученных перемешиванием исходных признаков и многое другое (см. например, [Meyes, 2019](https://arxiv.org/abs/1901.08644)).\n",
    "\n",
    "Стоит учитывать, что в современном мире машинного обучения, опубликовать статью без абляций становиться все более и более затруднительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общие советы по написанию статей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зачастую, выбирать журнал следует еще до того как закончена экспериментальная часть. Не откладывайте этот выбор слишком надолго, так как от него зависит что именно будет написано в статье. Например, какие-то журналы очень технические, и сосредоточены на деталях метода и методологии. Какие-то, наоборот просят выносить технические детали в Supplimentary Materials и требуют основного фокуса на применениях и/или выводах и последствиях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как выбрать журнал?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подумайте о людях, с которыми вы хотите поделиться своими результатами. Кто они? Чем они занимаются? Где работают? На каком языке разговаривают? Найдите несколько конкретных людей, соответствующих вашему описанию и спросите у них, какие журналы они читают. Скорее всего, наиболее подходящим для вас, будет тот журнал, который появлялся в ответах чаще всего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Полезные инструменты для написания статей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Английский язык, для многих из нас не является родным (и даже не тем языком, на котором мы свободно разговариваем). При этом английский - де-факто язык международной науки. \n",
    "\n",
    "Вам повезло, если в ваших соавторах есть носитель языка, или коллега, который много лет работал в Европе или США, но чаще всего - доступа к таким коллегам у нас нет.\n",
    "\n",
    "⚠️ **DISCLAIMER**: *Всем, о чем пойдет речь дальше, следует пользоваться с большой осторожностью и не пренебрегать дополнительными проверками.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хороший способ перевести текст с русского на английский (хотя луче бы вы сразу писали статью на английском) - воспользоваться переводчиком [DeepL](https://www.deepl.com/translator), он довольно неплохо справляется со сложными научными и техническими текстами + в него встроено редактирование \"на ходу\" (то есть, на каждое слово - можно посмотреть несколько вариантов перевода)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗ **КАРТИНКА С DEEPL**\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/deepl.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже написанные на английском тексты, часто требуется перефразировать, например, когда вы описываете результаты исследований других людей или просто считаете, что написанное не доносит тот смысл, который вы хотели донести. Тут на помощь приходит инструмент [Wordtuna](https://www.wordtune.com/), который позволяет перефразировать любое предложение другими словами. Опять-таки, часто в предложенных вариантах встречается белиберда, так что пользуйтесь внимательно и аккуратно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/EXTRA_publish/WORDTUNE.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто, когда мы пишем на английском, у нас страдает грамматика и орфография (да что уж на английском, на русском тоже). С помощью [Grammarly](https://app.grammarly.com/) можно, как минимум, часть ошибок обнаружить и поправить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один инструмент, [GPT-J](https://6b.eleuther.ai/), вообще не стоит рассматривать в серьез как инструмент для научной коммуникации. Тем не менее им можно пользоваться для вдохновения. Например, часто мы начинаем писать предложение и еще не уверены (далее *курсив* - дополнено GPT-J), *что сказать. Поэтому мы записываем слова одно за другим, в произвольном порядке. Затем мы смотрим на записанные слова. Затем мы начинаем думать о том, как связать эти слова друг с другом. Затем мы снова записываем предложение. Иногда мы вносим изменения. Иногда мы начинаем сначала. Иногда мы думаем, что это никуда не годится, и выбрасываем предложения.*\n",
    "\n",
    "В общем вы поняли идею."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Советы по структуре и стилю статьи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to write a first-class paper (Gewin, 2018)](https://www.nature.com/articles/d41586-018-02404-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статьи часто имеют жестко определенную структуру, но все таки, наличие структуры не противоречит возможности рассказать захватывающую историю (т.е. такую, которая ясно передает научные знания и которую приятно читать). Давайте обсудим как этого можно добиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Излагайте свою мысль четко"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подумайте, какое послание вы хотите донести до читателей. \n",
    "\n",
    "Самая важная информация должна быть в **основном тексте**. Чтобы не отвлекать внимание, авторам следует помещать дополнительные материалы в соответствующие разделы статьи  (*supplimentary material* или *appendix*).\n",
    "\n",
    "Бесчисленное количество рукописей отклоняется из-за того, что **разделы введение и обсуждение** (*introudction and discussion*) настолько слабы, что очевидно, что автор не имеет четкого представления о существующей литературе. Авторы должны продемонстрировать свои результаты в глобальном контексте, чтобы доказать значительность и/или оригинальность их результатов.\n",
    "\n",
    "Существует узкая грань между спекуляциями и выводами, основанными на доказательствах. Автор может спекулировать в дискуссии - но не слишком много. Если обсуждение состоит из одних домыслов, оно не годится, поскольку не основано на опыте автора. \n",
    "\n",
    "**В заключении**, в одном-двух предложениях расскажите о том, какие исследования вы планируете провести в будущем и что еще необходимо изучить (*outline*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создайте логичную структуру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Структура имеет первостепенное значение**. Попробуйте сделать так: в каждом абзаце первое предложение определяет контекст, основная часть содержит какую-то идею, а последнее предложение дает какое-то заключение. Для всей статьи введение задает контекст, результаты представляют содержание, а обсуждение подводит к выводу (совет из [Mensh et al., 2017](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005619)).\n",
    "\n",
    "Очень важно сфокусировать вашу работу **на одной ключевой идее**, которую вы сообщаете в заголовке. Все в статье должно логически и структурно поддерживать эту идею.\n",
    "\n",
    "Вы должны подвести наивного читателя к тому моменту, когда он будет готов усвоить то, что вы сделали. Как писатель, вы должны подробно описать проблему. Читатель не будет понимать, почему его должен волновать ваш эксперимент, пока вы не объясните ему, почему он должен сопереживать вашей работе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уверенно излагайте свои доводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ на один главный вопрос - \"Что вы сделали? - является ключом к определению структуры статьи. Каждый раздел рукописи должен поддерживать эту **одну** фундаментальную идею.\n",
    "\n",
    "Не бойтесь делать уверенные заявления, иначе получится вялое или запутанное письмо, которое звучит оборонительно, со слишком большим количеством оговорок и длинных списков - как будто вы пишите, чтобы отбиться от критики, которая еще не была высказана.\n",
    "\n",
    "Задача читателя - обратить внимание и запомнить прочитанное. Задача писателя - сделать эти две вещи легкими."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Остерегайтесь \"существительных-зомби\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомните себя, когда вы читаете статьи других людей. Скорее всего вы заняты и устали. Вполне вероятно, что читатели ваших статей будут себя чувствовать так же.\n",
    "\n",
    "Нет ни одной предпосылки к тому, что бы научные статьи были скучными, сухими и абстрактными. Люди - любят и умеют рассказывать истории. Конечно, научная литература должна быть фактологической, краткой и доказательной, но это не значит, что она не может быть увлекательной - рассказанной оригинальным голосом. Если науку не читают, ее не существует.\n",
    "\n",
    "Автор Хелен Суорд придумала выражение \"существительные-зомби\" для обозначения таких терминов, как \"внедрение\" или \"применение\", которые высасывают кровь из активных глаголов. Постарайтесь задействовать эмоции читателей и избегать формального, безличного языка. Тем не менее соблюдайте баланс. Не сенсационизируйте науку.\n",
    "\n",
    "Авторы научных статей должны с осторожностью относиться к \"творчеству\". Креатив - это конечно хорошо, но цель научной статьи - передать информацию. Вот и все. Изюминки могут отвлекать. Сделайте текст настолько простым и понятным, насколько это возможно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ориентируйтесь на широкую аудиторию\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недавнее исследование [(Girolamo et al., 2017)](https://www.jclinepi.com/article/S0895-4356(16)30853-8/fulltext) показывает, что статьи с четкими, лаконичными, декларативными заголовками имеют больше шансов получить отклик в социальных сетях или популярной прессе.\n",
    "\n",
    "Излагайте свою точку зрения четко и кратко - по возможности неспециализированным языком, чтобы читатели из других областей могли быстро понять ее смысл (или если термины использовать все-таки приходится - поясняйте их для читателей, которые могут быть менее знакомы с темой).\n",
    "\n",
    "Если вы пишете доступным для неспециалистов языком, вы открываете себе возможность для цитирования экспертами из других областей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cover letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Crafting cover letters, 2021](https://www.nature.com/articles/s41561-021-00824-y)\n",
    "\n",
    "И вот, наконец то, статья дописана и пришла пора ее отправить в журнал. Во время подачи, вас попросят прислать сопроводительное письмо (*Cover Letter*) для редактора.  Сопроводительные письма, подчеркивающие выводы исследования и сообщающие детали, имеющие отношение к процессу рецензирования, являются важной частью подачи рукописей, даже если их читают только авторы и редакторы. Однако написание этих писем может показаться дополнительным бременем. Почему писать хорошие письма все таки важно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сопроводительные письма могут предоставить редакторам **ценный контекст** (соответствует ли исследование тематике журнала, место выводов по отношению к открытым, важным научным вопросам).\n",
    "\n",
    "Не ломайте голову над тем, как адресовать письмо - достаточно простого \"*Уважаемый редактор*\" (можно адресовать конкретным редакторам, особенно если вы уже общались с ними ранее). Постарайтесь перед отправкой убедиться, что письмо **адресовано правильному журналу**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Будьте лаконичны**. Это ваш шанс непринужденно побеседовать о своей работе с редактором, и **одной страницы** обычно бывает достаточно. Воодушевление - это нормально (вы же рассказываете о конечном результате тяжелой работы), но гиперболизацию следует свести к минимуму. Гораздо полезнее **объяснить**, почему исследование представляет собой важный научный результат, вместо того, чтобы постоянно заявлять об этом. Если работа имеет более широкое общественное или политическое значение за пределами вашей области науки, это также стоит упомянуть. **Сосредоточьтесь на самом исследовании, а не на резюме авторов**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылки на другие исследования не обязательны, но могут быть полезны в некоторых обстоятельствах. Сопроводительные письма - подходящее место, чтобы объяснить, **как текущее исследование связано** с другими опубликованными или (особенно) еще не опубликованными работами вас или ваших соавторов. Предупредите, если публикация вашего исследования будет зависеть от публикации другого.\n",
    "\n",
    "При выборе работ для рецензирования редакторы учитывают новизну, поэтому краткое обсуждение других исследований с похожими выводами может быть уместным, если совпадения существенны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В письме порекомендуйте несколько релевантных рецензентов, которые охватывают диапазон тем и методов исследования. Это может помочь ускорить процесс рецензирования. Предлагаемые рецензенты в идеале не должны публиковаться ранее вместе с авторами вашего исследования или, по крайней мере, не публиковаться в течение некоторого времени, а также не должны быть связаны с теми же учреждениями, что и авторы рукописи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не стесняйтесь исключать рецензентов с которыми у вас может быть личный или профессиональный конфликт интересов, но делайте это в разумных пределах. Журналы не обязаны объяснять причины исключения, особенно если в список включено всего несколько имен. Однако исключать целые лабораторные группы и их выпускников не рекомендуется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чек-лист для публикации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ]  Пункт 1 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Список литературы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [How to avoid machine learning pitfalls: a guide for academic researchers (Lones, 2021)](https://arxiv.org/abs/2108.02497)\n",
    "\n",
    "* [Data and its (dis)contents: A survey of dataset development and use in machine learning research (Paullada et al., 2020)](https://arxiv.org/abs/2012.05345)\n",
    "\n",
    "* [ImageNet: A large-scale hierarchical image database (Deng et al., 2009)](https://ieeexplore.ieee.org/document/5206848)\n",
    "\n",
    "* [Excavating AI. The Politics of Images in Machine Learning Training Sets (Crawford & Paglen, 2019)](https://excavating.ai/)\n",
    "\n",
    "* [Towards fairer datasets: filtering and balancing the distribution of the people subtree in the ImageNet hierarchy (Yang et al., 2020)](https://dl.acm.org/doi/abs/10.1145/3351095.3375709)\n",
    "\n",
    "* [Translating Statistics to Make Decisions: A Guide for the Non-Statistician (Cox, 2017)](https://www.oreilly.com/library/view/translating-statistics-to/9781484222560/A426308_1_En_3_Chapter.html)\n",
    "\n",
    "* [Understanding data augmentation for classification: when to warp? (Wong et al., 2016)](https://arxiv.org/abs/1609.08764)\n",
    "\n",
    "* [A survey on Image Data Augmentation for Deep Learning (Shorten et al., 2019)](https://link.springer.com/article/10.1186/s40537-019-0197-0?code=a6ae644c-3bfc-43d9-b292-82d77d5890d5)\n",
    "\n",
    "* [Learning from class-imbalanced data: Review of methods and applications (Haixiang et al., 2017)](https://www.sciencedirect.com/science/article/abs/pii/S0957417416307175)\n",
    "\n",
    "* [NLP's Clever Hans Moment has Arrived (Heinzerling, 2019)](https://thegradient.pub/nlps-clever-hans-moment-has-arrived/)\n",
    "\n",
    "* [The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers (Csordás et al., 2021)](https://arxiv.org/abs/2108.12284)\n",
    "\n",
    "* [Drawing Multiple Augmentation Samples Per Image During Training Efficiently Decreases Test Error (Fort et al., 2021)](https://arxiv.org/abs/2105.13343)\n",
    "\n",
    "* [Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead (Rudin, 2019)](https://www.nature.com/articles/s42256-019-0048-x)\n",
    "\n",
    "* [Hidden Technical Debt in Machine Learning Systems (Sculley et al., 2015)](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)\n",
    "\n",
    "* [Sustainable MLOps - Trends and Challenges (Tamburri et al., 2020)](https://research.tue.nl/en/publications/sustainable-mlops-trends-and-challenges)\n",
    "\n",
    "* [On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation (Cawley, 2010)](https://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf)\n",
    "\n",
    "* [Leakage in data mining: Formulation, detection, and avoidance (Kaufman et al., 2012)](https://dl.acm.org/doi/10.1145/2382577.2382579)\n",
    "\n",
    "* [The Supervised Learning No-Free-Lunch Theorems (Wolpert, 2002)](https://link.springer.com/chapter/10.1007/978-1-4471-0123-9_3)\n",
    "\n",
    "* [Feature selection in machine learning: A new perspective (Cai et al., 2018)](https://www.sciencedirect.com/science/article/pii/S0925231218302911)\n",
    "\n",
    "* [On Hyperparameter Optimization of Machine Learning Algorithms: Theory and Practice (Yang et al., 2020)](https://arxiv.org/abs/2007.15745)\n",
    "\n",
    "* [AutoML: A Survey of the State-of-the-Art (He et al., 2021)](https://arxiv.org/abs/1908.00709)\n",
    "\n",
    "* [A survey of cross-validation procedures for model selection (Arlot et al., 2010)](https://projecteuclid.org/journals/statistics-surveys/volume-4/issue-none/A-survey-of-cross-validation-procedures-for-model-selection/10.1214/09-SS054.full)\n",
    "\n",
    "* [Learning from class-imbalanced data: Review of methods and applications (Haixiang et al., 2017)](https://www.sciencedirect.com/science/article/abs/pii/S0957417416307175)\n",
    "\n",
    "* [Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning (Raschka, 2020)](https://arxiv.org/abs/1811.12808)\n",
    "\n",
    "* [The Extent and Consequences of P-Hacking in Science (Head et a., 2015)](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002106)\n",
    "\n",
    "* [On Comparing Classifiers: Pitfalls to Avoid and a Recommended Approach (Salzberg, 1997)](https://link.springer.com/article/10.1023/A:1009752403260)\n",
    "\n",
    "* [Best (but oft-forgotten) practices: the multiple problems of multiplicity—whether and how to correct for many statistical tests (Streiner et al., 2015)](https://academic.oup.com/ajcn/article/102/4/721/4564678)\n",
    "\n",
    "* [A survey on ensemble learning (Dong et al., 2019)](https://link.springer.com/article/10.1007/s11704-019-8208-z)\n",
    "\n",
    "* [Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program) (Pineau et al., 2020)](https://arxiv.org/abs/2003.12206)\n",
    "\n",
    "* [A critical analysis of metrics used for measuring progress in artificial intelligence (Blagec et al., 2020)](https://arxiv.org/abs/2008.02577)\n",
    "\n",
    "* [The p-Value Requires Context, Not a Threshold (Betensky, 2019)](https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1529624)\n",
    "\n",
    "* [Principles and Practice of Explainable Machine Learning (Belle et al., 2021)](https://www.frontiersin.org/articles/10.3389/fdata.2021.688969/full)\n",
    "\n",
    "* [Science Forum: Ten common statistical mistakes to watch out for when writing or reviewing a manuscript (Makin et al., 2019)](https://elifesciences.org/articles/48175)\n",
    "\n",
    "* [Highly accurate protein structure prediction with AlphaFold (Jumper et al., 2021)](https://www.nature.com/articles/s41586-021-03819-2). \n",
    "\n",
    "* [Explainability Pitfalls: Beyond Dark Patterns in Explainable AI (Eshan et al., 2021)](https://arxiv.org/abs/2109.12480)\n",
    "\n",
    "* [How to write a first-class paper (Gewin, 2018)](https://www.nature.com/articles/d41586-018-02404-4)\n",
    "\n",
    "* [Ten simple rules for structuring papers, Mensh et al., 2017](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005619)\n",
    "\n",
    "* [Health care articles with simple and declarative titles were more likely to be in the Altmetric Top 100, Girolamo et al.,  2017](https://www.jclinepi.com/article/S0895-4356(16)30853-8/fulltext) \n",
    "\n",
    "* [Crafting cover letters, 2021](https://www.nature.com/articles/s41561-021-00824-y)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
