{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сверточные нейронные сети\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Материал прошлой лекции\n",
    "\n",
    "- функции активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полносвязная нейронная сеть \n",
    "FCN Fully-connected Neural Net. \n",
    "\n",
    "В современных статьях чаще используют сокращение MLP (Multi Layer Perceptron)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На прошлом занятии мы рассотрели следующий подход:\n",
    "\n",
    "- превращаем исходные данные в вектор \n",
    "\n",
    "В случае с цветным изображением 32x32 пикселя (32x32x3) этот Размер входного вектора будет равен 3072x1.\n",
    "\n",
    "-  Перемножим(скалярно) этот вектор с матрицей весов.Размер матрицы весов может быть например 100x3072. Где 3072 - размер входа, а 100 количество признаков которые мы хотим получить. Результат будет иметь размер 100x1\n",
    "\n",
    "\n",
    "- Поэлементно применяем к результату функцию обеспечивающую нелинейность, например Sigmoid или Relu (функция активации). Размерность данных при этом не меняется (100x1). Получили вектор активаций, или признаков.\n",
    "\n",
    "- Используем признаки как входы для нового слоя. Количество весов слоя будет зависеть от размерности входа и того что мы хотим получить на выходе. Если мы делаем классификатор на 10 классов, то матрица весов должна иметь размерность 10x100 и на этом можно остановиться. Но в общем случае количество слоев может быть произвольным.\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_1.png\" width=\"700\">\n",
    "\n",
    "\n",
    "\n",
    "Что нам дало добавление 2-го слоя. Мы позволили модели использовать более одного шаблона на класс. Можно убедиться в этом визуализировав веса первого слоя обученной модели.\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/mlp-templates.png\" width=\"400\">\n",
    "\n",
    "И такая схема работает лучше чем один слой. Однако она не решает всех проблемм.\n",
    "Сосредоточимся на изображениях.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нарушение связей между соседними пикселями\n",
    "\n",
    "Что произойдет когда мы растягиваем изображение в вектор?\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_9.png\" width=\"700\">\n",
    "\n",
    "В результате такого преобразования теряется связь между соседними пикселями. \n",
    "\n",
    "А интуитивно понятно, что при обработке изображений важен принцип локальности. \n",
    "\n",
    "Набор темных пикселей например мог например составлять контур уха кошки. Но это можно понять уведетб только пока они находились на изображении рядом.\n",
    "\n",
    "Нам необходимо найти способ как передать нейросети эту информацию. \n",
    "\n",
    "Идею для этого можно позаимствовать у лучшей в известном нам мире интеллектуальной системе - мозгу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рецептивные поля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При анализе зрительных сбразов, наш мозг учитывает локальную информацию.\n",
    "\n",
    "Расположенные рядом на сетчатке рецепторные клетки (палочки и колбочки) связанны с одной нервной (биполярной клеткой).  \n",
    "\n",
    "На следующих уровнях картина повторяется (одна ганглиозная клетка связанна с несколькими более простыми биполярными) и.т.д. \n",
    "\n",
    "Таким образом одна более сложная клетка обрабатывает сигнал с нескольких простых рецепторов расположенных рядом и возбуждается при определенной комбинации сигналов от них.\n",
    "\n",
    "Область сетчатки которая контролируется нервной клеткой  называется ее рецептивным полем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_10.png\" width=\"700\">\n",
    "\n",
    "На начальных уровнях этой иерарахии клетки реагируют на простые паттерны освещенности.\n",
    "\n",
    "Например \"свет в центре рецептивного поля, и отсутствие света по краям.\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее импульсы от зрительных клеток на сетчатке попадают в талмус (LGN), а затем в зртельную кору  (V1 .. V4)\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_11.png\" width=\"700\">\n",
    "\n",
    "В каждом последующем слое рецептивные поля клеток увеличиваются.\n",
    "И стимулы демонстрация которыйх вызавает активацию нейронов становятся более сложными. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\color{brown}{\\text{Допольнительная информация}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_12.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hubel & Wiesel,1959"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ice Cube Model\n",
    "\n",
    "https://docplayer.ru/79903347-Kasyanov-evgeniy-dmitrievich-sankt-peterburg-nmic-pn-im-v-m-beh-k-m-n-fedotov-ilya-andreevich-ryazan-ryazgmu.html\n",
    "\n",
    "Эта гипотетическая кубическая модель придумана для пояснения устройства клеток первичной визуальной коры, а именно  – как устроены предпочитаемые ориентации и, соответственно, реакции нейронов V1. Так, V1 можно условно поделить на кубы $2 мм^3$, каждый из которых получает сигналы от обоих глаз. Клетки с одинаковыми ориентационными предпочтениями формируют горизонтальные колонки, при этом соседние вертикальные колонки имеют слегка отличающиеся ориентационные предпочтения.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_14.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чувствительные к цветам клетки также собраны в столбцы (также их называют каплями, гиперколонками, шариками) 0,5 мм в диаметре в зонах соответствующих превалирующих глаз (картинка с цилиндрами). Каждый такой столбец содержит реагирующие либо на красно-зеленый, либо на сине-желтый контрасты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Свертка с фильтром\n",
    "\n",
    "\n",
    "Как реализовать идею на компьютере?\n",
    "\n",
    "Для этого испольльзуются так называемые фильтры.\n",
    "\n",
    "Допустим нам нужно найти на изображении некий объект (например рука).\n",
    "\n",
    "И у нас есть изображение этого объекта.\n",
    "\n",
    "Тогда мы можем накладывать прямоугольник с изображением интересующего нас объекта на изображение, во всех возможных положениях. В какой-то момент шаблон полностью совпадет с частью рисунка.\n",
    "\n",
    "\n",
    "Как определить что произошло совпадение?\n",
    "\n",
    "В простейшем варианте можно было бы просто посчитать попиксельную разницу, и сложить результат как это делалось в KNN.\n",
    "\n",
    "Тогда 0- соответствовал бы максимальному отклику.\n",
    "\n",
    "Однако на практике используют умножение. Благодаря этому, чем больше соответствует фрагмент изображения шаблону тем больше будет отклик.\n",
    "\n",
    "Это операция называется **\"свертка с фильтром\"**\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-2.gif\" width=\"300\">\n",
    "\n",
    "*В демонстрации, зеленая секция это входное изображение 5x5. Желтая матрица это фильтр, или ядро фильтра 3x3.*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    " # placeholder dor demo"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры 'hancrafted' фильтров\n",
    "\n",
    "Сами коэффициенты фильтра можно подбирать вручную. \n",
    "Многие известные фильтры подобранны таким образом. \n",
    "\n",
    "И использовать их можно не только для поиска объектов.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтр Гаусса\n",
    "\n",
    "Применяется для размытия изображений, он есть в большинстве фоторедакторов."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "cat = data.chelsea().mean(axis = 2).astype('int32')\n",
    "\n",
    "def im_show(arr):\n",
    "  plt.figure()\n",
    "  plt.imshow(arr, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "im_show(cat)\n",
    "import torch\n",
    "g_kernel5 = torch.tensor([\n",
    "                     [1,4,7,4,1],\n",
    "                     [4,16,26,16,4],\n",
    "                     [7,26,41,26,7],\n",
    "                     [4,16,26,16,4],\n",
    "                     [1,4,7,4,1]]\n",
    "                     ,dtype=torch.float) / 273 # sum of weights\n",
    "\n",
    "gaussian_filter = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=g_kernel5.shape, bias=False)\n",
    "gaussian_filter.weight.data = g_kernel5.unsqueeze(0).unsqueeze(0) #gaussian_kernel\n",
    "gaussian_filter.weight.requires_grad = False\n",
    "#input = torch.tensor(cat).unsqueeze(0).unsqueeze(0).type(torch.float)\n",
    "input = torch.tensor(cat).view(1,1,cat.shape[0],cat.shape[1]).type(torch.float)\n",
    "out = gaussian_filter(input)\n",
    "#print(out)\n",
    "im_show(out[0][0].numpy())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтр Собеля\n",
    "\n",
    "На заре компьютерного зрения люди придумывали различные операции, которые будут находить важные элементы на изображении. К примеру, границы. Примером подобной операции является фильтр Собеля. Он у Вас будет в практической работе.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/sobel_example.png\" width=\"300\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/sobel.png\" width=\"850\">"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Placeholder"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\color{brown}{\\text{Допольнительная информация}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Детектор границ Canny\n",
    "\n",
    "На самом деле, если мы будем применять данный алгоритм без подготовки изображения и дополнительных операций, то не получим хорошее качество детекции границ. Поэтому существуют детекторы границ, которые дополняют оператор Собеля (в алгоритме ниже оператор Собеля используется на шаге 2).\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/canny.png\" width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Детекторы углов\n",
    "\n",
    "Другими примерами подобных вручную созданных детекторов признаков являются всевозможные детекторы углов. Одним из самых известных среди них является детектор углов Харриса. Мы не будем на нем останавливаться, но вы может о нем прочесть самостоятельно.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Harris_Corner_Detector\n",
    "\n",
    "\n",
    "Как Вы увидите далее, сверточные нейронные сети, по факту автоматизируют процесс нахождения подобных признаков, высвобождая время исследователей и инженеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перемещая различные ядра свертки по изображению, можно выполнять манипуляции с изображениями. Вот как работают многие инструменты, которые можно найти в программах для редактирования изображений, таких как Photoshop или Gimp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Viola Jones ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сверточный слой нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы хотим использовать фильтры в нашей модели. При хотим что бы сеть сама научилась подбирать коэффициенты ядер фильтров. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_9.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо вектора весов размером с целое изображение используем квадратную матрицу небольшого размера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/filter1.png\" width=\"700\">\n",
    "\n",
    "В результате получим число, которое будет характеризовать отклик на данный фильтр. \n",
    "\n",
    "Операция свертки является сводится к скалярному произведению, поэтому является линейной. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Цветное/многоканальное изображение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если речь идет о цветном изображении, то входной тензор будет иметь измерение соответствующее числу цветовых каналов.\n",
    "\n",
    "СxHxW \n",
    "\n",
    "Для RGB изображений число каналов равно 3.\n",
    "\n",
    "CIFAR-10 изображения храняться в тензорах размером 3x32x32\n",
    "\n",
    "Тогда и ядро фильтра должно получить дополнительное измерение соответствующее числу каналов. \n",
    "\n",
    "Например матрица весов для фильтра 3x3 будет иметь размерность 3x3x3 \n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/conv1.png\" width=\"500\">\n",
    "\n",
    "Результатом свертки входного тензора с одним фильтром фильтром будет карта активации с глубиной 1, в независимости от количества каналов.\n",
    "\n",
    "*При этом входной тензор не обязательно должен формироаться из пикселей изображения, а может быть выходом предидущего сверточнойго слоя. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_15-1.png\" width=\"200\">\n",
    "\n",
    "\n",
    "Во время прямого прохода мы смещаем фильтр по ширине и высоте входного представления и вычисляем скалярное произведение между значениями фильтра и подлежащими значениями входного представления в любой точке.\n",
    "\n",
    "В процессе перемещения фильтра формируеется 2х мерная карта активации, которая содержит результат применения данного фильтра к каждой из областей входного представления.\n",
    "\n",
    "В базовом случае фильтр смещается с шагов 1 но это - параметр который может меняться.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_15.png\" width=\"700\">\n",
    "\n",
    "Так же можно заметить что даже при использовании единичного шага ширина $W_{out}$ и высота $H_{out}$ **карты активаций** будет отличаться от **пространственных размерностей** исходного тензора."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# let's do it manually\n",
    "\n",
    "A = np.arange(9).reshape(3,3) # our matrix\n",
    "C = np.array([[-1, 0], [0, 1]]) # filter\n",
    "\n",
    "res = [[np.sum(A[:2, :2] * C), np.sum(A[:2, 1:3] * C)],\n",
    "       [np.sum(A[1:3, :2] * C), np.sum(A[1:3, 1:3] * C)]]\n",
    "\n",
    "print(\"Input\",A)\n",
    "print(\"Filter\",C)\n",
    "print(\"conv\",res)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтров может быть несколько.\n",
    "\n",
    "В результате обучения каждый должен обучиться реагировать на определенный паттерн во входном тензоре\n",
    "\n",
    "Применения каждый даст свою карту активации размерностью $1xH_{out}xW_{out}$\n",
    "\n",
    "Если объединить (стековать) эти карты между собой то получим тензор размерности $KxH_{out}xW_{out}$\n",
    "\n",
    "\n",
    "Где K - количество фильтров.\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/depth.jpeg\" width=\"400\">\n",
    "\n",
    "\n",
    "На изображении результат приминения к изображению из CIFAR-10 сверточного слоя содержащего 5 фильтров.\n",
    "\n",
    "В документации Pytorch вместо K используется обозначение $С_{out}$ \n",
    "\n",
    "То есть результат применения фильтра трактуется аналогично цветовому каналу на самом первом слое.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим количество праметров и количество операций ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточный слой = Сверка + активация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате прохода по изображению мы получаем карту активации, также известную как карта признаков. Этот процесс называется пространственной свёрткой\n",
    "\n",
    "К изображению можно применять множество фильтров и получать на выходе разные карты активации.\n",
    "\n",
    "\n",
    "По тем же соображениям что и для линейного слоя, на для каждого фильтра обучается еще обин коэффициент отвечающий за смежение (bias)\n",
    "\n",
    "\n",
    "При этом сама операция свертки остается линейной операцией, и к выходу сверточного слоя применяется функция активации (например ReLu).\n",
    "\n",
    "*Так как функция активации применяется поэлементно, не важно какой именно слой находился передней ней полносвязанный или сверточный. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "                           nn.Conv2d(3,6,3),\n",
    "                           nn.ReLU(), # Activation don't depend on input shape\n",
    "                           nn.Flatten(),\n",
    "                           nn.Linear(5400,100), # H = 1 + (32 - 3) / 1 \n",
    "                           nn.ReLU(),  # Activation don't depend on input shape\n",
    "                           nn.Linear(100,10)\n",
    "                           )\n",
    "dummy_input = torch.randn((1,3,32,32))\n",
    "out = net(dummy_input)\n",
    "print(out)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение сверточного и полносвязанного слоев \n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/conv_layer.png\" width=\"700\">\n",
    "\n",
    "- Сколько весов у такого слоя?\n",
    "- А сколько операций умножения потребуется сделать при прямом проходе?\n",
    "\n",
    "А теперь посчитаем эти же парметры для полносвязанной сети - сети?\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_1.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Память и быстродействия\n",
    "\n",
    "**Fully connected net**\n",
    "3 слоя\n",
    "FC 3x32x32 = 3072 -> 512 \n",
    "512->128\n",
    "128->10\n",
    "\n",
    "W = 3072 * 512 (1 572 864) + 512* 128 (65536) + 128* 10 (1280)  = 1639680 ~= 6.25 Mb (10% от датасета CIFAR10 !)\n",
    "FLOPS = 1.64M\n",
    "\n",
    "\n",
    "**Convolution net**\n",
    "4 слоя\n",
    "\n",
    "3x32x32 x 10x3x3F -> 6x32x32 x 128x3x3F-> 128x32x32 -> 512x3x3F\n",
    "\n",
    "W = (3x3x3)*10+10 = 300 \n",
    "+\n",
    "(3x3x3)*128 +128 = 3584\n",
    "+\n",
    "(3x3x3)*512 +512 = 14366\n",
    "= 18220 ~= 71Kb\n",
    "\n",
    "FLOPS = 32*32*3*3*3*10 = 276 480\n",
    "+\n",
    "32*32*3*3*3*128 = 3 538 944\n",
    "+\n",
    "32*32*3*3*512 = 14 155 776\n",
    "\n",
    "= 17 971 200 ~= 18M\n",
    "\n",
    "\n",
    "Свертки содержат значительно меньшее количество обучаемых параметров. Но требуют больше вычислительных ресурсов (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected layer\n",
    "\n",
    "FC 3x32x32 = 3072 -> 512 \n",
    "512->128\n",
    "128->10\n",
    "\n",
    "W = 3072 * 512 (1 572 864) + 512* 128 (65536) + 128* 10 (1280)  = 1639680 ~= 6.25 Mb (10% от датасета!)\n",
    "FLOPS = 1.64M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры сверточного слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры операции свертки слоя это:\n",
    "\n",
    "- Размер ядра фильтра (F)\n",
    "- Шаг (stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_18.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размерность выходных данных напрямую зависит от этих параметров следующего слоя.\n",
    "\n",
    "Для тензоров у которых высота равна ширине ( H == W == N)\n",
    "\n",
    "Вичислить пространственне размеры выхода можно по формуле:\n",
    "\n",
    "**$N_{new} = 1 + (( N - F ) / stride)$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_19.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "При некоторых комбинациях этих двух параметров часть данных может не попасть в свертку. \n",
    "\n",
    "**N = 7, F = 3**\n",
    "\n",
    "stride 1 => (7 - 3)/1 + 1 = 5 - ОК\n",
    "\n",
    "stride 2 => (7 - 3)/2 + 1 = 3 - ОК\n",
    "\n",
    "stride 3 => (7 - 3)/3 + 1 = **2.33** В данном случае часть изображения в свертку не попадет"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "# Create torch tensor 7x7\n",
    "input = torch.tensor([[[[1,1,1,1,1,1,99],\n",
    "                     [1,1,1,1,1,1,99],\n",
    "                     [1,1,1,1,1,1,99],\n",
    "                     [1,1,1,1,1,1,99],\n",
    "                     [1,1,1,1,1,1,99],\n",
    "                     [1,1,1,1,1,1,99]]]],dtype=torch.float)\n",
    "print(input)\n",
    "conv = torch.nn.Conv2d(in_channels=1, # Number of channels\n",
    "                       out_channels=1, # Number of filters\n",
    "                       kernel_size=3, \n",
    "                       stride = 3,\n",
    "                       bias = False # Don't use bias\n",
    "                       )\n",
    "print(conv.weight.shape) # shape = [1,1,3,3] batch, channels, H, W\n",
    "conv.weight  = torch.nn.Parameter(torch.ones((1,1,3,3))) # Replace randow weights to ones\n",
    "activation = conv(input) \n",
    "print(activation)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Количество фильтров\n",
    "\n",
    "Задача свертки научиться разпознавать паттерны которые будут часто встречаться на изображениях в нашем датасете.\n",
    "\n",
    "Поэтому в слой свертки добавляют не один а несколько фильтров.\n",
    "\n",
    "От количества фильтров будет зависеть количество каналов в выходном тензоре.\n",
    "\n",
    "Поэтому в классе Pytorch он на зывается out_channels\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "conv = torch.nn.Conv2d(in_channels=3, # Number of input channels (3 for RGB images)\n",
    "                       out_channels=64, # Number of filters\n",
    "                       kernel_size=3)\n",
    "\n",
    "dummy_input = torch.randn((1,3,32,32))\n",
    "out = conv(dummy_input)\n",
    "print(out.shape) # [1, 64, 30, 30] batch, C_out, H_out, W_out\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изменение размера за счет краев\n",
    "\n",
    "Как можно видеть из примера, при каждой операции свертки, пространственые размеры выхода уменьшаются.\n",
    "\n",
    "\n",
    "В результате этого пиксели, которые находились на границе изображения участвуют в меньшем количестве сверток, чем те что были ближе к центру. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_20.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расширение (padding)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что бы избавиться от этого эффекта используется дополнение входного тензора (англ. padding). Обозначается как P.\n",
    "\n",
    " Выходы с предыдущего слоя дополняются так, чтобы после свертки размер выходного тензора совпадал с входным.\n",
    "\n",
    " Такие свертки называют одинаковыми (англ. same convolution), а свертки без дополнения изображения называются правильными (англ. valid convolution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_21.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ба добится эффекта сохранения размера, при единичном шаге (stride == 1)\n",
    "\n",
    "padding (P) можно рассчитать по формуле \n",
    "\n",
    "P = (F-1)/2\n",
    "\n",
    "\n",
    "*F - размер фильтра*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Среди способов, которыми можно заполнить новые пиксели, можно выделить следующие:\n",
    "\n",
    "zero shift: 00[ABC]00;\n",
    "\n",
    "border extension: AA[ABC]CC;\n",
    "\n",
    "mirror shift: BA[ABC]CB;\n",
    "\n",
    "cyclic shift: BC[ABC]AB."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(input.shape,input)\n",
    "conv = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride = 1,padding = int((3-1)/2),padding_mode='zeros', bias = False)\n",
    "conv.weight  = torch.nn.Parameter(torch.ones((1,1,3,3))) # Replace randow weights to ones\n",
    "activation = conv(input) \n",
    "print(activation.shape,activation)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Список параметров\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/conv_sum.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-3.gif\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Операция свертки в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_23.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/conv2_2.png\" width=\"700\">\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/conv2_3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применение сверточных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Количество слоев и размер фильтров\n",
    "\n",
    "* Сколько сверточных слоев следует добавлять в сеть?\n",
    "* Какой размер ядра фильтров использовать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если проводить аналогию я работой мозга, то фильтры на первых слоях сети должны реагировать на простые объекты занимающую малуч часть изображения. Или иметь малое рецептивное поле.\n",
    "\n",
    "\n",
    "На последних же слоях фильтры должны реагировать на признаки описывающие целые объекты, возможно занимающие все большую часть исходного изображения.\n",
    "\n",
    "Сответственно рецептивное поле фильтров на  последних слоях сети должно быть большим, сопоставимым с размером исходного изображения.\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/r-field.png\" width=\"700\">\n",
    "\n",
    "Увеличить рецептивное поле можно двумя способами:\n",
    "\n",
    "* увеличивать размер ядра фильтра\n",
    "* Увеличивать количество слоев (см. схему)\n",
    "\n",
    "\n",
    "Второй случай требует большого количества слоев.\n",
    "И что бы уменьшить вычислительную сложность размерности входов   внутренних слоев последовательно уменьшают.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение размеров слоев \n",
    "\n",
    "- <font color=red >Не использовать расширение (padding)</font> \n",
    "- <font color=black >Увеличить шаг</font> \n",
    "- <font color=green >Свертка с фильтром 1x1</font> \n",
    "- <font color=green >Уплотнение (Субдискретизация, Pooling)</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Уплотнение (Субдискретизация, Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача такая же как при сжатии обычых изображений: \n",
    "\n",
    "уменьшить объем данных, потеряв как можно меньше значимой информаци.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_24_1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "И способы используются аналогичные:\n",
    "\n",
    "**Max - pooling**\n",
    "Входной тензор делится на сегменты (например 2x2) в каждом канале каждого сегмента, выбирается максимальное значение.\n",
    "Из этих значение составляется выходной тензор.\n",
    "\n",
    "**Average pooling**\n",
    "Аналогично за тем исключением что вместо максимального используется среднее.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_25.png\" width=\"700\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Можно не делить изображение на сегменты, а а применять к нему pooling - фильтр, c шагом больше 1-цы.\n",
    "\n",
    "Именно так операция рализуется в коде.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "input = torch.tensor([[[\n",
    "                     [1,1,2,4],\n",
    "                     [5,6,7,8],\n",
    "                     [3,2,1,0],\n",
    "                     [1,2,3,4],\n",
    "                     ]]],dtype=torch.float)\n",
    "\n",
    "max_pool = torch.nn.MaxPool2d(2, stride=2)\n",
    "avg_pool = torch.nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "print(\"Max pooling\",max_pool(input))\n",
    "print(\"Average pooling\",avg_pool(input))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сответственно у слоя пулинга появляеются гиперпараметры:\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/pool_sum.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Свертка с фильтром 1x1\n",
    "\n",
    "Операция пулинга не влияет на количество каналов. А в его уплотнении тоже возникает потребность. Для этого применяют свертку размером 1x1.  \n",
    "\n",
    "\n",
    "Технически это обычный сверточный слой у которого размер ядра фильтра равен 1 и шаг равен 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_24.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другие виды сверток\n",
    "\n",
    "###1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Свертка - это математическая операция, которая объединяет две функции в третью. Например, допустим, что у нас есть две данные функции, **е(т)** а также **г(т)** и мы заинтересованы в применении одного поверх другого и вычислении площади пересечения:**f (t) * g (t) = (f * g) (t)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае мы применяем **г(т)**(называется ядром) более **е(т)** и изменение ответа **(Е* г) (т)** согласно пересечению над областью обеих функций. Эта концепция свертки является наиболее используемой техникой обработки сигналов, поэтому она также применяется в компьютерном зрении, что можно рассматривать как обработку сигнала от нескольких датчиков RGB. Интуиция в эффективности свертки заключается в их способности фильтровать заданные входные сигналы в объединенный, более полезный результат.\n",
    "\n",
    "В конкретном случае изображений сигнал лучше понимается с точки зрения матриц, а не форм волны. Поэтому наши функциие **(т)а** также **г(т)** теперь станетизображение *(матрица)* а также Ядро *(матрица)* соответственно. \n",
    "Еще раз, мы можем применить свертку, сдвинув одну из матриц поверх другой:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-1.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То, что вы видите выше, это просто матричное умножение скользящего окна на изображении с ядром, а затем сложение суммы. Сила сверток в контексте Computer Vision заключается в том, что они являются отличными экстракторами функций для области датчиков RGB. При индивидуальном рассмотрении каждый пиксель (датчик RGB) бессмысленно понимать, что содержит изображение. Именно отношения друг с другом в пространстве придают образу истинный смысл. Это относится к тому, как вы читаете эту статью на своем компьютере, когда пиксели, представляющие символы, и ваш мозг сопоставляют черные пиксели друг с другом в пространстве, чтобы сформировать концепцию символов.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "#torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\n",
    "m = nn.Conv1d(16, 33, 3, stride=2)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/3d_conv.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\n",
    "# With square kernels and equal stride\n",
    "m = nn.Conv3d(16, 33, 3, stride=2)\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))\n",
    "input = torch.randn(20, 16, 10, 50, 100)\n",
    "output = m(input)\n",
    "print(output.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\color{brown}{\\text{Допольнительная информация}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Реализация\n",
    "\n",
    "Операция свертки может быть реализованна как скалярное произведение.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm1.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm2.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm3.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm4.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm5.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm6.png\" width=\"700\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://medium.com/@_init_/an-illustrated-explanation-of-performing-2d-convolutions-using-matrix-multiplications-1e8de8cd2544"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Справочник по сверткам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1603.07285v1.pdf\n",
    "\n",
    "https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d\n",
    "\n",
    "\n",
    "the best: \n",
    "https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сверточная сеть\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cnn.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeNet\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/lenet5.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x,1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(net)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a simple feed-forward network. It takes the input, feeds it through several layers one after the other, and then finally gives the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "* Define the neural network that has some learnable parameters (or weights)\n",
    "* Iterate over a dataset of inputs\n",
    "* Process input through the network\n",
    "* Compute the loss (how far is the output from being correct)\n",
    "* Propagate gradients back into the network’s parameters\n",
    "* Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try a random 32x32 input. Note: expected input size of this net (LeNet) is 32x32. To use this net on the MNIST dataset, please resize the images from the dataset to 32x32."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для обучения не отличается от FC сети"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "target = torch.tensor([1])  # a dummy target, for example\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "\n",
    "loss = criterion(output, target)\n",
    "loss.backward() # backprop\n",
    "optimizer.step()    # Does the update"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-5.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torchvision import models,utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (25,25)\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "print(alexnet)\n",
    "weight_tensor = alexnet.features[0].weight.data\n",
    "print(weight_tensor.shape)\n",
    "\n",
    "img_grid = utils.make_grid(weight_tensor,pad_value=10)\n",
    "plt.imshow(np.transpose(img_grid , (1, 2, 0)))\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-6.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-7.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-8.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-9.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Live Convnet Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение значений активации нейронов в каждом слое сети в ответ на изображение или видео. В полностью связанных нейронных сетях порядок единиц не имеет значения, именно поэтому графики этих векторов не являются пространственно информативными. Однако в сверточных сетях фильтры применяются таким образом, чтобы учитывать лежащую в основе геометрию входных данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае же двумерных изображений фильтры применяются в ДВУМЕРНОЙ свертке по двум пространственным измерениям изображения. Эта свертка производит активации на последующих слоях, которые для каждого канала также расположены пространственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://yosinski.com/media/papers/Yosinski__2015__ICML_DL__Understanding_Neural_Networks_Through_Deep_Visualization__.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-12.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Активация слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее очевидный метод визуализации заключается в том, чтобы показать активации сети во время прямого прохода. Для сетей ReLU активации обычно начинает выглядеть относительно сгущенной и плотной, но по мере развития обучения активации обычно становится более редкой и локализованной. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Единственная опасная ловушка, которую можно легко заметить с помощью этой визуализации, заключается в том, что некоторые карты активации могут быть равны нулю для многих различных входов. Это может указывать на мертвые фильтры и может быть симптомом высокой скорости обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-14.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Окклюзирующие части изображения\n",
    "Предположим, что CNN относит изображение к классу \"собака\". Как мы можем быть уверены, что он действительно улавливает собаку на изображении, а не контекстуальные сигналы с фона или другого объекта? Один из способов исследовать, из какой части изображения исходит некоторое классификационное предсказание, заключается в построении графика вероятности интересующего класса (например, класса собак) в зависимости от положения объекта окклюдера. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть мы перебираем области изображения, устанавливаем патч изображения равным нулю и смотрим на вероятность класса. Мы можем визуализировать вероятность как 2-мерную тепловую карту. Этот подход был использован в визуализации и понимании сверточных сетей Мэтью Зейлера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cs231n.github.io/understanding-cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-15.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-16.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-17.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-18.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-19.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-20.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-21.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-22.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-23.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация Модели класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее разберем методику визуализации моделей классов, изученную с помощью сверточных нейронных сетей. Этот метод визуализации состоит в численном генерировании изображения, которое является репрезентативным для класса CNN. (which is representative of the class in terms of the ConvNet class scoring model.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пускай Sc(I) - оценка класса c, вычисленная классификационным слоем CNN для изображения I. Мы хотели бы найти регуляризованное изображение L2, таким, чтобы показатель Sc высоким:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/1-1.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "где λ - параметр регуляризации. Локально-оптимальный показатель I может быть найден методом обратного распространения. Этот процесс напрямую связан с обучением CNN, где обратное распространение используется для оптимизации весов по слоям. Разница в том, что в нашем случае оптимизация выполняется по отношению к входному изображению, а веса фиксируются к тем, которые были найдены на этапе обучения.\n",
    "Мы инициализировали оптимизацию с нулевым изображением (в нашем случае CNN была обучена на данных изображения с нулевым центром), а затем добавили к результату среднее изображение обучающего набора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит также отметить, что мы использовали (ненормализованные) оценки классов Sc, а не апостериоры классов, возвращаемые слоем soft-max:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/1-2.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Причина в том, что максимизация класса posterior может быть достигнута за счет минимизации баллов других классов. Таким образом, мы оптимизируем Sc для того, чтобы убедиться в том, что оптимизация концентрируется только на рассматриваемом классе Sc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1312.6034.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-24.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-25.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-26.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-27.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-28.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-29.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-30.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-31.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-32.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch. Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_28.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "colab": {
   "name": "L06_CNN_gan.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "YzIWqHnidXVF",
    "BiN2IBMUdg6V",
    "LqpE6WBLZJTC",
    "FftLboLFTDTm",
    "gIdrkGdjTDT7",
    "iFx8Z77-TDT_",
    "PaoQo-Q3TDUA",
    "16-FSprgTDUG",
    "LwR0e4bKTDTw"
   ],
   "toc_visible": true
  }
 }
}
