{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Idx8Yq94TDR3"
   },
   "source": [
    "# Сверточные нейронные сети\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFbx2HFtUNaO"
   },
   "source": [
    "## Материал прошлой лекции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjFgNOmjTDSI"
   },
   "source": [
    "### Полносвязная нейронная сеть \n",
    "(Fully-connected NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlsf_k-PTDSJ"
   },
   "source": [
    "Предположим, что у нас есть исходное 3D-изображение 32x32x3. Растянем его в один длинный вектор 3072x1 и перемножим с матрицей весов размером, для примера, 10x3072. В итоге нам нужно получить активацию (вывод с оценками классов) — для этого берём каждую из 10 строк матрицы и выполняем скалярное произведение с исходным вектором.\n",
    "В результате прохода по изображению мы получаем карту активации, также известную как карта признаков. Этот процесс называется пространственной свёрткой — более подробно о нём можно почитать в статье Свёртка в Deep Learning простыми словами. Из неё вы также можете узнать, почему размер карты активации получается меньше, чем у исходной фотографии.\n",
    "\n",
    "К изображению можно применять множество фильтров и получать на выходе разные карты активации. Так мы сформируем один свёрточный слой. Чтобы создать целую нейросеть, слои чередуются друг за другом, а между ними добавляются функции активации (например, ReLU) и специальные pooling-слои, уменьшающие размер карт признаков.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvTcjxSrTDSK"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_1.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/mlp-templates.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1tDCWAdTDSM"
   },
   "source": [
    "### Функция активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1Cst7I0TDSN"
   },
   "source": [
    "Ранее мы выяснили, что в каждый слой нейросети поступают входные данные. Они умножаются на веса полносвязного или свёрточного слоя, а результат передаётся в функцию активации или нелинейность. Мы также говорили о сигмоиде и ReLU, которые часто используются в качестве таких функций. Но список возможных вариантов не ограничивается только ими. Какой же следует выбирать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E62AQjZ9TDSR"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nt8DtdsgTDST"
   },
   "source": [
    "#### Функции активации: порог/ступенчатая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skoCONT2TDSU"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jb_GezIQTDSU"
   },
   "source": [
    "### Ступенчатая функция активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwquCuquTDSU"
   },
   "source": [
    "Первое, что приходит в голову, это вопрос о том, что считать границей активации для активационной функции. Если значение Y больше некоторого порогового значения, считаем нейрон активированным. В противном случае говорим, что нейрон неактивен. Такая схема должна сработать, но сначала давайте её формализуем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEN-e72ZTDSV"
   },
   "source": [
    "* Функция А = активирована, если Y > граница, иначе нет.\n",
    "* Другой способ:  A = 1, если Y > граница, иначе А = 0.\n",
    "\n",
    "\n",
    "Функция, которую мы только что создали, называется ступенчатой. Такая функция представлена на рисунке ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGDFiuLVTDSW"
   },
   "source": [
    "Функция принимает значение 1 (активирована), когда Y > 0 (граница), и значение 0 (не активирована) в противном случае.\n",
    "\n",
    "Мы создали активационную функцию для нейрона. Это простой способ, однако в нём есть недостатки. Рассмотрим следующую ситуацию.\n",
    "\n",
    "Представим, что мы создаем бинарный классификатор — модель, которая должна говорить “да” или “нет” (активирован или нет). Ступенчатая функция сделает это за вас — она в точности выводит 1 или 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_m9pS80-TDSX"
   },
   "source": [
    "Теперь представим случай, когда требуется большее количество нейронов для классификации многих классов: класс1, класс2, класс3 и так далее. Что будет, если активированными окажутся больше чем 1 нейрон? Все нейроны из функции активации выведут 1. В таком случае появляются вопросы о том, какой класс должен в итоге получиться для заданного объекта.\n",
    "\n",
    "Мы хотим, чтобы активировался только один нейрон, а функции активации других нейронов были равна нулю (только в этом случае можно быть уверенным, что сеть правильно определяет класс). Такую сеть труднее обучать и добиваться сходимости. Если активационная функция не бинарная, то возможны значения “активирован на 50%”, “активирован на 20%” и так далее. Если активированы несколько нейронов, можно найти нейрон с наибольшим значением активационной функции (лучше, конечно, чтобы это была softmax функция, а не max. Но пока не будем заниматься этими вопросами)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whqGTnVZTDSX"
   },
   "source": [
    "Но в таком случае, как и ранее, если более одного нейрона говорят “активирован на 100%”, проблема по прежнему остается. Так как существуют промежуточные значения на выходе нейрона, процесс обучения проходит более гладко и быстро, а вероятность появления нескольких полностью активированных нейронов во время тренировки снижается по сравнению со ступенчатой функцией активации (хотя это зависит от того, что вы обучаете и на каких данных).\n",
    "\n",
    "Мы определились, что хотим получать промежуточные значения активационной функции (аналоговая функция), а не просто говорить “активирован” или нет (бинарная функция)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIVNpZTzTDSY"
   },
   "source": [
    "1. Единичный скачок или жесткая пороговая функция (функция Хевисайда)\n",
    "\n",
    "Простая кусочно-линейная функция. Если входное значение меньше порогового, то значение функции активации равно минимальному допустимому, иначе – максимально допустимому.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/step_function.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4Q83Ob5TDSZ"
   },
   "source": [
    "http://www.aiportal.ru/articles/neural-networks/activation-function.html картинка перерисовать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "627XtTwwTDSZ"
   },
   "source": [
    "2. Линейный порог или гистерезис\n",
    "\n",
    "Несложная кусочно-линейная функция. Имеет два линейных участка, где функция активации тождественно равна минимально допустимому и максимально допустимому значению и есть участок, на котором функция строго монотонно возрастает.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/linear_threshold_function.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOtcOrFITDSa"
   },
   "source": [
    "http://www.aiportal.ru/articles/neural-networks/activation-function.html картинка перерисовать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfxXizDsTDSb"
   },
   "source": [
    "#### Функции активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbI7Pi04TDSc"
   },
   "source": [
    "Рассмотрим наиболее популярные функции активации и обсудим их преимущества и недостатки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FBokeQhTDSd"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_4.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0QLli00TDSd"
   },
   "source": [
    "#### Rectified linear unit (ReLU) - усеченное линейное преобразованиe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S00uymnTDSe"
   },
   "source": [
    "Отличие этой функции в том, что она имеет небольшой наклон в левой полуплоскости — значит, при отрицательных входных данных градиент не будет нулевым. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWT3YqKKTDSf"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_5.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qhu5cDqTDSf"
   },
   "source": [
    "При этом функцию по-прежнему легко вычислить. То есть, она решает практически все перечисленные проблемы. Одной из её разновидностей является PReLU, которая выглядит как f(x) = max(𝛼x, x). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52i1ekkbTDSf"
   },
   "source": [
    "#### Требования к функции активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9aKEKMFTDSh"
   },
   "source": [
    "- Нелинейность\n",
    "- Дифференцируемость\n",
    "- Диапазон (переполнение)\n",
    "- Скорость расчета\n",
    "- Насыщение (Saturating gradient = vanishing gradient)\n",
    "- Плотность активации "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DPQBsoQTDSj"
   },
   "source": [
    "**General and Adaptive Robust Loss Function**\n",
    "\n",
    "https://towardsdatascience.com/the-most-awesome-loss-function-172ffc106c99\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1nOBxKyTDSk"
   },
   "source": [
    "#### MaxOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87hcYWpcTDSk"
   },
   "source": [
    "Maxout выбирает максимальную сумму из двух (или более) наборов весов, умноженных на исходные данные с учётом смещения.\n",
    "Тем самым он обобщает ReLU и leaky ReLU, не обнуляя градиент. Но, как можно догадаться по виду функции, maxout требует удвоения параметров и нейронов.\n",
    "\n",
    "$ maxout(x) = max(W_1 x + b_1, ..., W_n x + b_n)$\n",
    "\n",
    "Вот как maxout обобщает ReLU и функцию модуля:\n",
    "\n",
    "$ReLU(x) = maxout(0, x), |x| = maxout(-x, x)$\n",
    "\n",
    "Подводя итог: используйте ReLU, можете попробовать взять leaky ReLU/Maxout/ELU.\n",
    "На тангенс и сигмоиду лучше не рассчитывать (разве что для выходного слоя при задачах классификации)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0SkpyxdTDSl"
   },
   "source": [
    "- https://github.com/Duncanswilson/maxout-pytorch/blob/master/maxout_pytorch.ipynb\n",
    "- https://cs231n.github.io/neural-networks-1/#actfun\n",
    "- https://arxiv.org/pdf/1302.4389.pdf\n",
    "- https://github.com/Usama113/Maxout-PyTorch/blob/master/Maxout.ipynb\n",
    "- https://medium.com/@rahuljain13101999/maxout-learning-activation-function-279e274bbf8e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imcmHgxaTDSm"
   },
   "source": [
    "#### Популярность функций активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jX7el6ETDSn"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_7.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPvWbD8hTDSp"
   },
   "source": [
    "## Нарушение связей между соседними пикселями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTfID_o2TDSq"
   },
   "source": [
    "Предположим, что у нас есть исходное 3D-изображение 32x32x3.\n",
    "Растянем его в один длинный вектор 3072x1 и перемножим с матрицей весов размером, для примера, 10x3072.\n",
    "В итоге нам нужно получить активацию (вывод с оценками классов) — для этого берём каждую из 10 строк матрицы и выполняем скалярное произведение с исходным вектором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVw9VttmTDSq"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_9.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "LqtOW3GeTDSr"
   },
   "source": [
    "Но в результате такого преобразования мы не сохранили связь между пикселями. Интуитивно понятно,\n",
    "что при обработке изображений важен принцип локальности. Допустим, мы хотим найти границы объектов\n",
    "на изображении. То есть, ответить для каждого пикселя на вопрос: проходит ли в этом месте\n",
    "граница между объектами.\n",
    "\n",
    "Обычно границы определяются как резкое изменение функции изобаржения (типо\n",
    "было черный фон (значение 0), а потом стал белый (стало 1) => граница). Очевидно, что для\n",
    "такой детекции, важно знать только близлежащие к проверямому пикселю пиксели.\n",
    "\n",
    "**Большая часть основной информации об объектах на изображении содержится в их краях (границах)**\n",
    "\n",
    "Нам необходимо найти способ как передать нейросети эту информацию. Идею для этого можно\n",
    "позаимствовать у лучшей в известном нам мире интеллектуальной системе - мозгу.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApgeCgeMTDSs"
   },
   "source": [
    "## Рецептивные поля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbwU2fs5TDSt"
   },
   "source": [
    "Рецептивное поле , или сенсорно пространство , является Разграниченной средой, где некоторые физиологические стимулы могут вызвать сенсорную нейронную реакцию в конкретных организмах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyP1MD6YTDSu"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_10.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6yK_y4yTDSv"
   },
   "source": [
    "Итак, в контексте нейронной сети рецептивное поле определяется как размер области на входе, которая производит функцию. По сути, это мера связи выходного объекта (любого слоя) с входной областью (патчем). Важно отметить, что идея рецептивных полей применима к локальным операциям (например, свертка, объединение). Например, в задачах на основе движения, таких как прогнозирование видео и оценка оптического потока, мы хотим фиксировать большие движения (смещения пикселей в 2D-сетке), поэтому мы хотим иметь адекватное воспринимающее поле. В частности, воспринимающего поля должно быть достаточно, если оно больше, чем наибольшая величина потока в наборе данных. Конечно, есть много способов увеличить воспринимающее поле в CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jQ5ATP6TDSy"
   },
   "source": [
    "Заменить на что-то более близкое к HW\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_11.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OjHPfHRTDSy"
   },
   "source": [
    "При использовании в этом смысле этот термин принимает значение, напоминающее рецептивные поля в реальных биологических нервных системах. CNN имеют особую архитектуру, имитирующую способ функционирования мозга реальных животных; вместо того, чтобы каждый нейрон в каждом слое соединялся со всеми нейронами в следующем слое ( многослойный перцептрон ), нейроны организованы в трехмерную структуру таким образом, чтобы учесть пространственные отношения между разными нейронами относительно исходные данные. Поскольку CNN используются в основном в области компьютерного зрения , данные, которые представляют нейроны, обычно являются изображениями; каждый входной нейрон представляет один пиксель исходного изображения. Первый слой нейронов состоит из всех входных нейронов; нейроны на следующем уровне будут получать соединения от некоторых входных нейронов (пикселей), но не от всех, как это было бы в случае MLP и других традиционных нейронных сетей. Следовательно, вместо того, чтобы каждый нейрон принимал соединения от всех нейронов на предыдущем уровне, CNN используют рецептивную полевую компоновку, в которой каждый нейрон получает соединения только от подмножества нейронов на предыдущем (нижнем) уровне. Рецептивное поле нейрона в одном из нижних слоев охватывает только небольшую область изображения, в то время как рецептивное поле нейрона в последующих (более высоких) слоях включает комбинацию рецептивных полей от нескольких (но не всех) нейронов в слой до (т.е. нейрон на более высоком уровне «смотрит» на большую часть изображения, чем нейрон на более низком уровне). Таким образом, каждый последующий слой способен изучать все более абстрактные особенности исходного изображения. Считается, что использование рецептивных полей таким образом дает CNN преимущество в распознавании визуальных паттернов по сравнению с другими типами нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQDTCUnvTDS0"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_12.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWwfor3NTDS1"
   },
   "source": [
    "### Hubel & Wiesel,1959"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgbPxagGTDS3"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wzhcyN6TDS3"
   },
   "source": [
    "### Ice Cube Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd46BcnzTDS4"
   },
   "source": [
    "Эта гипотетическая кубическая модель придумана для пояснения устройства клеток первичной визуальной коры, а именно  – как устроены предпочитаемые ориентации и, соответственно, реакции нейронов V1. Так, V1 можно условно поделить на кубы $2 мм^3$, каждый из которых получает сигналы от обоих глаз. Клетки с одинаковыми ориентационными предпочтениями формируют горизонтальные колонки, при этом соседние вертикальные колонки имеют слегка отличающиеся ориентационные предпочтения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxRl5g50TDS5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_14.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjcykMoUTDS6"
   },
   "source": [
    "Чувствительные к цветам клетки также собраны в столбцы (также их называют каплями, гиперколонками, шариками) 0,5 мм в диаметре в зонах соответствующих превалирующих глаз (картинка с цилиндрами). Каждый такой столбец содержит реагирующие либо на красно-зеленый, либо на сине-желтый контрасты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NZtexihTDS8"
   },
   "source": [
    "https://docplayer.ru/79903347-Kasyanov-evgeniy-dmitrievich-sankt-peterburg-nmic-pn-im-v-m-beh-k-m-n-fedotov-ilya-andreevich-ryazan-ryazgmu.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UA9suirFUynV"
   },
   "source": [
    "## Примеры 'hancrafted' фильтров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SokNzh3PTDSB"
   },
   "source": [
    "### Фильтр Собеля\n",
    "\n",
    "На заре компьютерного зрения люди придумывали различные операции, которые будут находить важные элементы на изображении. К примеру, границы. Примером подобной операции является фильтр Собеля. Он у Вас будет в практической работе.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/sobel_example.png\" width=\"300\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/sobel.png\" width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U5TO93eTDSD"
   },
   "source": [
    "### Детектор границ Canny\n",
    "\n",
    "На самом деле, если мы будем применять данный алгоритм без подготовки изображения и дополнительных операций, то не получим хорошее качество детекции границ. Поэтому существуют детекторы границ, которые дополняют оператор Собеля (в алгоритме ниже оператор Собеля используется на шаге 2).\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/canny.png\" width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmJWd5U_TDSG"
   },
   "source": [
    "### Детекторы углов\n",
    "\n",
    "Другими примерами подобных вручную созданных детекторов признаков являются всевозможные детекторы углов. Одним из самых известных среди них является детектор углов Харриса. Мы не будем на нем останавливаться, но вы может о нем прочесть самостоятельно.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Harris_Corner_Detector\n",
    "\n",
    "\n",
    "Как Вы увидите далее, сверточные нейронные сети, по факту автоматизируют процесс нахождения подобных признаков, высвобождая время исследователей и инженеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6LMBAMmTDTC"
   },
   "source": [
    "Перемещая различные ядра свертки по изображению, можно выполнять манипуляции с изображениями. Вот как работают многие инструменты, которые можно найти в программах для редактирования изображений, таких как Photoshop или Gimp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBOmrkZoSFjf"
   },
   "source": [
    "Viola Jones ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWFWP_26nDaB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "cat = data.chelsea().mean(axis = 2).astype('int32')\n",
    "\n",
    "def im_show(arr):\n",
    "  plt.figure()\n",
    "  plt.imshow(arr, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "im_show(cat)\n",
    "import torch\n",
    "g_kernel5 = torch.tensor([\n",
    "                     [1,4,7,4,1],\n",
    "                     [4,16,26,16,4],\n",
    "                     [7,26,41,26,7],\n",
    "                     [4,16,26,16,4],\n",
    "                     [1,4,7,4,1]]\n",
    "                     ,dtype=torch.float) / 273 # sum of weights\n",
    "\n",
    "gaussian_filter = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=g_kernel5.shape, bias=False)\n",
    "gaussian_filter.weight.data = g_kernel5.unsqueeze(0).unsqueeze(0) #gaussian_kernel\n",
    "gaussian_filter.weight.requires_grad = False\n",
    "#input = torch.tensor(cat).unsqueeze(0).unsqueeze(0).type(torch.float)\n",
    "input = torch.tensor(cat).view(1,1,cat.shape[0],cat.shape[1]).type(torch.float)\n",
    "out = gaussian_filter(input)\n",
    "#print(out)\n",
    "im_show(out[0][0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXnGLR7lTDS9"
   },
   "source": [
    "## Свертка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs5jPbk2c4jX"
   },
   "source": [
    "Мы хотим что бы сеть сама научилась создавать новые фильтры. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QroxIODMTDTE"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_9.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hs87Hj9y94Jc"
   },
   "source": [
    "В"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tetmj_j--LpB"
   },
   "source": [
    "Вместо вектора весов размером с целое изображение используем квадратную матрицу небольшого размера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L02KgTN3efWG"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/filter1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0IrYSyATDTD"
   },
   "source": [
    "### Свертка с фильтром"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id5NhAG4e86v"
   },
   "source": [
    "##### Изображение с одним каналом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d55SI7dTDTL"
   },
   "source": [
    "В Deep Learning свертка - это поэлементное умножение и сложение. Для изображения с 1 каналом свертка показана на рисунке ниже. Здесь фильтр представляет собой матрицу 3 x 3 с элементом [[1, 0, 1], [0, 1, 0], [1, 0, 1]]. Фильтр скользит по входу. В каждой позиции он выполняет поэлементное умножение и сложение. Каждая скользящая позиция заканчивается одним номером. Окончательный результат - матрица 3 x 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlynEoKITDTM"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-2.gif\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QesYkK4QTDTM"
   },
   "source": [
    "*Свертка изображения 5x5x1 с ядром 3x3x1 для получения свернутой функции 3x3x1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zR5ro0l-TDTM"
   },
   "source": [
    "В вышеприведенном демонстрации, зеленая секция напоминает наш входной 5x5x1 образ, я . Элемент, участвующий в выполнении операции свертки в первой части сверточного слоя, называется ядром / фильтром K , представленным желтым цветом. Мы выбрали K как матрицу 3x3x1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOBs0WFrfMLb"
   },
   "source": [
    "#### Цветное/многоканальное изображение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyAl24MzTDTF"
   },
   "source": [
    "В результате получим число, которое можно сравнить со значением нейрона. В нашем случае получится 10 значений. По этому принципу работают полносвязные слои.\n",
    "\n",
    "Основное отличие свёрточных слоёв в том, что они сохраняют пространственную структуру изображения. Теперь мы будем использовать веса в виде небольших фильтров — пространственных матриц, которые проходят по всему изображению и выполняют скалярное произведение на каждом его участке. При этом **размерность фильтра (не путать с размером) всегда соответствует размерности исходного снимка**.\n",
    "На самом деле почти всегда (так-как еще существуют depth-wise свертки. Но мы их сегодня рассматривать не будем.\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/conv1.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO8jRhf3TDTO"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_15-1.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yURPTv3mTDTG"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_15.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_-T5WQwTDTI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# let's do it manually\n",
    "\n",
    "A = np.arange(9).reshape(3,3) # our matrix\n",
    "C = np.array([[-1, 0], [0, 1]])\n",
    "\n",
    "res = [[np.sum(A[:2, :2] * C), np.sum(A[:2, 1:3] * C)],\n",
    "       [np.sum(A[1:3, :2] * C), np.sum(A[1:3, 1:3] * C)]]\n",
    "\n",
    "print(\"A\",A)\n",
    "print(\"C\",C)\n",
    "print(\"conv\",res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrAcHULGTDTH"
   },
   "source": [
    "Важно отметить, что каждый фильтр в слое считает от предыдущего слоя на всю глубину, но независмо от соседних с ним других фильтров в своем слое.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/depth.jpeg\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngqyIRSgTDTO"
   },
   "source": [
    "*Свёрточный слой является основным слоем при построении свёрточных нейронных сетей.*\n",
    "\n",
    "Обзор без погружения в особенности работы головного мозга. Давайте сперва попробуем разобраться в том, что же всё-таки вычисляет CONV-слой без погружения и затрагивания темы мозга и нейронов. Параметры свёрточного слоя состоят из набора обучаемых фильтров. Каждый фильтр представляет собой небольшую сетку вдоль ширины и высоты, но простирающуюся по всей глубине входного представления."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_Li07VHTDTP"
   },
   "source": [
    "Например, стандартный фильтр на первом слое свёрточной нейронной сети может иметь размеры 5х5х3 (5px — ширина и высота, 3 — количество цветовых каналов). Во время прямого прохода мы перемещаем (если быть точными — свёртываем) фильтр вдоль ширины и высоты входного представления и вычисляем скалярное произведение между значениями фильтра и подлежащими значениями входного представления в любой точке. В процессе перемещения фильтра вдоль ширины и высоты входного представления мы формируем 2х мерную карту активации, которая содержит значения применения данного фильтра к каждой из областей входного представления. Интуитивно становится ясно, что сеть обучит фильтры активироваться при виде определённого визуального признака, например, прямой под определённым углом или колесообразных представлений на более высоких уровнях. Теперь, когда мы применили все наши фильтры к исходному изображению, например, их было 12. В результате применения 12 фильтров мы получили 12 активационных карт размерностью 2. Чтобы произвести выходное представление — объединим эти карты (последовательно по 3-му измерению) и получим представление размерностью [WxHx12]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4K4pZ1lthJho"
   },
   "source": [
    "Оценим количество праметров и количество операций ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKEgK75-TDTR"
   },
   "source": [
    "### Сверточный слой = Сверка + активация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAESn-20TDTR"
   },
   "source": [
    "В результате прохода по изображению мы получаем карту активации, также известную как карта признаков. Этот процесс называется пространственной свёрткой — более подробно о нём можно почитать в статье Свёртка в Deep Learning простыми словами. Из неё вы также можете узнать, почему размер карты активации получается меньше, чем у исходной фотографии.\n",
    "\n",
    "К изображению можно применять множество фильтров и получать на выходе разные карты активации. Так мы сформируем один свёрточный слой. Чтобы создать целую нейросеть, слои чередуются друг за другом, а между ними добавляются функции активации (например, ReLU) и специальные pooling-слои, уменьшающие размер карт признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFx3n9GA-wxL"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/conv_layer.png\" width=\"700\">\n",
    "\n",
    "- Сколько весов у такгого слоя?\n",
    "- А сколько операций умножения потребуется сделать при прямом проходе?\n",
    "\n",
    "А для FC - сети?\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_1.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4R4Zed_-_V7"
   },
   "source": [
    "FC 3x32x32 = 3072 -> 512 \n",
    "512->128\n",
    "128->10\n",
    "\n",
    "W = 3072 * 512 (1 572 864) + 512* 128 (65536) + 128* 10 (1280)  = 1639680 ~= 6.25 Mb (10% от датасета!)\n",
    "FLOPS = 1.64M\n",
    "\n",
    "\n",
    "Conv Layer\n",
    "\n",
    "3x32x32 x 10x3x3F -> 6x32x32 x 128x3x3F-> 128x32x32 -> 512x3x3F\n",
    "\n",
    "W = (3x3x3)*10+10 = 300 \n",
    "+\n",
    "(3x3x3)*128 +128 = 3584\n",
    "+\n",
    "(3x3x3)*512 +512 = 14366\n",
    "= 18220 ~= 71Kb\n",
    "\n",
    "FLOPS = 32*32*3*3*3*10 = 276 480\n",
    "+\n",
    "32*32*3*3*3*128 = 3 538 944\n",
    "+\n",
    "32*32*3*3*512 = 14 155 776\n",
    "\n",
    "= 17 971 200 ~= 18M\n",
    "\n",
    "\n",
    "Свертки содержат значительно меньшее количество обучаемых параметров. Но требуют больше вычислительных ресурсов (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRxSnyMNTDTT"
   },
   "source": [
    "### Параметры сверточного слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOwGHylHTDTU"
   },
   "source": [
    "Обратите внимание, что некоторые слои содержат параметры, а некоторые — нет. В частности, CONV/FC-слои осуществляют трансформацию, которая является не только функцией зависящей от входных данных, но и зависящей от внутренних значений весов и смещений в самих нейронах. С другой стороны, RELU/POOL-слои применяют непараметризованные функции. Параметры в CONV/FC-слоях будут натренированы градиентным спуском таким образом, чтобы входные данные получали соответствующие корректные выходные метки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saH3zOvZTDTU"
   },
   "source": [
    "Параметры:\n",
    "- Размер фильтра (F)\n",
    "- Шаг (stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsmggD6OTDTW"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_18.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ntt3gmpyTDTX"
   },
   "source": [
    "Размер следующего слоя "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoDNlzQ5TDTY"
   },
   "source": [
    "**N = 7, F = 3**\n",
    "\n",
    "stride 1 => (7 - 3)/1 + 1 = 5 \n",
    "\n",
    "stride 2 => (7 - 3)/2 + 1 = 3 \n",
    "\n",
    "stride 3 => (7 - 3)/3 + 1 = **2.33** В данном случае часть изображения в свертку не попадет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dtq-A8lBTDTa"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_19.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0h5tuD0rh3Ss"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "#input = torch.ones((1,1,7,7))\n",
    "input = torch.tensor([[[[1,1,1,1,1,1,99],\n",
    "                     [1,1,1,1,1,1,99],\n",
    "                     [1,1,1,1,1,1,99],\n",
    "                     [1,1,1,1,1,1,99],\n",
    "                     [1,1,1,1,1,1,99],\n",
    "                     [1,1,1,1,1,1,99]]]],dtype=torch.float)\n",
    "print(input)\n",
    "conv = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride = 3)\n",
    "activation = conv(input) \n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nibtjSiyTDTd"
   },
   "source": [
    "### Изменение размера за счет краев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xhzlHq_TDTe"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_20.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaMwcYDETDTf"
   },
   "source": [
    "### Расширение (padding)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-22CgdWUTDTg"
   },
   "source": [
    "Можно заметить, что применение операции свертки уменьшает изображение. Также пиксели, которые находятся на границе изображения участвуют в меньшем количестве сверток, чем внутренние. В связи с этим в сверточных слоях используется дополнение изображения (англ. padding). Выходы с предыдущего слоя дополняются пикселями так, чтобы после свертки сохранился размер изображения. Такие свертки называют одинаковыми (англ. same convolution), а свертки без дополнения изображения называются правильными (англ. valid convolution). Среди способов, которыми можно заполнить новые пиксели, можно выделить следующие:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOWZQ95BTDTg"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_21.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLveSdW5TDTh"
   },
   "source": [
    "padding = (F-1)/2\n",
    "\n",
    "\n",
    "*F - размер фильтра*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sDSGFxDTDTh"
   },
   "source": [
    "zero shift: 00[ABC]00;\n",
    "\n",
    "border extension: AA[ABC]CC;\n",
    "\n",
    "mirror shift: BA[ABC]CB;\n",
    "\n",
    "cyclic shift: BC[ABC]AB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECOgbzywAlUE"
   },
   "outputs": [],
   "source": [
    "print(input)\n",
    "conv = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride = 3,padding = int(3-1/2),padding_mode='zeros')\n",
    "activation = conv(input) \n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTaQF97KTDTj"
   },
   "source": [
    "#### Входы и выходы сверточного слоя\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/conv_sum.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkLGp8SjTDTi"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-3.gif\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD-olj3cTDTk"
   },
   "source": [
    "### Операция свертки в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWA3dFHATDTl"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_23.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7y6HjGXTDTl"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/conv2_2.png\" width=\"700\">\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/conv2_3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTAR1Lz1TDTq"
   },
   "source": [
    "#### Рецептивные поля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibr7Du3GlPx1"
   },
   "source": [
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/r-field.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8FCFLGTTDTr"
   },
   "source": [
    "Уменьшение размеров слоев \n",
    "\n",
    "- <font color=red >Не использовать расширение (padding)</font> \n",
    "- <font color=red >Увеличить шаг</font> \n",
    "- <font color=green >Свертка с фильтром 1x1</font> \n",
    "- <font color=green >Уплотнение (Субдискретизация, Pooling)</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGoP-7PyTDTr"
   },
   "source": [
    "#### Свертка с фильтром 1x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sY-O9Ei2TDTs"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_24.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWs35nlxTDTt"
   },
   "source": [
    "#### Уплотнение (Субдискретизация, Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRQ1umWiTDTu"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_24_1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ge8RaPGGTDTu"
   },
   "source": [
    "#### Max and average pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImcKDUTDTDTv"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_25.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/pool_sum.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzIWqHnidXVF"
   },
   "source": [
    "### Другие виды сверток\n",
    "\n",
    "###1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVubcredTDS9"
   },
   "source": [
    "Свертка - это математическая операция, которая объединяет две функции в третью. Например, допустим, что у нас есть две данные функции, **е(т)** а также **г(т)** и мы заинтересованы в применении одного поверх другого и вычислении площади пересечения:**f (t) * g (t) = (f * g) (t)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pRD-VtVTDS-"
   },
   "source": [
    "В этом случае мы применяем **г(т)**(называется ядром) более **е(т)** и изменение ответа **(Е* г) (т)** согласно пересечению над областью обеих функций. Эта концепция свертки является наиболее используемой техникой обработки сигналов, поэтому она также применяется в компьютерном зрении, что можно рассматривать как обработку сигнала от нескольких датчиков RGB. Интуиция в эффективности свертки заключается в их способности фильтровать заданные входные сигналы в объединенный, более полезный результат.\n",
    "\n",
    "В конкретном случае изображений сигнал лучше понимается с точки зрения матриц, а не форм волны. Поэтому наши функциие **(т)а** также **г(т)** теперь станетизображение *(матрица)* а также Ядро *(матрица)* соответственно. \n",
    "Еще раз, мы можем применить свертку, сдвинув одну из матриц поверх другой:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkMvilTnTDS_"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_26bS2HnTDS_"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-1.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnIHSqvKTDTB"
   },
   "source": [
    "То, что вы видите выше, это просто матричное умножение скользящего окна на изображении с ядром, а затем сложение суммы. Сила сверток в контексте Computer Vision заключается в том, что они являются отличными экстракторами функций для области датчиков RGB. При индивидуальном рассмотрении каждый пиксель (датчик RGB) бессмысленно понимать, что содержит изображение. Именно отношения друг с другом в пространстве придают образу истинный смысл. Это относится к тому, как вы читаете эту статью на своем компьютере, когда пиксели, представляющие символы, и ваш мозг сопоставляют черные пиксели друг с другом в пространстве, чтобы сформировать концепцию символов.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1d1rHdglSh0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "#torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\n",
    "m = nn.Conv1d(16, 33, 3, stride=2)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiN2IBMUdg6V"
   },
   "source": [
    "### 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vwBehIq7Evl"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/3d_conv.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkbbFZGJld_V"
   },
   "outputs": [],
   "source": [
    "#torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\n",
    "# With square kernels and equal stride\n",
    "m = nn.Conv3d(16, 33, 3, stride=2)\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))\n",
    "input = torch.randn(20, 16, 10, 50, 100)\n",
    "output = m(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9KiuIpjB0Du"
   },
   "source": [
    "### Реализация\n",
    "\n",
    "Операция свертки может быть реализованна как скалярное произведение.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm1.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm2.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm3.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm4.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm5.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cm6.png\" width=\"700\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://medium.com/@_init_/an-illustrated-explanation-of-performing-2d-convolutions-using-matrix-multiplications-1e8de8cd2544"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ8l6x5bTDTv"
   },
   "source": [
    "#### Справочник по сверткам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSXtIMBmTDTw"
   },
   "source": [
    "https://arxiv.org/pdf/1603.07285v1.pdf\n",
    "\n",
    "https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d\n",
    "\n",
    "\n",
    "the best: \n",
    "https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqpE6WBLZJTC"
   },
   "source": [
    "## Сверточная сеть\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/cnn.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FftLboLFTDTm"
   },
   "source": [
    "#### LeNet\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/gan/lenet5.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpbTQuxzTDTm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x,1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eWKQsp_TDTn"
   },
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tpr2GLyxTDTo"
   },
   "source": [
    "It is a simple feed-forward network. It takes the input, feeds it through several layers one after the other, and then finally gives the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXioxW-XTDTo"
   },
   "source": [
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "* Define the neural network that has some learnable parameters (or weights)\n",
    "* Iterate over a dataset of inputs\n",
    "* Process input through the network\n",
    "* Compute the loss (how far is the output from being correct)\n",
    "* Propagate gradients back into the network’s parameters\n",
    "* Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6jW8kkUTDTo"
   },
   "source": [
    "Let’s try a random 32x32 input. Note: expected input size of this net (LeNet) is 32x32. To use this net on the MNIST dataset, please resize the images from the dataset to 32x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJNLFvsOTDTp"
   },
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1VMRAVm8Ngf"
   },
   "source": [
    "Код для обучения не отличается от FC сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgTQJp1ZTDTq"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "target = torch.tensor([1])  # a dummy target, for example\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "\n",
    "loss = criterion(output, target)\n",
    "loss.backward() # backprop\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_YdS1WJ9vJ_"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoMXaFZ-TDT3"
   },
   "source": [
    "# Визуализация сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6ok3ZnvTDT4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-5.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1yIxX77NYz9"
   },
   "outputs": [],
   "source": [
    "from torchvision import models,utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (25,25)\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "print(alexnet)\n",
    "weight_tensor = alexnet.features[0].weight.data\n",
    "print(weight_tensor.shape)\n",
    "\n",
    "img_grid = utils.make_grid(weight_tensor,pad_value=10)\n",
    "plt.imshow(np.transpose(img_grid , (1, 2, 0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7unRM0_YTDT4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-6.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8E71_7GTDT4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-7.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4neGEcSTDT4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-8.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKme2rQYTDT5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-9.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIdrkGdjTDT7"
   },
   "source": [
    "### Visualizing Live Convnet Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ufpdeYGTDT7"
   },
   "source": [
    "Построение значений активации нейронов в каждом слое сети в ответ на изображение или видео. В полностью связанных нейронных сетях порядок единиц не имеет значения, именно поэтому графики этих векторов не являются пространственно информативными. Однако в сверточных сетях фильтры применяются таким образом, чтобы учитывать лежащую в основе геометрию входных данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_VfZB42TDT9"
   },
   "source": [
    "В случае же двумерных изображений фильтры применяются в ДВУМЕРНОЙ свертке по двум пространственным измерениям изображения. Эта свертка производит активации на последующих слоях, которые для каждого канала также расположены пространственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X09cHIEgTDT9"
   },
   "source": [
    "http://yosinski.com/media/papers/Yosinski__2015__ICML_DL__Understanding_Neural_Networks_Through_Deep_Visualization__.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUq1e5aOTDT9"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-12.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7F6iF3klTDT_"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFx8Z77-TDT_"
   },
   "source": [
    "### Активация слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7Qy7zV9TDT_"
   },
   "source": [
    "Наиболее очевидный метод визуализации заключается в том, чтобы показать активации сети во время прямого прохода. Для сетей ReLU активации обычно начинает выглядеть относительно сгущенной и плотной, но по мере развития обучения активации обычно становится более редкой и локализованной. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVDYAj7uTDT_"
   },
   "source": [
    "Единственная опасная ловушка, которую можно легко заметить с помощью этой визуализации, заключается в том, что некоторые карты активации могут быть равны нулю для многих различных входов. Это может указывать на мертвые фильтры и может быть симптомом высокой скорости обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEGehlv7TDUA"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-14.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaoQo-Q3TDUA"
   },
   "source": [
    "#### Окклюзирующие части изображения\n",
    "Предположим, что CNN относит изображение к классу \"собака\". Как мы можем быть уверены, что он действительно улавливает собаку на изображении, а не контекстуальные сигналы с фона или другого объекта? Один из способов исследовать, из какой части изображения исходит некоторое классификационное предсказание, заключается в построении графика вероятности интересующего класса (например, класса собак) в зависимости от положения объекта окклюдера. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iT-lbw4KTDUA"
   },
   "source": [
    "То есть мы перебираем области изображения, устанавливаем патч изображения равным нулю и смотрим на вероятность класса. Мы можем визуализировать вероятность как 2-мерную тепловую карту. Этот подход был использован в визуализации и понимании сверточных сетей Мэтью Зейлера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1uEx77VTDUA"
   },
   "source": [
    "https://cs231n.github.io/understanding-cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75bJuujATDUC"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-15.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZBBgDv-TDUC"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-16.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgnAjHuLTDUD"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-17.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yu5eXqY4TDUD"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-18.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL1ad-nKTDUE"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-19.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZwiO_37TDUE"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-20.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAuR6Hh4TDUE"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-21.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfyzKQVOTDUF"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-22.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0LIHtK0TDUG"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-23.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16-FSprgTDUG"
   },
   "source": [
    "## Визуализация Модели класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1JMnHoxTDUH"
   },
   "source": [
    "Далее разберем методику визуализации моделей классов, изученную с помощью сверточных нейронных сетей. Этот метод визуализации состоит в численном генерировании изображения, которое является репрезентативным для класса CNN. (which is representative of the class in terms of the ConvNet class scoring model.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkQDH9aXTDUI"
   },
   "source": [
    "Пускай Sc(I) - оценка класса c, вычисленная классификационным слоем CNN для изображения I. Мы хотели бы найти регуляризованное изображение L2, таким, чтобы показатель Sc высоким:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLa1ztj3TDUI"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/1-1.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBhDtOARTDUI"
   },
   "source": [
    "где λ - параметр регуляризации. Локально-оптимальный показатель I может быть найден методом обратного распространения. Этот процесс напрямую связан с обучением CNN, где обратное распространение используется для оптимизации весов по слоям. Разница в том, что в нашем случае оптимизация выполняется по отношению к входному изображению, а веса фиксируются к тем, которые были найдены на этапе обучения.\n",
    "Мы инициализировали оптимизацию с нулевым изображением (в нашем случае CNN была обучена на данных изображения с нулевым центром), а затем добавили к результату среднее изображение обучающего набора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDa-X-Q9TDUJ"
   },
   "source": [
    "Стоит также отметить, что мы использовали (ненормализованные) оценки классов Sc, а не апостериоры классов, возвращаемые слоем soft-max:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwDcYmN8TDUK"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/1-2.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHvq_n3ITDUL"
   },
   "source": [
    "Причина в том, что максимизация класса posterior может быть достигнута за счет минимизации баллов других классов. Таким образом, мы оптимизируем Sc для того, чтобы убедиться в том, что оптимизация концентрируется только на рассматриваемом классе Sc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRkZgIB9TDUL"
   },
   "source": [
    "https://arxiv.org/pdf/1312.6034.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEGAVKTOTDUM"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-24.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_oyV_E8TDUN"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-25.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gD8T4YR4TDUN"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-26.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2YCTGl3TDUN"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-27.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1D9XfS-TDUP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-28.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7gbtx3NTDUP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-29.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMxwjfmTTDUQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-30.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkYqYYqVTDUR"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-31.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dbbmog4bTDUR"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-32.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HR2vlWdlYEuE"
   },
   "source": [
    "## Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwR0e4bKTDTw"
   },
   "source": [
    "#### Pytorch. Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eV5QdCMpTDTx"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06_28.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvlEYMFkTDT0"
   },
   "source": [
    "https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "colab": {
   "name": "L06_CNN_gan.ipynb",
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
