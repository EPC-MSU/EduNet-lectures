{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsmL4eVM-EEB"
   },
   "source": [
    "# Архитектуры CNN\n",
    "\n",
    "Мы рассмотрели базовые компоненты из которых состоят современные сверточные нейронные сети, а так же техники их обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0bNOuQr-EEN"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_1.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuvAbIqq_KQC"
   },
   "source": [
    "На этом занятии рассмортим какие именно модели можно построить на основе этих компонент. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg0zzVpq-EEP"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_2.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvMN3RH-uVU3"
   },
   "source": [
    "Условия: http://image-net.org/challenges/LSVRC/2017/\n",
    "\n",
    "Загрузка с [официального сайта](http://image-net.org/download) недоступна.\n",
    "\n",
    "\n",
    "Можно загрузить данные с [Kaggle](https://www.kaggle.com/c/imagenet-object-localization-challenge/data)\n",
    "\n",
    "Однако архив занимает порядка 156Gb и не поместится на диск Colab. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-2SdIiElTIy"
   },
   "outputs": [],
   "source": [
    "# Full list of labels \n",
    "#! wget \"https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt\"\n",
    "#! wget 'https://gist.githubusercontent.com/yrevar/6135f1bd8dcf2e0cc683/raw/d133d61a09d7e5a3b36b8c111a8dd5c4b5d560ee/imagenet1000_clsid_to_human.pkl'\n",
    "! wget 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
    "\n",
    "# Tiny Image-Net\n",
    "#урезанная версия датасета подготовленная в стенфордском университете.\n",
    "#!wget 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
    "#!unzip tiny-imagenet-200.zip\n",
    "\n",
    "! git clone https://github.com/ajschumacher/imagen.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DQvmGVOEUcd"
   },
   "source": [
    "Загрузили категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UYUvXrzmTy8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('imagenet_class_index.json') as f:\n",
    "  imagenet_labels = json.load(f)\n",
    "print(imagenet_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OENo6KyWEXUS"
   },
   "source": [
    "Посмотрим на картинки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "guXvmPqspgPr"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (25,15)\n",
    "plt.tight_layout()\n",
    "\n",
    "images = glob('imagen/imagen/*.jpg')\n",
    "\n",
    "def show(img,label1,num,label2=\"\"):\n",
    "    ax = plt.subplot(2, 3,num+1)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    #plt.axis('off')\n",
    "    plt.title(label1)\n",
    "    ax.set_xlabel(label2)\n",
    "  \n",
    "\n",
    "for i, path in enumerate(images[:6]):\n",
    "  im = Image.open(path)\n",
    "  name = path.split(\"_\")[2]\n",
    "  show(im,name,i,\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqIioZCI_yaT"
   },
   "source": [
    "Как упомяналось на первой лекции современный бум нейростевых технологий начался в 2012 году когда AlexNet большим отрывом от конкурентов победила в ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhYmlwCm-EER"
   },
   "source": [
    "## AlexNet\n",
    "\n",
    "\n",
    "создатели: Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton\n",
    "**University of Toronto**\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_3.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "Особенности\n",
    "- Большие фильтры на первых слоях\n",
    "- Обучалась на двух видеокартах  GTX580 ( ... )\n",
    "- Уменьшение размерности\n",
    "- 2 Полносвязанных слоя в конце\n",
    "\n",
    "https://neurohive.io/ru/vidy-nejrosetej/alexnet-svjortochnaja-nejronnaja-set-dlja-raspoznavanija-izobrazhenij/\n",
    "\n",
    "https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n",
    "\n",
    "ImageNet Classification with Deep ConvolutionalNeural Networks\n",
    "\n",
    "\n",
    "\n",
    "В AlexNet есть все компоненты, которые мы рассматривали ранее. Её архитектура состоит из пяти свёрточных слоёв, между которыми располагаются pooling-слои и слои нормализации, а завершают нейросеть три полносвязных слоя.\n",
    "\n",
    "\n",
    "На схеме архитектуры все выходные изображения делятся на два одинаковых участка — это связано с тем, что нейросеть обучалась на старых GPU GTX580, у которых было всего 3 ГБ видеопамяти. Для обработки использовались две видеокарты, чтобы параллельно выполнять операции над двумя частями изображения.\n",
    "Изначально на вход подаётся фотография размером 227×227×3, и размер свёрточных фильтров первого слоя — 11×11. Всего применяется 96 фильтров с шагом 4.\n",
    "\n",
    "Пространственные размеры изображения сначала довольно сильно сжимаются, затем постепенно увеличивается число фильтров. В результате ширина и высота этого уже не изображения, а набора активаций признаков, сильно уменьшаются, после чего оно поступает на два полносвязных своя, где количество весов уже довольно большое.\n",
    "\n",
    "\n",
    "AlexNet не получится использовать для классификации cifar10, потому что если начать так агрессивно уменьшать изображение размером 32Х32 px, то в определенный момент в него просто не поместится следующий фильтр, который нужно применить, и изображение просто исчезнет.\n",
    "\n",
    "Структура некоторых (особенно старых) сетей, заточенных под ImageNet, напрямую зависит от размера изображений: если соотношение сторон позволит фильтрам поместиться, проблем не возникнет,  если же оно меньше и в какой-то момент размер уменьшится до 2Х2 или 1Х1, то фильтр 3Х3 просто не сработает. В современных сетях есть слой, который позволяет решить эту проблему.\n",
    "\n",
    "\n",
    "\n",
    "На тот момент такая архитектура показала прорывную точность (ошибка упала с 20% до 15.4%).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R5-zshX-EES"
   },
   "source": [
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_4_1.png\"  width=\"750\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_4_2.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "Также стоит упомянуть о нескольких важных параметрах нейросети, необычных на тот момент:\n",
    "\n",
    "\n",
    "* AlexNet — практически первая архитектура, в которой применяется нелинейность ReLU. Ранее использовались сигмоидальные функции, которые работали медленнее;\n",
    "\n",
    "* Используется собственная нормализация (не столь универсальная, как Batch-нормализацию) с отдельными слоями. Как выяснилось позднее, они не дают значительного улучшающего эффекта и поэтому не распространены в современных архитектурах;\n",
    "\n",
    "* На этапе предварительной обработки используется очень большое дополнение данных (аугментация);\n",
    "\n",
    "* Dropout 0.5 (то есть при регуляризации отсеивается половина нейронов);\n",
    "\n",
    "* Размер пакета — 128;\n",
    "\n",
    "* SGD Momentum 0.9 (как показывают сегодняшние эксперименты, это не плохой вариант, но чтобы обучение сходилось, им требовалась с помощью эвристики ниже периодически обучать Learning rate);\n",
    "\n",
    "* Скорость обучения — 1e−2, снижается в 10 раз вручную, если точность в какой-то момент перестаёт расти;\n",
    "\n",
    "* Встречаются следующие рекомендации — изначально обучить сеть <font color=red >N(?)</font>, а затем добиться дополнительной точности в 2%, то можно вернуться к SGD Momentum и аккуратно поработать с ним с маленьким шагом;\n",
    "\n",
    "* Затухание весов L2 — 5e−4;\n",
    "\n",
    "* В архитектуре используется ансамбль из 7 CNN — это позволило снизить процент ошибок с 18,2% до 15,4%. (Ансамбль моделей — это когда обучается несколько моделей, а результат считается по среднему значению. Здесь используются 7 сетей, результат усредняется. Таким образом достаточно сильно снижается ошибка).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exzX8LDCDi8J"
   },
   "source": [
    "Сравним Pytorch реализацию с оригинальной. В чем отличия?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AVBRR95CfV7"
   },
   "outputs": [],
   "source": [
    "from torchvision import models,utils\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jenu7MTnDdyF"
   },
   "source": [
    "Проверим как работает. Почему так плохо?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOrdx6Buk8EE"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "def img2tensor(img):\n",
    "  t = F.to_tensor(img)\n",
    "  #t = F.normalize(t, (0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "  return t\n",
    "\n",
    "def catId2names(nums):\n",
    "  titles = []\n",
    "  for num in nums:\n",
    "    titles.append(imgenet_labels[str(num.item())][1])\n",
    "  return \", \".join(titles)\n",
    "  \n",
    "for i, path in enumerate(images[:6]):\n",
    "  im = Image.open(path)\n",
    "  tensor = img2tensor(im)\n",
    "  out = alexnet(tensor.unsqueeze(0)) # Add batch dimension\n",
    "  labels_num = torch.argsort(out[0]) # Ascending order\n",
    "  predicted = catId2names(labels_num[-5:]) # Top 5\n",
    "  titles = []\n",
    "  for num in labels_num[-5:]:\n",
    "    titles.append(imagenet_labels[str(num.item())][1])\n",
    "  name = path.split(\"_\")[2]\n",
    "  show(im,name,i,predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cdmvHwx-EEU"
   },
   "source": [
    "## ZFnet\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_5.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "Тюнингованный AlexNet\n",
    "\n",
    "Matthew D. Zeilerzeiler@cs.nyu.eduDept. of Computer Science, Courant Institute, Rob Fergusfergus@cs.nyu.eduDept. of Computer Science, **Courant Institute, New York Universit**\n",
    "\n",
    "\n",
    "В 2013 году выиграла соревнования созданная учеными из Йорского университета нейросеть ZFnet, достигнув результата 11.7% — в ней AlexNet использовалась в качестве основы, но с изменёнными параметрами и слоями. \n",
    "\n",
    "Отличия от AlexNet небольшие: \n",
    "* Немного поменялись размеры фильтров (было 11, стало 7); \n",
    "* Увеличилось общее количество фильтров;\n",
    "\n",
    "В целом и количество слоев, и общая структура сети, когда слои свертки и пулинга перемежаются друг с другом, а затем идут два полносвязных слоя, сохранились.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAVT-30n-EEW"
   },
   "source": [
    "## VGGNet\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_6.png\"  width=\"850\">\n",
    "\n",
    "Karen Simonyan and Andrew Zisserman\n",
    "\n",
    "Visual Geometry Group - **Oxford**\n",
    "\n",
    "https://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "\n",
    "\n",
    "* Появление \"стандартных\" блоков внутри модели\n",
    "* Свертки 3x3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHXloOzJk2T7"
   },
   "source": [
    "В 2014-ом году в Оксфорде была разработана модель VGGNet. Сеть получилась более точной и более глубокой.\n",
    "\n",
    "На слайде выше изображены сети AlexNet и две версии VGG-16 и VGG-19 с 16 и 19 слоями соответственно. На соревнованиях победила более глубокая VGG19, достигнув более чем в два раза лучшего результата по сравнению с AlexNet.\n",
    "\n",
    "Особенности: все сверточные слои имеют фильтры с активным полем размера 3Х3, они объединены в блоки, состоящие из некоторого количества сверток с разным (постепенно увеличивающимся) количеством фильтров. Затем идут слои пулинга. Идея базового блока внутри сети будет достаточно широко использоваться дальше. \n",
    "\n",
    "В 2014 году VGGNet достигла более чем в два раза лучшего результата по сравнению с AlexNet. \n",
    "\n",
    "С маленькими фильтрами мы получим не так много параметров, но при этом сможем гораздо эффективнее обрабатывать их.\n",
    "\n",
    "Попробуем посчитать размер выходных изображений и число параметров точно так же, как мы это делали для AlexNet. Если вычислить объём памяти, необходимый для обработки одного изображения, то он будет равен примерно 100 МБ (только для прямого прохода). Это означает, что видеокарта с 5 ГБ памяти сможет обрабатывать всего 50 фотографий за раз.\n",
    "\n",
    "\n",
    "Несколько фактов об архитектуре VGGNet:\n",
    "\n",
    "Нейросеть заняла 2 место в задаче классификации и 1 место в локализации на соревновании ImageNet (при локализации необходимо не только классифицировать объект, но и обвести его в ограничивающие рамки).\n",
    "Процедура обучения такая же, как у AlexNet.\n",
    "Слои нормализации отсутствуют.\n",
    "В прикладных задачах обычно используются архитектуры VGG16 или VGG19 (VGG19 работает лучше, но расходует больше памяти)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSLsJjsrCkkh"
   },
   "source": [
    "Чтобы понять, в чем смысл этих усовершенствований, нужно оценить количество памяти для хранения весов и количество операций, которые требуется выполнить при прямом прохождении сигнала через сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oe0Sq__-EEW"
   },
   "source": [
    "### Ресурсы\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_7.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oD7iiCXvDmmj"
   },
   "source": [
    "Пример оценки (на AlexNet)\n",
    "\n",
    "Большее количество слоев требует больше памяти, весов и вычислительных мощностей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6gGgvlI-EEY"
   },
   "source": [
    "### Размер рецептивного поля\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_8.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHkWL8fL-EEZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_9.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bb1lBBrb-EEb"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_10.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLL66UuZ-EEf"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_11.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "* Основная часть памяти расходуется на большие свертки в начальных слоях, где пространственные размеры(ширина и высота) велики\n",
    "\n",
    "* Больше всего весов в полносвязанных слоях\n",
    "\n",
    "* Вычислительные ресурсы нужны в первую очередь для сверток"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAiQb0BJ-EEg"
   },
   "source": [
    "## GooleNet\n",
    "В отличие от предшествующих моделей разработанна в коммерческой компании, с целью реального применения. \n",
    "\n",
    "Поэтому оснвной упор бул сделан на эффективности.\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_12.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHMO5qmik2UB"
   },
   "source": [
    "GoogleNet — ещё более глубокая архитектура с 22 слоями. Целью Google было разработать нейросеть с наибольшей вычислительной эффективностью. Для этого они придумали так называемый модуль Inception — вся архитектура состоит из множества таких модулей, следующих друг за другом.\n",
    "\n",
    "Также в GoogleNet нет полносвязных слоёв, и она содержит всего 5 миллионов параметров — в 12 раз меньше, чем у AlexNet.\n",
    "\n",
    "В составе GoogleNet есть небольшая подсеть — Stem Network. Она состоит из трёх свёрточных слоёв с двумя pooling-слоями и располагается в самом начале архитектуры.\n",
    "\n",
    "На схеме нейросети можно увидеть небольшие промежуточные «отростки» — это вспомогательные классификационные выходы для введения дополнительного градиента на начальных слоях.\n",
    "\n",
    "Идея основного модуля Inception заключается в том, что он сам по себе является небольшой локальной сетью. Вся его работа состоит в параллельном применении нескольких фильтров на исходное изображение. Данные фильтров объединяются, и создаётся выходной сигнал, который переходит на следующий слой.\n",
    "\n",
    "Но здесь же кроется проблема. Рассмотрим пример: возьмём упрощённую версию модуля Inception и попробуем посчитать размеры выходных изображений после применения каждого фильтра. При исходной фотографии 28×28×256 получим следующее:\n",
    "\n",
    "(залить отдельное изображение)\n",
    "\n",
    "\n",
    "В результате вычислений мы обнаружили, что наш небольшой блок выполняет 854 миллиона операций! При этом pooling-слои не уменьшают размер объекта — это означает, что после каждого объединения фильтров он будет только расти, и вычисления станут очень дорогостоящими.\n",
    "\n",
    "Чтобы этого избежать, введены так называемые «узкие места» — слои с фильтром 1×1, уменьшающие глубину изображения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjRODyby-EEg"
   },
   "source": [
    " ### Inception module\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_13.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55pUVeNT-EEh"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_14.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of74SOSB-EEi"
   },
   "source": [
    "### 1x1 Convolution\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_15.png\"  width=\"850\">\n",
    "\n",
    "Сверка 1х1 может рассматриваться как альтернатива полносвязанному слою.\n",
    "\n",
    "Alternatively, interpret it as applying the same FC layer on each input pixel preserves spatial dimensions, reduces depth!\n",
    "Projects depth to lower dimension (combination of feature maps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKMpC5Xu-EEj"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_16.png\"  width=\"850\">\n",
    "\n",
    "Использование таких модулей и отсутствие полносвязных слоёв делают GoogleNet очень эффективной и достаточно точной сетью. Но на этом развитие свёрточных архитектур не остановилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJcegWEj-EEk"
   },
   "source": [
    "### \"Stem network\"\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_17.png\"  width=\"850\">\n",
    "\n",
    "\n",
    " - в первых слоях быстро уменьшаются пространственные размеры. "
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "metadata": {},
   "source": [
    "\n",
    "В составе GoogleNet есть небольшая подсеть — Stem Network. Она состоит из трёх свёрточных слоёв с двумя pooling-слоями и располагается в самом начале архитектуры.\n",
    "\n",
    "На входе располагаются свертки с большим фильтром. Они служат для того, чтобы достаточно быстро и сильно **уменьшить пространственные размеры** (по сути сжать изображение перед параллельной обработкой), чтобы минимизировать количество элементов в слоях.\n",
    "\n",
    "Отдельно стоит обратить внимание на завершающую часть сети. Несложно заметить, что больше всего параметров появляется в полносвязных слоях, где каждый элемент связан с каждым. Сверточный слой очень экономичный по сравнению с полносвязным. В предыдущих моделях в конце было два полносвязных слоя, в которых находилась большая часть весов.\n",
    "\n",
    "Была придумана достаточно интересная вещь: слой глобального пулинга (при котором берется среднее значение).\n"
   ]
  },
  {
   "cell_type": "markdown",
>>>>>>> Stashed changes
   "metadata": {
    "id": "fuJsEx2t-EEk"
   },
   "source": [
    "### Global Average Pooling\n",
    "\n",
    "Полносвязанные слои замененны на GAP.\n",
    "\n",
    "* Меньше весов\n",
    "* Не зависимость от размера входа\n",
    "* Регуляризация\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_18.png\"  width=\"850\">\n",
    "\n",
    "<a href=\"https://arxiv.org/pdf/1312.4400.pdf\">2014 Network In Network</a>\n",
    "\n",
    "https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< Updated upstream
=======
   "metadata": {},
   "source": [
    "Идея в том, что все пространственные размеры, какими бы они не были (например, 6х6), сворачиваются в единицу.\n",
    "\n",
    "Мы накладываем фильтр размером 6х6 и берем среднее значение. То есть делаем пулинг с фильтром такого размера. Это происходит независимо по каждому слою. \n",
    "\n",
    "Таким образом, мы избавляемся от пространственного измерения и получаем на выходе вектор. При этом нам не нужно запоминать кучу параметров, как в полносвязном слое, и таким образом, это выполняет некоторую регуляризацию, которая позволяет, в том числе, бороться с переобучением, потому что мы избавляемся от части менее важных активаций. "
   ]
  },
  {
   "cell_type": "markdown",
>>>>>>> Stashed changes
   "metadata": {
    "id": "7TXH1Bga-EEk"
   },
   "source": [
    "### Затухание градиента\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_19.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо основного классификатора на выходе сети, два дополнительных классификатора, встроенных в промежуточные слои. \n",
    "Они понадобились для того, чтобы улучшить обратное распространение градиента, потому что без батч-нормализации в таких глубоких сетях градиент очень быстро затухал, и обучить сеть такого размера было серьезной проблемой.\n",
    "\n",
    "Обучение VGG осуществлялось неспростым способом: сначала обучали 7 слоев, затем добавляли туда следующие и обучали это вручную. Без использования батч-нормализации вряд ли получится повторить результат.\n",
    "\n",
    "Google подошел более системно, он добавил дополнительные выходы, которые способствовали тому, чтобы градиент меньше затухал. Благодаря этому удалось решить серьезную на тот момент проблему, которая ограничивала возможность обучения глубоких моделей.\n",
    "\n",
    "Статья про батч-нормализацию появилась как раз в 15ом году, видимо уже после выхода этой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATU7YtWd-EEq"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_20.png\"  width=\"850\">\n",
    "\n",
    "В 15ом году появились существенно более глубокие модели. Но одной батч-нормализации было недостаточно, потому что появилась возможность благодаря ее использованию тренировать сети с большим количеством слоев (на слайде выше - пример 56-слойной сети Microsoft). Но, как видно из графиков, у нее ошибка и на тренировочном, и на тестовом датасете больше, чем у 20-тислойной сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaDINObE-EE3"
   },
   "source": [
    "## ResNet\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_21.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/pdf/1512.03385.pdf\">2015 Deep Residual Learning for Image Recognition</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 2015 году соревнования выиграла сеть ResNet, произведя настоящую революцию глубины нейросетей. Она состояла из 152 слоёв и снизила процент ошибок до 3,57%. Это сделало её почти в два раза эффективнее GoogleNet.\n",
    "\n",
    "Возникло предположение, что сеть, состоящая из большего количества слоев должна работать как минимум не хуже, чем сеть меньшего размера, потому что в ней есть те же 20 слоев. \n",
    "\n",
    "Что же происходит с нейросетью, когда мы увеличиваем число слоёв? Можно ли, взяв обычную архитектуру вроде VGG, просто складывать всё больше и больше слоёв друг на друга и достигать лучшей точности? \n",
    "\n",
    "Нет, нельзя. Скорее всего, более глубокая нейросеть покажет даже худшие результаты как при обучении, так и при тестировании. И переобучение здесь не при чём, поскольку тогда тренировочная ошибка была бы низкой.\n",
    "\n",
    "Можно провести подобную аналогию: если мы видим изображение какое-то короткое время и нам нужно быстро его описать, мы скорее всего заметим какие-то крупные объекты (сцена: либо это помещение, либо лес, улица, возможно, мы отметим фигуры людей на переднем плане или же автомобили, здания.\n",
    "Если же требуется более подробно описать рассмотреть и описать картинку, мы уже к этому же имеющемуся описанию, добавим детали: во что одеты люди, какого цвета машины, погода и так далее.\n",
    "\n",
    "Возможно, руководствуясь подобными соображениями, был придуман остаточный слой (residual)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOpLZoi9-EE3"
   },
   "source": [
    "Resudial connection\n",
    "\n",
    "* сумма а не конкатенация\n",
    "* Batch normalization присутствует\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_22.png\"  width=\"850\">\n",
    "\n",
    "https://arxiv.org/pdf/1512.03385.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Его идея состоит в том, что мы к имеющемуся уже набору признаков добавляем значения некоторых новых: то есть не перезаписываем то, что было на предыдущем слое, а копируем признаки, сохраняем их и через несколько слоев мы суммируем (а не конкатенируем) их с результатами сверток вот на нескольких слоях, которые здесь присутствуют (Residual block).\n",
    "\n",
    "Все это вместе называется остаточным слоем или residual block.\n",
    "\n",
    "Это дало потрясающий эффект: с одной стороны, по этому каналу стал хорошо распространяться градиент без дополнительных хаков, с другой стороны, перестали теряться важные свойства, которые удалось выделить на предыдущих блоках.\n",
    "\n",
    "Если сеть из 20ти слоев способна распознавать с точностью более 90%, то там уже есть большая часть информации, а детали не должны ее затирать. Такая архитектура показала очень хороший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Zp6ogrj-EE4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_23.png\"  width=\"850\">\n",
    "\n",
    "identity =  Тождественное отображение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из таких блоков удалось построить очень глубокую сеть (были эксперименты из 1000 слоев). Для решения конкретной задачи победы на ImageNet хватило 150 слоев (добавление большего количества блоков уже не давало прироста точности для данной задачи).\n",
    "\n",
    "Здесь используются многие идеи, которые присутствовали в предыдущих моделях: вначале изображение резко уменьшается, дальше используются блоки 3х3, как в VGG, далее применяется глобальный пулинг вместо несколько полносвязных слоев. Блоки состоят из конструкций, изображенных выше: две свертки 3Х3 и прибавление результата предыдущего слоя. \n",
    "\n",
    "Также, на каждом слое перед активацией используется батч-нормализация.\n",
    "\n",
    "Периодически, в местах, где используется деление на 2, здесь в два раза уменьшаются пространственные размеры и также в 2 раза увеличивается количество фильтров.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzjItME9-EE4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_24.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если посмотреть на реализацию ImageNet, то вот что происходит с размерами изображения: сначала его уменьшают обычной сверткой с большим фильтром, а потом, в зависимости от того, насколько глубокая сеть\n",
    "некоторое количество идет блоков без уменьшение, потом происходит <font color=red>даунсэмплинг</font>, при том здесь используется не pulling, а просто свёртка с шагом 2.\n",
    "\n",
    "Таким образом через некоторые набор вот этих блоков из изображений уменьшается в два раза вот на выходе average pooling. Даже вот такая огромная 152-хслойная сеть с точки зрения потребления ресурсов получилось более эффективной, чем VGG-19. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-VF8yi_-EE5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_25.png\"  width=\"850\">\n",
    "\n",
    "Это еще было достигнуто также за счет того, что в более глубоких сетях вместо двух блоков 3х3 применялся вот такой более эффективный блок, где сначала происходит свёртка 1х1 и мы уменьшаем количество фильтров. С этим маленьким количеством фильтров делаем свертку 3х3, а потом восстанавливаем количество фильтров до начальных значений, чтобы можно было прибавить к ним вход, иначе у нас не совпадут размерности. Засчет этого достигается эффективность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-KE9j79-EE5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_26.png\"  width=\"850\">\n",
    "\n",
    "https://pytorch.org/docs/stable/_modules/torchvision/models/resnet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnWnwOZd-EE6"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_27.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1901.09321\">2019 Fixup Initialization: Residual Learning Without Normalization</a>\n",
    "\n",
    "https://towardsdatascience.com/understanding-fixup-initialization-6bf08d41b427"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzB6_pEY-EE6"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_28.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rrm3AwC-EE7"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_29.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd7UxT2M-EE8"
   },
   "source": [
    "## Feature extraction\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_30.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIJly3d8-EE8"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_31.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEFjAevj-EE8"
   },
   "source": [
    "## Обзор моделей\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_32.png\"  width=\"850\">\n",
    "\n",
    "https://arxiv.org/pdf/1810.00736.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmkKdv4r-EE8"
   },
   "source": [
    "\n",
    "## DensNet\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_33.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZiU8FmG-EE-"
   },
   "source": [
    "## ResNeXt\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_34.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1611.05431\">2016 Aggregated Residual Transformations for Deep Neural Networks</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5NQkB-h-EE-"
   },
   "source": [
    "### Groupped Convolution\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_35.png\"  width=\"850\">\n",
    "\n",
    "https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkEudbdP-EE_"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_36.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pz7ATAEb-EE_"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_37.png\"  width=\"850\">\n",
    "\n",
    "https://towardsdatascience.com/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5U6rw6yU-EFA"
   },
   "source": [
    "## WideResNet\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_38.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1605.07146\">2016 Wide Residual Networks</a>\n",
    "\n",
    "dropout внутри блоков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56XiFQSX-EFA"
   },
   "source": [
    "## SENet\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_39.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1709.01507\">2017 Squeeze-and-Excitation Networks</a>\n",
    "\n",
    "https://towardsdatascience.com/squeeze-and-excitation-networks-9ef5e71eacd7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8zrhhQZ-EFB"
   },
   "source": [
    "MobileNet\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_40.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPoXjOUW-EFB"
   },
   "source": [
    "### Depthwise separable convolution\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_41.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWIiGgeJ-EFC"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_42.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ps9DFALC-EFC"
   },
   "source": [
    "### Shuffled Grouped Convolution\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_43.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tt2ggPn5-EFD"
   },
   "source": [
    "## Neural Architecture Search\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_44.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sIsfSby-EFD"
   },
   "source": [
    "## Visual Transformers\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_45.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/2006.03677\">2020 Visual Transformers: Token-based Image Representation and Processing for Computer Vision</a>\n",
    "\n",
    "\n",
    "old version: https://syncedreview.com/2020/06/12/facebook-and-uc-berkeley-boost-cv-performance-and-lower-compute-cost-with-visual-transformers/\n",
    "\n",
    "MAC (multiply and accumulate operations) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpJ5x_35-EFD"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_46.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv5r9u9f-EFE"
   },
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "L09_CNN_Architectures.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
