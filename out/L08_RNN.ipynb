{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Рекуррентные нейронные сети (RNN)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Особенности рекуррентных нейронных сетей\n",
    "\n",
    "До этого мы работали с методами машинного обучения, которые работают с признаковым описанием фиксированной длины.\n",
    "\n",
    "Так правильно делать в случае табличных данных &mdash; обычно каждый объект в таблицах описан фиксированным набором признаков, и новые признаки не могут появиться \"вдруг\". Мы точно знаем, что на вход нам приходит объект размера 100, а на выходе мы должны для него предсказать 1 число. \n",
    "\n",
    "Верно это и про данные в виде изображений &mdash; обычно наша нейросеть учится на изображениях определенного разрешения. Да, иногда мы делаем нейросеть, которая способна работать с изображением почти любого разрешения, но добиваемся мы этого за счет вставки слоев global pooling, которые просто приводят любое признаковое описание, полученнное нашей нейросетью, а точнее, ее сверточной частью, ранее, к фиксированному размеру. \n",
    "\n",
    "Однако многие данные структурой фиксированной длины не обладают. К примеру &mdash; тексты. Возьмем все абзацы из \"Войны и Мира\". Какие-то будут больше, какие-то меньше. И обрезать их как-то нельзя. Аналогично будет и для текстов из твиттера и тд. И что делать, если мы хотим предсказывать, например, эмоциональную окрашенность текста? \n",
    "\n",
    "Более того, а что делать, если, к примеру, на основе абзаца текста нам необходимо сгенерировать его краткое содержание? То есть и то, что нужно предсказать, у нас может быть разной длины. Аналогично &mdash; мы хотим по данным о курсе валюты за прошлый год спрогнозировать курс валюты на следующий месяц по дням.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/time_series_data.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, у нас есть целый набор задач, для которых необходима особая структура нейросети, позволяющая так или иначе принимать данные разного размера. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Примеры задач\n",
    "\n",
    "**Анализ временных рядов**\n",
    "- Табличные данные\n",
    "- Аннотирование изображений и видео (Image/Video captioning)\n",
    "- Машинный перевод\n",
    "- Распознавание текста\n",
    "- Распознавание речи\n",
    "\n",
    "\n",
    "**Генеративные модели**\n",
    "- Генерация текста/речи (например, чат - боты)\n",
    "- Генерация изображений\n",
    "\n",
    "**Классификация**\n",
    "- Изображения\n",
    "- Блоки текста (Sentiment analysis)\n",
    "\n",
    "**Анализ последовательностей**\n",
    "- анализ текстов\n",
    "- биологические последовательности \n",
    "- химические последовательности\n",
    "\n",
    "\n",
    "Общее для задач - мы имеем возможность сохранять информацию, сформированную при обработке одной части объекта (**токена**), и использовать ее, когда мы анализируем другие части. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До прихода нейронных сетей предложения пытались описать при помощи набора правил - грамматик, которые довольно успешно могли генерировать новые осмысленные предложения. Так выглядит разбор при помощи грамматик простого предложения \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/parse_tree.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако грамматики плохо учитывали более глобальные связи. Например, очень тяжело было добиться того, чтобы в абзаце текста:\n",
    "\n",
    "\"Леша пришел домой. Он будет есть рыбу\"\n",
    "\n",
    "компьютер понял, что во втором предложении \"Он\" сооттветствует \"Леше\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея, на которой основано RNN, состоит в следующем &mdash; а давайте возьмем и всю последовательность пропустим через одну и туже нейросеть. \n",
    "Но при этом сама нейросеть кроме следующего элемента последовательности (например, слова в тексте), будет принимать еще один параметр &mdash; некий $v$, который в начале будет, например, вектором из нулей, а далее &mdash; значением, которое выдает сама нейросеть после обработки очередного элемента последовательности (**токена**)\n",
    "\n",
    "Также далее мы будем использовать понятие **нулевого токена** - токена, который символизирует заплатку, токен, не несущий никакого смысла, но который иногда нужно передать модели. Например - как сигнал начала работы\n",
    "\n",
    "В этом $v$ (чаще обозначается $h$) &mdash; будет храниться hidden state, состояние, учитывающее и локальный, и глобальный контекст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/rnn_idea.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Recurrent neural network\n",
    "](https://en.wikipedia.org/wiki/Recurrent_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом наша нейросеть может выдавать некий ответ на каждом шаге, но мы можем:\n",
    "\n",
    " 1. использовать только выданное на последнем (если нам нужно предсказать одно значение) &mdash; many-to-one\n",
    "\n",
    " 2. мы можем подавать в наше нейросетку токены (когда кончился исходный сигнал &mdash; подаем нулевые токены), пока она не сгенеирует токен, символизирующий остановку (many-to-many, one-to-many)\n",
    "\n",
    " 3. можем делать различные комбинации, игнорируя выходы нейросети в начале, например"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "«One to one» &mdash; обычная нейронная сеть, RNN здесь не нужно\n",
    "\n",
    "Более сложной является реализация «one to many», когда у нас есть всего один вход и нам необходимо сформировать несколько выходов. Такой тип нейронной сети актуален, когда мы говорим о генерации музыки или текстов. Мы задаем начальное слово или начальный звук, а дальше модель начинает самостоятельно генерировать выходы, в качестве входа к очередной ячейке рассматривая выход с прошлой ячейки нейронной сети.\n",
    "\n",
    " Если мы рассматриваем задачу классификации, то актуальна схема «many to one». Мы должны проанализировать все входы нейронной сети и только в конце определиться с классом.\n",
    " \n",
    "  Схему «many to many», когда количество выходов равно количеству входов нейронной сети. Обычно это задачи вида: разметить исходную последовательность. Например - указать столицы городов, названия важных объектов, веществ и т.д, что относится к задачам вида NER (Named entity recogition).\n",
    "  \n",
    "Ну и последней разновидностью нейронных сетей является сеть вида «many to many», когда количество выходов нейронной сети не равно количеству входов. Это актуально, к примеру, в машинном переводе, когда одна и та же фраза может иметь разное количество слов в разных языках (т.е. это реализует схему энкодер-декодер). Энкодер получает данные различной длины &mdash; например, предложение на английском языке. С помощью скрытых состояний он формирует из исходных данных вектор, который затем передаётся в декодер. Последний, в свою очередь, генерирует из полученного вектора выходные данные &mdash; исходную фразу, переведённую на другой язык."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/one_or_many_to_one_or_many_ways.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно объединять разные подходы. Сначала генерируем некий $h$, который содержит сжатую информацию о том, что было подано в нейросеть, а затем подаем его в нейросеть «one to many», которая генерирует, к примеру, перевод того, текста, что был подан первой части нейросети. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/sequence_to_sequence.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Базовый RNN блок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подробнее разобраться, что же происходит в загадочном зелёном прямоугольнике с надписью RNN. \n",
    "\n",
    "Внутри него мы вычисляем рекуррентное соотношение с помощью функции $f$, которая зависит от весов $w$, а именно:\n",
    "\n",
    "1. Чтобы найти новое состояние $h_t$, мы берём предыдущее скрытое состояние $ h_{t-1} $, а также текущий ввод $x_t$. Когда мы отправляем в модель следующие входные данные, полученное нами скрытое состояние $ h_t $ передаётся в эту же функцию, и весь процесс повторяется.\n",
    "\n",
    "2. Чтобы генерировать вывод в каждый момент времени, в модель добавляются полносвязные слои, которые постоянно обрабатывают состояния $ h_t $ и выдают основанные на них прогнозы. При этом функция $f$ и веса $w$ остаются неизменными.\n",
    "\n",
    "Самая простая реализация рекуррентной сети будет выглядеть следующим образом (тангенс здесь используется для введения нелинейности в систему):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/rnn_basic_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важное отличие от слоев с которыми мы уже сталкивались, сотоит в том что на выходе мы получаем два объекта: $y_t$ и $h_t$.\n",
    "\n",
    "$y_t$ &mdash; предсказание в текущий момент времени, например метка класса.\n",
    "\n",
    "$h_t$ &mdash; контекст в котором предсказание было сделанно. Он может использоваться для дальнейших предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNCell\n",
    "\n",
    "В Pytorch для вычисления $h_t$ используется модуль [RNNCell](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html)  \n",
    "\n",
    "$y_t$ в нем не вычисляется, предполагается что для его получения в модель должен быть добавлен дополнительный линейный слой.\n",
    "\n",
    "**`input_size`** &mdash;  рамер элемента последовательности.\n",
    "\n",
    "В отличие от сверточных, это всегда вектор, а не тензор, поэтому **`input_size`** &mdash;  скаляр.\n",
    "\n",
    "**`hidden_size`** &mdash; тоже скаляр. Он задает размер скрытого состояния которое тоже является вектором. Фактически это количество нейронов в слое.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "rnn_cell = torch.nn.RNNCell(input_size = 3, hidden_size = 2)\n",
    "dummy_sequence = torch.randn((1, 3)) # batch, input_size\n",
    "h = rnn_cell(dummy_sequence) \n",
    "print(\"Inital shape:\".ljust(17), f\"{dummy_sequence.shape}\")\n",
    "print(\"Resulting shape:\".ljust(17), f\"{h.shape}\")  # hidden state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно следующее:  \n",
    "Для понятности в данном примере опущена батчевая обработка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# Simple RNNcell without a bias and batch support\n",
    "class SimplifiedRNNCell(nn.Module): \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    # Init weight matrix, for simplicity omit bias\n",
    "    self.W_hx = np.random.randn(input_size, hidden_size) * 0.0001 # hidden_size == number of neurons\n",
    "    self.W_hh = np.random.randn(hidden_size, hidden_size) * 0.0001 # naive initialization\n",
    "    self.h0 = np.zeros((hidden_size)) # Initial hidden state\n",
    "  \n",
    "  def forward(self,x,h = None): # Without a batch dimension\n",
    "    if h is None:\n",
    "      h = self.h0\n",
    "    h = np.tanh(self.W_hx.T.dot(x)+self.W_hh.T.dot(h))\n",
    "    return h \n",
    "  \n",
    "simple_rnn_cell = SimplifiedRNNCell(input_size = 3, hidden_size = 2)\n",
    "h = simple_rnn_cell(dummy_sequence[0]) # No batch \n",
    "print(f\"Out = h\\n{h.shape} \\n{h}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в последовательности всегда несколько элементов. И надо применить алгоритм к каждому.\n",
    "\n",
    "\n",
    " Поэтому RNNCell напрямую не используется. Для него есть обертка: [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) который обеспечивает последовательный вызов RNNCell для всех элементов последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN блок в Pytorch \n",
    "\n",
    "**Warning: batch dim is second!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(input_size = 3, hidden_size = 2) # batch_first = True\n",
    "dummy_batched_seq = torch.randn((2, 1, 3)) # seq_len, batch, input_size\n",
    "out, h = rnn(dummy_batched_seq) \n",
    "\n",
    "print(\"Inital shape:\".ljust(20), f\"{dummy_batched_seq.shape}\")\n",
    "print(\"Resulting shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RNN without batching\n",
    "\n",
    "class SimplifiedRNNLayer(nn.Module): \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    self.rnn_cell = SimplifiedRNNCell(input_size, hidden_size)\n",
    "\n",
    "  # Without a batch dimension x have shape seq_len * input_size\n",
    "  def forward(self,x, h = None):\n",
    "    all_h = []\n",
    "    for i in range(x.shape[0]): # iterating over timestamps\n",
    "      h = self.rnn_cell(x[i],h)\n",
    "      all_h.append(h) \n",
    "    return  np.stack(all_h), h\n",
    "\n",
    "simple_rnn = SimplifiedRNNLayer(input_size = 4, hidden_size = 2)\n",
    "sequence = np.array([[0,1,2,0], [3,4,5,0]]) # batch with one sequence of two elements \n",
    "\n",
    "out, h = simple_rnn(sequence)\n",
    "print(\"Inital shape:\".ljust(20), f\"{sequence.shape}\")\n",
    "print(\"Resulting shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберемся.\n",
    "\n",
    "К данным добаляется еще одно измерение размер последовательности. Таким образом batch из 5 последовательностей по 6 элементов в каждой будет выглядеть так (время идёт первой размерностью, потому поэлементно идём \"сверху вниз\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/rnn_batch.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Размер самого элемента == 3\n",
    "\n",
    "Внутри RNN модуля элеменым последовательности обрабатываются последовательно:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/simple_rnn_h_state.png\" width = \"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса при этом используются одни и те же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn((2,1,3)) #  seq_len, batch, input_size\n",
    "\n",
    "print(\"RNNCell\")\n",
    "rnn_cell = torch.nn.RNNCell(3,2)\n",
    "print(\"Parameter\".ljust(10), \"Shape\")\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t.ljust(10), p.shape) \n",
    "\n",
    "cell_out = rnn_cell(input[0,:,:]) # take first element from sequence \n",
    "print()\n",
    "print(\"Result shape =\".ljust(20), cell_out.shape)\n",
    "print(\"Hidden state shape =\".ljust(20), cell_out.shape) # one hidden state\n",
    "\n",
    "print('----------------------------------------')\n",
    "\n",
    "print(\"RNN\")\n",
    "rnn = torch.nn.RNN(3,2)\n",
    "print(\"Parameter\".ljust(15), \"Shape\")\n",
    "for t, p in rnn.named_parameters():\n",
    "  print(t.ljust(15), p.shape) \n",
    "\n",
    "out, h = rnn(input)\n",
    "\n",
    "print()\n",
    "print(\"Result shape =\".ljust(20), out.shape) # h for all timestamps element\n",
    "print(\"Hidden state shape =\".ljust(20), cell_out.shape) # h for last element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример прогнозирования временного ряда\n",
    "\n",
    "---\n",
    "- [A Gentle Introduction to Handling a Non-Stationary Time Series in Python](https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/)\n",
    "- [A comprehensive beginner’s guide to create a Time Series Forecast](https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/)\n",
    "- [Detecting stationarity in time series data](https://towardsdatascience.com/detecting-stationarity-in-time-series-data-d29e0a21e638)\n",
    "- [Most useful Python functions for Time Series Analysis](https://towardsdatascience.com/most-useful-python-functions-for-time-series-analysis-ed1a9cb3aa8b)\n",
    "- [Data transformations and forecasting models: what to use and when](https://people.duke.edu/~rnau/whatuse.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что общего у прогнозирования потребления электроэнергии домохозяйствами, оценки трафика на дорогах в определенные периоды, прогнозировании паводков и прогнозировании цены, по которой акции будут торговаться на фондовой бирже?\n",
    "\n",
    "Все они подпадают под понятие данных временных рядов! Вы не можете точно предсказать любой из этих результатов без компонента «время». И по мере того, как в мире вокруг нас генерируется все больше и больше данных, прогнозирование временных рядов становится все более важной областью применения методов ML и DL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных \n",
    "[Time Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных\n",
    "\n",
    "Air Passengers per month.  \n",
    "[Dataset Air Passengers Number of air passengers per month](https://www.kaggle.com/rakannimer/air-passengers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if test -f ./airline-passengers.csv; then\n",
    "   echo \"Already downloaded\";\n",
    "else \n",
    "   wget https://edunet.kea.su/repo/EduNet-web_dependencies/L08/airline-passengers.csv; \n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('airline-passengers.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_data = dataset.iloc[:,1:2].values # transform dataframe to numpy.array\n",
    "# plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data, label = 'Airline Passangers Data')\n",
    "plt.title(\"Number of passengers per month\")\n",
    "plt.ylabel(\"#passengers\")\n",
    "plt.xlabel(\"Month\")\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "plt.xticks(labels_to_display, dataset['Month'][labels_to_display])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шкалирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min - Max normalization\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "print('Initial statistics:')\n",
    "print('Minimum value:', repr(td_min).rjust(5))\n",
    "print('Maximum value:', repr(td_max).rjust(5))\n",
    "\n",
    "training_data = (training_data - td_min) / (td_max - td_min)\n",
    "print('\\nResulting statistics:')\n",
    "print('Minimum value:', repr(training_data.min()).rjust(5))\n",
    "print('Maximum value:', repr(training_data.max()).rjust(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование ансамблей данных\n",
    "\n",
    "Поскольку мы хотим научиться предсказывать следующие значение на основе предыдущих, нам нужно подготовить данные соответствующим образом.\n",
    "\n",
    "Разобьем весь массив данных на фрагменты вида\n",
    "\n",
    "$x \\to y$\n",
    "\n",
    "где $x$ - это подпоследовательность, например записи с 1-й по 8-ю, а $y$ - это значение из 9-й записи, то самое которое мы хотим предсказать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# create data \"ensemble\"\n",
    "def sliding_windows(data, seq_length):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length):\n",
    "        _X = data[i:(i+seq_length)] # picking several sequential observations\n",
    "        _Y = data[i+seq_length] # picking the subsequent observation\n",
    "        X.append(_X)\n",
    "        Y.append(_Y)\n",
    "\n",
    "    return torch.Tensor(X), torch.Tensor(Y)\n",
    "    \n",
    "# set length of the ensemble; accuracy of the predictions and \n",
    "# speed perfomance almost always depend on it size\n",
    "seq_length = 8 # compare 2 and 32\n",
    "X, Y = sliding_windows(training_data, seq_length)\n",
    "print(\"Example of the obtained data:\\n\")\n",
    "print(\"Data corresponding to the first X:\")\n",
    "print(X[0])\n",
    "print(\"Data corresponding to the first Y:\")\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря такому подходу мы можем работать с RNN моделью так же как работали со сверточными моделями. Подавая на вход такую подпоследовательность + результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разобьем на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(Y) * 0.8)\n",
    "\n",
    "X_train = X[:train_size]\n",
    "Y_train = Y[:train_size]\n",
    "\n",
    "X_test = X[train_size:]\n",
    "Y_test = Y[train_size:]\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"X shape:\", X_train.shape)\n",
    "print(\"Y shape:\", Y_train.shape)\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "print(\"X shape:\", X_test.shape)\n",
    "print(\"Y shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirTrafficPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons \n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"x: \",x.shape) # 108 x 8 x 1 : [batch_size, seq_len, input_size] \n",
    "        out, h = self.rnn(x) \n",
    "        #print(\"out: \", out.shape) # 108 x 8 x 4 : [batch_size, seq_len, hidden_size] Useless!\n",
    "        #print(\"h : \", h.shape) # 1 x 108 x 4 [ num_layers, batch_size, hidden_size]\n",
    "        y = self.fc(h)\n",
    "        #print(\"y\",y.shape) # 1 x 108 x 1\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение\n",
    "\n",
    "Благодаря подготовке данных процесс обучения не будет отличаться от того что мы использовали на прошедших занятиях.\n",
    "\n",
    "В силу того что датасет маленький, все данные поместились в один batch, итерирования по batch-ам в явном виде здесь не происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_train(model, num_epochs = 2000, learning_rate = 0.01):\n",
    "  \n",
    "  criterion = torch.nn.MSELoss() # mean-squared error for regression\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Train the model\n",
    "  for epoch in range(num_epochs):\n",
    "      Y_pred, h = model(X_train) # we don't use h there, but we can!\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      # obtain the loss\n",
    "      loss = criterion(Y_pred[0], Y_train) # for shape compatibility\n",
    "      loss.backward()\n",
    "      \n",
    "      optimizer.step()\n",
    "      if epoch % 100 == 0:\n",
    "          print(f\"Epoch: {epoch},\".ljust(15), \"loss: %1.5f\" % (loss.item()))\n",
    "\n",
    "print(\"Simple RNN training process with MSE loss:\")\n",
    "input_size = 1\n",
    "hidden_size = 4 \n",
    "rnn = AirTrafficPredictor(input_size, hidden_size)\n",
    "time_series_train(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_plot(train_predict):\n",
    "  data_predict = train_predict.data\n",
    "  Y_data_plot = Y.data\n",
    "\n",
    "  # Denormalize\n",
    "  data_predict = data_predict[0] * (td_max - td_min) + td_min\n",
    "  Y_data_plot = Y_data_plot * (td_max - td_min) + td_min \n",
    "\n",
    "  # Ploitting\n",
    "  plt.figure(figsize=(12, 4))\n",
    "  plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "  # shifting the curve as first y-value not correspond first value overall\n",
    "  plt.plot(seq_length + np.arange(Y_data_plot.shape[0]), Y_data_plot)\n",
    "  plt.plot(seq_length + np.arange(Y_data_plot.shape[0]), data_predict)\n",
    "  \n",
    "  plt.title(\"Number of passengers per month\")\n",
    "  plt.ylabel(\"#passengers\")\n",
    "  plt.xlabel(\"Month\")\n",
    "  plt.xticks(labels_to_display, dataset['Month'][labels_to_display])\n",
    "  \n",
    "  plt.legend(['Train/Test separation', 'Real', 'Predicted'])\n",
    "  plt.grid(axis='x')\n",
    "  plt.show()\n",
    "\n",
    "rnn.eval()\n",
    "train_predict, h = rnn(X)\n",
    "time_series_plot(train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что модель в принципе справляется с задачей. Но посмотрим, как далее справятся более мощные архитектуры, и уже позднее напишем окончательные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример посимвольной генерации текста\n",
    "\n",
    "[Github RNN-walkthrough](https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb)\n",
    "\n",
    "Одним из основных направлений использования рекуррентных сетей является работа с текстами:\n",
    "- генерация (Language modeling)  \n",
    "и \n",
    "- перевод (Machine Translation)\n",
    "\n",
    "Давайте посмотрим как решаются такого рода задачи.\n",
    "\n",
    "Начнем с относительно простой - посимвольной генерации текста.\n",
    "\n",
    "**Постановка задачи:**\n",
    "\n",
    "предсказать следующий символ в последовательности.\n",
    "\n",
    "- исходный текст:  \n",
    "'hey how are you'\n",
    "\n",
    "- искаженный текст:  \n",
    "'hey how are yo'\n",
    "\n",
    "- Верное предсказание:\n",
    "'u'\n",
    "\n",
    "\n",
    "Теоретически эту технику можно использовать для генерации подсказок при наборе текстов, исправления ошибок или восстановления частично утраченного текста.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/character_by_character_generation_example.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных\n",
    "\n",
    "1. Зафиксировать словарь\n",
    "2. Разбить данные\n",
    "3. Выполнить кодирование символов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "text = ['hey how are you','good i am fine','have a nice day']\n",
    "\n",
    "# Join all the sentences together and extract the unique characters \n",
    "# from the combined sentences\n",
    "chars = set(''.join(text))\n",
    "\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}\n",
    "\n",
    "print(\"Dictionary for mapping character to the integer:\")\n",
    "pprint.pprint(char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо ASCII символа, каждой букве мы сопоставили номер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выравнивание данных (Padding)\n",
    "\n",
    "RNN допускают работу с данными переменной длины. Но что бы поместить предложения в batch надо их выровнять.\n",
    "\n",
    "\n",
    "Обычно размер батча делают равным самому длинному предложению, а остальные просто дополняют пробелами до этого размера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sent) for sent in text]\n",
    "maxlen = max(lengths)\n",
    "print(f\"The longest string has {maxlen} characters.\\n\")\n",
    "\n",
    "print(f\"Initial texts:\\n{text}\")\n",
    "# A simple loop that loops through the list of sentences and adds\n",
    "# a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "for i in range(len(text)):\n",
    "    while len(text[i])<maxlen:\n",
    "        text[i] += ' '\n",
    "\n",
    "print(f'Resulting texts:\\n{text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных\n",
    "\n",
    "\n",
    "\n",
    "В качестве входа будем использовать предложение без последнего символа:\n",
    "\n",
    "**'hey how are yo'**\n",
    "\n",
    ", а в качестве результата - предложение в котором он сгенерирован.\n",
    "\n",
    "**'ey how are you'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "    \n",
    "    # Remove firsts character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "    \n",
    "    print(\"Input sequence:\".ljust(18), f\"'{input_seq[i]}'\")\n",
    "    print(\"Target sequence:\".ljust(18), f\"'{target_seq[i]}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодирование\n",
    "\n",
    "Теперь символы надо перевести в числа. Для этого мы уже построили словарь.\n",
    "\n",
    "P.S. Запускать блок только один раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "    print(\"Encodded input sequence:\".ljust(25), input_seq[i])\n",
    "    print(\"Encodded target sequence:\".ljust(25), target_seq[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding\n",
    "\n",
    "Теперь из чисел надо сделать вектора. \n",
    "\n",
    "\n",
    "Почему бы не оставить числа?\n",
    "В прошлом примере модель хорошо с ними работала.\n",
    "\n",
    "В прошлом примере использовася MSE и на выходе было число.\n",
    "\n",
    "Если бы мы определили отношение порядка над номерами букв, то что-то подобное можно было бы сделать.\n",
    "\n",
    "Однако сейчас мы предсказываем класс буквы.\n",
    "Поэтому на входе и на выходе должен быть вектор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/one_hot_encoding_softmax.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(text)\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    \n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features\n",
    "\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
    "print(\"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(input_seq.shape))\n",
    "print(input_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый символ закодировали вектором.\n",
    "Не слишьком экономно, зато удобно умножать на матрицу весов.\n",
    "\n",
    "P.S. Запускать только один раз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/language_modeling.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "import torch\n",
    "\n",
    "input_seq = torch.Tensor(input_seq)\n",
    "target_seq = torch.Tensor(target_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class NextCharacterGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size = hidden_dim, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden_0 = torch.zeros(1, batch_size, self.rnn.hidden_size) # 1 correspond to number of layers\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden_0)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # Need Only if n_layers > 1\n",
    "        out = out.contiguous().view(-1, self.rnn.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = NextCharacterGenerator(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
    "\n",
    "# Define hyperparameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training Run\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print(f'Epoch: {epoch}/{num_epochs}'.ljust(20), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "    \n",
    "    out, hidden = model(character)\n",
    "    #print(out.shape)\n",
    "    #print(out)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden\n",
    "\n",
    "def sample(model, out_len, start='hey'):\n",
    "    model.eval() # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for _ in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)\n",
    "\n",
    "sample(model, 15, 'good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычная RNN имело множество проблем, в том числе, в нем очень быстро затухала информация о предыдущих словах в предложении. Помимо этого, были проблемы с затухением/взрывом самого градиента. \n",
    "\n",
    "Эти проблемы были частично решены в LSTM, предложенной в [Hochreiter & Schmidhuber (1997)](http://www.bioinf.jku.at/publications/older/2604.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обычной RNN в ячейке был только один путь передачи информации. На каждом шаге мы сливали информацию, накопленную с предыдущих шагов, с текущей:\n",
    "\n",
    "\n",
    "<img src = \"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/simple_rnn_h_state.png\" width = \"600px\">\n",
    "\n",
    "\n",
    "При этом информация о предыдущих токенах очень быстро затухает и теряется общая информация о предложении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура ячейки LSTM намного сложнее. Здесь есть целых 4 линейных слоя, каждый из которых выполняет разные задачи. Не пугайтесь запутанности структуры, подробнее мы ее разберем позже\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lstm_chain.png\" width=\"600px\">\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lstm_chain_notation.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главное нововведение - в LSTM же добавлен путь $c$, который по задумке должен этот общий контекст сохранять. \n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lstm_c_state_highway.png\" width=\"600px\">\n",
    "\n",
    "Другими словами, путь $c$ (иногда называется highway, магистраль)  помогает нейросети сохранять важную информацию, встретившуюся в какой-то момент в предложении, все время, пока эта информация требуются. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как это работает?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gates (Врата)\n",
    "\n",
    "Gates представляют собой последовательность из сигмоиды и последующего поэлементного произведения. Одни предназначены для решения вопроса: какую информацию LSTM должно передать дальше, а какую выкинуть. Ведь всю информацию не сохранишь - передаваемый между ячейками вектор имеет конечный фиксированный размер.\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lstm_gate.png\" width=\"100px\">\n",
    "\n",
    "Сигмоида принимает на вход вектор, и каждое его значение переводит в значения от $0$ до $1$ и полученный вектор передается операции  поэлементного произведения.\n",
    "\n",
    "$1$ соответствует команде - все данные, находящиеся на этом месте, сохранить. \n",
    "\n",
    "$0$ соответствует команде - все данные, находящиеся на этом месте, выкинуть. \n",
    "\n",
    "Откуда выкидываем? Из второго вектора, который приходит на вход операции произведения. Если для конкретной позиции вектора от сигмоиды пришла $1$ - то соответствующее значение останется без изменений. Иначе - число уменьшится по модулю, вплоть до $0$, если от сигмоиды пришел $0$. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forget gate \n",
    "\n",
    "Начнем с первого шага - ячейка принимает на вход новый токен $x_t$ и скрытое состояние $h_{t-1}$. На основании  $x_t$  и $h_{t-1}$ , ей надо решить, какую информацию необходимо выкинуть из вектора $C$\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lstm_forget_gate.png\" width=\"600px\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input gate \n",
    "\n",
    "Следующий шаг. Теперь хорошо бы решить, какую информацию мы хотим добавить в вектор $C$.\n",
    "\n",
    "Делается при помощи  $\\tilde{C_t}$, который хранит информацию, которую мы хотим добавить в вектор $C$. \n",
    "\n",
    "И $i_t$, который будет хранить информацию том, что и с каким коэффициентом  информацию из $\\tilde{C_t}$ мы будем добавлять в $C$.\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lstm_input_gate.png\" width=\"600px\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обновляем $C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть вся информация, необходимая, чтобы обновить вектор $C$ - мы знаем и что надо забыть, и что надо добавить. Делаем это\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lstm_update_c_state.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output gate\n",
    "\n",
    "Осталось последнее - решить, что ячейка выдаст наружу и передаст следующей ячейке - составить вектор $h_t$\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lstm_output_gate.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом участвуют входной токен $x_t$, предыдущее скрытое состояние $h_{t-1}$ и новый вектор контекста $C_t$. \n",
    "\n",
    "На основе $h_{t-1}$ и $x_t$ мы решаем, что мы хотим из вектора $C_t$ положить в $h_t$. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введение единого пути, магистрали для информации, в которую мы по ходу работы нейросети вносим изменения, напоминает подход, использованный в ResNet. \n",
    "\n",
    "Который, в частности, тоже решал проблему затухающего градиента. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMCell\n",
    "\n",
    "[pytorch LSTMCELL](https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
    "\n",
    "Интерфейс отличается от RNNCell количеством входов и выходов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lstm_cell = torch.nn.LSTMCell(input_size = 3, hidden_size = 4)\n",
    "input = torch.randn(1,3) # batch, input_size\n",
    "h_0 = torch.randn(1,4)\n",
    "c_0 = torch.randn(1,4)\n",
    "h, c = lstm_cell(input, (h_0,c_0)) # second arg is tuple\n",
    "print(\"Shape of h:\", h.shape) # batch, hidden_size\n",
    "print(\"Shape of c:\", c.shape) # batch, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM in Pytorch\n",
    "\n",
    "Отличие от RNN состоит в том что возвращается кроме $h$ возвращается еще и $c$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "lstm = nn.LSTM(input_size = 4, hidden_size = 5)\n",
    "input = torch.randn(3,2,4) # seq_len, batch, input_size\n",
    "out, (h, c) = lstm(input) # h and c returned in tuple\n",
    "\n",
    "print(\"Input shape:\".ljust(15),input.shape)\n",
    "print(\"Shape of h\".ljust(15),h.shape) # batch, hidden_size\n",
    "print(\"Shape of c\".ljust(15),c.shape) # batch, hidden_size\n",
    "print(\"Output shape:\".ljust(15),out.shape) # seq_len, batch, hidden_size : h for each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример использования на задаче с временным рядом\n",
    "\n",
    "Что бы убедиться в работоспособности конструкции заменим RNN блок на LSTM в задаче предсказания временного ряда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new LSTM based model\n",
    "\n",
    "class LSTMAirTrafficPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons \n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h,c) = self.lstm(x) \n",
    "        y = self.fc(h)\n",
    "        return y\n",
    "\n",
    "lstm =  LSTMAirTrafficPredictor(input_size = 1, hidden_size = 4)\n",
    "input = torch.randn((108,8,1)) \n",
    "out = lstm(input)\n",
    "\n",
    "print(\"LSTM model we use consider first input dimension as a batch dimension, output dimension logic has not changed:\")\n",
    "print(\"Input shape:\".ljust(15),input.shape)\n",
    "print(\"Output shape:\".ljust(15),out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.train()\n",
    "\n",
    "print(\"LSTM training process with MSE loss:\")\n",
    "\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = torch.nn.MSELoss() # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    " # Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    Y_pred = lstm(X_train) \n",
    "    optimizer.zero_grad()\n",
    "    #print(outputs.shape)\n",
    "    loss = criterion(Y_pred, Y_train.unsqueeze(0))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch},\".ljust(15), \"loss: %1.5f\" % (loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lstm.eval()\n",
    "train_predict = lstm(X)\n",
    "time_series_plot(train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "---\n",
    "1. Использование LSTM слоев при прогнозировании нестационарных временных рядов - отличное решение, тк нейронка способна самостоятельно выденить динамики изменениях составляющих временного ряда. Правда, в более сложных случаях (трейдинге, например, или чтении и расшивровки волн мозга) приходится прибегать к feature engineering\n",
    "2. Сложость нейронной сети должна быть адекватна сложности подаваемых в нее данных. С ростом ансамбля и числа нейронов увеличивается заучивание тренировочной выборки и теряется способность к обощению\n",
    "3. Предварительный анализ цикличности в данных (если она есть) помогает понять оптимальный размер ансамбля (тут видно, что цикл в среднем составляет 8 интервалов)\n",
    "4. Также результат может зависеть от типа скалирования, который Вы применяете. Нужно знать принципы работы скаллеров и не стесняться экспериментировать с ними. См. статьи: [Data Preprocessing with Scikit-Learn: Standardization and Scaling](https://towardsdatascience.com/data-preprocessing-with-scikit-learn-standardization-and-scaling-cfb695280412) и [Gradient Descent, the Learning Rate, and the importance of Feature Scaling](https://towardsdatascience.com/gradient-descent-the-learning-rate-and-the-importance-of-feature-scaling-6c0b416596e1)\n",
    "5. При всей выгодности приненении нейронных сетей, необходимо быть осторожным с автокорреляцией (см статью [Avoiding the pitfalls](https://towardsdatascience.com/how-not-to-use-machine-learning-for-time-series-forecasting-avoiding-the-pitfalls-19f9d7adf424))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модификации LSTM \n",
    "\n",
    "Было предложено множество модификаций структуры LSTM. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peephole connections\n",
    "Например, введение возможности всем gates напрямую подсматривать в вектор контекста $C$. Что, безусловно, логично - сложно решать, что делать с вектором $C$ (что из него стирать, что в него добавлять, что из него брать), если видишь его только опосредованно. \n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lstm_peepholes_connections.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение forget и input gates \n",
    "\n",
    "Также кажется, что правильно требовать от нейросети принимать решение о записи в/стирании из вектора $C$ одновременно. Если что-то стираем - надо что-то записать. И наоборот. \n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lstm_join_input_and_forget_gate.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU (Gated reccurent unit)\n",
    "\n",
    "Самая известная модификация LSTM - GRU. Она более компактна за счет сильных упрощений в сравнении со стандартной LSTM.\n",
    "\n",
    "Главные изменения - объединены forget и input gates, слиты $h_t$ и $C_t$, которые в обычной LSTM только участвовали в формировании друг друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/gru_basic_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "gru = torch.nn.GRU(input_size = 4, hidden_size =3)\n",
    "input = torch.randn(2, 1, 4) #seq_len, batch, input_size\n",
    "h0 = torch.randn(1, 1, 3)\n",
    "output, h = gru(input, h0)\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h:\".ljust(15), h.shape) # last h\n",
    "print(\"Output shape:\".ljust(15), output.shape) # seq_len = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практический опыт исследователей - иногда лучше работает GRU, иногда &mdash; LSTM. Точного рецепта успеха сказать нельзя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы пытаемся решить задачу sequence to sequence\n",
    "Обрабатывая входную последовательность, мы хотим обобщить всю информацию, которая в ней содержится в некий вектор $C$.\n",
    "\n",
    "\n",
    "Далее мы передаем этот вектор во вторую RNN, которая является декодером\n",
    "\n",
    "\n",
    "Мы используем вектор $C$ для передачи информации между энкодером и декодером, также мы предполагаем, что вектор $C$ обощает всю информацию, которая небходима декодеру для генерации выходных последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/seq_to_seq_with_rnn.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве $C$ и $S_o$ может использоваться просто $h_4$ (последнее скрытое состояние)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "С подходом, разобранным ранее есть большая проблема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/seq_to_seq_with_rnn.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование единственного вектора для предоставления информации может работать только для последовательностей малой длины (неразумно предполагать, что информация с длинной последовательностью можно сжать в один вектор) \n",
    "\n",
    "Чтобы понять, что надо сгенерировать глагол на другом языку в нужной форме числа, нашей нейросети надо сохранить информации о числе этого глагола во всех состояниях энкодера вплоть до того, что подается на вход декодеру.\n",
    "\n",
    "\n",
    "А что если нам надо перевести целый абзац текста? И нужно понимать, о ком конкретно идет речь в последнем предложении абзаца. А информация об этом в конце?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Длина вектора, в котором нам надо хранить информацию обо всей последовательности - постоянна. \n",
    "\n",
    "Понятно, что начиная с какого-то момента информацию всю мы сохранить в нем не сможем. \n",
    "\n",
    "Более того, при генерации, скажем, последнего слова, мы должны в векторе того же размера сохранить информацию о этом последнем слове и о том, что другие уже сгенерены - иначе модель может зациклиться или не сгенерировать часть слов.\n",
    "\n",
    "Все эти проблемы реальны и возникают в обычной Seq2Seq модели.\n",
    "\n",
    "Нам нужен некий механизм, который будет обходить это \"бутылочное горлышко\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-Sequence with RNNs and Attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте не будем делать состояние $c$ фиксированным. Пусть на каждом этапе, при генерации нового слова, наш декодер имеет возможность сформировать новое $c$, на основе всех скрытых состояний $h_i$ энкодера. \n",
    "Для простоты - пусть он подбирает веса, суммирующиеся в единицу, с которыми сложить эти представления, чтобы получить новое $c$.\n",
    "Таким образом, в каждый момент времени наш декодер имеет доступ ко всему исходному предложению (представлению каждого слова) и может акцентировать внимание на конкретно нужных в данный момент словах. \n",
    "\n",
    "Говоря немного мудрено - теперь длина пути, который надо преодолеть информации от места ее появления до места, где она может пригодиться - 1, а раньше она была пропорциональна длине исходного предложения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/seq_to_seq_with_rnn_and_attention_mechanism_step_1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/seq_to_seq_with_rnn_and_attention_mechanism_step_2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/seq_to_seq_with_rnn_and_attention_mechanism_step_3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Stanford University CS231n: Recurrent Neural Networks](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим как такой подход  работает на примере перевода с английского на французский \n",
    "\n",
    "Как мы знаем, на каждом шаге генерируется набор весов, которые отвечают за фокусировку на том или ином месте входной последовательности. Как мы видим, английское предложение имеет иной порядок слов относительно французского. Например, в английском варианте словосочетание **European Economic Area**, в то время как во французском **zone économique européenne**. \n",
    "\n",
    "В английском прилагательные идут перед существительным, в то время как во французском языке наоборот. \n",
    "\n",
    "Таким образом, благодаря гибкости модели, мы можем обрабатывать и учитывать разный порядок слов в разных языках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/visualize_attention_weights.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Механизм внимания не обязательно должен принимать на вход последовательность. \n",
    "\n",
    "* Мы можем применять его, в том числе для генерации подписей для картинок. Входом в данном случае будет являться матрица признаков, которая была получена при применении сверточной сети к картинке. \n",
    "\n",
    "* Далее по этой матрице мы считаем веса внимания и делаем аналогично первому примеру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим шагом будет также заметить, что для достаточно длинного предложения наша модель может забыть и то, что она генерирует. Потому мы можем сделать два attention - один на представление исходного предложения, а второе - на представление того, что уже сгенерировано (что еще не сгенерировано - заменяем нулями)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проблема attention\n",
    "\n",
    "Очевидно, у этого подхода есть свои минусы. \n",
    "\n",
    "Самый важный из них - ваша модель должна уметь предсказывать веса, с которыми складываются слова из предложения при формировании нового контекстного вектора $c$. И обычные подходы принуждают нас фиксировать размер этого вектора весов. \n",
    "\n",
    "За счет этого у нас возникает ограничение, от которого мы избавлялись - модель не может принимать (и, если используем attention на то, что сгенерировано, генерировать) предложения больше определенного размера. С другой стороны, ничто не мешает поставить этот максимальный размер достаточно большим, чтобы для бОльшей части предложений это работало. \n",
    "\n",
    "Почему это не сильный проигрыш в сравненении с LSTM - так оно все равно было ограничено в длине предложения, просто неявно, что даже хуже - лучше иметь модель, которая на длине предложения 45 падает, а не генерирует лабуду. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Captioning with RNNs and Attention\n",
    "\n",
    "Модели, основанные на внимании (attention) намного более продвинутые, нежели обычные нейросети. Они могут концентрироваться на отдельных частях данных, что позволяет избежать зашумления представлений.\n",
    "\n",
    "Идея состоит в том, что на каждом этапе генерации описания, нейронная сеть в разной степени обращать внимание на те или иные фрагменты изображения, соответствующие следующему слову в описании.\n",
    "\n",
    "После обучения модели можно увидеть, что она как бы переносит своё внимание по изображению для каждого генерируемого слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/image_captioning_with_rnn_and_attention_example_step_1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/image_captioning_with_rnn_and_attention_example_step_2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/image_captioning_with_rnn_and_attention_example_step_3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/image_captioning_with_rnn_and_attention_example_step_4.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Stanford University CS231n: lectures](http://cs231n.stanford.edu/slides/2017/)\n",
    "\n",
    "Пример работы на изображении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/visulize_attention_map.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Также нейросети, основанные на внимании, повсеместно используются для ответов на визуальные вопросы (Visual Question Answering). Цель этой задачи — обучить модель отвечать на вопрос по изображению. Например, она должна уметь не только называть сами объекты на фотографии, но и считать их, распознавать цвета и оценивать расположение относительно друг друга. Такие нейросети могут помочь незрячим людям и о нейро-символическом мышлении.\n",
    "\n",
    "[ссылка на исследование](https://www.reg.ru/blog/nejroset-opisyvaet-mir-nezryachim-lyudyam/) \n",
    "и еще [одна ссылка](https://www.reg.ru/blog/uchim-nejroseti-rassuzhdat-o-tom-chto-oni-vidyat/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/visulize_attention_map_examples.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key, query, value \n",
    "\n",
    "Мы можем формализовать процедуру attention через введение концепций **key**, **query** и **value**. \n",
    "\n",
    "К примеру, у нас есть картинка. На этой картинки у нас есть области, которые можно описать одним словом - **key**. Например - фонарь/девушка/... \n",
    "\n",
    "Сами эти области - это **value**, которые введенным **key** соответствуют. \n",
    "\n",
    "Далее нам приходит **query** - например, running. Мы можем посчитать похожесть каждого из ключей, которые у нас есть на query. \n",
    "\n",
    "И далее выдать информацию только по **value**, похожим на наш **query**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/key_query_value_example.jpg\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Послезная статья про NLP — BERT & Transformer, откуда взяты картинки по теме](https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути мы описали то, как будем делать при помощи нейронок питоновский словарь. С той разницей, что питоновский словарь может выдавать значения для только тех ключей, что в нем есть, а наш словарь выдает ответ для любого ключа-запроса, основываясь на его похожести на ключи словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key, Query, Value на примере текста \n",
    "\n",
    "Разобьем наше предложение на токены (в данном случае - просто слова). Получим представление каждого токена"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/key_query_value_sentence.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое слово будет являться одновременно и key, и value. \n",
    "\n",
    "Теперь можно подать любой query, например - вода, и в случае, если у нас эмбединги слов хорошие, что нам \"подсветятся\" слова, связанные с водой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Layer\n",
    "\n",
    "Эту идею реализует attention layer. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что мы таким образом получили? Фактически, мы получили дифференцируемый аналог словаря в Python. Только этот словарь еще умеет делать неточный поиск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть некий изначальный набор $X$ - слова в нашем предложении. \n",
    "\n",
    "Мы можем их преобразовать как-то, чтобы получить более удобные для дальнейшей цели $K$ - предполагается, что они лучше помогают сравнивать между собой слова. \n",
    "В простейшем случае некое линейное преобразование $K = XW_K$\n",
    "\n",
    "Далее у нас есть значения, $V$, которые тоже получаются из $X$ путем какого-то преобразования, которое делает их более применимыми для работы модели (важные признаки и тд), например $V = XW_Q$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее к нам приходят запросы $Q$, которые находятся в том же пространстве, что и ключи. Фактически - наша нейросеть пытается вытащить из данных интересующую ее информацию. К примеру - ей нужно найти всех животных и все растения - тогда $Q = \\text{\\{“животные”, “растения”\\}}$\n",
    "\n",
    "Мы сравниваем эти запросы с ключами - считаем просто попарные косинусные расстояние между каждым ключом $K_i$ и запросом $Q_j$. Получаем похожесть каждого ключа на запрос, нормируем ее на корень из размерности представления нашего ключа. \n",
    "\n",
    "$E = \\dfrac {QK^T} {\\sqrt{D}} $\n",
    "\n",
    "Получили матрицу похожестей $E$, где $E_{ij}$ - похожесть ключа $K_i$ на запрос $Q_j$\n",
    "\n",
    "Далее мы применяем к похожестям $E$ softmax, беря его по каждомуу ключу отдельно (по каждому столбцу матрицы $E$). Теперь у нас похожести каждого запроса складываются в единицу. \n",
    "\n",
    "$A = softmax(E,\\, dim=1)$\n",
    "\n",
    "Получили для каждого запроса его \"разложение\" в виде ключей. \n",
    "\n",
    "Далее, чтобы получить значения, соответствующие каждому запросу, складываем значения с весами соответствующих ключей\n",
    "\n",
    "$\\displaystyle Y_j = \\sum_iA_i V_i$\n",
    "\n",
    "$Y = AV$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/attention_layer.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax normalization \n",
    "\n",
    "Вы могли заметить, что в формуле для $E$ мы делим на корень из размерности представления ключа. Зачем это? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сгенерируем вектор из многомерного нормального распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "a = np.random.normal(0,100,size=(10000))\n",
    "\n",
    "plt.title(\"Normal distribution, std = 100\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xlabel(\"Sample value\")\n",
    "\n",
    "plt.hist(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И посмотрим, что будет с распределением значений этого вектора, если к нему применить softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax \n",
    "\n",
    "plt.title(\"Softmax on N(0, 100)\")\n",
    "plt.ylabel(\"Softmax value\")\n",
    "plt.xlabel(\"Sample index\")\n",
    "\n",
    "plt.plot(softmax(a))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти все значения 0 и одно (наибольшее), стало 1. \n",
    "Мы получили так называемое вырожденное распределение - у него вся плотность сосредоточена в одной точке. \n",
    "\n",
    "И получили на абсолютно случайных данных. \n",
    "\n",
    "Это приведет к затуханию градиента - мы будем распространять ошибку только для 1 значения из 10000. Учиться сеть будет плохо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но этого можно избежать - давайте просто стандартизируем наши данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.random.normal(0,100,size=(10000))\n",
    "\n",
    "unit_std = std/100\n",
    "\n",
    "plt.title(\"Normal distribution, std = 100\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xlabel(\"Sample value\")\n",
    "plt.hist(std)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Normal distribution, std = 1\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xlabel(\"Sample value\")\n",
    "plt.hist(unit_std)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути в распределении ничего не поменялось - только масштаб. Но теперь softmax работает нормально "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Softmax on N(0, 1)\")\n",
    "plt.ylabel(\"Softmax value\")\n",
    "plt.xlabel(\"Sample index\")\n",
    "\n",
    "plt.plot(softmax(unit_std))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остается только понять, а как нормировать наши данные в нашем слое? Считать налету, наверное, не лучшая идея. \n",
    "\n",
    "Наш слой делает скалярное произведение между двумя векторами, предположим, нормально распределенными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(dimensionality, experiments = int(10e4)):\n",
    "    c = []\n",
    "    for i in range(experiments):\n",
    "          a = torch.normal(0,1,size=(int(dimensionality),))\n",
    "          b = torch.normal(0,1,size=(int(dimensionality),))\n",
    "          c.append(torch.dot(a,b))\n",
    "        \n",
    "    c = torch.Tensor(c)\n",
    "    return float(c.mean()), float(c.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = {}, {}\n",
    "dims = torch.linspace(0, 100, 20)\n",
    "\n",
    "for dim in dims:\n",
    "\t\tdim = float(dim)\n",
    "\t\tt_mean, t_std = statistics(dim)\n",
    "\t\tmeans[dim] = t_mean\n",
    "\t\tstds[dim] = t_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(means.keys())\n",
    "y = list(means.values())\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.axhline(y=0, c='r', linestyle='--')\n",
    "plt.legend(['Mean value', 'Mean = 0'])\n",
    "plt.title(\"Mean value of dot products\")\n",
    "plt.ylabel(\"Mean value\")\n",
    "plt.xlabel(\"Vector dimensionality\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что среднее не сильно отличается от 0 (можно показать, что в среднем оно равно 0 для произведения нормально распределенных величин). \n",
    "\n",
    "А вот стандартное отклонение растет. И, можно предположить, что растет оно как корень из размерности вектора. Так и есть. Потому и появляется именно такой нормировочный множитель в attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(stds.keys())\n",
    "y = list(stds.values())\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"Std values and square distance\")\n",
    "plt.xlabel(\"Vector dimensionality\")\n",
    "\n",
    "x = np.linspace(0, 100, 10000)\n",
    "plt.plot(x, x**0.5, color='r')\n",
    "plt.legend([\"sqrt(x)\", \"empirical std\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keq, Query, Value на примере текста. Второй заход\n",
    "\n",
    "Хорошо, у нас есть предложение, мы его разбили на токены, допустим, мы хорошо умеем кодировать эти токены. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/key_query_value_sentence.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но каждый токен закодирован на основе самого себя, и только, например, слово bank встречается в тексте два раза, и будет закодировано одинаково, хотя несет разные значения (берег и, собственно, банк). \n",
    "\n",
    "Как нейросети их отличать? Ну, если мы попытаемся на основе только одного токена что-то сделать - никак. \n",
    "\n",
    "А как улучшить кодирование каждого токена, чтобы два \"банка\" отличались? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем следующее - каждый токен подадим в нейросеть **и в качестве query**. \n",
    "\n",
    "И будем аггрегировать полученную информацию, получая токен, который будет содержать более конкретную информацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/key_query_value_sentence_example.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, bank, который банк, будет содержать информацию о том, что он не просто bank, а \"Bank of America\", который нужно найти (find).\n",
    "\n",
    "Такой подход - когда key, query и value формируются на основе одного и того же входа нейросети называется self-attention\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention Layer\n",
    "\n",
    "Сделаем это все в виде слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/self_attention_layer.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что изменилось? \n",
    "\n",
    "Теперь $X$ участвует и в производстве $K$, и в производстве $V$, и в производстве $Q$. Потому и self-attention - предложение состоящее из слов $X_i$, ищет само себя в нашем дифференцируемом словаре. Почему это не приводит к тому, что мы просто получим вектор $V$?\n",
    "Потому что значения $X_i$ модифицируются и $K \\neq Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один пример проблемы с текстом, который обычные методы решали плохо\n",
    "\n",
    "Многие из нас знают Второй Закон Робототехники\n",
    "\n",
    "**Second Law of Robotics**\n",
    "\n",
    "\n",
    "A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\n",
    "\n",
    "Представим, что машина хочет понять, что здесь написано. И ей нужно понять, что имеется ввиду под it. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом она формирует на основе каждого слова key и value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/self_attention_example_folders_step_1.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем она смотрит, какие ключи похожи на Query, полученный из it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/self_attention_example_folders_step_2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить, что же на самом деле значит it, машина считает взвешенную сумму values, где  веса определяются похожестью query на value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/gpt2_value_vector_sum.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка на оригтнальную статью про GPT-2 с более подробными объяснениями как оно работает.](https://jalammar.github.io/illustrated-gpt2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге получается, что it представляет собой \"a robot\" (ну и само себя). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведена простая реализация слоя self-attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedSelfAttention(nn.Module): \n",
    "    def __init__(self, input_size, key_size = 100, value_size = 20):\n",
    "        super().__init__()\n",
    "        self.keyer = nn.Linear(input_size, key_size)\n",
    "        self.valuer = nn.Linear(input_size, value_size)\n",
    "        self.querier = nn.Linear(input_size, key_size)\n",
    "\n",
    "        self.norm_factor = key_size ** 0.5\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape:\".ljust(20), x.shape)\n",
    "\n",
    "        query = self.querier(x)\n",
    "        key = self.keyer(x)\n",
    "        value = self.valuer(x)\n",
    "\n",
    "        print(\"Query shape:\".ljust(20), query.shape)\n",
    "        print(\"Key shape:\".ljust(20), key.shape)\n",
    "        print(\"Value shape:\".ljust(20), value.shape)\n",
    "\n",
    "        activations = torch.mm(query, key.t()) / self.norm_factor\n",
    "        norm_activation = nn.functional.softmax(activations, dim = 1)\n",
    "        result = torch.mm(norm_activation, value)\n",
    "\n",
    "        print(\"Activations shape:\".ljust(20), activations.shape)\n",
    "        print(\"Result shape:\".ljust(20), result.shape)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 30\n",
    "data = torch.randn(10, in_size)\n",
    "\n",
    "SA = SimplifiedSelfAttention(in_size)\n",
    "result = SA(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional encoding\n",
    "\n",
    "Единственный возможный минус - наша нейросеть не учитывает порядка слов в предложении при составлении embedding. Это может нам мешать. Например, если в предложении два it, то они часто относятся к разным словам. Потому хотим уметь учитывать информацию о позиции. Для этого к $X$ при составлении $Q$ добавляется информация о позиции. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/positional_encoding.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делается это хитрым образом - мы берем и добавляем к каждому значению исходного вектора токенов некую комбинацию $sin$ и $cos$ с разными параметрами. \n",
    "\n",
    "Вектор $PE$, который мы будем добавлять к $X$ будет определяться по следующей формуле"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$PE_{pos, 2i} = \\sin \\left({\\dfrac {pos} {10000^{2i/d}}}\\right)$$\n",
    "\n",
    "$$PE_{pos, 2i+1} = \\cos \\left({\\dfrac {pos} {10000^{2i/d}}}\\right)$$\n",
    "\n",
    "$pos$ &mdash; это позиция токена\n",
    "\n",
    "$d$ &mdash; количество размерностей токена\n",
    "\n",
    "$i$ &mdash; $i$-тая размерность токена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import math\n",
    "import torch.nn as nn\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)].detach() \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(20)\n",
    "Y = pe(torch.zeros(1, 100, 20)) # sequence of shape 100, every token of sequence has shape 20  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(np.arange(100), Y[0, :, 0:4].data.numpy())\n",
    "plt.legend([\"dim %d\"%p for p in [1,2,3,4]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате каждая позиция коддируется уникальным представлением. При этом представление позволяет легко находить слова на заданном расстоянии от исходного (у них будет одинаково значение сигнала по какой-то оси)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(np.arange(100), Y[0, :, 4:8].data.numpy())\n",
    "plt.legend([\"dim %d\"%p for p in [4,5,6,7]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это помогает транформеру достаточно уникальным образом определять каждую позицию и понимать относительное расстояние между разными токенами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Self-Attention Layer\n",
    "\n",
    "\n",
    "Допустим,  нас стоит проблема, что мы не должны видеть часть слов в предложении - например, при генерации текста (по текущим словам предсказать следующее). Например, хотим сгенерировать фразу \"robot must obey orders\" на основе только первого слова. \n",
    "\n",
    "Если мы скормим в нейронную сеть во время обучения сразу все предложение, которое хотим генерировать, то у нас в первых словах будет \"протекать\" информация о предыдущих."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/queries_keys_scores_before_softmax.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае мы можем просто на соответствующих местах матрицы $E$ поставить минус бесконечности - тогда в эмбедингах слов, которые не должны знать о каких-то словах, информации об этих словах не будет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/scores_before_softmax_apply_attention_mask_masked_scores_before_softmax.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате мы сможем, после softmax \"лишняя\" информация не будет использоваться при генерации ответа на query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/masked_scores_softmax_along_rows_scores.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря этому трюку, у нас получается обучать transfomer по-прежнему как простую single-pass нейросеть, а не \"скатываться\" в RNN, где у нас возникнут проблемы с градиентами и временем работы "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihead Self-Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/multihead_self_attention_layer.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на то, к каким словам предложения gave может иметь отношение. В общим случае глагол может иметь связку со многоми частями предложения. Как, например, с подлежащим, так и с причастиями.\n",
    "\n",
    "В идеале, нам бы хотелось обратить внимние функции (attention) на все эти взаимосвязи. Для этого нам просто надо поставить несколько attention слоев парралельно. В идеале каждый будет учить что-нибудь свое - аналогия с конволюциями. \n",
    "\n",
    "* Чтобы осуществить задуманное, вместо одного набора query, будем использовать несколько независимых наборов. \n",
    "\n",
    "* Причем каждый набор будет считаться уникальной матрицей. \n",
    "\n",
    "* Аналогично сделаем для keys и values. Количество таких наборов внутри keys, queries, values должно быть **одинаковым**. \n",
    "\n",
    "* Обозначим это число как h - head, далее производим аналогичные манипуляции, при этом введем в параллель h таких функций attention\n",
    "* На последнем шаге мы их соединяем (конкатинируем)\n",
    "\n",
    "* При этом, можно заметить, что таком подходе на каждом шаге размерность токена будет увеличиваться (если, например, в качестве и key, и value, и query мы подаем одно и тоже предсталение токена). Если хотим сохранять управлять размерностью токена, то придется получать по меньшей мере value путем домножения на матрицу, размерность которой по второй оси меньше - **выполнять проекцию наших токенов в пространство меньшей размерности**\n",
    "\n",
    "* В частности, можно подобрать размерность этого пространства таким образом, чтобы при конкатенации размерность полученного токена равнялась исходной. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/scaled_dor_product_attention_multihead.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention is all you need\n",
    "\n",
    "Оказывается, этот подход работает сам по себе. Не нужно добавлять никаких реккурентных слоев - просто делаем много правильно соединенных attention layers. Полученная в результате архитектура получала название attention transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/attention_is_all_you_need.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый блок "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/attention_transformer_basic_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок устроен следующим образом: входные вектора мы запускаем в блок self-attention и используем residual connection как обходной путь вокруг self-attention, затем мы их складываем. Так как обычно используют multi head self-attention, тут нам и пригождается возможность подобрать параметры так, чтобы размерности входных и выходных токенов не отличались. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После - применяем слой нормализации, затем - слой feed forward (MLP), плюс обходной путь вокруг feed forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/mlp_transformer_block.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Складываем выход MLP-части с residual connection и выполняем нормализацию.\n",
    "\n",
    "Нормализация везде нужна для того, чтобы нейросеть нормально обучалась. \n",
    "\n",
    "Заводим ли разный MLP на каждый токен (по позиции) - конечно нет. К каждому токену применяются MLP с одними и теми же весами. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реальных моделях выходы этих слоев стекают друг с другом и получается большая трансформер-модель. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/img_license/mlp_transformer.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это пример Encoder-модели. Такова рассматриваемая далее BERT. В такой модели на выходе мы получаем некое хорошее представление исходного предложения. \n",
    "\n",
    "Но что если мы хотим сделать задачу перевода с одного языка на другой? Нужен еще Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первая стадия\n",
    "\n",
    "На первой стадии то, как работает Decoder не так сильно отличается от работы Encoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/decoder_transformer.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тем не менее, есть один важный нюанс -  мы используем Masked Attention - наша нейросеть не должна видеть слов, которые еще не сгенерировала. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе первого этапа у нас формируются только query - наша нейросеть на основе того, что она уже сгенерировала решает, какая информация ей нужна дальше "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вторая стадия\n",
    "\n",
    "Теперь мы используем для $K$, $V$ информацию, полученную из энкодера и получаем предсказание. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/encoder_decoder_transformer.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Примеры применений Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Непосредственное применение разобранной архитектуры Encoder-Decoder для перевода текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/transformer_text_translation_example.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT (Bidirectional Encoder Representations from Transformers )\n",
    "\n",
    "В случае BERT используется только Encoder часть\n",
    "\n",
    "Это нейросеть, предобученная на огромном корпусе английского текста. \n",
    "\n",
    "Перед ней ставили следующие задачи:\n",
    "\n",
    "**Задача 1**\n",
    "\n",
    "На вход дается предложение - в нем выбрано $15\\%$ токенов, из которых:  \n",
    "1. $80\\%$ замаскированы  \n",
    "2. $10\\%$ заменены случайным  \n",
    "3. $10\\%$ оставлены без изменений\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 2**\n",
    "\n",
    " На вход даются два предложения - сказать, идет ли второе непосредственно за первым в тексте, или нет (просто случайное предложение из корпуса)\n",
    "\n",
    "\n",
    "В результате на вход подается все в таком виде:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/bert.jpg\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$CLS$ токен нужен для того, чтобы нейросети было, куда класть информацию обо всем предложении в целом. \n",
    "\n",
    "$SEP$ нужен просто для того, чтобы разделять два предложения (если мы подаем их два) и для того, чтобы отмечать окончание. Использование $SEP$ с двумя целями позволяет подавать в уже обученную нейросеть только одно предложение. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Language Model\n",
    "\n",
    "Для первой задачи используем Encoder-Decoder \n",
    "\n",
    "То есть у нас есть **Encoder**, который получает богатые представления и добавленный только на время обучения **Decoder** (не attention, просто MLP).\n",
    "\n",
    "Именно Decoder отвечает за то, чтобы предсказывать пропущенные/замененные токены. Ошибка считается только по тем $15\\%$ токенов, для которых могло произойти изменения, а не по всему предложению.\n",
    "\n",
    "Как гарантируется, что модель не заменяет имевшиеся в предложение слова на другие? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/masked_language_model.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Sentence Prediction \n",
    "\n",
    "Для второй задачи - Classifier. \n",
    "\n",
    "При этом на вход ему подается только сам CLS токен \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/next_sentence_prediction.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель на обеих задачах одновременно. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning с BERT \n",
    "\n",
    "Обученную таким образом модель (оставляем только encoder), можно использовать для огромного числа других задач \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/transfer_learning_with_bert.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot learning \n",
    "\n",
    "Более того, есть BERT, тренированная на большом числе разных языков.\n",
    "\n",
    "Это позволяет, например, сравнивать предложения из разных языков, хотя мы этому даже не учились. Поиграть можно [здесь](https://colab.research.google.com/github/deepmipt/dp_tutorials/blob/master/Tutorial_2_DeepPavlov_BERT_transfer_learning.ipynb#scrollTo=S1iqGcxUINyU). Веса будут грузиться ДОЛГО"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/zero_shot_learning_bert.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Специализированные аналоги BERT\n",
    "\n",
    "Более того, можно тренировать BERT под строго определенные задачи - например, анализ текстов научных статей "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/bert_specialized_analogs.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT (Generative Pretrained Transformer )\n",
    "\n",
    "В случае GPT используется только Decoder часть. Но теперь во всех частях используются masked attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/generative_pretrained_transformer_gpt.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это нейросеть обширно используется для, например, задачи генерации текста,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает она следующим образом - даем ей в качестве исходного входа какую-то затравку. \n",
    "\n",
    "Можно просто SOS (Start of sentence) токен, обозначающий начало предложения и больше не несущий никакой дополнительной информации\n",
    "\n",
    "\n",
    "Она дает какой-то выход. Подаем этот выход нейросети как вход. \n",
    "Делаем так до тех пор, пока не надоест/не достигнем максимальной длины предложения/не встретим символ окончания генерации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/gpt2_autoregression.gif\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как ее обучали - на самом деле, тоже unsupervised. Но теперь перед моделью ставится задача предсказывать по предыдущим словам в предложении текущее.\n",
    "\n",
    "Понятно, что такую модель можно сразу же идти и использовать для генерации, для которой она и училась \n",
    "\n",
    "Однако затем ее можно применять для многих других задач (опять же, путем transfer learning):\n",
    "\n",
    "\n",
    "1. Классификации - подаем сразу все предложение, полученное представление используем для предсказания\n",
    "\n",
    "2. Entailment (Определение логического следования) - даем изначальные данные, гипотезу, надо оценить, следует ли гипотеза из данных\n",
    "\n",
    "3. Similarity - можем оценивать похожесть предложений. Так как это мы определяем порядок предложений, то, чтобы избежать неявной зависимости от порядка пропускания предложений, будем использовать результат пропускания через нейросеть обоих возможных порядков. \n",
    "\n",
    "4. Выбор варианта ответа на вопросы - может обучить нейросеть отвечать на вопросы с множественным выбором. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/gpt_classification_entailment_similarity.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно научить нейросеть отвечать на вопросы и т.д. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строго говоря, мы можем даже текст переводить с помощью GPT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/decoder_only_transformer_translation.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просто подаем предложение с токеном в конце, определяющим, на какой язык переводим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогичной схеме можем научить нашу сеть [делать summary текста](https://arxiv.org/abs/2109.10862)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/decoder_only_summarization.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Здесь](https://6b.eleuther.ai/) можно поиграть с open-source GPT-J\n",
    "\n",
    "А [здесь](https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb#scrollTo=e-NKauYvgTNG) - поиграть, но уже в Collab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"6\">Хорошие источники \n",
    "\n",
    "[Про трансформеры](https://www.notion.so/Transformers-969f4b27c48147778c1e2dbda0c83ce0)\n",
    "\n",
    "[Аннотированный трансформер](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\n",
    "\n",
    "[Код множества моделей с красивыами комментариями](https://nn.labml.ai/)\n",
    "\n",
    "[BERT](https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c)\n",
    "\n",
    "[Зоопарк BERT](https://ai.plainenglish.io/so-how-is-bert-different-ad43a42cab48)\n",
    "\n",
    "[От NLP до Transformer](https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524)\n",
    "\n",
    "[Illustrated transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "[Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/)\n",
    "\n",
    "[Open-source реализация GPT-3](https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/)\n",
    "\n",
    "[Transformer для русского языка](https://github.com/vlarine/transformers-ru)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
