{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Рекуррентные нейронные сети (RNN)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Особенности рекуррентных нейронных сетей\n",
    "\n",
    "До этого мы работали с методами машинного обучения, которые работают с признаковым описанием фиксированной длины.\n",
    "\n",
    "Так правильно делать в случае табличных данных &mdash; обычно каждый объект в таблицах описан фиксированным набором признаков, и новые признаки не могут появиться \"вдруг\". Мы точно знаем, что на вход нам приходит объект размера 100, а на выходе мы должны для него предсказать 1 число. \n",
    "\n",
    "Верно это и про данные в виде изображений &mdash; обычно наша нейросеть учится на изображениях определенного разрешения. Да, иногда мы делаем нейросеть, которая способна работать с изображением почти любого разрешения, но добиваемся мы этого за счет вставки слоев global pooling, которые просто приводят любое признаковое описание, полученное нашей нейросетью, а точнее, ее сверточной частью, ранее, к фиксированному размеру. \n",
    "\n",
    "Однако многие данные структурой фиксированной длины не обладают. К примеру &mdash; тексты. Возьмем все абзацы из \"Войны и Мира\". Какие-то будут больше, какие-то меньше. И обрезать их как-то нельзя. Аналогично будет и для текстов из Твиттера и т.д. И что делать, если мы хотим предсказывать, например, эмоциональную окрашенность текста? \n",
    "\n",
    "Более того, а что делать, если, к примеру, на основе абзаца текста нам необходимо сгенерировать его краткое содержание? То есть и то, что нужно предсказать, у нас может быть разной длины. Аналогично &mdash; мы хотим по данным о курсе валюты за прошлый год спрогнозировать курс валюты на следующий месяц по дням.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/time_series_data.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, у нас есть целый набор задач, для которых необходима особая структура нейросети, позволяющая, так или иначе, принимать данные разного размера. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Примеры задач\n",
    "\n",
    "**Анализ временных рядов**\n",
    "- Табличные данные\n",
    "- Аннотирование изображений и видео (Image/Video captioning)\n",
    "- Машинный перевод\n",
    "- Распознавание текста\n",
    "- Распознавание речи\n",
    "\n",
    "\n",
    "**Генеративные модели**\n",
    "- Генерация текста/речи (например, чат - боты)\n",
    "- Генерация изображений\n",
    "\n",
    "**Классификация**\n",
    "- Изображения\n",
    "- Блоки текста (Sentiment analysis)\n",
    "\n",
    "**Анализ последовательностей**\n",
    "- анализ текстов\n",
    "- биологические последовательности \n",
    "- химические последовательности\n",
    "\n",
    "\n",
    "Общее для задач - мы имеем возможность сохранять информацию, сформированную при обработке одной части объекта (**токена**), и использовать ее, когда мы анализируем другие части. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До прихода нейронных сетей предложения пытались описать при помощи набора правил - грамматик, которые довольно успешно могли генерировать новые осмысленные предложения. Так выглядит разбор при помощи грамматик простого предложения \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/parse_tree.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако грамматики плохо учитывали более глобальные связи. Например, очень тяжело было добиться того, чтобы в абзаце текста:\n",
    "\n",
    "\"Леша пришел домой. Он будет есть рыбу\"\n",
    "\n",
    "Компьютер понял, что во втором предложении \"Он\" соответствует \"Леше\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея, на которой основано RNN, состоит в следующем &mdash; а давайте возьмем и всю последовательность пропустим через одну и туже нейросеть. \n",
    "Но при этом сама нейросеть кроме следующего элемента последовательности (например, слова в тексте), будет принимать еще один параметр &mdash; некий $v$, который в начале будет, например, вектором из нулей, а далее &mdash; значением, которое выдает сама нейросеть после обработки очередного элемента последовательности (**токена**)\n",
    "\n",
    "Также далее мы будем использовать понятие **нулевого токена** - токена, который символизирует заплатку, токен, не несущий никакого смысла, но который иногда нужно передать модели. Например - как сигнал начала работы\n",
    "\n",
    "В этом $v$ (чаще обозначается $h$) &mdash; будет храниться hidden state, состояние, учитывающее и локальный, и глобальный контекст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/rnn_idea.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Recurrent neural network\n",
    "](https://en.wikipedia.org/wiki/Recurrent_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом наша нейросеть может выдавать некий ответ на каждом шаге, но мы можем:\n",
    "\n",
    " 1. Использовать только выданное на последнем (если нам нужно предсказать одно значение) &mdash; many-to-one\n",
    "\n",
    " 2. Мы можем подавать в наше нейросетку токены (когда кончился исходный сигнал &mdash; подаем нулевые токены), пока она не сгенерирует токен, символизирующий остановку (many-to-many, one-to-many)\n",
    "\n",
    " 3. Можем делать различные комбинации, игнорируя выходы нейросети в начале, например"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "«One to one» &mdash; обычная нейронная сеть, RNN здесь не нужно\n",
    "\n",
    "Более сложной является реализация «one to many», когда у нас есть всего один вход и нам необходимо сформировать несколько выходов. Такой тип нейронной сети актуален, когда мы говорим о генерации музыки или текстов. Мы задаем начальное слово или начальный звук, а дальше модель начинает самостоятельно генерировать выходы, в качестве входа к очередной ячейке рассматривая выход с прошлой ячейки нейронной сети.\n",
    "\n",
    " Если мы рассматриваем задачу классификации, то актуальна схема «many to one». Мы должны проанализировать все входы нейронной сети и только в конце определиться с классом.\n",
    " \n",
    "  Схему «many to many», когда количество выходов равно количеству входов нейронной сети. Обычно это задачи вида: разметить исходную последовательность. Например - указать столицы городов, названия важных объектов, веществ и т.д., что относится к задачам вида NER (Named entity recogition).\n",
    "  \n",
    "Ну и последней разновидностью нейронных сетей является сеть вида «many to many», когда количество выходов нейронной сети не равно количеству входов. Это актуально, к примеру, в машинном переводе, когда одна и та же фраза может иметь разное количество слов в разных языках (т.е. это реализует схему кодировщик-декодировщик). Кодировщик получает данные различной длины &mdash; например, предложение на английском языке. С помощью скрытых состояний он формирует из исходных данных вектор, который затем передаётся в декодировщик. Последний, в свою очередь, генерирует из полученного вектора выходные данные &mdash; исходную фразу, переведённую на другой язык."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/one_or_many_to_one_or_many_ways.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно объединять разные подходы. Сначала генерируем некий $h$, который содержит сжатую информацию о том, что было подано в нейросеть, а затем подаем его в нейросеть «one to many», которая генерирует, к примеру, перевод того текста, что был подан первой части нейросети. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/sequence_to_sequence.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Базовый RNN блок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим работу рекуррентной нейронной сети:\n",
    "1. На вход нейронной сети поступает некоторая последовательность $x = \\{x_1,...x_t,...,x_n\\}$. \n",
    "\n",
    "2. Для каждого поступившего $x_t$ мы формируем скрытое состояние $h_t$, которое является функцией от предыдущего состояния $h_{t-1}$ и текущего элемента последовательности $x_t$:\n",
    "$$h_t = f_W(h_{t-1}, x_t),$$\n",
    "где $W$  - это обучаемые параметры (веса).\n",
    "\n",
    "3. На основании рассчитанного скрытого состояния, учитывающего предыдущие значения  $x_i$ формируется выходная последовательность $y = \\{y_1,...y_t,...,y_k\\}$. Для формирования предсказания $y_t$ в текущий момент времени в модель могут быть добавлены полносвязные слои, принимающие на вход текущее скрытое состояние $h_t$.\n",
    "\n",
    "Ниже представлена простая RNN. В качестве функции активации используется тангенс.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/rnn_basic_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важное отличие от слоев, с которыми мы уже сталкивались, состоит в том, что на выходе мы получаем два объекта: $y_t$ и $h_t$.\n",
    "\n",
    "$y_t$ &mdash; предсказание в текущий момент времени, например метка класса.\n",
    "\n",
    "$h_t$ &mdash; контекст, в котором предсказание было сделано. Он может использоваться для дальнейших предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNCell\n",
    "\n",
    "В Pytorch для вычисления $h_t$ используется модуль [RNNCell](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html)  \n",
    "\n",
    "$y_t$ в нем не вычисляется, предполагается, что для его получения в модель должен быть добавлен дополнительный линейный слой.\n",
    "\n",
    "**`input_size`** &mdash;  размер элемента последовательности.\n",
    "\n",
    "В отличие от сверточных, это всегда вектор, а не тензор, поэтому **`input_size`** &mdash;  скаляр.\n",
    "\n",
    "**`hidden_size`** &mdash; тоже скаляр. Он задает размер скрытого состояния, которое тоже является вектором. Фактически это количество нейронов в слое.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "rnn_cell = torch.nn.RNNCell(input_size=3, hidden_size=2)\n",
    "dummy_sequence = torch.randn((1, 3)) # batch, input_size\n",
    "h = rnn_cell(dummy_sequence) \n",
    "print(\"Inital shape:\".ljust(17), f\"{dummy_sequence.shape}\")\n",
    "print(\"Resulting shape:\".ljust(17), f\"{h.shape}\")  # hidden state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно следующее:  \n",
    "Для понятности в данном примере опущена батчевая обработка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# Simple RNNcell without a bias and batch support\n",
    "class SimplifiedRNNCell(nn.Module): \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    # Init weight matrix, for simplicity omit bias\n",
    "    self.W_hx = np.random.randn(input_size, hidden_size) * 0.0001 # hidden_size == number of neurons\n",
    "    self.W_hh = np.random.randn(hidden_size, hidden_size) * 0.0001 # naive initialization\n",
    "    self.h0 = np.zeros((hidden_size)) # Initial hidden state\n",
    "  \n",
    "  def forward(self, x, h=None): # Without a batch dimension\n",
    "    if h is None:\n",
    "      h = self.h0\n",
    "    h = np.tanh(self.W_hx.T.dot(x) + self.W_hh.T.dot(h))\n",
    "    return h \n",
    "  \n",
    "simple_rnn_cell = SimplifiedRNNCell(input_size=3, hidden_size=2)\n",
    "h = simple_rnn_cell(dummy_sequence[0]) # No batch \n",
    "print(f\"Out = h\\n{h.shape} \\n{h}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в последовательности всегда несколько элементов. И надо применить алгоритм к каждому.\n",
    "\n",
    "\n",
    " Поэтому RNNCell напрямую не используется. Для него есть обертка: [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) который обеспечивает последовательный вызов RNNCell для всех элементов последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN блок в Pytorch \n",
    "\n",
    "**Warning: batch dim is second!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(input_size=3, hidden_size=2) # batch_first = True\n",
    "dummy_batched_seq = torch.randn((2, 1, 3)) # seq_len, batch, input_size\n",
    "out, h = rnn(dummy_batched_seq) \n",
    "\n",
    "print(\"Inital shape:\".ljust(20), f\"{dummy_batched_seq.shape}\")\n",
    "print(\"Resulting shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RNN without batching\n",
    "\n",
    "class SimplifiedRNNLayer(nn.Module): \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    self.rnn_cell = SimplifiedRNNCell(input_size, hidden_size)\n",
    "\n",
    "  # Without a batch dimension x have shape seq_len * input_size\n",
    "  def forward(self, x, h=None):\n",
    "    all_h = []\n",
    "    for i in range(x.shape[0]): # iterating over timestamps\n",
    "      h = self.rnn_cell(x[i], h)\n",
    "      all_h.append(h) \n",
    "    return  np.stack(all_h), h\n",
    "\n",
    "simple_rnn = SimplifiedRNNLayer(input_size=4, hidden_size=2)\n",
    "sequence = np.array([[0, 1, 2, 0], [3, 4, 5, 0]]) # batch with one sequence of two elements \n",
    "\n",
    "out, h = simple_rnn(sequence)\n",
    "print(\"Inital shape:\".ljust(20), f\"{sequence.shape}\")\n",
    "print(\"Resulting shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберемся.\n",
    "\n",
    "К данным добавляется еще одно измерение размер последовательности. Таким образом, batch из 5 последовательностей по 6 элементов в каждой будет выглядеть так (время идёт первой размерностью, потому поэлементно идём \"сверху вниз\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/rnn_batch.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Размер самого элемента == 3\n",
    "\n",
    "Внутри RNN модуля элементы последовательности обрабатываются последовательно:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://edunet.kea.su/repo/EduNet-content/L08/out/simple_rnn_h_state.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса при этом используются одни и те же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_seq = torch.randn((2, 1, 3)) #  seq_len, batch, input_size\n",
    "\n",
    "print(\"RNNCell\")\n",
    "rnn_cell = torch.nn.RNNCell(3, 2)\n",
    "print(\"Parameter\".ljust(10), \"Shape\")\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t.ljust(10), p.shape) \n",
    "\n",
    "cell_out = rnn_cell(dummy_seq[0, :, :]) # take first element from sequence \n",
    "print()\n",
    "print(\"Result shape =\".ljust(20), cell_out.shape)\n",
    "print(\"Hidden state shape =\".ljust(20), cell_out.shape) # one hidden state\n",
    "\n",
    "print('----------------------------------------')\n",
    "\n",
    "print(\"RNN\")\n",
    "rnn = torch.nn.RNN(3, 2)\n",
    "print(\"Parameter\".ljust(15), \"Shape\")\n",
    "for t, p in rnn.named_parameters():\n",
    "  print(t.ljust(15), p.shape) \n",
    "\n",
    "out, h = rnn(dummy_seq)\n",
    "\n",
    "print()\n",
    "print(\"Result shape =\".ljust(20), out.shape) # h for all timestamps element\n",
    "print(\"Hidden state shape =\".ljust(20), cell_out.shape) # h for last element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слои (Stacked RNNs)\n",
    "\n",
    "\n",
    "RNN блоки можно объединять в слои, накладывая их друг на друга. Для этой операции в `torch.nn.RNN` есть аргумент `num_layers`, с помощью которого можно указать количество слоёв.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/L08/out/layers.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((2, 1, 3))  #seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3, 2, num_layers=3)\n",
    "\n",
    "# Weights matrix sizes not changed!\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out:\\n\", out.shape) # Hidden states for all elements from top layer\n",
    "print(\"h:\\n\", h.shape) # Hidden states for last element for all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional\n",
    "\n",
    "Последовательность можно пропустить через сеть два раза: в прямом и обратном направлении. Для этого создаётся слой, аналогичный входному, для обратного направления, и результат двух слоёв конкатинируется.\n",
    "\n",
    "[Understanding RNN implementation in PyTorch](https://medium.com/analytics-vidhya/understanding-rnn-implementation-in-pytorch-eefdfdb4afdb)\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/L08/out/bidirectional.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((2, 1, 3))  #seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3, 2, bidirectional=True)\n",
    "\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out:\\n\", out.shape) # Concatenated Hidden states from both layers\n",
    "print(\"h:\\n\", h.shape) # Hidden states last element from  both : 2*num_layers*hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример прогнозирования временного ряда\n",
    "\n",
    "---\n",
    "- [How to Remove Non-Stationarity in Time Series Forecasting](https://towardsdatascience.com/how-to-remove-non-stationarity-in-time-series-forecasting-563c05c4bfc7)\n",
    "- [A Guide to Time Series Forecasting in Python](https://builtin.com/data-science/time-series-forecasting-python)\n",
    "- [Detecting stationarity in time series data](https://towardsdatascience.com/detecting-stationarity-in-time-series-data-d29e0a21e638)\n",
    "- [Most useful Python functions for Time Series Analysis](https://towardsdatascience.com/most-useful-python-functions-for-time-series-analysis-ed1a9cb3aa8b)\n",
    "- [Data transformations and forecasting models: what to use and when](https://people.duke.edu/~rnau/whatuse.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что общего у прогнозирования потребления электроэнергии домохозяйствами, оценки трафика на дорогах в определенные периоды, прогнозировании паводков и прогнозировании цены, по которой акции будут торговаться на фондовой бирже?\n",
    "\n",
    "Все они подпадают под понятие данных временных рядов! Вы не можете точно предсказать любой из этих результатов без компонента «время». И по мере того, как в мире вокруг нас генерируется все больше и больше данных, прогнозирование временных рядов становится все более важной областью применения методов ML и DL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных \n",
    "[Time Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных\n",
    "\n",
    "Air Passengers per month.  \n",
    "[Dataset Air Passengers Number of air passengers per month](https://www.kaggle.com/rakannimer/air-passengers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://edunet.kea.su/repo/EduNet-web_dependencies/L08/airline-passengers.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = dataset.iloc[:, 1:2].values # transform dataframe to numpy.array\n",
    "# plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data, label='Airline Passangers Data')\n",
    "plt.title(\"Number of passengers per month\")\n",
    "plt.ylabel(\"#passengers\")\n",
    "plt.xlabel(\"Month\")\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "plt.xticks(labels_to_display, dataset['Month'][labels_to_display])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шкалирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min - Max normalization\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "print('Initial statistics:')\n",
    "print('Minimum value:', repr(td_min).rjust(5))\n",
    "print('Maximum value:', repr(td_max).rjust(5))\n",
    "\n",
    "training_data = (training_data - td_min) / (td_max - td_min)\n",
    "print('\\nResulting statistics:')\n",
    "print('Minimum value:', repr(training_data.min()).rjust(5))\n",
    "print('Maximum value:', repr(training_data.max()).rjust(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование ансамблей данных\n",
    "\n",
    "Поскольку мы хотим научиться предсказывать следующие значение на основе предыдущих, нам нужно подготовить данные соответствующим образом.\n",
    "\n",
    "Разобьем весь массив данных на фрагменты вида\n",
    "\n",
    "$x \\to y$\n",
    "\n",
    "где $x$ - это подпоследовательность, например записи с 1-й по 8-ю, а $y$ - это значение из 9-й записи, то самое, которое мы хотим предсказать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# create data \"ensemble\"\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "        _x = data[i:(i + seq_length)] # picking several sequential observations\n",
    "        _y = data[i+seq_length] # picking the subsequent observation\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return torch.Tensor(np.array(x)), torch.Tensor(np.array(y))\n",
    "    \n",
    "# set length of the ensemble; accuracy of the predictions and \n",
    "# speed perfomance almost always depend on it size\n",
    "seq_length = 8 # compare 2 and 32\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "print(\"Example of the obtained data:\\n\")\n",
    "print(\"Data corresponding to the first x:\")\n",
    "print(x[0])\n",
    "print(\"Data corresponding to the first y:\")\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря такому подходу, мы можем работать с RNN моделью так же, как работали со сверточными моделями. Подавая на вход такую подпоследовательность + результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разобьем на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(y) * 0.8)\n",
    "\n",
    "x_train = x[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "x_test = x[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"x shape:\", x_train.shape)\n",
    "print(\"y shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "print(\"x shape:\", x_test.shape)\n",
    "print(\"y shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AirTrafficPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons \n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"x: \",x.shape) # 108 x 8 x 1 : [batch_size, seq_len, input_size] \n",
    "        out, h = self.rnn(x) \n",
    "        #print(\"out: \", out.shape) # 108 x 8 x 4 : [batch_size, seq_len, hidden_size] Useless!\n",
    "        #print(\"h : \", h.shape) # 1 x 108 x 4 [ num_layers, batch_size, hidden_size]\n",
    "        y = self.fc(h)\n",
    "        #print(\"y\",y.shape) # 1 x 108 x 1\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение\n",
    "\n",
    "Благодаря подготовке данных процесс обучения не будет отличаться от того что мы использовали на прошедших занятиях.\n",
    "\n",
    "В силу того, что датасет маленький, все данные поместились в один batch, итерирования по batch-ам в явном виде здесь не происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_train(model, num_epochs=2000, learning_rate=0.01):\n",
    "  \n",
    "  criterion = torch.nn.MSELoss() # mean-squared error for regression\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Train the model\n",
    "  for epoch in range(num_epochs):\n",
    "      y_pred, h = model(x_train) # we don't use h there, but we can!\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      # obtain the loss\n",
    "      loss = criterion(y_pred[0], y_train) # for shape compatibility\n",
    "      loss.backward()\n",
    "      \n",
    "      optimizer.step()\n",
    "      if epoch % 100 == 0:\n",
    "          print(f\"Epoch: {epoch},\".ljust(15), \"loss: %1.5f\" % (loss.item()))\n",
    "\n",
    "print(\"Simple RNN training process with MSE loss:\")\n",
    "input_size = 1\n",
    "hidden_size = 4 \n",
    "rnn = AirTrafficPredictor(input_size, hidden_size)\n",
    "time_series_train(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_plot(train_predict):\n",
    "  data_predict = train_predict.data\n",
    "  y_data_plot = y.data\n",
    "\n",
    "  # Denormalize\n",
    "  data_predict = data_predict[0] * (td_max - td_min) + td_min\n",
    "  y_data_plot = y_data_plot * (td_max - td_min) + td_min \n",
    "\n",
    "  # Ploitting\n",
    "  plt.figure(figsize=(12, 4))\n",
    "  plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "  # shifting the curve as first y-value not correspond first value overall\n",
    "  plt.plot(seq_length + np.arange(y_data_plot.shape[0]), y_data_plot)\n",
    "  plt.plot(seq_length + np.arange(y_data_plot.shape[0]), data_predict)\n",
    "  \n",
    "  plt.title(\"Number of passengers per month\")\n",
    "  plt.ylabel(\"#passengers\")\n",
    "  plt.xlabel(\"Month\")\n",
    "  plt.xticks(labels_to_display, dataset['Month'][labels_to_display])\n",
    "  \n",
    "  plt.legend(['Train/Test separation', 'Real', 'Predicted'])\n",
    "  plt.grid(axis='x')\n",
    "  plt.show()\n",
    "\n",
    "rnn.eval()\n",
    "train_predict, h = rnn(x)\n",
    "time_series_plot(train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что модель в принципе справляется с задачей. Но посмотрим, как далее справятся более мощные архитектуры, и уже позднее напишем окончательные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример посимвольной генерации текста\n",
    "\n",
    "[Github RNN-walkthrough](https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb)\n",
    "\n",
    "Одним из основных направлений использования рекуррентных сетей является работа с текстами:\n",
    "- генерация (Language modeling)  \n",
    "и \n",
    "- перевод (Machine Translation)\n",
    "\n",
    "Давайте посмотрим, как решаются такого рода задачи.\n",
    "\n",
    "Начнем с относительно простой - посимвольной генерации текста.\n",
    "\n",
    "**Постановка задачи:**\n",
    "\n",
    "предсказать следующий символ в последовательности.\n",
    "\n",
    "- исходный текст:  \n",
    "'hey how are you'\n",
    "\n",
    "- искаженный текст:  \n",
    "'hey how are yo'\n",
    "\n",
    "- Верное предсказание:\n",
    "'u'\n",
    "\n",
    "\n",
    "Теоретически эту технику можно использовать для генерации подсказок при наборе текстов, исправления ошибок или восстановления частично утраченного текста.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/character_by_character_generation_example.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных\n",
    "\n",
    "1. Зафиксировать словарь\n",
    "2. Разбить данные\n",
    "3. Выполнить кодирование символов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "text = ['hey how are you','good i am fine','have a nice day']\n",
    "\n",
    "# Join all the sentences together and extract the unique characters \n",
    "# from the combined sentences\n",
    "chars = set(''.join(text))\n",
    "\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}\n",
    "\n",
    "print(\"Dictionary for mapping character to the integer:\")\n",
    "pprint.pprint(char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо ASCII символа, каждой букве мы сопоставили номер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выравнивание данных (Padding)\n",
    "\n",
    "RNN допускают работу с данными переменной длины. Но чтобы поместить предложения в batch надо их выровнять.\n",
    "\n",
    "\n",
    "Обычно размер батча делают равным самому длинному предложению, а остальные просто дополняют пробелами до этого размера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sent) for sent in text]\n",
    "maxlen = max(lengths)\n",
    "print(f\"The longest string has {maxlen} characters.\\n\")\n",
    "\n",
    "print(f\"Initial texts:\\n{text}\")\n",
    "# A simple loop that loops through the list of sentences and adds\n",
    "# a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "for i in range(len(text)):\n",
    "    while len(text[i])<maxlen:\n",
    "        text[i] += ' '\n",
    "\n",
    "print(f'Resulting texts:\\n{text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных\n",
    "\n",
    "\n",
    "\n",
    "В качестве входа будем использовать предложение без последнего символа:\n",
    "\n",
    "**'hey how are yo'**\n",
    "\n",
    ", а в качестве результата - предложение, в котором он сгенерирован.\n",
    "\n",
    "**'ey how are you'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "    \n",
    "    # Remove firsts character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "    \n",
    "    print(\"Input sequence:\".ljust(18), f\"'{input_seq[i]}'\")\n",
    "    print(\"Target sequence:\".ljust(18), f\"'{target_seq[i]}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодирование\n",
    "\n",
    "Теперь символы надо перевести в числа. Для этого мы уже построили словарь.\n",
    "\n",
    "P.S. Запускать блок только один раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "    print(\"Encodded input sequence:\".ljust(25), input_seq[i])\n",
    "    print(\"Encodded target sequence:\".ljust(25), target_seq[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding\n",
    "\n",
    "Теперь из чисел надо сделать вектора. \n",
    "\n",
    "\n",
    "Почему бы не оставить числа?\n",
    "В прошлом примере модель хорошо с ними работала.\n",
    "\n",
    "В прошлом примере использовался MSE, и на выходе было число.\n",
    "\n",
    "Если бы мы определили отношение порядка над номерами букв, то что-то подобное можно было бы сделать.\n",
    "\n",
    "Однако сейчас мы предсказываем класс буквы.\n",
    "Поэтому на входе и на выходе должен быть вектор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/one_hot_encoding_softmax.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(text)\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    \n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features\n",
    "\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
    "print(\"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(input_seq.shape))\n",
    "print(input_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый символ закодировали вектором.\n",
    "Не слишком экономно, зато удобно умножать на матрицу весов.\n",
    "\n",
    "P.S. Запускать только один раз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/language_modeling.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "import torch\n",
    "\n",
    "input_seq = torch.Tensor(input_seq)\n",
    "target_seq = torch.Tensor(target_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class NextCharacterGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size=hidden_dim, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden_0 = torch.zeros(1, batch_size, self.rnn.hidden_size) # 1 correspond to number of layers\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden_0)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # Need Only if n_layers > 1\n",
    "        out = out.contiguous().view(-1, self.rnn.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = NextCharacterGenerator(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
    "\n",
    "# Define hyperparameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training Run\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}/{num_epochs}'.ljust(20), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "    \n",
    "    out, hidden = model(character)\n",
    "    #print(out.shape)\n",
    "    #print(out)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden\n",
    "\n",
    "def sample(model, out_len, start='hey'):\n",
    "    model.eval() # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for _ in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)\n",
    "\n",
    "sample(model, 15, 'good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблемы RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретически, можно было бы сразу пропустить все данные через сеть и затем вычислить градиент, однако возникнут следующие проблемы:\n",
    "\n",
    " - Большие последовательности не поместятся в памяти\n",
    " - Поскольку цепочка будет очень длинной, то возникнет исчезновение/взрыв градиента\n",
    " - По мере прохождения сигнала по цепи контекст затирается\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исчезающий/взрывающийся градиент (Vanishing/exploding gradient) - явления исчезающего и взрывающегося градиента часто встречаются в контексте RNN. И при большой длине последовательности это становится критичным. Причина в том, что зависимость величины градиента от числа слоёв экспоненциальная, поскольку веса умножаются многократно.\n",
    "\n",
    "$dL ∝ (W)^N$.\n",
    "\n",
    "$W > 1$ => взрыв\n",
    "\n",
    "$W < 1$ => затухание\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/L08/out/498_FA2019_lecture12-086.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из путей решения проблемы: градиентное отсечение (Gradient clipping) - метод, который ограничивает максимально допустимое значение градиента, позволяя избежать градиентного взрыва."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычная RNN имело множество проблем, в том числе, в нем очень быстро затухала информация о предыдущих словах в предложении. Помимо этого, были проблемы с затуханием/взрывом самого градиента. \n",
    "\n",
    "Эти проблемы были частично решены в LSTM, предложенной в [Hochreiter & Schmidhuber (1997)](http://www.bioinf.jku.at/publications/older/2604.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обычной RNN в ячейке был только один путь передачи информации. На каждом шаге мы сливали информацию, накопленную с предыдущих шагов, с текущей:\n",
    "\n",
    "\n",
    "<img src = \"https://edunet.kea.su/repo/EduNet-content/L08/out/simple_rnn_h_state.png\" width=\"700px\">\n",
    "\n",
    "\n",
    "При этом информация о предыдущих токенах очень быстро затухает и теряется общая информация о предложении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура ячейки LSTM намного сложнее. Здесь есть целых 4 линейных слоя, каждый из которых выполняет разные задачи.\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L08/out/lstm_chain.png\" width=\"700px\">\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L08/out/lstm_chain_notation.png\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главное нововведение - в LSTM же добавлен путь $c$, который по задумке должен этот общий контекст сохранять. \n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L08/out/lstm_c_state_highway.png\" width=\"300px\">\n",
    "\n",
    "Другими словами, путь $c$ (иногда называется highway, магистраль)  помогает нейросети сохранять важную информацию, встретившуюся в какой-то момент в предложении, все время, пока эта информация требуются. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMCell\n",
    "\n",
    "[pytorch LSTMCELL](https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
    "\n",
    "Интерфейс отличается от RNNCell количеством входов и выходов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lstm_cell = torch.nn.LSTMCell(input_size=3, hidden_size=4)\n",
    "input = torch.randn(1, 3) # batch, input_size\n",
    "h_0 = torch.randn(1, 4)\n",
    "c_0 = torch.randn(1, 4)\n",
    "h, c = lstm_cell(input, (h_0, c_0)) # second arg is tuple\n",
    "print(\"Shape of h:\", h.shape) # batch, hidden_size\n",
    "print(\"Shape of c:\", c.shape) # batch, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM in Pytorch\n",
    "\n",
    "Отличие от RNN состоит в том, что кроме $h$ возвращается еще и $c$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "lstm = nn.LSTM(input_size=4, hidden_size=5)\n",
    "input = torch.randn(3, 2, 4) # seq_len, batch, input_size\n",
    "out, (h, c) = lstm(input) # h and c returned in tuple\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h\".ljust(15), h.shape) # batch, hidden_size\n",
    "print(\"Shape of c\".ljust(15), c.shape) # batch, hidden_size\n",
    "print(\"Output shape:\".ljust(15), out.shape) # seq_len, batch, hidden_size : h for each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример использования на задаче с временным рядом\n",
    "\n",
    "Чтобы убедиться в работоспособности конструкции, заменим RNN блок на LSTM в задаче предсказания временного ряда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://edunet.kea.su/repo/EduNet-web_dependencies/L08/airline-passengers.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min - Max normalization\n",
    "training_data = dataset.iloc[:, 1:2].values\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "print('Initial statistics:')\n",
    "print('Minimum value:', repr(td_min).rjust(5))\n",
    "print('Maximum value:', repr(td_max).rjust(5))\n",
    "\n",
    "training_data = (training_data - td_min) / (td_max - td_min)\n",
    "print('\\nResulting statistics:')\n",
    "print('Minimum value:', repr(training_data.min()).rjust(5))\n",
    "print('Maximum value:', repr(training_data.max()).rjust(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create data \"ensemble\"\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "        _x = data[i:(i + seq_length)] # picking several sequential observations\n",
    "        _y = data[i + seq_length] # picking the subsequent observation\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return torch.Tensor(np.array(x)), torch.Tensor(np.array(y))\n",
    "    \n",
    "# set length of the ensemble; accuracy of the predictions and \n",
    "# speed perfomance almost always depend on it size\n",
    "seq_length = 8 # compare 2 and 32\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "\n",
    "train_size = int(len(y) * 0.8)\n",
    "\n",
    "x_train = x[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "x_test = x[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"x shape:\", x_train.shape)\n",
    "print(\"y shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "print(\"x shape:\", x_test.shape)\n",
    "print(\"y shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_plot(train_predict):\n",
    "  data_predict = train_predict.data\n",
    "  y_data_plot = y.data\n",
    "\n",
    "  # Denormalize\n",
    "  data_predict = data_predict[0] * (td_max - td_min) + td_min\n",
    "  y_data_plot = y_data_plot * (td_max - td_min) + td_min \n",
    "\n",
    "  # Ploitting\n",
    "  plt.figure(figsize=(12, 4))\n",
    "  plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "  # shifting the curve as first y-value not correspond first value overall\n",
    "  plt.plot(seq_length + np.arange(y_data_plot.shape[0]), y_data_plot)\n",
    "  plt.plot(seq_length + np.arange(y_data_plot.shape[0]), data_predict)\n",
    "  \n",
    "  plt.title(\"Number of passengers per month\")\n",
    "  plt.ylabel(\"#passengers\")\n",
    "  plt.xlabel(\"Month\")\n",
    "  plt.xticks(labels_to_display, dataset['Month'][labels_to_display])\n",
    "  \n",
    "  plt.legend(['Train/Test separation', 'Real', 'Predicted'])\n",
    "  plt.grid(axis='x')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new LSTM based model\n",
    "\n",
    "class LSTMAirTrafficPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons \n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h, c) = self.lstm(x) \n",
    "        y = self.fc(h)\n",
    "        return y\n",
    "\n",
    "lstm =  LSTMAirTrafficPredictor(input_size=1, hidden_size=4)\n",
    "input = torch.randn((108, 8, 1)) \n",
    "out = lstm(input)\n",
    "\n",
    "print(\"LSTM model we use consider first input dimension as a batch dimension, output dimension logic has not changed:\")\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Output shape:\".ljust(15), out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.train()\n",
    "\n",
    "print(\"LSTM training process with MSE loss:\")\n",
    "\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = torch.nn.MSELoss() # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    " # Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = lstm(x_train) \n",
    "    optimizer.zero_grad()\n",
    "    #print(outputs.shape)\n",
    "    loss = criterion(y_pred, y_train.unsqueeze(0))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch},\".ljust(15), \"loss: %1.5f\" % (loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lstm.eval()\n",
    "train_predict = lstm(x)\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "time_series_plot(train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "---\n",
    "1. Использование LSTM слоев при прогнозировании нестационарных временных рядов - отличное решение, т.к. нейронка способна самостоятельно выделить динамики изменениях составляющих временного ряда. Правда, в более сложных случаях (трейдинге, например, или чтении и расшифровки волн мозга) приходится прибегать к feature engineering\n",
    "2. Сложность нейронной сети должна быть адекватна сложности подаваемых в нее данных. С ростом ансамбля и числа нейронов увеличивается заучивание тренировочной выборки и теряется способность к обобщению\n",
    "3. Предварительный анализ цикличности в данных (если она есть) помогает понять оптимальный размер ансамбля (тут видно, что цикл, в среднем, составляет 8 интервалов)\n",
    "4. Также результат может зависеть от типа скалирования, который Вы применяете. Нужно знать принципы работы скаллеров и не стесняться экспериментировать с ними. См. статьи: [Data Preprocessing with Scikit-Learn: Standardization and Scaling](https://towardsdatascience.com/data-preprocessing-with-scikit-learn-standardization-and-scaling-cfb695280412) и [Gradient Descent, the Learning Rate, and the importance of Feature Scaling](https://towardsdatascience.com/gradient-descent-the-learning-rate-and-the-importance-of-feature-scaling-6c0b416596e1)\n",
    "5. При всей выгодности применения нейронных сетей, необходимо быть осторожным с автокорреляцией (см. статью [Avoiding the pitfalls](https://towardsdatascience.com/how-not-to-use-machine-learning-for-time-series-forecasting-avoiding-the-pitfalls-19f9d7adf424))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модификации LSTM \n",
    "\n",
    "Было предложено множество модификаций структуры LSTM. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peephole connections\n",
    "Например, введение возможности всем gates напрямую подсматривать в вектор контекста $C$. Что, безусловно, логично - сложно решать, что делать с вектором $C$ (что из него стирать, что в него добавлять, что из него брать), если видишь его только опосредованно. \n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L08/out/lstm_peepholes_connections.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение forget и input gates \n",
    "\n",
    "Также, кажется, что правильно требовать от нейросети принимать решение о записи в/стирании из вектора $C$ одновременно. Если что-то стираем - надо что-то записать. И наоборот. \n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L08/out/lstm_join_input_and_forget_gate.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU (Gated reccurent unit)\n",
    "\n",
    "Самая известная модификация LSTM - GRU. Она более компактна за счет сильных упрощений в сравнении со стандартной LSTM.\n",
    "\n",
    "Главные изменения - объединены forget и input gates, слиты $h_t$ и $C_t$, которые в обычной LSTM только участвовали в формировании друг друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/gru_basic_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = torch.nn.GRU(input_size=4, hidden_size=3)\n",
    "input = torch.randn(2, 1, 4) #seq_len, batch, input_size\n",
    "h0 = torch.randn(1, 1, 3)\n",
    "output, h = gru(input, h0)\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h:\".ljust(15), h.shape) # last h\n",
    "print(\"Output shape:\".ljust(15), output.shape) # seq_len = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практический опыт исследователей - иногда лучше работает GRU, иногда &mdash; LSTM. Точного рецепта успеха сказать нельзя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем решить задачу **sequence-to-sequence**: преобразование последовательности длины $N$ в последовательность длины $T$. $T$ может быть не равно $N$.\n",
    "\n",
    "Примеры **sequence-to-sequence** задач:\n",
    "*   машинный перевод,\n",
    "*   генерация ответа на вопрос,\n",
    "*   генерация описания картинки или видео.\n",
    "\n",
    "Для решения таких задач  можно использовать две **RNN**: **кодировщик** и **декодировщик**. \n",
    "* Задача **кодировщика**: обобщить информацию о **входной последовательности** $(x_1,..., x_N)$, сформировав **вектор контекста** $C$ фиксированного размера.\n",
    "* Задача **декодировщик**: используя информацию из $C$, сформировать **выходную последовательность** $(y_1, ..., y_T)$.\n",
    "\n",
    "В качестве вектора $C$ можно использовать последнее **скрытое состояние** кодировщика $h_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/seq_to_seq_with_rnn.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном подходе мы используем один **вектор контекста** фиксированной длины $c$, в который собираем информацию со всей **входной последовательности** $(x_1,...,x_N)$.\n",
    "\n",
    "**Входная последовательность** может содержать как единицы, так и тысячи элементов. В задаче машинного перевода **входной последовательностью** может быть:\n",
    "* короткая фраза,\n",
    "* абзац “Войны и мира”.\n",
    "\n",
    "Контекст важен. Для генерации глагола в правильной форме, нужно понимать к какому существительному он относится, а для качественного перевода конца абзаца необходимо понимать, о чем шла речь в его начале. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/seq_to_seq_with_rnn.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом возникают проблемы:\n",
    "- **Вектор контекста** $c$ фиксированной длины не может вместить любое количество информации, поэтому для длинных последовательностей качество будет ухудшаться. \n",
    "- На каждой итерации декодировщика **скрытое состояние** $s_t$ должно сохранять информацию о том, какие элементы **выходной последовательности** уже были сгенерированы. Если $s_t$ не способно вместить эту информацию модель может зациклиться или потерять часть **выходной последовательности**.\n",
    "\n",
    "**Вектор контекста** $c$ и **скрытые состояния** декодировщика $s_t$ являются “бутылочными горлышками” модели.\n",
    "\n",
    "Как решить проблему “бутылочного горлышка”?\n",
    "* формировать свой контекст $c_t$ для каждого элемента **выходной последовательности** $y_t$,  \n",
    "* использовать для формирования контекста $c_t$ все **скрытые состояния** кодировщика $h_i$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-Sequence with RNNs and Attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для формирования **векторов контекста** $(c_1, ..., c_T)$ возьмем линейную комбинацию **скрытых состояний** кодировщика $h_i$ с весами $a_{ti}$:\n",
    "<center>$ c_t=\\sum_{i=1}^{N}a_{ti}h_i$.</center>\n",
    "\n",
    "Веса $a_{ti}$ указывают, какие **скрытые состояния** кодировщика $h_i$ важны для формирования элемента **выходной последовательности** $y_t$.  Они “показывают” декодировщику куда “смотреть” при генерации данного элемента. Такой механизм в нейросетях получил название **attention** (внимание).\n",
    "\n",
    "Веса $a_{ti}$ предсказывает сама модель. Для удобства веса подбираются таким образом, чтобы их сумма для каждого **вектора контекста** $c_t$ была равна 1 (нормализация):\n",
    "<center>$ \\sum_{i=1}^{N}a_{ti} = 1$,</center>\n",
    "\n",
    "<center>$  0\\leqslant a_{ti} \\leqslant 1$.</center>\n",
    "\n",
    "Для этого на выходе предсказывающего веса слоя ставят **SoftMax**.\n",
    "\n",
    "Чтобы **вектор контекста** $c_t$ содержал информацию о уже сгенеренных элементах **выходной последовательности**, значение веса до нормализации  $e_{ti}$ зависит не только от скрытого состояния кодировщика $h_i$, но и от предыдущего скрытого состояния декодировщика $s_{t-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/seq_to_seq_with_rnn_and_attention_mechanism_step_1.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/seq_to_seq_with_rnn_and_attention_mechanism_step_2.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/seq_to_seq_with_rnn_and_attention_mechanism_step_3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Stanford University CS231n: Recurrent Neural Networks](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как такой подход  работает на примере перевода с английского на французский \n",
    "\n",
    "Как мы знаем, на каждом шаге генерируется набор весов, которые отвечают за фокусировку на том или ином месте входной последовательности. Как мы видим, английское предложение имеет иной порядок слов относительно французского. Например, в английском варианте словосочетание **European Economic Area**, в то время как во французском **zone économique européenne**. \n",
    "\n",
    "В английском прилагательные идут перед существительным, в то время как во французском языке наоборот. \n",
    "\n",
    "Таким образом, благодаря гибкости модели, мы можем обрабатывать и учитывать разный порядок слов в разных языках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/visualize_attention_weights.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Механизм внимания не обязательно должен принимать на вход последовательность. \n",
    "\n",
    "* Мы можем применять его, в том числе для генерации подписей для картинок. Входом в данном случае будет являться матрица признаков, которая была получена при применении сверточной сети к картинке. \n",
    "\n",
    "* Далее по этой матрице мы считаем веса внимания и делаем аналогично первому примеру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим шагом будет также заметить, что для достаточно длинного предложения наша модель может забыть и то, что она генерирует. Потому мы можем сделать два attention - один на представление исходного предложения, а второе - на представление того, что уже сгенерировано (что еще не сгенерировано - заменяем нулями)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проблема attention\n",
    "\n",
    "Очевидно, у этого подхода есть свои минусы. \n",
    "\n",
    "Самый важный из них - ваша модель должна уметь предсказывать веса, с которыми складываются слова из предложения при формировании нового контекстного вектора $c$. И обычные подходы принуждают нас фиксировать размер этого вектора весов. \n",
    "\n",
    "За счет этого у нас возникает ограничение, от которого мы избавлялись - модель не может принимать (и, если используем attention на то, что сгенерировано, генерировать) предложения больше определенного размера. С другой стороны, ничто не мешает поставить этот максимальный размер достаточно большим, чтобы для бОльшей части предложений это работало. \n",
    "\n",
    "Почему это не сильный проигрыш в сравнении с LSTM - так оно все равно было ограничено в длине предложения, просто неявно, что даже хуже - лучше иметь модель, которая на длине предложения 45 падает, а не генерирует лабуду. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Captioning with RNNs and Attention\n",
    "\n",
    "Модели, основанные на внимании (attention) намного более продвинутые, нежели обычные нейросети. Они могут концентрироваться на отдельных частях данных, что позволяет избежать зашумления представлений.\n",
    "\n",
    "Идея состоит в том, что на каждом этапе генерации описания, нейронная сеть в разной степени обращает внимание на те или иные фрагменты изображения, соответствующие следующему слову в описании.\n",
    "\n",
    "После обучения модели можно увидеть, что она как бы переносит своё внимание по изображению для каждого генерируемого слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/image_captioning_with_rnn_and_attention_example_step_1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/image_captioning_with_rnn_and_attention_example_step_2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/image_captioning_with_rnn_and_attention_example_step_3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/image_captioning_with_rnn_and_attention_example_step_4.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Stanford University CS231n: lectures](http://cs231n.stanford.edu/slides/2017/)\n",
    "\n",
    "Посмотрим, что “привлекает внимание” нейронной сети при написании текстового описания картинки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/visulize_attention_map.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейронные сети, использующие механизм внимания (attention) активно применяются для решения задачи [Visual Question Answering](https://paperswithcode.com/paper/vqa-visual-question-answering). В данной задаче нейросеть должна научиться давать развернутые ответы на вопросы по изображению. Модель должна не только решать задачу классификации, но и распознавать признаки (цвет, форма, размер, количество и т.д.) предметов на изображении, различать в какой части изображения находится предмет и его положение относительно других предметов. Решение этой задачи может помочь людям с проблемами со зрением лучше ориентироваться в пространстве. \n",
    "\n",
    "[ссылка на исследование](https://www.reg.ru/blog/nejroset-opisyvaet-mir-nezryachim-lyudyam/) \n",
    "и еще [одна ссылка](https://www.reg.ru/blog/uchim-nejroseti-rassuzhdat-o-tom-chto-oni-vidyat/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/visulize_attention_map_examples.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key, query, value \n",
    "\n",
    "Мы можем формализовать процедуру attention через введение концепций **key**, **query** и **value**. \n",
    "\n",
    "К примеру, у нас есть картинка. На этой картинки у нас есть области, которые можно описать одним словом - **key**. Например - фонарь/девушка/... \n",
    "\n",
    "Сами эти области - это **value**, которые введенным **key** соответствуют. \n",
    "\n",
    "Далее нам приходит **query** - например, running. Мы можем посчитать похожесть каждого из ключей, которые у нас есть на query. \n",
    "\n",
    "И далее выдать информацию только по **value**, похожим на наш **query**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/key_query_value_example.jpg\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524\">NLP — BERT & Transformer</a></p> </em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Послезная статья про NLP](https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути, мы описали то, как будем делать при помощи нейронок питоновский словарь. С той разницей, что питоновский словарь может выдавать значения только для тех ключей, что в нем есть, а наш словарь выдает ответ для любого ключа-запроса, основываясь на его похожести на ключи словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key, Query, Value на примере текста \n",
    "\n",
    "Разобьем наше предложение на токены (в данном случае - просто слова). Получим представление каждого токена"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/key_query_value_sentence.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524\">NLP — BERT & Transformer</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое слово будет являться одновременно и key, и value. \n",
    "\n",
    "Теперь можно подать любой query, например - вода, и в случае, если у нас эмбединги слов хорошие, что нам \"подсветятся\" слова, связанные с водой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Layer\n",
    "\n",
    "Эту идею реализует attention layer. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что мы, таким образом, получили? Фактически, мы получили дифференцируемый аналог словаря в Python. Только этот словарь еще умеет делать неточный поиск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть некий изначальный набор $X$ - слова в нашем предложении. \n",
    "\n",
    "Мы можем их преобразовать как-то, чтобы получить более удобные для дальнейшей цели $K$ - предполагается, что они лучше помогают сравнивать между собой слова. \n",
    "В простейшем случае некое линейное преобразование $K = XW_K$\n",
    "\n",
    "Далее у нас есть значения, $V$, которые тоже получаются из $X$ путем какого-то преобразования, которое делает их более применимыми для работы модели (важные признаки и т.д.), например $V = XW_Q$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее к нам приходят запросы $Q$, которые находятся в том же пространстве, что и ключи. Фактически - наша нейросеть пытается вытащить из данных интересующую ее информацию. К примеру - ей нужно найти всех животных и все растения - тогда $Q = \\text{\\{“животные”, “растения”\\}}$\n",
    "\n",
    "Мы сравниваем эти запросы с ключами - считаем просто попарные косинусные расстояние между каждым ключом $K_i$ и запросом $Q_j$. Получаем похожесть каждого ключа на запрос, нормируем ее на корень из размерности представления нашего ключа. \n",
    "\n",
    "$E = \\dfrac {QK^T} {\\sqrt{D}} $\n",
    "\n",
    "Получили матрицу похожестей $E$, где $E_{ij}$ - похожесть ключа $K_i$ на запрос $Q_j$\n",
    "\n",
    "Далее мы применяем к похожестям $E$ softmax, беря его по каждому ключу отдельно (по каждому столбцу матрицы $E$). Теперь у нас похожести каждого запроса складываются в единицу. \n",
    "\n",
    "$A = softmax(E,\\, dim=1)$\n",
    "\n",
    "Получили для каждого запроса его \"разложение\" в виде ключей. \n",
    "\n",
    "Далее, чтобы получить значения, соответствующие каждому запросу, складываем значения с весами соответствующих ключей\n",
    "\n",
    "$\\displaystyle Y_j = \\sum_iA_i V_i$\n",
    "\n",
    "$Y = AV$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/attention_layer.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax normalization \n",
    "\n",
    "Вы могли заметить, что в формуле для $E$ мы делим на корень из размерности представления ключа. Зачем это? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сгенерируем вектор из многомерного нормального распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "a = np.random.normal(0, 100, size=(10000))\n",
    "\n",
    "plt.title(\"Normal distribution, std = 100\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xlabel(\"Sample value\")\n",
    "\n",
    "plt.hist(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И посмотрим, что будет с распределением значений этого вектора, если к нему применить softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax \n",
    "\n",
    "plt.title(\"Softmax on N(0, 100)\")\n",
    "plt.ylabel(\"Softmax value\")\n",
    "plt.xlabel(\"Sample index\")\n",
    "\n",
    "plt.plot(softmax(a))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти все значения 0 и одно (наибольшее), стало 1. \n",
    "Мы получили так называемое вырожденное распределение - у него вся плотность сосредоточена в одной точке. \n",
    "\n",
    "И получили на абсолютно случайных данных. \n",
    "\n",
    "Это приведет к затуханию градиента - мы будем распространять ошибку только для 1 значения из 10000. Учиться сеть будет плохо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но этого можно избежать - давайте просто стандартизируем наши данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.random.normal(0, 100, size=(10000))\n",
    "\n",
    "unit_std = std / 100\n",
    "\n",
    "plt.title(\"Normal distribution, std = 100\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xlabel(\"Sample value\")\n",
    "plt.hist(std)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Normal distribution, std = 1\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xlabel(\"Sample value\")\n",
    "plt.hist(unit_std)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути, в распределении ничего не поменялось - только масштаб. Но теперь softmax работает нормально "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Softmax on N(0, 1)\")\n",
    "plt.ylabel(\"Softmax value\")\n",
    "plt.xlabel(\"Sample index\")\n",
    "\n",
    "plt.plot(softmax(unit_std))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остается только понять, а как нормировать наши данные в нашем слое? Считать налету, наверное, не лучшая идея. \n",
    "\n",
    "Наш слой делает скалярное произведение между двумя векторами, предположим, нормально распределенными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(dimensionality, experiments=int(10e4)):\n",
    "    c = []\n",
    "    for i in range(experiments):\n",
    "          a = torch.normal(0, 1, size=(int(dimensionality),))\n",
    "          b = torch.normal(0, 1, size=(int(dimensionality),))\n",
    "          c.append(torch.dot(a, b))\n",
    "        \n",
    "    c = torch.Tensor(c)\n",
    "    return float(c.mean()), float(c.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "means, stds = {}, {}\n",
    "dims = torch.linspace(0, 100, 20)\n",
    "\n",
    "for dim in dims:\n",
    "\t\tdim = float(dim)\n",
    "\t\tt_mean, t_std = statistics(dim)\n",
    "\t\tmeans[dim] = t_mean\n",
    "\t\tstds[dim] = t_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(means.keys())\n",
    "y = list(means.values())\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.axhline(y=0, c='r', linestyle='--')\n",
    "plt.legend(['Mean value', 'Mean = 0'])\n",
    "plt.title(\"Mean value of dot products\")\n",
    "plt.ylabel(\"Mean value\")\n",
    "plt.xlabel(\"Vector dimensionality\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что среднее не сильно отличается от 0 (можно показать, что в среднем оно равно 0 для произведения нормально распределенных величин). \n",
    "\n",
    "А вот стандартное отклонение растет. И, можно предположить, что растет оно как корень из размерности вектора. Так и есть. Потому и появляется именно такой нормировочный множитель в attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(stds.keys())\n",
    "y = list(stds.values())\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"Std values and square distance\")\n",
    "plt.xlabel(\"Vector dimensionality\")\n",
    "\n",
    "x = np.linspace(0, 100, 10000)\n",
    "plt.plot(x, x**0.5, color='r')\n",
    "plt.legend([\"sqrt(x)\", \"empirical std\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keq, Query, Value на примере текста. Второй заход\n",
    "\n",
    "Хорошо, у нас есть предложение, мы его разбили на токены, допустим, мы хорошо умеем кодировать эти токены. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/key_query_value_sentence.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524\">NLP — BERT & Transformer</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но каждый токен закодирован на основе самого себя, и только, например, слово bank встречается в тексте два раза, и будет закодировано одинаково, хотя несет разные значения (берег и, собственно, банк). \n",
    "\n",
    "Как нейросети их отличать? Ну, если мы попытаемся на основе только одного токена что-то сделать - никак. \n",
    "\n",
    "А как улучшить кодирование каждого токена, чтобы два \"банка\" отличались? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем следующее - каждый токен подадим в нейросеть **и в качестве query**. \n",
    "\n",
    "И будем агрегировать полученную информацию, получая токен, который будет содержать более конкретную информацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/key_query_value_sentence_example.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524\">NLP — BERT & Transformer</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, bank, который банк, будет содержать информацию о том, что он не просто bank, а \"Bank of America\", который нужно найти (find).\n",
    "\n",
    "Такой подход - когда key, query и value формируются на основе одного и того же входа нейросети называется self-attention\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention Layer\n",
    "\n",
    "Сделаем это все в виде слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/self_attention_layer.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что изменилось? \n",
    "\n",
    "Теперь $X$ участвует и в производстве $K$, и в производстве $V$, и в производстве $Q$. Потому и self-attention - предложение состоящее из слов $X_i$, ищет само себя в нашем дифференцируемом словаре. Почему это не приводит к тому, что мы просто получим вектор $V$?\n",
    "Потому что значения $X_i$ модифицируются и $K \\neq Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один пример проблемы с текстом, который обычные методы решали плохо\n",
    "\n",
    "Многие из нас знают Второй Закон Робототехники\n",
    "\n",
    "**Second Law of Robotics**\n",
    "\n",
    "\n",
    "A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\n",
    "\n",
    "Представим, что машина хочет понять, что здесь написано. И ей нужно понять, что имеется ввиду под it. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом она формирует на основе каждого слова key и value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/self_attention_example_folders_step_1.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jalammar.github.io/illustrated-gpt2/\">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем она смотрит, какие ключи похожи на Query, полученный из it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/self_attention_example_folders_step_2.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jalammar.github.io/illustrated-gpt2/\">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить, что же на самом деле значит it, машина считает взвешенную сумму values, где  веса определяются похожестью query на value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/gpt2_value_vector_sum.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jalammar.github.io/illustrated-gpt2/\">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка на оригинальную статью про GPT-2 с более подробными объяснениями как оно работает.](https://jalammar.github.io/illustrated-gpt2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге получается, что it представляет собой \"a robot\" (ну и само себя). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведена простая реализация слоя self-attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimplifiedSelfAttention(nn.Module): \n",
    "    def __init__(self, input_size, key_size=100, value_size=20):\n",
    "        super().__init__()\n",
    "        self.keyer = nn.Linear(input_size, key_size)\n",
    "        self.valuer = nn.Linear(input_size, value_size)\n",
    "        self.querier = nn.Linear(input_size, key_size)\n",
    "\n",
    "        self.norm_factor = key_size ** 0.5\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape:\".ljust(20), x.shape)\n",
    "\n",
    "        query = self.querier(x)\n",
    "        key = self.keyer(x)\n",
    "        value = self.valuer(x)\n",
    "\n",
    "        print(\"Query shape:\".ljust(20), query.shape)\n",
    "        print(\"Key shape:\".ljust(20), key.shape)\n",
    "        print(\"Value shape:\".ljust(20), value.shape)\n",
    "\n",
    "        activations = torch.mm(query, key.t()) / self.norm_factor\n",
    "        norm_activation = nn.functional.softmax(activations, dim=1)\n",
    "        result = torch.mm(norm_activation, value)\n",
    "\n",
    "        print(\"Activations shape:\".ljust(20), activations.shape)\n",
    "        print(\"Result shape:\".ljust(20), result.shape)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 30\n",
    "data = torch.randn(10, in_size)\n",
    "\n",
    "SA = SimplifiedSelfAttention(in_size)\n",
    "result = SA(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional encoding\n",
    "\n",
    "Единственный возможный минус - наша нейросеть не учитывает порядка слов в предложении при составлении embedding. Это может нам мешать. Например, если в предложении два it, то они часто относятся к разным словам. Потому хотим уметь учитывать информацию о позиции. Для этого к $X$ при составлении $Q$ добавляется информация о позиции. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/positional_encoding.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делается это хитрым образом - мы берем и добавляем к каждому значению исходного вектора токенов некую комбинацию $sin$ и $cos$ с разными параметрами. \n",
    "\n",
    "Вектор $PE$, который мы будем добавлять к $X$ будет определяться по следующей формуле"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$PE_{pos, 2i} = \\sin \\left({\\dfrac {pos} {10000^{2i/d}}}\\right)$$\n",
    "\n",
    "$$PE_{pos, 2i+1} = \\cos \\left({\\dfrac {pos} {10000^{2i/d}}}\\right)$$\n",
    "\n",
    "$pos$ &mdash; это позиция токена\n",
    "\n",
    "$d$ &mdash; количество размерностей токена\n",
    "\n",
    "$i$ &mdash; $i$-тая размерность токена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)].detach() \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(20)\n",
    "y = pe(torch.zeros(1, 100, 20)) # sequence of shape 100, every token of sequence has shape 20  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(np.arange(100), y[0, :, 0:4].data.numpy())\n",
    "plt.legend([\"dim %d\"%p for p in [1,2,3,4]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате каждая позиция коддируется уникальным представлением. При этом представление позволяет легко находить слова на заданном расстоянии от исходного (у них будет одинаково значение сигнала по какой-то оси)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
    "plt.legend([\"dim %d\"%p for p in [4, 5, 6, 7]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это помогает трансформеру достаточно уникальным образом определять каждую позицию и понимать относительное расстояние между разными токенами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Self-Attention Layer\n",
    "\n",
    "\n",
    "Допустим,  у нас стоит проблема, что мы не должны видеть часть слов в предложении - например, при генерации текста (по текущим словам предсказать следующее). Например, хотим сгенерировать фразу \"robot must obey orders\" на основе только первого слова. \n",
    "\n",
    "Если мы скормим в нейронную сеть во время обучения сразу все предложение, которое хотим генерировать, то у нас в первых словах будет \"протекать\" информация о предыдущих."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/queries_keys_scores_before_softmax.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае мы можем просто на соответствующих местах матрицы $E$ поставить минус бесконечности - тогда в эмбедингах слов, которые не должны знать о каких-то словах, информации об этих словах не будет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/scores_before_softmax_apply_attention_mask_masked_scores_before_softmax.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате мы сможем, после softmax \"лишняя\" информация не будет использоваться при генерации ответа на query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/masked_scores_softmax_along_rows_scores.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря этому трюку, у нас получается обучать transfomer по-прежнему как простую single-pass нейросеть, а не \"скатываться\" в RNN, где у нас возникнут проблемы с градиентами и временем работы "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihead Self-Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/multihead_self_attention_layer.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на то, к каким словам предложения gave может иметь отношение. В общем случае глагол может иметь связку со многими частями предложения. Как, например, с подлежащим, так и с причастиями.\n",
    "\n",
    "В идеале, нам бы хотелось обратить внимание функции (attention) на все эти взаимосвязи. Для этого нам просто надо поставить несколько attention слоев параллельно. В идеале каждый будет учить что-нибудь свое - аналогия с конволюциями. \n",
    "\n",
    "* Чтобы осуществить задуманное, вместо одного набора query, будем использовать несколько независимых наборов. \n",
    "\n",
    "* Причем каждый набор будет считаться уникальной матрицей. \n",
    "\n",
    "* Аналогично сделаем для keys и values. Количество таких наборов внутри keys, queries, values должно быть **одинаковым**. \n",
    "\n",
    "* Обозначим это число как h - head, далее производим аналогичные манипуляции, при этом введем в параллель h таких функций attention\n",
    "* На последнем шаге мы их соединяем (конкатинируем)\n",
    "\n",
    "* При этом можно заметить, что таком подходе на каждом шаге размерность токена будет увеличиваться (если, например, в качестве и key, и value, и query мы подаем одно и тоже предсталение токена). Если хотим сохранять управлять размерностью токена, то придется получать, по меньшей, мере value путем домножения на матрицу, размерность которой по второй оси меньше - **выполнять проекцию наших токенов в пространство меньшей размерности**\n",
    "\n",
    "* В частности, можно подобрать размерность этого пространства таким образом, чтобы при конкатенации размерность полученного токена равнялась исходной. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/scaled_dor_product_attention_multihead.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention is all you need\n",
    "\n",
    "Оказывается, этот подход работает сам по себе. Не нужно добавлять никаких рекуррентных слоев - просто делаем много правильно соединенных attention layers. Полученная в результате архитектура получала название attention transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/attention_is_all_you_need.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый блок "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/attention_transformer_basic_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок устроен следующим образом: входные вектора мы запускаем в блок self-attention и используем residual connection как обходной путь вокруг self-attention, затем мы их складываем. Так как обычно используют multi head self-attention, тут нам и пригождается возможность подобрать параметры так, чтобы размерности входных и выходных токенов не отличались. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После - применяем слой нормализации, затем - слой feed forward (MLP), плюс обходной путь вокруг feed forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/mlp_transformer_block.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Складываем выход MLP-части с residual connection и выполняем нормализацию.\n",
    "\n",
    "Нормализация везде нужна для того, чтобы нейросеть нормально обучалась. \n",
    "\n",
    "Заводим ли разный MLP на каждый токен (по позиции) - конечно нет. К каждому токену применяются MLP с одними и теми же весами. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реальных моделях выходы этих слоев стекают друг с другом и получается большая трансформер-модель. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/mlp_transformer.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это пример Encoder-модели. Такова рассматриваемая далее BERT. В такой модели на выходе мы получаем некое хорошее представление исходного предложения. \n",
    "\n",
    "Но что если мы хотим сделать задачу перевода с одного языка на другой? Нужен еще Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первая стадия\n",
    "\n",
    "На первой стадии то, как работает Decoder не так сильно отличается от работы Encoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/decoder_transformer.jpg\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524\">NLP — BERT & Transformer</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тем не менее, есть один важный нюанс -  мы используем Masked Attention - наша нейросеть не должна видеть слов, которые еще не сгенерировала. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе первого этапа у нас формируются только query - наша нейросеть на основе того, что она уже сгенерировала решает, какая информация ей нужна дальше "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вторая стадия\n",
    "\n",
    "Теперь мы используем для $K$, $V$ информацию, полученную из энкодера и получаем предсказание. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/encoder_decoder_transformer.jpg\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524\">NLP — BERT & Transformer</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как перейти к самым ярким примерам использования трансформеров, давайте разберёмся, как именно трансформеры взаимодействуют с текстом. Мы же не можем загрузить буквы, слова и предложения в нейронную сеть. Нам необходимо загружать вектора. Выше по тексту (для посимвольной генерации), эту проблему мы решали следующим образом: создавали *словарь* для букв и каждой букве присваивали индекс (a=0, b=1, c=2 ...). Давайте посмотрим, можем ли мы провернуть то же самое для предложений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наивная токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим предложение: `Я люблю Natural Language Processing (NLP). А ты?`\n",
    " \n",
    "Присваивать отдельный индекс каждому предложению, кажется, совсем не оптимально. Что тогда? Мы можем разбить предложение на слова (*токенезировать предложение*) по пробелам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'Я люблю Natural Language Processing (NLP). А ты?'\n",
    "tokenized = input.split(' ')\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неплохо, но можно обратить внимание, что мы не учли пунктуацию. Кажется неразумным создавать отдельный индекс для каждой комбинации NLP и знаков препинания. Давайте проведём токенизацию с учётом знаков препинания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "  \n",
    "# initializing string\n",
    "input = 'Я люблю Natural Language Processing (NLP). А ты?'\n",
    "  \n",
    "# using findall() to get all regex matches. \n",
    "res = re.findall(r'\\w+|[^\\s\\w]+', input)\n",
    "  \n",
    "# printing result \n",
    "print(str(res)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше, но представьте себе размер словаря, если мы будем токенизировать таким образом все слова в Википедии. Такой большой объём словаря приведёт к тому, что у модели будет огромный размер эмбедингов в качестве входного и выходного слоя, что приведёт к увеличению необходимой памяти. Обычно, размер словаря трансформеров не превышает 50 000 токенов. Почему бы тогда не использовать посимвольную токенезацию, как раньше?\n",
    "\n",
    "Хотя посимвольная токенизация очень проста и значительно снижает требования к памяти, она значительно усложняет обучение модели осмысленным представлениям входных данных. Например, выучить осмысленное контекстно-независимое представление для буквы `\"с\"` гораздо сложнее, чем выучить контекстно-независимое представление для слова `\"сегодня\"`. Поэтому токенизация символов часто сопровождается потерей производительности. Чтобы получить лучшее из двух миров, трансформеры используют что-то среднее между токенизацией на уровне слов и на уровне символов, называемый токенизацией подслова (*subword tokenization*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Subword Tokenization* (Токенизация подслова)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритмы токенизации подслова основываются на принципе, что часто используемые слова не должны разбиваться на более мелкие подслова, а редкие слова должны быть разложены на значимые подслова. Например, слово \"*annoyingly*\" может считаться редким словом и может быть разложено на \"*annoying*\" и \"*ly*\". И \"*annoying*\", и \"*ly*\" как самостоятельные подслова будут встречаться чаще, и в то же время значение слова \"*annoyingly*\" сохранится за счёт составного значения \"*annoying*\" и \"*ly*\".\n",
    " \n",
    "Токенизация подслова позволяет модели иметь разумный объём словаря и при этом обучаться значимым контекстно-независимым представлениям. Кроме того, токенизация подслова позволяет модели обрабатывать слова, которые она никогда раньше не видела, путём разложения их на известные подслова.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся популярной библиотекой для токенизации от команды Hugging Face `transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer.tokenize(\"I have a new GPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предложение сначала было приведено к нижнему регистру. Мы видим, что слова [\"i\", \"have\", \"a\", \"new\"] присутствуют в словаре токенизатора, а слово \"gpu\" - нет. Следовательно, токенизатор разбивает \"gpu\" на известные подслова: [\"gp\" и \"##u\"]. \"##\" означает, что остальная часть лексемы должна быть присоединена к предыдущей без пробела (для декодирования или обратного хода токенизации)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte-Pair Encoding (BPE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодирование байт-парой (BPE) опирается на претокенизатор, который разбивает обучающие данные на слова. Примером простой претокенизации может быть разбивка по пробелам. Более продвинутая предварительная токенизация включает токенизацию на основе каких-то правил.\n",
    "\n",
    "После предварительной токинизации у нас получится набор уникальных слов и будет определена частота встречаемости каждого слова в обучающих данных. Затем BPE создаёт базовый словарь, состоящий из всех символов, которые встречаются в наборе уникальных слов, и изучает правила слияния для формирования нового символа из двух символов базового словаря. Так происходит до тех пор, пока словарный запас не достигнет желаемого размера. Обратите внимание, что желаемый объём словаря - это гиперпараметр, который необходимо определить перед обучением токенизатора.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера предположим, что после предварительной токенизации был определён следующий набор слов, включая их частоту:\n",
    "\n",
    "`(\"hug\", 10), (\"pug\", 5), (\"pun\", 12), (\"bun\", 4), (\"hugs\", 5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что базовый словарь -  `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\"]`. \n",
    "\n",
    "Разделим все слова на отдельные буквы: \n",
    "\n",
    "`(\"h\" \"u\" \"g\", 10), (\"p\" \"u\" \"g\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"u\" \"g\" \"s\", 5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPE подсчитывает частоту каждой возможной пары символов и выбирает ту пару символов, которая встречается наиболее часто. В приведённом выше примере `\"h\"`, за которым следует `\"u\"`, встречается 10 + 5 = 15 раз (10 раз в 10 вхождениях слова `\"hug\"`, 5 раз в 5 вхождениях слова `\"hugs\"`). Однако наиболее частой парой символов является `\"u\"`, за которой следует `\"g\"`, встречающаяся 10 + 5 + 5 = 20 раз в общей сложности. Таким образом, первое правило слияния, которому обучается токенизатор, - это сгруппировать все символы `\"u\"`, за которыми следует символ `\"g\"`, вместе. Затем `\"ug\"` добавляется в словарный запас. После этого набор слов становится следующим:\n",
    "\n",
    "`(\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"ug\" \"s\", 5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем BPE определяет следующую наиболее часто встречающуюся пару символов. Это `\"u\"`, за которым следует `\"n\"`, который встречается 16 раз. `\"u\"`, `\"n\"` объединяются в `\"un\"` и добавляются в словарь. Следующая по частоте пара символов - `\"h\"`, за которой следует `\"ug\"`, встречается 15 раз. Снова пара объединяется, и `\"hug\"` может быть добавлен в словарь.\n",
    "\n",
    "На данном этапе словарный запас состоит из `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"]`, а наш набор уникальных слов представлен как\n",
    "\n",
    "`(\"hug\", 10), (\"p\" \"ug\", 5), (\"p\" \"un\", 12), (\"b\" \"un\", 4), (\"hug\" \"s\", 5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если остановить обучение BPE на этом моменте, то выученные правила слияния будут применяться к новым словам (при условии, что эти новые слова не содержат символов, которых не было в базовом словаре). \n",
    "\n",
    "Например, слово `\"bug\"` будет токенизировано как `[\"b\", \"ug\"]`, а `\"mug\"` будет токенизировано как `[\"<unk>\", \"ug\"]`, поскольку символ `\"m\"` отсутствует в базовом словаре. Как правило, отдельные буквы, такие как `\"m\"`, не заменяются символом `\"<unk>\"`, поскольку обучающие данные обычно включают хотя бы одно вхождение каждой буквы, но это может произойти для очень специальных символов, таких как эмодзи.\n",
    "\n",
    "Как упоминалось ранее, размер словаря, т.е. размер базового словаря + количество слияний, является гиперпараметром для выбора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть и множество других форм токенизации, подробнее о них можно прочитать в [Summary of the tokenizers](https://huggingface.co/docs/transformers/tokenizer_summary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры применений Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Непосредственное применение разобранной архитектуры Encoder-Decoder для перевода текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/transformer_text_translation_example.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT (Bidirectional Encoder Representations from Transformers )\n",
    "\n",
    "В случае BERT используется только Encoder часть\n",
    "\n",
    "Это нейросеть, предобученная на огромном корпусе английского текста. \n",
    "\n",
    "Перед ней ставили следующие задачи:\n",
    "\n",
    "**Задача 1**\n",
    "\n",
    "На вход дается предложение - в нем выбрано $15\\%$ токенов, из которых:  \n",
    "1. $80\\%$ замаскированы  \n",
    "2. $10\\%$ заменены случайным  \n",
    "3. $10\\%$ оставлены без изменений\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 2**\n",
    "\n",
    " На вход даются два предложения - сказать, идет ли второе непосредственно за первым в тексте, или нет (просто случайное предложение из корпуса)\n",
    "\n",
    "\n",
    "В результате на вход подается все в таком виде:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/bert.jpg\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524\">NLP — BERT & Transformer</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$CLS$ токен нужен для того, чтобы нейросети было, куда класть информацию обо всем предложении в целом. \n",
    "\n",
    "$SEP$ нужен просто для того, чтобы разделять два предложения (если мы подаем их два) и для того, чтобы отмечать окончание. Использование $SEP$ с двумя целями позволяет подавать в уже обученную нейросеть только одно предложение. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Language Model\n",
    "\n",
    "Для первой задачи используем Encoder-Decoder \n",
    "\n",
    "То есть у нас есть **Encoder**, который получает богатые представления и добавленный только на время обучения **Decoder** (не attention, просто MLP).\n",
    "\n",
    "Именно Decoder отвечает за то, чтобы предсказывать пропущенные/замененные токены. Ошибка считается только по тем $15\\%$ токенов, для которых могло произойти изменения, а не по всему предложению.\n",
    "\n",
    "Как гарантируется, что модель не заменяет имевшиеся в предложение слова на другие? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/masked_language_model.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524\">NLP — BERT & Transformer</a></p> </em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Sentence Prediction \n",
    "\n",
    "Для второй задачи - Classifier. \n",
    "\n",
    "При этом на вход ему подается только сам CLS токен \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/next_sentence_prediction.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524\">NLP — BERT & Transformer</a></p> </em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель на обеих задачах одновременно. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning с BERT \n",
    "\n",
    "Обученную таким образом модель (оставляем только encoder), можно использовать для огромного числа других задач \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/transfer_learning_with_bert.jpg\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524\">NLP — BERT & Transformer</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot learning \n",
    "\n",
    "Более того, есть BERT, тренированная на большом числе разных языков.\n",
    "\n",
    "Это позволяет, например, сравнивать предложения из разных языков, хотя мы этому даже не учились. Поиграть можно [здесь](https://colab.research.google.com/github/deepmipt/dp_tutorials/blob/master/Tutorial_2_DeepPavlov_BERT_transfer_learning.ipynb#scrollTo=S1iqGcxUINyU). Веса будут грузиться ДОЛГО"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/zero_shot_learning_bert.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Специализированные аналоги BERT\n",
    "\n",
    "Более того, можно тренировать BERT под строго определенные задачи - например, анализ текстов научных статей "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/bert_specialized_analogs.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://www.kaggle.com/code/divyadevadas/nlp-tweet-bert-roberta-eda-tensorflow-pytorch/notebook\">NLP Tweet: BERT, RoBERTa, EDA,TensorFlow , Pytorch</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT (Generative Pretrained Transformer )\n",
    "\n",
    "В случае GPT используется только Decoder часть. Но теперь во всех частях используются masked attention "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/generative_pretrained_transformer_gpt.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://www.kaggle.com/code/abhilash1910/nlp-workshop-playing-with-transformers/notebook\">NLP Workshop-Playing With Transformers</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это нейросеть обширно используется для, например, задачи генерации текста,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает она следующим образом - даем ей в качестве исходного входа какую-то затравку. \n",
    "\n",
    "Можно просто SOS (Start of sentence) токен, обозначающий начало предложения и больше не несущий никакой дополнительной информации\n",
    "\n",
    "\n",
    "Она дает какой-то выход. Подаем этот выход нейросети как вход. \n",
    "Делаем так до тех пор, пока не надоест/не достигнем максимальной длины предложения/не встретим символ окончания генерации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/gpt2_autoregression.gif\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jalammar.github.io/illustrated-gpt2/\">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как ее обучали - на самом деле, тоже unsupervised. Но теперь перед моделью ставится задача предсказывать по предыдущим словам в предложении текущее.\n",
    "\n",
    "Понятно, что такую модель можно сразу же идти и использовать для генерации, для которой она и училась \n",
    "\n",
    "Однако затем ее можно применять для многих других задач (опять же, путем transfer learning):\n",
    "\n",
    "\n",
    "1. Классификации - подаем сразу все предложение, полученное представление используем для предсказания\n",
    "\n",
    "2. Entailment (Определение логического следования) - даем изначальные данные, гипотезу, надо оценить, следует ли гипотеза из данных\n",
    "\n",
    "3. Similarity - можем оценивать похожесть предложений. Так как это мы определяем порядок предложений, то, чтобы избежать неявной зависимости от порядка пропускания предложений, будем использовать результат пропускания через нейросеть обоих возможных порядков. \n",
    "\n",
    "4. Выбор варианта ответа на вопросы - может обучить нейросеть отвечать на вопросы с множественным выбором. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/gpt_classification_entailment_similarity.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно научить нейросеть отвечать на вопросы и т.д. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строго говоря, мы можем даже текст переводить с помощью GPT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/decoder_only_transformer_translation.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jalammar.github.io/illustrated-gpt2/\">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просто подаем предложение с токеном в конце, определяющим, на какой язык переводим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По аналогичной схеме можем научить нашу сеть [делать summary текста](https://arxiv.org/abs/2109.10862)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/decoder_only_summarization.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://jalammar.github.io/illustrated-gpt2/\">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Здесь](https://6b.eleuther.ai/) можно поиграть с open-source GPT-J\n",
    "\n",
    "А [здесь](https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb#scrollTo=e-NKauYvgTNG) - поиграть, но уже в Collab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"6\">Хорошие источники \n",
    "\n",
    "[Про трансформеры](https://www.notion.so/Transformers-969f4b27c48147778c1e2dbda0c83ce0)\n",
    "\n",
    "[Аннотированный трансформер](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\n",
    "\n",
    "[Код множества моделей с красивыми комментариями](https://nn.labml.ai/)\n",
    "\n",
    "[BERT](https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c)\n",
    "\n",
    "[Зоопарк BERT](https://ai.plainenglish.io/so-how-is-bert-different-ad43a42cab48)\n",
    "\n",
    "[От NLP до Transformer](https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524)\n",
    "\n",
    "[Illustrated transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "[Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/)\n",
    "\n",
    "[Open-source реализация GPT-3](https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/)\n",
    "\n",
    "[Transformer для русского языка](https://github.com/vlarine/transformers-ru)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
