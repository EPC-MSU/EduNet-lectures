{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Классическое машинное обучение </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Системы предсказаний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо нейронных сетей, обучение работе с которыми являются основной задачей курса, есть и другие подходы к проблеме создания систем, помогающих решать те или иные проблемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/prediction_systems.png\" alt=\"alttext\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Экспертные системы (Rule-based systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самым первым подходом к созданию системы, способной на основе входных данных делать какие-то выводы, были так называемые **Rule-based systems**. В этих системах и за описание объекта — выделении значимых признаков — и за выработку правил, по которым система должна принимать то или иное решение, отвечал человек. \n",
    "\n",
    "В современности такие системы до сих пор используются, например, в определителях растений. Такие определители представляют собой набор утверждений, например: \"Растение имеет стержневую корневую систему\", \"Плод растения - костянка\", на основе согласия/несогласия с которыми книга отсылает вас к другим утверждениям или, в конце концов, к названию растения. \n",
    "\n",
    "Очевидно, что результативность такого подхода зависит: \n",
    "1. от наличия базовых знаний у того, кто определителем пользуется;\n",
    "2. от качества и охвата самого набора правил — к примеру, может ли этот набор правил справиться с ситуацией, когда какой-то признак отсутствует. В приведенном выше примере — растение плодоносит не весь год, потому не всегда можно четко ответить, какой у него плод.\n",
    "\n",
    "Единственная выгода такой системы по сравнению с подходом \"позови нормального специалиста\" является то, что в большинстве случаев, требования к умениям пользователя все же меньше.\n",
    "\n",
    "Игрушечный пример такой схемы: \n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/expert_system.jpg\" alt=\"alttext\" width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классическое машинное обучение<a class=\"anchor\" style=\"autocontent\" id=\"Классическое-машинное-обучение1\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классическое машинное обучение избавляет нас от необходимости вручную составлять какие-то правила. \n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/classic_machine_learning_process.png\" alt=\"alttext\" width=850/>\n",
    "\n",
    "В этом подходе от нас все равно требуется описание нашего объекта определенными признаками — мы должны получать это описание либо вручную, либо обрабатывая объект какими-то программами. Чтобы отличать такие признаки от признаков, которые автоматически выделяют нейронные сети, их называют **hand-designed features**. \n",
    "\n",
    "Но затем эти описанные объекты передаются алгоритму, который уже сам формирует набор правил, по которому он должен решать поставленную задачу. Уже разобранные вами линейная регрессия и SVM сами выбирают, какие признаки и с какими весами им учитывать при принятии финального решения. В некоторых случаях (например, SVM), признаки могут дополнительно (явно или неявно) преобразовываться внутри самой модели и на их основе могут формироваться новые признаки. \n",
    "\n",
    "Но главное ограничение всегда остается - за описание объекта отвечает какой-то внешний источник и то, какие признаки в принципе подавать алгоритму на вход решает человек. А набор возможных преобразований признаков, как правило, строго фиксирован. \n",
    "\n",
    "И составление таких признаков требует от исследователя очень хорошего знания изучаемой темы, знания специфики работы используемого алгоритма — к примеру, подавать алгоритму на вход попарные произведения всех признаков, или алгоритм сам в ходе работы их явно или неявно получит. \n",
    "\n",
    "И очевидно, на больших объемах данных, когда в принципе можно использовать очень малоинформативные признаки (данных-то много, все коэффициенты при них оценим), которые и не придут исследователю в голову, классическое машинное обучение будет проигрывать. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глубокое машинное обучение<a class=\"anchor\" style=\"autocontent\" id=\"Глубокое-машинное-обучение\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В глубоком же машинном обучение признаки за нас выделяет нейросеть.\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/deep_learning_process.png\" alt=\"alttext\" width=600/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это позволяет нейросети самой решать, какие признаки для данных объектов и для данной задачи важны и итеративно выделять сначала простые признаки, а затем комбинировать их в более сложные. За счет этого, в то время как качество подходов классического машинного обучения, по мере увеличения размера обучающей выборки со временем выходит на плато, для нейросетей это плато наступает сильно позже или вообще не наступает.\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/ml_dl_learning_plateau.png\" alt=\"alttext\" width=500/>\n",
    "\n",
    "Потенциально такой подход позволяет почти не применять человеческую экспертизу при построении модели под задачу. Однако в реальности, человеческая экспертиза теперь переходит на уровень подбора архитектуры нейросети. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Необходимость методов классического машинного обучения<a class=\"anchor\" style=\"autocontent\" id=\"Необходимость-методов-классического-машинного-обучения\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Казалось бы, если все так классно, то зачем нам вообще знать и использовать стандартные методы машинного обучения? \n",
    "\n",
    "Оказывается, что существует целый спектр задач, в которых либо объем данных недостаточен для использования нейронных сетей, либо сама структура данных не предполагает каких-либо внутренних повторяющихся паттернов, на которые и заточены нейронные сети. \n",
    "\n",
    "\n",
    "В ситуации, когда у вас есть просто таблица с признаками каждого объекта (**данные табулярного формата**), каждый признак не особо связан как-то с другими и взаиморасположение признаков в таблице не играет никакой роли:\n",
    "1. По крайней мере, в начале вам придется использовать полносвясзные слои, что очень сильно увеличивает число параметров нейросети\n",
    "2. Полученные нейросети как правило не сильно превосходят методы классического обучения, а могут и вести себя хуже (из-за переобучения)\n",
    "\n",
    "Кроме того, стоит учитывать, что часто для того, чтобы достигнуть качества top-of-the-art методов классического машинного обучения, необходимо долгое время подбирать архитектуры нейросети и настраивать ее параметры.\n",
    "\n",
    "Время же получение решений при помощи классических методов часто исчисляется часами. Таким образом, даже в худшем случае, вы сможете оценить, насколько проблема хорошо решаема, и получить хороший бейзлайн для сравнения. \n",
    "\n",
    "Помимо этого, методы машинного обучения дают более трактуемые предсказания - как правило, из них легче получить важность каждого отдельно взятого признака. \n",
    "\n",
    "Кроме того, в современных задачах часто используются комбинации нейронных сетей и алгоритмов классического машинного обучения. Например, можно нейронные сети в качестве генераторов признаков для методов классического обучения. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Деревья решений<a class=\"anchor\" style=\"autocontent\" id=\"Деревья-решений\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деревья решений — это одна из первых моделей машинного обучения, которая была известна человеку. Изначально их строили без специальных алгоритмов, а просто вручную. \n",
    "\n",
    "Когда требовалось принять решение по проблеме, для которой построено дерево, человек брал и проходился по этому дереву."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/manual_construction_of_decision_trees.png\" width=\"650\">\n",
    "\n",
    "Как оно устроено? В каждом узле есть какой-то вопрос. Например, нормальное ли у человека слезоотделение, есть ли него астигматизм и так далее. И, отвечая на каждый из этих вопросов, мы подбираем человеку линзы.\n",
    "Опять же, такое дерево решений можно построить без использования моделей машинного обучения, просто на основании опыта многих врачей.\n",
    "По сути это как раз те самые экспертные системы.\n",
    "\n",
    "Понятно, что вручную такие деревья строить тяжело, для большого объема данных их руками и не построишь. \n",
    "Также возникает вопрос: зачем вообще нужна такая старая модель? \n",
    "\n",
    "Оказывается, что эти модели могут быть неожиданно эффективны и их можно автоматически строить с помощью специально разработанных алгоритмов. Причем, это можно делать достаточно быстро даже на больших объемах данных.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> How to win a Kaggle competition? </center>\n",
    "\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L03/anthony_goldbloom.jpg\" width=\"300\"></center>\n",
    "\n",
    "<center><em>Anthony Goldbloom</em></center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><em>\"According to Anthony, in the history of Kaggle competitions, there are only two Machine Learning approaches that win competitions:</em></center>\n",
    "    \n",
    "<center><em>\"Handcrafted & Neural Networks.\"</em></center>\n",
    "\n",
    "По словам Энтони Голдблум, одного из наиболее известных участников kaggle, на соревнованиях побеждают hand-crafted алгоритмы и нейронные сети. Под hand-crafted Энтони понимает алгоритмы, основанные на деревьях решений. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Где побеждают ансамбли деревьев решений?**\n",
    "\n",
    "* Recomendation systems (Netflix Prize 2009);\n",
    "* Learning to rank (Yahoo Learning to rank challenge 2010); \n",
    "* Crowdflower Search Results Relevance (2015);\n",
    "* Avito Context Ad Clicks (2015); \n",
    "* Везде :)\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/decision_tree_win_competitions.jpg\" width=\"200\"></center>\n",
    "\n",
    "\n",
    "\n",
    "<center><em>\"As long as Kaggle has been around, Anthony says, it has <font color=green >almost always</font> been **ensembles of decision trees that have won competitions**.\"</em></center>\n",
    "\n",
    "В принципе, до недавнего времени деревья решений побеждали практически везде — в рекомендательных системах, в задачах ранжирования, задачах релевантной выдачи для поиска, на предсказаниях, какую рекламу выберет пользователь и так далее.  В любой задаче, где нет какой-то локальный связанности - которая есть в изображениях, текстах и других областях, захваченных нейронными сетями.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Принцип работы дерева решений\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/decision_tree_principle.png\" width=\"800\">\n",
    "\n",
    "Принцип работы дерева решений можно проиллюстрировать на данном примере. Есть 2 признака, в данном случае вещественных. Для каждой точки мы создаем вопрос: 1 признак — больше 0.7 или меньше? Если больше 0.7, то это красная точка. Если меньше 0.7, то идем во второй внутренний узел T2 и спрашиваем: x2 меньше 0.5 или больше? Если меньше 0.5, то точка будет красная, в другом случае — синяя. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбиение пространства**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/decision_trees_partitioning_space.png\" width=\"900\">\n",
    "\n",
    "Фактически, дерево решений бьет пространство признаков с помощью плоскостей на области, и в каждой из этих областей предсказывается какая-то константная величина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деревья решений (классификация)<a class=\"anchor\" style=\"autocontent\" id=\"Деревья-решений-(классификация)\"/><br>\n",
    "Деревья решений, как правило, используются при решении 2-х типов задач — классификации и регрессии.\n",
    "Первая — классификация. Например, предсказание типа линз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/probability_predicions_by_decision_tree.png\" width=\"850\">\n",
    "\n",
    "Особенно актуальны модели, которые могут предсказывать вероятности классов. Жесткие предсказания — не самый удачный вариант, лучше оставить человеку возможность выбирать. К примеру, лекарства всегда действует с какой-то вероятностью, потому что невозможно учесть все факторы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/probability_estimation_by_decision_tree.png\" width=\"700\">\n",
    "\n",
    "На самом деле в деревьях решений в каждом листе находятся разные объекты, то есть каждому листу могут соответствовать объекты разных классов, а предсказать нужно один. Как предсказать вероятность этого класса? Нужно понять, что дерево решений выделило область пространства и пытается эту область описать эффективно (с точки зрения решения текущей задачи)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть небольшая выборка, и мы хотим оценить вероятность. Как это сделать: число представителей данного класса делим на общее число объектов в клетке.  \n",
    "\n",
    "Это согласуется с тем, как мы делаем в статистике. При построении дерева мы видим только обучающую выборку. А хотим делать выводы о генеральной совокупности. Конкретно здесь мы оцениваем, какая доля из объектов, попадающих в данный узел, принадлежит нужному классу. \n",
    "\n",
    "Оценка доли объектов классов в популяции - здесь \n",
    "$$\\hat{p} = \\dfrac n N$$\n",
    "\n",
    "Эта оценка имеет дисперсию - величину, в некотором роде характеризующую то, насколько сильно мы можем ошибиться с оценкой доли. \n",
    "\n",
    "$$D(\\hat{p}) = \\dfrac {p \\cdot (1 - p)} {N}$$\n",
    "\n",
    "Это сразу дает нам одну важную интуицию - желательно, чтобы в листе дерева было не очень мало объектов. Чем объектов меньше - тем больше дисперсия и больше возможная ошибка. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как построить дерево решений?<a class=\"anchor\" style=\"autocontent\" id=\"Как-построить-дерево-решений?\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для бинарных признаков<a class=\"anchor\" style=\"autocontent\" id=\"Для-бинарных-признаков\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/decision_tree_for_two_features.png\" width=\"800\">\n",
    "\n",
    "Допустим, у нас есть табличка, в ней пока нет никаких вещественных признаков. \n",
    "Также есть много данных. Мы хотим построить дерево решений по этой табличке. \n",
    "Предсказывать будем, есть у человека инфаркт или нет. Возьмем в качестве признака боль в груди. В 1-ом и во 2-ом листе получается разное распределение людей. В левом листе инфаркт более вероятен, в правом — менее вероятен. Другим признаком может быть “как хорошо циркулирует кровь”, в таком случае тоже получится неплохое разделение. 3 признак — “есть ли атеросклероз”.\n",
    "\n",
    "В результате все при разбиении выглядят хорошо, кроме последнего, но вдруг мы что-то не учитываем.\n",
    "\n",
    "Что с этим делать? Как из этих 3 разделений что-то выбрать? Логично выбрать такое разбиение, дает нам \"хорошие\" узлы - те, в которых преимущественно сосредоточенны объекты одного класса\n",
    "\n",
    "Одна из используемых метрик называется Gini. Она считается по следующей формуле:\n",
    "\n",
    "$$Gini = 1 - \\sum_ip_i^2$$\n",
    "\n",
    "Фактически, она показывает, какова вероятность того, что два объекта, попавшие в один узел, принадлежат разным классам. Соответственно, чем она ниже, тем лучше получившийся узел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/compute_gini_for_binary_features.png\" width=\"1000\">\n",
    "\n",
    "Такую метрику можно посчитать для каждого узла. Дальше можно посчитать метрику для узла, который мы били. Дальше посчитать, насколько стал лучше результат в зависимости от используемого признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/impurity_decrease_formula.png\" width=\"600\">\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/compute_impurity_decrease.png\" width=\"600\">\n",
    "\n",
    "Оказывается, что наибольший impurity_decrease в признаке “боль в груди”. Значит, мы возьмем “боль в груди”, как признак, на основании которого продолжим строить дерево. \n",
    "\n",
    "Теперь каждое из этих листьев, которые у нас получились, мы можем разбить. Имеет ли смысл их бить, используя тот же признак (“боль в груди”)? Очевидно, нет, потому что мы по нему уже все разделили. Но можно использовать 2 других признака. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/compute_gini_for_another_features.png\" width=\"700\">\n",
    "\n",
    "Каждый раз мы будем выбирать новые признаки. В одном листе один признак лучше бьет его на 2, в другом — другой. В результате получим итоговое дерево, где все признаки используются по одному разу. \n",
    "\n",
    "Можно ли остановиться раньше? В принципе да. Например, когда у нас получатся листья, в которых есть объекты только 1 класса. В этом случае не имеет смысла использовать другие разбиения. Либо может сложиться ситуация, когда разбиение по признаку, которое мы дополнительно взяли, ситуацию никак не улучшает, и дерево предсказывает настолько же плохо, как если бы мы его не использовали. Но это редкая ситуация. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для вещественных признаков<a class=\"anchor\" style=\"autocontent\" id=\"Для-вещественных-признаков\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как работать с вещественными переменными?**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/decision_tree_for_real_numbers.png\" width=\"1200\">\n",
    "\n",
    "\n",
    "\n",
    "Допустим, у нас есть вещественные примеры (например, измерения). Что делать с ними? Берем сетевой угол переменной, для каждого порога делаем разбиение (как делали ранее для бинарного признака) и считаем impurity_decrease. Из всех этих разбиений можно выбрать то, которое дает наилучший результат.\n",
    "\n",
    "Дальше мы среди всех вещественных признаков можем выбрать тот, у которого наилучшее разбиение дает наилучший impurity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для категориальных признаков<a class=\"anchor\" style=\"autocontent\" id=\"Для-категориальных-признаков\"/><br>\n",
    "Мы разобрали бинарные и вещественные признаки.\n",
    "\n",
    "Также существуют категориальные признаки — это когда признаки принимают несколько значений, но при этом мы не можем их как-то упорядочить. Например, цвет, порода собаки, город и так далее. \n",
    "Нельзя сказать, что зеленый больше красного.\n",
    "Но с такими признаками тоже надо как-то работать. \n",
    "\n",
    "Нейронные сети работают с категориальными признаками плохо, обычно необходимо специальным образом предобработать данные, чтобы нейронная сеть смогла с ними работать. Напрямую закодировать \n",
    "\n",
    "Если у нас есть категориальной признак, у которого N возможных значений (например, N цветов), то есть мы можем разбить наши объекты на 2 группы 2^N возможных способов. То есть красный и синий идут в одну сторону, а белый и желтый в другую. Таким образом, мы можем выбрать, идет какой-то цвет в определенный лист или нет. Отсюда получается  порядка 2^N возможных разбиений. Перебирать все возможные разбиения - долго и для категориальных признаков с большим числом возможных категорий неприменимо. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/decision_tree_for_categorical_features.png\" width=\"800\">\n",
    "\n",
    "\n",
    "\n",
    "Но мы не предсказываем категориальный признак, а используем категориальный признак для предсказания чего-то. Можем взять и посчитать для каждой категории категориального признака среднее значение целевой переменной. Дальше отсортировать эти категории по полученному среднему значению. Окажется, что оптимальное разбиение будет одним из тех, которые мы получим в данном случае. Все остальные разбиения гарантированно не являются оптимальными. Получается, что для категориальных переменных мы легко находим правильный способ разбиения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деревья решений (Регрессия)<a class=\"anchor\" style=\"autocontent\" id=\"Деревья-решений-(Регрессия)\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/decision_tree_regression.png\" width=\"700\">\n",
    "\n",
    "Для решения задач регрессии дерево строится практически точно так же, но есть несколько нюансов. Во-первых, в листе нужно предсказывать не класс, а какое-то значение. Тут опять возникает вопрос: в области пространства мы знаем какие-то объекты. Им соответствует какое-то значение. Как лучше всего одним числом охарактеризовать все эти объекты? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/regression_metrics.png\" width=\"900\">\n",
    "\n",
    "<center><em>Метрики регрессии</em></center>\n",
    "\n",
    "Если мы вспомним статистику, у нас нет однозначного ответа. То есть мы можем для распределения всех этих \"y\" предсказывать наиболее частое значение, медиану, среднее значение. \n",
    "Обычно предсказывают среднее значение, потому что с ним легче всего работать и, опять же, среднее чаще всего используют в статистике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять же, фактически хотим оценить среднее всех объектов генеральной совокупности, попадающих в данный узел, используя объекты из тренировочной выборки, попавшие в данный узел.\n",
    "\n",
    "$$\\overline{x} = \\dfrac {\\sum_i X_i} {n}$$\n",
    "\n",
    "Опять же, у нашей оценки будет дисперсия, которая показывает, насколько сильно мы можем ошибаться по сравнению с реальным средним. \n",
    "\n",
    "$$D(\\overline{x}) = \\dfrac {\\sigma^2} {n} $$\n",
    "\n",
    "Опять же, полученная формула говорит нам о том, что желательно иметь в каждом листе достаточное число объектов, чтобы дисперсия оценки была меньше "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь надо сформулировать критерий качества узла для регрессионного дерева. Что мы хотим? Мы хотим, чтобы значения в узле отличались как можно меньше. В этом случае наше среднее будет предсказывать значение для объекта, попавшего в узел, с меньшей ошибкой. В идеале, мы хотим, чтобы все значения были одинаковы.\n",
    "\n",
    "Какую меру можно использовать? Для этого подумаем, а как мы в итоге обычно оцениваем качество регрессии? При помощи MSE. MSE на тренировочной выборке, если мы предсказываем ее среднее, будет таким:\n",
    "\n",
    "$$\\frac 1 n \\sum (X_i - \\overline{X})^2 = \\dfrac {n} {n - 1} D(X)$$\n",
    "\n",
    "То есть, фактически, нам надо минимизировать дисперсию выборки. Разбиение, которое лучше всех уменьшает дисперсию выборки - то, что нам нужно. Единственное, будем взвешивать дисперсии на размер узла. Иначе самыми выгодными будут разбиения, отправляющие в один из узлов только один объект. Те из вас, кто помнит формулу объединения дисперсии двух выборок, могут найти в таком взвешивании и статистический смысл. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/splitting_regression_tree.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деревья решений и работа с пропущенными значениями<a class=\"anchor\" style=\"autocontent\" id=\"Деревья-решений-и-работа-с-пропущенными-значениями\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/decision_tree_and_nan_values_in_data.png\" >\n",
    "\n",
    "\n",
    "Очень сложно, в том числе и в нейронных сетях, бороться с пропущенными значениями. Если значение какого-то признака неизвестно, то любая непрерывная модель, в том числе и нейронные сети, будет без дополнительных ухищрений вести себя очень плохо. Потому что надо как-то объяснить модели, что значения какого-то признака нет. \n",
    "\n",
    "Это сложно сделать, поскольку с этим признаком должны производиться некие математические операции. И потому обычно отсутствующий признак нельзя оставить так, как есть. Обычно его:\n",
    " 1. на место пропущенных значений записать какие-то числа (заполнить пропущенные значения);\n",
    " 2. либо удаляют все объекты с пропущенными значениями. \n",
    "\n",
    "Чаще всего в науке так сделать нельзя, потому что данные стоят очень дорого, и потому выбрасывают объекты только потому, что у них нет какого-либо признака, достаточно редко. \n",
    "\n",
    "Потому обычно прибегают к первому варианту. Как это можно сделать? Можно предположить, что данные не очень сложные, признаки не зависят друг от друга, и заполнить пропущенные значения средними значениями соответствующего признака. Например, если средний возраст людей 30 лет, то для людей, чей возраст неизвестен, будем писать это же значение. \n",
    "\n",
    "Но бывают случаи, когда этот способ (среднее, медиана или любая другая взятая величина, которую мы считаем по известным значениям признаков) не работает. \n",
    "\n",
    "Можно сделать иначе - накидываем дополнительные блоки / модели, которые будут предсказывать пропущенные значения. Если пропущено много признаков, то возникает много проблем, связанных с тем, что надо обучить много моделей: каждая из них совершает ошибки, в итоговым датасете получается много зашумленных данных, не факт, что модель вообще обучится. \n",
    " \n",
    "Третий вариант — использовать алгоритм, который умеет справляться с пропуском. Один из таких алгоритмов — KNN. Можно брать ближайших соседей по известным признакам и на место неизвестного признака поставить среднее значение. Можно сделать нейросеть, которая будет устойчива к отсутствию какого-то признака. Способ рабочий.\n",
    "\n",
    "Деревья решений могут бороться с этой проблемой двумя способами. \n",
    "Первый — мы не можем сказать, что это значение какое-то особое для нейронных сетей. Засунуть None в нейросеть нельзя. Дереву можно сказать, что для какого-то значения признака нет, трактуя это как особое правило (выделим такие объекты в особую группу). Это действительно будет работать.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/decision_tree_surrogate_splits.png\" width=\"700\">\n",
    "\n",
    "\n",
    "<center><em>Дерево решений - суррогатные сплиты</em></center>\n",
    "\n",
    "Второй вариант: если мы в этом узле разбивали объекты по данному признаку и для текущего объекта он неизвестен, то можно поискать среди нашей обучающей выборки признаки, которые дают разбиение, похожее на признак с неизвестным значением. Это не надо делать вручную, в некоторых пакетах это реализовано за вас. Это работающее решение, которое явно лучше, чем заполнение пропусков вручную. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преимущества и недостатки деревьев решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему деревья - очень мощный метод?<a class=\"anchor\" style=\"autocontent\" id=\"Почему-деревья---очень-мощный-метод?\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Взгляд точки зрения функционального анализа**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/why_decision_tree_powerful_method.png\" width=\"1000\">\n",
    "\n",
    "\n",
    "У деревьев решений есть еще одно хорошее свойство. На первом занятии вы познакомились с замечательный теоремой об универсальном аппроксиматоре. Ее суть в том, что если взять нейросеть, и у нее будет 2 скрытых слоя, то она сможет аппроксимировать в любую заданную гладкую функцию. \n",
    "\n",
    "Для деревьев решений есть аналогичная теорема, говорящая о том, что дерево может аппроксимировать в любую заданную кусочно-постоянную функцию. \n",
    "\n",
    "Дерево решений, в отличие от нейронной сети, может адаптироваться к выборке любого размера, любому количеству признаков. Для нейронной сети эта теорема предполагает, что можно бесконечно увеличивать скрытые слои. В реальной жизни так не делают. \n",
    "\n",
    "В случае же с деревьями решений лист разбивается еще на 2 части. Это можно делать бесконечно до тех пор, пока в каждом листе не окажется по одному объекту. Это приведет к сильному переобучению, но в принципе, если бы у нас была вся генеральная совокупность, мы бы выучили ее гораздо легче деревом решений, чем нейронной сетью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Неустойчивость деревьев решений<a class=\"anchor\" style=\"autocontent\" id=\"Неустойчивость-деревьев-решений\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/instability_of_decision_trees.png\" width=\"900\">\n",
    "\n",
    "Деревья решений не используется в чистом виде, потому что они неустойчивы. Если у нас есть данные, и мы выкинем из данных 2 объекта, то дерево решений может очень сильно поменяться. Красивого дерева, как на примере в самом начале, у нас не получится. Будет мешанина, которая может в любой момент поменяться, если мы выкинем пару объектов.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продемонстрируем неустойчивость решения, получаемого при помощи деревьев решений на примере датасета iris ([ирисы Фишера](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0)). \n",
    "\n",
    "Ирисы Фишера состоят из данных о 150 экземплярах ириса, по 50 экземпляров из трёх видов — Ирис щетинистый (Iris setosa), Ирис виргинский (Iris virginica) и Ирис разноцветный (Iris versicolor)\n",
    "\n",
    "Для каждого экземпляра измерялись четыре характеристики (в сантиметрах):\n",
    "\n",
    "1. Длина наружной доли околоцветника (англ. sepal length);\n",
    "2. Ширина наружной доли околоцветника (англ. sepal width);\n",
    "3. Длина внутренней доли околоцветника (англ. petal length);\n",
    "4. Ширина внутренней доли околоцветника (англ. petal width)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем учиться отделять Ирис виргинаский (versicolor) от остальных видов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_iris()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['target'] = dataset.target != 1 # 0 for setosa, 1 - versicolor, 2 - virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем два разных разбиения на обучение и тест. И посмотрим, будут ли отличаться деревья, построенные для данных разбиений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "# first set of points\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(df[dataset.feature_names], df['target'], random_state=0)\n",
    "clf1 = DecisionTreeClassifier(max_depth = 3)\n",
    "clf1.fit(X_train1, Y_train1)\n",
    "\n",
    "# second set of points \n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(df[dataset.feature_names], df['target'], random_state=42)\n",
    "clf2 = DecisionTreeClassifier(max_depth = 3)\n",
    "clf2.fit(X_train2, Y_train2)\n",
    "\n",
    "\n",
    "fn=['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)']\n",
    "cn=['setosa', 'versicolor', 'virginica']\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5), dpi=80)\n",
    "tree.plot_tree(clf1,\n",
    "               feature_names = fn, \n",
    "               class_names = cn,\n",
    "               filled = True, ax=axes[0])\n",
    "tree.plot_tree(clf2,\n",
    "               feature_names = fn, \n",
    "               class_names = cn,\n",
    "               filled = True, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что даже деревья максимальной глубины 3 уже не совпадают между собой. Конечно, у нас маленький датасет - как правило, чем датасет больше, тем устойчивее будет получаться дерево на первых уровнях. Но часто и деревья используют куда большей глубины. \n",
    "\n",
    "Если использовать деревья бОльшей глубины, то и структура деревьев (то, как они выглядят, даже если не обращать внимания на конкретные признаки в узлах), будет отличаться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set of points\n",
    "clf1 = DecisionTreeClassifier(max_depth = 10, random_state = 0)\n",
    "clf1.fit(X_train1, Y_train1)\n",
    "\n",
    "# second set of points\n",
    "clf2 = DecisionTreeClassifier(max_depth = 10, random_state = 42)\n",
    "clf2.fit(X_train2, Y_train2)\n",
    "\n",
    "\n",
    "fn=['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)']\n",
    "cn=['setosa', 'versicolor', 'virginica']\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5), dpi=80)\n",
    "tree.plot_tree(clf1,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True, ax=axes[0])\n",
    "tree.plot_tree(clf2,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучение деревьев<a class=\"anchor\" style=\"autocontent\" id=\"Переобучение-деревьев\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если алгоритм при небольшом изменении признаков сильно меняет свое решение, это, как правило, указывает на переобучение. Алгоритм сильно реагируют на любой шум в данных - доверять его решениям опасно. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажем это на синтетическом датасете "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handson-ml\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, Y, axes=[-1.5, 2.5, -1, 1.5], alpha=0.5, contour=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    Y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, Y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, Y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    plt.plot(X[:, 0][Y==0], X[:, 1][Y==0], \"yo\", alpha=alpha)\n",
    "    plt.plot(X[:, 0][Y==1], X[:, 1][Y==1], \"bs\", alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "X, Y = sklearn.datasets.make_moons(n_samples=500, noise=0.30, random_state = 42)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(X[:, 0][Y==0], X[:, 1][Y==0], \"yo\")\n",
    "plt.plot(X[:, 0][Y==1], X[:, 1][Y==1], \"bs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 42)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "clf = DecisionTreeClassifier(max_depth = 20, random_state = 42)\n",
    "clf.fit(X_train, Y_train)\n",
    "plot_decision_boundary(clf, X, Y)\n",
    "plt.title(\"Decision border\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В областях, покрашенных в желтый, модель будет классифицировать точки как точки из 0 класса. В зеленый - как точки из 1го класса. \n",
    "\n",
    "Обратите внимание на странные, рваные области на рисунке. В этих областях из-за шума, присутствующего в данных, оказались точки  неправильного класса. Дерево не смогло их распознать как неправильные и просто выучило, очевидно, неверные правила. \n",
    "\n",
    "Что произойдет, если мы возьмем точки из того же датасета, но другие? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set of points\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X, Y, random_state = 1)\n",
    "clf1 = DecisionTreeClassifier(max_depth = 20, random_state = 42) \n",
    "clf1.fit(X_train1, Y_train1)\n",
    "\n",
    "# second set of points\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X, Y, random_state = 2)\n",
    "clf2 = DecisionTreeClassifier(max_depth = 20, random_state = 42) \n",
    "clf2.fit(X_train2, Y_train2)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(clf1, X, Y)\n",
    "plt.title(\"Decision border 1\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(clf2, X, Y)\n",
    "plt.title(\"Decision border 2\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Границы решений поменялись, причем сильно. Исчезли одни \"рваные\" границы и появились другие. Опять же, наше дерево неустойчиво, из-за малейшего шума в данных оно может поменять свое предсказание. Оно переобучается на шум в данных. \n",
    "\n",
    "Говорят, что у нашего дерева высокий **variance**. \n",
    "\n",
    "Можно ли что-то поправить? Ну, у нас в настройках максимальная глубина дерева поставлена равной 20. Это очевидно много. Давайте сделаем дерево глубины 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set of points\n",
    "clf1 = DecisionTreeClassifier(max_depth = 1, random_state = 42)\n",
    "clf1.fit(X_train1, Y_train1)\n",
    "\n",
    "# second set of points\n",
    "clf2 = DecisionTreeClassifier(max_depth = 1, random_state = 42)\n",
    "clf2.fit(X_train2, Y_train2)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(clf1, X, Y)\n",
    "plt.title(\"Decision border 1\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(clf2, X, Y)\n",
    "plt.title(\"Decision border 2\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или глубины 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set of points \n",
    "clf1 = DecisionTreeClassifier(max_depth = 2, random_state = 42)\n",
    "clf1.fit(X_train1, Y_train1)\n",
    "\n",
    "# second set of points\n",
    "clf2 = DecisionTreeClassifier(max_depth = 2, random_state = 42)\n",
    "clf2.fit(X_train2, Y_train2)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(clf1, X, Y)\n",
    "plt.title(\"Decision border 1\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(clf2, X, Y)\n",
    "plt.title(\"Decision border 2\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь полученные границы решений (почти) совпадают. Но что мы видим? Наше дерево абсолютно не в состоянии (в обоих случаях) уловить закономерность в исходных данных. Если мы отложим только тренировочный датасет, то увидим следующее "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 42)\n",
    "\n",
    "clf1 = DecisionTreeClassifier(max_depth = 2, random_state = 42)\n",
    "clf1.fit(X_train, Y_train)\n",
    "\n",
    "clf2 = DecisionTreeClassifier(max_depth = 20, random_state = 42)\n",
    "clf2.fit(X_train, Y_train)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(clf1, X_train, Y_train)\n",
    "plt.title(\"Decision border, depth=2, train only\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(clf2, X_train, Y_train)\n",
    "plt.title(\"Decision border, depth=20, train only\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в то время как дерево большой глубины выучило нашу тренировочную выборку почти идеально, дерево малой глубины для многих объектов из тренировочной выборки предсказывает не тот класс. Причем, оно не может исправиться просто в силу ограничения на глубину. \n",
    "\n",
    "В случае дерева с малой глубиной нам не хватает **сложности модели**, чтобы уловить **внутреннюю структуру данных**. Говорят, что у нашей модели высокий **bias**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias, Variance, Irreducible error \n",
    "\n",
    "Можно показать, что ошибка любой модели раскладывается в сумму трех компонент:\n",
    "\n",
    "$$ Model\\_error = Bias^2 + Variance + Irreducible\\_error $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias<a class=\"anchor\" style=\"autocontent\" id=\"Bias\"/><br>\n",
    "Обычно, высокий bias имеют недообученные модели. Например, реальная зависимость, которую мы наблюдаем - нелинейная, а мы пытаемся аппроксимировать ее линией. В этом случае наше решение заведомо смещено (biassed) в сторону линейной модели и мы всегда будем ошибаться в сравнении с реальной моделью данных\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/problem_of_hight_bias.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance\n",
    "Можно получить и обратную ситуацию. Реальная закономерность имеет линейный вид, а мы пытаемся ее аппроксимировать нелинейной моделью. \n",
    "В этом случае мы будем выучивать любой шум в данных и пытаться объяснить его нашей моделью. \n",
    "Малое изменение в данных будет приводить к большим изменениям в прогнозе модели. \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/problem_of_hight_variance.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда bias и variance представляет еще таким образом:\n",
    "1. можно быть очень точным и попадать всегда в центр мишени - это соответствует низкому bias и низкому variance;\n",
    "2. можно попадать примерно в центр мишени, но при этом с большим разбросом - низкий bias, но высокий variance;\n",
    "3. можно стрелять кучно, но не туда) - это высокий bias и низкий variance;\n",
    "4. ну а можно просто стрелять наугад, куда душа зовет - это высокий bias и высокий variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/low_hight_bias_variance.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irreducible error<a class=\"anchor\" style=\"autocontent\" id=\"Irreducible-error\"/><br>\n",
    "В идеальном для нас случае - когда мы угадали с моделью наших данных, гипотетически можно получить. $$Bias=0, Variance=0$$\n",
    "Однако, у нас есть ошибки в измерении самой предсказываемой величины. Из-за этого наша модель всегда будет иметь некий уровень ошибки, ниже которого опуститься нельзя. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias vs variance<a class=\"anchor\" style=\"autocontent\" id=\"Bias-vs-variance\"/><br>\n",
    "\n",
    "В реальности же, когда реальную модель данных угадать в точности почти невозможно, есть bias-variance tradeoff - нельзя бесконечно уменьшать и Bias, и Variance. Есть какая-то точка оптимума. С какого-то момента при уменьшении Bias начнет увеличиваться Variance, и наоборот. \n",
    "При этом, можно построить  связь этих величин с увеличением сложности модели (capacity)\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/bias_variance_tradeoff.png\" width=\"450\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применительно к деревьям<a class=\"anchor\" style=\"autocontent\" id=\"Применительно-к-деревьям\"/><br>\n",
    "Дерева малой глубины имеет малую сложность - и высокий bias. \n",
    "Дерево большой глубины имеет высокую сложность - и высокий variance. \n",
    "\n",
    "Можно подобрать для дерева идеальную capacity, когда Bias и Variance будут суммарно давать наименьший вклад в ошибку. Этим мы занимаемся при подборе параметров. \n",
    "Но, оказывается, есть и другие способы борьбы с variance и/или bias, которые мы разберем позже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что если бы могли говорить не просто решение дерева, а привязывать к этому какую-то статистику, например, сколько деревьев, построенных по подобной процедуре, приняли такое же решение - было бы легче.\n",
    "\n",
    "Если наложить решающие границы 100 решающих деревьев, построенных на разных выборках из X, y, то мы увидим, что \"хорошие области\", соответствующие реальному разделению данных будут общими между деревьями, а плохие - индивидуальны. \n",
    "К сожалению, в реальности, мы не можем брать бесконечное число наборов данных из генеральной совокупности (представленной в данном случае X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    " \n",
    "for i in range(1,101):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( X, Y, random_state = i)\n",
    "    clf = DecisionTreeClassifier(max_depth = 20, random_state = 0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    plot_decision_boundary(clf, X, Y, alpha = 0.02, contour=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бутстрэп<a class=\"anchor\" style=\"autocontent\" id=\"Бутстрэп\"/><br>\n",
    "\n",
    "Часто мы хотим получить какое-то представление о точности какой-либо нашей оценки - медианы выборки, качества модели, корреляции между двумя переменными и тд. И мы не знаем, как распределена характеристика, которую мы оцениваем. \n",
    "\n",
    "Есть много подходов к тому, как получить такую оценку и один из них - бутстрэп. \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/bootstrap.png\" width=\"600\">\n",
    "\n",
    "Что мы делаем: \n",
    "\n",
    "1. Делаем из нашего исходного датасета N выборок такого же размера с повторениями. \n",
    "\n",
    "2. Для каждой полученной выборки (обычно их называют **псевдовыборками**) считаем характеристику, для которой хотим получить оценку. \n",
    "\n",
    "3. В результате такой процедуры получаем N значений характеристики. Строим гистограмму этих значений. Получили примерное распределение нашей характеристики. \n",
    "\n",
    "4. Можем построить 95% доверительный интервал для нашей характеристики - для этого отрезаем 2.5% самых больших значений и самых малых. \n",
    "\n",
    "Давайте попробуем сделать это на двух практических примерах\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корреляция и построение доверительного интервала для нее<a class=\"anchor\" style=\"autocontent\" id=\"Корреляция-и-построение-доверительного-интервала-для-нее\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто мы хотим понять, как взаимосвязаны две переменные. И часто для оценки этой взаимосвязи используется корреляция. Например, корреляция Пирсона позволяет оценить линейную зависимость между двумя переменными. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 1<a class=\"anchor\" style=\"autocontent\" id=\"Пример-1\"/><br>\n",
    "Подсчет корреляции Пирсона реализован в Python с помощью функции *scipy.stats.pearsonr*. Посчитаем при помощи этой функции корреляцию между длиной наружной доли околоцветника и внутренней доли околоцветника. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "dataset = load_iris()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['target'] = dataset.target != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "cor_value, pval = scipy.stats.pearsonr(df['sepal length (cm)'], df['petal length (cm)'])\n",
    "print(f\"Correlation coefficient is {cor_value}\")\n",
    "print(f\"P-value is {pval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция выдает нам одновременно и коэффициент, и его значимость - вероятность наблюдать такое или более критическое значение. Однако на основе чего она считала p-value? \n",
    "\n",
    "Можно обратиться к документации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?scipy.stats.pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value считается в предположении, что наши переменные распределены нормально. \n",
    "\n",
    "Аналогично, при тех же предположениях, при помощи приведенной ниже функции можно подсчитать доверительный интервал для нашего коэффициента корреляции, который дает нам интервальную, а не точечную оценку для значения корреляции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pearsonr_ci(X, Y, alpha = 0.05):\n",
    "    ''' calculate Pearson correlation along with the confidence interval using scipy and numpy\n",
    "    Parameters\n",
    "    ----------\n",
    "    X, Y : iterable object such as a list or np.array\n",
    "      Input for correlation calculation\n",
    "    alpha : float\n",
    "      Significance level. 0.05 by default\n",
    "    Returns\n",
    "    -------\n",
    "    r : float\n",
    "      Pearson's correlation coefficient\n",
    "    pval : float\n",
    "      The corresponding p value\n",
    "    lo, hi : float\n",
    "      The lower and upper bound of confidence intervals\n",
    "    '''\n",
    "\n",
    "    r, p = scipy.stats.pearsonr(X, Y)\n",
    "    r_z = np.arctanh(r)\n",
    "    se = 1/np.sqrt(X.size - 3)\n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2)\n",
    "    lo_z, hi_z = r_z - z * se, r_z + z * se\n",
    "    lo, hi = np.tanh((lo_z, hi_z))\n",
    "    return lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, hi = pearsonr_ci(df['sepal length (cm)'], df['petal length (cm)'])\n",
    "\n",
    "print(f'Lower bound of confidence interval: {lo}')\n",
    "print(f'Upper bound of confidence interval: {hi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что, если мы не хотим делать предположения о нормальности? \n",
    "Или знаем, что они не выполняются? \n",
    "Или не хотим писать сложных функций на каждый случай - если x распределено так-то, то считай так-то, если так-то, то так-то и т.д.?\n",
    "\n",
    "В этом случае нам и поможет бутстрэп. Напишем функцию, которая будет нам для любой характеристики, считаемой для пар из x и y, выдавать значения этой характеристики, посчитанные на псевдовыборках. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_metric(X, \n",
    "                     Y,\n",
    "                     metric_fn,\n",
    "                     samples_cnt = 1000,\n",
    "                     random_state = 42):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    b_metric = np.zeros(samples_cnt)\n",
    "    for it in range(samples_cnt):\n",
    "        poses = np.random.choice(X.shape[0], size=X.shape[0], replace=True)\n",
    "        \n",
    "        X_boot = X[poses]\n",
    "        Y_boot = Y[poses]\n",
    "        \n",
    "        m_val = metric_fn(X_boot, Y_boot)\n",
    "        b_metric[it] = m_val\n",
    "    \n",
    "    return b_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем значение корреляции Пирсона на бутстрэп-репликах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "boot_cor = bootstrap_metric(X = df['sepal length (cm)'],\n",
    "                            Y = df['petal length (cm)'],\n",
    "                            metric_fn=lambda X, Y: scipy.stats.pearsonr(X, Y)[0])\n",
    "\n",
    "# plot histogram of the obtained values:\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.histplot(boot_cor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить bootstrap 1-alpha доверительный интервал, просто посчитаем alpha/2 и  1-alpha квантили в полученном массиве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "lo_2, hi_2 = np.quantile(boot_cor, q=[alpha/2, 1 - alpha/2])\n",
    "\n",
    "print(f'Lower bound of confidence interval: {lo}, bootstap: {lo_2}')\n",
    "print(f'Upper bound of confidence interval: {hi}, bootstap: {hi_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили доверительный интервал, полученный при помощи бутстрапа. Заметим, что точность интервала зависит от числа реплик, которые вы сделаете — чем больше, тем точнее интервал. \n",
    "\n",
    "Сравнивая с интервалом, подсчитанным в предположении нормальности, видим, что они почти друг от друга не отличаются. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 2<a class=\"anchor\" style=\"autocontent\" id=\"Пример-2\"/><br>\n",
    "Загрузим данные о людях с подозрением на сердечные заболевания. \n",
    "Допустим, мы хотим узнать, есть ли связь между уровнем холестерина (колонка chol) и возрастом (age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_dataset = pd.read_csv(\"https://edunet.kea.su/repo/EduNet-web_dependencies/L03/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo, hi = pearsonr_ci(heart_dataset['age'], heart_dataset['chol'])\n",
    "\n",
    "print(f'Lower bound of confidence interval: {lo}')\n",
    "print(f'Upper bound of confidence interval: {hi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_value, p_value = scipy.stats.pearsonr(heart_dataset['age'], heart_dataset['chol'])\n",
    "\n",
    "print(f'Correlation coefficient is: {cor_value}')\n",
    "print(f'P-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что корреляция есть (доверительный интервал не включает 0). Или где-то есть подвох? На самом деле - да. Возраст точно не распределен нормально. Потому считать доверительный интервал с предположениями о нормальности переменных - не очень хорошо. \n",
    "Посмотрим, что скажет нам bootstrap-интервал:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_cor = bootstrap_metric(X=heart_dataset['age'],\n",
    "                            Y=heart_dataset['chol'],\n",
    "                            metric_fn=lambda X, Y: scipy.stats.pearsonr(X, Y)[0])\n",
    "lo_2, hi_2 = np.quantile(boot_cor, q=[alpha/2, 1 - alpha/2])\n",
    "\n",
    "\n",
    "print(f'Lower bound of confidence interval(bootstap): {lo_2}')\n",
    "print(f'Upper bound of confidence interval(bootstap): {hi_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что, действительно, полученная корреляция значима. Но теперь этот результат получен без очевидно неверных предположений. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение доверительного интервала для качества метрики<a class=\"anchor\" style=\"autocontent\" id=\"Построение-доверительного-интервала-для-качества-метрики\"/><br>\n",
    "\n",
    "Представим теперь, что мы сравним поведение двух моделей на тестовом датасете. Допустим, нам интересует F1-score. Как нам это сделать? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 1 (искусственный)<a class=\"anchor\" style=\"autocontent\" id=\"Пример-1-(искусственный)\"/><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1500\n",
    "Y = np.random.choice([0, 1], size=size, replace=True)\n",
    "print(f'shape Y: {Y.shape}')\n",
    "print(f'First 10 values: {Y[0:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая имитирует поведение модели, которая угадывает правильный класс в $p$ проценте случаев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_model(Y_real, p):\n",
    "    guessed = np.random.choice([True, False], size=size, replace=True, p=[p, 1-p])\n",
    "    Y_pred = np.zeros_like(Y_real)\n",
    "    Y_pred[guessed] = Y_real[guessed]\n",
    "    Y_pred[~guessed] = 1 - Y_real[~guessed]\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас две модели обладают одинаковым качеством, а третья - лучшим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = lambda Y: guess_model(Y, p=0.7)\n",
    "model2 = lambda Y: guess_model(Y, p=0.7)\n",
    "model3 = lambda Y: guess_model(Y, p=0.75)\n",
    "\n",
    "np.random.seed(42)\n",
    "Y_pred1 = model1(Y)\n",
    "Y_pred2 = model2(Y)\n",
    "Y_pred3 = model3(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый вариант - просто посчитать f1-score каждой модели и проранжировать их в соответствии с f1-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "qual1 = f1_score(y_true=Y, y_pred=Y_pred1)\n",
    "qual2 = f1_score(y_true=Y, y_pred=Y_pred2)\n",
    "qual3 = f1_score(y_true=Y, y_pred=Y_pred3)\n",
    "\n",
    "print(f' qual1: {qual1}\\n qual2: {qual2}\\n qual3: {qual3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидная проблема - да, нужная нам модель выбрана, но почему мы считаем различие между первой и второй моделью значимыми, а между второй и третьей - нет?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'qual2 - qual1: {qual2 - qual1}\\nqual3 - qual2: {qual3 - qual2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, такой способ (при помощи точечной оценки), может привести к ошибке, так как не дает нам судить о **значимости** отличий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует много способов посчитать значимость данного отличия. Мы рассмотрим способ сравнения на основе bootstrap. Об остальных можете почитать в обзоре, приведенном в списке литературы. \n",
    "\n",
    "Способ, собственно состоит в применении бутстрэпа к предсказаниям модели и реальным меткам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_f1score_m1 = bootstrap_metric(Y, Y_pred1, metric_fn=lambda X, Y: f1_score(y_true=X, y_pred=Y))\n",
    "boot_f1score_m2 = bootstrap_metric(Y, Y_pred2, metric_fn=lambda X, Y: f1_score(y_true=X, y_pred=Y))\n",
    "boot_f1score_m3 = bootstrap_metric(Y, Y_pred3, metric_fn=lambda X, Y: f1_score(y_true=X, y_pred=Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим 90% доверительный интервал качества для каждой модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.10\n",
    "print(\"F1 score for the 1st model: \", np.quantile(boot_f1score_m1, q=[alpha/2, 1 - alpha/2]))\n",
    "print(\"F1 score for the 2st model: \", np.quantile(boot_f1score_m2, q=[alpha/2, 1 - alpha/2]))\n",
    "print(\"F1 score for the 3st model: \", np.quantile(boot_f1score_m3, q=[alpha/2, 1 - alpha/2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы видим, что доверительные интервалы для качества первой и второй модели практически одинаковы, в то время как доверительный интервал для качества третьей модели от них сильно отличается и не пересекается. \n",
    "\n",
    "Можем построить боксплот:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(y=np.concatenate([boot_f1score_m1, boot_f1score_m2, boot_f1score_m3]),\n",
    "            x=[\"model1\"] * 1000 + ['model2'] * 1000 + ['model3'] * 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 2 (классифицируем людей с больным сердцем и нет)<a class=\"anchor\" style=\"autocontent\" id=\"Пример-2-(классифицируем-людей-с-больным-сердцем-и-нет)\"/><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = heart_dataset.drop(\"target\", axis=1)\n",
    "Y = heart_dataset['target'] > 0\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y.values, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_model = GridSearchCV(SVC(), {'kernel':('linear',\n",
    "                                           'rbf'),\n",
    "                                 'C':[0.01, 0.1, 1, 10]}\n",
    "                         ).fit(X_train, Y_train)\n",
    "\n",
    "logr_model = GridSearchCV(LogisticRegression(solver='liblinear', max_iter=100000), \n",
    "                          {'penalty':('l1', \n",
    "                                      'l2'),\n",
    "                            'C':[0.01, 0.1, 1, 10, 100]}\n",
    "                          ).fit(X_train, Y_train)\n",
    "\n",
    "# few objects in the leaf - poor estimates of class probabilities - the model is overtraining\n",
    "dt_model = GridSearchCV(DecisionTreeClassifier(), \n",
    "                          {'max_depth':[1, 3, 5, 7, 10],\n",
    "                           'min_samples_leaf': [1, 3, 5, 10]}\n",
    "                        ).fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score # PR-AUC\n",
    "\n",
    "Y_pred1 = svc_model.decision_function(X_test) # by default, SVM gives score to each object instead of probabilities\n",
    "Y_pred2 = logr_model.predict_proba(X_test)[:, 1]\n",
    "Y_pred3 = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "qual1 = average_precision_score(y_true=Y_test, y_score=Y_pred1)\n",
    "qual2 = average_precision_score(y_true=Y_test, y_score=Y_pred2)\n",
    "qual3 = average_precision_score(y_true=Y_test, y_score=Y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Logistic regression pr-auc: {qual1:.03f}\")\n",
    "print(f\"SVC pr-auc: {qual2:.03f}\")\n",
    "print(f\"DecisionTreeClassifier pr-auc: {qual3:.03f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подсчитаем бутстрэп-оценки. Обратите внимание - теперь мы передаем не предсказания, а вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_score_logreg = bootstrap_metric(Y_test, \n",
    "                                   Y_pred1, \n",
    "                                   metric_fn=lambda X, Y: average_precision_score(y_true=X, y_score=Y))\n",
    "boot_score_svc = bootstrap_metric(Y_test,\n",
    "                                   Y_pred2,\n",
    "                                   metric_fn=lambda X, Y: average_precision_score(y_true=X, y_score=Y))\n",
    "boot_score_dt = bootstrap_metric(Y_test,\n",
    "                                   Y_pred3,\n",
    "                                   metric_fn=lambda X, Y: average_precision_score(y_true=X, y_score=Y))\n",
    "\n",
    "alpha=0.10\n",
    "print(\"Logistic regression pr-auc 90%-ci: \", np.quantile(boot_score_logreg, q=[alpha/2, 1 - alpha/2]))\n",
    "print(\"SVC pr-auc 90%-ci:\", np.quantile(boot_score_svc, q=[alpha/2, 1 - alpha/2]))\n",
    "print(\"DecisionTreeClassifier pr-auc 90%-ci:\", np.quantile(boot_score_dt, q=[alpha/2, 1 - alpha/2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что качество SVC и логистической регрессии почти не отличается, а дерево решений уступает обеим моделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(y=np.concatenate([boot_score_logreg,\n",
    "                              boot_score_svc, \n",
    "                              boot_score_dt]),\n",
    "            x=[\"Log-reg\"] * 1000 + ['SVC'] * 1000 + ['DT'] * 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ансамбли<a class=\"anchor\" style=\"autocontent\" id=\"Ансамбли\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корректирующий код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть сигнал: \n",
    "\n",
    "\n",
    "<font color=blue size=30>1110110011</font>\n",
    "\n",
    "Но при передаче на другое устройство в нем могут возникать ошибки.\n",
    "\n",
    "<font color=blue size=30>1</font><font color=red size=30>0</font><font color=blue size=30>1011</font><font color=red size=30>1</font><font color=blue size=30>011</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое простое решение возникшей проблемы:\n",
    "\n",
    " 1. Шум, который вносит ошибки, скорее всего не зависит от места в сигнале;\n",
    " 2. Передадим 3 раза один и тот же сигнал;\n",
    "\n",
    "<font color=blue size=30>1</font><font color=red size=30>0</font><font color=blue size=30>1011</font><font color=red size=30>1</font><font color=blue size=30>011</font>\n",
    "\n",
    "<font color=blue size=30>1110</font><font color=red size=30>0</font><font color=blue size=30>10011</font>\n",
    "\n",
    "<font color=blue size=30>11</font><font color=red size=30>0</font><font color=blue size=30>0110</font><font color=red size=30>1</font> <font color=blue size=30>11</font>\n",
    "\n",
    "\n",
    "\n",
    " 3. Усредним, что получилось (в каждом случае возьмем наиболее часто встречающуюся цифру);\n",
    "\n",
    "<font color=blue size=30>1110110011</font>\n",
    "\n",
    "\n",
    " 4. С большой долей вероятности итоговый сигнал восстановится; \n",
    " 5. Чем больше копий сигналов передастся, тем выше вероятность, что сигнал восстановится полностью корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем код, чтобы удостовериться в наших выводах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_signal(size, random_state = 42):\n",
    "    signal = np.random.choice([0,1], size, replace=True)\n",
    "    return signal\n",
    "\n",
    "def compare_signs(sig1, sig2):\n",
    "    return (sig1 != sig2).sum()\n",
    "\n",
    "def add_noise(sig, noise_p = 0.20):\n",
    "    sig = sig.copy()\n",
    "    changed = np.random.choice([True, False], sig.shape[0], replace=True, p = [noise_p, 1 - noise_p])\n",
    "    sig[changed] = 1 - sig[changed]\n",
    "    return sig \n",
    "\n",
    "def average_signals(sigs):\n",
    "    sig = np.mean(sigs, axis=0)\n",
    "    sig = np.round(sig, 0)\n",
    "    return sig\n",
    "\n",
    "def send_signal(signal, tries):\n",
    "    passed_sigs = [add_noise(signal) for _ in range(tries)]\n",
    "    fin_signal = average_signals(passed_sigs)\n",
    "    return fin_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "repeats = 1000\n",
    "signals_cnt_rng = range(1, 30, 2)\n",
    "\n",
    "signal = get_signal(10)\n",
    "mistakes = np.zeros((repeats, len(signals_cnt_rng)))\n",
    "\n",
    "for j, sig_cnt in enumerate(signals_cnt_rng):\n",
    "    for i in range(repeats):\n",
    "        rec_sig = send_signal(signal, sig_cnt)\n",
    "        mistakes[i, j] = compare_signs(rec_sig, signal)\n",
    "\n",
    "\n",
    "mn = mistakes.mean(axis=0)\n",
    "sd = mistakes.std(axis=0)\n",
    "plt.title(\"Number of error in signal\")\n",
    "plt.ylabel(\"Number of errors\")\n",
    "plt.xlabel(\"Number of signals passed at once\")\n",
    "plt.plot(signals_cnt_rng, mn)\n",
    "plt.fill_between(signals_cnt_rng, mn - sd, mn+sd,  facecolor='blue',\n",
    "                 alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Оказывается, это имеет отношение к проблеме, с которой мы столкнулись с деревьями решений.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постановка задачи:\n",
    "\n",
    "Есть 10 объектов, в реальности все принадлежат классу 1\n",
    "\n",
    "\n",
    "<font color=blue size=30>1111111111</font>\n",
    "\n",
    "Пусть у нас есть три **независимых** классификатора A, B и C. Каждый предсказывает 1 в 70% случаев. \n",
    "\n",
    "\n",
    "Мы хотим получить общий классификатор на основании этих трех. \n",
    "\n",
    "\n",
    "\n",
    "Мы хотим получить предсказание базовых классификаторов, применить к ним какую-то функцию, которая выдаст итоговый ответ. Вид этой функции задается заранее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Усреднение предсказания классификаторов\n",
    "\n",
    "Будем просто усреднять предсказание наших классификаторов\n",
    "\n",
    "\n",
    "$$ h(x) = \\dfrac 1 T \\sum_{i=1}^{T}a_i(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простое голосование\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/simple_voting.png\" width=\"600\">\n",
    "\n",
    "\n",
    "Допустим, у нас 3 классификатора, которые предсказывают независимо друг от друга. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем вероятность того, что:\n",
    "\n",
    " 1. все три классификатора верны: 0.7 * 0.7 * 0.7 = 0.3429\n",
    " 2. два классификатора верны: 0.7 * 0.7 * 0.3 + 0.7 * 0.3 * 0.7 + 0.3 * 0.7 * 0.7 = 0.4409\n",
    " \n",
    "Таким образом, если брать большинство голосов, то мы будем в 78% случаев предсказывать верно. Мы взяли 3 классификатора, которые сами по себе были не очень хорошими, и получили классификатор лучшего качества. \n",
    "Очевидно, что если взять 4, 5, 10 классификаторов, то ситуация будет становиться лучше. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть теперь у нас три классификатора, выдающие следующие предсказания\n",
    "\n",
    "<font color=blue size=30>11111111</font><font color=red size=30>00</font> - 80% точность\n",
    "\n",
    "<font color=blue size=30>11111111</font><font color=red size=30>00</font> - 80% точность\n",
    "\n",
    "<font color=blue size=30>1</font></font><font color=red size=30>0</font><font color=blue size=30>111111</font><font color=red size=30>00</font> - 70% точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если объединим предсказания, то получим:\n",
    "\n",
    "<font color=blue size=30>11111111</font><font color=red size=30>00</font> - 80% точность\n",
    "\n",
    "Потому что очень **высокая зависимость предсказаний**. Выше видно, что два классификатора предсказывают абсолютно одинаково. Вероятность, что они делают это случайно, очень мала. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот если возьмем такие классификаторы, то все получится:\n",
    "    \n",
    "<font color=blue size=30>11111111</font><font color=red size=30>00</font> - 80% точность\n",
    "\n",
    "<font color=red size=30>0</font><font color=blue size=30>111</font><font color=red size=30>0</font><font color=blue size=30>111</font><font color=red size=30>0</font><font color=blue size=30>1</font> - 70% точность\n",
    "\n",
    "<font color=blue size=30>1</font><font color=red size=30>000</font><font color=blue size=30>1</font><font color=red size=30>0</font><font color=blue size=30>1111</font> - 60% точность\n",
    "\n",
    "\n",
    "Усреднение:\n",
    "\n",
    "<font color=blue size=30>11111111</font><font color=red size=30>0</font><font color=blue size=30>1</font> - 90% точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент: зависимость качества ансамбля от качества индивидуального предсказателя и от числа предсказателей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(Y_real, p, cnt):\n",
    "    size = Y_real.shape[0]\n",
    "    guessed = np.random.choice([True, False], (cnt, size), p=[p, 1-p])\n",
    "    Y = np.repeat(Y_real.reshape(1, -1), cnt, axis=0)\n",
    "    Y[~guessed] = 1 - Y[~guessed] \n",
    "    return Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "size = 1000\n",
    "reps = 10\n",
    "\n",
    "cnt_base_predictors = [1] + list(range(5, 105, 5))\n",
    "single_qual = [0.45, 0.5, 0.51, 0.55, 0.6, 0.75, 0.9]\n",
    "\n",
    "dt = {\"cnt\":[], \"single_qual\":[], \"accuracy\":[]}\n",
    "\n",
    "for i in range(reps):\n",
    "    Y_real = np.random.choice([0,1], size)\n",
    "    for cnt in cnt_base_predictors:\n",
    "        for p in single_qual:\n",
    "\n",
    "            preds = get_predictions(Y_real, p, cnt)\n",
    "            voting =  np.round(preds.mean(axis=0))\n",
    "            accuracy = (Y_real == voting).mean()\n",
    "            dt['cnt'].append(cnt)\n",
    "            dt['single_qual'].append(f\"{p:.02}\")\n",
    "            dt['accuracy'].append(accuracy)\n",
    "\n",
    "results = pd.DataFrame(dt)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "sns.lineplot(data=results, x='cnt', y='accuracy', hue='single_qual', lw=3, alpha=0.5)\n",
    "plt.xlabel(\"Number of base classifiers\", size=20)\n",
    "plt.ylabel(\"Accuracy\", size=20)\n",
    "plt.legend(loc='best', fontsize=12, title=\"Single classifier quality\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим:\n",
    "1. чем лучше базовый классификатор, тем меньше нужно классификаторов при прочих равных для достижения большего качества;\n",
    "2. если качество базового классификатора даже чуть больше 0.5, то качество ансамбля растет с увеличением числа моделей в ансамбле;\n",
    "3. если качество базового классификатора неотличимо от случайного (0.5), то качество ансамбля будет оставаться равным 0.5;\n",
    "4. если качество базового классификатора ниже случайного (0.5), то качество случайного классификатора стремится к 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент: коррелированность моделей \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как зависит качество предсказания от коррелированности предсказателей. Конкретно — от ожидаемой коррелированности вероятностей ошибиться на данном объекте для любой взятой пары классификаторов из ансамбля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def get_correlated_predictions(Y_real, p, cnt, r):\n",
    "    size = Y_real.shape[0]\n",
    "    x1 = np.random.uniform(0, 1, size)\n",
    "    x2 = np.random.uniform(0, 1, (cnt, size))\n",
    "    q = np.sqrt(r)\n",
    "    Y = q * x1 + (1 - q ** 2) ** 0.5 * x2 # Y variables now correlated with correlation=r \n",
    "    Y_mod = np.zeros_like(Y)\n",
    "    for i in range(Y.shape[0]):\n",
    "      Y_mod[i] = scipy.stats.rankdata(Y[i])\n",
    "\n",
    "    Y =  Y_mod / size # back to uniform, slightly affects correlations\n",
    "    \n",
    "    Y_pred = np.repeat(Y_real.reshape(1, -1), cnt, axis=0) \n",
    "    Y_pred[Y < 1-p ] = 1 - Y_pred[Y < 1-p ] # to predictions, affects correlations\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x = np.arange(0, 1, 0.05)\n",
    "accuracy = np.zeros_like(x)\n",
    "p = 0.7\n",
    "cnt = 100\n",
    "for ind, r in enumerate(x):\n",
    "    preds = get_correlated_predictions(Y_real, p, cnt, r)\n",
    "    voting =  np.round(preds.mean(axis=0))\n",
    "    accuracy[ind] =  (Y_real == voting).mean()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title(f\"Accuracy of {cnt} classifiers ensemble\", size=30)\n",
    "plt.xlabel(\"Correlation among classifiers\", size=25)\n",
    "plt.ylabel(\"Accuracy\",  size=25)\n",
    "plt.axhline(y=p, color='red', lw=5, ls='--', label=\"Single classifier\")\n",
    "sns.lineplot(x=x, y=accuracy, lw=5, label='Ensemble')\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что по мере увеличения коррелированности моделей, качество все больше и больше приближается к качеству одной базовой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging  = Bootstrap aggregation<a class=\"anchor\" style=\"autocontent\" id=\"Bagging--=-Bootstrap-aggregation\"/><br>\n",
    "Нам надо откуда-то брать классификаторы, которые сами по себе предсказывают лучше, чем случайное число, при этом они должны быть не коррелированы. На самом деле это нетривиальная задача: откуда нам брать классификаторы, учитывая, что у нас 1 датасет? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/bagging.png\" width=\"600\">\n",
    "\n",
    "Первый вариант — нам поможет уже рассмотренный bootstrap:\n",
    "\n",
    "1. Делаем из нашего исходного датасета N выборок такого же размера с повторениями. \n",
    "\n",
    "2. На каждой полученной выборке (обычно их называют **псевдовыборками**) строим отдельную модель. Чтобы полученным модели были слабо зависимы, будем использовать алгоритм, который чувствителен к небольшим изменениям в выборке. \n",
    "\n",
    "3. Получаем N слабо зависимых моделей. \n",
    "\n",
    "4. Когда нам нужно сделать предсказание для нового объекта, делаем предсказание каждой из N моделей, а затем усредняем предсказание. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn для bagging можно использовать класс BaggingClassifier из sklearn.ensemble. Мы напишем свой код для бэггинга для большей наглядности происходящего. Кроме того, это вам понадобится при выполнении заданий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем свой bagging<a class=\"anchor\" style=\"autocontent\" id=\"Пишем-свой-bagging\"/><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "def get_bootstrap_sample(X, Y):\n",
    "    size = X.shape[0]\n",
    "    poses = np.random.choice(size, \n",
    "                             size=size,\n",
    "                             replace=True)\n",
    "    X_boot = X[poses]\n",
    "    Y_boot = Y[poses]\n",
    "    return X_boot, Y_boot\n",
    "\n",
    "class BaggingBinaryClassifierEnsemble():\n",
    "    def __init__(self, base_classifier, ensemble_size, random_state=42):\n",
    "        self. base_classifier =  base_classifier\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.random_state = random_state\n",
    "        self.ensemble = []\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        np.random.seed(self.random_state)\n",
    "        for est_id in range(self.ensemble_size):\n",
    "            X_boot, Y_boot = get_bootstrap_sample(X, Y)\n",
    "            model = sklearn.clone(self.base_classifier) # create new base model\n",
    "            model.fit(X_boot, Y_boot)\n",
    "            self.ensemble.append(model)\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "        if not self.ensemble:\n",
    "            raise Exception(\"Unfitted model\")\n",
    "            \n",
    "        Y_pred = 0\n",
    "        for est in self.ensemble:\n",
    "            Y_pred += est.predict(X)\n",
    "        Y_pred = Y_pred / self.ensemble_size    \n",
    "        return Y_pred\n",
    "        \n",
    "    def predict(self, X):\n",
    "        Y_proba = self.predict_proba(X)\n",
    "        Y_pred = np.round(Y_proba)\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент1:  Классифицируем людей с больным сердцем и нет<a class=\"anchor\" style=\"autocontent\" id=\"Эксперимент1:--Классифицируем-людей-с-больным-сердцем-и-нет\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты здесь и далее будем использовать параметры моделей, подобранные ранее, когда мы использовали их вне ансамбля. В данном случае это не имеет значения, но в случае разбираемых далее случайного леса и градиентного бустинга, параметры подбирают **вместе** с построением ансамбля. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_dataset = pd.read_csv(\"https://edunet.kea.su/repo/EduNet-web_dependencies/L03/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = heart_dataset.drop(\"target\", axis=1)\n",
    "Y = heart_dataset['target'] > 0\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_model = GridSearchCV(SVC(), {'kernel':('linear',\n",
    "                                           'rbf'),\n",
    "                                 'C':[0.01, 0.1, 1, 10]}\n",
    "                         ).fit(X_train, Y_train)\n",
    "\n",
    "logr_model = GridSearchCV(LogisticRegression(solver='liblinear', max_iter=100000), \n",
    "                          {'penalty':('l1', \n",
    "                                      'l2'),\n",
    "                            'C':[0.01, 0.1, 1, 10, 100]}\n",
    "                          ).fit(X_train, Y_train)\n",
    "\n",
    "# few objects in the leaf - poor estimates of class probabilities - the model is overtraining \n",
    "dt_model = GridSearchCV(DecisionTreeClassifier(), \n",
    "                          {'max_depth':[1, 3, 5, 7, 10],\n",
    "                           'min_samples_leaf': [1, 3, 5, 10]}\n",
    "                        ).fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опробуем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_dt = BaggingBinaryClassifierEnsemble(dt_model.best_estimator_, \n",
    "                                            ensemble_size=100)\n",
    "\n",
    "bagging_logreg = BaggingBinaryClassifierEnsemble(logr_model.best_estimator_,\n",
    "                                                 ensemble_size=100)\n",
    "\n",
    "bagging_svc = BaggingBinaryClassifierEnsemble(svc_model.best_estimator_,\n",
    "                                              ensemble_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_dt.fit(X_train.values, Y_train.values)\n",
    "bagging_logreg.fit(X_train.values, Y_train.values)\n",
    "bagging_svc.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_blr = bagging_logreg.predict_proba(X_test.values)\n",
    "Y_pred_bsvc = bagging_svc.predict_proba(X_test.values)\n",
    "Y_pred_bdt = bagging_dt.predict_proba(X_test.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score # PR-AUC\n",
    "\n",
    "qual_blr = average_precision_score(y_true=Y_test, y_score=Y_pred_blr)\n",
    "qual_bsvc = average_precision_score(y_true=Y_test, y_score=Y_pred_bsvc)\n",
    "qual_bdt = average_precision_score(y_true=Y_test, y_score=Y_pred_bdt)\n",
    "print(f\"Bagged Logistic regression pr-auc: {qual_blr:.03f}\")\n",
    "print(f\"Bagged SVC pr-auc: {qual_bsvc :.03f}\")\n",
    "print(f\"Bagged DecisionTreeClassifier pr-auc: {qual_bdt:.03f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_metric(X, \n",
    "                     Y,\n",
    "                     metric_fn,\n",
    "                     samples_cnt = 1000,\n",
    "                     alpha = 0.05,\n",
    "                     random_state = 42):\n",
    "    size = len(X)\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    b_metric = np.zeros(samples_cnt)\n",
    "    for it in range(samples_cnt):\n",
    "        poses = np.random.choice(X.shape[0], size=X.shape[0], replace=True)\n",
    "        \n",
    "        X_boot = X[poses]\n",
    "        Y_boot = Y[poses]\n",
    "        \n",
    "        m_val = metric_fn(X_boot, Y_boot)\n",
    "        b_metric[it] = m_val\n",
    "    \n",
    "    return b_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_score_blogreg = bootstrap_metric(Y_test.values, \n",
    "                                   Y_pred_blr, \n",
    "                                   metric_fn=lambda X, Y: average_precision_score(y_true=X, \n",
    "                                                                                  y_score=Y))\n",
    "boot_score_bsvc = bootstrap_metric(Y_test.values,\n",
    "                                   Y_pred_bsvc ,\n",
    "                                   metric_fn=lambda X, Y: average_precision_score(y_true=X, \n",
    "                                                                                  y_score=Y))\n",
    "boot_score_bdt = bootstrap_metric(Y_test.values,\n",
    "                                   Y_pred_bdt,\n",
    "                                   metric_fn=lambda X, Y: average_precision_score(y_true=X, \n",
    "                                                                                  y_score=Y))\n",
    "alpha=0.10\n",
    "print(\"Bagged Logistic regression pr-auc 90%-ci: \", np.quantile(boot_score_blogreg, q=[alpha/2, 1 - alpha/2]))\n",
    "print(\"Bagged SVC pr-auc 90%-ci:\", np.quantile(boot_score_bsvc, q=[alpha/2, 1 - alpha/2]))\n",
    "print(\"Bagged DecisionTreeClassifier pr-auc 90%-ci:\", np.quantile(boot_score_bdt, q=[alpha/2, 1 - alpha/2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred1 = svc_model.decision_function(X_test) # by default, SVM gives score to each object instead of probabilities\n",
    "Y_pred2 = logr_model.predict_proba(X_test)[:, 1]\n",
    "Y_pred3 = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "qual1 = average_precision_score(y_true=Y_test, y_score=Y_pred1)\n",
    "qual2 = average_precision_score(y_true=Y_test, y_score=Y_pred2)\n",
    "qual3 = average_precision_score(y_true=Y_test, y_score=Y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_score_logreg = bootstrap_metric(Y_test.values, \n",
    "                                   Y_pred1, \n",
    "                                   metric_fn=lambda X, Y: average_precision_score(y_true=X, y_score=Y))\n",
    "boot_score_svc = bootstrap_metric(Y_test.values,\n",
    "                                   Y_pred2,\n",
    "                                   metric_fn=lambda X, Y: average_precision_score(y_true=X, y_score=Y))\n",
    "boot_score_dt = bootstrap_metric(Y_test.values,\n",
    "                                   Y_pred3,\n",
    "                                   metric_fn=lambda X, Y: average_precision_score(y_true=X, y_score=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(y=np.concatenate([boot_score_logreg,\n",
    "                              boot_score_svc, \n",
    "                              boot_score_dt, \n",
    "                              boot_score_blogreg,\n",
    "                              boot_score_bsvc,\n",
    "                              boot_score_bdt\n",
    "                             ]),\n",
    "             x=[\"Log-reg\"] * 1000 + ['SVC'] * 1000 + ['DT'] * 1000 + [\"Bagged Logreg\"] * 1000\\\n",
    "             + [\"Bagged SVC\"] * 1000 + [\"Bagged DT\"] * 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внезапно, мы видим, что главному аутсайдеру — дереву решений, в случае bagging удается побить все остальные решения и улучшить получить качество сравнимое, если не лучше, с качеством других базовых моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент2:  Сравним разделяющие плоскости дерева решений и бэггинга на деревьях решений<a class=\"anchor\" style=\"autocontent\" id=\"Эксперимент2:--Сравним-разделяющие-плоскости-дерева-решений-и-бэггинга-на-деревьях-решений\"/><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X, Y = sklearn.datasets.make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, Y, axes=[-1.5, 2.5, -1, 1.5], alpha=0.5, contour=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    Y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, Y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, Y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    plt.plot(X[:, 0][Y==0], X[:, 1][Y==0], \"yo\", alpha=alpha)\n",
    "    plt.plot(X[:, 0][Y==1], X[:, 1][Y==1], \"bs\", alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "clf = DecisionTreeClassifier(max_depth = 10, \n",
    "                             random_state = 42)\n",
    "clf.fit(X_train, Y_train)\n",
    "plot_decision_boundary(clf, X, Y)\n",
    "plt.title(\"Single Decision Tree\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "bagging_dt = BaggingBinaryClassifierEnsemble(DecisionTreeClassifier(max_depth=10), \n",
    "                                            ensemble_size=100)\n",
    "bagging_dt.fit(X_train, Y_train)\n",
    "plot_decision_boundary(bagging_dt, X, Y)\n",
    "plt.title(\"Bagged Decision Tree\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что разделяющая плоскость для дерева более гладкая и лучше отражает реальное разделение классов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого мы говорили (обсуждая bias-variance trade-off), что хорошо бы взять решающие границы большого числа деревьев,\n",
    "построенных на разных  тренировочных датасетах, полученных из генеральной совокупности, и усреднить эти границы, получив более хорошую решающую границу. К сожалению, мы не можем брать бесконечное число тренировочных датасетов. Но у нас есть бутстрэп. И он тоже достаточно хорошо аппроксимирует границу, которую мы бы получили, будь у нас много разных тренировочных датасетов:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Decision borders of DT trained on different train datasets\", fontsize=14)\n",
    "for i in range(100):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=i)\n",
    "    clf = DecisionTreeClassifier(max_depth = 20, random_state = 42)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    plot_decision_boundary(clf, X, Y, alpha=0.02, contour=False)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Decision borders of DT trained on different  bootstrap datasets\", fontsize=14)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)\n",
    "bagging_dt = BaggingBinaryClassifierEnsemble(DecisionTreeClassifier(max_depth=10), \n",
    "                                              ensemble_size=100, random_state=42)\n",
    "\n",
    "bagging_dt.fit(X_train, Y_train)\n",
    "\n",
    "for base_dt in bagging_dt.ensemble:\n",
    "    plot_decision_boundary(base_dt, X, Y, alpha=0.02, contour=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод случайных подпространств (RSM, random subspace method)<a class=\"anchor\" style=\"autocontent\" id=\"Метод-случайных-подпространств-(RSM,-random-subspace-method)\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй вариант получения псевдовыборок — мы можем сэмплировать не объекты, а признаки.  При этом бесполезно иметь в выборке два одинаковых признака, потом мы делаем выборки меньшего размера, чем исходное число признаков и без повторений. \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/random_subspace_method.png\" width=\"1100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно для каждой модели выбирают:\n",
    "\n",
    " для задач классификации:$$\\sqrt{feature\\_cnt}$$ для задач регрессии : $$ \\frac {feature\\_cnt} {3}$$  Хотя строгих правил нет, этот параметр можно подбирать на кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем свой RSM<a class=\"anchor\" style=\"autocontent\" id=\"Пишем-свой-RSM\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять же, напишем метод случайных подпространств сами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsm_sample(X, Y, f_num=None):\n",
    "    size = X.shape[1]\n",
    "    f_num = f_num or int(np.sqrt(size)) + 1 \n",
    "    f_num = min(size, f_num)\n",
    "    \n",
    "    f_poses = np.random.choice(size, \n",
    "                             size=f_num,\n",
    "                             replace=False)\n",
    "    X_rsm = X[:, f_poses]\n",
    "    Y_rsm = Y.copy()\n",
    "    return X_rsm, Y_rsm, f_poses\n",
    "\n",
    "class RSMBinaryClassifierEnsemble():\n",
    "    def __init__(self, base_classifier, ensemble_size, random_state=42, max_features=None):\n",
    "        self. base_classifier =  base_classifier\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.random_state = random_state\n",
    "        self.max_features = max_features\n",
    "        \n",
    "        self.ensemble = []\n",
    "        self.feature_poses = [] \n",
    "        # we had to keep track of features selected. In sklearn Random Forest, discussed below, \n",
    "        # another, more stable implementation is used.\n",
    "        # they use `f_num` random features but in case no good split found, they try other features too.  \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        np.random.seed(self.random_state)\n",
    "        for est_id in range(self.ensemble_size):\n",
    "            X_boot, Y_boot, f_poses = get_rsm_sample(X, Y, f_num=self.max_features)\n",
    "            self.feature_poses.append(f_poses)\n",
    "            model = sklearn.clone(self.base_classifier) # create new base model\n",
    "            model.fit(X_boot, Y_boot)\n",
    "            self.ensemble.append(model)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self.ensemble:\n",
    "            raise Exception(\"Unfitted model\")\n",
    "            \n",
    "        Y_pred = 0\n",
    "        for ind, est in enumerate(self.ensemble):\n",
    "            Y_pred += est.predict(X[:, self.feature_poses[ind]])\n",
    "        Y_pred = Y_pred / self.ensemble_size    \n",
    "        return Y_pred\n",
    "    \n",
    "        \n",
    "    def predict(self, X):\n",
    "        Y_proba = self.predict_proba(X)\n",
    "        Y_pred = np.round(Y_proba)\n",
    "        return Y_pred\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент1: Классифицируем людей с больным сердцем и нет<a class=\"anchor\" style=\"autocontent\" id=\"Эксперимент1:-Классифицируем-людей-с-больным-сердцем-и-нет\"/><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_dataset.drop(\"target\", axis=1)\n",
    "Y = heart_dataset['target'] > 0\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)\n",
    "\n",
    "rsm_dt = RSMBinaryClassifierEnsemble(dt_model.best_estimator_,\n",
    "                                     ensemble_size=100)\n",
    "\n",
    "rsm_logreg = RSMBinaryClassifierEnsemble(logr_model.best_estimator_,\n",
    "                                         ensemble_size=100)\n",
    "\n",
    "rsm_svc = RSMBinaryClassifierEnsemble(svc_model.best_estimator_,\n",
    "                                      ensemble_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsm_dt.fit(X_train.values, Y_train.values)\n",
    "rsm_logreg.fit(X_train.values, Y_train.values)\n",
    "rsm_svc.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_rlr = rsm_logreg.predict_proba(X_test.values)\n",
    "Y_pred_rsvc = rsm_svc.predict_proba(X_test.values)\n",
    "Y_pred_rdt = rsm_dt.predict_proba(X_test.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_score_rlogreg = bootstrap_metric(Y_test.values,\n",
    "                                      Y_pred_rlr,\n",
    "                                      metric_fn=lambda X, Y: \n",
    "                                      average_precision_score(y_true=X, y_score=Y))\n",
    "\n",
    "boot_score_rsvc = bootstrap_metric(Y_test.values,\n",
    "                                   Y_pred_rsvc ,\n",
    "                                   metric_fn=lambda X, Y:\n",
    "                                   average_precision_score(y_true=X, y_score=Y))\n",
    "\n",
    "boot_score_rdt = bootstrap_metric(Y_test.values,\n",
    "                                  Y_pred_rdt,\n",
    "                                  metric_fn=lambda X, Y: \n",
    "                                  average_precision_score(y_true=X, y_score=Y))\n",
    "\n",
    "alpha=0.10\n",
    "print(\"RSM Logistic regression pr-auc 90%-ci: \", np.quantile(boot_score_blogreg, q=[alpha/2, 1 - alpha/2]))\n",
    "print(\"RSM SVC pr-auc 90%-ci:\", np.quantile(boot_score_bsvc, q=[alpha/2, 1 - alpha/2]))\n",
    "print(\"RSM DecisionTreeClassifier pr-auc 90%-ci:\", np.quantile(boot_score_bdt, q=[alpha/2, 1 - alpha/2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(y=np.concatenate([boot_score_logreg,\n",
    "                              boot_score_svc, \n",
    "                              boot_score_dt, \n",
    "                              boot_score_blogreg,\n",
    "                              boot_score_bsvc,\n",
    "                              boot_score_bdt,\n",
    "                              boot_score_rlogreg,\n",
    "                              boot_score_rsvc,\n",
    "                              boot_score_rdt\n",
    "                             ]),\n",
    "             x=[x for x in  ('Log-reg', \n",
    "              'SVC',\n",
    "              'DT',\n",
    "              \"Bagged Logreg\", \n",
    "              \"Bagged SVC\", \n",
    "              \"Bagged DT\",\n",
    "              \"RSM Logreg\", \n",
    "              \"RSM SVC\", \n",
    "              \"RSM DT\") for y in range(1000)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять же, видим, что RSM помогает только дереву решений. Остальные методы не улучшают своего качества. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Комбинация RSM и Bagging<a class=\"anchor\" style=\"autocontent\" id=\"Комбинация-RSM-и-Bagging\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Можно объединить оба способа: применяем bootstrap к объектам (получается выборка одного размера, но с повторяющимися объектами, а каких-то объектов не будет), и, кроме этого, выкидываем часть признаков. Зачем это нужно? В этом случае мы получим еще более сильно отличающиеся друг от друга случайные выборки. \n",
    "\n",
    "sklearn.ensemble.BaggingClassifier и sklearn.ensemble.BaggingRegressor  вопреки названию может поддерживать оба способа.\n",
    "\n",
    "\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/rsm_and_bagging.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему для одних классов моделей работает, а для других - нет<a class=\"anchor\" style=\"autocontent\" id=\"Почему-для-одних-классов-моделей-работает,-а-для-других---нет\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь будем использовать BaggingClassier из стандартной библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "models = {}\n",
    "\n",
    "\n",
    "svc_model = GridSearchCV(SVC(), {'kernel':('linear', \n",
    "                                           'rbf'),\n",
    "                                 'C':[0.01, 0.1, 1, 10]}\n",
    "                         ).fit(X_train, Y_train)\n",
    "models['SVC'] = svc_model\n",
    "\n",
    "\n",
    "logr_model = GridSearchCV(LogisticRegression(solver='liblinear', max_iter=100000), \n",
    "                          {'penalty':('l1', \n",
    "                                      'l2'),\n",
    "                            'C':[0.01, 0.1, 1, 10, 100]}\n",
    "                          ).fit(X_train, Y_train)\n",
    "models['LogReg'] = logr_model\n",
    "\n",
    "# few objects in the leaf - poor estimates of class probabilities - the model is overtraining\n",
    "dt_model = GridSearchCV(DecisionTreeClassifier(), \n",
    "                          {'max_depth':[1, 3, 5, 7, 10],\n",
    "                           'min_samples_leaf': [1, 3, 5, 10]}\n",
    "                        ).fit(X_train, Y_train)\n",
    "models['DT'] = dt_model\n",
    "\n",
    "\n",
    "bagging_dt = BaggingClassifier(dt_model.best_estimator_, \n",
    "                               n_estimators=100,\n",
    "                               random_state=42)\n",
    "models[\"Bagging DT\"] = bagging_dt\n",
    "\n",
    "\n",
    "bagging_logr = BaggingClassifier(logr_model.best_estimator_, \n",
    "                                 n_estimators=100,\n",
    "                                 random_state=42)\n",
    "models[\"Bagging LogReg\"] = bagging_logr\n",
    "\n",
    "\n",
    "bagging_svc = BaggingClassifier(svc_model.best_estimator_,\n",
    "                                n_estimators=100,\n",
    "                                random_state=42)\n",
    "models[\"Bagging SVC\"] = bagging_svc \n",
    "\n",
    "\n",
    "sqrt_features = int(np.sqrt(X.shape[1])) + 1\n",
    "\n",
    "\n",
    "rsm_dt = BaggingClassifier(dt_model.best_estimator_, \n",
    "                           n_estimators=100, \n",
    "                           bootstrap=False,\n",
    "                           max_features=sqrt_features,\n",
    "                           random_state=42)\n",
    "models[\"RSM DT\"] =  rsm_dt\n",
    "\n",
    "\n",
    "rsm_logreg = BaggingClassifier(logr_model.best_estimator_,\n",
    "                               n_estimators=100,\n",
    "                               bootstrap=False,\n",
    "                               max_features=sqrt_features,\n",
    "                               random_state=42)\n",
    "models[\"RSM LogReg\"] = rsm_logreg\n",
    "\n",
    "\n",
    "rsm_svc = BaggingClassifier(svc_model.best_estimator_, \n",
    "                            n_estimators=100, \n",
    "                            bootstrap=False,\n",
    "                            max_features=sqrt_features,\n",
    "                            random_state=42)\n",
    "models[\"RSM SVC\"] = rsm_svc\n",
    "\n",
    "# Both Bagging and RSM \n",
    "bag_rsm_dt = BaggingClassifier(dt_model.best_estimator_, \n",
    "                               n_estimators=100, \n",
    "                               bootstrap=True,\n",
    "                               max_features=sqrt_features,\n",
    "                               random_state=42)\n",
    "models[\"BagRSM DT\"] = bag_rsm_dt\n",
    "\n",
    "\n",
    "bag_rsm_logreg = BaggingClassifier(logr_model.best_estimator_, \n",
    "                                   n_estimators=100, \n",
    "                                   bootstrap=True,\n",
    "                                   max_features=sqrt_features,\n",
    "                                   random_state=42)\n",
    "models[\"BagRSM LogReg\"] = bag_rsm_logreg\n",
    "\n",
    "\n",
    "bag_rsm_svc = BaggingClassifier(svc_model.best_estimator_, \n",
    "                                n_estimators=100, \n",
    "                                bootstrap=True,\n",
    "                                max_features=sqrt_features,\n",
    "                                random_state=42)\n",
    "models[\"BagRSM SVC\"] = bag_rsm_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainig models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name != \"SVC\":\n",
    "        Y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        Y_pred = model.decision_function(X_test)\n",
    "    predictions[name] = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_scores = {}\n",
    "\n",
    "for name, Y_pred in predictions.items():\n",
    "    boot_score = bootstrap_metric(Y_test.values, \n",
    "                                   Y_pred, \n",
    "                                   metric_fn=lambda X, Y:\n",
    "                                  average_precision_score(y_true=X, y_score=Y))\n",
    "    boot_scores[name] = boot_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(boot_scores)\n",
    "# cast to long format\n",
    "results = results.melt(value_vars=results.columns,\n",
    "                       value_name=\"prauc\", \n",
    "                       var_name=\"model\") \n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(data=results, y=\"prauc\", x=\"model\")\n",
    "plt.xlabel(\"model\", size=20)\n",
    "plt.ylabel(\"PR-AUC\", size=20)\n",
    "plt.title(\"Quality of different models\", size=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что, опять же, существенное улучшение качества наблюдается только, когда в качестве базовой модели мы используем дерево. \n",
    "\n",
    "Мы говорили о том, что важное требование того, чтобы простое голосование работало - чтобы ошибки моделей не коррелировали между собой. \n",
    "\n",
    "Попробуем оценить попарную корреляцию в ошибках базовых моделей в наших ансамблях. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def base_model_pair_correlation(ensemble, X):\n",
    "    corrs = []\n",
    "    for (i, est1), (j, est2) in itertools.combinations(enumerate(ensemble.estimators_), 2):\n",
    "        Xi_test = X.values[:, ensemble.estimators_features_[i]]\n",
    "        Xj_test = X.values[:, ensemble.estimators_features_[j]]\n",
    "        \n",
    "        \n",
    "        if not isinstance(est1, sklearn.svm.SVC): \n",
    "            Y_pred_t1 = est1.predict_proba(Xi_test)[:, 1]\n",
    "            \n",
    "            Y_pred_t2 = est2.predict_proba(Xj_test)[:, 1]\n",
    "        else:\n",
    "            Y_pred_t1 = est1.decision_function(Xi_test)\n",
    "            Xj_test = X_test.values[:, ensemble.estimators_features_[j]]\n",
    "            Y_pred_t2 = est2.decision_function(Xj_test)\n",
    "        corrs.append(scipy.stats.pearsonr(Y_pred_t1, Y_pred_t2)[0])\n",
    "    return np.array(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_correlations = {}\n",
    "for name, model in models.items():\n",
    "    if not \"Bagging\" in name and not \"RSM\" in name:\n",
    "        continue\n",
    "    pair_correlations[name] = base_model_pair_correlation(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_res = pd.DataFrame(pair_correlations)\n",
    "cor_res = cor_res.melt(value_vars=cor_res.columns,\n",
    "                       value_name=\"paircor\", \n",
    "                       var_name=\"model\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, давайте посчитаем качество базовых моделей, входящих в каждый из ансамблей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_prauc(ensemble, X, Y):\n",
    "    qual = np.zeros(ensemble.n_estimators)\n",
    "    for ind, est in enumerate(ensemble.estimators_):\n",
    "        X_test = X.values[:, ensemble.estimators_features_[i]]\n",
    "        if not isinstance(est, sklearn.svm.SVC):\n",
    "            Y_pred = est.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            Y_pred = est.decision_function(X_test)\n",
    "        qual[ind] = average_precision_score(y_score=Y_pred, y_true=Y)\n",
    "    return qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prauc = {}\n",
    "for name, model in models.items():\n",
    "    if not \"Bagging\" in name and not \"RSM\" in name:\n",
    "        continue\n",
    "    base_prauc[name] = base_model_prauc(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prauc_res = pd.DataFrame(base_prauc)\n",
    "base_prauc_res = base_prauc_res.melt(value_vars=base_prauc_res.columns,\n",
    "                       value_name=\"prauc\", \n",
    "                       var_name=\"model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.subplot(211)\n",
    "sns.boxplot(data=cor_res, y=\"paircor\", x=\"model\")\n",
    "plt.title(\"Pairwise correlations in ensembles\", size=30)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"Pairwise correlation\", size=20)\n",
    "\n",
    "plt.subplot(212)\n",
    "sns.boxplot(data=base_prauc_res, y=\"prauc\", x=\"model\")\n",
    "plt.title(\"Base model quality\", size=30)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"PR-AUC\", size=20)\n",
    "plt.subplots_adjust()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие можно сделать выводы из предложенных графиков?\n",
    "\n",
    "1. Bagging, RSM и их комбинация помогают уменьшать корреляцию между базовыми моделями. Причем, комбинация Bagging и RSM работают лучшее, чем каждый из них поодиночке;\n",
    "2. В случае просто Bagging дерево решений получает существенный прирост качества за счет того, что модели на его основе коррелированы значительно слабее, нежели модели на основе логистической регрессии и машины опорных векторов;\n",
    "3. В остальных случаях корреляция моделей на основе деревьев решений все равно немного ниже, чем у других моделей, при этом качество базовых моделей сравнимо. Из-за этого, опять же, ансамбль на основе дерева решений показывает лучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайный лес<a class=\"anchor\" style=\"autocontent\" id=\"Случайный-лес\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из предыдущей части мы увидели, что использование bagging или RSM для SVM или подобных моделей не несет большого смысла. \n",
    "\n",
    "И если использовать bagging или RSM для SVM, то значимого улучшения качества не будет. \n",
    "\n",
    "Но для деревьев решений это не так. Будем брать деревья большой глубины.  Незначительные изменения в данных приводят к значительным  изменениям в топологии таких деревьев. Таким образом, мы приходим к **случайному лесу** = Bagging + RSM над деревом решений.\n",
    "\n",
    "При этом RSM в классическом случайном лесе делается не на уровне дерева, а на уровне узла. В каждом узле дерева, когда мы выбираем лучшее разбиение его на два дочерних, мы просматриваем не все признаки, а только определенное их количество. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/random_forest.png\" width=\"700\">\n",
    "\n",
    "\n",
    "Обычно случайный лес работает лучше, чем отдельно случайно взятое дерево. Но главное - случайный лес намного более устойчив к шуму. \n",
    "Оказывается, что это свойство до сих пор позволяет случайному лесу успешно использоваться в областях с шумными данными. Например, в биологии. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зависимость качества случайного леса от числа деревьев<a class=\"anchor\" style=\"autocontent\" id=\"Зависимость-качества-случайного-леса-от-числа-деревьев\"/><br> \n",
    "Для случайного леса верно следующее: когда мы берем множество базовых классификаторов (в данном случае деревьев) и усредняем их, то результат этих усреднений стремится к идеальному дереву решений, причем построенному на идеальных, а не на исходных признаках. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, действительно ли это так. Для того, чтобы не пересчитывать случайный лес для каждого числа деревьев решений, обучим один случайный лес с 1000 деревьев решений, а леса с меньшим числом решений будем \n",
    "\n",
    "И будем работать для разнообразия — с задачей регрессии. Задача — предсказать цену на дом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calif_housing = sklearn.datasets.fetch_california_housing()\n",
    "X = calif_housing.data\n",
    "Y = calif_housing.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И напишем функцию, которая будет автоматически обучать переданные ей модели и считать для них качество на тесте. Чтобы избавиться от необходимости копировать код между ячейками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_and_test_regressor(models, X_train, Y_train, X_test, Y_test):\n",
    "    for name, model in models.items():\n",
    "        print(f\"Fitting {name}\")\n",
    "        model.fit(X_train, Y_train)\n",
    "    predictions = {}\n",
    "    for name, model in models.items():\n",
    "        Y_pred = model.predict(X_test)\n",
    "        predictions[name] = Y_pred\n",
    "        \n",
    "    boot_scores = {}\n",
    "\n",
    "    for name, Y_pred in predictions.items():\n",
    "        print(f\"Calculating bootstrap score for {name}\")\n",
    "        boot_score = bootstrap_metric(Y_test, \n",
    "                                       Y_pred, \n",
    "                                       metric_fn=lambda X, Y: mean_squared_error(y_true=X, \n",
    "                                                                                      y_pred=Y))\n",
    "        boot_scores[name] = boot_score\n",
    "        \n",
    "    \n",
    "    results = pd.DataFrame(boot_scores)\n",
    "    # cast to long format\n",
    "    results = results.melt(value_vars=results.columns,\n",
    "                       value_name=\"mse\", \n",
    "                       var_name=\"model\") \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "models_rf = {}\n",
    "\n",
    "models_rf['DT'] =  GridSearchCV(DecisionTreeRegressor(), \n",
    "                          {'max_depth':[1, 3, 5, 7, 10],\n",
    "                           'min_samples_leaf': [1, 3, 5, 10]} \n",
    "                     )# add single decision tree for comparison\n",
    "\n",
    "# this can be done faster, see warm_start parameter for this\n",
    "# (https://stackoverflow.com/questions/42757892/how-to-use-warm-start)\n",
    "for n_estimators in [3, 5, 10, 50, 100, 150, 250]:\n",
    "    models_rf[f\"RF{n_estimators}\"] = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                                           random_state=42, \n",
    "                                                           n_jobs=-1) # run in parallel\n",
    "\n",
    "# Trainig models\n",
    "results_rf = train_and_test_regressor(models_rf, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(data=results_rf, y=\"mse\", x=\"model\")\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Number of estimators vs MSE\", size=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что действительно, с какого-то момента число качество модели почти не изменяется, увеличение числа базовых классификаторов как минимум не ухудшает ее качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зависимость качества случайного леса от глубины дерева<a class=\"anchor\" style=\"autocontent\" id=\"Зависимость-качества-случайного-леса-от-глубины-дерева\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже обсуждали, что чем больше глубина дерева, тем большая нескорелированность базовых моделей будет получаться. По идее, в случайном лесе важно использовать именно глубокие деревья, причем, в большинстве случаев их глубину не надо ограничивать (или ограничивать большими значениями порядка 10-12). Проверим это. \n",
    "\n",
    "Кроме этого, будем добавлять кроме случайного леса с заданной глубиной еще одиночное дерево такой же глубины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models_depth = {}\n",
    "\n",
    "for depth in [1, 3, 5, 7, 9, 11, 13, None]:\n",
    "\n",
    "    models_depth[f\"DT_depth{depth}\"] = DecisionTreeRegressor(max_depth=depth,\n",
    "                                                             random_state=42)\n",
    "    \n",
    "    models_depth[f\"RF_depth{depth}\"] = RandomForestRegressor(n_estimators=100,\n",
    "                                                             max_depth=depth,\n",
    "                                                             random_state = 42, \n",
    "                                                             n_jobs=-1) # run in parallel\n",
    "\n",
    "# Trainig models\n",
    "results_depth = train_and_test_regressor(models_depth, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=results_depth, y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Depth vs MSE\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно, в данном случае модель без ограничения на глубину дерева показывает наилучшие результаты. \n",
    "Модель же с малой глубиной дерева работает сильно хуже. \n",
    "\n",
    "Качество случайного леса с малой глубиной дерева не отличается от качества одиночного дерева той же глубины. Опять же, деревья малой глубины слабо отличаются друг от друга, потому усреднение их предсказаний не дает почти никакого выигрыша.\n",
    "\n",
    "Стоит все же отметить, что в случае малых выборок, незначительные ограничения на глубину дерева могут дать выигрыш.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минимальное число объектов в листе<a class=\"anchor\" style=\"autocontent\" id=\"Минимальное-число-объектов-в-листе.\"/><br>\n",
    "Так же иногда качество дополнительно улучшается, если поставить небольшое ограничение на минимальное число объектов в листе, чтобы запретить явно переобученные деревья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_samples= {}\n",
    "\n",
    "for mn_sm in [1, 3, 5, 7, 10]:\n",
    "\n",
    "    models_min_samples[f\"DT_mnsamples{mn_sm}\"] = DecisionTreeRegressor(max_depth=None,\n",
    "                                                            min_samples_leaf=mn_sm,\n",
    "                                                            random_state=42)\n",
    "    \n",
    "    models_min_samples[f\"RF_mnsamples{mn_sm}\"] = RandomForestRegressor(n_estimators=100,\n",
    "                                                            max_depth=None,\n",
    "                                                            min_samples_leaf=mn_sm,\n",
    "                                                            random_state=42, \n",
    "                                                            n_jobs=-1) # run in parallel\n",
    "\n",
    "# Trainig models\n",
    "results_mn_samples = train_and_test_regressor( models_min_samples, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=results_mn_samples, y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Min samples in leaf vs MSE\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае, однако, мы это не наблюдаем. Более того, опять же, с увеличением числа ограничений на дерево, падает непохожесть деревьев друг на друга и качество случайного леса так же начинает падать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучается ли случайный лес?<a class=\"anchor\" style=\"autocontent\" id=\"Переобучается-ли-случайный-лес?\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует мнение, что случайный лес не переобучается. Это не так. Можно подобрать такие два набора параметров, что первый дает лучше качество на тренировочной выборке, а второй — на тестовой. При этом увеличение числа деревьев в ансамбле с этим справиться поможет слабо.\n",
    "\n",
    "Возьмем, к примеру, наш игрушечный пример на плоскости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, Y = sklearn.datasets.make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth = 10, random_state = 42)\n",
    "clf.fit(X_train, Y_train)\n",
    "plot_decision_boundary(clf, X, Y)\n",
    "plt.title(\"Single Decision Tree\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "rf = RandomForestClassifier(n_estimators=1000) \n",
    "rf.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf, X, Y)\n",
    "plt.title(\"Random forest\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, видны области, в которых случайный лес переобучился.\n",
    "\n",
    "Добавление ограничения на число объектов в листьях улучшает ситуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "rf1 = RandomForestClassifier(n_estimators=1000) \n",
    "rf1.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf1, X, Y)\n",
    "plt.title(\"Random forest\", fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "rf2 = RandomForestClassifier(n_estimators=1000, min_samples_leaf=5) \n",
    "rf2.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf2, X, Y)\n",
    "plt.title(\"Random forest, min_samples_leaf=5\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним качество на трейне — у первого леса оно больше, в то время как на тесте лучше качество у второго дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_score = rf1.predict(X_train)\n",
    "q = average_precision_score(y_true=Y_train, y_score=Y_score)\n",
    "print(f\"RF1 Train: {q:.02}\")\n",
    "Y_score = rf1.predict(X_test)\n",
    "q = average_precision_score(y_true=Y_test, y_score=Y_score)\n",
    "print(f\"RF1 Test: {q:.02}\")\n",
    "      \n",
    "Y_score = rf2.predict(X_train)\n",
    "q = average_precision_score(y_true=Y_train, y_score=Y_score)\n",
    "print(f\"RF2 Train: {q:.02}\")\n",
    "Y_score = rf2.predict(X_test)\n",
    "q = average_precision_score(y_true=Y_test, y_score=Y_score)\n",
    "print(f\"RF2 Test: {q:.02}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес и bias-variance tradeoff<a class=\"anchor\" style=\"autocontent\" id=\"Случайный-лес-и-variance\"/><br>\n",
    "Случайный лес - инструмент для уменьшения variance нашей модели. Можно показать, что при стремлении числа моделей в ансамбле к бесконечности, а их коррелированности - к 0, variance ансамбля стремится к нулю. Однако при этом bias ансамбля будет равен bias базовой модели \n",
    "\n",
    "Продемонстрируем это"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(241)\n",
    "dt1 = DecisionTreeClassifier(max_depth=1) \n",
    "dt1.fit(X_train, Y_train)\n",
    "plot_decision_boundary(dt1, X, Y)\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.title(\"Decision tree, max_depth=1\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(242)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3) \n",
    "dt3.fit(X_train, Y_train)\n",
    "plot_decision_boundary(dt3, X, Y)\n",
    "plt.title(\"Decision tree, max_depth=3\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(243)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5) \n",
    "dt5.fit(X_train, Y_train)\n",
    "plot_decision_boundary(dt5, X, Y)\n",
    "plt.title(\"Decision tree, max_depth=5\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(244)\n",
    "dt12 = DecisionTreeClassifier(max_depth=12) \n",
    "dt12.fit(X_train, Y_train)\n",
    "plot_decision_boundary(dt12, X, Y)\n",
    "plt.title(\"Decision tree, max_depth=12\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(245)\n",
    "rf1 = RandomForestClassifier(max_depth=1, n_estimators=500, n_jobs=-1) \n",
    "rf1.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf1, X, Y)\n",
    "plt.title(\"Random forest, max_depth=1\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(246)\n",
    "rf3 = RandomForestClassifier(max_depth=3, n_estimators=500, n_jobs=-1) \n",
    "rf3.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf3, X, Y)\n",
    "plt.title(\"Random forest, max_depth=3\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(247)\n",
    "rf5 = RandomForestClassifier(max_depth=5, n_estimators=500, n_jobs=-1) \n",
    "rf5.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf5, X, Y)\n",
    "plt.title(\"Random forest, max_depth=5\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(248)\n",
    "rf12 = RandomForestClassifier(max_depth=12, n_estimators=500, n_jobs=-1) \n",
    "rf12.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf12, X, Y)\n",
    "plt.title(\"Random forest, max_depth=12\", fontsize=14)\n",
    "plt.subplots_adjust()\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что общая сложность решающей границы меняется не сильно - bias случайного леса по сравнению с bias дерева решений не меняется. \n",
    "А вот гладкость границы увеличивается, тем самым, уменьшается variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    " <font size=\"5\">Взвешенное голосование</font>\n",
    "\n",
    "$$ h(x) = \\sum_i b_i a_i (x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/weighted_voting.png\" width=\"500\">\n",
    "\n",
    "\n",
    "Не все модели предсказывают что-то одинаково хорошо. В случайном лесе у нас были деревья решений, которые мы обучали на равнозначных выборках, поэтому могли усреднять их предсказания. \n",
    "\n",
    "Теперь представим, что у нас есть нейросеть, которую мы обучали на огромной выборке, есть линейная модель, которую мы учили на 200 объектах, есть случайный лес, который мы учили на выборке с множеством пропущенных признаков. Очевидно, что эти модели будут давать разное качество. \n",
    "\n",
    "Разумно эти модели учитывать с каким-то весом класса. На основе этого построен метод под названием boosting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Вы наверняка слышали о нем, потому что градиентный boosting — предмет большого количества мемов про машинное обучение, потому что он помогает получить решение, которое сложно побить другими видами моделей.\n",
    "\n",
    "В то время как случайный лес представлял собой попытку стрелять по мишени много раз в надежде, что в среднем мы попадем в нее, идея бустинга больше похожа на игру в гольф. Пусть каждая модель будет представлять собой один слабенький удар клюшкой. А последующие удары — будут корректировать результаты этого удара, постепенно приближаясь к лунке. \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/boosting_advantages.jpg\" width=\"900\">\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг позволяет нам на основе большого числа слабых моделей получить одну сильную. Опять же, в качестве модели используется дерево решений, но не большой высоты, а наоборот, маленькой. Чтобы оно само по себе в принципе не могло выучить выборку хорошо. \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/join_weak_learners.png\" width=\"500\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель i-й модели в ансамбле — скорректировать ошибки предыдущих i-1 моделей. В результате, когда мы суммируем вклады всех моделей ансамбля, получается хорошее предсказание.\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/summarize_predictions_of_ensemble_models.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost \n",
    "(Freund & Schapire, 1996)\n",
    "\n",
    "Первый бустинг был предложен Фреундом и назывался AdaBoost. На нем легче всего объяснить всю идею бустинга.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть выборка (плюсы и минусы). Мы хотим различать их между собой. Назначим вес каждому плюсу и минусу. Важно классифицировать их одинаково, поэтому их вес=1÷N, где N — число (суммарный объект).\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/adaboost_classification.png\" width=\"200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим первый предсказатель. \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/adaboost_first_iteration.png\" width=\"150\">\n",
    "\n",
    "Он классифицировал объекты плохо, но лучше, чем если бы он это делал случайно. Некоторые объекты он определил верно, а на некоторых (три плюса) ошибся. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда мы скажем, что эти плюсы важнее, чем все остальное, потому что на них мы уже научились всё предсказывать. \n",
    "Дальше обучим еще одну модель на той же выборке, но скажем, что эти плюсы важнее, чем все остальное объекты.\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/adaboost_add_weight_second_iteration.png\" width=\"150\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Новая модель будет ошибаться уже на минусах. Добавляем веса этим минусам. \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/adaboost_add_weight_third_iteration.png\" width=\"150\">\n",
    "\n",
    "Строим еще один классификатор, который правильно классифицирует важные для нас объекты, а на неважные не обращают внимания. Получилось три классификатора, которые по-разному ошибаются на обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но если сложить эти классификаторы с правильными весами, которые можно подсчитать по специальной формуле, то полученная модель будет решать нашу задачу классификации идеально.\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/adaboost_summarize_all_iterations.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Переобучается ли AdaBoost?<a class=\"anchor\" style=\"autocontent\" id=\"Переобучается-ли-AdaBoost?\"/><br>\n",
    "Сложился миф о том, что он не переобучается. На самом деле это нет так, просто когда он появился, для переобучения не хватало вычислительных мощностей (нужно сделать много итераций, чтобы переобучение увидеть).\n",
    "\n",
    "Но у него было интересное свойство, которое унаследовали все последующие бустинги: вы можете идеально выучить обучающую выборку, но при этом вы добавляете новые деревья, и качество на тестовой выборке становится лучше. Это обусловлено тем, что каждое последующее дерево, которое мы добавляем, уточняет границу разделения, делает ее более плавной, и это зачастую помогает нашему классификатору. \n",
    "\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/adaboost_overfitting.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применимость AdaBoost<a class=\"anchor\" style=\"autocontent\" id=\"Применимость-AdaBoost\"/><br>\n",
    "AdaBoost реализован в sklearn и он может использовать в качестве базовой любую модель, которая умеет работать с весами объектов в выборке. \n",
    "\n",
    "На данный момент, тем не менее, AdaBoost уступил место градиентному бустингу и почти не используется. \n",
    "Мы обсудили его в образовательных целях — на нем легче всего понять основную идею бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting (градиентный бустинг)<a class=\"anchor\" style=\"autocontent\" id=\"Gradient-boosting-(градиентный-бустинг)\"/><br>\n",
    "\n",
    "Создатель продолжения AdaBoost — градиентного бустинга —  Leo Breiman заметил, что бустинг можно рассматривать как итеративную минимизацию некой целевой функции ошибки. \n",
    "\n",
    "Как нейронные сети в ходе своего обучения, так и бустинг (с помощью добавленных слабых моделей) минимизируют функции ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/gradient_boosting.png\" width=\"450\">\n",
    "\n",
    "\n",
    "Как он их минимизирует? Точно так же, как нейронная сеть. Он использует градиентный спуск. \n",
    "Можно сделать следующее: у нас есть исходное приближение. Мы как-то ошибаемся. Считаем градиент ошибки, дальше пытаемся его аппроксимировать. Делаем новое приближение. Опять как-то ошибаемся — и повторяем все еще и еще. \n",
    "\n",
    "Для объекта из тестовой выборки:\n",
    "\n",
    " 1. Первая модель обеспечивает нам исходное приближение.\n",
    " 2. Вторая модель пытается предсказать градиент ошибки. Зная градиент ошибки для тестового объекта, мы можем эту ошибку уменьшить, получив новое приближение.\n",
    " 3. Третья модель пытается предсказать градиент ошибки нового приближения. Опять, зная его, можем получить еще одно, более точное приближение.\n",
    " 4. Повторяем, пока не пройдем все N моделей.\n",
    "\n",
    "Оказывается, такой подход позволяет достигать state-of-the art результатов при работе с табличными данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, запустим градиентный бустинг \"почти\" наугад:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = calif_housing.data\n",
    "Y = calif_housing.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "models = {}\n",
    "models['RF'] = RandomForestRegressor(n_estimators=250,  # for better result set to 1000\n",
    "                                     max_depth=None, \n",
    "                                     min_samples_leaf=1, \n",
    "                                     n_jobs=-1, \n",
    "                                     random_state=42)\n",
    "# make pipeline to normalization\n",
    "models['LinReg'] = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "models['GradientBoostingRegressor'] = GradientBoostingRegressor(learning_rate=0.1, # for better result set to 0.05\n",
    "                                                                n_estimators=250, # for better result set to 1000\n",
    "                                                                random_state=42)\n",
    "\n",
    "# Training models\n",
    "results_boost = train_and_test_regressor(models, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "ax = sns.boxplot(data=results_boost , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"RF vs LR vs GB\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что сходу мы побили случайный лес и линейную регрессию. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучение<a class=\"anchor\" style=\"autocontent\" id=\"Переобучение\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В то же время, **Gradient boosting**, в отличие от случайного леса, может сильно переобучиться. Это важно понимать. Для небольших датасетов часто может оказаться, что случайный лес дает более надежные результаты. \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/gradient_boosting_overfitting.png\" width=\"600\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree = GradientBoostingRegressor(n_estimators=300, \n",
    "                                   learning_rate=1 # faster learning rate to force ovefitting\n",
    "                                   )\n",
    "gbtree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем метод, который есть во многих реализациях бустинга в том или ином виде — staged_predict, который получать предсказание от первых i деревьев ансамбля, что позволяет быстро строить график качества градиентного бустинга в зависимости от числа базовых моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train = []\n",
    "error_test = []\n",
    "for it, (Y_train_pred, Y_test_pred) in enumerate(zip(gbtree.staged_predict(X_train), \n",
    "                                                     gbtree.staged_predict(X_test))):\n",
    "    ertr = mean_squared_error(y_true=Y_train, y_pred=Y_train_pred)\n",
    "    error_train.append(ertr)\n",
    "    erte = mean_squared_error(y_true=Y_test, y_pred=Y_test_pred)\n",
    "    error_test.append(erte)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(error_train, label='train')\n",
    "plt.plot(error_test, label='test')\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы *немного* схитрили, сильно увеличив learning rate нашей модели — дополнительный множитель к весу, с которым добавляются в нее новые модели. Из-за этого даже на таком простом датасете мы в состоянии увидеть явное переобучение. \n",
    "\n",
    "Давайте об этом learning rate и поговорим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Shrinkage (learning rate)<a class=\"anchor\" style=\"autocontent\" id=\"Shrinkage-(learning-rate)\"/><br>\n",
    "\n",
    "Как у градиентного спуска есть learning rate, который определяет силу каждого нашего следующего шага,  так и у градиентного бустинга есть параметр, который называется shrinkage или learning rate — это дополнительный параметр, на который мы домножаем вес, с которым мы добавляем новые модели в ансамбль. \n",
    "\n",
    "\n",
    "Мы не хотим сильно скакать по пространству решений, мы хотим спускаться медленно и сойтись к какому-то хорошему минимуму. Потому мы берем и вес каждой модели, которую мы рассчитываем по специальному алгоритму, еще домножаем на маленький коэффициент, который называется shrinkage или learning rate. Фактически, мы берем и умножаем градиент на некий альфа (это то же, что было в градиентном спуске, ничего нового мы не добавили).\n",
    "\n",
    "Если не домножать вес каждой модели дополнительно на этот параметр, то мы можем попасть в ситуацию, которая будем пролетать мимо минимума функции ошибки (та же опасность, что и в обычном градиентном спуске).\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/shrinkage_learning_rate_for_gradient_boosting.png\" width=\"500\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае с градиентным спуском, **learning rate** влияет не только на то, как быстро мы станем переобучаться, но и на глубину минимума, который мы найдем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here anb below in the cell can be set to 1000 for better visualization\n",
    "gbtree1 = GradientBoostingRegressor(n_estimators=500, learning_rate=1)\n",
    "gbtree1.fit(X_train, Y_train)\n",
    "\n",
    "gbtree2 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.5)\n",
    "gbtree2.fit(X_train, Y_train)\n",
    "\n",
    "gbtree3 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.1)\n",
    "gbtree3.fit(X_train, Y_train)\n",
    "\n",
    "gbtree4 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.05)\n",
    "gbtree4.fit(X_train, Y_train)\n",
    "\n",
    "gbtree5 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.01)\n",
    "gbtree5.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = []\n",
    "step = []\n",
    "mse = []\n",
    "for gb_tree in (gbtree1, gbtree2, gbtree3, gbtree4, gbtree5):\n",
    "    \n",
    "    for it, Y_test_pred in enumerate(gb_tree.staged_predict(X_test)):\n",
    "\n",
    "        erte = mean_squared_error(y_true=Y_test, y_pred=Y_test_pred)\n",
    "        mse.append(erte)\n",
    "        lr.append(str(gb_tree.learning_rate))\n",
    "        step.append(it)\n",
    "\n",
    "df = pd.DataFrame({\"learning_rate\":lr, \n",
    "                   \"n_estimators\": step,\n",
    "                   \"mse\": mse})\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.lineplot(data=df, x='n_estimators', y='mse', hue='learning_rate', lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае мы видим, что значение learning rate, установленного по умолчанию, позволяет получить наименьшую ошибку на валидации. \n",
    "В то же время слишком большие значения learning rate (1 и 0.5) приводят к тому, что мы не достигаем таких глубоких минимумов и, более того, начинаем переобучаться. \n",
    "При этом слишком маленькое значение learning rate может привести к тому, что нам понадобится очень большое число деревьев, чтобы достигнуть минимума (если мы его вообще достигнем)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Число деревьев в ансамбле<a class=\"anchor\" style=\"autocontent\" id=\"Число-деревьев-в-ансамбле\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число деревьев, как было видно из предыдущего графика, зависит от установленного learning rate. \n",
    "Потому обычно ставят learning_rate равным 0.1 и подбирают оптимальное значение числа деревьев в ансамбле.\n",
    "Делают это на кросс-валидации, но для экономии времени просто дополнительно разобьем train датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_learn, X_valid, Y_learn, Y_valid = train_test_split(X_train, Y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1)\n",
    "gbtree.fit(X_learn, Y_learn)\n",
    "\n",
    "error_train = []\n",
    "error_test = []\n",
    "for it, (Y_learn_pred, Y_valid_pred) in enumerate(zip(gbtree.staged_predict(X_learn), \n",
    "                                                     gbtree.staged_predict(X_valid))):\n",
    "    ertr = mean_squared_error(y_true=Y_learn, y_pred=Y_learn_pred)\n",
    "    error_train.append(ertr)\n",
    "    erte = mean_squared_error(y_true=Y_valid, y_pred=Y_valid_pred)\n",
    "    error_test.append(erte)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(error_train, label='train')\n",
    "plt.plot(error_test, label='test')\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что ошибка продолжает медленно уменьшаться, но в принципе увеличение идет очень маленькое, потому в целях  демонстрации выберем число деревьев равным 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Глубина деревьев в градиентном бустинге<a class=\"anchor\" style=\"autocontent\" id=\"Глубина-деревьев-в-градиентном-бустинге\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае бустинга нам нужны **слабые модели**. Потому очень глубокие деревья в бустинге встречаются редко — бустинг с ними проиграет по качеству. \n",
    "Обычно глубина дерева выбирается вместе с минимальным числом объектов в листе (min_samples_leaf) или весе листа (min_weight_fraction_leaf), так как эти параметры взаимосвязаны и вместе влияют на сложность полученных деревьев.\n",
    "Здесь же, опять, в целях демонстрации мы подберем сначала глубину дерева, а потом минимальное число объектов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for depth in (1, 2, 3, 5, 10): \n",
    "    models[f\"GB_depth{depth}\"] = GradientBoostingRegressor(n_estimators=500, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth=depth, \n",
    "                                   random_state=42)\n",
    "\n",
    "# Train model\n",
    "depth_boost = train_and_test_regressor(models, X_learn, Y_learn, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=depth_boost , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"GB depth\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Искомая глубина находится между 3 и 10. Проверим 4, 6 и 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_add = {}\n",
    "for depth in (4, 6, 7): \n",
    "    models_add[f\"GB_depth{depth}\"] = GradientBoostingRegressor(n_estimators=500,\n",
    "                                    learning_rate=0.1, \n",
    "                                    max_depth=depth, \n",
    "                                    random_state=42)\n",
    "\n",
    "# Train model\n",
    "depth_boost_add = train_and_test_regressor(models_add, X_learn, Y_learn, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_boost_joined = pd.concat([depth_boost, depth_boost_add])\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=depth_boost_joined , y=\"mse\", x=\"model\", order=[f\"GB_depth{i}\" for i in (1, 2, 3, 5, 6, 7, 10)])\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"GB depth\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значит, оптимальная глубина — 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минимальное число объектов в листе<a class=\"anchor\" style=\"autocontent\" id=\"Минимальное-число-объектов-в-листе\"/><br>\n",
    "Опять же, этот параметр влияет на сложность полученных деревьев. Как уже отмечалось ранее, стоит подбирать его вместе с глубиной, но мы ограничены по времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for min_samples_leaf in (1, 3, 5, 7, 9, 11): \n",
    "    models[f\"GB_mns{min_samples_leaf}\"] = GradientBoostingRegressor(n_estimators=500, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth=5, \n",
    "                                   min_samples_leaf=min_samples_leaf, \n",
    "                                   random_state=42)\n",
    "\n",
    "# Train model\n",
    "mns_boost = train_and_test_regressor(models, X_learn, Y_learn, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=mns_boost , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"GB min samples leaf\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставим число объектов в листе равное 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling-and-max_features-and-max_features and max_features <a class=\"anchor\" style=\"autocontent\" id=\"Subsampling-and-max_features-and-max_features\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно каждому дереву в ансамбле давать только часть объектов из выборки — получим стохастический градиентный бустинг. За это отвечает параметр subsample. \n",
    "Аналогично, можно давать каждому дереву в ансамбле лишь часть признаков — max_features.\n",
    "Это может давать дополнительный прирост качества. Сейчас мы этот этап опускаем, так как у нас мало признаков и не очень много объектов, а также в целях экономии времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/subsampling_and_max_features.png\" width=\"900\">\n",
    "\n",
    "\n",
    "Кроме того, мы можем каждое дерево еще немножко рандомизировать. Можем давать ему не всю выборку, не все признаки. Это работает не всегда, гиперпараметры, контролирующие это поведение, нужно подбирать. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Понижение learning rate<a class=\"anchor\" style=\"autocontent\" id=\"Понижение-learning-rate\"/><br>\n",
    "После того, как мы подобрали остальные параметры, можно попытаться выиграть дополнительное качество за счет понижения learning_rate и одновременное увеличение числа деревьев ансамбля. \n",
    "\n",
    "Опять же, этот этап пропустим.\n",
    "\n",
    "Построим график качества для текущего learning rate — мы же брали не оптимальное число предсказателей, посмотрим, можно ли уже на финальном этапе взять побольше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree = GradientBoostingRegressor(n_estimators=1000,\n",
    "                                   max_depth=5,\n",
    "                                   min_samples_leaf=9,\n",
    "                                   learning_rate=0.1,\n",
    "                                   random_state=42)\n",
    "gbtree.fit(X_learn, Y_learn)\n",
    "\n",
    "error_train = []\n",
    "error_test = []\n",
    "for it, (Y_learn_pred, Y_valid_pred) in enumerate(zip(gbtree.staged_predict(X_learn), \n",
    "                                                     gbtree.staged_predict(X_valid))):\n",
    "    ertr = mean_squared_error(y_true=Y_learn, y_pred=Y_learn_pred)\n",
    "    error_train.append(ertr)\n",
    "    erte = mean_squared_error(y_true=Y_valid, y_pred=Y_valid_pred)\n",
    "    error_test.append(erte)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(error_train, label='train')\n",
    "plt.plot(error_test, label='test')\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ок, возьмем 500 деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "models['RF'] = RandomForestRegressor(n_estimators=250, \n",
    "                                     max_depth=None, \n",
    "                                     min_samples_leaf=1, \n",
    "                                     n_jobs=-1, \n",
    "                                     random_state=42)\n",
    "\n",
    "models['LinReg'] = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "\n",
    "models['GBR'] = GradientBoostingRegressor(learning_rate=0.1, \n",
    "                                          n_estimators=250, \n",
    "                                          random_state=42)\n",
    "\n",
    "models['GBR tuned'] = GradientBoostingRegressor(learning_rate=0.1, \n",
    "                                                n_estimators=500, \n",
    "                                                max_depth=5,\n",
    "                                                min_samples_leaf=9,\n",
    "                                                random_state=42)\n",
    "\n",
    "# Train models\n",
    "tuned_boost = train_and_test_regressor(models, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=tuned_boost , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что мы дополнительно уменьшили ошибку нашего метода "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг и bias-variance tradeoff\n",
    "\n",
    "В то время как случайный лес только уменьшал variance модели, бустинг стремится уменьшить и bias, и variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X, Y = sklearn.datasets.make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.subplot(341)\n",
    "dt1 = DecisionTreeClassifier(max_depth=1) \n",
    "dt1.fit(X_train, Y_train)\n",
    "plot_decision_boundary(dt1, X, Y)\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.title(\"Decision tree, max_depth=1\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(342)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3) \n",
    "dt3.fit(X_train, Y_train)\n",
    "plot_decision_boundary(dt3, X, Y)\n",
    "plt.title(\"Decision tree, max_depth=3\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(343)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5) \n",
    "dt5.fit(X_train, Y_train)\n",
    "plot_decision_boundary(dt5, X, Y)\n",
    "plt.title(\"Decision tree, max_depth=5\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(344)\n",
    "dt12 = DecisionTreeClassifier(max_depth=12) \n",
    "dt12.fit(X_train, Y_train)\n",
    "plot_decision_boundary(dt12, X, Y)\n",
    "plt.title(\"Decision tree, max_depth=12\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(345)\n",
    "rf1 = RandomForestClassifier(max_depth=1, n_estimators=500, n_jobs=-1) \n",
    "rf1.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf1, X, Y)\n",
    "plt.title(\"Random forest, max_depth=1\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(346)\n",
    "rf3 = RandomForestClassifier(max_depth=3, n_estimators=500, n_jobs=-1) \n",
    "rf3.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf3, X, Y)\n",
    "plt.title(\"Random forest, max_depth=3\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(347)\n",
    "rf5 = RandomForestClassifier(max_depth=5, n_estimators=500, n_jobs=-1) \n",
    "rf5.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf5, X, Y)\n",
    "plt.title(\"Random forest, max_depth=5\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(348)\n",
    "rf12 = RandomForestClassifier(max_depth=5, n_estimators=500, n_jobs=-1) \n",
    "rf12.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf12, X, Y)\n",
    "plt.title(\"Decision tree, max_depth=12\", fontsize=14)\n",
    "plt.subplots_adjust()\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(349)\n",
    "boost1 = GradientBoostingClassifier(max_depth=1, n_estimators=250)\n",
    "boost1.fit(X_train, Y_train)\n",
    "plot_decision_boundary(boost1, X, Y)\n",
    "plt.title(\"Gradient boosting, max_depth=1\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(3, 4, 10)\n",
    "boost3 =  GradientBoostingClassifier(max_depth=3, n_estimators=250) \n",
    "boost3.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf3, X, Y)\n",
    "plt.title(\"Gradient boosting, max_depth=3\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(3, 4, 11)\n",
    "boost5 =  GradientBoostingClassifier(max_depth=5, n_estimators=250) \n",
    "boost5.fit(X_train, Y_train)\n",
    "plot_decision_boundary(rf5, X, Y)\n",
    "plt.title(\"Gradient boosting, max_depth=5\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.subplot(3, 4, 12)\n",
    "boost12 =  GradientBoostingClassifier(max_depth=5, n_estimators=250) \n",
    "boost12.fit(X_train, Y_train)\n",
    "plot_decision_boundary(boost12, X, Y)\n",
    "plt.title(\"Gradient boosting, max_depth=12\", fontsize=14)\n",
    "plt.subplots_adjust()\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модификации градиентного бустинга<a class=\"anchor\" style=\"autocontent\" id=\"Модификации-градиентного-бустинга\"/><br>\n",
    "\n",
    "Есть много модификаций градиентного бустинга. В отличие от реализации в sklearn, большая часть из них умеет параллелиться на CPU или даже на GPU. \n",
    "\n",
    "Потому при работе с реальными данными использовать градиентный бустинг из sklearn не стоит. XGBoost и/или LigthGBM дадут результат как правило лучше и быстрее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost<a class=\"anchor\" style=\"autocontent\" id=\"XGBoost\"/><br>\n",
    "Мы хотим спускаться медленно и не хотим, чтобы модели по пути были сложными. Пусть минимально отличающиеся от случайного, но при этом не очень сложными. \n",
    "\n",
    "Поэтому XGBoost вводит специальный штраф за сложные деревья (большей глубины, чем 2 — 3). За счет того, что в градиентном бустинге можно минимизировать любую дифференцируемую функцию ошибок, мы просто добавляем штраф напрямую в функцию ошибок исходного градиентного бустинга.\n",
    "\n",
    "**Компромисс между функцией потерь и регуляризатором**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/xgboost.png\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calif_housing = sklearn.datasets.fetch_california_housing()\n",
    "X = calif_housing.data\n",
    "Y = calif_housing.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопируем параметры, которые совпадают между градиентным бустингом и XGBoost. Посмотрим, вдруг получится еще улучшить качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "models_add = {}\n",
    "models_add['xgb'] = xgboost.XGBRegressor(n_estimators=500,  \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=5, \n",
    "                     random_state=42,\n",
    "                     min_child_weight=9, # not exact analogue for min_samples_leaf\n",
    "                     n_jobs=-1, # can be constructed in parrallel, much!!! faster) \n",
    "                     objective ='reg:squarederror') \n",
    "\n",
    "# Train models\n",
    "xgb_add = train_and_test_regressor(models_add, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=pd.concat([tuned_boost, xgb_add]) , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть и незначимо, но xgboost с полоборота лучше GBR. И, главное — в разы быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min_child_weight<a class=\"anchor\" style=\"autocontent\" id=\"min_child_weight\"/><br>\n",
    "XGBoost немного иначе определяет важность листа — не насколько именно объектов в лист попало, а насколько объекты в листе имеют сильно разные предсказания. Из-за этого способа определения, min_child_weight может принимать нецелые значения, в том числе меньше 1 (к примеру, в случае задачи классификации)\n",
    "\n",
    "Попробуем затюнить только этот параметр. Заметьте, мы можем спокойно использовать 2000 естиматоров, не боясь ждать результата рассчетов долгое время "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for min_child_weight in (1, 2, 3, 5, 7, 9, 11, 13, 15): \n",
    "    models[f\"XGB_mnw{min_child_weight}\"] = xgboost.XGBRegressor(n_estimators=2000,  \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=5, \n",
    "                     random_state=42,\n",
    "                     min_child_weight=min_child_weight,                                          \n",
    "                     n_jobs=-1,\n",
    "                     objective ='reg:squarederror')\n",
    "\n",
    "# Train models\n",
    "xgb_mw = train_and_test_regressor(models, X_learn, Y_learn, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=xgb_mw, y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"XGB min_child_weight\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем равное 9 (в принципе, можно было бы подобрать чуть точнее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_add2 = {}\n",
    "models_add2['xgb_mcw'] = xgboost.XGBRegressor(n_estimators=2000,  \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=5, \n",
    "                     random_state=42,\n",
    "                     min_child_weight=9,\n",
    "                     n_jobs=-1,\n",
    "                     objective ='reg:squarederror')\n",
    "\n",
    "# Train models\n",
    "xgb_add2 = train_and_test_regressor(models_add2, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=pd.concat([tuned_boost, xgb_add, xgb_add2]) , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти ничего не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM <a class=\"anchor\" style=\"autocontent\" id=\"LightGBM\"/><br>\n",
    "\n",
    "\n",
    "Он был изначально разработан для того, чтобы работать очень быстро. В него добавили много ухищрений, связанных с этим. Кроме этого, LightGBM по умолчанию строит дерево немного иначе, нежели XGBoost.\n",
    "\n",
    "XGBoost по умолчанию строит дерево по уровням - на каждом уровне, если узел можно разбить так, чтобы улучшить значение функции ошибки, то мы это делаем. Ограничены мы только максимальной глубиной дерева. \n",
    "\n",
    "LightGBM же строит дерево по узлам. На каждом шаге бьется тот узел, разбиение которого сильнее всего минимизирует функцию ошибки. И ограничения на глубину нет. В LightGBM вводится ограничение не на глубину дерева, а на общее число листьев в итоговом дереве. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/lightgbm.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию он **еще** быстрее (хотя в xgboost тоже есть опции для ускорения)\n",
    "\n",
    "Из-за особенностей построения им деревьев, надо задавать не высоту дерева, а максимальное число листьев. Поставим пока так, чтобы число листьев было равно числу листьев в дереве высоты 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "\n",
    "models_add3 = {}\n",
    "models_add3['lightgbm'] = lightgbm.LGBMRegressor(n_estimators=2000, # can use more estimators due to SPEEEEEED \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=-1,\n",
    "                     num_leaves=2**5,                       \n",
    "                     random_state=42,\n",
    "                     min_child_weight=9,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "# Train models\n",
    "lgb_add = train_and_test_regressor(models_add3, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=pd.concat([tuned_boost, xgb_add, xgb_add2, lgb_add]) , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На уровне с xgboost. Зато быстрее)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Максимальное число листьев в дереве<a class=\"anchor\" style=\"autocontent\" id=\"Максимальное-число-листьев-в-дереве\"/><br>\n",
    "Попробуем все же отдельно подобрать ограничение на число листьев. По словам создателей, оно не должно быть больше числа листьев в соответствующем дереве глубины 5, то есть 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for num_leaves in (8, 16, 24, 32, 40): \n",
    "    models[f\"LGB_lvn{num_leaves}\"] =  lightgbm.LGBMRegressor(n_estimators=2000,  \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=-1,\n",
    "                     num_leaves=num_leaves,                       \n",
    "                     random_state=42,\n",
    "                     min_child_weight=10,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "# Train models\n",
    "lgb_nl = train_and_test_regressor(models, X_learn, Y_learn, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=lgb_nl, y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"LGB num_leaves\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из этого графика, оптимальное число листьев - в районе 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for num_leaves in (8, 12, 16, 20): \n",
    "    models[f\"LGB_nl{num_leaves}\"] =  lightgbm.LGBMRegressor(n_estimators=2000,  \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=-1,\n",
    "                     num_leaves=num_leaves,                       \n",
    "                     random_state=42,\n",
    "                     min_child_weight=10,\n",
    "                     n_jobs=-1) \n",
    "\n",
    "# Train models\n",
    "lgb_nl = train_and_test_regressor(models, X_learn, Y_learn, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=lgb_nl, y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"LGB num_leaves\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем 12 листьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_add4 = {}\n",
    "models_add4['lightgbm lv12'] = lightgbm.LGBMRegressor(n_estimators=2000,  \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=-1,\n",
    "                     num_leaves=12,                       \n",
    "                     random_state=42,\n",
    "                     min_child_weight=9,\n",
    "                     n_jobs=-1) \n",
    "\n",
    "# Train models\n",
    "lgb_add2 = train_and_test_regressor(models_add4, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=pd.concat([tuned_boost, xgb_add, xgb_add2, lgb_add, lgb_add2]) , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество почти не изменилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost\n",
    "\n",
    "Разработал Яндекс.  \n",
    "\n",
    "CatBoost:\n",
    "\n",
    "1. хорошо умеет работать с категориальными признаками. Если у вас много категориальных признаков - он может дать существенный выигрыш. \n",
    "2. по умолчанию использует в качестве модели модификацию обычного дерева решения - Symmetric Tree, которое менее склонно к переобучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install catboost\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "\n",
    "models_add4 = {}\n",
    "models_add4['catboost'] = catboost.CatBoostRegressor(iterations=2000,  \n",
    "                     learning_rate=0.1, \n",
    "                     depth=5,                       \n",
    "                     random_state=42,\n",
    "                     min_data_in_leaf=9,\n",
    "                     verbose=0)\n",
    "                     #task_type=\"GPU\") # can use gpu, but no parallel-cpu option\n",
    "\n",
    "# Train models\n",
    "cat_add = train_and_test_regressor(models_add4, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=pd.concat([tuned_boost, xgb_add, xgb_add2, lgb_add, cat_add]) , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало  лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Про другие реализации случайного леса<a class=\"anchor\" style=\"autocontent\" id=\"Про-другие-реализации-случайного-леса\"/><br>\n",
    "В xgboost и lightgbm есть свои, более быстрые и иногда более эффективные реализации случайного леса. Но их надо дополнительно настраивать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_rf = {}\n",
    "\n",
    "models_rf[\"xgb_rf\"] = xgboost.XGBRFRegressor(n_estimators=250, \n",
    "                                             colsample_bytree=0.8, \n",
    "                                             subsample=0.8,\n",
    "                                             reg_lambda=0.001, # to get deeper, less regularized trees\n",
    "                                             max_depth=20, # trees must be deep\n",
    "                                             n_jobs=-1,\n",
    "                                             objective ='reg:squarederror')\n",
    "\n",
    "models_rf[\"lgb_rf\"] = lightgbm.LGBMRegressor(n_estimators=250,\n",
    "                            bagging_freq=1, # for lgb random forest must be set to 1\n",
    "                            num_leaves=2**14, # don't forget to change the number of leaves to smth big\n",
    "                            boosting_type=\"rf\", # set boosteer type\n",
    "                            feature_fraction=0.8, # for lgb random forest must be less then 1\n",
    "                            bagging_fraction=0.8, # for lgb random forest must be less then 1\n",
    "                            min_child_samples=1, # to get deeper trees \n",
    "                            n_jobs=-1)\n",
    "\n",
    "# Train models\n",
    "rf_add = train_and_test_regressor(models_rf, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=pd.concat([tuned_boost.query('model == \"RF\"'), rf_add]) , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметьте, что в данном случае они показывают себя иначе, нежели sklearn RandomForest. Это частое явление - так как деревья в пакетах xgboost и lightgbm строятся отличным от sklearn образом. Это может как улучшать качество, так и ухудшать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Про подбор параметров модифицированных бустингов<a class=\"anchor\" style=\"autocontent\" id=\"Про-подбор-параметров-модифицированных-бустингов\"/><br>\n",
    "Каждый из модифицированных бустингов имеет свои особые параметры и рекомендации от создателей и участников Kaggle, как и в каком порядке выбирать параметры для конкретного бустинга. Если вы решили использовать тот или иной вид бустинга в своей задаче - ОЗНАКОМЬТЕСЬ c этими советами. \n",
    "\n",
    "Все три бустинга, к примеру, позволяют задавать не только число признаков, использующихся в каждом узле, но и число признаков, использующихся в каждом дереве в целом. \n",
    "\n",
    "Кроме того, все три бустинга имеют настройки, ускоряющие их работу (у lightgbm эти настройки выставлены по умолчанию) и все три бустинга умеют работать на GPU\n",
    "\n",
    "Здесь мы бегло пробежались по самым верхам, копируя подобранные на предыдущих этапах параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Блендинг и Стэкинг\n",
    "\n",
    " <font size=\"5\"> Смесь экспертов</font>\n",
    "\n",
    "До этого мы использовали два подхода. Первый подход — берем много предсказаний большого количества моделей и усредняем (считаем, что модели равноправны).\n",
    "\n",
    "$$ h(x) = \\dfrac 1 k \\sum_{i=i}^k  a_i (x) $$\n",
    "Потом задумываемся о том, что каждая модель предсказывает в целом по-разному. Одна модель ошибается в 10% случаях, другая — в 15% и так далее. Неплохо бы к предсказаниям этих моделей подобрать веса. Так рождается идея того же бустинга.\n",
    "\n",
    "$$ h(x) = \\dfrac 1 k \\sum_{i=i}^k b_i a_i (x) $$\n",
    "\n",
    "\n",
    "Следующий логичный шаг — подумать о том, что каждая модель может ошибаться на каких-то своих объектах. Например, при предсказании, насколько велика вероятность, что человек серьезно заболеет, одна модель будет плохо работать для европейцев, а другая — для жителей Новой Гвинеи. \n",
    "\n",
    "$$ h(x) = \\dfrac 1 k \\sum_{i=i}^k b_i(x) a_i (x) $$\n",
    "\n",
    "Получается ситуация, в которой то, насколько хорошо будет предсказывать модель, зависит от самого объекта. Фактически это означает то, что мы бы хотели для каждого объекта получать какой-то вектор весов, а дальше суммировать предсказания моделей $a_i$, используя эти веса. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как получать эти веса для каждого объекта? \n",
    "Обучим еще одну модель, которая явно или неявно предсказывает веса алгоритмов и агрегирует их предсказания. Называться она будет **метаалгоритмом**.\n",
    "\n",
    "Обычно для метаалгоритма используется сравнительно простые модели, например, линейную модель (в этом случае веса предсказаний базовых моделей не будут зависеть от объекта) или \n",
    "\n",
    "Как получить такую модель? Есть два распространенных подхода - **stacking** и **blending**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending (Блендинг)<a class=\"anchor\" style=\"autocontent\" id=\"Blending-(Блендинг)\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На соревновании Netflix Prize была поставлена задача - предсказать, как люди оценят тот или иной фильм. \n",
    "Победил подход, основанный на таком объединении модели, при котором у вас каждая модель получает вес в зависимости от объекта. Подход называется **блендинг**.\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L03/netflix_prize.png\" width=\"600\">\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть **обучающая и тестовая выборка**.\n",
    "\n",
    "1. Бьем обучающую выборку на две подвыборки - A (побольше) и B\n",
    "\n",
    "2. Обучаем набор базовых алгоритмов на подвыборке A. \n",
    "\n",
    "3. Получаем предсказания этих базовых алгоритмов на объектах из выборки B\n",
    "\n",
    "4. Используем эти предсказания в качестве признаков для метаалгоритма, который будет предсказывать веса алгоритмов. Обучаем его на выборке B.\n",
    "\n",
    "5. Для того, чтобы сделать предказание на тесте:\n",
    "  1. Получаем предсказания базовых моделей на тесте\n",
    "  2. Аггрегируем их при помощи метаалгоритма\n",
    "\n",
    "\n",
    "Тестовую выборку не трогаем. Дополнительно **разбиваем обучение и обучаем алгоритмы на разбиении**, каждый алгоритм дает какое-то предсказание. На отложенной части обучения делаем то же предсказание, то есть используем предсказания алгоритмов как дополнительные признаки. Получается датасет, в котором есть изначальные признаки и предсказания моделей. Дальше можно **обучить мета-алгоритм либо на объединении всех этих признаков, либо только на этих признаках**. Получится, что алгоритм будет брать предсказания других алгоритмов, обрабатывать их внутри себя и выдавать итоговое предсказание. \n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/blending.png\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недостатком блендинга является то, что мы дополнительно разбиваем обучающую выборку - нельзя учить и базовые алгоритмы, и основной на одних и тех же данных. \n",
    "\n",
    "Для улучшения качества можно сделать несколько блендингов (по-разному разбивая обучающую выборку на выборки A и B), а дальше усреднять предсказания разных блендингов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать простой блендинг. Единственное, немного схитрим. Для обучения метаалгоритма будем использовать датасет, который использовали при подборе гиперпараметров алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlendingRegressor():\n",
    "    def __init__(self, \n",
    "                 first_layer_models, \n",
    "                 second_layer_model):\n",
    "        self.first_layer_models = {name : sklearn.clone(model) for name, model in first_layer_models.items()}\n",
    "        self.second_layer_model = sklearn.clone(second_layer_model)\n",
    "    \n",
    "    def fit_1st_layer(self, X, Y):\n",
    "        for name, model in self.first_layer_models.items():\n",
    "            print(f\"Fitting {name}\")\n",
    "            model.fit(X, Y)\n",
    "        \n",
    "    def predict_1st_layer(self, X):\n",
    "        features = np.zeros((X.shape[0], len(self.first_layer_models)) )\n",
    "        for ind, model in enumerate(self.first_layer_models.values()):\n",
    "            features[:, ind] = model.predict(X)\n",
    "        return features \n",
    "        \n",
    "    def fit_2st_layer(self, X, Y):\n",
    "        features = self.predict_1st_layer(X)\n",
    "        self.second_layer_model.fit(features, Y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        features = self.predict_1st_layer(X)\n",
    "        Y_pred = self.second_layer_model.predict(features)\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_models = {}\n",
    "first_layer_models['linreg'] = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "\n",
    "\n",
    "first_layer_models['rf'] = RandomForestRegressor(n_estimators=250, \n",
    "                                    max_depth=None, \n",
    "                                     min_samples_leaf=1, \n",
    "                                     n_jobs=-1, \n",
    "                                    random_state=42)\n",
    "\n",
    "# too long \n",
    "#first_layer_models['gbr'] = GradientBoostingRegressor(learning_rate=0.05, \n",
    "#                                 n_estimators=1000, \n",
    "#                                 random_state=42)\n",
    "#first_layer_models['gbr_tuned'] = GradientBoostingRegressor(learning_rate=0.1, \n",
    "#                                      n_estimators=2000, \n",
    "#                                      max_depth=5,\n",
    "#                                      min_samples_leaf=5,\n",
    "#                                      random_state=42)\n",
    "\n",
    "\n",
    "first_layer_models['xgb'] = xgboost.XGBRegressor(n_estimators=500,  \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=5, \n",
    "                     random_state=42,\n",
    "                     min_child_weight=10,\n",
    "                     n_jobs=-1,\n",
    "                     objective ='reg:squarederror') \n",
    "\n",
    "\n",
    "first_layer_models['lgb_tuned'] = lightgbm.LGBMRegressor(n_estimators=2000,  \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=-1,\n",
    "                     num_leaves=12,                       \n",
    "                     random_state=42,\n",
    "                     min_child_weight=7,\n",
    "                     n_jobs=-1) \n",
    "\n",
    "first_layer_models['catboost'] = catboost.CatBoostRegressor(iterations=2000, \n",
    "                                                            verbose=0,\n",
    "                                                            learning_rate=0.1, \n",
    "                                                            depth=5,                       \n",
    "                                                            random_state=42,\n",
    "                                                            min_data_in_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_learn, X_valid, Y_learn, Y_valid = train_test_split(X_train, Y_train, random_state=42)\n",
    "blend_reg = BlendingRegressor(first_layer_models, LinearRegression())\n",
    "\n",
    "blend_reg.fit_1st_layer(X_learn, Y_learn)\n",
    "blend_reg.fit_2st_layer(X_valid, Y_valid)\n",
    "Y_pred = blend_reg.predict(X_test)\n",
    "blend_boot = bootstrap_metric(Y_test, \n",
    "                 Y_pred, \n",
    "                 metric_fn=lambda X, Y: mean_squared_error(y_true=X, y_pred=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_data = pd.DataFrame({\"mse\": blend_boot})\n",
    "blend_data['model'] = 'SingleBlending'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(data=pd.concat([tuned_boost, xgb_add, xgb_add2, lgb_add, cat_add, blend_data]) , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одиночный блендинг работает даже хуже, чем один catboost\n",
    "\n",
    "Попробуем обучить 10 блендингов с разными разбиениями X_train на X_learn и X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blending_ensemble = []\n",
    "\n",
    "# takes some time to run\n",
    "for i in range(1, 11):\n",
    "    print(f\"Training blender {i}\")\n",
    "    X_learn, X_valid, Y_learn, Y_valid = train_test_split(X_train, Y_train, random_state=i * 7 % 13)\n",
    "    blend_reg = BlendingRegressor(first_layer_models, \n",
    "                                  LinearRegression())\n",
    "\n",
    "    blend_reg.fit_1st_layer(X_learn, Y_learn)\n",
    "    blend_reg.fit_2st_layer(X_valid, Y_valid)\n",
    "    blending_ensemble.append(blend_reg)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = 0\n",
    "for blend_reg in blending_ensemble:\n",
    "    Y_pred += blend_reg.predict(X_test)\n",
    "Y_pred /= len(blending_ensemble)\n",
    "\n",
    "\n",
    "eblend_boot = bootstrap_metric(Y_test, \n",
    "                 Y_pred, \n",
    "                 metric_fn=lambda X, Y: mean_squared_error(y_true=X, y_pred=Y))\n",
    "eblend_data = pd.DataFrame({\"mse\": eblend_boot})\n",
    "eblend_data['model'] = 'EnsembleBlending'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(eblend_boot, q=[0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(cat_add['mse'], q=[0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "ax = sns.boxplot(data=pd.concat([tuned_boost, xgb_add, xgb_add2, lgb_add, cat_add, blend_data, eblend_data]) , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество по сравнению с лучшей моделью (catboost) существенно не отличается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стэкинг<a class=\"anchor\" style=\"autocontent\" id=\"Стэкинг\"/><br>\n",
    "\n",
    "Так же можно использовать другой способ, который позволяет использовать всю обучающую выборку\n",
    "\n",
    "Вместо того, чтобы бить обучающую выборку на выборки А и Б случайным образом, давайте использовать кросс-валидацию. \n",
    "\n",
    "* 1. Для каждого из базовых алгоритмов, которые хотим объединять: \n",
    "  * 1.1  Бьем обучающую выборку на блоки\n",
    "  * 1.2  На каждом кросс-валидационном разбиении учим базовый алгоритм. На блоке, который не вошел в обучение делаем предсказание.\n",
    "  * 1.3. В результате получаем предсказания для всей обучающей выборки.\n",
    "  * 1.4  Для предсказания на тестовой выборке, обучаем наш базовый алгоритм на всей выборке\n",
    "* 2. Обучаем на полученных предсказаниях мета-алгоритм\n",
    "\n",
    " <img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/stacking_crossvalidation.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3. Для того, чтобы сделать предсказание на тесте, делаем предсказания моделями, полученными на шаге 1.4. И аггрегируем их предсказания при помощи мета-алгоритма, полученного на шаге 2\n",
    " \n",
    " <img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/stacking_test_predictions.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стэкинг, в отличие от блендинга, использует все обучение - мы не теряем часть объектов безвозвратно.\n",
    "Но этим мы вносим несколько проблем, одной из которых является то, что модели, на предсказаниях которых мы учили мета-алгоритм и модели, предсказаниях которых мы в итоге им агрегируем, немного отличаются. Если в одном случае вероятность <font color=red>0.2</font>, предсказанная моделью, значила: «я не совсем уверена в предсказании», то теперь это может значить «я очень уверена в предсказании». \n",
    "\n",
    "\n",
    "Кроме того, по наблюдениям, такой подход более склонен к переобучению. Для борьбы с ним можно, к примеру, подмешивать к предсказаниям базовых моделей шум. \n",
    "\n",
    "Так же, по причине того, что нам надо делать предсказание на кроссвалидации, и работать этот метод будет дольше Blending. Зато иногда он работает лучше "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn уже реализован свой StackingRegressor, потому в этой лекции мы его реализовывать не будем. \n",
    "\n",
    "Можете посмотреть пример реализации, например, [здесь](https://github.com/Dyakonov/ml_hacks/blob/master/dj_stacking.ipynb). В принципе, если вам действительно понадобится стэкинг, полезно иметь свою собственную реализацию, чтобы легко менять в ней некоторые детали (вариантов стекинга - великое множество)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем в нашу новую модель только быстро учащиеся модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = []\n",
    "\n",
    "base_models.append([\"linreg\", make_pipeline(StandardScaler(with_mean=False), LinearRegression())])\n",
    "\n",
    "base_models.append([\"xgb\", xgboost.XGBRegressor(n_estimators=500,  \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=5, \n",
    "                     random_state=42,\n",
    "                     min_child_weight=10,\n",
    "                     n_jobs=-1,\n",
    "                     objective ='reg:squarederror')])\n",
    "\n",
    "base_models.append([\"lgb\", lightgbm.LGBMRegressor(n_estimators=2000,  \n",
    "                     learning_rate=0.1, \n",
    "                     max_depth=-1,\n",
    "                     num_leaves=12,                       \n",
    "                     random_state=42,\n",
    "                     min_child_weight=7,\n",
    "                     n_jobs=-1)])\n",
    "\n",
    "base_models.append([\"cgb\", catboost.CatBoostRegressor(iterations=2000, \n",
    "                                                            verbose=0,\n",
    "                                                            learning_rate=0.1, \n",
    "                                                            depth=5,                       \n",
    "                                                            random_state=42,\n",
    "                                                            min_data_in_leaf=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "stacking_reg = StackingRegressor(base_models,\n",
    "                   LinearRegression(), # level-two model is Linear Regression\n",
    "                   cv=3)\n",
    "\n",
    "stacking_reg.fit(X_train, Y_train)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = stacking_reg.predict(X_test)\n",
    "print(mean_squared_error(y_true=Y_test, y_pred=Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_boot = bootstrap_metric(Y_test, \n",
    "                 Y_pred, \n",
    "                 metric_fn=lambda X, Y: mean_squared_error(y_true=X, y_pred=Y))\n",
    "\n",
    "stack_data = pd.DataFrame({\"mse\": stack_boot})\n",
    "stack_data['model'] = 'Stacking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "ax = sns.boxplot(data=pd.concat([tuned_boost, \n",
    "                                 xgb_add, \n",
    "                                 xgb_add2,\n",
    "                                 lgb_add, \n",
    "                                 cat_add, \n",
    "                                 blend_data, \n",
    "                                 eblend_data,\n",
    "                                 stack_data]) , y=\"mse\", x=\"model\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=30)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(stack_data['mse'], \n",
    "            q=[0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(cat_add['mse'], \n",
    "            q=[0.025, 0.975])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять же, видим, что стэкинг на данной задаче не принес существенного улучшения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стэкинг vs блендинг<a class=\"anchor\" style=\"autocontent\" id=\"Стэкинг-vs-блендинг\"/><br>\n",
    "На самом деле, подходы часто объединяют в один или путают местами. Например, улучшая блендинг в сторону использования всей обучающей выборки можно получить стэкинг. И т.д. \n",
    "\n",
    "Оба подхода имеют множество модификаций, к примеру, с добавлением к признаков-предсказаний базовых моделей изначальных признаков и тд. \n",
    "Оба подхода показывают схожие результаты. И оба подхода улучшают свое качество по мере увеличения размера обучающей выборки. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример того, как выглядит решающая граница для стэкинга и блендинга \n",
    "\n",
    "Задача — разделить синее и красное облако точек. На изображении выше показано, как разные алгоритмы справляются с этим — есть K-Nearest Neighbors, ridge регрессия и случайный лес с разной глубиной деревьев. \n",
    "Все три алгоритма как-то справляются, но лучшие результаты показывает K-Nearest Neighbors. Ridge регрессия работает не очень хорошо потому, что разделение не линейное. Случайный лес угадал тенденцию, но ему либо недостаточно данных, либо надо добавить ещё деревья, либо поменять настройки параметров.\n",
    "\n",
    "\n",
    "Но если мы берем блендинг и стэкинг этих моделей, то оба этих подхода проводят  хорошую разделяющую границу (намного лучше, чем эти подходы по отдельности).\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L03/img_license/stacking_vs_blending.png\" width=\"1000\">\n",
    "\n",
    "\n",
    "Известно, что нейронные сети хорошо работают с изображениями, зачастую поступают следующим образом: учат много разных нейросетей на изображениях, либо берут уже обученные архитектуры, затем делают с ними блендинг или стэкинг на какой-то отложенной выборке. Результаты получаются лучше, чем от использования одной только нейросети\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практические рекомендации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения абсолютного большинства задач на неоднородных данных на практике **чаще всего применяют** методы бэггинга и бустинга над деревьями решений (соответственно Random Forests  -- **RF** **и** Gradient boosting on decision trees -- **GBDT**). Для изображений, звуковых последовательностей, текстов и прочих однородных данных часто оказываются предпочтительными более сложные нейростетевые подходы, с чем мы ещё подробно познакомимся в ходе нашего курса.\n",
    "\n",
    "Предположим, мы хотим построить модель классификации или регрессии, а наш датасет представляет собой неоднородные табличные данные. Естественно возникает вопрос:\n",
    "> Какой именно ML алгоритм (какую реализацию) нам следует выбрать для решения конкретной задачи?\n",
    "\n",
    "\n",
    "Не смотря на некоторые успехи в построении универсального ответа на такой вопрос ([AutoML](https://en.wikipedia.org/wiki/Automated_machine_learning)), судя по всему, удовлетворительный общий ответ отсутствует. При построении решения в каждом конкретном случае мы вынуждены учитывать особенности имеющихся данных, какие метрики качества модели для нас имеют наибольшее значение, каковы наши располагаемые вычислительные или (и) временные ресурсы.\n",
    "\n",
    "Тем не менее, попробуем сформулировать ряд упрощенных рекомендаций по применению RF и GBDT, которые могут дать необходимую начальную интуицию для работы с данными моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какой алгоритм машинного обучения в общем случае выбрать: RF или GBDT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какие деревья решений использовать в качестве элементов случайного леса, а на каких стоить градиентный бустинг?\n",
    "\n",
    "Как мы уже успели установить выше, справедливо разложение:\n",
    "\n",
    "```ошибка предсказания модели = bias + varience``` \n",
    "\n",
    "и имеет место явление bias-variance tradeoff, принципиально не позволяющие одинаково сильно минимизировать оба вклада в ошибку предсказания модели.\n",
    "\n",
    "* Ансамблирование в виде бэггинга, использующееся при при построении RF, заточено на уменьшение `varience` путём \"усреднения\" ответов элементарных предсказателей. Использование бэггинга существенно не позволяет улучшить `bias` -- этот показатель наследуется от базового эстиматора. Таким образом, **при построении случайного леса следует взять относительно глубокие деревья решений (можно говорить о глубине в 6-10 ветвлений)**, обладающие собственным низким показателем `bias`.\n",
    "\n",
    "* Ансамблирование в виде бустинга наоборот в первую очередь заточено на улучшение показателя `bias` итоговой модели, путём взаимного улучшения большого числа *стабильных, но слабых* эстиматоров (то есть обладающих высоким показателем `bias` и низким `varience`). Таким образом, *при построении градиентного бустинга над деревьями решений следует взять в качестве базовой модели неглубокие деревья* (вплоть до решающих пней -- деревьев решений с единственным ветвлением)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### У RF значительно меньше гиперпараметров, чем у GBDT. Но как их выбрать?\n",
    "\n",
    "> глубина отдельных деревьев\n",
    "\n",
    "\n",
    "> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какая реализация GBDT \"лучше\": CatBoost vs XGBoost vs LightGBM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какие гиперпараметры GBDT реализаций следует подбирать в первую очередь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Современные реализации GBPD содержат крайний широкий список доступны для настройки параметров. Первичное знакомство с длинными списками параметров может оказаться дезориентирующим, потому мы приведём короткий список наиболее существенных гиперпараметров, которые повлияют на успех обучения модели. \n",
    "\n",
    "Среди таких наиболее важных параметров, выделим два класса:\n",
    "* параметры, влияющие на контроль переобучения модели \n",
    "* параметры, определяющие с какой скоростью будет происходить процесс обучения модели\n",
    "\n",
    "Названия параметров в приведённой ниже таблице являются ссылками на актуальную версию документации:\n",
    "\n",
    "| param type            | CatBoost                         | XGBoost                                        | LightGBM                                                      |\n",
    "|-----------------------|----------------------------------|------------------------------------------------|---------------------------------------------------------------|\n",
    "| overfitting control   | [`learning_rate`](https://catboost.ai/en/docs/concepts/parameter-tuning#learning-rate)<br>[`depth`](https://catboost.ai/en/docs/concepts/parameter-tuning#tree-depth)<br>[`l2_leaf_reg`](https://catboost.ai/en/docs/concepts/parameter-tuning#l2-reg) | [`eta`](https://xgboost.readthedocs.io/en/stable/parameter.html#:~:text=%EF%83%81-,eta,-%5Bdefault%3D0.3%2C%20alias)<br>[`max_depth`](https://xgboost.readthedocs.io/en/stable/parameter.html#:~:text=range%3A%20%5B0%2C%E2%88%9E%5D-,max_depth,-%5Bdefault%3D6%5D)<br>[`min_child_weight`](https://xgboost.readthedocs.io/en/stable/parameter.html#:~:text=range%3A%20%5B0%2C%E2%88%9E%5D-,min_child_weight,-%5Bdefault%3D1%5D) | [`learning_rate`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#learning_rate)<br>[`max_depth`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#max_depth)<br>[`num_leaves`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#num_leaves)<br>[`min_data_in_leaf`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#min_data_in_leaf) |\n",
    "| speed of the training | [`rsm`](https://catboost.ai/en/docs/references/training-parameters/common#rsm)<br>[`iterations`](https://catboost.ai/en/docs/references/training-parameters/common#iterations)                | [`colsample_bytree`](https://xgboost.readthedocs.io/en/stable/parameter.html#:~:text=support%20uniform%20sampling.-,colsample_bytree,-%2C%20colsample_bylevel%2C)<br>[`subsample`](https://xgboost.readthedocs.io/en/stable/parameter.html#:~:text=range%3A%20%5B0%2C%E2%88%9E%5D-,subsample,-%5Bdefault%3D1%5D)<br>[`n_estimators`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#:~:text=for%20XGBoost%20regression.-,Parameters,n_estimators%20(int),-%E2%80%93%20Number%20of%20gradient)  | [`feature_fraction`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#feature_fraction)<br>[`bagging_fraction`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#bagging_fraction)                          |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применение нейронных сетей к табличным данным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть попытки построить архитектуры нейронных сетей таким образом, чтобы они могли работать с табличными данными. \n",
    "Из недавних можно отметить архитектуру от Яндекса \n",
    "[NODE](https://arxiv.org/pdf/1909.06312.pdf) и [TabNet](https://arxiv.org/pdf/1908.07442.pdf)([TabNet git](https://github.com/dreamquark-ai/tabnet)) от Гугл .\n",
    "\n",
    "Вторая работа особенно удачна и уже активно используется в соревнованиях на Kaggle. Стоит отметить, что победы над древесными моделями не одержано. Но полученная модель иногда достигает их качества и обладает рядом интересных особенностей:\n",
    "\n",
    "1. Как и любая другая нейросетевая архитектура - она дифференцируема. Можно вставить обученную нейросеть как часть другой и использовать transfer learning и прочее\n",
    "2. Нейросеть автоматически выбирает признаки, потому feature importance можно получить без дополнительных ухищрений.\n",
    "3. Ее можно обучать в semisupervised манере - сначала предобучить на неразмеченных данных, а потом уже использовать размеченные.\n",
    "\n",
    "Установим пакет, реализующий эту нейросеть на pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как это нейросеть, возможно вам захочется сначала поменять среду исполнения на среду с GPU (если поменять после установленные пакеты в Colab слетят)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install pytorch-tabnet \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "calif_housing = sklearn.datasets.fetch_california_housing()\n",
    "X = calif_housing.data\n",
    "Y = calif_housing.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)\n",
    "X_learn, X_valid, Y_learn, Y_valid = train_test_split(X_train, Y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим с параметрами по умолчанию, передав датасет для валидации - нам нужно узнать, когда нейросеть начнет переобучаться.\n",
    "\n",
    " Заметьте, что у xgboost и lightgbm тоже есть такая возможность (early_stopping), которая позволяет легко подбирать число базовых моделей. Подробнее - смотрите в документации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросеть принимает y в формате (предсказываемая величина, число предсказываемых величин), потому нам потребуется reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import  TabNetRegressor\n",
    "\n",
    "tabnet = TabNetRegressor()\n",
    "tabnet.fit(X_learn, Y_learn.reshape(-1, 1),\n",
    "           eval_set = [(X_valid,  Y_valid.reshape(-1, 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим теперь на всем тренировочном датасете, поставив число эпох обучения равным тому, что нам сообщила выдача функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet = TabNetRegressor()\n",
    "tabnet.fit(X_train, Y_train.reshape(-1, 1), max_epochs=53) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "Y_pred = tabnet.predict(X_test)\n",
    "print(mean_squared_error(y_true=Y_test, y_pred=Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что качество сильно хуже, чем у топ-моделей бустинга. Возможно, надо попробовать не параметры по умолчанию нейросети, или нейронную сеть другой архитектуры! \n",
    "\n",
    "Однако пока создатели не предоставили точных рекомендаций по подбору этих параметров. Можете попробовать улучшить качество модели для интереса. \n",
    "\n",
    "По сообщениям участников Kaggle, модель все же чаще всего уступает хорошо затюненным бустингам("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Ссылки на материалы для самостоятельного изучения</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Общие источники</font>\n",
    "\n",
    "[Про разделение на классическое и глубокое машинное обучение ](https://www.deeplearningbook.org/contents/intro.html) \n",
    "\n",
    "[Один из лучших учебников по классическому машинному обучению](https://web.stanford.edu/~hastie/ElemStatLearn/)\n",
    "\n",
    "[Хорошая книга по машинному обучению](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646) \n",
    "\n",
    "<font size=\"5\">Про деревья решений</font>\n",
    "\n",
    "\n",
    "[Деревья решений](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn)\n",
    "\n",
    "<font size=\"5\">Про ансамбли</font>\n",
    "\n",
    "\n",
    "[kaggle ensembling guide](https://www.kaggle.com/code/amrmahmoud123/1-guide-to-ensembling-methods/notebook)\n",
    "\n",
    "[comprehensive guide for ensemble models](https://www.projectpro.io/article/a-comprehensive-guide-to-ensemble-learning-methods/432)\n",
    "\n",
    "[Цикл лекций по обучению ансамблей](https://medium.com/ml-research-lab/ensemble-learning-relation-with-bias-and-variance-431cdc0a3fc9)\n",
    "\n",
    "[Про стэкинг и блендинг](https://dyakonov.org/2017/03/10/c%D1%82%D0%B5%D0%BA%D0%B8%D0%BD%D0%B3-stacking-%D0%B8-%D0%B1%D0%BB%D0%B5%D0%BD%D0%B4%D0%B8%D0%BD%D0%B3-blending/)\n",
    "\n",
    "<font size=\"5\">XGBoost</font>\n",
    "\n",
    "[отличие XGBoost от обычного градиентного бустинга](https://stats.stackexchange.com/questions/202858/xgboost-loss-function-approximation-with-taylor-expansion)\n",
    "\n",
    "[оригинальная статья](https://arxiv.org/pdf/1603.02754.pdf)\n",
    "\n",
    "[как подбирать параметры xgboost](https://usermanual.wiki/Document/Complete20Guide20to20Parameter20Tuning20in20XGBoost20with20codes20in20Python.1988513968)\n",
    "\n",
    "\n",
    "<font size=\"5\">CatBoost</font>\n",
    "\n",
    "\n",
    "[Решение задач классификации при помощи CatBoost](https://www.youtube.com/watch?v=xl1fwCza9C8)\n",
    "\n",
    "[Официальная документация](https://catboost.ai/docs/concepts/parameter-tuning.html#rand-str)\n",
    "\n",
    "\n",
    "<font size=\"5\">LightGBM</font>\n",
    "\n",
    "[Очень подробная и удобная документация](https://lightgbm.readthedocs.io/en/latest/ )\n",
    "\n",
    "\n",
    "[Описание параметров](https://neptune.ai/blog/lightgbm-parameters-guide?utm_source=datacamp&utm_medium=post&utm_campaign=blog-lightgbm-parameters-guide&utm_campaign=News&utm_medium=Community&utm_source=DataCamp.com)\n",
    "\n",
    "[Новый бустинг с деревьями, содержащими в листах линейные регрессии](https://arxiv.org/pdf/1802.05640.pdf)\n",
    "\n",
    "\n",
    "<font size=\"5\">Дисбаланс классов</font>\n",
    "\n",
    "[Обучение в случае дисбаланса классов](http://www.svds.com/learning-imbalanced-classes/)\n",
    "\n",
    "[Bagging и случайные леса для обучения с имбалансом классов](https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/)\n",
    "\n",
    "[Коэффициент корреляции Мэтьюса](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7)\n",
    "\n",
    "\n",
    "<font size=\"5\">Нейронные сети и бустинг</font>\n",
    "\n",
    "[TabNet](https://arxiv.org/pdf/1908.07442.pdf)\n",
    "\n",
    "[TabNet, реализация на pytorch](https://github.com/dreamquark-ai/tabnet)\n",
    "\n",
    "[NODE](https://arxiv.org/pdf/1909.06312.pdf)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
