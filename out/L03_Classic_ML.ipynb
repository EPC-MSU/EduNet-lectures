{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Классическое машинное обучение </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Системы предсказаний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо нейронных сетей, обучение работе с которыми является основной задачей курса, есть и другие подходы к проблеме создания систем, помогающих решать те или иные задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/prediction_systems.png\" alt=\"alttext\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Экспертные системы (Rule-based systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самым первым подходом к созданию системы, способной на основе входных данных делать какие-то выводы, были так называемые **Rule-based systems**. В этих системах и за описание объекта — выделение значимых признаков, и за выработку правил, по которым система должна принимать то или иное решение, отвечал человек.\n",
    "\n",
    "Такие системы до сих пор используются, например, в определителях растений. Определители представляют собой набор утверждений, например: \"Растение имеет стержневую корневую систему\", \"Плод растения — костянка\", на основе согласия/несогласия с которыми книга отсылает вас к другим утверждениям или, в конце концов, к названию растения.\n",
    "\n",
    "Результативность такого подхода зависит от:\n",
    "* наличия базовых знаний у того, кто пользуется определителем;\n",
    "* качества и охвата самого набора правил — к примеру, может ли этот набор правил справиться с ситуацией, когда какой-то признак отсутствует. Например, растение плодоносит не весь год, поэтому не всегда можно четко ответить, какой у него плод.\n",
    "\n",
    "Единственной выгодой такой системы по сравнению с экспертом является то, что в большинстве случаев требования к умениям пользователя все же меньше.\n",
    "\n",
    "Игрушечный пример такой схемы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/expert_system.jpg\" alt=\"alttext\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классическое машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классическое машинное обучение избавляет нас от необходимости вручную составлять какие-то правила."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/classic_machine_learning_process.png\" alt=\"alttext\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом подходе от нас все равно требуется описание нашего объекта определенными признаками — мы должны получать это описание либо вручную, либо обрабатывая объект какими-то программами. Чтобы отличать такие признаки от признаков, которые автоматически выделяют нейронные сети, их называют **hand-designed features**.\n",
    "\n",
    "Затем эти описанные объекты передаются алгоритму, который уже сам формирует набор правил, по которому он должен решать поставленную задачу. Уже разобранные вами линейная регрессия и SVM сами выбирают, какие признаки и с какими весами им учитывать при принятии финального решения. В некоторых случаях (например, SVM) признаки могут дополнительно (явно или неявно) преобразовываться внутри самой модели, и на их основе могут формироваться новые признаки.\n",
    "\n",
    "Но главное ограничение всегда остается: за описание объекта отвечает какой-то внешний источник и то, какие признаки подавать алгоритму на вход, решает человек. А набор возможных преобразований признаков, как правило, строго фиксирован.\n",
    "\n",
    "И составление таких признаков требует от исследователя очень хорошего знания изучаемой темы, знания специфики работы используемого алгоритма — к примеру, подавать алгоритму на вход попарные произведения всех признаков, или алгоритм сам в ходе работы их явно или неявно получит.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глубокое машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В глубоком обучении признаки может выделить нейросеть. Важно понимать, что нейросеть не гарантирует нахождение качественных признаков, но имеет шансы их получить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/deep_learning_process.png\" alt=\"alttext\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросеть преобразует признаковое пространство от слоя к слою и сама определяет, какие признаки для данных объектов и для данной задачи важны, и итеративно выделяет сначала простые признаки, а затем комбинирует их в более сложные. В то время как качество подходов классического машинного обучения по мере увеличения размера обучающей выборки со временем выходит на плато, для нейросетей это плато наступает сильно позже или вообще не наступает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/ml_dl_learning_plateau.png\" alt=\"alttext\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потенциально такой подход позволяет почти не применять человеческую экспертизу при построении модели под задачу. Однако в реальности человеческая экспертиза теперь переходит на уровень подбора архитектуры нейросети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Необходимость методов классического машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует ряд причин, почему важно знать и применять методы классического машинного обучения:\n",
    "\n",
    "* **Недостаточный объем данных для нейронных сетей.** Как обсуждалось ранее, при малом объеме данных методы классического машинного обучения показывают более высокую эффективность.\n",
    "* **Табличные данные.** Решения на основе классического машинного обучения часто показывают сопоставимое или более высокое качество на табличных данных.\n",
    "* **Время получения решения задачи.** Скорость экспериментов и получения хорошего бейзлайна выше, чем у решения с помощью нейронных сетей.\n",
    "*  **Интерпретируемость предсказаний.** Из методов классического машинного обучения легче получить важность каждого отдельно взятого признака.\n",
    "* **Комбинирование подходов.** В современных задачах часто используются комбинации нейронных сетей и алгоритмов классического машинного обучения. Например, можно использовать нейронные сети в качестве генераторов признаков для методов классического обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Деревья решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деревья решений — это одни из первых моделей машинного обучения, которые были известны человеку. Изначально их строили без специальных алгоритмов, а просто вручную.\n",
    "\n",
    "Когда требовалось принять решение по проблеме, для которой построено дерево, человек брал и проходился по этому дереву."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/manual_construction_of_decision_trees.png\" width=\"900\"></center>\n",
    "\n",
    "<center><em>Предсказание типа линз для человека</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За принципом работы дерева решений стоит понятная интуиция. В каждом узле есть какой-то вопрос. Например, нормальное ли у человека слезоотделение, есть ли у него астигматизм и так далее. И, отвечая на каждый из этих вопросов, мы перемещаемся по дереву до тех пор, пока не придем к нужному типу линз.\n",
    "\n",
    "Такое дерево решений можно построить без использования моделей машинного обучения, просто на основании опыта многих врачей (экспертные системы).\n",
    "\n",
    "Вручную такие деревья строить тяжело, для большого объема данных их руками и не построишь.\n",
    "Также возникает вопрос: зачем нужна такая старая модель?\n",
    "\n",
    "Оказывается, что эти модели могут быть неожиданно эффективны и их можно автоматически строить с помощью алгоритмов и делать это достаточно быстро даже на больших объемах данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/neuro_tree.jpeg\" width=\"700\"></center>\n",
    "\n",
    "<center><em>\"As long as Kaggle has been around, Anthony says, it has <font color=green >almost always</font> been <b>ensembles of decision trees that have won competitions</b>\".</em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По словам Энтони Голдблума, основателя и генерального директора Kaggle, на соревнованиях побеждают алгоритмы, основанные на деревьях решений, и нейронные сети.\n",
    "\n",
    "**Где побеждают ансамбли деревьев решений?**\n",
    "\n",
    "* Recomendation systems (Netflix Prize 2009);\n",
    "* Learning to rank (Yahoo Learning to rank challenge 2010);\n",
    "* Crowdflower Search Results Relevance (2015);\n",
    "* Avito Context Ad Clicks (2015);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В любой задаче, где нет какой-то локальной связанности, которая есть в изображениях, текстах и т.д., деревья решений эффективнее, чем нейронные сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Принцип работы дерева решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/decision_tree_principle.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принцип работы дерева решений можно проиллюстрировать на данном примере. Есть 2 признака, в данном случае вещественных. Для каждой точки мы создаем вопрос: признак $x_1$ больше $0.7$ или меньше? Если больше $0.7$, то это красная точка. Если меньше $0.7$, то идем во второй внутренний узел T2 и спрашиваем: признак $x_2$ меньше $0.5$ или больше? Если меньше $0.5$, то точка будет красная, в другом случае — синяя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбиение пространства**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/decision_trees_partitioning_space.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений делит пространство признаков с помощью плоскостей на области, и в каждой из этих областей предсказывается константная величина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деревья решений, как правило, используются при решении 2-х типов задач — классификации и регрессии.\n",
    "Первая — классификация. Например, предсказание типа линз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/probability_predicions_by_decision_tree.png\" width=\"900\"></center>\n",
    "\n",
    "<center><em>Предсказание типа линз для человека</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Особенно актуальны модели, которые могут предсказывать вероятности классов. Жесткие предсказания — не самый удачный вариант, лучше оставить человеку возможность выбирать. К примеру, лекарства всегда действуют с какой-то вероятностью, потому что невозможно учесть все факторы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/probability_estimation_by_decision_tree.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В деревьях решений в каждом листе находятся разные объекты, то есть каждому листу могут соответствовать объекты разных классов, а предсказать нужно один.\n",
    "\n",
    "Мы хотим оценить вероятность принадлежности объекта к какому то определенному классу. Как это сделать: число представителей данного класса делим на общее число объектов. Это дает нам одну важную интуицию: желательно, чтобы в листе дерева было не очень мало объектов. Чем объектов меньше, тем больше возможная ошибка.\n",
    "\n",
    "Это согласуется с тем, как мы делаем в статистике. При построении дерева мы видим только обучающую выборку, а хотим делать выводы о генеральной совокупности. Конкретно здесь мы оцениваем, какая доля из объектов, попадающих в данный узел, принадлежит нужному классу. Можно использовать [распределение Бернулли 📚[wiki]](https://ru.wikipedia.org/wiki/Распределение_Бернулли) для двух классов или [мультиномиальное распределение 📚[wiki]](https://ru.wikipedia.org/wiki/Мультиномиальное_распределение) для большего количества классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для бинарных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/decision_tree_for_two_features.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что мы решаем задачу бинарной классификации (есть инфаркт у человека или нет). В наших табличных данных только бинарные признаки. Мы хотим построить дерево решений по этой таблице.\n",
    "\n",
    "Возьмем в качестве первого вопроса признак \"боль в груди\". В 1-ом и во 2-ом листе получается разное распределение людей. В левом листе инфаркт более вероятен, в правом — менее вероятен.\n",
    "\n",
    "Другим признаком может быть “как хорошо циркулирует кровь”, в таком случае тоже получится неплохое разделение. Последний признак — “есть ли атеросклероз”.\n",
    "\n",
    "Мы получили три разбиения по разным признакам. Теперь мы бы хотели выбрать лучший признак, а для этого нам нужно их сравнить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логично выбрать такое разбиение, которое дает нам \"хорошие\" узлы — те, в которых преимущественно сосредоточены объекты одного класса\n",
    "\n",
    "Одна из используемых метрик называется [Gini ✏️[blog]](https://www.learndatasci.com/glossary/gini-impurity/) . Она считается по следующей формуле:\n",
    "\n",
    "$$\\large \\text{Gini} = 1 - \\sum_ip_i^2$$\n",
    "\n",
    "Gini — мера [неопределенности ✏️[blog]](https://quantdare.com/decision-trees-gini-vs-entropy/) значения класса внутри узла. Соответственно, чем она ниже, тем лучше получившийся узел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем Gini для признака \"Боль в груди\":\n",
    "\n",
    "$\\text{Gini}_1 = 1- (\\dfrac{105}{105+33})^2 - (\\dfrac{33}{105+33})^2 = 0.364$\n",
    "\n",
    "$\\text{Gini}_2 = 1- (\\dfrac{34}{34+125})^2 - (\\dfrac{125}{34+125})^2 = 0.336$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/compute_gini_for_binary_features.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такую метрику можно посчитать для каждого узла. Дальше посчитать метрику для следующего узла. Дальше можем оценить насколько стал лучше результат в зависимости от используемого признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Impurity decrease} = \\text{Gini}_0 - (\\frac{n_1}{n_1+n_2}\\text{Gini}_1 + \\frac{n_2}{n_1+n_2}\\text{Gini}_2),$$\n",
    "\n",
    "где $n_1, n_2$ — число объектов в листьях,\n",
    "\n",
    "$ \\quad\\  \\text{Gini}_0$ — чистота исходного узла."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Боль в груди:**\n",
    "\n",
    " $\\text{Impurity decrease} = 0.498 - (\\dfrac{138}{138+159})\\cdot 0.364 - (\\dfrac{159}{138+159})\\cdot 0.336 = 0.149$\n",
    "\n",
    "**Хорошо циркулирует кровь:**\n",
    "\n",
    " $\\text{Impurity decrease} = 0.498 - (\\dfrac{164}{164+133})\\cdot 0.349 - (\\dfrac{133}{164+133})\\cdot 0.373 = 0.138$\n",
    "\n",
    "**Есть атеросклероз:**  \n",
    "\n",
    "$\\text{Impurity decrease} = 0.498 - (\\dfrac{123}{123+174})\\cdot 0.377 - (\\dfrac{174}{123+174})\\cdot 0.383 = 0.117$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/compute_impurity_decrease.png\" width=\"600\">\n",
    "\n",
    "**Выбираем это разбиение как приводящее к наибольшему уменьшению Impurity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наибольший $\\text{Impurity decrease}$ в признаке “боль в груди”. Значит, мы возьмем “боль в груди” как признак, на основании которого продолжим строить дерево.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/compute_gini_for_another_features.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый раз мы будем выбирать новые признаки. В одном листе один признак лучше разделяет его на 2, в другом — другой. Тут мы остановились при достижении глубины дерева 2.\n",
    "\n",
    "Мы могли выбрать другой критерий остановки. Например, когда у нас получатся листья, в которых есть объекты только 1 класса. В этом случае не имеет смысла использовать другие разбиения. Либо может сложиться ситуация, когда разбиение по признаку, которое мы дополнительно взяли, ситуацию никак не улучшает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для вещественных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/decision_tree_for_real_numbers.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вещественный признак сортируется, после чего мы выбираем оптимальный порог для разбиения. Для этого считаем `impurity_decrease` для каждого порога и выбираем лучший."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задач регрессии дерево строится практически так же, но есть несколько нюансов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/decision_tree_regression.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как лучше всего одним числом охарактеризовать все эти объекты, попавшие в один лист?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/regression_metrics.png\" width=\"900\"></center>\n",
    "\n",
    "<center><em>Метрики регрессии</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы вспомним статистику, то у нас нет однозначного ответа. Мы можем для распределения всех этих объектов в листе предсказывать наиболее частое значение, медиану, среднее значение.\n",
    "\n",
    "Обычно предсказывают среднее значение, потому что с ним легче всего работать и его чаще всего используют в статистике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотим оценить среднее всех объектов генеральной совокупности, попадающих в данный узел, используя объекты из тренировочной выборки, попавшие в данный узел.\n",
    "\n",
    "$$\\large \\overline{y} = \\dfrac {\\sum_i y_i} {n}$$\n",
    "\n",
    "У нашей оценки будет дисперсия, которая показывает, насколько сильно мы можем ошибаться по сравнению с реальным (несмещенным) средним.\n",
    "\n",
    "$$\\large D(Y) = \\dfrac {\\sum_{i=1}^n(y_i-\\overline{y})} {n-1} $$\n",
    "\n",
    "Из-за неточности в оценке среднего при оценке дисперсии в знаменателе стоит $n-1$. Желательно иметь в каждом листе достаточное число объектов, чтобы компенсировать эту $-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь надо сформулировать критерий качества узла для регрессионного дерева. Мы хотим, чтобы значения в узле отличались как можно меньше. В этом случае наше среднее будет предсказывать значение для объекта, попавшего в узел, с меньшей ошибкой. В идеале мы хотим, чтобы все значения были одинаковы.\n",
    "\n",
    "MSE на тренировочной выборке, если мы предсказываем ее среднее, будет таким:\n",
    "\n",
    "$$\\large \\text{MSE} = \\frac 1 N \\sum_{l=1}^L \\sum_{i=1}^{n_l} (y_{li} - \\overline{y_l})^2 = \\frac 1 N \\sum_{l=1}^L \\sum_{i=1}^{n_l}\\dfrac{n_l-1}{n_l}D(Y_l),$$\n",
    "\n",
    "где $N$ — общее количество объектов в выборке, $L$ — общее число листьев, $n_l$ — число объектов в листе $l$.\n",
    "\n",
    "Уменьшение дисперсии листьев $D(Y_l)$ приводит к уменьшению $MSE$.\n",
    "\n",
    "Дополнительно будем взвешивать дисперсии на размер узла. Иначе самыми выгодными будут разбиения, отправляющие в один из узлов только один объект."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбиение регрессионного дерева**:\n",
    "\n",
    "$$\\large R_1(j, s) = \\{ Y | x_j \\leq s \\} \\ and \\ R_2(j, s) = \\{ Y | x_j > s \\}$$\n",
    "\n",
    "Мера качества узла — дисперсия оценки $R_0$.\n",
    "\n",
    "Остальное так же, как с классификацией:\n",
    "\n",
    "$$\\large \\frac{D_{R_1} \\cdot n_1 + D_{R_2} \\cdot n_2}{n_1 + n_2} < D_{R_0} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преимущества и недостатки деревьев решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему деревья — очень мощный метод?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Взгляд с точки зрения функционального анализа**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/why_decision_tree_powerful_method.png\" width=\"900\">\n",
    "\n",
    "$\\displaystyle \\qquad \\qquad h(x) = \\sum \\sigma(\\dots \\sum(w^Tx)) \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad h(x) = \\sum_dc_dI\\{x \\in R_d\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У деревьев решений есть еще одно хорошее свойство. Позже вы познакомитесь с замечательной [теоремой об универсальном аппроксиматоре 📚[wiki]](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%A6%D1%8B%D0%B1%D0%B5%D0%BD%D0%BA%D0%BE). Ее суть в том, что нейросеть с одним скрытым слоем сможет аппроксимировать любую заданную гладкую функцию.\n",
    "\n",
    "Для деревьев решений есть аналогичная теорема, говорящая о том, что дерево может аппроксимировать любую заданную кусочно-постоянную функцию.\n",
    "\n",
    "Дерево решений, в отличие от нейронной сети, может адаптироваться к выборке любого размера, любому количеству признаков. Для нейронной сети эта теорема предполагает, что можно бесконечно увеличивать скрытые слои.\n",
    "\n",
    "В случае же с деревьями решений лист разбивается еще на 2 части. Это можно делать бесконечно до тех пор, пока в каждом листе не окажется по одному объекту. Это приведет к сильному переобучению, но, если бы у нас была вся генеральная совокупность, мы бы выучили ее гораздо легче деревом решений, чем нейронной сетью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Неустойчивость деревьев решений<a class=\"anchor\" style=\"autocontent\" id=\"Неустойчивость-деревьев-решений\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/instability_of_decision_trees.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деревья решений не используются в чистом виде, потому что они неустойчивы. Если у нас есть данные, и мы удалим из них 2 объекта, то дерево решений может сильно поменяться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продемонстрируем неустойчивость решения, получаемого при помощи деревьев решений, на примере датасета Iris ([ирисы Фишера 📚[wiki]](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0)).\n",
    "\n",
    "Ирисы Фишера состоят из данных о 150 экземплярах ириса, по 50 экземпляров трёх видов: Ирис щетинистый (Iris setosa), Ирис виргинский (Iris virginica) и Ирис разноцветный (Iris versicolor).\n",
    "\n",
    "Для каждого экземпляра измерялись четыре характеристики (в сантиметрах):\n",
    "\n",
    "1. Длина наружной доли околоцветника (англ. sepal length);\n",
    "2. Ширина наружной доли околоцветника (англ. sepal width);\n",
    "3. Длина внутренней доли околоцветника (англ. petal length);\n",
    "4. Ширина внутренней доли околоцветника (англ. petal width)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем учиться отделять Ирис виргинский (versicolor) от остальных видов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_iris()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df[\"target\"] = dataset.target != 1  # 0 for setosa, 1 - versicolor, 2 - virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем два разных разбиения на обучение и тест. И посмотрим, будут ли отличаться деревья, построенные для данных разбиений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "# first set of points\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(\n",
    "    df[dataset.feature_names], df[\"target\"], random_state=0\n",
    ")\n",
    "clf1 = DecisionTreeClassifier(max_depth=3)\n",
    "clf1.fit(x_train1, y_train1)\n",
    "\n",
    "# second set of points\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(\n",
    "    df[dataset.feature_names], df[\"target\"], random_state=42\n",
    ")\n",
    "clf2 = DecisionTreeClassifier(max_depth=3)\n",
    "clf2.fit(x_train2, y_train2)\n",
    "\n",
    "fn = [\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"]\n",
    "cn = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5), dpi=100)\n",
    "tree.plot_tree(clf1, feature_names=fn, class_names=cn, filled=True, ax=axes[0])\n",
    "tree.plot_tree(clf2, feature_names=fn, class_names=cn, filled=True, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что даже деревья максимальной глубины 3 уже не совпадают между собой. Справедливо отметить, что у нас маленький датасет — как правило, чем датасет больше, тем устойчивее будет получаться дерево на первых уровнях.\n",
    "\n",
    "Если использовать деревья бОльшей глубины, то и структура деревьев (то, как они выглядят, даже если не обращать внимания на конкретные признаки в узлах), будет отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set of points\n",
    "clf1 = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "clf1.fit(x_train1, y_train1)\n",
    "\n",
    "# second set of points\n",
    "clf2 = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "clf2.fit(x_train2, y_train2)\n",
    "\n",
    "\n",
    "fn = [\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"]\n",
    "cn = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5), dpi=100)\n",
    "tree.plot_tree(clf1, feature_names=fn, class_names=cn, filled=True, ax=axes[0])\n",
    "tree.plot_tree(clf2, feature_names=fn, class_names=cn, filled=True, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучение деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если алгоритм при небольшом изменении признаков сильно меняет свое решение,  то это указывает на возможное переобучение. Алгоритм сильно реагирует на любой шум в данных— доверять его решениям опасно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим это на синтетическом датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handson-ml\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_decision_boundary(\n",
    "    clf, x, y, axes=[-1.5, 2.5, -1, 1.5], alpha=0.85, contour=True, bolded=False\n",
    "):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    x_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(x_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap([\"#FEE7D0\", \"#bea6ff\", \"#B8E1EC\"])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap([\"#FEE7D0\", \"#5D5DA6\", \"#B8E1EC\"])\n",
    "        if bolded:\n",
    "            custom_cmap2 = ListedColormap([\"#FEE7D0\", \"#5D5DA6\", \"#000000\"])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2)\n",
    "    plt.plot(x[:, 0][y == 0], x[:, 1][y == 0], \"D\", c=\"#F9B041\", alpha=alpha)\n",
    "    plt.plot(x[:, 0][y == 1], x[:, 1][y == 1], \"o\", c=\"#2DA9E1\", alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "x, y = sklearn.datasets.make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x[:, 0][y == 0], x[:, 1][y == 0], \"D\", c=\"#F9B041\")\n",
    "plt.plot(x[:, 0][y == 1], x[:, 1][y == 1], \"o\", c=\"#2DA9E1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "clf = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "plot_decision_boundary(clf, x, y)\n",
    "plt.title(\"Decision border\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В областях, покрашенных в оранжевый, модель будет классифицировать точки как объекты из класса $0$. В синих — как объекты из класса $1$.\n",
    "\n",
    "Обратите внимание на странные рваные области на рисунке. В этих областях из-за шума, присутствующего в данных, оказались объекты неправильного класса. Дерево переобучилось под обучающую выборку.\n",
    "\n",
    "Что произойдет, если мы возьмем разные разбиения данных на обучение и тест для одного и того же датасета?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set of points\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x, y, random_state=1)\n",
    "clf1 = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
    "clf1.fit(x_train1, y_train1)\n",
    "\n",
    "# second set of points\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, random_state=2)\n",
    "clf2 = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
    "clf2.fit(x_train2, y_train2)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(clf1, x, y)\n",
    "plt.title(\"Decision border 1\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(clf2, x, y)\n",
    "plt.title(\"Decision border 2\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Границы решений поменялись. Исчезли одни \"рваные\" границы и появились другие. Наше дерево неустойчиво, из-за малейшего шума в данных оно может поменять свое предсказание. Оно переобучается на шум в данных.\n",
    "\n",
    "Говорят, что у нашего дерева высокий **variance**.\n",
    "\n",
    "Можно ли что-то поправить?\n",
    "\n",
    "У нас в настройках максимальная глубина дерева поставлена равной 20. Сделаем дерево глубины 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set of points\n",
    "clf1 = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "clf1.fit(x_train1, y_train1)\n",
    "\n",
    "# second set of points\n",
    "clf2 = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "clf2.fit(x_train2, y_train2)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(clf1, x, y)\n",
    "plt.title(\"Decision border 1\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(clf2, x, y)\n",
    "plt.title(\"Decision border 2\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или глубины 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set of points\n",
    "clf1 = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf1.fit(x_train1, y_train1)\n",
    "\n",
    "# second set of points\n",
    "clf2 = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf2.fit(x_train2, y_train2)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(clf1, x, y)\n",
    "plt.title(\"Decision border 1\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(clf2, x, y)\n",
    "plt.title(\"Decision border 2\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь полученные границы решений (почти) совпадают. Но наше дерево не в состоянии (в обоих случаях) уловить закономерность в исходных данных. Если мы отложим только тренировочный датасет, то увидим следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "\n",
    "clf1 = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf1.fit(x_train, y_train)\n",
    "\n",
    "clf2 = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
    "clf2.fit(x_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "plot_decision_boundary(clf1, x_train, y_train)\n",
    "plt.title(\"Decision border, depth=2, train only\", fontsize=14)\n",
    "plt.subplot(122)\n",
    "plot_decision_boundary(clf2, x_train, y_train)\n",
    "plt.title(\"Decision border, depth=20, train only\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в то время как дерево большой глубины выучило нашу тренировочную выборку почти идеально, дерево малой глубины для многих объектов из тренировочной выборки предсказывает не тот класс. Причем, оно не может исправиться просто в силу ограничения на глубину.\n",
    "\n",
    "В случае дерева с малой глубиной нам не хватает **сложности модели**, чтобы уловить **внутреннюю структуру данных**. Говорят, что у нашей модели высокий **bias**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias, Variance, Irreducible error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно показать, что ошибка любой модели раскладывается в сумму трех компонент:\n",
    "\n",
    "$$ \\large \\text{Model error} = \\text{Bias} + \\text{Variance} + \\text{Irreducible error} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias\n",
    "Обычно, высокий bias имеют модели, которые недостаточно сложны по сравнению с реальной закономерностью данных. Например, реальная зависимость, которую мы наблюдаем, нелинейная, а мы пытаемся аппроксимировать ее прямой линией. В этом случае наше решение заведомо смещено (biased) в сторону линейной модели, и мы будем систематически ошибаться в сравнении с реальной моделью данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/high_bias.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance\n",
    "Можно получить и обратную ситуацию. Если модель будет слишком сложная (в смысле своей выразительной способности) и \"гибкая\", то она сможет подстроиться под данные и выучить тренировочную выборку полностью. В этом случае модель будет подстраиваться под любой шум в данных и пытаться объяснить его какой-то сложной закономерностью.\n",
    "\n",
    "Малое изменение в данных будет приводить к большим изменениям в прогнозе модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/high_variance.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда bias и variance представляют еще таким образом:\n",
    "1. Можно быть точным и попадать всегда в центр мишени — это соответствует низкому bias и низкому variance.\n",
    "2. Можно попадать примерно в центр мишени, но при этом с большим разбросом — низкий bias, но высокий variance.\n",
    "3. Можно стрелять кучно, но не в центр — это высокий bias и низкий variance.\n",
    "4. Можно просто стрелять наугад — это высокий bias и высокий variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/low_hight_bias_variance.png\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irreducible error\n",
    "Если удачно подобрать модель и ее гиперпараметры, то гипотетически можно точно предсказать среднее значение ожидаемой величины, то есть получить и низкий $\\text{Bias}$, и низкий $\\text{Variance}$.\n",
    "\n",
    "В реальности при измерении физической величины есть случайные непредсказуемые погрешности — отклонения от среднего. Из-за этого предсказания всегда будут иметь определенный уровень ошибки, ниже которого опуститься нельзя — это и есть $\\text{Irreducible error}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/low_bias_low_variance.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias vs variance\n",
    "\n",
    "В практических задачах, когда невозможно подобрать реальную модель данных, не получается бесконечно уменьшать и Bias, и Variance — приходится искать компромисс (bias-variance tradeoff). С какого-то момента при уменьшении Bias начнет увеличиваться Variance, и наоборот. Задача исследователя — найти точку оптимума.\n",
    "\n",
    "Можно построить зависимость этих величин от сложности модели (capacity). По мере увеличения сложности Variance имеет тенденцию к возрастанию, а Bias — к убыванию. Более сложные модели подстраиваются под случайные шумы обучающей выборки, а более простые — не могут воспроизвести реальные закономерности.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/bias_variance_tradeoff.png\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Управлять эффектом variance и bias можно как с помощью выбора модели, так и с помощью выбора гиперпараметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продемонстрируем источники компонент Bias и Variance на примере регрессии зашумленной косинусоиды методом k-NN. Создадим функцию для генерации небольшой обучающей выборки и отобразим ее на графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_points = 300\n",
    "num_grid = 500\n",
    "x_max = 3.14\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "def get_sample(num_points, x_max, std=0.3, x_sample=None):\n",
    "    if x_sample is None:\n",
    "        x_sample = (np.random.rand(num_points) - 0.5) * 2 * x_max\n",
    "    y_sample = np.cos(x_sample.flatten()) + np.random.randn(x_sample.shape[0]) * std\n",
    "    return x_sample.reshape(-1, 1), y_sample\n",
    "\n",
    "\n",
    "x_grid = np.linspace(-x_max, x_max, num_grid).reshape(-1, 1)\n",
    "x_sample, y_sample = get_sample(num_points=num_points, x_max=x_max)\n",
    "_, y_true = get_sample(num_points=num_points, x_max=x_max, std=0, x_sample=x_grid)\n",
    "\n",
    "plt.scatter(x_sample, y_sample, c=\"#bea6ff\", label=\"Noise\")\n",
    "plt.plot(x_grid, y_true, \"b--\", linewidth=4, label=\"Real func\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим одну и ту же модель с параметром количества соседей $1$ на разных выборках. Сравним предсказания моделей друг с другом и с реальной целевой функцией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "num_points = 30\n",
    "num_models = 3\n",
    "plt.figure(figsize=(24, 6))\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=1)\n",
    "y_pred = np.zeros((num_models, num_grid))\n",
    "sample_color = [\"#00E134\", \"#FF9100\", \"#FF00B3\"]\n",
    "for model_num in range(num_models):\n",
    "    x_sample, y_sample = get_sample(num_points=num_points, x_max=x_max)\n",
    "    model.fit(x_sample, y_sample)\n",
    "    y_pred[model_num] = model.predict(x_grid)\n",
    "    _, y_true = get_sample(num_points=num_points, x_max=x_max, std=0, x_sample=x_grid)\n",
    "\n",
    "    plt.subplot(1, 3, model_num + 1)\n",
    "    plt.scatter(\n",
    "        x_sample, y_sample, c=sample_color[model_num], label=f\"sample {model_num+1}\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        x_grid,\n",
    "        y_pred[model_num],\n",
    "        c=sample_color[model_num],\n",
    "        alpha=0.8,\n",
    "        label=f\"model trained on sample {model_num+1}\",\n",
    "    )\n",
    "    plt.plot(x_grid, y_true, \"b--\", linewidth=4, label=\"real mean\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.ylim(-1.5, 1.8)\n",
    "    plt.legend(loc=\"lower center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания моделей отличаются друг от друга и от истинной кривой средних значений косинуса.\n",
    "\n",
    "Обучим 1000 моделей, для разного количества соседей ($1, 3, 25$) на разных подвыборках наших данных. Выберем одну тестовую точку и посмотрим, как предсказания моделей в этой точке зависят от гиперпараметра — количества соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "num_models = 1000\n",
    "\n",
    "for n_neighbors in [1, 3, 25]:\n",
    "    model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "\n",
    "    y_pred = np.zeros((num_models, num_grid))\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "    plt.subplot(gs[0])\n",
    "\n",
    "    for model_num in range(num_models):\n",
    "        x_sample, y_sample = get_sample(num_points=num_points, x_max=x_max)\n",
    "        model.fit(x_sample, y_sample)\n",
    "        y_pred[model_num] = model.predict(x_grid)\n",
    "        plt.plot(x_grid, y_pred[model_num], alpha=0.01, c=\"g\", linewidth=5)\n",
    "\n",
    "    _, y_true = get_sample(num_points=num_points, x_max=x_max, std=0, x_sample=x_grid)\n",
    "    plt.plot(x_grid, y_true, c=\"b\", linewidth=3, label=\"real mean\")\n",
    "    plt.axvline(x=x_grid[num_grid // 2], c=\"r\", linewidth=1, label=\"X text point\")\n",
    "    plt.xlim((-x_max, x_max))\n",
    "    plt.ylim((-1, 2))\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.gca().set_title(f\"{num_models} models: {n_neighbors} nearest neighbours\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.subplot(gs[1])\n",
    "    var = y_pred[:, num_grid // 2].var()\n",
    "    bias = np.abs(y_true[num_grid // 2] - y_pred[:, num_grid // 2].mean())\n",
    "    plt.hist(\n",
    "        y_pred[:, num_grid // 2],\n",
    "        bins=15,\n",
    "        color=\"g\",\n",
    "        alpha=0.5,\n",
    "        orientation=\"horizontal\",\n",
    "        label=f\"predictions: \\nvar = {var:.2f}\\nbias = {bias:.2f}\",\n",
    "    )\n",
    "    plt.axhline(y=y_true[num_grid // 2], c=\"b\", linewidth=3, label=\"real mean\")\n",
    "    plt.ylim((-1, 2))\n",
    "    plt.xlabel(\"hist counts\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.gca().set_title(f\"predictions at test point\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По мере увеличения числа соседей:\n",
    "- повышается абсолютное значение сдвига среднего значения предсказаний моделей относительно истинного значения (Bias) — в среднем предсказания моделей становятся менее точными\n",
    "- снижается дисперсия предсказаний модели (Variance) — предсказания моделей становятся устойчивее и слабее зависят от конкретной выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применительно к деревьям\n",
    "Дерево малой глубины имеет малую сложность и высокий Bias.\n",
    "\n",
    "Дерево большой глубины имеет высокую сложность и высокий Variance.\n",
    "\n",
    "Можно подобрать для дерева идеальную capacity, когда Bias и Variance будут суммарно давать наименьший вклад в ошибку. Этим мы занимаемся при подборе параметров.\n",
    "Но есть и другие способы борьбы с Variance и/или Bias, которые мы разберем позже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что если бы мы могли не просто брать решение дерева, а привязывать к этому какую-то статистику, например, сколько деревьев, построенных по подобной процедуре, приняли такое же решение, то мы смогли бы получить более качественное решение.\n",
    "\n",
    "Если наложить решающие границы 100 решающих деревьев, построенных на разных выборках из $x, y$, то мы увидим, что \"хорошие области\", соответствующие реальному разделению данных, будут общими между деревьями, а плохие — индивидуальны.\n",
    "К сожалению, в реальности мы не можем брать бесконечное число наборов данных из генеральной совокупности (представленной в данном случае $x, y$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(1, 101):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=i)\n",
    "    clf = DecisionTreeClassifier(max_depth=20, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    plot_decision_boundary(clf, x, y, alpha=0.02, contour=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бутстрэп\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы хотим получить какое-то представление о точности нашей оценки: качества модели, корреляции между двумя переменными и т.д. И мы не знаем, как распределена характеристика, которую мы оцениваем.\n",
    "\n",
    "Есть много подходов к тому, как получить такую оценку, и один из них — бутстрэп."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/bootstrap.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что мы делаем:\n",
    "\n",
    "1. Делаем из нашего исходного датасета N выборок такого же размера с повторениями.\n",
    "\n",
    "2. Для каждой полученной выборки (обычно их называют **псевдовыборками**) считаем характеристику, для которой хотим получить оценку.\n",
    "\n",
    "3. В результате такой процедуры получаем N значений характеристики. Строим гистограмму этих значений. Получаем примерное распределение нашей характеристики.\n",
    "\n",
    "4. Можем построить 95% доверительный интервал для нашей характеристики. Для этого отрезаем 2.5% самых больших значений и самых малых.\n",
    "\n",
    "Давайте попробуем сделать это на двух практических примерах.\n",
    "\n",
    "Подробнее про [бутстрэп 🎓[article]](https://www.jstor.org/stable/2958830?typeAccessWorkflow=login&seq=1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение доверительного интервала для качества метрики\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы хотим сравнить поведение двух моделей на тестовом датасете. Допустим, нас интересует F1-score. Как нам это сделать?\n",
    "\n",
    "Сгенерируем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "size = 1500\n",
    "y = np.random.choice([0, 1], size=size, replace=True)\n",
    "print(f\"shape y: {y.shape}\")\n",
    "print(f\"First 10 values: {y[0:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая имитирует поведение модели, угадывающей правильный класс в $p$ процентах случаев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_model(y_real, p):\n",
    "    guessed = np.random.choice([True, False], size=size, replace=True, p=[p, 1 - p])\n",
    "    y_pred = np.zeros_like(y_real)\n",
    "    y_pred[guessed] = y_real[guessed]\n",
    "    y_pred[~guessed] = 1 - y_real[~guessed]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас две модели обладают одинаковым качеством, а третья — лучшим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = lambda y: guess_model(y, p=0.7)\n",
    "model2 = lambda y: guess_model(y, p=0.7)\n",
    "model3 = lambda y: guess_model(y, p=0.75)\n",
    "\n",
    "np.random.seed(0)\n",
    "y_pred1 = model1(y)\n",
    "y_pred2 = model2(y)\n",
    "y_pred3 = model3(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый вариант — просто посчитать F1-score каждой модели и проранжировать их в соответствии с F1-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "qual1 = f1_score(y_true=y, y_pred=y_pred1)\n",
    "qual2 = f1_score(y_true=y, y_pred=y_pred2)\n",
    "qual3 = f1_score(y_true=y, y_pred=y_pred3)\n",
    "\n",
    "print(f\" qual1: {qual1:.3f}\\n qual2: {qual2:.3f}\\n qual3: {qual3:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужная нам модель выбрана, но почему мы считаем различия между второй и третьей моделью значимыми, а между первой и второй — нет?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"qual2 - qual1: {(qual2 - qual1):.3f}\\nqual3 - qual2: {(qual3 - qual2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой способ (при помощи точечной оценки) может привести к ошибке, так как не дает нам судить о **значимости** отличий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует много способов посчитать значимость данного отличия. Мы рассмотрим способ сравнения на основе bootstrap. Об остальных можете почитать в обзоре, приведенном в списке литературы.\n",
    "\n",
    "Способ состоит в применении бутстрэпа к предсказаниям модели и реальным меткам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_metric(x, y, metric_fn, samples_cnt=1000, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    b_metric = np.zeros(samples_cnt)\n",
    "    for it in range(samples_cnt):\n",
    "        poses = np.random.choice(x.shape[0], size=x.shape[0], replace=True)\n",
    "\n",
    "        x_boot = x[poses]\n",
    "        y_boot = y[poses]\n",
    "        m_val = metric_fn(x_boot, y_boot)\n",
    "        b_metric[it] = m_val\n",
    "\n",
    "    return b_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так мы сможем получить распределние нашей оценки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "boot_f1score_m1 = bootstrap_metric(\n",
    "    y, y_pred1, metric_fn=lambda x, y: f1_score(y_true=x, y_pred=y)\n",
    ")\n",
    "\n",
    "# plot histogram of the obtained values:\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(boot_f1score_m1)\n",
    "plt.title(\"bootstrap f1 scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_f1score_m1 = bootstrap_metric(\n",
    "    y, y_pred1, metric_fn=lambda x, y: f1_score(y_true=x, y_pred=y)\n",
    ")\n",
    "boot_f1score_m2 = bootstrap_metric(\n",
    "    y, y_pred2, metric_fn=lambda x, y: f1_score(y_true=x, y_pred=y)\n",
    ")\n",
    "boot_f1score_m3 = bootstrap_metric(\n",
    "    y, y_pred3, metric_fn=lambda x, y: f1_score(y_true=x, y_pred=y)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим 90% доверительный интервал качества для каждой модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.10\n",
    "print(\n",
    "    \"F1 score for the 1st model: \",\n",
    "    np.quantile(boot_f1score_m1, q=[alpha / 2, 1 - alpha / 2]),\n",
    ")\n",
    "print(\n",
    "    \"F1 score for the 2st model: \",\n",
    "    np.quantile(boot_f1score_m2, q=[alpha / 2, 1 - alpha / 2]),\n",
    ")\n",
    "print(\n",
    "    \"F1 score for the 3st model: \",\n",
    "    np.quantile(boot_f1score_m3, q=[alpha / 2, 1 - alpha / 2]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы видим, что доверительные интервалы для качества первой и второй модели практически одинаковы, в то время как доверительный интервал для качества третьей модели от них сильно отличается и не пересекается.\n",
    "\n",
    "Можем построить боксплот ([box-plot 📚[wiki]](https://ru.wikipedia.org/wiki/%D0%AF%D1%89%D0%B8%D0%BA_%D1%81_%D1%83%D1%81%D0%B0%D0%BC%D0%B8)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=pd.DataFrame({\"model1\": boot_f1score_m1,\n",
    "                               \"model2\": boot_f1score_m2,\n",
    "                               \"model3\": boot_f1score_m3})\n",
    ")\n",
    "plt.ylabel(\"f1 score\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы могли бы использовать и тест [Манна — Уитни 📚[wiki]](https://ru.wikipedia.org/wiki/U-%D0%BA%D1%80%D0%B8%D1%82%D0%B5%D1%80%D0%B8%D0%B9_%D0%9C%D0%B0%D0%BD%D0%BD%D0%B0_%E2%80%94_%D0%A3%D0%B8%D1%82%D0%BD%D0%B8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "statistic_m1_m2, p_value_m1_m2 = mannwhitneyu(boot_f1score_m1, boot_f1score_m2)\n",
    "statistic_m1_m3, p_value_m1_m3 = mannwhitneyu(boot_f1score_m1, boot_f1score_m3)\n",
    "statistic_m2_m3, p_value_m2_m3 = mannwhitneyu(boot_f1score_m2, boot_f1score_m3)\n",
    "\n",
    "# fmt: off\n",
    "print(f\"m1 and m2 Mann–Whitney statistic: {statistic_m1_m2:<10} p-value:{p_value_m1_m2}\")\n",
    "print(f\"m1 and m3 Mann–Whitney statistic: {statistic_m1_m3:<10} p-value:{p_value_m1_m3}\")\n",
    "print(f\"m2 and m3 Mann–Whitney statistic: {statistic_m2_m3:<10} p-value:{p_value_m2_m3}\")\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что результат идентичен. В дальнейшем мы будем использовать только графки для оценки, но на практике полезно использовать несколько способов, чтобы избежать ошибочных суждений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим на другом примере, используя данные о людях с наличием или отсутствием сердечных заболеваний. Загрузим датасет [Heart Disease 🛠️[doc]](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/heart.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = heart_dataset.drop(\"target\", axis=1)\n",
    "y = heart_dataset[\"target\"] > 0\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y.values, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_model = GridSearchCV(\n",
    "    SVC(), {\"kernel\": (\"linear\", \"rbf\"), \"C\": [0.01, 0.1, 1, 10]}\n",
    ").fit(x_train, y_train)\n",
    "\n",
    "logr_model = GridSearchCV(\n",
    "    LogisticRegression(solver=\"liblinear\", max_iter=100000),\n",
    "    {\"penalty\": (\"l1\", \"l2\"), \"C\": [0.01, 0.1, 1, 10, 100]},\n",
    ").fit(x_train, y_train)\n",
    "\n",
    "# few objects in the leaf - poor estimates of class probabilities - the model is overfitting\n",
    "dt_model = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    {\"max_depth\": [1, 3, 5, 7, 10], \"min_samples_leaf\": [1, 3, 5, 10]},\n",
    ").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score  # PR-AUC\n",
    "\n",
    "y_pred1 = svc_model.decision_function(\n",
    "    x_test\n",
    ")  # by default, SVM gives score to each object instead of probabilities\n",
    "y_pred2 = logr_model.predict_proba(x_test)[:, 1]\n",
    "y_pred3 = dt_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "qual1 = average_precision_score(y_true=y_test, y_score=y_pred1)\n",
    "qual2 = average_precision_score(y_true=y_test, y_score=y_pred2)\n",
    "qual3 = average_precision_score(y_true=y_test, y_score=y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Logistic regression pr-auc: {qual1:.03f}\")\n",
    "print(f\"SVC pr-auc: {qual2:.03f}\")\n",
    "print(f\"DecisionTreeClassifier pr-auc: {qual3:.03f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подсчитаем бутстрэп-оценки. Обратите внимание на то, что теперь мы передаем не предсказания, а вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_score_logreg = bootstrap_metric(\n",
    "    y_test, y_pred1, metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y)\n",
    ")\n",
    "boot_score_svc = bootstrap_metric(\n",
    "    y_test, y_pred2, metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y)\n",
    ")\n",
    "boot_score_dt = bootstrap_metric(\n",
    "    y_test, y_pred3, metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y)\n",
    ")\n",
    "\n",
    "alpha = 0.10\n",
    "print(\n",
    "    \"Logistic regression pr-auc 90%-ci: \",\n",
    "    np.quantile(boot_score_logreg, q=[alpha / 2, 1 - alpha / 2]),\n",
    ")\n",
    "print(\"SVC pr-auc 90%-ci:\", np.quantile(boot_score_svc, q=[alpha / 2, 1 - alpha / 2]))\n",
    "print(\n",
    "    \"DecisionTreeClassifier pr-auc 90%-ci:\",\n",
    "    np.quantile(boot_score_dt, q=[alpha / 2, 1 - alpha / 2]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что качество SVC и логистической регрессии почти не отличается, а дерево решений уступает обеим моделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=pd.DataFrame({\"Log-reg\": boot_score_logreg,\n",
    "                               \"SVC\": boot_score_svc,\n",
    "                               \"DT\": boot_score_dt})\n",
    ")\n",
    "plt.ylabel(\"PR-AUC\", size=20)\n",
    "plt.xlabel(\"Base models\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ансамбли"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корректирующий код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть сигнал:\n",
    "\n",
    "\n",
    "<font color=2BA8E0 size=30>1110110011</font>\n",
    "\n",
    "Но при передаче на другое устройство в нем могут возникать ошибки:\n",
    "\n",
    "<font color=2BA8E0 size=30>1</font><font color=red size=30>0</font><font color=2BA8E0 size=30>1011</font><font color=red size=30>1</font><font color=2BA8E0 size=30>011</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое простое решение возникшей проблемы:\n",
    "\n",
    " 1. Шум, который вносит ошибки, скорее всего не зависит от места в сигнале\n",
    " 2. Передадим 3 раза один и тот же сигнал\n",
    "\n",
    "<font color=2BA8E0 size=30>1</font><font color=red size=30>0</font><font color=2BA8E0 size=30>1011</font><font color=red size=30>1</font><font color=2BA8E0 size=30>011</font>\n",
    "\n",
    "<font color=2BA8E0 size=30>1110</font><font color=red size=30>0</font><font color=2BA8E0 size=30>10011</font>\n",
    "\n",
    "<font color=2BA8E0 size=30>11</font><font color=red size=30>0</font><font color=2BA8E0 size=30>0110</font><font color=red size=30>1</font> <font color=2BA8E0 size=30>11</font>\n",
    "\n",
    "\n",
    "\n",
    " 3. Усредним, что получилось (в каждом случае возьмем наиболее часто встречающуюся цифру)\n",
    "\n",
    "<font color=2BA8E0 size=30>1110110011</font>\n",
    "\n",
    "\n",
    " 4. С большой долей вероятности итоговый сигнал восстановится\n",
    " 5. Чем больше копий сигналов передастся, тем выше вероятность, что сигнал восстановится полностью корректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем код, чтобы удостовериться в наших выводах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_signal(size, random_state=42):\n",
    "    signal = np.random.choice([0, 1], size, replace=True)\n",
    "    return signal\n",
    "\n",
    "\n",
    "def compare_signs(sig1, sig2):\n",
    "    return (sig1 != sig2).sum()\n",
    "\n",
    "\n",
    "def add_noise(sig, noise_p=0.20):\n",
    "    sig = sig.copy()\n",
    "    changed = np.random.choice(\n",
    "        [True, False], sig.shape[0], replace=True, p=[noise_p, 1 - noise_p]\n",
    "    )\n",
    "    sig[changed] = 1 - sig[changed]\n",
    "    return sig\n",
    "\n",
    "\n",
    "def average_signals(sigs):\n",
    "    sig = np.mean(sigs, axis=0)\n",
    "    sig = np.round(sig, 0)\n",
    "    return sig\n",
    "\n",
    "\n",
    "def send_signal(signal, tries):\n",
    "    passed_sigs = [add_noise(signal) for _ in range(tries)]\n",
    "    fin_signal = average_signals(passed_sigs)\n",
    "    return fin_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "repeats = 1000\n",
    "signals_cnt_rng = range(1, 30, 2)\n",
    "\n",
    "signal = get_signal(10)\n",
    "mistakes = np.zeros((repeats, len(signals_cnt_rng)))\n",
    "\n",
    "for j, sig_cnt in enumerate(signals_cnt_rng):\n",
    "    for i in range(repeats):\n",
    "        rec_sig = send_signal(signal, sig_cnt)\n",
    "        mistakes[i, j] = compare_signs(rec_sig, signal)\n",
    "\n",
    "\n",
    "mn = mistakes.mean(axis=0)\n",
    "sd = mistakes.std(axis=0)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Number of error in signal\", fontsize=14)\n",
    "plt.ylabel(\"Number of errors\", fontsize=14)\n",
    "plt.xlabel(\"Number of signals passed at once\", fontsize=14)\n",
    "plt.plot(signals_cnt_rng, mn)\n",
    "plt.fill_between(signals_cnt_rng, mn - sd, mn + sd, facecolor=\"blue\", alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Оказывается, это имеет отношение к проблеме, с которой мы столкнулись с деревьями решений.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Усреднение предсказания классификаторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постановка задачи:\n",
    "\n",
    "Есть 10 объектов, в реальности все принадлежат классу 1\n",
    "\n",
    "\n",
    "<font color=2BA8E0 size=30>1111111111</font>\n",
    "\n",
    "Пусть у нас есть три **независимых** классификатора A, B и C. Каждый предсказывает 1 в 70% случаев.\n",
    "\n",
    "\n",
    "Мы хотим получить общий классификатор на основании этих трех.\n",
    "\n",
    "\n",
    "\n",
    "Мы хотим получить предсказание базовых классификаторов и применить к ним какую-то функцию, которая выдаст итоговый ответ. Вид этой функции задается заранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем просто усреднять предсказание наших классификаторов\n",
    "\n",
    "$$\\large h(x) = \\dfrac 1 T \\sum_{i=1}^{T}a_i(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простое голосование\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/simple_voting.png\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем вероятность того, что:\n",
    "\n",
    " 1. Все три классификатора верны: $0.7 * 0.7 * 0.7 = 0.3429$\n",
    " 2. Два классификатора верны: $0.7 * 0.7 * 0.3 + 0.7 * 0.3 * 0.7 + 0.3 * 0.7 * 0.7 = 0.4409$\n",
    "\n",
    "Таким образом, если брать большинство голосов, то мы будем в 78% случаев предсказывать верно. Мы взяли 3 классификатора, которые сами по себе были не очень хорошими, и получили классификатор лучшего качества.\n",
    "Если взять больше классификаторов, то ситуация будет еще лучше.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть теперь у нас три классификатора, выдающие следующие предсказания\n",
    "\n",
    "<font color=2BA8E0 size=30>11111111</font><font color=red size=30>00</font> — $80\\%$ точность\n",
    "\n",
    "<font color=2BA8E0 size=30>11111111</font><font color=red size=30>00</font> — $80\\%$ точность\n",
    "\n",
    "<font color=2BA8E0 size=30>1</font></font><font color=red size=30>0</font><font color=2BA8E0 size=30>111111</font><font color=red size=30>00</font> — $70\\%$ точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если объединим предсказания, то получим:\n",
    "\n",
    "<font color=2BA8E0 size=30>11111111</font><font color=red size=30>00</font> — $80\\%$ точность\n",
    "\n",
    "Потому что очень **высокая зависимость предсказаний**. Выше видно, что два классификатора предсказывают абсолютно одинаково. Вероятность, что они делают это случайно, очень мала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот если возьмем такие классификаторы, то все получится:\n",
    "\n",
    "<font color=2BA8E0 size=30>11111111</font><font color=red size=30>00</font> — $80\\%$ точность\n",
    "\n",
    "<font color=red size=30>0</font><font color=2BA8E0 size=30>111</font><font color=red size=30>0</font><font color=2BA8E0 size=30>111</font><font color=red size=30>0</font><font color=2BA8E0 size=30>1</font> — $70\\%$ точность\n",
    "\n",
    "<font color=2BA8E0 size=30>1</font><font color=red size=30>000</font><font color=2BA8E0 size=30>1</font><font color=red size=30>0</font><font color=2BA8E0 size=30>1111</font> — $60\\%$ точность\n",
    "\n",
    "\n",
    "Усреднение:\n",
    "\n",
    "<font color=2BA8E0 size=30>11111111</font><font color=red size=30>0</font><font color=2BA8E0 size=30>1</font> — $90\\%$ точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зависимость качества ансамбля от качества индивидуального предсказателя и от числа предсказателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(y_real, p, cnt):\n",
    "    size = y_real.shape[0]\n",
    "    guessed = np.random.choice([True, False], (cnt, size), p=[p, 1 - p])\n",
    "    y = np.repeat(y_real.reshape(1, -1), cnt, axis=0)\n",
    "    y[~guessed] = 1 - y[~guessed]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "size = 1000\n",
    "reps = 10\n",
    "\n",
    "cnt_base_predictors = [1] + list(range(5, 105, 5))\n",
    "single_qual = [0.45, 0.5, 0.51, 0.55, 0.6, 0.75, 0.9]\n",
    "\n",
    "dt = {\"cnt\": [], \"single_qual\": [], \"accuracy\": []}\n",
    "\n",
    "for i in range(reps):\n",
    "    y_real = np.random.choice([0, 1], size)\n",
    "    for cnt in cnt_base_predictors:\n",
    "        for p in single_qual:\n",
    "            preds = get_predictions(y_real, p, cnt)\n",
    "            voting = np.round(preds.mean(axis=0))\n",
    "            accuracy = (y_real == voting).mean()\n",
    "            dt[\"cnt\"].append(cnt)\n",
    "            dt[\"single_qual\"].append(f\"{p:.02}\")\n",
    "            dt[\"accuracy\"].append(accuracy)\n",
    "\n",
    "results = pd.DataFrame(dt)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "sns.lineplot(data=results, x=\"cnt\", y=\"accuracy\", hue=\"single_qual\", lw=3, alpha=0.5)\n",
    "plt.xlabel(\"Number of base classifiers\", size=20)\n",
    "plt.ylabel(\"Accuracy\", size=20)\n",
    "plt.legend(loc=\"best\", fontsize=12, title=\"Single classifier quality\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что:\n",
    "1. Чем лучше базовый классификатор, тем меньше нужно классификаторов при прочих равных условиях для достижения высокого качества.\n",
    "2. Если качество базового классификатора даже чуть больше 0.5, то качество ансамбля растет с увеличением числа моделей в ансамбле.\n",
    "3. Если качество базового классификатора неотличимо от случайного (0.5), то качество ансамбля будет оставаться равным 0.5.\n",
    "4. Если качество базового классификатора ниже случайного (0.5), то качество ансамбля стремится к 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коррелированность моделей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как зависит качество предсказания от коррелированности предсказателей. Конкретно — от ожидаемой коррелированности вероятностей ошибиться на данном объекте для любой взятой пары классификаторов из ансамбля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "\n",
    "def get_correlated_predictions(y_real, p, cnt, r):\n",
    "    size = y_real.shape[0]\n",
    "    x1 = np.random.uniform(0, 1, size)\n",
    "    x2 = np.random.uniform(0, 1, (cnt, size))\n",
    "    q = np.sqrt(r)\n",
    "    y = q * x1 + (1 - q**2) ** 0.5 * x2  # y variables now correlated with correlation=r\n",
    "    y_mod = np.zeros_like(y)\n",
    "    for i in range(y.shape[0]):\n",
    "        y_mod[i] = scipy.stats.rankdata(y[i])\n",
    "\n",
    "    y = y_mod / size  # back to uniform, slightly affects correlations\n",
    "\n",
    "    y_pred = np.repeat(y_real.reshape(1, -1), cnt, axis=0)\n",
    "    y_pred[y < 1 - p] = 1 - y_pred[y < 1 - p]  # to predictions, affects correlations\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x = np.arange(0, 1, 0.05)\n",
    "accuracy = np.zeros_like(x)\n",
    "p = 0.7\n",
    "cnt = 100\n",
    "for ind, r in enumerate(x):\n",
    "    preds = get_correlated_predictions(y_real, p, cnt, r)\n",
    "    voting = np.round(preds.mean(axis=0))\n",
    "    accuracy[ind] = (y_real == voting).mean()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title(f\"Accuracy of {cnt} classifiers ensemble\", size=20)\n",
    "plt.xlabel(\"Correlation among classifiers\", size=20)\n",
    "plt.ylabel(\"Accuracy\", size=20)\n",
    "plt.axhline(y=p, color=\"red\", lw=5, ls=\"--\", label=\"Single classifier\")\n",
    "sns.lineplot(x=x, y=accuracy, lw=5, label=\"Ensemble\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что по мере увеличения коррелированности моделей качество все больше и больше приближается к качеству одной базовой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging = Bootstrap aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужны классификаторы, которые сами по себе предсказывают лучше, чем случайные, при этом они должны быть не коррелированы. На самом деле это нетривиальная задача: откуда нам брать разные классификаторы, если у нас один датасет?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/bagging.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый вариант — нам поможет уже рассмотренный bootstrap:\n",
    "\n",
    "1. Делаем из нашего исходного датасета N выборок такого же размера с повторениями.\n",
    "\n",
    "2. На каждой **псевдовыборке** строим отдельную модель. Чтобы полученные модели были слабо зависимы, будем использовать алгоритм, который чувствителен к небольшим изменениям в выборке.\n",
    "\n",
    "3. Получаем N слабо зависимых моделей.\n",
    "\n",
    "4. Когда нам нужно сделать предсказание для нового объекта, делаем предсказание каждой из N моделей, а затем усредняем предсказание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `sklearn` для бэггинга можно использовать класс `BaggingClassifier` из `sklearn.ensemble`. Мы напишем свой код для бэггинга для большей наглядности происходящего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем свой bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "\n",
    "def get_bootstrap_sample(x, y):\n",
    "    size = x.shape[0]\n",
    "    poses = np.random.choice(size, size=size, replace=True)\n",
    "    x_boot = x[poses]\n",
    "    y_boot = y[poses]\n",
    "    return x_boot, y_boot\n",
    "\n",
    "\n",
    "class BaggingBinaryClassifierEnsemble:\n",
    "    def __init__(self, base_classifier, ensemble_size, random_state=42):\n",
    "        self.base_classifier = base_classifier\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.random_state = random_state\n",
    "        self.ensemble = []\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        np.random.seed(self.random_state)\n",
    "        for est_id in range(self.ensemble_size):\n",
    "            x_boot, y_boot = get_bootstrap_sample(x, y)\n",
    "            model = sklearn.clone(self.base_classifier)  # create new base model\n",
    "            model.fit(x_boot, y_boot)\n",
    "            self.ensemble.append(model)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        if not self.ensemble:\n",
    "            raise Exception(\"Unfitted model\")\n",
    "\n",
    "        y_pred = 0\n",
    "        for est in self.ensemble:\n",
    "            y_pred += est.predict(x)\n",
    "        y_pred = y_pred / self.ensemble_size\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_proba = self.predict_proba(x)\n",
    "        y_pred = np.round(y_proba)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классифицируем людей с больным сердцем и нет, используя bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты здесь и далее будем использовать параметры моделей, подобранные ранее, когда мы использовали их вне ансамбля. В данном случае это не имеет значения, но в случае разбираемых далее случайного леса и градиентного бустинга параметры подбирают **вместе** с построением ансамбля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/heart.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = heart_dataset.drop(\"target\", axis=1)\n",
    "y = heart_dataset[\"target\"] > 0\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_model = GridSearchCV(\n",
    "    SVC(), {\"kernel\": (\"linear\", \"rbf\"), \"C\": [0.01, 0.1, 1, 10]}\n",
    ").fit(x_train, y_train)\n",
    "\n",
    "logr_model = GridSearchCV(\n",
    "    LogisticRegression(solver=\"liblinear\", max_iter=100000),\n",
    "    {\"penalty\": (\"l1\", \"l2\"), \"C\": [0.01, 0.1, 1, 10, 100]},\n",
    ").fit(x_train, y_train)\n",
    "\n",
    "# few objects in the leaf - poor estimates of class probabilities - the model is overtraining\n",
    "dt_model = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    {\"max_depth\": [1, 3, 5, 7, 10], \"min_samples_leaf\": [1, 3, 5, 10]},\n",
    ").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опробуем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_dt = BaggingBinaryClassifierEnsemble(\n",
    "    dt_model.best_estimator_, ensemble_size=100\n",
    ")\n",
    "\n",
    "bagging_logreg = BaggingBinaryClassifierEnsemble(\n",
    "    logr_model.best_estimator_, ensemble_size=100\n",
    ")\n",
    "\n",
    "bagging_svc = BaggingBinaryClassifierEnsemble(\n",
    "    svc_model.best_estimator_, ensemble_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_dt.fit(x_train.values, y_train.values)\n",
    "bagging_logreg.fit(x_train.values, y_train.values)\n",
    "bagging_svc.fit(x_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_blr = bagging_logreg.predict_proba(x_test.values)\n",
    "y_pred_bsvc = bagging_svc.predict_proba(x_test.values)\n",
    "y_pred_bdt = bagging_dt.predict_proba(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score  # PR-AUC\n",
    "\n",
    "qual_blr = average_precision_score(y_true=y_test, y_score=y_pred_blr)\n",
    "qual_bsvc = average_precision_score(y_true=y_test, y_score=y_pred_bsvc)\n",
    "qual_bdt = average_precision_score(y_true=y_test, y_score=y_pred_bdt)\n",
    "print(f\"Bagged Logistic regression pr-auc: {qual_blr:.03f}\")\n",
    "print(f\"Bagged SVC pr-auc: {qual_bsvc :.03f}\")\n",
    "print(f\"Bagged DecisionTreeClassifier pr-auc: {qual_bdt:.03f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_metric(x, y, metric_fn, samples_cnt=1000, alpha=0.05, random_state=42):\n",
    "    size = len(x)\n",
    "    np.random.seed(random_state)\n",
    "    b_metric = np.zeros(samples_cnt)\n",
    "    for it in range(samples_cnt):\n",
    "        poses = np.random.choice(x.shape[0], size=x.shape[0], replace=True)\n",
    "\n",
    "        x_boot = x[poses]\n",
    "        y_boot = y[poses]\n",
    "\n",
    "        m_val = metric_fn(x_boot, y_boot)\n",
    "        b_metric[it] = m_val\n",
    "\n",
    "    return b_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_score_blogreg = bootstrap_metric(\n",
    "    y_test.values,\n",
    "    y_pred_blr,\n",
    "    metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y),\n",
    ")\n",
    "boot_score_bsvc = bootstrap_metric(\n",
    "    y_test.values,\n",
    "    y_pred_bsvc,\n",
    "    metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y),\n",
    ")\n",
    "boot_score_bdt = bootstrap_metric(\n",
    "    y_test.values,\n",
    "    y_pred_bdt,\n",
    "    metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y),\n",
    ")\n",
    "alpha = 0.10\n",
    "print(\n",
    "    \"Bagged Logistic regression pr-auc 90%-ci: \",\n",
    "    np.quantile(boot_score_blogreg, q=[alpha / 2, 1 - alpha / 2]),\n",
    ")\n",
    "print(\n",
    "    \"Bagged SVC pr-auc 90%-ci:\",\n",
    "    np.quantile(boot_score_bsvc, q=[alpha / 2, 1 - alpha / 2]),\n",
    ")\n",
    "print(\n",
    "    \"Bagged DecisionTreeClassifier pr-auc 90%-ci:\",\n",
    "    np.quantile(boot_score_bdt, q=[alpha / 2, 1 - alpha / 2]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = svc_model.decision_function(\n",
    "    x_test\n",
    ")  # by default, SVM gives score to each object instead of probabilities\n",
    "y_pred2 = logr_model.predict_proba(x_test)[:, 1]\n",
    "y_pred3 = dt_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "qual1 = average_precision_score(y_true=y_test, y_score=y_pred1)\n",
    "qual2 = average_precision_score(y_true=y_test, y_score=y_pred2)\n",
    "qual3 = average_precision_score(y_true=y_test, y_score=y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_score_logreg = bootstrap_metric(\n",
    "    y_test.values,\n",
    "    y_pred1,\n",
    "    metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y),\n",
    ")\n",
    "boot_score_svc = bootstrap_metric(\n",
    "    y_test.values,\n",
    "    y_pred2,\n",
    "    metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y),\n",
    ")\n",
    "boot_score_dt = bootstrap_metric(\n",
    "    y_test.values,\n",
    "    y_pred3,\n",
    "    metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 6))\n",
    "\n",
    "result_arrays = [\n",
    "    boot_score_logreg,\n",
    "    boot_score_svc,\n",
    "    boot_score_dt,\n",
    "    boot_score_blogreg,\n",
    "    boot_score_bsvc,\n",
    "    boot_score_bdt,\n",
    "]\n",
    "base_models = [\"Log-Reg\", \"SVC\", \"DT\"] * 2\n",
    "ensemble_types = [\"Single\"] * 3 + [\"Bagged\"] * 3\n",
    "\n",
    "dfs = []\n",
    "for i, res in enumerate(result_arrays):\n",
    "    df = pd.DataFrame(res, columns=[\"pr_auc\"])\n",
    "    df[\"base_model\"] = base_models[i]\n",
    "    df[\"ensemble_method\"] = ensemble_types[i]\n",
    "    dfs.append(df)\n",
    "\n",
    "sns.boxplot(data=pd.concat(dfs), y=\"pr_auc\", x=\"base_model\", hue=\"ensemble_method\")\n",
    "plt.xlabel(\"Base models\", size=20)\n",
    "plt.ylabel(\"PR-AUC\", size=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дереву решений — при ансамблировании удается получить качество не хуже других базовых моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравним разделяющие плоскости дерева решений и бэггинга на деревьях решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "x, y = sklearn.datasets.make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_decision_boundary(\n",
    "    clf, x, y, axes=[-1.5, 2.5, -1, 1.5], alpha=0.85, contour=True, bolded=False\n",
    "):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    x_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(x_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap([\"#FEE7D0\", \"#bea6ff\", \"#B8E1EC\"])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap([\"#FEE7D0\", \"#5D5DA6\", \"#B8E1EC\"])\n",
    "        if bolded:\n",
    "            custom_cmap2 = ListedColormap([\"#FEE7D0\", \"#5D5DA6\", \"#000000\"])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2)\n",
    "    plt.plot(x[:, 0][y == 0], x[:, 1][y == 0], \"D\", c=\"#F9B041\", alpha=alpha)\n",
    "    plt.plot(x[:, 0][y == 1], x[:, 1][y == 1], \"o\", c=\"#2DA9E1\", alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "plot_decision_boundary(clf, x, y)\n",
    "plt.title(\"Single Decision Tree\", fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "bagging_dt = BaggingBinaryClassifierEnsemble(\n",
    "    DecisionTreeClassifier(max_depth=10), ensemble_size=100\n",
    ")\n",
    "bagging_dt.fit(x_train, y_train)\n",
    "plot_decision_boundary(bagging_dt, x, y)\n",
    "plt.title(\"Bagged Decision Tree\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что разделяющая плоскость для дерева более гладкая и лучше отражает реальное разделение классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод случайных подпространств (RSM, random subspace method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй вариант получения псевдовыборок — сэмплировать не объекты, а признаки.  При этом бесполезно иметь в выборке два одинаковых признака, так как потом мы делаем выборки меньшего размера, чем исходное число признаков и без повторений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/random_subspace_method.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно для каждой модели выбирают:\n",
    "\n",
    " для задач классификации:\n",
    "\n",
    " $$\\sqrt{\\text{feature_cnt}}$$\n",
    "\n",
    " для задач регрессии:\n",
    "\n",
    " $$ \\frac {\\text{feature_cnt}} {3}$$\n",
    "\n",
    "  Хотя строгих правил нет, этот параметр можно подбирать на кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем свой RSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем метод случайных подпространств сами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsm_sample(x, y, f_num=None):\n",
    "    size = x.shape[1]\n",
    "    f_num = f_num or int(np.sqrt(size)) + 1\n",
    "    f_num = min(size, f_num)\n",
    "\n",
    "    f_poses = np.random.choice(size, size=f_num, replace=False)\n",
    "    x_rsm = x[:, f_poses]\n",
    "    y_rsm = y.copy()\n",
    "    return x_rsm, y_rsm, f_poses\n",
    "\n",
    "\n",
    "class RSMBinaryClassifierEnsemble:\n",
    "    def __init__(\n",
    "        self, base_classifier, ensemble_size, random_state=42, max_features=None\n",
    "    ):\n",
    "        self.base_classifier = base_classifier\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.random_state = random_state\n",
    "        self.max_features = max_features\n",
    "\n",
    "        self.ensemble = []\n",
    "        self.feature_poses = []\n",
    "        # we had to keep track of features selected. In sklearn Random Forest, discussed below,\n",
    "        # another, more stable implementation is used.\n",
    "        # they use `f_num` random features but in case no good split found, they try other features too.\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        np.random.seed(self.random_state)\n",
    "        for est_id in range(self.ensemble_size):\n",
    "            x_boot, y_boot, f_poses = get_rsm_sample(x, y, f_num=self.max_features)\n",
    "            self.feature_poses.append(f_poses)\n",
    "            model = sklearn.clone(self.base_classifier)  # create new base model\n",
    "            model.fit(x_boot, y_boot)\n",
    "            self.ensemble.append(model)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        if not self.ensemble:\n",
    "            raise Exception(\"Unfitted model\")\n",
    "\n",
    "        y_pred = 0\n",
    "        for ind, est in enumerate(self.ensemble):\n",
    "            y_pred += est.predict(x[:, self.feature_poses[ind]])\n",
    "        y_pred = y_pred / self.ensemble_size\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_proba = self.predict_proba(x)\n",
    "        y_pred = np.round(y_proba)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Классифицируем людей с больным сердцем и нет, используя RSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = heart_dataset.drop(\"target\", axis=1)\n",
    "y = heart_dataset[\"target\"] > 0\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "\n",
    "rsm_dt = RSMBinaryClassifierEnsemble(dt_model.best_estimator_, ensemble_size=100)\n",
    "\n",
    "rsm_logreg = RSMBinaryClassifierEnsemble(logr_model.best_estimator_, ensemble_size=100)\n",
    "\n",
    "rsm_svc = RSMBinaryClassifierEnsemble(svc_model.best_estimator_, ensemble_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsm_dt.fit(x_train.values, y_train.values)\n",
    "rsm_logreg.fit(x_train.values, y_train.values)\n",
    "rsm_svc.fit(x_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rlr = rsm_logreg.predict_proba(x_test.values)\n",
    "y_pred_rsvc = rsm_svc.predict_proba(x_test.values)\n",
    "y_pred_rdt = rsm_dt.predict_proba(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_score_rlogreg = bootstrap_metric(\n",
    "    y_test.values,\n",
    "    y_pred_rlr,\n",
    "    metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y),\n",
    ")\n",
    "\n",
    "boot_score_rsvc = bootstrap_metric(\n",
    "    y_test.values,\n",
    "    y_pred_rsvc,\n",
    "    metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y),\n",
    ")\n",
    "\n",
    "boot_score_rdt = bootstrap_metric(\n",
    "    y_test.values,\n",
    "    y_pred_rdt,\n",
    "    metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y),\n",
    ")\n",
    "\n",
    "alpha = 0.10\n",
    "print(\n",
    "    \"RSM Logistic regression pr-auc 90%-ci: \",\n",
    "    np.quantile(boot_score_blogreg, q=[alpha / 2, 1 - alpha / 2]),\n",
    ")\n",
    "print(\n",
    "    \"RSM SVC pr-auc 90%-ci:\", np.quantile(boot_score_bsvc, q=[alpha / 2, 1 - alpha / 2])\n",
    ")\n",
    "print(\n",
    "    \"RSM DecisionTreeClassifier pr-auc 90%-ci:\",\n",
    "    np.quantile(boot_score_bdt, q=[alpha / 2, 1 - alpha / 2]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "result_arrays = [\n",
    "    boot_score_logreg,\n",
    "    boot_score_svc,\n",
    "    boot_score_dt,\n",
    "    boot_score_blogreg,\n",
    "    boot_score_bsvc,\n",
    "    boot_score_bdt,\n",
    "    boot_score_rlogreg,\n",
    "    boot_score_rsvc,\n",
    "    boot_score_rdt,\n",
    "]\n",
    "base_models = [\"Log-Reg\", \"SVC\", \"DT\"] * 3\n",
    "ensemble_types = [\"Single\"] * 3 + [\"Bagged\"] * 3 + [\"RSM\"] * 3\n",
    "\n",
    "dfs = []\n",
    "for i, res in enumerate(result_arrays):\n",
    "    df = pd.DataFrame(res, columns=[\"pr_auc\"])\n",
    "    df[\"base_model\"] = base_models[i]\n",
    "    df[\"ensemble_method\"] = ensemble_types[i]\n",
    "    dfs.append(df)\n",
    "\n",
    "sns.boxplot(data=pd.concat(dfs), y=\"pr_auc\", x=\"base_model\", hue=\"ensemble_method\")\n",
    "plt.xlabel(\"Base model\", size=20)\n",
    "plt.ylabel(\"PR-AUC\", size=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSM значительно помогает только дереву решений. Остальные методы почти не улучшают своего качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Комбинация RSM и Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно объединить оба способа: применяем bootstrap к объектам (получается выборка одного размера, но с повторяющимися объектами, а каких-то объектов не будет), и, кроме этого, выкидываем часть признаков. В этом случае мы получим еще более сильно отличающиеся друг от друга случайные выборки.\n",
    "\n",
    "`sklearn.ensemble.BaggingClassifier` и `sklearn.ensemble.BaggingRegressor` вопреки названию могут поддерживать оба способа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/rsm_and_bagging.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему для одних классов моделей работает, а для других — нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь будем использовать `BaggingClassier` из стандартной библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "models = {}\n",
    "\n",
    "logr_model = GridSearchCV(\n",
    "    LogisticRegression(solver=\"liblinear\", max_iter=100000),\n",
    "    {\"penalty\": (\"l1\", \"l2\"), \"C\": [0.01, 0.1, 1, 10, 100]},\n",
    ").fit(x_train, y_train)\n",
    "models[\"LogReg\"] = logr_model\n",
    "\n",
    "svc_model = GridSearchCV(\n",
    "    SVC(), {\"kernel\": (\"linear\", \"rbf\"), \"C\": [0.01, 0.1, 1, 10]}\n",
    ").fit(x_train, y_train)\n",
    "models[\"SVC\"] = svc_model\n",
    "\n",
    "# few objects in the leaf - poor estimates of class probabilities - the model is overtraining\n",
    "dt_model = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    {\"max_depth\": [1, 3, 5, 7, 10], \"min_samples_leaf\": [1, 3, 5, 10]},\n",
    ").fit(x_train, y_train)\n",
    "models[\"DT\"] = dt_model\n",
    "\n",
    "bagging_logr = BaggingClassifier(\n",
    "    logr_model.best_estimator_, n_estimators=100, random_state=42\n",
    ")\n",
    "models[\"Bagging LogReg\"] = bagging_logr\n",
    "\n",
    "bagging_svc = BaggingClassifier(\n",
    "    svc_model.best_estimator_, n_estimators=100, random_state=42\n",
    ")\n",
    "models[\"Bagging SVC\"] = bagging_svc\n",
    "\n",
    "bagging_dt = BaggingClassifier(\n",
    "    dt_model.best_estimator_, n_estimators=100, random_state=42\n",
    ")\n",
    "models[\"Bagging DT\"] = bagging_dt\n",
    "\n",
    "sqrt_features = int(np.sqrt(x.shape[1])) + 1\n",
    "\n",
    "rsm_logreg = BaggingClassifier(\n",
    "    logr_model.best_estimator_,\n",
    "    n_estimators=100,\n",
    "    bootstrap=False,\n",
    "    max_features=sqrt_features,\n",
    "    random_state=42,\n",
    ")\n",
    "models[\"RSM LogReg\"] = rsm_logreg\n",
    "\n",
    "rsm_svc = BaggingClassifier(\n",
    "    svc_model.best_estimator_,\n",
    "    n_estimators=100,\n",
    "    bootstrap=False,\n",
    "    max_features=sqrt_features,\n",
    "    random_state=42,\n",
    ")\n",
    "models[\"RSM SVC\"] = rsm_svc\n",
    "\n",
    "rsm_dt = BaggingClassifier(\n",
    "    dt_model.best_estimator_,\n",
    "    n_estimators=100,\n",
    "    bootstrap=False,\n",
    "    max_features=sqrt_features,\n",
    "    random_state=42,\n",
    ")\n",
    "models[\"RSM DT\"] = rsm_dt\n",
    "\n",
    "# Both Bagging and RSM\n",
    "bag_rsm_logreg = BaggingClassifier(\n",
    "    logr_model.best_estimator_,\n",
    "    n_estimators=100,\n",
    "    bootstrap=True,\n",
    "    max_features=sqrt_features,\n",
    "    random_state=42,\n",
    ")\n",
    "models[\"BagRSM LogReg\"] = bag_rsm_logreg\n",
    "\n",
    "\n",
    "bag_rsm_svc = BaggingClassifier(\n",
    "    svc_model.best_estimator_,\n",
    "    n_estimators=100,\n",
    "    bootstrap=True,\n",
    "    max_features=sqrt_features,\n",
    "    random_state=42,\n",
    ")\n",
    "models[\"BagRSM SVC\"] = bag_rsm_svc\n",
    "\n",
    "bag_rsm_dt = BaggingClassifier(\n",
    "    dt_model.best_estimator_,\n",
    "    n_estimators=100,\n",
    "    bootstrap=True,\n",
    "    max_features=sqrt_features,\n",
    "    random_state=42,\n",
    ")\n",
    "models[\"BagRSM DT\"] = bag_rsm_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name != \"SVC\":\n",
    "        y_pred = model.predict_proba(x_test)[:, 1]\n",
    "    else:\n",
    "        y_pred = model.decision_function(x_test)\n",
    "    predictions[name] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_scores = {}\n",
    "\n",
    "for name, y_pred in predictions.items():\n",
    "    boot_score = bootstrap_metric(\n",
    "        y_test.values,\n",
    "        y_pred,\n",
    "        metric_fn=lambda x, y: average_precision_score(y_true=x, y_score=y),\n",
    "    )\n",
    "    boot_scores[name] = boot_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "base_models = [\"Log-Reg\", \"SVC\", \"DT\"] * 4\n",
    "ensemble_types = [\"Single\"] * 3 + [\"Bagged\"] * 3 + [\"RSM\"] * 3 + [\"BagRSM\"] * 3\n",
    "\n",
    "dfs = []\n",
    "for i, model_name in enumerate(boot_scores):\n",
    "    df = pd.DataFrame(boot_scores[model_name], columns=[\"pr_auc\"])\n",
    "    df[\"base_model\"] = base_models[i]\n",
    "    df[\"ensemble_method\"] = ensemble_types[i]\n",
    "    dfs.append(df)\n",
    "\n",
    "sns.boxplot(data=pd.concat(dfs), y=\"pr_auc\", x=\"base_model\", hue=\"ensemble_method\")\n",
    "plt.xlabel(\"Base model\", size=20)\n",
    "plt.ylabel(\"PR-AUC\", size=20)\n",
    "plt.legend(fontsize=20, loc=\"lower right\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существенное улучшение качества наблюдается только при использовании решающего дерева в качестве базовой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы простое голосование повышало качество ансамбля, необходимо, чтобы ошибки базовых моделей не коррелировали между собой.\n",
    "\n",
    "Попробуем оценить попарную корреляцию в ошибках базовых моделей в ансамблях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def base_model_pair_correlation(ensemble, x):\n",
    "    corrs = []\n",
    "    for (i, est1), (j, est2) in itertools.combinations(\n",
    "        enumerate(ensemble.estimators_), 2\n",
    "    ):\n",
    "        xi_test = x.values[:, ensemble.estimators_features_[i]]\n",
    "        xj_test = x.values[:, ensemble.estimators_features_[j]]\n",
    "\n",
    "        if not isinstance(est1, sklearn.svm.SVC):\n",
    "            y_pred_t1 = est1.predict_proba(xi_test)[:, 1]\n",
    "\n",
    "            y_pred_t2 = est2.predict_proba(xj_test)[:, 1]\n",
    "        else:\n",
    "            y_pred_t1 = est1.decision_function(xi_test)\n",
    "            xj_test = x_test.values[:, ensemble.estimators_features_[j]]\n",
    "            y_pred_t2 = est2.decision_function(xj_test)\n",
    "        corrs.append(scipy.stats.pearsonr(y_pred_t1, y_pred_t2)[0])\n",
    "    return np.array(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_correlations = {}\n",
    "for name, model in models.items():\n",
    "    if not \"Bagging\" in name and not \"RSM\" in name:\n",
    "        continue\n",
    "    pair_correlations[name] = base_model_pair_correlation(model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_res = pd.DataFrame(pair_correlations)\n",
    "cor_res = cor_res.melt(\n",
    "    value_vars=cor_res.columns, value_name=\"paircor\", var_name=\"model\"\n",
    ")\n",
    "\n",
    "\n",
    "# get base models and ensembling methods from names\n",
    "def read_base(s):\n",
    "    if \"dt\" in s.lower():\n",
    "        return \"DT\"\n",
    "    elif \"svc\" in s.lower():\n",
    "        return \"SVC\"\n",
    "    else:\n",
    "        return \"Log-Reg\"\n",
    "\n",
    "\n",
    "def read_ensemble(s):\n",
    "    bag, rsm = False, False\n",
    "    if \"bag\" in s.lower():\n",
    "        bag = True\n",
    "    if \"rsm\" in s.lower():\n",
    "        rsm = True\n",
    "    if bag and rsm:\n",
    "        return \"BagRSM\"\n",
    "    if bag:\n",
    "        return \"Bagged\"\n",
    "    if rsm:\n",
    "        return \"RSM\"\n",
    "    return \"Single\"\n",
    "\n",
    "\n",
    "cor_res[\"base_model\"] = cor_res[\"model\"].apply(read_base)\n",
    "cor_res[\"ensemble_method\"] = cor_res[\"model\"].apply(read_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, посчитаем качество базовых моделей, входящих в каждый из ансамблей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_prauc(ensemble, x, y):\n",
    "    qual = np.zeros(ensemble.n_estimators)\n",
    "    for ind, est in enumerate(ensemble.estimators_):\n",
    "        x_test = x.values[:, ensemble.estimators_features_[i]]\n",
    "        if not isinstance(est, sklearn.svm.SVC):\n",
    "            y_pred = est.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            y_pred = est.decision_function(x_test)\n",
    "        qual[ind] = average_precision_score(y_score=y_pred, y_true=y)\n",
    "    return qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prauc = {}\n",
    "for name, model in models.items():\n",
    "    if not \"Bagging\" in name and not \"RSM\" in name:\n",
    "        continue\n",
    "    base_prauc[name] = base_model_prauc(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prauc_res = pd.DataFrame(base_prauc)\n",
    "base_prauc_res = base_prauc_res.melt(\n",
    "    value_vars=base_prauc_res.columns, value_name=\"pr_auc\", var_name=\"model\"\n",
    ")\n",
    "base_prauc_res[\"base_model\"] = base_prauc_res[\"model\"].apply(read_base)\n",
    "base_prauc_res[\"ensemble_method\"] = base_prauc_res[\"model\"].apply(read_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "plt.subplot(211)\n",
    "sns.boxplot(data=cor_res, y=\"paircor\", x=\"base_model\", hue=\"ensemble_method\")\n",
    "plt.title(\"Pairwise correlations in ensembles\", size=25)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"Pairwise correlation\", size=20)\n",
    "plt.legend(fontsize=20, loc=\"lower left\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "\n",
    "plt.subplot(212)\n",
    "sns.boxplot(data=base_prauc_res, y=\"pr_auc\", x=\"base_model\", hue=\"ensemble_method\")\n",
    "plt.title(\"Base model quality\", size=25)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"PR-AUC\", size=20)\n",
    "plt.subplots_adjust()\n",
    "plt.legend(fontsize=20, loc=\"lower left\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать следующие выводы:\n",
    "\n",
    "1. Bagging, RSM и их комбинация помогают уменьшать корреляцию между базовыми моделями. Причем, комбинация Bagging и RSM работает лучшее, чем каждый из них поодиночке;\n",
    "2. В случае просто Bagging, дерево решений получает существенный прирост качества за счет того, что модели на его основе коррелированы значительно слабее, чем модели на основе логистической регрессии и метода опорных векторов;\n",
    "3. Отсутствие корреляции при RSM и BagRSM для Log_reg и SVM связано с отсутствием важных признаков при обучении некоторых моделей. Предсказание моделей на разных выборках при одинаковых признаках будет мало отличаться. Из-за этого ансамбль на основе деревьев решений опять показывает лучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из предыдущей части мы увидели, что использование bagging или RSM для SVM или подобных моделей не несет большого смысла. Но для деревьев решений это не так. Будем брать деревья большой глубины. Незначительные изменения в данных приводят к значительным  изменениям в топологии таких деревьев. Таким образом, мы приходим к **случайному лесу** = Bagging + RSM над деревом решений.\n",
    "\n",
    "При этом RSM в классическом случайном лесе делается не на уровне дерева, а на уровне узла. В каждом узле дерева, когда мы выбираем лучшее разбиение его на два дочерних, мы просматриваем не все признаки, а только определенное их количество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/random_forest.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес работает лучше, чем отдельное случайно взятое дерево. Но главное, что случайный лес намного более устойчив к шуму.\n",
    "Это свойство до сих пор позволяет случайному лесу успешно использоваться в областях с шумными данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зависимость качества случайного леса от числа деревьев\n",
    "Для случайного леса верно следующее: когда мы берем множество базовых классификаторов (в данном случае деревьев) и усредняем их, то **результат этих усреднений стремится к идеальному дереву решений**, причем построенному на идеальных, а не на исходных признаках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим это на задаче регрессии [California Housing dataset 🛠️[doc]](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calif_housing = sklearn.datasets.fetch_california_housing()\n",
    "x = calif_housing.data\n",
    "y = calif_housing.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные — средние характеристики квартиры в доме. Цель — предсказать цену на дом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим несколько случайных лесов с различным количеством деревьев и простое дерево решений для сравнения с ним (baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "models_rf = {}\n",
    "\n",
    "# add single decision tree for comparison\n",
    "models_rf[\"DT\"] = GridSearchCV(\n",
    "    DecisionTreeRegressor(),\n",
    "    {\"max_depth\": [1, 3, 5, 7, 10], \"min_samples_leaf\": [1, 3, 5, 10]},\n",
    ")\n",
    "\n",
    "# this can be done faster, see warm_start parameter for this\n",
    "# (https://stackoverflow.com/questions/42757892/how-to-use-warm-start)\n",
    "for n_estimators in [3, 5, 10, 50, 100, 150, 250]:\n",
    "    models_rf[f\"RF{n_estimators}\"] = RandomForestRegressor(\n",
    "        n_estimators=n_estimators, random_state=42, n_jobs=-1\n",
    "    )  # run in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим все модели.\n",
    "Для этого напишем вспомогательную функцию, которая будет обучать переданные ей модели и считать для них качество на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def train_and_test_regressor(models, x_train, y_train, x_test, y_test, verb=True):\n",
    "    boot_scores = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(x_train, y_train)  # train the model\n",
    "        y_pred = model.predict(x_test)  # get predictions\n",
    "        boot_scores[name] = bootstrap_metric(  # calculate bootstrap score\n",
    "            y_test,\n",
    "            y_pred,\n",
    "            metric_fn=lambda x, y: mean_squared_error(y_true=x, y_pred=y),\n",
    "        )\n",
    "        if verb:\n",
    "            print(f\"Fitted {name} with bootstrap score {boot_scores[name].mean():.3f}\")\n",
    "\n",
    "    results = pd.DataFrame(boot_scores)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results_rf = train_and_test_regressor(models_rf, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=results_rf)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.xlabel(\"n_estimators\", size=20)\n",
    "plt.title(\"Number of estimators vs MSE\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличение числа базовых моделей сначала сильно улучшает качество модели. Однако после определенного количества базовых моделей улучшение качества становится незначительным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зависимость качества случайного леса от глубины дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем больше глубина дерева, тем большая нескорелированность базовых моделей будет получаться. В общем случае в случайном лесе важно использовать именно глубокие деревья, причем в большинстве случаев их глубину не надо ограничивать (или ограничивать большими значениями порядка 10–12).\n",
    "\n",
    "Обучим случайный лес с заданной глубиной дерева и сравним с одиночным деревом такой же глубины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_depth = {}\n",
    "rf_depth = {}\n",
    "\n",
    "for depth in range(1, 20, 2):\n",
    "    dt_depth[depth] = DecisionTreeRegressor(max_depth=depth, random_state=42)\n",
    "\n",
    "    rf_depth[depth] = RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=depth, random_state=42, n_jobs=-1\n",
    "    )  # run in parallel\n",
    "\n",
    "dt_res = train_and_test_regressor(\n",
    "    dt_depth, x_train, y_train, x_test, y_test, verb=False\n",
    ")\n",
    "rf_res = train_and_test_regressor(\n",
    "    rf_depth, x_train, y_train, x_test, y_test, verb=False\n",
    ")\n",
    "\n",
    "dt_res = dt_res.melt(value_vars=dt_res.columns, value_name=\"mse\", var_name=\"tree_depth\")\n",
    "dt_res['model'] = \"DT\"\n",
    "rf_res = rf_res.melt(value_vars=rf_res.columns, value_name=\"mse\", var_name=\"tree_depth\")\n",
    "rf_res['model'] = \"RF\"\n",
    "depth_res = pd.concat((dt_res, rf_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=depth_res, x=\"tree_depth\", y=\"mse\", hue=\"model\")\n",
    "plt.xlabel(\"Tree depth\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Tree depth vs MSE\", size=20)\n",
    "plt.legend()\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие результаты показывает случайный лес из наиболее глубоких деревьев.\n",
    "\n",
    "Качество случайного леса с малой глубиной дерева не отличается от качества одиночного дерева той же глубины. Это связано с тем, что деревья малой глубины слабо отличаются друг от друга (высокий bias и низкий variance), потому усреднение их предсказаний почти не улучшает качество.\n",
    "\n",
    "Отметим, что в случае малых выборок ограничения на глубину дерева могут дать выигрыш."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минимальное число объектов в листе\n",
    "Иногда качество случайного леса можно улучшить, если поставить небольшое ограничение на минимальное число объектов в листе, чтобы запретить явно переобученные деревья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_models_min_samples = {}\n",
    "rf_models_min_samples = {}\n",
    "\n",
    "for mn_sm in [1, 3, 5, 7, 10]:\n",
    "    dt_models_min_samples[mn_sm] = DecisionTreeRegressor(\n",
    "        max_depth=None, min_samples_leaf=mn_sm, random_state=42\n",
    "    )\n",
    "\n",
    "    rf_models_min_samples[mn_sm] = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=mn_sm,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )  # run in parallel\n",
    "\n",
    "dt_results_mn_samples = train_and_test_regressor(\n",
    "    dt_models_min_samples, x_train, y_train, x_test, y_test\n",
    ")\n",
    "rf_results_mn_samples = train_and_test_regressor(\n",
    "    rf_models_min_samples, x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "dt_results_mn_samples = dt_results_mn_samples.melt(value_vars=dt_results_mn_samples.columns, value_name=\"mse\", var_name=\"min_samples\")\n",
    "dt_results_mn_samples['model'] = \"DT\"\n",
    "rf_results_mn_samples = rf_results_mn_samples.melt(value_vars=rf_results_mn_samples.columns, value_name=\"mse\", var_name=\"min_samples\")\n",
    "rf_results_mn_samples['model'] = \"RF\"\n",
    "leaf_res = pd.concat((dt_results_mn_samples, rf_results_mn_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=leaf_res, x=\"min_samples\", y=\"mse\", hue=\"model\")\n",
    "plt.xlabel(\"Tree depth\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Tree depth vs MSE\", size=20)\n",
    "plt.legend()\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае, однако, ограничение на количество объектов в листе ухудшает качество ансамбля. Одна из причин заключается в том, что с увеличением числа ограничений на дерево уменьшается непохожесть деревьев друг на друга, и качество случайного леса так же начинает уменьшаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучается ли случайный лес?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует мнение, что случайный лес не переобучается. Это не так. Можно подобрать такие два набора параметров, что первый даст лучшее качество на тренировочной выборке, а второй — на тестовой. При этом увеличение числа деревьев в ансамбле с этим справиться поможет слабо.\n",
    "\n",
    "Возьмем, к примеру, наш синтетический пример на плоскости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "x, y = sklearn.datasets.make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "plot_decision_boundary(clf, x, y)\n",
    "plt.title(\"Single Decision Tree\", fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(x_train, y_train)\n",
    "plot_decision_boundary(rf, x, y)\n",
    "plt.title(\"Random forest\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видны области, в которых случайный лес переобучился.\n",
    "\n",
    "Добавление ограничения на число объектов в листьях улучшает ситуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "rf1 = RandomForestClassifier(n_estimators=1000)\n",
    "rf1.fit(x_train, y_train)\n",
    "plot_decision_boundary(rf1, x, y)\n",
    "plt.title(\"Random forest\", fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "rf2 = RandomForestClassifier(n_estimators=1000, min_samples_leaf=5)\n",
    "rf2.fit(x_train, y_train)\n",
    "plot_decision_boundary(rf2, x, y)\n",
    "plt.title(\"Random forest, min_samples_leaf=5\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лес без ограничения на минимальное число объектов в листе переобучился — достиг максимального качества на обучающей выборке, но на тестовой имеет качество ниже, чем лес с ограничением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = rf1.predict(x_train)\n",
    "q = average_precision_score(y_true=y_train, y_score=y_score)\n",
    "print(f\"RF1 Train: {q:.02}\")\n",
    "y_score = rf1.predict(x_test)\n",
    "q = average_precision_score(y_true=y_test, y_score=y_score)\n",
    "print(f\"RF1 Test: {q:.02}\")\n",
    "\n",
    "y_score = rf2.predict(x_train)\n",
    "q = average_precision_score(y_true=y_train, y_score=y_score)\n",
    "print(f\"RF2 Train: {q:.02}\")\n",
    "y_score = rf2.predict(x_test)\n",
    "q = average_precision_score(y_true=y_test, y_score=y_score)\n",
    "print(f\"RF2 Test: {q:.02}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидиация случайного леса на Out-Of-Bag (OOB) объектах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря механизму обучения случайного леса у нас появляется еще один способ валидировать модель. Для каждого дерева используются не все объекты нашей выборки, следовательно мы можем получать предсказания деревьев на объектах, которые не использовались для обучения этих деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/oob_rf.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За это отвечает параметр `oob_score` (по умолчанию `False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "rf_oob = RandomForestClassifier(n_estimators=1000, min_samples_leaf=5, oob_score=True)\n",
    "rf_oob.fit(x, y)\n",
    "print(f\"RF OOB score: {rf_oob.oob_score_:.02}\")\n",
    "\n",
    "scores = cross_validate(rf_oob, x, y, cv=5)\n",
    "print(f\"RF CV score: {scores['test_score'].mean():.02}\")\n",
    "\n",
    "rf_oob.fit(x_train, y_train)\n",
    "print(f\"RF Test set score: {rf_oob.score(x_test, y_test):.02}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно понимать, что OOB score не заменяет другие способы валидации, а является дополнительным способом, который используется в основном тогда, когда данных мало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес и bias-variance tradeoff\n",
    "Случайный лес — инструмент для уменьшения variance нашей модели. Можно показать, что при стремлении числа моделей в ансамбле к бесконечности, а их коррелированности — к 0, variance ансамбля стремится к нулю. Однако при этом bias ансамбля будет равен bias базовой модели.\n",
    "\n",
    "Продемонстрируем это:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Decision trees\n",
    "for i, max_depth in enumerate([1, 3, 5, 12]):\n",
    "    plt.subplot(241 + i)\n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    dt.fit(x_train, y_train)\n",
    "    plot_decision_boundary(dt, x, y, alpha=0.5, bolded=True)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.title(f\"Decision tree, max_depth={max_depth}\", fontsize=14)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "# Random forests\n",
    "for i, max_depth in enumerate([1, 3, 5, 12]):\n",
    "    plt.subplot(245 + i)\n",
    "    rf = RandomForestClassifier(max_depth=max_depth, n_estimators=500, n_jobs=-1)\n",
    "    rf.fit(x_train, y_train)\n",
    "    plot_decision_boundary(rf, x, y, alpha=0.5, bolded=True)\n",
    "    plt.title(f\"Random forest, max_depth={max_depth}\", fontsize=14)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что общая сложность решающей границы меняется не сильно: bias случайного леса по сравнению с bias дерева решений не меняется.\n",
    "А вот гладкость границы увеличивается, тем самым, уменьшается variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг — это еще один способ ансамблирования моделей. В отличие от случайного леса, где каждая модель в ансамбле строится независимо, в бустинге построение очередной модели зависит от уже состоящих в ансамбле моделей. Каждая следующая модель в ансамбле стремится улучшить предсказание всего ансамбля."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг позволяет нам на основе большого числа \"слабых\" моделей получить одну \"сильную\". Под слабыми моделями подразумеваем модели, точность которых может быть лишь немногим выше случайного угадывания.\n",
    "\n",
    "В качестве моделей традиционно используются деревья решений, но не большой глубины, а наоборот — маленькой, чтобы каждое из них не могло выучить выборку хорошо.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/join_weak_learners.png\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из всех бустингов больше всего прославился и доказал свою эффективность **градиентный бустинг**. Он позволяет получить решение, которое сложно побить другими видами моделей.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting (градиентный бустинг)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с интуиции. Предположим, что мы играем в гольф. Наша задача — загнать мячик в лунку, причем, когда мячик далеко от нее, мы можем ударить посильнее, чтобы сократить расстояние, но когда мы уже близко к лунке, то стараемся бить клюшкой аккуратнее, чтобы не промахнуться. После каждого удара мы оцениваем расстояние до лунки и приближаем мячик в ее сторону. Применительно к нашей теме удар клюшкой по мячику — это каждая модель в градиентном бустинге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/summarize_predictions_of_ensemble_models.png\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель $i$-той модели в ансамбле — скорректировать ошибки предыдущих ${i-1}$ моделей. В результате, когда мы суммируем вклады всех моделей ансамбля, получается хорошее предсказание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[colab] 🥨 Демонстрация понимания интуиции градиентного бустинга](https://colab.research.google.com/drive/1hILdJzsuAsXabA4aIwtb9RGgUn_bvhCL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте формализуем, что нам нужно, чтобы обучить алгоритм градиентного бустинга:\n",
    "\n",
    "- набор данных $\\left\\{\\left(x_i, y_i\\right)\\right\\}_{i=1, \\ldots, n}$,\n",
    "- число итераций $M$ (оно же количество моделей),\n",
    "- выбор дифференцируемой функции потерь $L(y, f)$,\n",
    "- выбор семейства функций базовых алгоритмов $h(x, \\theta)$ с процедурой их обучения.\n",
    "\n",
    "Минимизировать ошибку будем с помощью градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/gradient_boosting.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рзаберем пошагово:\n",
    "\n",
    "Начинаем с первого предсказания, можем выбрать на самом деле любое число, например среднее значение\n",
    "\n",
    "$$ \\large \\hat{f}(x)=\\hat{f}_0, \\hat{f}_0=\\gamma, \\gamma \\in \\mathbb{R}\n",
    " \\tag{1}$$\n",
    "\n",
    "Либо подобрать с наименьшей ошибкой\n",
    "\n",
    "$$\\large \\hat{f}_0=\\underset{\\gamma}{\\arg \\min } \\sum_{i=1}^n L\\left(y_i, \\gamma\\right) $$\n",
    "\n",
    "Посмотрим на графике, как бы могла выглядеть наша зависимость. Посчитаем ошибку и отобразим наше предсказание.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/gb_explanation_step1.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем примере мы видим, что нужно двигаться вправо, чтобы уменьшить ошибку. В действительности мы этого не знаем, но можем посчитать градиент и узнать направление возрастания функции ошибки. Нас же интересует обратное направление или градиент со знаком минус (антиградиент).\n",
    "\n",
    "$$\\large r_{i t}=-\\frac{\\partial L\\left(y_i, f\\left(x_i\\right)\\right)}{\\partial f\\left(x_i\\right)} \\quad \\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/gb_explanation_step2.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим новый базовый алгоритм $h_t(x)$, который обучается на то, чтобы уменьшить ошибку от текущего состояния ансамбля, и в качестве целевой переменной для него берем антиградиент функции потерь  $\\left\\{\\left(x_i, r_{i t}\\right)\\right\\}_{i=1, \\ldots, n}$\n",
    "\n",
    "$$\\large\\underset{\\theta}{\\arg \\min } \\sum_{i=1}^n L\\left(h(x_i, \\theta), r_{it}\\right) \\tag{3}$$\n",
    "\n",
    "Подбираем оптимальный параметр $\\large \\rho$. Этот параметр будет разным у каждого дерева в нашем ансамбле, в отличие от learning rate:\n",
    "\n",
    " $$\\large \\rho_t=\\underset{\\rho}{\\arg \\min } \\sum_{i=1}^n L\\left(y_i, \\hat{f}\\left(x_i\\right)+\\rho \\cdot h\\left(x_i, \\theta\\right)\\right) \\tag{4}$$\n",
    "\n",
    "Сдвигаем предсказание в сторону уменьшения ошибки, где $\\lambda$ — это learning rate:\n",
    "\n",
    " $$\\large \\hat{f}_t(x)= \\lambda \\cdot \\rho_t \\cdot h_t(x) \\tag{5}$$\n",
    "\n",
    "Обновляем текущее приближение $\\hat{f}(x)$:\n",
    "$$ \\large\n",
    "\\hat{f}(x) \\leftarrow \\hat{f}(x)+\\hat{f}_t(x)=\\sum_{i=0}^t \\hat{f}_i(x) \\tag{6}\n",
    "$$\n",
    "\n",
    "Далее повторяем шаги 2–6, пока не получим требуемое качество, и собираем итоговый ансамбль $\\hat{f}(x)$:\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\hat{f}(x)=\\sum_{i=0}^M \\hat{f}_i(x)\n",
    "$$\n",
    "\n",
    "[[blog] ✏️ Подробнее о градиентном бустинге](https://habr.com/ru/company/ods/blog/327250/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы говорили про базовые модели, то предполагали, что этими базовыми моделями являются деревья решений. Однако это необязательно, можно использовать и другие алгоритмы в качестве базовых моделей.\n",
    "\n",
    "Деревья решений имеют ряд преимуществ:\n",
    "\n",
    "- Гибкость — деревья решений могут описывать сложные нелинейные взаимосвязи между объектами и целевой переменной. Они могут обрабатывать как числовые, так и категориальные данные и работать с пропущенными значениями.\n",
    "\n",
    "- Интерпретируемость — деревья решений просты в понимании и интерпретации. Они дают четкое представление о том, как модель пришла к определенному прогнозу.\n",
    "\n",
    "- Устойчивость к выбросам — деревья решений менее чувствительны к выбросам, чем другие алгоритмы машинного обучения. Они способны изолировать их и предотвратить их влияние на всю модель.\n",
    "\n",
    "- Эффективность — деревья решений могут быть построены быстро, они способны обрабатывать большие наборы данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, запустим градиентный бустинг без подбирания параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calif_housing = sklearn.datasets.fetch_california_housing()\n",
    "x = calif_housing.data\n",
    "y = calif_housing.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И напишем функцию, которая будет автоматически обучать переданные ей модели и считать для них качество на тесте, чтобы избавиться от необходимости копировать код между ячейками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def train_and_test_regressor(models, x_train, y_train, x_test, y_test):\n",
    "    for name, model in models.items():\n",
    "        print(f\"Fitting {name}\")\n",
    "        model.fit(x_train, y_train)\n",
    "    predictions = {}\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(x_test)\n",
    "        predictions[name] = y_pred\n",
    "\n",
    "    boot_scores = {}\n",
    "\n",
    "    for name, y_pred in predictions.items():\n",
    "        print(f\"Calculating bootstrap score for {name}\")\n",
    "        boot_score = bootstrap_metric(\n",
    "            y_test,\n",
    "            y_pred,\n",
    "            metric_fn=lambda x, y: mean_squared_error(y_true=x, y_pred=y),\n",
    "        )\n",
    "        boot_scores[name] = boot_score\n",
    "\n",
    "    results = pd.DataFrame(boot_scores)\n",
    "    # cast to long format\n",
    "    results = results.melt(\n",
    "        value_vars=results.columns, value_name=\"mse\", var_name=\"model\"\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "models = {}\n",
    "\n",
    "# make pipeline for normalization\n",
    "models[\"LinReg\"] = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "\n",
    "models[\"RF\"] = RandomForestRegressor(\n",
    "    n_estimators=250,  # for better result set to 1000\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "models[\"GradientBoosting\"] = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,  # for better result set to 0.05\n",
    "    n_estimators=250,  # for better result set to 1000\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "results_boost = train_and_test_regressor(models, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "ax = sns.boxplot(data=results_boost, y=\"mse\", x=\"model\", hue='model')\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"LR vs RF vs GB\", size=25)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что бустинг сразу дает хороший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В то же время **Gradient boosting**, в отличие от случайного леса, может сильно переобучиться. Это важно понимать. Для небольших датасетов часто может оказаться, что случайный лес дает более надежные результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/gradient_boosting_overfitting.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree = GradientBoostingRegressor(\n",
    "    n_estimators=300, learning_rate=1.0  # faster learning rate to force ovefitting\n",
    ")\n",
    "gbtree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем метод `staged_predict`, который есть во многих реализациях бустинга в том или ином виде. Он получает предсказание от первых $i$ деревьев ансамбля, что позволяет быстро строить график качества градиентного бустинга в зависимости от числа базовых моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train = []\n",
    "error_test = []\n",
    "for it, (y_train_pred, y_test_pred) in enumerate(\n",
    "    zip(gbtree.staged_predict(x_train), gbtree.staged_predict(x_test))\n",
    "):\n",
    "    ertr = mean_squared_error(y_true=y_train, y_pred=y_train_pred)\n",
    "    error_train.append(ertr)\n",
    "    erte = mean_squared_error(y_true=y_test, y_pred=y_test_pred)\n",
    "    error_test.append(erte)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(error_train, label=\"train\", c=\"#2DA9E1\", linewidth=4)\n",
    "plt.plot(error_test, label=\"test\", c=\"#4AAE4D\", linewidth=4)\n",
    "plt.xlabel(\"n_estimators\", size=20)\n",
    "plt.ylabel(\"mse\", size=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы *немного* схитрили, сильно увеличив learning rate нашей модели — дополнительный множитель к весу, с которым добавляются в нее новые модели. Из-за этого даже на таком простом датасете мы в состоянии увидеть явное переобучение.\n",
    "\n",
    "Давайте об этом learning rate и поговорим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shrinkage (learning rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как у градиентного спуска есть learning rate, который определяет силу каждого нашего следующего шага,  так и у градиентного бустинга есть параметр, который называется shrinkage или learning rate — это дополнительный параметр, на который мы домножаем вес, с которым мы добавляем новые модели в ансамбль.\n",
    "\n",
    "Мы не хотим сильно скакать по пространству решений, мы хотим спускаться медленно и сойтись к какому-то хорошему минимуму. Потому мы вес каждой модели, которую мы рассчитываем по специальному алгоритму, еще домножаем на маленький коэффициент, который называется shrinkage или learning rate. Фактически, мы берем и умножаем градиент на некий $\\alpha$ (это то же, что было в градиентном спуске, ничего нового мы не добавили).\n",
    "\n",
    "Если не домножать вес каждой модели дополнительно на этот параметр, то мы можем попасть в ситуацию, когда будем пролетать мимо минимума функции ошибки (та же опасность, что и в обычном градиентном спуске)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/shrinkage_learning_rate_for_gradient_boosting.png\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае с градиентным спуском, **learning rate** влияет не только на то, как быстро мы станем переобучаться, но и на глубину минимума, который мы найдем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here anb below in the cell can be set to 1000 for better visualization\n",
    "\n",
    "gbtrees_list = []\n",
    "\n",
    "for lr in [1, 0.5, 0.1, 0.05, 0.01]:\n",
    "    gbtree = GradientBoostingRegressor(n_estimators=500, learning_rate=lr)\n",
    "    gbtree.fit(x_train, y_train)\n",
    "    gbtrees_list.append(gbtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = []\n",
    "step = []\n",
    "mse = []\n",
    "for gb_tree in gbtrees_list:\n",
    "    for it, y_test_pred in enumerate(gb_tree.staged_predict(x_test)):\n",
    "        erte = mean_squared_error(y_true=y_test, y_pred=y_test_pred)\n",
    "        mse.append(erte)\n",
    "        lr.append(str(gb_tree.learning_rate))\n",
    "        step.append(it)\n",
    "\n",
    "df = pd.DataFrame({\"learning_rate\": lr, \"n_estimators\": step, \"mse\": mse})\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.lineplot(data=df, x=\"n_estimators\", y=\"mse\", hue=\"learning_rate\", lw=3)\n",
    "plt.xlabel(\"n_estimators\", size=20)\n",
    "plt.ylabel(\"mse\", size=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylim((0.2, 0.6))\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае мы видим, что значение learning rate, установленное по умолчанию (`learning_rate=0.1`), позволяет получить наименьшую ошибку на валидации.\n",
    "Слишком большие значения learning rate (1 и 0.5) приводят к тому, что мы не достигаем таких глубоких минимумов и начинаем переобучаться.\n",
    "Слишком малое значение learning rate может привести к тому, что нам понадобится очень большое число деревьев, чтобы достигнуть минимума (если мы его вообще достигнем)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Число деревьев в ансамбле"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число деревьев, как было видно из предыдущего графика, зависит от установленного learning rate.\n",
    "Потому обычно ставят `learning_rate = 0.1` и подбирают оптимальное значение числа деревьев в ансамбле.\n",
    "Делают это на кросс-валидации, но для экономии времени просто дополнительно разобьем train датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_learn, x_valid, y_learn, y_valid = train_test_split(x_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1)\n",
    "gbtree.fit(x_learn, y_learn)\n",
    "\n",
    "error_train = []\n",
    "error_test = []\n",
    "for it, (y_learn_pred, y_valid_pred) in enumerate(\n",
    "    zip(gbtree.staged_predict(x_learn), gbtree.staged_predict(x_valid))\n",
    "):\n",
    "    ertr = mean_squared_error(y_true=y_learn, y_pred=y_learn_pred)\n",
    "    error_train.append(ertr)\n",
    "    erte = mean_squared_error(y_true=y_valid, y_pred=y_valid_pred)\n",
    "    error_test.append(erte)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(error_train, label=\"train\", c=\"#2DA9E1\", linewidth=4)\n",
    "plt.plot(error_test, label=\"test\", c=\"#4AAE4D\", linewidth=4)\n",
    "plt.xlabel(\"n_estimators\", size=20)\n",
    "plt.ylabel(\"mse\", size=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что ошибка продолжает медленно уменьшаться, но увеличение идет очень маленькое, потому в целях  демонстрации выберем число деревьев равным 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Глубина деревьев в градиентном бустинге"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае бустинга нам нужны **слабые модели**. Поэтому очень глубокие деревья в бустинге встречаются редко — бустинг с ними проиграет по качеству.\n",
    "Обычно глубина дерева выбирается вместе с минимальным числом объектов в листе `min_samples_leaf` или весом листа `min_weight_fraction_leaf`, так как эти параметры взаимосвязаны и вместе влияют на сложность полученных деревьев.\n",
    "Здесь же в целях демонстрации мы подберем сначала глубину дерева, а потом минимальное число объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for depth in (1, 2, 3, 5, 10):\n",
    "    models[depth] = GradientBoostingRegressor(\n",
    "        n_estimators=500, learning_rate=0.1, max_depth=depth, random_state=42\n",
    "    )\n",
    "\n",
    "depth_boost = train_and_test_regressor(models, x_learn, y_learn, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=depth_boost, y=\"mse\", x=\"model\", hue='model', palette='tab10')\n",
    "plt.xlabel(\"GB depth\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"GB depth vs MSE\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.legend([],[], frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Искомая глубина находится между 3 и 10. Добавим на график точки 4, 6 и 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_add = {}\n",
    "for depth in (4, 6, 7):\n",
    "    models_add[depth] = GradientBoostingRegressor(\n",
    "        n_estimators=500, learning_rate=0.1, max_depth=depth, random_state=42\n",
    "    )\n",
    "\n",
    "depth_boost_add = train_and_test_regressor(\n",
    "    models_add, x_learn, y_learn, x_valid, y_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_boost_joined = pd.concat([depth_boost, depth_boost_add])\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(\n",
    "    data=depth_boost_joined, y=\"mse\", x=\"model\", order=[1, 2, 3, 4, 5, 6, 7, 10], hue='model', palette='tab10'\n",
    ")\n",
    "plt.xlabel(\"GB depth\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"GB depth vs MSE\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.legend([],[], frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значит, оптимальная для данной задачи глубина — 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минимальное число объектов в листе\n",
    "Этот параметр влияет на сложность полученных деревьев. Как уже отмечалось ранее, стоит подбирать его вместе с глубиной, но мы ограничены по времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for min_samples_leaf in (1, 3, 5, 7, 9, 11):\n",
    "    models[min_samples_leaf] = GradientBoostingRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "mns_boost = train_and_test_regressor(models, x_learn, y_learn, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=mns_boost, y=\"mse\", x=\"model\", hue='model', palette='tab10')\n",
    "plt.xlabel(\"Min samples in leaf\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"GB min samples leaf vs MSE\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.legend([],[], frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставим число объектов в листе, равное 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры subsampling и max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно каждому дереву в ансамбле давать только часть объектов из выборки — получим стохастический градиентный бустинг. За это отвечает параметр `subsample`.\n",
    "\n",
    "Аналогично можно давать каждому дереву в ансамбле лишь часть признаков — `max_features`.\n",
    "\n",
    "Это может давать дополнительный прирост качества. Сейчас мы этот этап опускаем, так как у нас мало признаков и не очень много объектов, а также в целях экономии времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Понижение learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как мы подобрали остальные параметры, можно попытаться выиграть дополнительное качество за счет понижения `learning_rate` и одновременного увеличения числа деревьев в ансамбле.\n",
    "\n",
    "Построим график качества для текущего `learning_rate` — мы же брали не оптимальное число предсказателей. Посмотрим, можно ли уже на финальном этапе взять побольше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree = GradientBoostingRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=9,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    ")\n",
    "gbtree.fit(x_learn, y_learn)\n",
    "\n",
    "error_train = []\n",
    "error_test = []\n",
    "for it, (y_learn_pred, y_valid_pred) in enumerate(\n",
    "    zip(gbtree.staged_predict(x_learn), gbtree.staged_predict(x_valid))\n",
    "):\n",
    "    ertr = mean_squared_error(y_true=y_learn, y_pred=y_learn_pred)\n",
    "    error_train.append(ertr)\n",
    "    erte = mean_squared_error(y_true=y_valid, y_pred=y_valid_pred)\n",
    "    error_test.append(erte)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(error_train, label=\"train\", c=\"#2DA9E1\", linewidth=4)\n",
    "plt.plot(error_test, label=\"test\", c=\"#4AAE4D\", linewidth=4)\n",
    "plt.xlabel(\"n_estimators\", size=20)\n",
    "plt.ylabel(\"mse\", size=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем 500 деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "models[\"LinReg\"] = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "\n",
    "models[\"RF\"] = RandomForestRegressor(\n",
    "    n_estimators=250, max_depth=None, min_samples_leaf=1, n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "models[\"GBR\"] = GradientBoostingRegressor(\n",
    "    learning_rate=0.1, n_estimators=250, random_state=42\n",
    ")\n",
    "\n",
    "models[\"GBR tuned\"] = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=500,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=9,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "tuned_boost = train_and_test_regressor(models, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=tuned_boost, y=\"mse\", x=\"model\", hue='model')\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что мы дополнительно уменьшили ошибку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг и bias-variance tradeoff\n",
    "\n",
    "В то время как случайный лес уменьшал только variance модели, бустинг стремится уменьшить и bias, и variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "x, y = sklearn.datasets.make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Decision trees\n",
    "for i, max_depth in enumerate([1, 3, 5, 12]):\n",
    "    plt.subplot(3, 4, 1 + i)\n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    dt.fit(x_train, y_train)\n",
    "    plot_decision_boundary(dt, x, y, alpha=0.4, bolded=True)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.title(f\"Decision tree, max_depth={max_depth}\", fontsize=13)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "\n",
    "# Random forests\n",
    "for i, max_depth in enumerate([1, 3, 5, 12]):\n",
    "    plt.subplot(3, 4, 5 + i)\n",
    "    rf = RandomForestClassifier(max_depth=max_depth, n_estimators=500, n_jobs=-1)\n",
    "    rf.fit(x_train, y_train)\n",
    "    plot_decision_boundary(rf, x, y, alpha=0.4, bolded=True)\n",
    "    plt.title(f\"Random forest, max_depth={max_depth}\", fontsize=13)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "# Gradient boostings\n",
    "for i, max_depth in enumerate([1, 3, 5, 12]):\n",
    "    plt.subplot(3, 4, 9 + i)\n",
    "    boost = GradientBoostingClassifier(max_depth=max_depth, n_estimators=250)\n",
    "    boost.fit(x_train, y_train)\n",
    "    plot_decision_boundary(boost, x, y, alpha=0.4, bolded=True)\n",
    "    plt.title(f\"Gradient boosting, max_depth={max_depth}\", fontsize=13)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модификации градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть много модификаций градиентного бустинга. В отличие от реализации в `sklearn`, большая часть из них умеет параллелиться на CPU или даже на GPU.\n",
    "\n",
    "Поэтому при работе с реальными данными использовать градиентный бустинг из `sklearn` не стоит. XGBoost и/или LigthGBM дадут результат как правило лучше и быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы хотим спускаться медленно и не хотим, чтобы модели по пути были сложными. Пусть минимально отличающимися от случайных, но при этом не очень сложными.\n",
    "\n",
    "Поэтому XGBoost вводит специальный штраф за сложные деревья (большей глубины, чем 2–3). За счет того, что в градиентном бустинге можно минимизировать любую дифференцируемую функцию ошибок, мы просто добавляем штраф напрямую в функцию ошибок исходного градиентного бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/xgboost.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calif_housing = sklearn.datasets.fetch_california_housing()\n",
    "x = calif_housing.data\n",
    "y = calif_housing.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопируем параметры, которые совпадают в градиентном бустинге и XGBoost. Посмотрим, получится ли еще улучшить качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "models_add = {}\n",
    "models_add[\"xgb\"] = xgboost.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    min_child_weight=9,  # not exact analogue for min_samples_leaf\n",
    "    n_jobs=-1,  # can be constructed in parrallel, much!!! faster)\n",
    "    objective=\"reg:squarederror\",\n",
    ")\n",
    "\n",
    "xgb_add = train_and_test_regressor(models_add, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=pd.concat([tuned_boost, xgb_add]), y=\"mse\", x=\"model\", hue='model')\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть и незначительно, но XGBoost лучше GBR. И, главное, в разы быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Параметр min_child_weight\n",
    "XGBoost немного иначе определяет важность листа: не сколько именно объектов попало в лист, а насколько объекты в листе имеют сильно разные предсказания. Из-за этого способа определения `min_child_weight` может принимать нецелые значения, в том числе меньше 1 (к примеру, в случае задачи классификации).\n",
    "\n",
    "Попробуем подобрать только этот параметр. Заметьте, мы можем спокойно использовать 2000 деревьев, не боясь ждать результата расчетов долгое время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for min_child_weight in (1, 2, 3, 5, 7, 9, 11, 13, 15):\n",
    "    models[f\"xGB_mnw{min_child_weight}\"] = xgboost.XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        min_child_weight=min_child_weight,\n",
    "        n_jobs=-1,\n",
    "        objective=\"reg:squarederror\",\n",
    "    )\n",
    "\n",
    "xgb_mw = train_and_test_regressor(models, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(data=xgb_mw, y=\"mse\", x=\"model\", hue='model')\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"XGB min_child_weight\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_add2 = {}\n",
    "models_add2[\"xgb_mcw\"] = xgboost.XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    min_child_weight=9,\n",
    "    n_jobs=-1,\n",
    "    objective=\"reg:squarederror\",\n",
    ")\n",
    "\n",
    "xgb_add2 = train_and_test_regressor(models_add2, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=pd.concat([tuned_boost, xgb_add, xgb_add2]), y=\"mse\", x=\"model\", hue='model')\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти ничего не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Он был изначально разработан для того, чтобы работать очень быстро. В него добавили много ухищрений, связанных с этим. Кроме этого, LightGBM по умолчанию строит дерево немного иначе, нежели XGBoost.\n",
    "\n",
    "XGBoost по умолчанию строит дерево по уровням — на каждом уровне если узел можно разбить так, чтобы улучшить значение функции ошибки, то мы это делаем. Ограничены мы только максимальной глубиной дерева.\n",
    "\n",
    "LightGBM же строит дерево по узлам. На каждом шаге бьется тот узел, разбиение которого сильнее всего минимизирует функцию ошибки. И ограничения на глубину нет. В LightGBM вводится ограничение не на глубину дерева, а на общее число листьев в итоговом дереве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/lightgbm.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию он **еще** быстрее (хотя в XGBoost тоже есть опции для ускорения).\n",
    "\n",
    "Из-за особенностей построения им деревьев надо задавать не высоту дерева, а максимальное число листьев. Поставим пока так, чтобы число листьев было равно числу листьев в дереве высоты 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "\n",
    "models_add3 = {}\n",
    "models_add3[\"lightgbm\"] = lightgbm.LGBMRegressor(\n",
    "    n_estimators=2000,  # can use more estimators due to SPEEEEEED\n",
    "    learning_rate=0.1,\n",
    "    max_depth=-1,\n",
    "    num_leaves=2**5,\n",
    "    random_state=42,\n",
    "    min_child_weight=9,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "lgb_add = train_and_test_regressor(models_add3, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(\n",
    "    data=pd.concat([tuned_boost, xgb_add, xgb_add2, lgb_add]), y=\"mse\", x=\"model\", hue='model'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На уровне с XGBoost. Зато быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Максимальное число листьев в дереве\n",
    "Отдельно подберем ограничение на число листьев. По словам создателей, оно не должно быть больше числа листьев в соответствующем дереве глубины 5, то есть 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for num_leaves in (8, 16, 24, 32, 40):\n",
    "    models[f\"LGB_lvn{num_leaves}\"] = lightgbm.LGBMRegressor(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=-1,\n",
    "        num_leaves=num_leaves,\n",
    "        random_state=42,\n",
    "        min_child_weight=10,\n",
    "        n_jobs=-1,\n",
    "        force_col_wise=True,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "lgb_nl = train_and_test_regressor(models, x_learn, y_learn, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(data=lgb_nl, y=\"mse\", x=\"model\", hue='model')\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"LGB num_leaves\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из этого графика можно сделать вывод, что оптимальное число листьев находится в районе 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for num_leaves in (8, 12, 16, 20):\n",
    "    models[f\"LGB_nl{num_leaves}\"] = lightgbm.LGBMRegressor(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=-1,\n",
    "        num_leaves=num_leaves,\n",
    "        random_state=42,\n",
    "        min_child_weight=10,\n",
    "        n_jobs=-1,\n",
    "        force_col_wise=True,\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "lgb_nl = train_and_test_regressor(models, x_learn, y_learn, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(data=lgb_nl, y=\"mse\", x=\"model\", hue='model')\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"LGB num_leaves\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем 12 листьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_add4 = {}\n",
    "models_add4[\"lightgbm lv12\"] = lightgbm.LGBMRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=-1,\n",
    "    num_leaves=12,\n",
    "    random_state=42,\n",
    "    min_child_weight=9,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "lgb_add2 = train_and_test_regressor(models_add4, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(\n",
    "    data=pd.concat([tuned_boost, xgb_add, xgb_add2, lgb_add, lgb_add2]),\n",
    "    y=\"mse\",\n",
    "    x=\"model\",\n",
    "    hue='model'\n",
    ")\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество почти не изменилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разработал Яндекс.\n",
    "\n",
    "CatBoost:\n",
    "\n",
    "1. Хорошо умеет работать с категориальными признаками. Если у вас много категориальных признаков, он может дать существенный выигрыш.\n",
    "2. Умеет работать с текстом без предварительной обработки. Достаточно указать, что колонка содержит текстовый признак.\n",
    "3. По умолчанию использует в качестве модели модификацию обычного дерева решения — Symmetric Tree, которое менее склонно к переобучению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "\n",
    "models_add4 = {}\n",
    "models_add4[\"catboost\"] = catboost.CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    ")\n",
    "# task_type=\"GPU\") # can use gpu, but no parallel-cpu option\n",
    "\n",
    "cat_add = train_and_test_regressor(models_add4, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(\n",
    "    data=pd.concat([tuned_boost, xgb_add, xgb_add2, lgb_add, cat_add]),\n",
    "    y=\"mse\",\n",
    "    x=\"model\",\n",
    "    hue='model'\n",
    ")\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало  лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оптимизации гиперпараметров существуют готовые решения, которые используют различные методы black-box оптимизации. Разберем одну из наиболее популярных библиотек — [**Optuna** 🛠️[doc]](https://optuna.org/).\n",
    "\n",
    "Есть интеграции с scikit-learn, XGBoost и LightGBM, но мы рассмотрим общий случай, который подойдет для любой модели, даже нейронной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import RandomSampler\n",
    "\n",
    "# Define function which will optimized\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # boundaries for the optimizer's\n",
    "    depth = trial.suggest_int(\"depth\", 5, 9, step=1)\n",
    "    min_data_in_leaf = trial.suggest_int(\"min_data_in_leaf\", 6, 14, step=2)\n",
    "    l2_leaf_reg = trial.suggest_categorical(\"l2_leaf_reg\", [2, 5, 7, 10])\n",
    "    random_strength = trial.suggest_float(\"random_strength\", 1, 4)\n",
    "\n",
    "    # create new model(and all parameters) every iteration\n",
    "    model = catboost.CatBoostRegressor(\n",
    "        iterations=2000,\n",
    "        learning_rate=0.1,\n",
    "        depth=depth,\n",
    "        min_data_in_leaf=min_data_in_leaf,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        random_strength=random_strength,\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    boot_score = bootstrap_metric(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        metric_fn=lambda x, y: mean_squared_error(y_true=x, y_pred=y),\n",
    "    )\n",
    "\n",
    "    return boot_score.mean()\n",
    "\n",
    "\n",
    "# Create \"exploration\"\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\", study_name=\"Optimizer\", sampler=RandomSampler(42)\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective, n_trials=20\n",
    ")  # The more iterations, the higher the chances of catching the most optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на историю оптимизации нашей метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем посмотреть, с какими параметрами какие результаты получились, и сделать выводы, в каких диапазонах лучше подбирать параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\"depth\", \"min_data_in_leaf\", \"l2_leaf_reg\", \"random_strength\"]\n",
    "optuna.visualization.plot_slice(study, params=params, target_name=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем лучшие параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best params\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna оценивает важность параметров для лучшего результата:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим CatBoost на значениях, подобранных Optuna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_add5 = {}\n",
    "models_add5[\"catboost_tuned\"] = catboost.CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.1,\n",
    "    depth=study.best_params[\"depth\"],\n",
    "    min_data_in_leaf=study.best_params[\"min_data_in_leaf\"],\n",
    "    l2_leaf_reg=study.best_params[\"l2_leaf_reg\"],\n",
    "    random_strength=study.best_params[\"random_strength\"],\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    ")\n",
    "# task_type=\"GPU\") # can use gpu, but no parallel-cpu option\n",
    "\n",
    "cat_tuned_add = train_and_test_regressor(models_add5, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(\n",
    "    data=pd.concat([tuned_boost, xgb_add, xgb_add2, lgb_add, cat_add, cat_tuned_add]),\n",
    "    y=\"mse\",\n",
    "    x=\"model\",\n",
    "    hue='model'\n",
    ")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество незначительно улучшилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Про подбор параметров модифицированных бустингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый из модифицированных бустингов имеет свои особые параметры и рекомендации от создателей и участников Kaggle, как и в каком порядке выбирать параметры для конкретного бустинга. Если вы решили использовать тот или иной вид бустинга в своей задаче, ОЗНАКОМЬТЕСЬ c этими советами.\n",
    "\n",
    "Все три бустинга, к примеру, позволяют задавать не только число признаков, использующихся в каждом узле, но и число признаков, использующихся в каждом дереве в целом.\n",
    "\n",
    "Кроме того, все три бустинга имеют настройки, ускоряющие их работу (у LightGBM эти настройки выставлены по умолчанию), и все три бустинга умеют работать на GPU.\n",
    "\n",
    "Здесь мы бегло пробежались по самым верхам, копируя подобранные на предыдущих этапах параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Про другие реализации случайного леса\n",
    "В XGBoost и LightGBM есть свои, более быстрые и иногда более эффективные реализации случайного леса. Но их надо дополнительно настраивать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_rf = {}\n",
    "\n",
    "models_rf[\"xgb_rf\"] = xgboost.XGBRFRegressor(\n",
    "    n_estimators=250,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    reg_lambda=0.001,  # to get deeper, less regularized trees\n",
    "    max_depth=20,  # trees must be deep\n",
    "    n_jobs=-1,\n",
    "    objective=\"reg:squarederror\",\n",
    ")\n",
    "\n",
    "models_rf[\"lgb_rf\"] = lightgbm.LGBMRegressor(\n",
    "    n_estimators=250,\n",
    "    subsample_freq=1,  # for lgb random forest must be set to 1\n",
    "    num_leaves=2**14,  # don't forget to change the number of leaves to smth big\n",
    "    boosting_type=\"rf\",  # set boosteer type\n",
    "    colsample_bytree=0.8,  # for lgb random forest must be less then 1\n",
    "    subsample=0.8,  # for lgb random forest must be less then 1\n",
    "    min_child_samples=1,  # to get deeper trees\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "rf_add = train_and_test_regressor(models_rf, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(\n",
    "    data=pd.concat([tuned_boost.query('model == \"RF\"'), rf_add]), y=\"mse\", x=\"model\", hue='model'\n",
    ")\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметьте, что в данном случае они показывают себя иначе, нежели `sklearn.RandomForest`. Это частое явление, так как деревья в пакетах XGBoost и LightGBM строятся отличным от sklearn образом. Это может как улучшать качество, так и ухудшать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Блендинг и Стэкинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Смесь экспертов</font>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/weighted_voting.png\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого мы использовали два подхода. Первый подход — берем много предсказаний большого количества моделей и усредняем (считаем, что модели равноправны).\n",
    "\n",
    "$$\\large h(x) = \\dfrac 1 k \\sum_{i=i}^k  a_i (x) $$\n",
    "Потом задумываемся о том, что каждая модель предсказывает в целом по-разному. Одна модель ошибается в $10\\%$ случаев, другая — в $15\\%$ и так далее. Было бы неплохо к предсказаниям этих моделей подобрать веса. Так рождается идея того же бустинга.\n",
    "\n",
    "$$\\large h(x) = \\sum_{i=i}^k b_i a_i (x) $$\n",
    "\n",
    "\n",
    "Следующий логичный шаг — подумать о том, что каждая модель может ошибаться на каких-то своих объектах. Например, при предсказании, насколько велика вероятность, что человек серьезно заболеет, одна модель будет плохо работать для европейцев, а другая — для жителей Новой Гвинеи.\n",
    "\n",
    "$$\\large h(x) = \\sum_{i=i}^k b_i(x) a_i (x) $$\n",
    "\n",
    "Получается ситуация, в которой то, насколько хорошо будет предсказывать модель, зависит от самого объекта. Фактически это означает то, что мы бы хотели для каждого объекта получать какой-то вектор весов, а дальше суммировать предсказания моделей $a_i$, используя эти веса.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как получать эти веса для каждого объекта?\n",
    "Обучим еще одну модель, которая явно или неявно предсказывает веса алгоритмов и агрегирует их предсказания. Называться она будет **мета-алгоритмом**.\n",
    "\n",
    "Обычно в качестве мета-алгоритма используются сравнительно простые модели, например, линейные.\n",
    "\n",
    "Как получить такую модель? Есть два распространенных подхода — **stacking** и **blending**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending (Блендинг)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На соревновании Netflix Prize была поставлена задача — предсказать, как люди оценят тот или иной фильм.\n",
    "Победил подход, основанный на таком объединении моделей, при котором у вас каждая модель получает вес в зависимости от объекта. Подход называется **блендинг**.\n",
    "\n",
    "Отличительной особенностью такого способа ансамблирования является использование моделей разной природы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L03/netflix_prize.png\" width=\"600\"/></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://machinelearningmastery.ru/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637969614ea/\">Прототипирование системы рекомендаций</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберем пошагово, как реализуется блендинг:\n",
    "1. Делим данные на подвыборки. Обучающая выборка состоит из двух подвыборок — одна для обучения ансамбля алгоритмов (чаще это выборка побольше), другая для обучения мета-алгоритма.\n",
    "2. Обучаем ансамбль на первой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/split_data_blending.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Получаем предсказания ансамбля на объектах второй выборки.\n",
    "4. Используем эти предсказания как признаки для обучения мета-алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/train_meta_blending.png\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Получаем предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/test_predict_blending.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недостатком блендинга является то, что мы дополнительно разбиваем обучающую выборку, так как нельзя учить и базовые алгоритмы, и мета-алгоритм на одних и тех же данных.\n",
    "\n",
    "Для улучшения качества можно сделать несколько блендингов (по-разному разбивая обучающую выборку на подвыборки), а дальше усреднять предсказания разных блендингов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать простой блендинг. Единственное, немного схитрим. Для обучения мета-алгоритма будем использовать датасет, который использовали при подборе гиперпараметров алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlendingRegressor:\n",
    "    def __init__(self, first_layer_models, second_layer_model):\n",
    "        self.first_layer_models = {\n",
    "            name: sklearn.clone(model) for name, model in first_layer_models.items()\n",
    "        }\n",
    "        self.second_layer_model = sklearn.clone(second_layer_model)\n",
    "\n",
    "    def fit_1st_layer(self, x, y):\n",
    "        for name, model in self.first_layer_models.items():\n",
    "            print(f\"Fitting {name}\")\n",
    "            model.fit(x, y)\n",
    "\n",
    "    def predict_1st_layer(self, x):\n",
    "        features = np.zeros((x.shape[0], len(self.first_layer_models)))\n",
    "        for ind, model in enumerate(self.first_layer_models.values()):\n",
    "            features[:, ind] = model.predict(x)\n",
    "        return features\n",
    "\n",
    "    def fit_2nd_layer(self, x, y):\n",
    "        features = self.predict_1st_layer(x)\n",
    "        self.second_layer_model.fit(features, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        features = self.predict_1st_layer(x)\n",
    "        y_pred = self.second_layer_model.predict(features)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_models = {}\n",
    "\n",
    "first_layer_models[\"linreg\"] = make_pipeline(\n",
    "    StandardScaler(with_mean=False), LinearRegression()\n",
    ")\n",
    "\n",
    "first_layer_models[\"rf\"] = RandomForestRegressor(\n",
    "    n_estimators=250, max_depth=None, min_samples_leaf=1, n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "first_layer_models[\"xgb\"] = xgboost.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    min_child_weight=10,\n",
    "    n_jobs=-1,\n",
    "    objective=\"reg:squarederror\",\n",
    ")\n",
    "\n",
    "first_layer_models[\"lgb_tuned\"] = lightgbm.LGBMRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=-1,\n",
    "    num_leaves=12,\n",
    "    random_state=42,\n",
    "    min_child_weight=7,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "first_layer_models[\"catboost\"] = catboost.CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    verbose=0,\n",
    "    learning_rate=0.1,\n",
    "    depth=5,\n",
    "    random_state=42,\n",
    "    min_data_in_leaf=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_learn, x_valid, y_learn, y_valid = train_test_split(x_train, y_train, random_state=42)\n",
    "blend_reg = BlendingRegressor(first_layer_models, LinearRegression())\n",
    "\n",
    "blend_reg.fit_1st_layer(x_learn, y_learn)\n",
    "blend_reg.fit_2nd_layer(x_valid, y_valid)\n",
    "y_pred = blend_reg.predict(x_test)\n",
    "blend_boot = bootstrap_metric(\n",
    "    y_test, y_pred, metric_fn=lambda x, y: mean_squared_error(y_true=x, y_pred=y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_data = pd.DataFrame({\"mse\": blend_boot})\n",
    "blend_data[\"model\"] = \"SingleBlending\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(\n",
    "    data=pd.concat([tuned_boost, xgb_add, xgb_add2, lgb_add, cat_add, blend_data]),\n",
    "    y=\"mse\",\n",
    "    x=\"model\",\n",
    "    hue='model'\n",
    ")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одиночный блендинг работает даже хуже, чем один CatBoost\n",
    "\n",
    "Попробуем обучить 10 блендингов с разными разбиениями `x_train` на `x_learn` и `x_valid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "blending_ensemble = []\n",
    "\n",
    "# takes some time to run\n",
    "for i in range(1, 11):\n",
    "    print(f\"Training blending {i}\")\n",
    "    x_learn, x_valid, y_learn, y_valid = train_test_split(\n",
    "        x_train, y_train, random_state=i * 7 % 13\n",
    "    )\n",
    "    blend_reg = BlendingRegressor(first_layer_models, LinearRegression())\n",
    "\n",
    "    blend_reg.fit_1st_layer(x_learn, y_learn)\n",
    "    blend_reg.fit_2nd_layer(x_valid, y_valid)\n",
    "    blending_ensemble.append(blend_reg)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = 0\n",
    "for blend_reg in blending_ensemble:\n",
    "    y_pred += blend_reg.predict(x_test)\n",
    "y_pred /= len(blending_ensemble)\n",
    "\n",
    "\n",
    "eblend_boot = bootstrap_metric(\n",
    "    y_test, y_pred, metric_fn=lambda x, y: mean_squared_error(y_true=x, y_pred=y)\n",
    ")\n",
    "eblend_data = pd.DataFrame({\"mse\": eblend_boot})\n",
    "eblend_data[\"model\"] = \"EnsembleBlending\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(eblend_boot, q=[0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(cat_add[\"mse\"], q=[0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(\n",
    "    data=pd.concat(\n",
    "        [tuned_boost, xgb_add, xgb_add2, lgb_add, cat_add, blend_data, eblend_data]\n",
    "    ),\n",
    "    y=\"mse\",\n",
    "    x=\"model\",\n",
    "    hue='model'\n",
    ")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество по сравнению с лучшей моделью (CatBoost) существенно не отличается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стэкинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно использовать другой способ, который позволяет использовать всю обучающую выборку.\n",
    "\n",
    "Вместо того, чтобы делить обучающую выборку на подвыборки, давайте использовать кросс-валидацию.\n",
    "\n",
    "Для этого:\n",
    "1. Делим обучающий набор на блоки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/split_data_stacking.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучаем базовую модель из ансамбля на каждом кросс-валидационном разбиении.\n",
    "\n",
    " На блоке, который не вошел в обучение, делаем предсказание. Получаем предсказания для всех объектов обучающей выборки. Повторяем процедуру для каждой модели в ансамбле.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/cv_train_stacking.png\" width=\"800\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Обучаем мета-алгоритм на полученных признаках.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/train_meta_stacking.png\" width=\"500\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. Для предсказания на тестовых данных ансамбль базовых алгоритмов переучивается на всей тренировочной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/all_train_stacking.png\" width=\"500\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Используем этот ансамбль для получения признаков для предсказания мета-алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L03/out/test_predict_stacking.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стэкинг, в отличие от блендинга, использует всю тренировочную выборку.\n",
    "\n",
    "Но этим мы вносим несколько проблем, одной из которых является то, что ансамбль, на предсказаниях которого мы учили мета-алгоритм, и ансамбль, предсказания которого мы в итоге используем, немного отличаются.\n",
    "\n",
    "Такой подход более склонен к переобучению. Для борьбы с ним можно, к примеру, подмешивать к предсказаниям базовых моделей шум.\n",
    "\n",
    "Также, по причине того, что нам надо делать предсказание на кросс-валидации, работать этот метод будет дольше, чем Blending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn уже реализован свой `StackingRegressor`, поэтому в этой лекции мы его реализовывать не будем.\n",
    "\n",
    "Можете посмотреть пример реализации, например, [здесь 🐾[git]](https://github.com/Dyakonov/ml_hacks/blob/master/dj_stacking.ipynb). Если вам действительно понадобится стэкинг, полезно иметь свою собственную реализацию, чтобы легко менять в ней некоторые детали (вариантов стекинга великое множество)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем в нашу новую модель только быстро обучащиеся модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = []\n",
    "\n",
    "base_models.append(\n",
    "    [\"linreg\", make_pipeline(StandardScaler(with_mean=False), LinearRegression())]\n",
    ")\n",
    "\n",
    "base_models.append(\n",
    "    [\n",
    "        \"xgb\",\n",
    "        xgboost.XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            random_state=42,\n",
    "            min_child_weight=10,\n",
    "            n_jobs=-1,\n",
    "            objective=\"reg:squarederror\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "base_models.append(\n",
    "    [\n",
    "        \"lgb\",\n",
    "        lightgbm.LGBMRegressor(\n",
    "            n_estimators=2000,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=-1,\n",
    "            num_leaves=12,\n",
    "            random_state=42,\n",
    "            min_child_weight=7,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "base_models.append(\n",
    "    [\n",
    "        \"cgb\",\n",
    "        catboost.CatBoostRegressor(\n",
    "            iterations=2000,\n",
    "            verbose=0,\n",
    "            learning_rate=0.1,\n",
    "            depth=5,\n",
    "            random_state=42,\n",
    "            min_data_in_leaf=5,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "\n",
    "stacking_reg = StackingRegressor(base_models, LinearRegression(), cv=3)\n",
    "stacking_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stacking_reg.predict(x_test)\n",
    "print(mean_squared_error(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_boot = bootstrap_metric(\n",
    "    y_test, y_pred, metric_fn=lambda x, y: mean_squared_error(y_true=x, y_pred=y)\n",
    ")\n",
    "\n",
    "stack_data = pd.DataFrame({\"mse\": stack_boot})\n",
    "stack_data[\"model\"] = \"Stacking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "ax = sns.boxplot(\n",
    "    data=pd.concat(\n",
    "        [\n",
    "            tuned_boost,\n",
    "            xgb_add,\n",
    "            xgb_add2,\n",
    "            lgb_add,\n",
    "            cat_add,\n",
    "            blend_data,\n",
    "            eblend_data,\n",
    "            stack_data,\n",
    "        ]\n",
    "    ),\n",
    "    y=\"mse\",\n",
    "    x=\"model\",\n",
    "    hue='model',\n",
    "    palette='tab10'\n",
    ")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.xlabel(\"\", size=20)\n",
    "plt.ylabel(\"MSE\", size=20)\n",
    "plt.title(\"Boosting and others\", size=20)\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "plt.xticks(size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(stack_data[\"mse\"], q=[0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(cat_add[\"mse\"], q=[0.025, 0.975])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что стэкинг в данной задаче не принес существенного улучшения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стэкинг vs блендинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле эти подходы часто объединяют в один или путают местами. Например, улучшая блендинг в сторону использования всей обучающей выборки, можно получить стэкинг.\n",
    "\n",
    "Оба подхода имеют множество модификаций, к примеру, с добавлением признаков-предсказаний базовых моделей к исходным признакам и т. д.\n",
    "Оба подхода показывают схожие результаты. И оба подхода улучшают свое качество по мере увеличения размера обучающей выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея ансамблирования будет довольно часто встречаться в различных подходах в машинном обучении. Мы рассмотрели основные базовые концепции, которые помогут в понимании более сложных. При достижении \"потолка\" в качестве вашей модели полезно подумать в сторону ансамблирования для улучшения качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Некоторые практические рекомендации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какой ML алгоритм в общем случае выбрать: RF или GBDT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из [практики соревнований по машинному обучению ✏️[blog]](https://www.kaggle.com/code/kashnitsky/topic-10-gradient-boosting/notebook) известно, что использование градиентного бустинга для решения задач с табличными данными даёт возможность получить максимально качественное решение. Тем не менее, следует понимать, что это гипотетическое лучшее качество решения достигается путём сложного подбора параметров и финальной настройки модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве короткой практической рекомендации можно сформулировать следующий пайплайн для решения задачи на реальных табличных данных:\n",
    "\n",
    "1. Обучить на имеющихся данных \"простую\" модель случайного леса, оценку её качества взять за отправную точку при дальнейшей работе.\n",
    "1. Провести эксперименты по отбору и конструированию признаков (feature engineering) (благодаря гипотетической большей скорости обучения случайного леса, разумно проводить это исследование именно с этой моделью).\n",
    "1. Повторять эксперименты с feature engineering, подбирая оптимальные основные гиперпараметры случайного леса (об этом ниже).\n",
    "1. Отобрав лучшие варианты наборов признаков из экспериментов с решением на случайных лесах, использовать их при обучении модели одной из реализаций градиентного бустинга (если в данных доминируют категориальные признаки, то в первую очередь следует воспользоваться реализацией бустинга от CatBoost, в противном случае можно воспользоваться любой популярной реализацией — CatBoost, XGBoost, LightGBM).\n",
    "1. Произвести настройку гиперпараметров модели (об этом ниже).\n",
    "1. Если не получилось достичь желаемого качества решения, следует вернуться к экспериментам с feature engineering, но уже сразу проводить их для модели бустинга. Вернуться к этапу подбора гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какие деревья решений использовать в качестве элементов случайного леса, а на каких строить градиентный бустинг?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже успели установить выше, справедливо разложение:\n",
    "\n",
    "```ошибка предсказания модели = bias + variance```\n",
    "\n",
    "и имеет место явление bias-variance tradeoff, принципиально не позволяющее одинаково сильно минимизировать оба вклада в ошибку предсказания модели.\n",
    "\n",
    "* Ансамблирование в виде бэггинга, использующееся при построении RF, заточено на уменьшение `variance` путём \"усреднения\" ответов элементарных предсказателей. Использование бэггинга существенно не позволяет улучшить `bias` — этот показатель наследуется от базового эстиматора. Таким образом, **при построении случайного леса следует взять относительно глубокие деревья решений** (можно говорить о глубине в 6–10 ветвлений), обладающие собственным низким показателем `bias`.\n",
    "\n",
    "* Ансамблирование в виде бустинга, наоборот, в первую очередь заточено на улучшение показателя `bias` итоговой модели путём взаимного улучшения большого числа *стабильных, но слабых* эстиматоров (то есть обладающих высоким показателем `bias` и низким `variance`). Таким образом, **при построении градиентного бустинга над деревьями решений следует взять в качестве базовой модели неглубокие деревья** (вплоть до решающих пней — деревьев решений с единственным ветвлением)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### У RF значительно меньше гиперпараметров, чем у GBDT. Но как их выбрать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фактически, все реализации алгоритма случайного леса будут содержать три важных гиперпараметра:\n",
    "\n",
    "* **Глубина деревьев**.\n",
    "\n",
    "Мы ожидаем, что каждое из деревьев в составе леса обладает достаточной обобщающей способностью, чтобы быть принципиально способным самостоятельно предсказывать данные. То есть во время подбора гиперпараметров случайного леса данный параметр стоит постепенно увеличивать, контролируя качество на тренировочной и валидационной выборках — слишком глубокие деревья могут привести к переобучению модели.\n",
    "\n",
    "* **Количество деревьев** в лесу.\n",
    "\n",
    "Бэггинг деревьев решений позволяет нам минимизировать `variance` итоговой модели, но понятно, что ресурс для такого улучшения не безграничен. Количество деревьев в лесу можно постепенно увеличивать до тех пор, пока это не перестанет приводить к существенному улучшению качества предсказания модели.\n",
    "\n",
    "\n",
    "* Какая **доля признаков** подаётся отдельным деревьям решений в составе случайного леса.\n",
    "\n",
    "Подавая на вход одиночным деревьям решений б**о**льшее число признаков, мы делаем их более \"сильными предсказателями\", но взамен увеличиваем их скоррелированность (тем самым нарушаем процедуру бэггинга). Для конкретных данных положение оптимума можно наверняка установить только полным перебором параметра, но общей практикой является использование трети от общего числа свойств для задачи регрессии и округленного вниз квадратного корня из числа свойств для задач классификации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какие гиперпараметры GBDT реализаций следует подбирать в первую очередь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Современные реализации GBPD содержат крайне широкий список доступных для настройки параметров. Первичное знакомство с длинными списками параметров может оказаться дезориентирующим, поэтому мы приведём короткий список наиболее существенных гиперпараметров, которые повлияют на успех обучения модели.\n",
    "\n",
    "Среди таких наиболее важных параметров выделим два класса:\n",
    "* параметры, влияющие на контроль переобучения модели;\n",
    "* параметры, определяющие скорость процесса обучения модели.\n",
    "\n",
    "Названия параметров в приведённой ниже таблице являются ссылками на актуальную версию документации:\n",
    "\n",
    "| param type            | CatBoost                         | XGBoost                                        | LightGBM                                                      |\n",
    "|-----------------------|----------------------------------|------------------------------------------------|---------------------------------------------------------------|\n",
    "| overfitting control   | [`learning_rate`](https://catboost.ai/en/docs/concepts/parameter-tuning#learning-rate)<br>[`depth`](https://catboost.ai/en/docs/concepts/parameter-tuning#tree-depth)<br>[`l2_leaf_reg`](https://catboost.ai/en/docs/concepts/parameter-tuning#l2-reg) | [`eta`](https://xgboost.readthedocs.io/en/stable/parameter.html#:~:text=%EF%83%81-,eta,-%5Bdefault%3D0.3%2C%20alias)<br>[`max_depth`](https://xgboost.readthedocs.io/en/stable/parameter.html#:~:text=range%3A%20%5B0%2C%E2%88%9E%5D-,max_depth,-%5Bdefault%3D6%5D)<br>[`min_child_weight`](https://xgboost.readthedocs.io/en/stable/parameter.html#:~:text=range%3A%20%5B0%2C%E2%88%9E%5D-,min_child_weight,-%5Bdefault%3D1%5D) | [`learning_rate`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#learning_rate)<br>[`max_depth`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#max_depth)<br>[`num_leaves`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#num_leaves)<br>[`min_data_in_leaf`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#min_data_in_leaf) |\n",
    "| speed of the training | [`rsm`](https://catboost.ai/en/docs/references/training-parameters/common#rsm)<br>[`iterations`](https://catboost.ai/en/docs/references/training-parameters/common#iterations)                | [`colsample_bytree`](https://xgboost.readthedocs.io/en/stable/parameter.html#:~:text=support%20uniform%20sampling.-,colsample_bytree,-%2C%20colsample_bylevel%2C)<br>[`subsample`](https://xgboost.readthedocs.io/en/stable/parameter.html#:~:text=range%3A%20%5B0%2C%E2%88%9E%5D-,subsample,-%5Bdefault%3D1%5D)<br>[`n_estimators`](https://xgboost.readthedocs.io/en/stable/python/python_api.html#:~:text=for%20XGBoost%20regression.-,Parameters,n_estimators%20(int),-%E2%80%93%20Number%20of%20gradient)  | [`feature_fraction`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#feature_fraction)<br>[`bagging_fraction`](https://lightgbm.readthedocs.io/en/latest/Parameters.html#bagging_fraction)                          |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применение нейронных сетей к табличным данным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть попытки построить архитектуры нейронных сетей таким образом, чтобы они могли работать с табличными данными.\n",
    "Можно отметить архитектуру от Яндекса\n",
    "[NODE 🎓[arxiv]](https://arxiv.org/pdf/1909.06312.pdf) и [TabNet 🎓[arxiv]](https://arxiv.org/pdf/1908.07442.pdf), [TabNet 🐾[git]](https://github.com/dreamquark-ai/tabnet) от Гугл.\n",
    "\n",
    "Вторая работа особенно удачна и уже активно используется в соревнованиях на Kaggle. Стоит отметить, что победы над древесными моделями не одержано. Но полученная модель иногда достигает их качества и обладает рядом интересных особенностей:\n",
    "\n",
    "1. Как и любая другая нейросетевая архитектура, она дифференцируема. Можно вставить обученную нейросеть как часть другой и использовать transfer learning и прочее.\n",
    "2. Нейросеть автоматически выбирает признаки, поэтому feature importance можно получить без дополнительных ухищрений.\n",
    "3. Ее можно обучать в semisupervised манере: сначала предобучить на неразмеченных данных, а потом уже использовать размеченные.\n",
    "\n",
    "Установим пакет, реализующий эту нейросеть на PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "calif_housing = sklearn.datasets.fetch_california_housing()\n",
    "x = calif_housing.data\n",
    "y = calif_housing.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "x_learn, x_valid, y_learn, y_valid = train_test_split(x_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим с параметрами по умолчанию, передав датасет для валидации. Нам нужно узнать, когда нейросеть начнет переобучаться.\n",
    "\n",
    " Заметьте, что у XGBoost и LightGBM тоже есть такая возможность `early_stopping`, которая позволяет легко подбирать число базовых моделей. Подробнее смотрите в документации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросеть принимает `y` в формате (предсказываемая величина, число предсказываемых величин), поэтому нам потребуется `reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "tabnet = TabNetRegressor()\n",
    "tabnet.fit(\n",
    "    x_learn, y_learn.reshape(-1, 1), eval_set=[(x_valid, y_valid.reshape(-1, 1))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим теперь на всем тренировочном датасете, поставив число эпох обучения равным тому, что нам сообщила выдача функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet = TabNetRegressor()\n",
    "tabnet.fit(x_train, y_train.reshape(-1, 1), max_epochs=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = tabnet.predict(x_test)\n",
    "print(mean_squared_error(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что качество сильно хуже, чем у топ-моделей бустинга. Возможно, надо попробовать параметры, отличные от параметров по умолчанию, или нейронную сеть другой архитектуры!\n",
    "\n",
    "По сообщениям участников Kaggle, модель все же чаще всего уступает хорошо затюненным бустингам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Литература</font>\n",
    "\n",
    "<font size=\"5\">Общие источники</font>\n",
    "\n",
    "* [[book] 📚 Про разделение на классическое и глубокое машинное обучение ](https://www.deeplearningbook.org/contents/intro.html)\n",
    "* [[book] 📚 Один из лучших учебников по классическому машинному обучению](https://web.stanford.edu/~hastie/ElemStatLearn/)\n",
    "* [[book] 📚 Хорошая книга по машинному обучению](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646)\n",
    "\n",
    "<font size=\"5\">Про деревья решений</font>\n",
    "\n",
    "* [[blog] ✏️ Деревья решений](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn)\n",
    "\n",
    "<font size=\"5\">Про ансамбли</font>\n",
    "\n",
    "* [[blog] ✏️ Kaggle Ensembling guide](https://www.kaggle.com/code/amrmahmoud123/1-guide-to-ensembling-methods/notebook)\n",
    "* [[blog] ✏️ Comprehensive guide for ensemble models](https://www.projectpro.io/article/a-comprehensive-guide-to-ensemble-learning-methods/432)\n",
    "* [[blog] ✏️ Про стэкинг и блендинг](https://dyakonov.org/2017/03/10/c%D1%82%D0%B5%D0%BA%D0%B8%D0%BD%D0%B3-stacking-%D0%B8-%D0%B1%D0%BB%D0%B5%D0%BD%D0%B4%D0%B8%D0%BD%D0%B3-blending/)\n",
    "\n",
    "<font size=\"5\">XGBoost</font>\n",
    "\n",
    "* [[blog] ✏️ Отличие XGBoost от обычного градиентного бустинга](https://stats.stackexchange.com/questions/202858/xgboost-loss-function-approximation-with-taylor-expansion)\n",
    "* [[arxiv] 🎓 Оригинальная статья](https://arxiv.org/pdf/1603.02754.pdf)\n",
    "* [[blog] ✏️ Как подбирать параметры XGBoost](https://usermanual.wiki/Document/Complete20Guide20to20Parameter20Tuning20in20XGBoost20with20codes20in20Python.1988513968)\n",
    "\n",
    "<font size=\"5\">CatBoost</font>\n",
    "\n",
    "* [[video] 📺 Решение задач классификации при помощи CatBoost](https://www.youtube.com/watch?v=xl1fwCza9C8)\n",
    "* [[doc] 🛠️ Официальная документация](https://catboost.ai/docs/concepts/parameter-tuning.html#rand-str)\n",
    "\n",
    "<font size=\"5\">LightGBM</font>\n",
    "\n",
    "* [[doc] 🛠️ Очень подробная и удобная документация](https://lightgbm.readthedocs.io/en/latest/ )\n",
    "* [[blog] ✏️ Описание параметров](https://neptune.ai/blog/lightgbm-parameters-guide?utm_source=datacamp&utm_medium=post&utm_campaign=blog-lightgbm-parameters-guide&utm_campaign=News&utm_medium=Community&utm_source=DataCamp.com)\n",
    "* [[arxiv] 🎓 Новый бустинг с деревьями, содержащими в листах линейные регрессии](https://arxiv.org/pdf/1802.05640.pdf)\n",
    "\n",
    "<font size=\"5\">Дисбаланс классов</font>\n",
    "\n",
    "* [[blog] ✏️ Обучение в случае дисбаланса классов](http://www.svds.com/learning-imbalanced-classes/)\n",
    "* [[blog] ✏️ Bagging и случайные леса для обучения с дисбалансом классов](https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/)\n",
    "* [[article] 🎓 Коэффициент корреляции Мэтьюса](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7)\n",
    "\n",
    "<font size=\"5\">Нейронные сети и бустинг</font>\n",
    "\n",
    "* [[arxiv] 🎓 TabNet](https://arxiv.org/pdf/1908.07442.pdf)\n",
    "* [[git] 🐾 TabNet, реализация на PyTorch](https://github.com/dreamquark-ai/tabnet)\n",
    "* [[arxiv] 🎓 NODE](https://arxiv.org/pdf/1909.06312.pdf)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
