{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=\"6\">Нейронные сети</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ограничения Линейного классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним материал лекции №2\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L02_Linear_classifier/img/L02_Linear_classifier-11.jpg\" width=\"550\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Линейный классификатор: скалярное произведение\n",
    "- Лосс - функции: SVM,CrossEntropyLoss\n",
    "- Градиентный спуск\n",
    "- Оценка точности Линейного классификатора (0.38)\n",
    "\n",
    "Попробуем визуализировать, шаблоны, получающиеся усреднением изображений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!wget http://edunet.kea.su/repo/src/L05_Neural_networks/lc_cifar10_weights.txt\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display templates \n",
    "plt.rcParams[\"figure.figsize\"] = (25, 10)\n",
    "\n",
    "W = torch.from_numpy(np.loadtxt(\"lc_cifar10_weights.txt\")) # 3073x10\n",
    "print(W.shape)\n",
    "\n",
    "# Remove bias\n",
    "W = W[:-1, :]\n",
    "print(W.shape)\n",
    "\n",
    "# Denormalize\n",
    "w_min = torch.min(W)\n",
    "w_max = torch.max(W)\n",
    "templates =  255*(W-w_min)/(w_max-w_min)\n",
    "\n",
    "# Display templates\n",
    "labels = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    img = templates[:,i].view(3, 32, 32).permute(1, 2, 0).type(torch.uint8)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ограничение этого подхода состоит в том, что покольку для каждого класса существует один шаблон, он будет сохранять информацию обо всех объектах класса сразу (например, на получившихся шаблонах у лошади две головы, машина красная и т.д.). Такой подход не допускает вариативности, а это будет мешать модели запоминать разные варианты объектов одного класса, что ограничивает точность модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ХОR — проблема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У линейного классификатора есть существенные ограничения применения. Рассмотрим задачу XOR. На вход подаётся упорядоченный набор из двух чисел согласно таблице истинности xor. Задача линейного классификатора сопоставить этим числам их класс согласно таблице. Графически два входных числа можно изобразить на плоскости как координаты и цветом обозначить их истинный класс. Задача классификатора - построить линию, отделяющую красные точки (класс 0) от зелёных точек (класс 1). Однако, видно, что одной линией это сделать геометрически невозможно.\n",
    "\n",
    "То есть линейный классификатор уже не может справится с этой задачей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/1.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проблемы классификации более сложных объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда компьютер смотрит на изображение, то не видит целостное представление кошки или любого другого объекта. Он видит лишь гигантскую сетку чисел. Например, если размер изображения 800 на 600 и каждый пиксель представлен тремя числами для красного, зелёного и синего каналов, то получится сетка из 800х600х3 = 1,440,000 чисел. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, если мы снимем кошку с другого ракурса или при ином освещении, то вся сетка чисел будет выглядеть совершенно иначе. Помимо этого, животные могут принимать множество различных поз, или же на фотографии может оказаться только часть кошки, например, хвост. Алгоритмы распознавания должны быть устойчивы к таким изменениям. Эта проблема получила название «семантический разрыв» — непонимание информации, которая заключена в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот лишь малая часть параметров, от которых зависит точность распознавания линейного классификатора.\n",
    "\n",
    "Обратите внимание, что на всех изображениях, в том или ином виде присутствуют кошки. При решении задачи классификации, например \"кошка/собака\", все изображения должны быть определены как \"кошка\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/2.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо этих сложностей, существует ещё проблема внутриклассовых вариаций, когда одно понятие охватывает множество визуальных проявлений. Например, кошки могут быть разных пород, возрастов и размеров. И методы распознавания должны обрабатывать все возможные варианты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из подходов к решению этой проблемы &mdash; модифицировать модель таким образом, чтобы на выходе у нее было не 10, а 100 шаблонов, позволяющих запоминать разные объекты одного класса и далее использовать эти шаблоны для разбиения объектов на классы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/8.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем эту модель на основе линейного классификатора из лекции №2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x): # x is image\n",
    "  x = torch.cat((x, torch.Tensor([1])), dim=0) # bias trick\n",
    "  scores = x.matmul(self.W) # dot product\n",
    "  return torch.argmax(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем к выходам классификатора еще один классификатор. Будет ли работать данная модель?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3072)\n",
    "W1 = torch.randn(3072, 100)*0.0001 # without bias\n",
    "W2 = torch.randn(100, 10)*0.0001 # without bias\n",
    "scores1 = x.matmul(W1) # matrix multiplication, equivalent x@W1\n",
    "scores2 = scores1.matmul(W2)\n",
    "\n",
    "print(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нетрудно заметить, что последовательное применение двух классификаторов ко входным данным эквивалентно применению одного классификатора с матрицей весов, равной произведению двух матриц весов классификаторов примененных последовательно.\n",
    "\n",
    "$$scores2 = x\\cdot W1\\cdot W2$$ \n",
    "$$W = W1\\cdot W2$$\n",
    "$$scores2 = x\\cdot W$$ \n",
    "\n",
    "Для того, чтобы последовательно примененные классификаторы не вырождались в один, необходимо применить нелинейность к их выходам, например, сделаем так, чтобы каждый шаблон, предсказывающий класс объекта воспринимал только те сигналы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = x.matmul(W1) \n",
    "print(f\"\\nScores1 {scores1}\")\n",
    "activations = torch.maximum(torch.tensor(0), scores1) # Use only patterns with big score\n",
    "print(f\"\\nActivations {activations}\" )\n",
    "scores2 = activations.matmul(W2)\n",
    "print(f\"\\nScores2 {scores2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нелинейность:\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L02_Linear_classifier/img/L02_Linear_classifier-09.jpg\" width=\"450\">\n",
    "\n",
    "Такая конструкция называется **функцией активации**. И мы уже пользовались подобной когда разбирали Cross entropy loss (Softmax)\n",
    "\n",
    "Приведем код в порядок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "  def __init__(self):\n",
    "    self.W1 = torch.randn(3072, 100)*0.0001 # without bias\n",
    "    self.W2 = torch.randn(100, 10)*0.0001 # without bias\n",
    "\n",
    "  def predict(self,x):\n",
    "    scores1 = x.matmul(self.W1) # Linear / Fully connected layer1\n",
    "    activations1 = torch.maximum(torch.tensor(0), scores1) # ReLU activation\n",
    "    scores2 = activations1.matmul(self.W2)\n",
    "    return activations1, scores2\n",
    "\n",
    "x = torch.rand(3072) # input image\n",
    "nn = NeuralNet()\n",
    "activations, scores = nn.predict(x)\n",
    "print(f'activations {activations}\\nscores: {scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Переход от ЛК к прецептрону"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ядром этой операции является скалярное произведение. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L04_Feature_Engineering/img/L04_skalyar.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/9.png\"  width=\"550\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И она соответствует одиному слою искусственной нейроннной сети (за исключением функции активации)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L02_Linear_classifier/img/L02_Linear_classifier-10.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Перцептрон - нейросеть с одним скрытым слоем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1957 году Фрэнк Розенблатт изобрёл вычислительную систему «Марк-1», которая стала первой реализацией перцептрона. Этот алгоритм тоже использует интерпретацию линейного классификатора и функцию потерь, но на выходе выдаёт либо 0, либо 1, без промежуточных значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/Rosenblatt.jpg\"  width=\"300\">\n",
    "\n",
    "[Перцептрон](https://ru.wikipedia.org/wiki/%D0%9F%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1960 году Бернард Уидроу и Тед Хофф разработали однослойную нейросеть ADALINE и её улучшенную версию — трёхслойную MADALINE. Это были первые глубокие (для того времени) архитектуры, но в них ещё не использовался метод обратного распространения ошибки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/percepton.PNG\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Принцип работы перцептрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В основу идеи перцептрона были положены биологические процессы, например светочувствительные клетки сетчатки глаза. Каждый рецептор может находиться в одном из двух состояний — покоя или возбуждения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перцептрон состоит из трёх типов элементов:\n",
    "\n",
    "* Простым S-элементом (сенсорным) является чувствительный элемент, который от воздействия какого-либо из видов энергии (например, света, звука, давления, тепла и т. п.) вырабатывает сигнал. Если входной сигнал превышает некоторый порог θ, на выходе элемента получаем +1, в противном случае — 0.\n",
    "\n",
    "* Простым A-элементом (ассоциативным) называется логический решающий элемент, который даёт выходной сигнал +1, когда алгебраическая сумма его входных сигналов превышает некоторую пороговую величину θ (говорят, что элемент активный), в противном случае выход равен нулю.\n",
    "\n",
    "* Простым R-элементом (реагирующим, то есть действующим) называется элемент, который выдаёт сигнал +1, если сумма его входных сигналов является строго положительной, и сигнал −1, если сумма его входных сигналов является строго отрицательной. Если сумма входных сигналов равна нулю, выход считается либо равным нулю, либо неопределённым."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае **скрытым слоем** называются А-элементы.\n",
    "\n",
    "А **функцией активации** для А-элементов является пороговая функция:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/L05_1-1.png\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/4.png\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для R-элементов же функция активации (signum) выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/3.png\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом поступающие от датчиков сигналы передаются ассоциативным элементам, а затем реагирующим элементам. Перцептроны позволяют создать набор «ассоциаций» между входными стимулами и необходимой реакцией на выходе. В биологическом плане это соответствует преобразованию, например, зрительной информации в физиологический ответ от двигательных нейронов. Согласно современной терминологии, перцептроны могут быть классифицированы как искусственные нейронные сети:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* с одним скрытым слоем\n",
    "* с пороговой передаточной функцией\n",
    "* с прямым распространением сигнала"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы «научить» перцептрон классифицировать образы, был разработан специальный итерационный метод обучения проб и ошибок, напоминающий процесс обучения человека — метод коррекции ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обучение перцептрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам мало знать, как распространяется сигнал в перцептроне и какие функции используются при прямом распространении. Важно ещё уметь **обучить** перцептрон - то есть подстроить веса и пороги таким образом, чтобы наша нейронная сеть могла решать задачу.\n",
    "\n",
    "**Метод коррекции ошибки** — метод обучения перцептрона, предложенный Фрэнком Розенблаттом. Представляет собой такой метод обучения, при котором вес связи не изменяется до тех пор, пока текущая реакция перцептрона остается правильной. При появлении неправильной реакции вес изменяется на единицу, а знак (+/-) определяется противоположным от знака ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Принципиальные ограничения перцептрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые успехи исследований перцептронов и других нейросетей вызвал взрыв активности и энтузиазма. В течение некоторого времени казалось, что ключ к интеллекту найден, и воспроизведение человеческого мозга является лишь вопросом конструирования достаточно большой сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако уже через несколько лет было доказано, что перцептрон не может воспроизвести ряд простых функций, например функцию xor. После этого открытия интерес к нейросетям резко падал и они находились в забвении. По сути, даже опубликовать статью по данной теме было затруднительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможности перцептронов оказались довольно ограниченными.\n",
    "\n",
    "* Спектр решаемых задач: с помощью перцептрона можно решать задачи классификации и апроксимации. С большими ограничениями (например классификация возможна только бинарная)\n",
    "* Выбор непрерывной функции активации не влияет на достижение решения. Единственное, для чего имеет смысл усложнять функцию активации по сравнению с пороговой (которая является самой наипростейшей), — это возможность интерпретации выходов нейронов как вероятностей принадлежности к соответствующему классу, что в свою очередь может повлиять на качество прогноза.\n",
    "* Нет способа (на тот момент) обучать многослойные перцептроны.\n",
    "* Перцептрон основывается на статистическом обучении, то для него доступны те задачи, в которых объекты каждого класса имеют общие фрагменты, но могут быть в разных комбинациях, например, задачи распознавания образов.\n",
    "*  1969 году Марвин Минский и Сеймур Паперт посвятили критике перцептрона целую книгу. Минский описывал специальные задачи такие как «чётность» и «один в блоке», которые показывают ограничения перцептрона в том, что он не может распознавать инвариантные входные данные (изображения) бесконечного порядка. А в частности, при распознавании чётности конечного порядка первый слой перцептрона вынужден становиться полно связным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Типичные задачи, с которыми не может справится перцептрон:\n",
    "\n",
    "1, 2 — преобразования группы переносов\n",
    "\n",
    "3 — из какого количества частей состоит фигура?\n",
    "\n",
    "4 — внутри какого объекта нет другой фигуры?\n",
    "\n",
    "5 — какая фигура внутри объектов повторяется два раза?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/5.png\"  width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Многослойные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По мере развития мощности компьютеров, теоретической базы, появления больших датасетов и метода обратного распространения ошибки, появилась возможность строить более сложные сети - многослойные нейронные сети (многослойные перцептроны) или же в современном понимании просто **нейронные сети**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример **полносвязной (fully connected network)** нейронной сети с двумя скрытыми слоями:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/nn_fully_connected.png\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Neural machine translation](https://arxiv.org/pdf/1409.0473.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Функции потерь (loss functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Положим у нас есть нейронная сеть с некоторыми весами, прежде всего мы должны понять насколько она точна - то есть наши ожидания соответствуют результату работы нейронной сети. Мы подали на вход нейронной сети изображение, сигналы прошли через наши слои и функции активации вперёд **(forward propagation)**, и на выходе мы имеем некоторый ответ. Как его оценить? Насколько он точен?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки соответствия полученного результата ожидаемому используют функции потерь. С помощью функции потери оценивают ошибку нейронной сети. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь в нейронной сети должна удовлетворять двум условиям:\n",
    "\n",
    "* Функция потерь должна быть записана как среднее;\n",
    "* Функция потерь не должна зависеть от каких-либо активационных значений нейронной сети, кроме значений, выдаваемых на выходе.\n",
    "\n",
    "[PyTorch Docs](https://pytorch.org/docs/stable/nn.html#loss-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE) - это средняя квадратическая ошибка. Данная функция потерь очень популярная, поскольку она проста для понимания и реализации, и в целом работает довольно хорошо. Чтобы рассчитать MSE, вы берете разницу между предсказаниями вашей модели и фактическими значениями, вычитаете их, возводя разницу в квадрат и затем усредняете по всему набору данных.\n",
    "Результат всегда положительный, независимо от знака предсказанных и истинных значений, и идеальное значение равно 0,0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MSE=\\frac{1}{n}\\sum_{i=1}^n(Y_i - \\hat{Y_i})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def MSE(y_predicted, y_actual):    \n",
    "    squared_error = (y_predicted-y_actual)**2\n",
    "    sum_squared_error = np.sum(squared_error)\n",
    "    mse = sum_squared_error/y_actual.size\n",
    "    return mse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.MSELoss()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "input = torch.Tensor([0.5, -0.25, 0.75])\n",
    "print(f'input: {input}')\n",
    "target = torch.Tensor([1, 0.25, 0.25])\n",
    "print(f'target: {target}')\n",
    "output = loss(input, target)\n",
    "print(f'output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Преимущество:** MSE отлично подходит для проверки того, что наша обученная модель не имеет выбросов с огромными ошибками, поскольку MSE придает большее значение этим ошибкам из-за квадрата функции.\n",
    "\n",
    "\n",
    "* **Недостаток:** Если наша модель делает одно очень плохое предсказание, то квадратичная часть функции увеличивает ошибку. Тем не менее, во многих практических случаях мы не очень заботимся об этих выбросах и стремимся к более всесторонней модели, которая достаточно хороша для большинства случаев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean Absolute Error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средняя абсолютная ошибка (MAE) лишь немного отличается по определению от MSE, но, что интересно, обеспечивает почти совершенно противоположные свойства. Чтобы рассчитать MAE, вы берете разницу между предсказаниями вашей модели и основополагающей правдой, применяете абсолютное значение к этой разнице, а затем усредняете его по всему набору данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MAE=\\frac{1}{n}\\sum_{i=1}^n|Y_i - \\hat{Y_i}|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def MAE(y_predicted, y_actual):\n",
    "    abs_error = np.abs(y_predicted - y_actual)\n",
    "    sum_abs_error = np.sum(abs_error)\n",
    "    mae = sum_abs_error / y_actual.size\n",
    "    return mae\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.L1Loss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()\n",
    "input = torch.Tensor([0.5, -0.25, 0.75])\n",
    "print(f'input: {input}')\n",
    "target = torch.Tensor([1, 0.25, 0.25])\n",
    "print(f'target: {target}')\n",
    "output = loss(input, target)\n",
    "print(f'output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Преимущество:** Прелесть MAE заключается в том, что её преимущество напрямую покрывает недостаток MSE. Поскольку мы берем абсолютное значение, все ошибки будут взвешены в одной линейной шкале. Таким образом, в отличие от MSE, мы не будем придавать слишком большой вес нашим выбросам, а наша функция потерь обеспечивает общую и даже меру того, насколько хорошо работает наша модель.\n",
    "\n",
    "\n",
    "* **Недостаток:** Если мы действительно заботимся о прогнозируемых отклонениях нашей модели, то MAE не будет столь же эффективным. Большие ошибки, возникающие из-за выбросов, в конечном итоге взвешиваются точно так же, как и более маленькие ошибки. Это может привести к тому, что наша модель в большинстве случаев будет отличной, но время от времени будет делать несколько очень плохих прогнозов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроссэнтропия (перекрёстная энтропия) - одна из самых важных функций, используемых в обучении нейронных сетей.\n",
    "\n",
    "Пусть:\n",
    "* **p** - истинное распределение\n",
    "* **q** - прогнозируемое распределение\n",
    "\n",
    "Перекрёстная энтропия между двумя распределениями вероятностей **p** и **q** измеряет среднее число бит, необходимых для опознания события из набора возможностей, если используемая схема кодирования базируется на заданном распределении вероятностей **q**, вместо «истинного» распределения **p**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H(p,q) = -E_p[\\log q]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где:\n",
    "* Hp - оператор математического ожидания относительно распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако чаще кроссэнтропию определяют с помощью энтропии и расстояния Кульбака-Лейблера:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(p,q) = H(p) +D_{KL}(p||q)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае нейронных сетей, где вероятности представлены дискретными выходами, формула превращается в:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(p,q)=-\\sum_xp(x)\\log q(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/10.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Поскольку чаще всего кроссэнтропию используют после softmax то в готовых реализациях softmax объединяют с кроссэнтроией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/11.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.CrossEntropyLoss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.rand(3, 5)\n",
    "print(f'input: {input}')\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(f'target: {target}')\n",
    "output = loss(input, target)\n",
    "print(f'output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Преимущества:** Важное свойство кроссэнтропии - возможность работать с весами для классов. А значит и возможность применения этой функции потерь при работе с несбалансированным датасетом.\n",
    "* **Недостатки:** Вычислительная сложность выше чем MSE или MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Binary cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае когда количество классов равно двум функция кроссэнтропии определяется как:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H_p(q)=-\\frac{1}{N}\\sum_{i=1}^N y_i\\cdot log(p(y_i))+(1-y_i)\\cdot log(1-p(y_i))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бинарная кроссэнтропия. В отличие от кроссэнтропии она не зависит от каждого компонента вектора (класса), что означает, что на потери, вычисленные для каждого компонента вектора вывода CNN, не влияют значения других компонентов. Вот почему он используется для классификации с несколькими метками, когда понимание элемента, принадлежащего определенному классу, не должно влиять на решение для другого класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        torch.nn.BCELoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "input = torch.rand(3)\n",
    "print(f'input: {input}')\n",
    "target = torch.empty(3, dtype=torch.float).random_(2)\n",
    "print(f'target: {target}')\n",
    "output = loss(input, target)\n",
    "print(f'output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Итоги\n",
    "\n",
    "Кросс-энтропия предпочтительнее для *классификации*, в то время как среднеквадратичная ошибка является одним из лучших вариантов для *регрессии*. Это происходит непосредственно из самой постановки задач &mdash; в классификации вы работаете с очень конкретным набором возможных выходных значений, поэтому MSE плохо определен (поскольку он не обладает такого рода знаниями, поэтому наказывает ошибки несовместимым образом). Чтобы лучше понять явления, полезно проследить и понять отношения между ними.\n",
    "\n",
    "И то, и другое можно рассматривать как оценки максимального правдоподобия, просто с различными предположениями о зависимой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Функции активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый элемент нейронной сети (нейрон) имеет один или несколько входов и один выход. Нейрон представляет собой систему из двух элементов — сумматора и функции активации. \n",
    "\n",
    "Рассмотрим нейрон, у которого взвешенная сумма входов:\n",
    "\n",
    "$$ z=\\sum_{i=1}^nw_i \\cdot x_i+b=WX+b$$\n",
    "\n",
    "где $w_i$ и $x_i$ &mdash;   вес и входное значение $i$-го входа, $W$ и $X$ &mdash; векторы весов и входов, а $b$ &mdash; смещение. $z$ может принимать любые значения в диапазоне $(-\\infty;+\\infty)$, оно  передается в функцию активации $\\sigma()$, которая определяет выходное значение этого нейрона: $$a=\\sigma(WX+b)=\\sigma(z)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/l5_out_1.png\"  width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В математическом смысле функция активации преобразует результат работы нейрона в известный диапазон значений, например $(0;1)$.\n",
    "\n",
    "Историческим примером функции активации является пороговая функция активации, вдохновленная активацией нейронов, использовавшаяся в перцептронах &mdash; первых нейронных сетях.\n",
    "\n",
    "В биологических нейронных сетях функция активации определяется пороговым потенциалом, при достижении которого происходит возбуждение потенциала действия в клетке. В наиболее простой форме эта функция является двоичной — то есть нейрон либо возбуждается, либо нет. \n",
    "\n",
    "Таким же образом ведет себя пороговая функция активации, использовавшаяся в перцептронах &mdash; первых нейронных сетях:\n",
    "\n",
    "$$f(x) =\n",
    "\\begin{cases}\n",
    "0, &\\text{$x<b$} \\\\ \n",
    "1, &\\text{$x\\geq b$}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/4.png\"  width=\"300\">\n",
    "\n",
    "Производная пороговой функции активации:\n",
    "\n",
    "$$f'(x) =\n",
    "\\begin{cases}\n",
    "0, &\\text{$x\\neq b$} \\\\ \n",
    "DNE, &\\text{$x= b$}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Главным недостатком пороговой функции активации является то, что поскольку производная пороговой функции неопределена при $x=b$, а во всех остальных случаях равна 0, не может быть использована для оптимизации параметров нейронной сети методом градиентного спуска, использующимися при обучении современных нейронных сетей. \n",
    "\n",
    "В настоящее время пороговая функция активации не используется, поскольку не удовлетворяет требованиям, которые предъявляются к современным нейронным сетям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Свойства функций активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции активации должны обладать следующими свойствами:\n",
    "\n",
    "* **Нелинейность:**\n",
    "Функция активации необходима для введения нелинейности в нейронные сети. Если функция активации не применяется, выходной сигнал становится простой линейной функцией. Неактивированная нейронная сеть будет действовать как линейная регрессия с ограниченной способностью к обучению:\n",
    "$$\\hat{y}=NN(X,W_1,...,W_n)=X\\cdot W_1\\cdot ...\\cdot W_n=X\\cdot W$$ \n",
    "Только нелинейные функции активации позволяют нейронным сетям решать задачи аппроксимации нелинейных функций:\n",
    "$$\\hat{y}=NN(X,W_1,...,W_n)=\\sigma(...\\sigma(X\\cdot W_1)...\\cdot W_n)\\neq X\\cdot W$$\n",
    "\n",
    "* **Возможность прохождения градиента:** \n",
    "Функции активации должны быть способными пропускать градиент, чтобы было возможно оптимизировать параметры сети градиентными методами, в частности использовать алгоритм обратного распространения ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Типы функций активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим наиболее популярные функции активации и обсудим их преимущества и недостатки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/L05_25-1.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[AI in Pursuit of Happiness, Finding\n",
    "Only Sadness: Multi-Modal Facial\n",
    "Emotion Recognition Challenge  ](https://arxiv.org/pdf/1911.05187.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Логистическая (сигмоидальная)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid (сигмоидальная) для одномерного случая - используется в задачах классификации, в основном после выхода последнего нейрона. Позволяет определить вероятность принадлежности к одному из двух классов (0 или 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x)=\\frac{1}{1+e^{-x}}=\\frac{e^{x}}{e^{x}+1}=\\frac{1}{2}+\\frac{1}{2}tanh(\\frac{x}{2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/logistic_plot.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная логистической функции:\n",
    "\n",
    "$$\\frac{d}{dx}f(x)=\\frac{e^x\\cdot (1+e^x)-e^x \\cdot e^x}{(1+e^x)^2}=\\frac{e^x}{(1+e^x)^2}=f(x)(1-f(x))=f(x)f(-x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если активационная функция не бинарная (не как пороговая), то для нейрона возможны значения “активирован на 50%”, “активирован на 20%” и так далее. Если активированы несколько нейронов, можно найти нейрон с наибольшим значением активационной функции.\n",
    "\n",
    "Так как существуют промежуточные значения на выходе нейрона, **процесс обучения проходит более гладко и быстро**, а вероятность появления нескольких полностью активированных нейронов во время тренировки снижается по сравнению со ступенчатой функцией активации (хотя это зависит от того, что вы обучаете и на каких данных)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.Sigmoid()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.Sigmoid()\n",
    "input = torch.randn(5)*5\n",
    "output = activation(input)\n",
    "print(f'input: {input}\\noutput: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сигмоида выглядит гладкой и подобна пороговой функции.\n",
    "\n",
    "**Достоинства:**\n",
    "\n",
    "Во-первых, сигмоида — нелинейна по своей природе, а комбинация таких функций производит тоже нелинейную функцию. Поэтому мы можем конструировать многослойные сети.\n",
    "\n",
    "Еще одно достоинство такой функции — она гладкая, что делает выходной сигнал аналоговым, в отличие от ступенчатой функции. Для сигмоиды также характерен гладкий градиент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Недостатки:**\n",
    "\n",
    "Насыщение сигмоиды приводит к затуханию градиентов. Крайне нежелательное свойство сигмоиды заключается в том, что при насыщении функции с той или иной стороны (0 или 1), градиент на этих участках становится близок к нулю. Напомним, что в процессе обратного распространения ошибки данный (локальный) градиент умножается на общий градиент. Следовательно, если локальный градиент очень мал, он фактически обнуляет общий градиент. В результате, сигнал почти не будет проходить через нейрон к его весам и рекурсивно к его данным. Кроме того, следует быть очень осторожным при инициализации весов сигмоидных нейронов, чтобы предотвратить насыщение. Например, если исходные веса имеют слишком большие значения, большинство нейронов перейдет в состояние насыщения, в результате чего сеть будет плохо обучаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выход сигмоиды не центрирован относительно нуля. Это свойство является нежелательным, поскольку нейроны в последующих слоях будут получать значения, которые не центрированы относительно нуля, что оказывает влияние на динамику градиентного спуска. Если значения, поступающие в нейрон, всегда положительны (например, $x > 0$ поэлементно в $f = wx + b$), тогда в процессе обратного распространения ошибки все градиенты весов $w$ будут либо положительны, либо отрицательны (в зависимости от градиента всего выражения $f$). Это может привести к нежелательной зигзагообразной динамике обновлений весов. Однако следует отметить, что когда эти градиенты суммируются по пакету, итоговое обновление весов может иметь различные знаки, что отчасти нивелирует описанный недостаток. Таким образом, отсутствие центрирования является неудобством, но имеет менее серьезные последствия, по сравнению с проблемой насыщения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Гиперболический тангенс**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперболический тангенс очень похож на сигмоиду. И действительно, это скорректированная сигмоидная функция."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x)=tanh(x)=\\frac{2}{1+e^{-2x}}-1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/0-447458-798873.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперболический тангенс используется в рекуррентных нейронных сетях, поскольку может принимать отрицательные значения, что позволяет как увеличивать, так и уменьшать скрытое состояние ячейки памяти (подробнее в будущих лекциях).\n",
    "\n",
    "**Достоинства**: Гиперболический тангенс имеет те же характеристики, что и у сигмоиды, рассмотренной ранее. Его природа нелинейна, он хорошо подходит для комбинации слоёв. В отличие от логистической функции (для которой значения функции центрированы около 0.5), диапазон значений функции $(-1, 1)$, таким образом, её значения центрированы относительно 0, что позволяет нивелировать соответствующие недостатки сигмоиды. Стоит отметить, что градиент тангенциальной функции больше, чем у сигмоиды (производная круче). Решение о том, выбрать ли сигмоиду или тангенс, зависит от ваших требований к амплитуде градиента. \n",
    "\n",
    "**Недостатки**: Также как и сигмоиде, гиперболическому тангенсу свойственная проблема исчезновения градиента в области насыщения функции.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.Tanh()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.Tanh()\n",
    "input = torch.randn(5)*5\n",
    "output = activation(input)\n",
    "print(f'input: {input}\\noutput: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **ReLu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последние годы большую популярность приобрела функция активации под названием «выпрямитель» (rectifier, по аналогии с однополупериодным выпрямителем в электротехнике). Нейроны с данной функцией активации называются ReLU (rectified linear unit). ReLU имеет следующую формулу и реализует простой пороговый переход в нуле:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$relu(x)=max(0,x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/l5_out_3.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная ReLu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{d}{dx}relu(x) =\n",
    "\\begin{cases}\n",
    "\\frac{d}{dx}0, &\\text{$x<0$} \\\\ \n",
    "\\frac{d}{dx}x, &\\text{$x\\geq0$}\n",
    "\\end{cases}=\n",
    "\\begin{cases}\n",
    "0, &\\text{$x<0$} \\\\ \n",
    "1, &\\text{$x\\geq0$}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.ReLU()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.ReLU()\n",
    "input = torch.randn(5)\n",
    "output = activation(input)\n",
    "print(f'input: {input}\\noutput: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим положительные и отрицательные стороны ReLU.\n",
    "\n",
    "**Достоинства:**\n",
    "\n",
    "Вычисление сигмоиды и гиперболического тангенса требует выполнения ресурсоемких операций, таких как возведение в степень, в то время как ReLU может быть реализован с помощью простого порогового преобразования матрицы активаций в нуле. Кроме того, ReLU не подвержен насыщению.\n",
    "Применение ReLU существенно повышает скорость сходимости стохастического градиентного спуска (в некоторых случаях до 6 раз) по сравнению с сигмоидой и гиперболическим тангенсом. Считается, что это обусловлено линейным характером и отсутствием насыщения данной функции.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Недостатки:**\n",
    "\n",
    "К сожалению, ReLU не всегда достаточно надежны и в процессе обучения могут выходить из строя («умирать»). Например, большой градиент, проходящий через ReLU, может привести к такому обновлению весов, что данный нейрон никогда больше не активируется. Если это произойдет, то, начиная с данного момента, градиент, проходящий через этот нейрон, всегда будет равен нулю. Соответственно, данный нейрон будет необратимо выведен из строя. Например, при слишком большой скорости обучения (learning rate), может оказаться, что до 40% ReLU «мертвы» (то есть, никогда не активируются). Эта проблема решается посредством выбора надлежащей скорости обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Leaky ReLu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU с «утечкой» (leaky ReLU, LReLU) представляет собой одну из попыток решить описанную выше проблему выхода из строя обычных ReLU. Обычный ReLU на интервале $x < 0$ дает на выходе ноль, в то время как LReLU имеет на этом интервале небольшое отрицательное значение (угловой коэффициент около 0,01). То есть функция для LReLU имеет вид  $f(x) = \\alpha x$ при $x < 0$ и $f(x) = x$ при $x ≥ 0$, где $\\alpha$ – малая константа. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$lrelu(x)=max(0.01x,x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/lrelu_plot.png\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная leaky ReLU:\n",
    "\n",
    "$$\\frac{d}{dx}lrelu(x)=\\frac{d}{dx}max(0.01x,x)=\\begin{cases}\n",
    "\\frac{d}{dx}0.01x, &\\text{$x<0$} \\\\ \n",
    "\\frac{d}{dx}x, &\\text{$x\\geq0$}\n",
    "\\end{cases}=\n",
    "\\begin{cases}\n",
    "0.01, &\\text{$x<0$} \\\\ \n",
    "1, &\\text{$x\\geq0$}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.LeakyReLU\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.LeakyReLU(0.01)\n",
    "input = torch.randn(5)\n",
    "output = activation(input)\n",
    "print(f'input: {input}\\noutput: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Достоинства**: Сохраняет достоинства ReLU, при этом не страдает от проблемы \"умирания\" \n",
    "\n",
    "**Недостатки**: Некоторые исследователи сообщают об успешном применении данной функции активации, но результаты не всегда стабильны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **GELU (Gaussian Error Linear Unit)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гауссова ошибка линейного блока. Функция активации, используемая в самых последних трансформерах: Google BERT и OpenAI GPT-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$GELU(x)=xP(X\\leq x)=x\\Phi(x)=x\\cdot \\frac{1}{2}[1+erf(\\frac{x}{\\sqrt{2}})]$$\n",
    "$$erf(x)=\\frac{2}{\\sqrt{\\pi}}\\int_0^xe^{-t^2}dt$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/unnamed.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.GELU()\n",
    "input = torch.randn(5)*5\n",
    "output = activation(input)\n",
    "print(f'input: {input}\\noutput: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Достоинства**: State-of-the-art функция активации в задачах NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Другие модификации ReLU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parametric ReLU (**PReLU**)\n",
    "Для параметрического ReLU (parametric ReLU, PReLU) угловой коэффициент &alpha; на отрицательном интервале не задается предварительно, а определяется на основе данных. Авторы публикации утверждают, что применение данной функции активации является ключевым фактором, позволившим превзойти уровень человека в задаче распознавания изображений ImageNet. Процесс обратного распространения ошибки и обновления для PReLU достаточно прост и подобен соответствующему процессу для традиционных ReLU.\n",
    "\n",
    "$$prelu(x)=max(\\alpha x,x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Randomized ReLU (**RReLU**)\n",
    "Для рандомизированного ReLU (randomized ReLU, RReLU) угловой коэффициент на отрицательном интервале во время обучения генерируется случайным образом из заданного интервала, а во время тестирования остается постоянным. В рамках Kaggle-соревнования National Data Science Bowl (NDSB) RReLU позволили уменьшить переобучение благодаря свойственному им элементу случайности.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Exponential Linear Unit (**ELU**)\n",
    "Экспоненциальная линейная единица. Эта функция активации устраняет некоторые проблемы с ReLU и сохраняет некоторые положительные моменты. Для этой функции активации выбирается альфа-значение; общее значение составляет от 0,1 до 0,3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ELU(x)=\\begin{cases}\n",
    "x, &\\text{$x>0$} \\\\ \n",
    "\\alpha(e^x-1), &\\text{$x\\leq0$}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация функций активации:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/more_activations_for_god_of_activations.gif\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Activation Functions Explained](https://mlfromscratch.com/activation-functions-explained/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Обучение нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе **обучения** (англ. fit) сеть в определённом порядке просматривает обучающую выборку. Порядок просмотра может быть последовательным и случайным. Некоторые сети, обучающиеся без учителя (например, сети Хопфилда), просматривают выборку только один раз. Другие (например, сети Кохонена), а также сети, обучающиеся с учителем, просматривают выборку множество раз, при этом один полный проход по выборке называется **эпохой обучения** (англ. epoch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении с учителем набор исходных данных делят на две части — собственно обучающую выборку и тестовые данные, принцип разделения может быть произвольным. Обучающие данные подаются сети для обучения, а проверочные используются для расчета ошибки сети (проверочные данные никогда для обучения сети не применяются). Таким образом, если на проверочных данных ошибка уменьшается, то сеть действительно выполняет обобщение. Если ошибка на обучающих данных продолжает уменьшаться, а ошибка на тестовых данных увеличивается, значит, сеть перестала выполнять обобщение и просто «запоминает» обучающие данные. Это явление называется **переобучением сети** или оверфиттингом (англ. overfit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Прямое распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedforward neural network - нейронная сеть с прямым распространением сигнала"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим **обучение с учителем**, при котором обучаемой сети последовательно представляется набор примеров из обучающего множества. Примеры представляют собой пары эталонных входных воздействий и желаемых выходных сигналов. Процесс обучения проходит циклически, на каждой итерации выполняется расчет сигналов при прямом и обратном распространениях, после чего сигналы ошибок используются для формирования локальных градиентов векторов адаптируемых параметров. Вычисленные локальные градиенты используются для последующей корректировки адаптируемых параметров. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используемые режимы обучения – это последовательный режим (online), при котором подстройка параметров происходит после каждого примера, и пакетный (**batch**), при котором подстройка осуществляется на основе кумулятивного локального градиента – суммы локальных градиентов по всем итерациям примеров из обучающего множества. В обоих режимах полный цикл представления множества шаблонов обучения, завершающийся подстройкой параметров, эпохой обучения сети. Для количественной оценки качества работы сети вводится функция потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Веса сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в перцептроне, в нейронной сети используются **веса**. (Иногда используют название синапсы по аналогии с человеческим мозгом). Веса сети - это вещественные числа (чаще от -1 до 1), которых характеризуют влияние входа на выход.\n",
    "\n",
    "**Нейрон** – базовая единица нейронной сети. У каждого нейрона есть определённое количество входов, куда поступают сигналы, которые суммируются с учётом значимости (веса) каждого входа. Далее сигналы поступают на входы других нейронов. Вес каждого такого «узла» может быть как положительным, так и отрицательным. Например, если у нейрона есть два 'входа', то у него есть и два  весовых значения, которые можно регулировать независимо друг от друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Как вычислить результат работы нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/12.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим задачу классификации XOR, то есть на вход подадим 1 и 0, и будем ожидать 1 на выходе. Веса сети определим случайным образом:\n",
    "\n",
    "$I1=1\\quad I2=0$\n",
    "\n",
    "$w_1=0.45\\quad  w_2=0.78\\quad \n",
    "w_3=-0.12\\quad  w_4=0.13$ \n",
    "\n",
    "$w_5=1.5\\quad  w_6=-2.3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "H1 = I1*W1+I2*W3 = 1*0.45+0*-0.12 = 0.45\n",
    "H2 = I1*W2+I2*W4 = 1*0.78+0*0.13 = 0.78\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы значения H1 и H2 не выходили за предельные значения, используется функция активации "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "H1_out = sigmoid(H1) = sigmoid(0.45) = 0.61\n",
    "H2_out = sigmoid(H2) = sigmoid(0.78) = 0.69\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "O1_in = 0.61*1.5+0.69*-2.3=-0.672\n",
    "O1_out = sigmoid(-0.672)=0.33\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ нейронной сети O1_out = 0.33, а мы ожидали на выходе 1. О том, как скорректировать веса нужным образом будет рассказано в разделе о методе обратного распространения ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Смещение (bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/13.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим простой пример. На вход нейрона подаётся вес умноженный на входное значение. После применения функции активации, в зависимости от веса, при всевозможных значениях входа мы можем получить следующие графики:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/bias1.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A Biased Graph Neural Network Sampler](https://arxiv.org/pdf/2103.01089.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но что если мы захотим чтобы при ```x=2``` чтобы сеть выводила ```0```, тогда без веса смещения эту задачу не решить.\n",
    "\n",
    "Просто изменить крутизну сигмоиды на самом деле не получится - вы хотите иметь возможность сдвинуть всю кривую вправо ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Смещение** (англ. bias) - это дополнительный коэффициент прибавляющийся ко сумме входов, наличие смещения позволяет сдвинуть функцию активации влево или вправо, что может иметь решающее значение для успешного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/14.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда, при разных смещениях мы можем получить сдвинутые функции активации, что способствует лучшему обучению нейронной сети:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/bias3.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Метод обратного распространения ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/15.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас есть все компоненты для обучения 2-х слойной модели:\n",
    "- предобработали данные\n",
    "- умножили их на веса\n",
    "- применили функцию активации\n",
    "- снова умножили\n",
    "- нашли значение функции потерь\n",
    "- нашли градиент\n",
    "- обновили веса ....\n",
    "- оценили точность\n",
    "\n",
    "А как будем искать градиент?\n",
    "Во второй лекции мы в ручную считали от нее производную. Так как модель поменялась придется делать это заново\n",
    "\n",
    "Для того что бы упростить этот процесс используется формализм под названием \"Алгоритм обратного распространения ошибки\" или \"Backpropagation\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Backpropagation - метод обратного распространения ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод обратного распространения ошибки (англ. backpropagation)** — метод вычисления градиента, который используется при обновлении весов многослойного перцептрона. Метод является модификацией классического метода **градиентного спуска. (англ. gradient descent)** Впервые метод был описан в 1974 г. А. И. Галушкиным, а также независимо и одновременно Полом Дж. Вербосом. Далее существенно развит в 1986 г. Дэвидом И. Румельхартом, Дж. Е. Хинтоном и Рональдом Дж. Вильямсом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем в развитии машинного обучения начался период застоя, поскольку компьютеры того времени были не пригодны для создания масштабных моделей. В 2006 году Джеффри Хинтон и Руслан Салахутдинов опубликовали статью, в которой показали, как можно эффективно обучать глубокие нейросети. Но даже тогда они пока не приобрели современный вид."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Первых по-настоящему впечатляющих результатов исследователи искусственного интеллекта достигли в 2012 году, когда почти одновременно появились успешные решения задач распознавания речи и классификации изображений. Тогда же была представлена первая свёрточная нейросеть AlexNet, которая достигла высокой на тот момент точности классификации датасета ImageNet. С тех пор подобные архитектуры довольно широко применяются в разных областях.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Идея"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея этого метода состоит в распространении сигналов ошибки от выходов сети к её входам, в направлении, обратном прямому распространению сигналов в обычном режиме работы.\n",
    "\n",
    "Для возможности применения метода обратного распространения ошибки передаточная функция нейронов должна быть дифференцируема."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появление алгоритма обратного распространения ошибки вкупе с возрастающими компьютерными мощностиями позволило обучить многослойную нейронную сеть которую можно было применять для решения практических задач.\n",
    "\n",
    "Архитектура такой сети была разработана в 1989г. Яном Ле Куном. Сеть имела 5 слоев, из них 2 сверточных.\n",
    "\n",
    "Применялась в США для распознавания рукописных букв на почтовых конвертах до начала 2000г."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея этого метода состоит в распространении сигналов ошибки от выходов сети к её входам, в направлении, обратном прямому распространению сигналов в обычном режиме работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Граф вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любую нейронную сеть можно представить в виде графа \"последовательных действий\", где результат вычисляется итеративно, одно действие за другим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм по которому вычисляются веса можно представить в виде графа. Для кода который мы использовали для линейного классификаторо он будет выглядеть так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/16.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И производную от Loss для такого графа можно найти в ручную, что мы и делали.\n",
    "\n",
    "Однако по мере добавления слоев модель может оказаться намного сложнее. Напримет, так выглядит граф для AlexNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/17.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм обратного распространения ошибки позволяет находить градиенты для любого графа вычислений, если функция которую он описывает дифференцируема.\n",
    "\n",
    "В его основе лежит правило взятия производной сложной функции (chain rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_7.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И мы уже пользовались им когда брали производную от CrossEntropyLoss\n",
    "\n",
    "\n",
    "$$ L =  - \\sum_i \\log(\\dfrac {e^{s_{y_i}}} {\\sum_j e^{s_{y_j}}})$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropyLoss(self, x, y):\n",
    "      y = [int(i) for i in y]\n",
    "      n_features = x.shape[1] # number of features\n",
    "      n_samples = x.shape[0] # number of samples\n",
    "\n",
    "      # CalculateCross-entropy loss over a batch \n",
    "      scores = np.dot(x, self.W) # logits\n",
    "\n",
    "      # Softmax\n",
    "      exp_scores = np.exp(scores - np.max(scores, axis=1, keepdims=True))\n",
    "      probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "      # Cross Entropy\n",
    "      correct_logprobs = -np.log(probs[np.arange(n_samples), y])\n",
    "      loss = np.sum(correct_logprobs) / n_samples\n",
    "\n",
    "      # Calculate gradient over a batch \n",
    "      dW = np.zeros(x.shape)\n",
    "      # Calculate gradients respect to probs\n",
    "      probs[np.arange(n_samples), y] -= 1\n",
    "      probs /= n_samples\n",
    "      # Use chain rule\n",
    "      dW = x.T.dot(probs)\n",
    "      \n",
    "      return loss, dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Пошаговый разбор метода обратного распространения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прямой проход (forward):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/18.png\"  width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Обратный(backward):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/19.png\"  width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L = Loss$ - всегда скаляр.\n",
    "\n",
    "$Loss = L(f(q(x,y),z))$\n",
    "\n",
    "А что если вход соединен с несколькими вершинами графа, либо у вершины у вершины больше одного выхода?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/20.png\"  width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае в месте ветвления можно создать дополнительную вершину, которая будет соответствовать операции копирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/21.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда при обратном распространении входящим (upstream) будет вектор значений. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/22.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом можно выделить шаблоны для получения градиентов при базовых операциях:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_8_5.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А общее правило взятия градиентов можно представить следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b0.PNG\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве более сложного примера, рассмотрим следующую функцию:\n",
    "\n",
    "$$f(x,w)=\\frac{1}{1+e^{-(w_0x_0+w_1x_1+w_2)}}$$\n",
    "\n",
    "Представим ее в виде графа вычислений:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/24.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно найти градиенты $\\frac{df}{dw_0}$, $\\frac{df}{dw_1}$, $\\frac{df}{dw_2}$, $\\frac{df}{dx_0}$ и $\\frac{df}{dx_1}$. Пусть $w_0=2,\\;x_0=-1,\\;w_1=-3,\\;x_1=-2,\\;w_2=-3$. Для данного примера сделаем прямой проход через граф вычислений, на выходе получим $f=0.73$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/25.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее в соостветствии с алгоритмом обратного распространения ошибки, расчитаем градиенты, проходясь последовательно по графу вычислений:\n",
    "\n",
    "Для начала посчитаем производную функции $\\frac{df}{df}$, которая будет равна единице. Движемся дальше &mdash; следующая вершина содержит функцию $f(x)=\\frac{1}{x}$, её производная $\\frac{df}{dx}=-\\frac{1}{x^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/26.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующем узле находится функция $f(x)=1+x$. $+1$ &mdash; константа, производная которой равна нулю, производная всего выражения $\\frac{df}{dx}=1$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/27.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третья вершина — это экспонента $f(x)=e^x$, её производная $\\frac{df}{dx}=e^x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/28.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Четвертая вершина — это умножение на константу $f(x)=ax$, её производная $\\frac{df}{dx}=a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/29.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, на каждом шаге мы умножаем локальный градиент на восходящий, чтобы выполнялось цепное правило дифференцирования.\n",
    "\n",
    "Мы подошли к узлу сложения с двумя входящими в него рёбрами, для которого известен восходящий градиент, равный $0.2$. В вершине сложения локальный градиент по отношению к каждому из входов будет равен $1$. Поэтому мы просто берём единицу (локальный градиент) и умножаем её на восходящий градиент для обоих рёбер. Аналогично поступаем и со следующим узлом сложения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/30.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее перед ними находится вершина умножения. В этом случае локальный градиент по отношению к каждому из входов просто является значением другого входа, умноженным на восходящий градиент. Аналогично поступаем со второй вершиной напротив $w_1$ и $x_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/31.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном примере мы разбивали граф вычислений на множество простейших вершин. Но на самом деле это не всегда необходимо: вершины можно группировать друг с другом, если они образуют дифференцируемую функцию. Это может существенно сократить и упростить вычисления.\n",
    "\n",
    "В частности, можно заметить, что в данном примере выражение $w_0x_0+w_1x_1+w_2$ подается на вход в функцию сигмоиды, мы можем взять ту часть графа, которая соответствует сигмоиде, и объединить несколько узлов в один. У сигмоиды есть очень полезное свойство: её производная легко выражается через саму функцию:\n",
    "\n",
    "$$\\frac{d\\sigma{(x)}}{dx}=(1-\\sigma{(x)})\\sigma{(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/32.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде, без использования библиотек подсчёт градиентов можно записать как:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/33.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объектно-ориентированный код:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/34.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/\n",
    "L05_9_2.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/35.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img_licence/l5_1.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Обратное распространение для векторов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_10.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_10_1.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_10_2.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Анимация работы метода обратного распространения ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/backprop_animation.gif\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Backprop in PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим пример реализации шага обратного прохода на примере вычисления квадрата ошибки для линейной регрессии (для простоты не будем рассматривать смещение):\n",
    "\n",
    "$$y=w\\cdot x, \\quad при \\;x=[1,2,3,4],\\;y=[2,4,6,8],\\;w=1$$\n",
    "\n",
    "В данном примере видно, что предсказанный моделью $\\hat{y}=[1,2,3,4]$ не совпадает с истинными значениями $y$, и соотвтественно квадратичная ошибка для такого примера будет $$MSE=\\frac{1}{4}\\sum_{i=1}^4E_i^2=\\frac{1}{4}\\sum_{i=1}^4(\\hat{y}_i-y_i)^2=\\frac{1+4+9+16}{4}=7.5$$\n",
    "\n",
    "Градиент весов $w$ вычисляется следующим образом в соответсвии с chain rule:\n",
    "\n",
    "$$\\frac{d MSE}{d w} = \\frac{\\partial MSE}{\\partial E}\\cdot \\frac{\\partial E}{\\partial \\hat{y}}\\cdot \\frac{\\partial \\hat{y}}{\\partial w}$$\n",
    "\n",
    "Рассчитаем его с использованием PyTorch:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "# This is the parameter we want to optimize -> requires_grad=True\n",
    "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# forward pass to compute MSE\n",
    "Y_hat = W*X\n",
    "E = Y_hat-Y\n",
    "SE = E**2\n",
    "MSE = SE.mean()\n",
    "print(f\"MSE = {MSE}\")\n",
    "\n",
    "# backward pass to compute gradient dMSE/dw\n",
    "MSE.backward()\n",
    "print (f\"W.grad = {W.grad}\")\n",
    "print (f\"E.grad = {E.grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном примере мы произвели следующие рассчеты:\n",
    "\n",
    "$\\frac{\\partial MSE}{\\partial E}=\\frac{\\sum\\partial E^2}{\\partial E}=\\frac{1}{4}\\cdot2\\cdot E=\\frac{1}{2}*[-1, -2, -3, -4]=[-0.5, -1, -1.5, -2]\\quad *-поэлементное\\;умножение$\n",
    "\n",
    "$\\frac{\\partial E}{\\partial \\hat{y}}=\\frac{\\partial (\\hat{y}-y)}{\\partial \\hat{y}}=1$\n",
    "\n",
    "$\\frac{\\partial \\hat{y}}{\\partial w}=\\frac{\\partial wx}{\\partial w}=x=[1, 2, 3, 4]$\n",
    "\n",
    "$\\frac{d MSE}{d w} = \\frac{\\partial MSE}{\\partial E}\\cdot \\frac{\\partial E}{\\partial \\hat{y}}\\cdot \\frac{\\partial \\hat{y}}{\\partial w}=\\sum[-0.5, -1, -1.5, -2]*[1, 2, 3, 4]=-0.5-2-4.5-8=-15$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MSE.backward()` автоматически вычисляет градиент $\\frac{dMSE}{dw}$ при указании `requires_grad=True`. \n",
    "Результаты вычислений будут храниться в `W.grad`. Для всех промежуточных переменных градиенты не сохраняются, поэтому попытка обратиться, например, к `E.grad` выдает `None`. \n",
    "\n",
    "Также после однократного обратного прохода, в целях экономии памяти, граф, используемый для вычисления градиента будет удаляться и следующий запуск `MSE.backward()` будет выдавать ошибку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE.backward() # Error on second backward call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сохранить вычислительный граф, для аргумента `retain_graph` функции `bacward()` нужно указать значение `True`. Также может быть полезным сохранять значения градиентов для промежуточных переменных, это делается с помощью функции `tensor.retain_grad()`. В таком случае, значения градиентов, полученные на следующих итерациях обратного распространения ошибки, будут складываться с текущими значениями градиентов.\n",
    "\n",
    "Градиенты переменных, для которых был указан `requires_grad=True` сохраняются автоматически, чтобы избежать их накопления при многократном итерировании алгоритма обратного распространения, нужно обнулять градиент на каждом шаге с помошью функции `tensor.grad.zero_()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "# This is the parameter we want to optimize -> requires_grad=True\n",
    "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# forward pass to compute MSE\n",
    "Y_hat = W * X\n",
    "E = Y_hat - Y\n",
    "E.retain_grad() # Save grads for intermediate tensor E in memory\n",
    "SE = E**2\n",
    "MSE = SE.sum().div(4)\n",
    "\n",
    "print(\"========== Backprop 1 ==============\")\n",
    "MSE.backward(retain_graph=True)\n",
    "print (f\"dMSE/dE = {E.grad}\")\n",
    "print (f\"dMSE/dW = {W.grad}\")\n",
    "\n",
    "print(\"========== Backprop 2 ==============\")\n",
    "MSE.backward(retain_graph=True)\n",
    "# Gradients are accumulated\n",
    "print (f\"dMSE/dE = {E.grad}\")\n",
    "print (f\"dMSE/dW = {W.grad}\")\n",
    "\n",
    "print(\"========== Backprop 3 ==============\")\n",
    "W.grad.zero_() # Nullify gradients for W for the next iteration\n",
    "MSE.backward(retain_graph=True)\n",
    "# Gradients for W are not accumulated, but not for E\n",
    "print (f\"dMSE/dE = {E.grad}\")\n",
    "print (f\"dMSE/dW = {W.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы умеем вычислять градиент $\\frac{\\partial MSE}{\\partial w}$ для нашего примера. Теперь давайте с его помощью оптимизируем веса, используя алгоритм обратного распростронения ошибки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Define model output\n",
    "def forward(X):\n",
    "    return W*X\n",
    "\n",
    "# Compute MSE loss\n",
    "def loss(Y_hat, Y):\n",
    "    return ((Y_hat-Y)**2).mean()\n",
    "\n",
    "print(f'Prediction before training: f(X) = {forward(X)}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.005\n",
    "n_iters = 101\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # Propagate forward\n",
    "    Y_hat = forward(X)\n",
    "\n",
    "    # Compute loss\n",
    "    MSE = loss(Y_hat, Y)\n",
    "\n",
    "    # Propagate backward, compute gradients\n",
    "    MSE.backward()\n",
    "\n",
    "    # Update weights\n",
    "    with torch.no_grad(): # We don't want this step to be the part of the computational graph\n",
    "        W -= learning_rate*W.grad \n",
    "    \n",
    "    # Nullify gradients after updating to avoid their accumulation\n",
    "    W.grad.zero_()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch}: w = {W.item():.3f}, loss = {MSE.item():.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(X) = {forward(X)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что наш подход позволяет оптимизировать вес $w$ регрессии из примера и таким образом добиться почти идеального предсказания нашей модели, однако в данном подходе дополнительно можно автоматизировать вычисление функции потерь и обновление параметров с учетом градиента, используя готовые функции потерь из `torch.nn` и оптимизаторы из `torch.optim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Define model output\n",
    "def forward(X):\n",
    "    return W*X\n",
    "\n",
    "print(f'Prediction before training: f(X) = {forward(X)}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.005\n",
    "n_iters = 101\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([W], lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # Propagate forward\n",
    "    Y_hat = forward(X)\n",
    "\n",
    "    # Compute loss\n",
    "    MSE = loss(Y, Y_hat)\n",
    "\n",
    "    # Propagate backward, compute gradients\n",
    "    MSE.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Nullify the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch}: W = {W.item():.3f} loss = {MSE.item():.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(X) = {forward(X)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Преимущества и недостатки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на многочисленные успешные применения метода обратного распространения, он не является универсальным решением. Больше всего неприятностей приносит неопределённо долгий процесс обучения. В сложных задачах для обучения сети могут потребоваться дни или даже недели, она может и вообще не обучиться. Причиной может быть одна из описанных ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Паралич сети\n",
    "\n",
    "    В процессе обучения сети значения весов могут в результате коррекции стать очень большими величинами. Это может привести к тому, что все или большинство нейронов будут функционировать при очень больших значениях, в области, где производная функции очень мала. Так как посылаемая обратно в процессе обучения ошибка пропорциональна этой производной, то процесс обучения может практически замереть. \n",
    "    \n",
    "    В теоретическом отношении эта проблема плохо изучена. Обычно этого избегают уменьшением размера шага, но это увеличивает время обучения. Различные эвристики использовались для предохранения от паралича или для восстановления после него, но пока что они могут рассматриваться лишь как экспериментальные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Локальные минимумы\n",
    "\n",
    "    Метод градиентного спуска может застрять в локальном минимуме, так и не попав в глобальный минимум.\n",
    "\n",
    "    Обратное распространение использует разновидность градиентного спуска, то есть осуществляет спуск вниз по поверхности ошибки, непрерывно подстраивая веса в направлении к минимуму. \n",
    "    \n",
    "    Поверхность ошибки сложной сети сильно изрезана и состоит из холмов, долин, складок и оврагов в пространстве высокой размерности. Сеть может попасть в локальный минимум (неглубокую долину), когда рядом имеется гораздо более глубокий минимум. В точке локального минимума все направления ведут вверх, и сеть не способна из него выбраться. Основную трудность при обучении нейронных сетей составляют как раз методы выхода из локальных минимумов: каждый раз выходя из локального минимума снова ищется следующий локальный минимум тем же методом обратного распространения ошибки до тех пор, пока найти из него выход уже не удаётся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Размер шага\n",
    "\n",
    "    Если размер шага фиксирован и очень мал, то сходимость слишком медленная, если же он фиксирован и слишком велик, то может возникнуть паралич или постоянная неустойчивость. Эффективно увеличивать шаг до тех пор, пока не прекратится улучшение оценки в данном направлении антиградиента и уменьшать, если такого улучшения не происходит. П. Д. Вассерман описал адаптивный алгоритм выбора шага, автоматически корректирующий размер шага в процессе обучения. В книге А. Н. Горбаня предложена разветвлённая технология оптимизации обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Переобучение\n",
    "\n",
    "    Следует также отметить возможность переобучения сети (overfitting), что является скорее результатом ошибочного проектирования её топологии и/или неправильным выбором критерия остановки обучения. При переобучении теряется свойство сети обобщать информацию. Весь набор образов, предоставленных к обучению, будет выучен сетью, но любые другие образы, даже очень похожие, могут быть распознаны неверно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Пример простой сети на датасете mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PyTorch для создания нейронных сетей требуется отнаследоваться от класса nn.Module и переопределить метод forward, в который подаются входные данные, и ожидаются выходные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В класс мы добавляем две переменные, два слоя Linear. Linear -это слой, позволяющий, умножить веса на входной вектор и добавить смещение. Первый параметр - размер входного вектора, второй - размер выходного.\n",
    "\n",
    "В методе forward мы указываем последовательность применения операций для получения результата. Сначала изменим представление входного вектора, чтобы от изменения batch_size у нас ничего не сломалось.\n",
    "\n",
    "Далее идёт первый слой, после него функция активации relu и второй слой, возвращающий вектор длиной 10, означающий принадлежность к одному из классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x): # Called inside __call__ method\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наследование от nn.Module позволяет объединять блоки:\n",
    "\n",
    "[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "trainset = MNIST(root='./MNIST', train=True, download=True, transform=transform)\n",
    "testset = MNIST(root='./MNIST', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 64\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим нашу лосс-функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим оптимайзер для найшей сети. Оптимайзер, в библиотеках для нейронных сетей -- это сущность, осуществляющая градиентный спуск. Подробнее об оптимайзере будет рассказано в дальнейших лекциях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим сеть десять эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "epochs = 10\n",
    "loss_hist = []\n",
    "for ep in range(epochs):\n",
    "    hist_loss = 0\n",
    "    for _, data in enumerate(trainloader, 0): # get bacth\n",
    "        # parse batch\n",
    "        images, labels = data\n",
    "        # sets the gradients of all optimized tensors to zero.\n",
    "        optimizer.zero_grad() \n",
    "        # get outputs\n",
    "        outputs = net(images) \n",
    "        # calculate loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        # calculate gradients\n",
    "        loss.backward() \n",
    "        # performs a single optimization step (parameter update).\n",
    "        optimizer.step()\n",
    "        hist_loss += loss.item()\n",
    "    loss_hist.append(hist_loss /len(trainloader))\n",
    "    print(f\"Epoch={ep} loss={loss_hist[ep]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(epochs), loss_hist)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посчитаем `accuracy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calaculate_accuracy(model, dataloader):\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = model.forward(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = calaculate_accuracy(net, trainloader)\n",
    "print(f\"Accuracy train= {acc_train}\")\n",
    "acc_test = calaculate_accuracy(net, testloader)\n",
    "print(f\"Accuracy test= {acc_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, classes = next(iter(testloader))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net.forward(images)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.reshape(images, (64, 28, 28))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[:10]\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "outputs = outputs[:10]\n",
    "outputs.shape\n",
    "digits = np.argmax(outputs.detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for digit, image in zip(digits, images):\n",
    "    print(digit)\n",
    "    pixels = image.reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки:\n",
    "\n",
    "\n",
    "[StatSoft. Радиальная базисная функция](http://statsoft.ru/home/textbook/modules/stneunet.html#radial)\n",
    "\n",
    "[Важность функции потери в машинном обучении](https://www.machinelearningmastery.ru/importance-of-loss-function-in-machine-learning-eddaaec69519/)\n",
    "\n",
    "[Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss and all those confusing names](https://gombru.github.io/2018/05/23/cross_entropy_loss/)\n",
    "\n",
    "[Функции активации нейросети: сигмоида, линейная, ступенчатая, ReLu, tahn](https://neurohive.io/ru/osnovy-data-science/activation-functions/)\n",
    "\n",
    "[Объясненные современные функции активации: GELU, SELU, ELU, ReLU и другие](https://www.machinelearningmastery.ru/state-of-the-art-activation-functions-explained-gelu-selu-elu-relu-and-more-a4247171ca4e/)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 1
}
