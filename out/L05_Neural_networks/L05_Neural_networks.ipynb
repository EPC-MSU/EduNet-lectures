{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ограничения Линейного классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. ХОR — проблема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У линейного классификатора есть существенные ограничения применения. Рассмотрим задачу XOR. На вход подаётся упорядоченный набор из двух чисел согласно таблице истинности xor. Задача линейного классификатора сопоставить этим числам их класс согласно таблице. Графически два входных числа можно изобразить на плоскости как координаты и цветом обозначить их истинный класс. Задача классификатора - построить линию, отделяющую красные точки (класс 0) от зелёных точек (класс 1). Однако видно что одной линией это сделать геометрически невозможно.\n",
    "\n",
    "То есть линейный классификатор уже не может справится с этой задачей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/xor.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Проблемы классификации более сложных объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда компьютер смотрит на изображение, то не видит целостное представление кошки или любого другого объекта. Он видит лишь гигантскую сетку чисел. Например, если размер изображения 800 на 600 и каждый пиксель представлен тремя числами для красного, зелёного и синего каналов, то получится сетка из 800х600х3 = 1,440,000 чисел. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, если мы снимем кошку с другого ракурса или при ином освещении, то вся сетка чисел будет выглядеть совершенно иначе. Помимо этого, животные могут принимать множество различных поз, или же на фотографии может оказаться только часть кошки, например, хвост. Алгоритмы распознавания должны быть устойчивы к таким изменениям. Эта проблема получила название «семантический разрыв» — непонимание информации, которая заключена в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот лишь малая часть параметров, от которых зависит точность распознавания линейного классификатора.\n",
    "\n",
    "Обратите внимание, что на всех изображениях, в том или ином виде присутствуют кошки. При решении задачи классификации, например \"кошка/собака\", все изображения должны быть определены как \"кошка\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/L05_2.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо этих сложностей существует ещё проблема внутриклассовых вариаций, когда одно понятие охватывает множество визуальных проявлений. Например, кошки могут быть разных пород, возрастов и размеров. И методы распознавания должны обрабатывать все возможные варианты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_2.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Переход от ЛК к прецептрону"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ядром этой операции является скалярное произведение. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L04_Feature_Engineering/img/L04_skalyar.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_1.png\"  width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И она соответствует одиному слойю искусственной искусственной нейроннной сети (за исключением функции активации)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L02_Linear_classifier/img/L02_Linear_classifier-10.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Перцептрон - нейросеть с одним скрытым слоем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1957 году Фрэнк Розенблатт изобрёл вычислительную систему «Марк-1», которая стала первой реализацией перцептрона. Этот алгоритм тоже использует интерпретацию линейного классификатора и функцию потерь, но на выходе выдаёт либо 0, либо 1, без промежуточных значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/Rosenblatt.jpg\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1960 году Бернард Уидроу и Тед Хофф разработали однослойную нейросеть ADALINE и её улучшенную версию — трёхслойную MADALINE. Это были первые глубокие (для того времени) архитектуры, но в них ещё не использовался метод обратного распространения ошибки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/percepton.PNG\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Принцип работы перцептрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В основу идеи перцептрона были положены биологические процессы, например светочувствительные клетки сетчатки глаза. Каждый рецептор может находиться в одном из двух состояний — покоя или возбуждения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перцептрон состоит из трёх типов элементов:\n",
    "\n",
    "* Простым S-элементом (сенсорным) является чувствительный элемент, который от воздействия какого-либо из видов энергии (например, света, звука, давления, тепла и т. п.) вырабатывает сигнал. Если входной сигнал превышает некоторый порог θ, на выходе элемента получаем +1, в противном случае — 0.\n",
    "\n",
    "* Простым A-элементом (ассоциативным) называется логический решающий элемент, который даёт выходной сигнал +1, когда алгебраическая сумма его входных сигналов превышает некоторую пороговую величину θ (говорят, что элемент активный), в противном случае выход равен нулю.\n",
    "\n",
    "* Простым R-элементом (реагирующим, то есть действующим) называется элемент, который выдаёт сигнал +1, если сумма его входных сигналов является строго положительной, и сигнал −1, если сумма его входных сигналов является строго отрицательной. Если сумма входных сигналов равна нулю, выход считается либо равным нулю, либо неопределённым."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае **скрытым слоем** называются А-элементы.\n",
    "\n",
    "А **функцией активации** для А-элементов является пороговая функция:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/L05_1-1.png\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/thresh.png\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для R-элементов же функция активации (signum) выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/signum.png\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом поступающие от датчиков сигналы передаются ассоциативным элементам, а затем реагирующим элементам. Перцептроны позволяют создать набор «ассоциаций» между входными стимулами и необходимой реакцией на выходе. В биологическом плане это соответствует преобразованию, например, зрительной информации в физиологический ответ от двигательных нейронов. Согласно современной терминологии, перцептроны могут быть классифицированы как искусственные нейронные сети:\n",
    "\n",
    "* с одним скрытым слоем\n",
    "* с пороговой передаточной функцией\n",
    "* с прямым распространением сигнала\n",
    "\n",
    "Чтобы «научить» перцептрон классифицировать образы, был разработан специальный итерационный метод обучения проб и ошибок, напоминающий процесс обучения человека — метод коррекции ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Обучение перцептрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам мало знать, как распространяется сигнал в перцептроне и какие функции используются при прямом распространении. Важно ещё уметь **обучить** перцептрон - то есть подстроить веса и пороги таким образом, чтобы наша нейронная сеть могла решать задачу.\n",
    "\n",
    "**Метод коррекции ошибки** — метод обучения перцептрона, предложенный Фрэнком Розенблаттом. Представляет собой такой метод обучения, при котором вес связи не изменяется до тех пор, пока текущая реакция перцептрона остается правильной. При появлении неправильной реакции вес изменяется на единицу, а знак (+/-) определяется противоположным от знака ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Принципиальные ограничения перцептрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые успехи исследований перцептронов и других нейросетей вызвал взрыв активности и энтузиазма. В течение некоторого времени казалось, что ключ к интеллекту найден, и воспроизведение человеческого мозга является лишь вопросом конструирования достаточно большой сети.\n",
    "\n",
    "Однако уже через несколько лет было доказано, что перцептрон не может воспроизвести ряд простых функций, например функцию xor. После этого открытия интерес к нейросетям резко падал и они ввнаходились в забвении. По сути, даже опубликовать статью по данной теме было затруднительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможности перцептронов оказались довольно ограниченными.\n",
    "\n",
    "* Спектр решаемых задач: с помощью перцептрона можно решать задачи классификации и апроксимации. С большими ограничениями (например классификация возможна только бинарная)\n",
    "* Выбор непрерывной функции активации не влияет на достижение решения. Единственное, для чего имеет смысл усложнять функцию активации по сравнению с пороговой (которая является самой наипростейшей), — это возможность интерпретации выходов нейронов как вероятностей принадлежности к соответствующему классу, что в свою очередь может повлиять на качество прогноза.\n",
    "* Нет способа (на тот момент) обучать многослойные перцептроны.\n",
    "* Перцептрон основывается на статистическом обучении, то для него доступны те задачи, в которых объекты каждого класса имеют общие фрагменты, но могут быть в разных комбинациях, например, задачи распознавания образов.\n",
    "*  1969 году Марвин Минский и Сеймур Паперт посвятили критике перцептрона целую книгу. Минский описывал специальные задачи такие как «чётность» и «один в блоке», которые показывают ограничения перцептрона в том, что он не может распознавать инвариантные входные данные (изображения) бесконечного порядка. А в частности, при распознавании чётности конечного порядка первый слой перцептрона вынужден становиться полно связным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Типичные задачи, с которыми не может справится перцептрон:\n",
    "\n",
    "1, 2 — преобразования группы переносов\n",
    "\n",
    "3 — из какого количества частей состоит фигура?\n",
    "\n",
    "4 — внутри какого объекта нет другой фигуры?\n",
    "\n",
    "5 — какая фигура внутри объектов повторяется два раза?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/fail_tasks.png\"  width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Многослойные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По мере развития мощности компьютеров, теоретической базы, появления больших датасетов и метода обратного распространения ошибки, появилась возможность строить более сложные сети - многослойные нейронные сети (многослойные перцептроны) или же в современном понимании просто **нейронные сети**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример **полносвязной (fully connected network)** нейронной сети с двумя скрытыми слоями:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/nn_fully_connected.png\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Типы нейросетей и их классификация:**\n",
    "\n",
    "\n",
    "* Классификация по типу входных данных: аналоговые (на входе действительные числа), двоичные (на входе двоичные числа) и образные (на входе знаки, иероглифы, символы) нейронные сети.\n",
    "\n",
    "\n",
    "* Классификация по характеру обучения: обучение с учителем (выходное пространство решений нейронной сети известно), обучение без учителя (выходное пространство решений формируется только на основе входных воздействий; такие сети называют самоорганизующимися); обучение с подкреплением (используется система назначения штрафов и поощрений, получаемых в результате взаимодействия ИНС со средой).\n",
    "\n",
    "\n",
    "* Классификация по характеру настройки синапсов: сети с фиксированными связями (весовые коэффициенты нейронной сети выбираются сразу, исходя из условий задачи), сети с динамическими связями (у этих сетей в процессе обучения происходит настройка синаптических связей).\n",
    "\n",
    "\n",
    "* Классификация по времени передачи сигнала: синхронные сети (время передачи для каждой синаптической связи равно либо нулю, либо фиксированной постоянной), асинхронные сети (время передачи для каждой связи между элементами свое, но тоже постоянное).\n",
    "\n",
    "\n",
    "* Классификация по характеру связей: сети прямого распространения (все связи направлены строго от входных нейронов к выходным), рекуррентные сети (сигнал с выходных нейронов или нейронов скрытого слоя частично передается обратно на входы нейронов входного слоя), рекуррентная сеть Хопфилда (фильтрует входные данные, возвращаясь к устойчивому состоянию и, таким образом, позволяет решать задачи сжатия данных и построения ассоциативной памяти), двунаправленные сети (между слоями существуют связи как в направлении от входного слоя к выходному, так и в обратном)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Функции потерь (loss functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Положим у нас есть нейронная сеть с некоторыми весами, прежде всего мы должны понять насколько она точна - то есть наши ожидания соответствуют результату работы нейронной сети. Мы подали на вход нейронной сети изображение, сигналы прошли через наши слои и функции активации вперёд **(propagation, forward)**, и на выходе мы имеем некоторый ответ. Как его оценить? Насколько он точен?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки соответствия полученного результата ожидаемому используют функции потерь. С помощью функции потери оценивают ошибку нейронной сети. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь в нейронной сети должна удовлетворять двум условиям:\n",
    "\n",
    "* Функция потерь должна быть записана как среднее;\n",
    "* Функция потерь не должна зависеть от каких-либо активационных значений нейронной сети, кроме значений, выдаваемых на выходе.\n",
    "\n",
    "PyTorch Docs:\n",
    "https://pytorch.org/docs/stable/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE) - это средняя квадратическая ошибка. Данная функция потерь очень популярная, поскольку она проста для понимания и реализации, и в целом работает довольно хорошо. Чтобы рассчитать MSE, вы берете разницу между предсказаниями вашей модели и фактическими значениями, вычитаете их, возводя разницу в квадрат и затем усредняете по всему набору данных.\n",
    "Результат всегда положительный, независимо от знака предсказанных и основанных значений истинности, и идеальное значение равно 0,0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/mse.PNG\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def MSE(y_predicted, y_actual):    squared_error = (y_predicted - y_actual) ** 2\n",
    "    sum_squared_error = np.sum(squared_error)\n",
    "    mse = sum_squared_error / y_actual.size\n",
    "    return mse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.MSELoss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Преимущество:** MSE отлично подходит для проверки того, что наша обученная модель не имеет выбросов с огромными ошибками, поскольку MSE придает большее значение этим ошибкам из-за квадрата функции.\n",
    "\n",
    "\n",
    "* **Недостаток:** Если наша модель делает одно очень плохое предсказание, то квадратичная часть функции увеличивает ошибку. Тем не менее, во многих практических случаях мы не очень заботимся об этих выбросах и стремимся к более всесторонней модели, которая достаточно хороша для большинства случаев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Mean Absolute Error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средняя абсолютная ошибка (MAE) лишь немного отличается по определению от MSE, но, что интересно, обеспечивает почти совершенно противоположные свойства. Чтобы рассчитать MAE, вы берете разницу между предсказаниями вашей модели и основополагающей правдой, применяете абсолютное значение к этой разнице, а затем усредняете его по всему набору данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/mae.png\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def MAE(y_predicted, y_actual):\n",
    "    abs_error = np.abs(y_predicted - y_actual)\n",
    "    sum_abs_error = np.sum(abs_error)\n",
    "    mae = sum_abs_error / y_actual.size\n",
    "    return mae\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.L1Loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Преимущество:** Прелесть MAE заключается в том, что её преимущество напрямую покрывает недостаток MSE. Поскольку мы берем абсолютное значение, все ошибки будут взвешены в одной линейной шкале. Таким образом, в отличие от MSE, мы не будем придавать слишком большой вес нашим выбросам, а наша функция потерь обеспечивает общую и даже меру того, насколько хорошо работает наша модель.\n",
    "\n",
    "\n",
    "* **Недостаток:** Если мы действительно заботимся о прогнозируемых отклонениях нашей модели, то MAE не будет столь же эффективным. Большие ошибки, возникающие из-за выбросов, в конечном итоге взвешиваются точно так же, как и более маленькие ошибки. Это может привести к тому, что наша модель в большинстве случаев будет отличной, но время от времени будет делать несколько очень плохих прогнозов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроссэнтропия (перекрёстная энтропия) - одна из самых важных функий, используемых в обучении нейронных сетей.\n",
    "\n",
    "Пусть:\n",
    "* **p** - истинное распределение\n",
    "* **q** - прогнозируемое распределение\n",
    "\n",
    "Перекрёстная энтропия между двумя распределениями вероятностей **p** и **q** измеряет среднее число бит, необходимых для опознания события из набора возможностей, если используемая схема кодирования базируется на заданном распределении вероятностей **q**, вместо «истинного» распределения **p**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/cross_entropy.PNG\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где:\n",
    "* Hp - оператор математического ожидания относительно распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако чаще кроссэнтропию определяют с помощью энтропии и расстояния Кульбака-Лейблера:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/cross_entropy2.PNG\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае нейронных сетей, где вероятности представлены дискретными выходами, формула превращается в:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/cross_entropy3.PNG\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/cross_entropy4.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Поскольку чаще всего кроссэнтропию используют после softmax то чаще в готовых реализациях softmax объединяют с кроссэнтроией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/soft_cross_entropy.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.CrossEntropyLoss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преимущества:** Важное свойство кроссэнтропии - возможность работать с весами для классов. А значит и возможность применения этой функции потерь при работе с несбалансированным датасетом.\n",
    "**Недостатки:** Вычислительная сложность выше чем MSE или MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4. Binary cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае когда количество классов равно двум функция кроссэнтропии определяется как:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/bce.png\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бинарная кроссэнтропия. В отличие от кроссэнтропии она не зависит от каждого компонента вектора (класса), что означает, что на потери, вычисленные для каждого компонента вектора вывода CNN, не влияют значения других компонентов. Вот почему он используется для классификации с несколькими метками, когда понимание элемента, принадлежащего определенному классу, не должно влиять на решение для другого класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        torch.nn.BCELoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4. Итоги\n",
    "\n",
    "Кросс-энтропия предпочтительнее для *классификации*, в то время как среднеквадратичная ошибка является одним из лучших вариантов для *регрессии* . Это происходит непосредственно из самой постановки задач - в классификации вы работаете с очень конкретным набором возможных выходных значений, поэтому MSE плохо определен (поскольку он не обладает такого рода знаниями, поэтому наказывает ошибки несовместимым образом). Чтобы лучше понять явления, полезно проследить и понять отношения между ними.\n",
    "\n",
    "И то, и другое можно рассматривать как оценки максимального правдоподобия, просто с различными предположениями о зависимой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Функции активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим результат работы нейрона:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/neuron_out.PNG\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция активации определяет выходное значение нейрона в зависимости от результата взвешенной суммы входов и порогового значения.\n",
    "\n",
    "Значение Y может быть любым в диапазоне от -бесконечности до +бесконечности. В действительности нейрон не знает границу, после которой следует активация. Для ответа на вопрос: должен ли нейрон быть активирован, необходимо задать функцию активации так как можем провести аналогию с биологией. Именно таким образом работает мозг, а мозг — хорошее свидетельство работы сложной системы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этой цели было решено добавлять активационную функцию. Она проверяет произведенное нейроном значение Y на предмет того, должны ли внешние связи рассматривать этот нейрон как активированный, или его можно игнорировать. В математическом смысле она преоразует результат работы нейрона в известный диапазон значений, в котором можно указать область, где нейрон считать активированным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Виды функций активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы рассматривали пороговую функцию и sign - это функция активации. Однако наиболее широкое применение обрели другие функции активации. Однако только нелинейные функции активации позволяют таким сетям решать нетривиальные задачи с использованием малого числа узлов. Что будет если функции активации в нейронной сети будут линейными?\n",
    "\n",
    "Рассмотрим наиболее популярные функции активации и обсудим их преимущества и недостатки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/L05_25-1.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Логистическая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid (сигмоидальная) для одномерного случая - используется в задачах классификации, в основном после выхода последнего нейрона. Позволяет определить вероятность принадлежности к одному из двух классов (0 или 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.nn.Sigmoid\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/logistic_plot.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/logistic.PNG\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/dev_logistic.PNG\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если активационная функция не бинарная (не как sign или пороговая), то возможны значения “активирован на 50%”, “активирован на 20%” и так далее. Если активированы несколько нейронов, можно найти нейрон с наибольшим значением активационной функции.\n",
    "\n",
    "Так как существуют промежуточные значения на выходе нейрона, **процесс обучения проходит более гладко и быстро**, а вероятность появления нескольких полностью активированных нейронов во время тренировки снижается по сравнению со ступенчатой функцией активации (хотя это зависит от того, что вы обучаете и на каких данных)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сигмоида выглядит гладкой и подобна ступенчатой функции. Рассмотрим её преимущества.\n",
    "\n",
    "**Достоинства:**\n",
    "\n",
    "Во-первых, сигмоида — нелинейна по своей природе, а комбинация таких функций производит тоже нелинейную функцию. Поэтому мы можем конструировать многослойные сети.\n",
    "\n",
    "Еще одно достоинство такой функции — она не бинарна, что делает активацию аналоговой, в отличие от ступенчатой функции. Для сигмоиды также характерен гладкий градиент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Недостатки:**\n",
    "\n",
    "Насыщение сигмоиды приводит к затуханию градиентов. Крайне нежелательное свойство сигмоиды заключается в том, что при насыщении функции с той или иной стороны (0 или 1), градиент на этих участках становится близок к нулю. Напомним, что в процессе обратного распространения ошибки данный (локальный) градиент умножается на общий градиент. Следовательно, если локальный градиент очень мал, он фактически обнуляет общий градиент. В результате, сигнал почти не будет проходить через нейрон к его весам и рекурсивно к его данным. Кроме того, следует быть очень осторожным при инициализации весов сигмоидных нейронов, чтобы предотвратить насыщение. Например, если исходные веса имеют слишком большие значения, большинство нейронов перейдет в состояние насыщения, в результате чего сеть будет плохо обучаться.\n",
    "\n",
    "Выход сигмоиды не центрирован относительно нуля. Это свойство является нежелательным, поскольку нейроны в последующих слоях будут получать значения, которые не центрированы относительно нуля, что оказывает влияние на динамику градиентного спуска (gradient descent). Если значения, поступающие в нейрон, всегда положительны (например, x > 0 поэлементно в f = ωTx + b), тогда в процессе обратного распространения ошибки все градиенты весов ω будут либо положительны, либо отрицательны (в зависимости от градиента всего выражения f). Это может привести к нежелательной зигзагообразной динамике обновлений весов. Однако следует отметить, что когда эти градиенты суммируются по пакету, итоговое обновление весов может иметь различные знаки, что отчасти нивелирует описанный недостаток. Таким образом, отсутствие центрирования является неудобством, но имеет менее серьезные последствия, по сравнению с проблемой насыщения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Гиперболический тангенс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/tanh.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперболический тангенс очень похож на сигмоиду. И действительно, это скорректированная сигмоидная функция."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому такая функция имеет те же характеристики, что и у сигмоиды, рассмотренной ранее. Её природа нелинейна, она хорошо подходит для комбинации слоёв, а диапазон значений функции -(-1, 1). Поэтому нет смысла беспокоиться, что активационная функция перегрузится от больших значений. Однако стоит отметить, что градиент тангенциальной функции больше, чем у сигмоиды (производная круче). Решение о том, выбрать ли сигмоиду или тангенс, зависит от ваших требований к амплитуде градиента. Также как и сигмоиде, гиперболическому тангенсу свойственная проблема исчезновения градиента.\n",
    "\n",
    "Тангенс также является очень популярной и используемой активационной функцией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. ReLu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU - rectified linear unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/relu.png\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная ReLu\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/dev_relu.png\"  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/lrelu_plot.png\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последние годы большую популярность приобрела функция активации под названием «выпрямитель» (rectifier, по аналогии с однополупериодным выпрямителем в электротехнике). Нейроны с данной функцией активации называются ReLU (rectified linear unit). ReLU имеет следующую формулу f(x) = max(0, x) и реализует простой пороговый переход в нуле.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим положительные и отрицательные стороны ReLU.\n",
    "\n",
    "**Достоинства:**\n",
    "\n",
    "Вычисление сигмоиды и гиперболического тангенса требует выполнения ресурсоемких операций, таких как возведение в степень, в то время как ReLU может быть реализован с помощью простого порогового преобразования матрицы активаций в нуле. Кроме того, ReLU не подвержен насыщению.\n",
    "Применение ReLU существенно повышает скорость сходимости стохастического градиентного спуска (в некоторых случаях до 6 раз) по сравнению с сигмоидой и гиперболическим тангенсом. Считается, что это обусловлено линейным характером и отсутствием насыщения данной функции.\n",
    "Отрицательные стороны:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Недостатки:**\n",
    "\n",
    "К сожалению, ReLU не всегда достаточно надежны и в процессе обучения могут выходить из строя («умирать»). Например, большой градиент, проходящий через ReLU, может привести к такому обновлению весов, что данный нейрон никогда больше не активируется. Если это произойдет, то, начиная с данного момента, градиент, проходящий через этот нейрон, всегда будет равен нулю. Соответственно, данный нейрон будет необратимо выведен из строя. Например, при слишком большой скорости обучения (learning rate), может оказаться, что до 40% ReLU «мертвы» (то есть, никогда не активируются). Эта проблема решается посредством выбора надлежащей скорости обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5. Leaky ReLu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/lrelu.png\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная Leaky ReLu\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/dev_lrelu.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/lrelu_plot.png\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU с «утечкой» (leaky ReLU, LReLU) представляет собой одну из попыток решить описанную выше проблему выхода из строя обычных ReLU. Обычный ReLU на интервале x < 0 дает на выходе ноль, в то время как LReLU имеет на этом интервале небольшое отрицательное значение (угловой коэффициент около 0,01). То есть функция для LReLU имеет вид  f(x) = αx при x < 0 и f(x) = x при x ≥ 0, где α – малая константа. Некоторые исследователи сообщают об успешном применении данной функции активации, но результаты не всегда стабильны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6. Другие модификации ReLu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parametric ReLU (**PReLU**)\n",
    "Для параметрического ReLU (parametric ReLU, PReLU) угловой коэффициент на отрицательном интервале не задается предварительно, а определяется на основе данных. Авторы публикации утверждают, что применение данной функции активации является ключевым фактором, позволившим превзойти уровень человека в задаче распознавания изображений ImageNet. Процесс обратного распространения ошибки и обновления для PReLU достаточно прост и подобен соответствующему процессу для традиционных ReLU.\n",
    "\n",
    "\n",
    "* Randomized ReLU (**RReLU**)\n",
    "Для рандомизированного ReLU (randomized ReLU, RReLU) угловой коэффициент на отрицательном интервале во время обучения генерируется случайным образом из заданного интервала, а во время тестирования остается постоянным. В рамках Kaggle-соревнования National Data Science Bowl (NDSB) RReLU позволили уменьшить переобучение благодаря свойственному им элементу случайности.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gaussian Error Linear Unit (**Gelu**)\n",
    "Гауссова ошибка линейного блока. Функция активации, используемая в самых последних трансформерах - Google BERT и OpenAI GPT-2. Документ с 2016 года, однако привлёк внимание только недавно.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/gelu.PNG\"  width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Exponential Linear Unit (**ELU**)\n",
    "Экспоненциальная линейная единица. Эта функция активации устраняет некоторые проблемы с ReLU и сохраняет некоторые положительные моменты. Для этой функции активации выбирается альфа-значение; общее значение составляет от 0,1 до 0,3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/elu.png\"  width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация функций активации:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/more_activations_for_god_of_activations.gif\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Обучение нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе **обучения** (англ. fit) сеть в определённом порядке просматривает обучающую выборку. Порядок просмотра может быть последовательным и случайным. Некоторые сети, обучающиеся без учителя (например, сети Хопфилда), просматривают выборку только один раз. Другие (например, сети Кохонена), а также сети, обучающиеся с учителем, просматривают выборку множество раз, при этом один полный проход по выборке называется **эпохой обучения** (англ. epoch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении с учителем набор исходных данных делят на две части — собственно обучающую выборку и тестовые данные; принцип разделения может быть произвольным. Обучающие данные подаются сети для обучения, а проверочные используются для расчета ошибки сети (проверочные данные никогда для обучения сети не применяются). Таким образом, если на проверочных данных ошибка уменьшается, то сеть действительно выполняет обобщение. Если ошибка на обучающих данных продолжает уменьшаться, а ошибка на тестовых данных увеличивается, значит, сеть перестала выполнять обобщение и просто «запоминает» обучающие данные. Это явление называется **переобучением сети** или оверфиттингом (англ. overfit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Прямое распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedforward neural network - нейронная сеть с прямым распространением сигнала"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим **обучение с учителем**, при котором обучаемой сети последовательно представляется набор примеров из обучающего множества. Примеры представляют собой пары эталонных входных воздействий и желаемых выходных сигналов. Процесс обучения проходит циклически, на каждой итерации выполняется расчет сигналов при прямом и обратном распространениях, после чего сигналы ошибок используются для формирования локальных градиентов векторов адаптируемых параметров. Вычисленные локальные градиенты используются для последующей корректировки адаптируемых параметров. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используемые режимы обучения – это последовательный режим (online), при котором подстройка параметров происходит после каждого примера, и пакетный (**batch**), при котором подстройка осуществляется на основе кумулятивного локального градиента – суммы локальных градиентов по всем итерациям примеров из обучающего множества. В обоих режимах полный цикл представления множества шаблонов обучения, завершающийся подстройкой параметров, эпохой обучения сети. Для количественной оценки качества работы сети вводится функция потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Веса сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в перцептроне, в нейронной сети используются **веса**. (Иногда используют название синапсы по аналогии с человеческим мозгом). Веса сети - это вещественные числа (чаще от -1 до 1), которых характеризуют влияние входа на выход.\n",
    "\n",
    "**Нейрон** – базовая единица нейронной сети. У каждого нейрона есть определённое количество входов, куда поступают сигналы, которые суммируются с учётом значимости (веса) каждого входа. Далее сигналы поступают на входы других нейронов. Вес каждого такого «узла» может быть как положительным, так и отрицательным. Например, если у нейрона есть два 'входа', то у него есть и два  весовых значения, которые можно регулировать независимо друг от друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Как вычислить результат работы нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/nn1.png\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим задачу классификации XOR, то есть на вход подадим 1 и 0, и будем ожидать 1 на выходе. Веса сети определим случайным образом:\n",
    "\n",
    "I1=1 I2=0\n",
    "\n",
    "w1=0.45 w2=0.78\n",
    "w3=-0.12 w4=0.13\n",
    "\n",
    "\n",
    "w5=1.5 w6=-2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "H1 = I1*W1+I2*W3 = 1*0.45+0*-0.12 = 0.45\n",
    "H2 = I1*W2+I2*W4 = 1*0.78+0*0.13 = 0.78\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы значения H1 и H2 не выходили за предельные значения, используется функция активации (О ней подробно в следующих разделах)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "H1_out = sigmoid(H1) = sigmoid(0.45) = 0.61\n",
    "H2_out = sigmoid(H2) = sigmoid(0.78) = 0.69\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "O1_in = 0.61*1.5+0.69*-2.3=-0.672\n",
    "O1_out = sigmoid(-0.672)=0.33\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ нейронной сети O1_out = 0.33, а мы ожидали на выходе 1. О том, как скорректировать веса нужным образом будет рассказано в разделе о методе обратного распространения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Смещение (bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/bias0.png\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим простой пример. На вход нейрона подаётся вес умноженный на входное значение. После применения функции активации, в зависимости от веса, при всевозможных значениях входа мы можем получить следующие графики:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/bias1.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но что если мы захотим чтобы при ```x=2``` чтобы сеть выводила ```0```, тогда без веса смещения эту задачу не решить.\n",
    "\n",
    "Просто изменить крутизну сигмоиды на самом деле не получится - вы хотите иметь возможность сдвинуть всю кривую вправо ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Смещение** (англ. bias) - это дополнительный коэффициент прибавляющийся ко сумме входов, наличие смещения позволяет сдвинуть функцию активации влево или вправо, что может иметь решающее значение для успешного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/bias2.png\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда, при разных смещениях мы можем получить сдвинутые функции активации, что способствует лучшему обучению нейронной сети:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/bias3.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Метод обратного распространения ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_3.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас есть все компоненты для обучения 2-х слойной модели:\n",
    "- предобработали данные\n",
    "- умножили их на веса\n",
    "- применили функцию активации\n",
    "- снова умножили\n",
    "- нашли значение функции потерь\n",
    "- нашли градиент\n",
    "- обновили веса ....\n",
    "- оценили точность\n",
    "\n",
    "А как будем искать градиент?\n",
    "Во второй лекции мы в ручную считали от нее производную. Так как модель поменялась придется делать это заново...\n",
    "\n",
    "Для того что бы упростить этот процесс используется формализм под названием \"Алгоритм обратного распространения ошибки\" или \"Backpropagation\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Backpropagation - метод обратного распространения ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод обратного распространения ошибки (англ. backpropagation)** — метод вычисления градиента, который используется при обновлении весов многослойного перцептрона. Метод является модификацией классического метода **градиентного спуска. (англ. gradient descent)** Впервые метод был описан в 1974 г. А. И. Галушкиным, а также независимо и одновременно Полом Дж. Вербосом. Далее существенно развит в 1986 г. Дэвидом И. Румельхартом, Дж. Е. Хинтоном и Рональдом Дж. Вильямсом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем в развитии машинного обучения начался период застоя, поскольку компьютеры того времени были не пригодны для создания масштабных моделей. В 2006 году Джеффри Хинтон и Руслан Салахутдинов опубликовали статью, в которой показали, как можно эффективно обучать глубокие нейросети. Но даже тогда они пока не приобрели современный вид."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Первых по-настоящему впечатляющих результатов исследователи искусственного интеллекта достигли в 2012 году, когда почти одновременно появились успешные решения задач распознавания речи и классификации изображений. Тогда же была представлена первая свёрточная нейросеть AlexNet, которая достигла высокой на тот момент точности классификации датасета ImageNet. С тех пор подобные архитектуры довольно широко применяются в разных областях.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Идея"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея этого метода состоит в распространении сигналов ошибки от выходов сети к её входам, в направлении, обратном прямому распространению сигналов в обычном режиме работы.\n",
    "\n",
    "Для возможности применения метода обратного распространения ошибки передаточная функция нейронов должна быть дифференцируема."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появление алгоритма обратного распространения ошибки вкупе с возрастающими компьютерными мощностиями позволило обучить многослойную нейронную сеть которую можно было применять для решения практических задач.\n",
    "\n",
    "Архитектура такой сети была разработана в 1989г. Яном Ле Куном. Сеть имела 5 слоев, из них 2 сверточных.\n",
    "\n",
    "Применялась в США для распознавания рукописных букв на почтовых конвертах до начала 2000г."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея этого метода состоит в распространении сигналов ошибки от выходов сети к её входам, в направлении, обратном прямому распространению сигналов в обычном режиме работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Граф вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любую нейронную сеть можно представить в виде графа \"последовательных действий\", где результат вычисляется итеративно, одно действие за другим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм по которому вычисляются веса можно представить в виде графа. Для кода который мы использовали для линейного классификаторо он будет выглядеть так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_4.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И производную от Loss для такгого графа можно найти в ручную что мы и делали.\n",
    "\n",
    "Однако по мере добавления слоев модель может оказаться намного сложнее. Напримет так выглядит граф для AlexNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_5.png\"  width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм обратного распространения ошибки позволяет находить градиенты для любого графа вычислений, если функция которую он описывает дифференцируема.\n",
    "\n",
    "В его основе лежит правило взятия производной сложной функции (chain rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_7.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И мы уже пользовались им когда брали производную от CrossEntropyLoss\n",
    "\n",
    "\n",
    "$$ L =  - \\sum_i \\log(\\dfrac {e^{s_{y_i}}} {\\sum_j e^{s_{y_j}}})$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropyLoss(self,x, y):\n",
    "      y = [int(i) for i in y]\n",
    "      n_features = x.shape[1] # number of features\n",
    "      n_samples = x.shape[0] # number of samples\n",
    "\n",
    "      # CalculateCross-entropy loss over a batch \n",
    "      scores = np.dot(x, self.W) #logits\n",
    "\n",
    "      # Softmax\n",
    "      exp_scores = np.exp(scores - np.max(scores, axis=1, keepdims=True))\n",
    "      probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "      # Cross Entropy\n",
    "      correct_logprobs = -np.log(probs[np.arange(n_samples), y])\n",
    "      loss = np.sum(correct_logprobs) / n_samples\n",
    "\n",
    "      # Calculate gradient over a batch \n",
    "      dW = np.zeros(x.shape)\n",
    "      # Calculate gradients respect to probs\n",
    "      probs[np.arange(n_samples), y] -= 1\n",
    "      probs /= n_samples\n",
    "      # Use chain rule\n",
    "      dW = x.T.dot(probs)\n",
    "      \n",
    "      return loss, dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. Пошаговый разбор метода обратного распространения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прямой проход (forward):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_6.png\"  width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Обратный(backward):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_8_1.png\"  width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L = Loss - всегда скаляр.\n",
    "\n",
    "Loss = L(f(q(x,y),z))\n",
    "\n",
    "А что если вход соединен с несколькими вершинами графа, либо у вершины у вершины больше одного выхода?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_8_2.png\"  width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае в месте ветвления можно создать дополниельную вершину которая будет соответствовать операции копирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_8_3.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда при обратном распространении входящим (upstream) будет вектор значений. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_8_4.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом можно выделить шаблоны для получения градинтов при базовых операциях:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_8_5.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А общее правило взятия градиентов можно представить следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b0.PNG\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим немного более сложный пример:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b1.PNG\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы изменить наши веса считаем последовательно градиенты, идущие от выхода к входам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b2.PNG\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b3.PNG\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b4.PNG\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b5.PNG\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b6.PNG\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b7.PNG\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b8.PNG\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b9.PNG\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде, без использования библиотек подсчёт градиентов можно записать как:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/b10.PNG\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объектно - ориентированный код:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_9_1.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/\n",
    "L05_9_2.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_9_3.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_9_4.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обратное распространение для векторов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_10.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_10_1.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/gan/L05_10_2.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. Анимация работы метода обратного распространения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L05_Neural_networks/img/backprop_animation.gif\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprop in pytorch\n",
    "https://colab.research.google.com/drive/1X6hKtyZFqk9YstrpbOIFEnZc4Ub24Uj_?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Преимущества и недостатки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на многочисленные успешные применения метода обратного распространения, он не является универсальным решением. Больше всего неприятностей приносит неопределённо долгий процесс обучения. В сложных задачах для обучения сети могут потребоваться дни или даже недели, она может и вообще не обучиться. Причиной может быть одна из описанных ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Паралич сети\n",
    "\n",
    "    В процессе обучения сети значения весов могут в результате коррекции стать очень большими величинами. Это может привести к тому, что все или большинство нейронов будут функционировать при очень больших значениях, в области, где производная функции очень мала. Так как посылаемая обратно в процессе обучения ошибка пропорциональна этой производной, то процесс обучения может практически замереть. В теоретическом отношении эта проблема плохо изучена. Обычно этого избегают уменьшением размера шага, но это увеличивает время обучения. Различные эвристики использовались для предохранения от паралича или для восстановления после него, но пока что они могут рассматриваться лишь как экспериментальные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Локальные минимумы\n",
    "\n",
    "    Метод градиентного спуска может застрять в локальном минимуме, так и не попав в глобальный минимум\n",
    "    Обратное распространение использует разновидность градиентного спуска, то есть осуществляет спуск вниз по поверхности ошибки, непрерывно подстраивая веса в направлении к минимуму. Поверхность ошибки сложной сети сильно изрезана и состоит из холмов, долин, складок и оврагов в пространстве высокой размерности. Сеть может попасть в локальный минимум (неглубокую долину), когда рядом имеется гораздо более глубокий минимум. В точке локального минимума все направления ведут вверх, и сеть не способна из него выбраться. Основную трудность при обучении нейронных сетей составляют как раз методы выхода из локальных минимумов: каждый раз выходя из локального минимума снова ищется следующий локальный минимум тем же методом обратного распространения ошибки до тех пор, пока найти из него выход уже не удаётся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Размер шага\n",
    "\n",
    "    Если размер шага фиксирован и очень мал, то сходимость слишком медленная, если же он фиксирован и слишком велик, то может возникнуть паралич или постоянная неустойчивость. Эффективно увеличивать шаг до тех пор, пока не прекратится улучшение оценки в данном направлении антиградиента и уменьшать, если такого улучшения не происходит. П. Д. Вассерман описал адаптивный алгоритм выбора шага, автоматически корректирующий размер шага в процессе обучения. В книге А. Н. Горбаня предложена разветвлённая технология оптимизации обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Переобучение\n",
    "\n",
    "    Следует также отметить возможность переобучения сети (overfitting), что является скорее результатом ошибочного проектирования её топологии и/или неправильным выбором критерия остановки обучения. При переобучении теряется свойство сети обобщать информацию. Весь набор образов, предоставленных к обучению, будет выучен сетью, но любые другие образы, даже очень похожие, могут быть распознаны неверно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Пример простой сети на датасете mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем всё необходимое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PyTorch для создания нейронных сетей требуется отнаследоваться от класса nn.Module и переопределить метод forward, в который подаются входные данные, и ожидаются выходные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В класс мы добавляем две переменные, два слоя Linear. Linear -это слой, позволяющий, умножить веса на входной вектор и добавить смещение. Первый параметр - размер входного вектора, второй - размер выходного.\n",
    "\n",
    "В методе forward мы указываем последовательность применения операций для получения результата. Сначала изменим представление входного вектора, чтобы от изменения batch_size у нас ничего не сломалось.\n",
    "\n",
    "Далее идёт первый слой, после него функция активации relu и второй слой, возвращающий вектор длиной 10, означающий принадлежность к одному из классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x): # Called inside __call__ method\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наследование от nn.Module позволяет объединять блоки:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 04.03.21 torchvision обновился до версии 0.9.0\n",
    "## В этой этот же момент была сломана версия 0.8.2 (несмотря на то что релиз версии был 10.12.20)\n",
    "## В колабе стоит 0.8.2, обновите версию и удостоверьтесь что после обновления версия 0.9.0\n",
    "## https://github.com/pytorch/vision/pull/1939\n",
    "## https://github.com/pytorch/vision/issues/1938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "trainset = MNIST(root='./MNIST', train=True, download=True, transform=transform)\n",
    "testset = MNIST(root='./MNIST', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 64\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим нашу лосс-функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим оптимайзер для найшей сети. Оптимайзер, в библиотеках для нейронных сетей -- это сущность, осуществляющая градиентный спуск. Подробнее об оптимайзере будет рассказано в дальнейших лекциях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим сеть десять эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "loss_hist = []\n",
    "for ep in range(epochs):\n",
    "    hist_loss = 0\n",
    "    for _, data in enumerate(trainloader, 0): # get bacth\n",
    "        # parse batch\n",
    "        images, labels = data\n",
    "        # sets the gradients of all optimized tensors to zero.\n",
    "        optimizer.zero_grad() \n",
    "        # get outputs\n",
    "        outputs = net(images) \n",
    "        # calculate loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        # calculate gradients\n",
    "        loss.backward() \n",
    "        # performs a single optimization step (parameter update).\n",
    "        optimizer.step()\n",
    "        hist_loss += loss.item()\n",
    "    loss_hist.append(hist_loss /len(trainloader))\n",
    "    print(f\"Epoch={ep} loss={loss_hist[ep]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(epochs), loss_hist)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посчитаем accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calaculate_accuracy(model, dataloader):\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = model.forward(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = calaculate_accuracy(net, trainloader)\n",
    "print(f\"Accuracy train= {acc_train}\")\n",
    "acc_test = calaculate_accuracy(net, testloader)\n",
    "print(f\"Accuracy test= {acc_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, classes = next(iter(testloader))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net.forward(images)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.reshape(images, (64, 28, 28))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[:10]\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs[:10]\n",
    "outputs.shape\n",
    "digits = np.argmax(outputs.detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for digit, image in zip(digits, images):\n",
    "    print(digit)\n",
    "    pixels = image.reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки:\n",
    "\n",
    "\n",
    "http://statsoft.ru/home/textbook/modules/stneunet.html#radial\n",
    "\n",
    "https://www.machinelearningmastery.ru/importance-of-loss-function-in-machine-learning-eddaaec69519/\n",
    "\n",
    "https://gombru.github.io/2018/05/23/cross_entropy_loss/\n",
    "\n",
    "https://neurohive.io/ru/osnovy-data-science/activation-functions/\n",
    "\n",
    "https://www.machinelearningmastery.ru/state-of-the-art-activation-functions-explained-gelu-selu-elu-relu-and-more-a4247171ca4e/"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 1
}
