{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План лекции (временный блок):\n",
    "* GAN - Генеративно-состязательная сеть (англ. Generative adversarial network, сокращённо GAN)\n",
    " * Контент: изображения архитектуры сети\n",
    " * Контент: Генератор (архитектура)\n",
    " * Контент: Классификатор (архитектура)\n",
    "* cGAN - Условные порождающие состязательные сети CGAN (Conditional Generative Adversarial Nets)\n",
    " * Картинка принципа работы (в сеть подаются так же изображения)\n",
    " * like above: арихитектура cGAN\n",
    "* DCGAN (Deep Convolutional Generative Adversarial Nets)\n",
    " * де-факто это cGAN, только для изображений, картинки похожи\n",
    "* StackGAN - порождающая состязательная сеть для генерации фото-реалистичных изображений исходя из текстового описания\n",
    "* LAPGAN (Laplacian Pyramid of Adversarial Networks)\n",
    "* ControlGAN (Controllable Generative Adversarial Networks)\n",
    "* AC-GAN Auxiliary Classifier Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Блок с мусором"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ниже - лекция Техносферы\n",
    "\n",
    "https://www.youtube.com/watch?v=hPux6TVtM58%D0%BF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### План лекции\n",
    "1. Обучение без учителя и GAN\n",
    "2. Применения GAN\n",
    "* DCGAN\n",
    "* Domain transfer network\n",
    "* SRGAN\n",
    "* Text to image (StackedGAN)\n",
    "* Image to image (cGAN)\n",
    "3. Проблема плохих градиентов и подходы к решению\n",
    "* LSGAN\n",
    "* WGAN\n",
    "* BEGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация при размеченном датасете"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### Проблемы с размеченными датасетами\n",
    "* Данных много, но меток обычно мало/очень шумные/дорогие\n",
    "* Transfer learning - нетривиальная проблема\n",
    "* Распределение на обучающем множестве не совпадает с распределением ’in the wild’\n",
    "* Распределение данных меняется со временем/адаптируется к вашей системе\n",
    "##### Подходы к решению\n",
    "* Semi-supervised learning (в широком смысле)\n",
    "* Online learning (например: stock prediction) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Understanding data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Наша задача - научиться генерировать реалистичные изображения. Под generative modeling понимают решение двух задач.\n",
    "\n",
    "1. Понимание того, как устроено распределение $p_{data}(x)$\n",
    "2. Построение функции G, которая по заданному вектору будет генерировать изображение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning to generate Chairs, Tables and Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-06.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-07.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему получилось так удачно?** \n",
    "\n",
    "*Огромное количество информации на входе*\n",
    "\n",
    "\n",
    "1. категория семпла\n",
    "2. углы и повороты\n",
    "3. заданные параметры трансформаций\n",
    "4. сегментация\n",
    "\n",
    "**Можно ли автоматизировать извлечение этих фичей?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генеративно-состязательные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы изучаем окружающий мир, то у нас нет ответов что есть что, однако, со временем, мы учимся распознавать образы, речь, движения благодаря тому, что мы просто смотрим и слушаем! Если детям сказать \"Это собака\" - это ничтожно маленькая информация. \n",
    "\n",
    "Положим, если давать человеку бит в секунду, и, учитывая что человек живёт в среднем $10^9$ секунд, а так же то, что в мозге человека примерно $10^{14}$ нейронных связей, значит человек использует мозг на одну стотысячную. Откуда ему получить столько информации чтобы стать человеком? Изучать мир самому! Анализируя все входные источники своего тела: глаза, уши и так далее.\n",
    "\n",
    "Метки, к которым мы привыкли в курсе нейронных сетей, в изображении с глаз отсутствуют. То есть преимущественно мы учимся без учителя.\n",
    "\n",
    "Как подойти к такой задаче с помощью нейронных сетей?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поставим задачу генерации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы имеем неразмеченные данные, и хотим генерировать новые данные, которые будут удовлетворять следующим условиям:\n",
    "* Новые данные должны быть похожи на исходные\n",
    "* При этом не повторять их в точности (или повторять, при случайном стечении обстоятельств)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эволюция в генерации изображений лиц:\n",
    "\n",
    "<img src=\"face_evol.jpg\" alt=\"alttext\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**https://thispersondoesnotexist.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы обусловились о случайности, то нам эту случайность нужно реализовать. Как это сделать с нейронной сетью? В сетях, которые мы проходили при подаче экземпляра и фиксированных весах всегда получается один и тот же результат. Случайно изменять веса сети? Есть способ лучше - давать в качестве входа случайных шум."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![random_example.png](random_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему именно вектор? Почему не одно случайное число. Ответ прост: изменяя одно случайное число, мы будем перемещаться на очень небольшое расстояние и генерация будет однообразной. Поскольку мы физически не можем генерировать числа в бесконечных пределах, мы вынуждены использовать фиксированный диапазон.\n",
    "\n",
    "В одномерном случае, взяв диапазон [0,1] у нас всего одна размерность нашего перемещения.\n",
    "Если взять двухмерный, или трёхмерный случай, то у нас уже есть две и три **степени свободы**.\n",
    "\n",
    "То есть случайный шум большой размерности даёт нам больше объёма для генерации. Это называется **input latent space** - входное латентное простанство.\n",
    "\n",
    "Note: из-за неустоявшейся терминологии, случайное распределение на входе генератора называется латентным пространством, так же как и скрытое пространство в автоэнкодерах. Поэтому в этой лекции будем называть его **входным** латентным пространством. Так же встречается вариант: predefined latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Какую размерность и форму выбрать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Длина вектора (размерность латентного пространства) выбирается больше, чем количество разных\n",
    "независимых свойств объекта, которые мы хотим получить. Если длина 0, то случайности\n",
    "нет и генератор будет всегда производить один и тот же объект. Если длина 1, то будет\n",
    "шкала, вдоль которой будут расположены, например, генерируемые изображения. Для генератора\n",
    "лиц, это будет, в лучшем случае, шкала от молодой женщины блондинки к пожилому мужчине\n",
    "брюнету. Лучший способ выбрать длину вектора - это посмотреть похожую задачу в публикациях,\n",
    "взять подобную размерность, и начать экспериментировать с размерностью оттуда.\n",
    "\n",
    "У большого латентного пространства есть минусы: увеличивая размерность латентного пространства мы можем расширить его настолько, что при обучении модели точек в этом латентром пространстве будет настолько мало, что в основном пространство будет состоять из пустот. Тогда модель будет крайне некачественно \"понимать\" что ей нужно генерировать в точке, которой не было на обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичный вопрос встаёт и по поводу формы распределения входного латентного пространства. Как мы знаем из лекции про обучение сети, инициализация весов и нормализация имеют существенный вклад в работу модели. Поэтому, принято использовать многомерное нормальное распределение для input latent space, потому что оно лучше взаимодействует с весами модели и увеличивает сходимость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](MultivariateNormal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем решить эту задачу полносвязной сетью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import Dataset, random_split\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gen_pair(num=100):\n",
    "    x = np.random.uniform(low=-1, high=1, size=(num,))\n",
    "    y = x*x\n",
    "    return np.hstack((x.reshape(-1,1), y.reshape(-1,1)))\n",
    "\n",
    "pairs = gen_pair(100)\n",
    "plt.scatter(pairs[:,0], pairs[:,1])\n",
    "plt.title(\"Случайные точки на параболе, которые используем в качестве датасета.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом, простом случае, латентным пространством уна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noice.shape: torch.Size([40960, 3])\n",
      "xy_pair.shape: torch.Size([40960, 2])\n"
     ]
    }
   ],
   "source": [
    "n_batches = 10\n",
    "batch_size = 4096\n",
    "ls = 3 # latent space\n",
    "\n",
    "noice = np.random.normal(size=(n_batches*batch_size, ls))\n",
    "noice = torch.tensor(noice, dtype=torch.float)\n",
    "print(f\"noice.shape: {noice.shape}\")\n",
    "\n",
    "xy_pair = gen_pair(num = n_batches*batch_size)\n",
    "xy_pair = torch.tensor(xy_pair, dtype=torch.float)\n",
    "print(f\"xy_pair.shape: {xy_pair.shape}\")\n",
    "\n",
    "dataset = TensorDataset(noice, xy_pair) # model inputs, model outputs\n",
    "\n",
    "len_tr = int(len(dataset)*0.8)\n",
    "len_tst = len(dataset) - len_tr\n",
    "trainset, testset = random_split(dataset,[len_tr,len_tst])\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_space=3\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape)\n",
    "#     print(y.shape)\n",
    "#     x = x.view(-1, latent_space)\n",
    "#     print(x.shape)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_loss(model,testloader,loss_function, device=\"cuda\"):\n",
    "    with torch.no_grad():\n",
    "        loss_test_total = 0\n",
    "        for samples, labels in testloader:\n",
    "            outputs = model(samples.to(device))\n",
    "            loss = loss_function(outputs, labels.to(device))\n",
    "            loss_test_total += loss.item()\n",
    "        return loss_test_total/len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotWorkModel(nn.Module):\n",
    "    def __init__(self, latent_space):\n",
    "        super().__init__()\n",
    "        self.latent_space = latent_space\n",
    "        self.fc1 = nn.Linear(latent_space, 25)\n",
    "        self.fc2 = nn.Linear(latent_space, 25)\n",
    "        self.fc3 = nn.Linear(25,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, latent_space)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4096x25 and 3x25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-eb1a403220c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-ad35bce213cc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# x = x.view(-1, latent_space)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\python\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\python\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4096x25 and 3x25)"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "model = NotWorkModel(latent_space = ls)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_epoch = 0\n",
    "    for samples, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(samples)\n",
    "        loss = loss_function(outputs, labels.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        loss_epoch += loss.item()\n",
    "        \n",
    "    loss_test = get_test_loss(model,testloader,loss_function, device=\"cpu\")\n",
    "        \n",
    "    print(f\"Epoch={epoch+1} train_loss={loss_epoch/len(trainloader):.4} test_loss={loss_test:.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как определить лосс функцию \"похожести\" изображения?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Автоэнкодеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея очень похожая на PCA: найти сжимающее отображение исходных данных (Encoder) в пространство меньшей размерности, такое, что из него возможно восстановить исходное изображение (Decoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-08.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наивный подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Естественно, хочется взять MSE как лосс-функцию и попробовать оптимизировать.\n",
    "\n",
    "Но, к сожалению, результаты **не впечатляют.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-09.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, мы взяли слишком простой лосс, можно придумать что-то лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Глубокое распознавание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-10.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-11.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопросы\n",
    "\n",
    "* Как глубина влияет на степень реконструкции? (текстура, цвет, положение)\n",
    "* Каков эффект max-pooling?\n",
    "* Как можно использовать готовые классификаторы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эмпирические результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На практике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно работает, настроить параметры несложно.\n",
    "\n",
    "* Лучше всего использовать комбинацию loss-функций\n",
    "* Image-to-image loss: L1\n",
    "* Deep features loss: VGG 16/19\n",
    "* Регуляризация: total variation\n",
    "\n",
    "**Но можно еще лучше!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Генеративные состязательные сети (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем основные определения:\n",
    "$z ∼ p_z(z)$ - noise vector\n",
    "$p_g(z)$ - распределение сгенерированных картинок из noise\n",
    "$p_{data}(x)$ - распределение настоящих картинок\n",
    "$G(z)$ - генератор (генерирует картинку из z)\n",
    "$D(x)$ - дискриминатор (отличает реальные от сгенерированных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-15.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача генератора - сгенерировать картинку, которую дискриминатор сочтет реалистичной.\n",
    "\n",
    "Задача дискриминатора - отличить сгенерированную от реальной.\n",
    "\n",
    "\n",
    "Математически - это игра двух игроков:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-16.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-17.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теоретические результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-18.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-19.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-20.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преимущества GAN**\n",
    "* Теоретические гарантии сходимости\n",
    "* Можно обучать обычным SGD\n",
    "* Решает в явном виде задачу generative modeling\n",
    "* Но неявным образом (нейросети)\n",
    "\n",
    "\n",
    "**Недостатки GAN**\n",
    "* Нестабильное обучение\n",
    "* Очень долгая сходимость\n",
    "* Mode-collapsing\n",
    "* Generator/Discriminator starvation\n",
    "* Поиск оптимальных параметров - pure luck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тем не менее, на практике GAN почти всегда дает заметные улучшения. Следующая лекция о том, как улучшить GAN.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-22.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-23.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary Classifier GAN, или AC-GAN для краткости, является расширением GAN, который изменяет дискриминатор, чтобы предсказать метку класса данного изображения, а не получить его в качестве входных данных. \n",
    "\n",
    "Он имеет эффект стабилизации процесса обучения и позволяет генерировать большие высококачественные изображения, изучая представление в скрытом пространстве, которое не зависит от метки класса.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-51.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был предложен новый метод улучшения обучения выигрышей путем кондиционирования входных данных метками классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-input multi-output network:\n",
    "* Входные данные: встраивание класса и вектор шума\n",
    "* Выходы: двоичный классификатор (поддельные/реальные изображения) и многоклассовый классификатор (классы изображений)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-57.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация:\n",
    "* Generator\n",
    "* Discriminator\n",
    "* dual loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Архитектура описана таким образом, что дискриминатор и вспомогательный классификатор могут рассматриваться как отдельные модели, разделяющие веса моделей. На практике дискриминатор и вспомогательный классификатор могут быть реализованы в виде единой нейросетевой модели с двумя выходами.\n",
    "\n",
    "Первый вывод представляет собой единственную вероятность через сигмоидную функцию активации, которая указывает на “реальность” входного изображения и оптимизируется с использованием двоичной перекрестной энтропии, как обычная модель дискриминатора GAN.\n",
    "\n",
    "Второй вывод-это вероятность принадлежности изображения к каждому классу через функцию активации softmax, как и любая заданная многоклассовая классификационная нейросетевая модель, и оптимизируется с использованием категориальной кросс-энтропии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generator Model:**\n",
    "* Input: Random point from the latent space, and the class label.\n",
    "* Output: Generated image.\n",
    "\n",
    "**Discriminator Model:**\n",
    "* Input: Image.\n",
    "* Output: Probability that the provided image is real, probability of the image belonging to each known class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На приведенном ниже графике суммируются входные и выходные данные ряда условных грантов, включая AC-GAIN, обеспечивая некоторый контекст для различий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-56.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCGAN использует сверточные и сверточно-транспонированные (convolutional and convolutional-transpose) слои в дискриминаторе и генераторе соответственно. \n",
    "\n",
    "Впервые он был описан Рэдфордом и др. в статье \"Обучение неконтролируемому представлению с помощью Глубоких Сверточных генеративных состязательных сетей\". Дискриминатор состоит из чередующихся слоев свертки, слоев пакетной нормы и активаций LeakyReLU. \n",
    "\n",
    "**input ** - это входное изображение размером 3x64x64, а output -скалярная вероятность того, что вход получен из реального распределения данных.** \n",
    "\n",
    "Генератор состоит из сверточно-транспонированных слоев, слоев пакетной нормы и активаций ReLU. Входным сигналом является скрытый вектор z, который берется из стандартного нормального распределения, а выходным-изображение RGB размером 3x64x64.\n",
    "\n",
    "Шаговые конвективные слои позволяют латентному вектору трансформироваться в объем той же формы, что и изображение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-24.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-25.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-50.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-49.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Интерполяция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-26.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain transfer network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-27.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-28.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Super resolution GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-29.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-30.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-31.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-32.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-33.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-34.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-35.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-36.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Иллюстрации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-37.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-38.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблемы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual**\n",
    "* Mode-collapsing\n",
    "* Instability (long run)\n",
    "* Noise generation (L1 лучше по началу)\n",
    "* Bad converging (подбор гиперпараметров - боль)\n",
    "\n",
    "\n",
    "**Возможно, проблема в том, что мы оптимизируем что-то не то?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-40.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-41.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-42.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-43.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Расстояние Вассерштейна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-44.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wasserstein > KL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-45.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-46.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СХОДИМОСТЬ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-47.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-48.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@rangerscience/lets-read-science-stackgan-text-to-photo-realistic-image-synthesis-4562b2b14059\n",
    "\n",
    "https://arxiv.org/pdf/1612.03242v2.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1710.10916.pdf\n",
    "\n",
    "https://www.rulit.me/data/programs/resources/pdf/Generative-Adversarial-Networks-with-Python_RuLit_Me_610886.pdf\n",
    "\n",
    "видео\n",
    "\n",
    "https://www.youtube.com/watch?v=PXWIaLE7_NU\n",
    "\n",
    "https://www.youtube.com/watch?v=crI5K4RCZws\n",
    "\n",
    "гит\n",
    "\n",
    "https://github.com/zeusm9/Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAPGAN (Laplacian Pyramid of Adversarial Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1506.05751.pdf\n",
    "\n",
    "https://paperswithcode.com/method/lapgan\n",
    "\n",
    "https://sh-tsang.medium.com/review-lapgan-laplacian-generative-adversarial-network-gan-e87200bbd827\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ControlGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/mrlibw/ControlGAN\n",
    "\n",
    "https://github.com/taki0112/ControlGAN-Tensorflow\n",
    "\n",
    "статьи\n",
    "\n",
    "https://arxiv.org/pdf/1708.00598.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1909.07083.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1910.05774.pdf  многабукв\n",
    "\n",
    "https://meta-guide.com/data/data-processing/text-to-image-systems/natural-language-text-to-image-2019 множественные ссылки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AC-GAN Auxiliary Classifier Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "статьи\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-an-auxiliary-classifier-gan-ac-gan-from-scratch-with-keras/ можно брать материал\n",
    "https://towardsdatascience.com/understanding-acgans-with-code-pytorch-2de35e05d3e4\n",
    "\n",
    "https://arxiv.org/pdf/1909.05370.pdf\n",
    "\n",
    "https://openaccess.thecvf.com/content/WACV2021/papers/Kavalerov_A_Multi-Class_Hinge_Loss_for_Conditional_GANs_WACV_2021_paper.pdf\n",
    "\n",
    "гит\n",
    "\n",
    "https://github.com/lukedeo/keras-acgan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
