{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План лекции (временный блок):\n",
    "* GAN - Генеративно-состязательная сеть (англ. Generative adversarial network, сокращённо GAN)\n",
    " * Контент: изображения архитектуры сети\n",
    " * Контент: Генератор (архитектура)\n",
    " * Контент: Классификатор (архитектура)\n",
    "* cGAN - Условные порождающие состязательные сети CGAN (Conditional Generative Adversarial Nets)\n",
    " * Картинка принципа работы (в сеть подаются так же изображения)\n",
    " * like above: арихитектура cGAN\n",
    "* DCGAN (Deep Convolutional Generative Adversarial Nets)\n",
    " * де-факто это cGAN, только для изображений, картинки похожи\n",
    "* StackGAN - порождающая состязательная сеть для генерации фото-реалистичных изображений исходя из текстового описания\n",
    "* LAPGAN (Laplacian Pyramid of Adversarial Networks)\n",
    "* ControlGAN (Controllable Generative Adversarial Networks)\n",
    "* AC-GAN Auxiliary Classifier Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ниже - лекция Техносферы\n",
    "\n",
    "https://www.youtube.com/watch?v=hPux6TVtM58%D0%BF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### План лекции\n",
    "1. Обучение без учителя и GAN\n",
    "2. Применения GAN\n",
    "* DCGAN\n",
    "* Domain transfer network\n",
    "* SRGAN\n",
    "* Text to image (StackedGAN)\n",
    "* Image to image (cGAN)\n",
    "3. Проблема плохих градиентов и подходы к решению\n",
    "* LSGAN\n",
    "* WGAN\n",
    "* BEGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-03.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Проблемы с размеченными датасетами\n",
    "* Данных много, но меток обычно мало/очень шумные/дорогие\n",
    "* Transfer learning - нетривиальная проблема\n",
    "* Распределение на обучающем множестве не совпадает с распределением ’in the wild’\n",
    "* Распределение данных меняется со временем/адаптируется к вашей системе\n",
    "##### Подходы к решению\n",
    "* Semi-supervised learning (в широком смысле)\n",
    "* Online learning (например: stock prediction) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша задача - научиться генерировать реалистичные изображения. Под generative modeling понимают решение двух задач.\n",
    "\n",
    "1. Понимание того, как устроено распределение $p_{data}(x)$\n",
    "2. Построение функции G, которая по заданному вектору будет генерировать изображение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning to generate Chairs, Tables and Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-06.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-07.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему получилось так удачно?** \n",
    "\n",
    "*Огромное количество информации на входе*\n",
    "\n",
    "\n",
    "1. категория семпла\n",
    "2. углы и повороты\n",
    "3. заданные параметры трансформаций\n",
    "4. сегментация\n",
    "\n",
    "**Можно ли автоматизировать извлечение этих фичей?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Автоэнкодеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея очень похожая на PCA: найти сжимающее отображение исходных данных (Encoder) в пространство меньшей размерности, такое, что из него возможно восстановить исходное изображение (Decoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-08.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наивный подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Естественно, хочется взять MSE как лосс-функцию и попробовать оптимизировать.\n",
    "\n",
    "Но, к сожалению, результаты **не впечатляют.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-09.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, мы взяли слишком простой лосс, можно придумать что-то лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Глубокое распознавание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-10.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-11.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопросы\n",
    "\n",
    "* Как глубина влияет на степень реконструкции? (текстура, цвет, положение)\n",
    "* Каков эффект max-pooling?\n",
    "* Как можно использовать готовые классификаторы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эмпирические результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На практике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно работает, настроить параметры несложно.\n",
    "\n",
    "* Лучше всего использовать комбинацию loss-функций\n",
    "* Image-to-image loss: L1\n",
    "* Deep features loss: VGG 16/19\n",
    "* Регуляризация: total variation\n",
    "\n",
    "**Но можно еще лучше!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Генеративные состязательные сети (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем основные определения:\n",
    "$z ∼ p_z(z)$ - noise vector\n",
    "$p_g(z)$ - распределение сгенерированных картинок из noise\n",
    "$p_{data}(x)$ - распределение настоящих картинок\n",
    "$G(z)$ - генератор (генерирует картинку из z)\n",
    "$D(x)$ - дискриминатор (отличает реальные от сгенерированных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-15.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача генератора - сгенерировать картинку, которую дискриминатор сочтет реалистичной.\n",
    "\n",
    "Задача дискриминатора - отличить сгенерированную от реальной.\n",
    "\n",
    "\n",
    "Математически - это игра двух игроков:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-16.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-17.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теоретические результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-18.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-19.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-20.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преимущества GAN**\n",
    "* Теоретические гарантии сходимости\n",
    "* Можно обучать обычным SGD\n",
    "* Решает в явном виде задачу generative modeling\n",
    "* Но неявным образом (нейросети)\n",
    "\n",
    "\n",
    "**Недостатки GAN**\n",
    "* Нестабильное обучение\n",
    "* Очень долгая сходимость\n",
    "* Mode-collapsing\n",
    "* Generator/Discriminator starvation\n",
    "* Поиск оптимальных параметров - pure luck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тем не менее, на практике GAN почти всегда дает заметные улучшения. Следующая лекция о том, как улучшить GAN.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-22.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-23.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary Classifier GAN, или AC-GAN для краткости, является расширением GAN, который изменяет дискриминатор, чтобы предсказать метку класса данного изображения, а не получить его в качестве входных данных. \n",
    "\n",
    "Он имеет эффект стабилизации процесса обучения и позволяет генерировать большие высококачественные изображения, изучая представление в скрытом пространстве, которое не зависит от метки класса.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-51.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был предложен новый метод улучшения обучения выигрышей путем кондиционирования входных данных метками классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-input multi-output network:\n",
    "* Входные данные: встраивание класса и вектор шума\n",
    "* Выходы: двоичный классификатор (поддельные/реальные изображения) и многоклассовый классификатор (классы изображений)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-57.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация:\n",
    "* Generator\n",
    "* Discriminator\n",
    "* dual loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Архитектура описана таким образом, что дискриминатор и вспомогательный классификатор могут рассматриваться как отдельные модели, разделяющие веса моделей. На практике дискриминатор и вспомогательный классификатор могут быть реализованы в виде единой нейросетевой модели с двумя выходами.\n",
    "\n",
    "Первый вывод представляет собой единственную вероятность через сигмоидную функцию активации, которая указывает на “реальность” входного изображения и оптимизируется с использованием двоичной перекрестной энтропии, как обычная модель дискриминатора GAN.\n",
    "\n",
    "Второй вывод-это вероятность принадлежности изображения к каждому классу через функцию активации softmax, как и любая заданная многоклассовая классификационная нейросетевая модель, и оптимизируется с использованием категориальной кросс-энтропии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generator Model:**\n",
    "* Input: Random point from the latent space, and the class label.\n",
    "* Output: Generated image.\n",
    "\n",
    "**Discriminator Model:**\n",
    "* Input: Image.\n",
    "* Output: Probability that the provided image is real, probability of the image belonging to each known class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На приведенном ниже графике суммируются входные и выходные данные ряда условных грантов, включая AC-GAIN, обеспечивая некоторый контекст для различий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-56.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCGAN использует сверточные и сверточно-транспонированные (convolutional and convolutional-transpose) слои в дискриминаторе и генераторе соответственно. \n",
    "\n",
    "Впервые он был описан Рэдфордом и др. в статье \"Обучение неконтролируемому представлению с помощью Глубоких Сверточных генеративных состязательных сетей\". Дискриминатор состоит из чередующихся слоев свертки, слоев пакетной нормы и активаций LeakyReLU. \n",
    "\n",
    "**input ** - это входное изображение размером 3x64x64, а output -скалярная вероятность того, что вход получен из реального распределения данных.** \n",
    "\n",
    "Генератор состоит из сверточно-транспонированных слоев, слоев пакетной нормы и активаций ReLU. Входным сигналом является скрытый вектор z, который берется из стандартного нормального распределения, а выходным-изображение RGB размером 3x64x64.\n",
    "\n",
    "Шаговые конвективные слои позволяют латентному вектору трансформироваться в объем той же формы, что и изображение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-24.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-25.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-50.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-49.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Интерполяция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-26.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain transfer network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-27.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-28.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Super resolution GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-29.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-30.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-31.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-32.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-33.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-34.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-35.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-36.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Иллюстрации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-37.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-38.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблемы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual**\n",
    "* Mode-collapsing\n",
    "* Instability (long run)\n",
    "* Noise generation (L1 лучше по началу)\n",
    "* Bad converging (подбор гиперпараметров - боль)\n",
    "\n",
    "\n",
    "**Возможно, проблема в том, что мы оптимизируем что-то не то?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-40.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-41.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-42.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-43.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Расстояние Вассерштейна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-44.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wasserstein > KL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-45.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-46.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СХОДИМОСТЬ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-47.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-48.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@rangerscience/lets-read-science-stackgan-text-to-photo-realistic-image-synthesis-4562b2b14059\n",
    "\n",
    "https://arxiv.org/pdf/1612.03242v2.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1710.10916.pdf\n",
    "\n",
    "https://www.rulit.me/data/programs/resources/pdf/Generative-Adversarial-Networks-with-Python_RuLit_Me_610886.pdf\n",
    "\n",
    "видео\n",
    "\n",
    "https://www.youtube.com/watch?v=PXWIaLE7_NU\n",
    "\n",
    "https://www.youtube.com/watch?v=crI5K4RCZws\n",
    "\n",
    "гит\n",
    "\n",
    "https://github.com/zeusm9/Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAPGAN (Laplacian Pyramid of Adversarial Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1506.05751.pdf\n",
    "\n",
    "https://paperswithcode.com/method/lapgan\n",
    "\n",
    "https://sh-tsang.medium.com/review-lapgan-laplacian-generative-adversarial-network-gan-e87200bbd827\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ControlGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/mrlibw/ControlGAN\n",
    "\n",
    "https://github.com/taki0112/ControlGAN-Tensorflow\n",
    "\n",
    "статьи\n",
    "\n",
    "https://arxiv.org/pdf/1708.00598.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1909.07083.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1910.05774.pdf  многабукв\n",
    "\n",
    "https://meta-guide.com/data/data-processing/text-to-image-systems/natural-language-text-to-image-2019 множественные ссылки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AC-GAN Auxiliary Classifier Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "статьи\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-an-auxiliary-classifier-gan-ac-gan-from-scratch-with-keras/ можно брать материал\n",
    "https://towardsdatascience.com/understanding-acgans-with-code-pytorch-2de35e05d3e4\n",
    "\n",
    "https://arxiv.org/pdf/1909.05370.pdf\n",
    "\n",
    "https://openaccess.thecvf.com/content/WACV2021/papers/Kavalerov_A_Multi-Class_Hinge_Loss_for_Conditional_GANs_WACV_2021_paper.pdf\n",
    "\n",
    "гит\n",
    "\n",
    "https://github.com/lukedeo/keras-acgan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
