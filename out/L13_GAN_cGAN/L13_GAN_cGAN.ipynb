{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План лекции (временный блок):\n",
    "* GAN - Генеративно-состязательная сеть (англ. Generative adversarial network, сокращённо GAN)\n",
    " * Контент: изображения архитектуры сети\n",
    " * Контент: Генератор (архитектура)\n",
    " * Контент: Классификатор (архитектура)\n",
    "* cGAN - Условные порождающие состязательные сети CGAN (Conditional Generative Adversarial Nets)\n",
    " * Картинка принципа работы (в сеть подаются так же изображения)\n",
    " * like above: арихитектура cGAN\n",
    "* DCGAN (Deep Convolutional Generative Adversarial Nets)\n",
    " * де-факто это cGAN, только для изображений, картинки похожи\n",
    "* StackGAN - порождающая состязательная сеть для генерации фото-реалистичных изображений исходя из текстового описания\n",
    "* LAPGAN (Laplacian Pyramid of Adversarial Networks)\n",
    "* ControlGAN (Controllable Generative Adversarial Networks)\n",
    "* AC-GAN Auxiliary Classifier Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Блок с мусором"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ниже - лекция Техносферы\n",
    "\n",
    "https://www.youtube.com/watch?v=hPux6TVtM58%D0%BF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### План лекции\n",
    "1. Обучение без учителя и GAN\n",
    "2. Применения GAN\n",
    "* DCGAN\n",
    "* Domain transfer network\n",
    "* SRGAN\n",
    "* Text to image (StackedGAN)\n",
    "* Image to image (cGAN)\n",
    "3. Проблема плохих градиентов и подходы к решению\n",
    "* LSGAN\n",
    "* WGAN\n",
    "* BEGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация при размеченном датасете"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### Проблемы с размеченными датасетами\n",
    "* Данных много, но меток обычно мало/очень шумные/дорогие\n",
    "* Transfer learning - нетривиальная проблема\n",
    "* Распределение на обучающем множестве не совпадает с распределением ’in the wild’\n",
    "* Распределение данных меняется со временем/адаптируется к вашей системе\n",
    "##### Подходы к решению\n",
    "* Semi-supervised learning (в широком смысле)\n",
    "* Online learning (например: stock prediction) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Understanding data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Наша задача - научиться генерировать реалистичные изображения. Под generative modeling понимают решение двух задач.\n",
    "\n",
    "1. Понимание того, как устроено распределение $p_{data}(x)$\n",
    "2. Построение функции G, которая по заданному вектору будет генерировать изображение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning to generate Chairs, Tables and Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-06.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-07.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему получилось так удачно?** \n",
    "\n",
    "*Огромное количество информации на входе*\n",
    "\n",
    "\n",
    "1. категория семпла\n",
    "2. углы и повороты\n",
    "3. заданные параметры трансформаций\n",
    "4. сегментация\n",
    "\n",
    "**Можно ли автоматизировать извлечение этих фичей?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генеративно-состязательные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы изучаем окружающий мир, то у нас нет ответов что есть что, однако, со временем, мы учимся распознавать образы, речь, движения благодаря тому, что мы просто смотрим и слушаем! Если детям сказать \"Это собака\" - это ничтожно маленькая информация. \n",
    "\n",
    "Положим, если давать человеку бит в секунду, и, учитывая что человек живёт в среднем $10^9$ секунд, а так же то, что в мозге человека примерно $10^{14}$ нейронных связей, значит человек использует мозг на одну стотысячную. Откуда ему получить столько информации чтобы стать человеком? Изучать мир самому! Анализируя все входные источники своего тела: глаза, уши и так далее.\n",
    "\n",
    "Метки, к которым мы привыкли в курсе нейронных сетей, в изображении с глаз отсутствуют. То есть преимущественно мы учимся без учителя.\n",
    "\n",
    "Как подойти к такой задаче с помощью нейронных сетей?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поставим задачу генерации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы имеем неразмеченные данные, и хотим генерировать новые данные, которые будут удовлетворять следующим условиям:\n",
    "* Новые данные должны быть похожи на исходные\n",
    "* При этом не повторять их в точности (или повторять, при случайном стечении обстоятельств)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эволюция в генерации изображений лиц:\n",
    "\n",
    "<img src=\"face_evol.jpg\" alt=\"alttext\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**https://thispersondoesnotexist.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы обусловились о случайности, то нам эту случайность нужно реализовать. Как это сделать с нейронной сетью? В сетях, которые мы проходили при подаче экземпляра и фиксированных весах всегда получается один и тот же результат. Случайно изменять веса сети? Есть способ лучше - давать в качестве входа случайных шум."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![random_example.png](random_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему именно вектор? Почему не одно случайное число. Ответ прост: изменяя одно случайное число, мы будем перемещаться на очень небольшое расстояние и генерация будет однообразной. Поскольку мы физически не можем генерировать числа в бесконечных пределах, мы вынуждены использовать фиксированный диапазон.\n",
    "\n",
    "В одномерном случае, взяв диапазон [0,1] у нас всего одна размерность нашего перемещения.\n",
    "Если взять двухмерный, или трёхмерный случай, то у нас уже есть две и три **степени свободы**.\n",
    "\n",
    "То есть случайный шум большой размерности даёт нам больше объёма для генерации. Это называется **input latent space** - входное латентное простанство.\n",
    "\n",
    "Note: из-за неустоявшейся терминологии, случайное распределение на входе генератора называется латентным пространством, так же как и скрытое пространство в автоэнкодерах. Поэтому в этой лекции будем называть его **входным** латентным пространством. Так же встречается вариант: predefined latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Какую размерность и форму выбрать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Длина вектора (размерность латентного пространства) выбирается больше, чем количество разных\n",
    "независимых свойств объекта, которые мы хотим получить. Если длина 0, то случайности\n",
    "нет и генератор будет всегда производить один и тот же объект. Если длина 1, то будет\n",
    "шкала, вдоль которой будут расположены, например, генерируемые изображения. Для генератора\n",
    "лиц, это будет, в лучшем случае, шкала от молодой женщины блондинки к пожилому мужчине\n",
    "брюнету. Лучший способ выбрать длину вектора - это посмотреть похожую задачу в публикациях,\n",
    "взять подобную размерность, и начать экспериментировать с размерностью оттуда.\n",
    "\n",
    "У большого латентного пространства есть минусы: увеличивая размерность латентного пространства мы можем расширить его настолько, что при обучении модели точек в этом латентром пространстве будет настолько мало, что в основном пространство будет состоять из пустот. Тогда модель будет крайне некачественно \"понимать\" что ей нужно генерировать в точке, которой не было на обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичный вопрос встаёт и по поводу формы распределения входного латентного пространства. Как мы знаем из лекции про обучение сети, инициализация весов и нормализация имеют существенный вклад в работу модели. Поэтому, принято использовать многомерное нормальное распределение для input latent space, потому что оно лучше взаимодействует с весами модели и увеличивает сходимость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"MultivariateNormal.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генератор. Решаем задачу простым подходом.\n",
    "(как делать на практике не нужно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самым тривиальным решением кажется подача случайного шума на вход и реальные точки параболы будем ожидать на выходе. Проверим как это будет работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import Dataset, random_split\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pair(num=100):\n",
    "    x = np.random.uniform(low=-1, high=1, size=(num,))\n",
    "    y = x*x\n",
    "    return np.hstack((x.reshape(-1,1), y.reshape(-1,1))) # Создадим num корректных точек (x,y) на параболе\n",
    "\n",
    "pairs = gen_pair(100)\n",
    "plt.scatter(pairs[:,0], pairs[:,1])\n",
    "plt.title(\"Случайные точки на параболе, которые используем в качестве датасета.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим наши точки на параболе со случайным входным шумом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 10\n",
    "batch_size = 128\n",
    "ls = 3 # latent space\n",
    "\n",
    "noice = np.random.normal(size=(n_batches*batch_size, ls))\n",
    "noice = torch.tensor(noice, dtype=torch.float)\n",
    "print(f\"noice.shape: {noice.shape}\")\n",
    "\n",
    "xy_pair = gen_pair(num = n_batches*batch_size)\n",
    "xy_pair = torch.tensor(xy_pair, dtype=torch.float)\n",
    "print(f\"xy_pair.shape: {xy_pair.shape}\")\n",
    "\n",
    "dataset = TensorDataset(noice, xy_pair) # model inputs, model outputs\n",
    "\n",
    "len_tr = int(len(dataset)*0.8)\n",
    "len_tst = len(dataset) - len_tr\n",
    "trainset, testset = random_split(dataset,[len_tr,len_tst])\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_loss(model,test_loader,loss_function):\n",
    "    with torch.no_grad():\n",
    "        loss_test_total = 0\n",
    "        for samples, labels in test_loader:\n",
    "            outputs = model(samples.cuda())\n",
    "            loss = loss_function(outputs, labels.cuda())\n",
    "            loss_test_total += loss.item()\n",
    "        return loss_test_total/len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим простую модель, которая будет ожидать шум на вход, и генерировать точки на выходе. (Обратите внимание, что функция активации на последнем слое отсутствует, поскольку мы не ограничиваем наш генератор в каком-то диапазоне.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenModel(nn.Module):\n",
    "    def __init__(self, latent_space):\n",
    "        super().__init__()\n",
    "        self.latent_space = latent_space\n",
    "        self.fc1 = nn.Linear(self.latent_space, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.latent_space)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "model = NotWorkModel(latent_space = ls)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.L1Loss().cuda()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_epoch = 0\n",
    "    for samples, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(samples.cuda())\n",
    "        loss = loss_function(outputs.cuda(), labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.item()\n",
    "        \n",
    "    loss_test = get_test_loss(model,test_loader,loss_function)\n",
    "    if epoch%100==0:\n",
    "        print(f\"Epoch={epoch} train_loss={loss_epoch/len(train_loader):.4} test_loss={loss_test:.4}\")\n",
    "        # test_image(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим результаты генерации на шуме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image(model):\n",
    "    model.cpu()\n",
    "    noice = torch.tensor(np.random.normal(size=(1000, ls)), dtype=torch.float)\n",
    "    xy_pair_gen = model(noice)\n",
    "\n",
    "    xy_pair_gen = xy_pair_gen.detach().numpy()\n",
    "    plt.scatter(xy_pair_gen[:,0], xy_pair_gen[:,1])\n",
    "    plt.axis([-1, 1, 0, 1])\n",
    "    plt.show()\n",
    "    model.cuda()\n",
    "test_image(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Причина неудачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что модель обучается плохо. Давайте разберёмся почему. В одном сэмпле данных мы подаём конкретный шум и конкретную точку, в следующем сэмпле так же. Поскольку в качестве лосс-функции была выбрана L1Loss, то генерация модели по батчу будет устремлять градиент в усреднённую позицию, которая не будет соответствовать позиции точки на параболе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нужно придумать как сделать так, чтобы точки \"растолкать\" из области, где парабола отсутствует.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дискриминатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы решить проблему сильного разброса точек (оттолкнуть их от пустот) можно наказывать нейронную сеть не напрямую лосс функцией, а сетью, которая будет говорить нам что точка лежит на параболе или не лежит. Однако, проверять это условие анализируя пару x, y на принадлежность к параболе плохая идея. Потому что точки получаются из случайного шума и ожидать что они попадут точно в параболу мы не имеем права. Поскольку попадание должно быть выше чем точность типа данных (32-bit floating point для torch.float). Мы рискуем не получить в процессе обучения ни одной точки, попавшей в параболу. Нам нужно дейстовать мягче.\n",
    "\n",
    "Поэтому, определим сеть-классификатор точек (лежит/не лежит), которую назовём **дискриминатор**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 25)\n",
    "        self.fc2 = nn.Linear(15, 15)\n",
    "        self.fc3 = nn.Linear(15,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого мы имеем: генератор, выдающий точки то ли попадая в параболу, то ли не попадая в неё. А так же дискриминатор, который будет учиться их различать. Поэтому мы будем подавать на генератор синтетические правильные точки, считая их реальными, и точки, которые выдаёт генератор, считая их подделкой.\n",
    "\n",
    "Таким образом, генератор будет учиться подражать реальным данным, а дискриминатор будет учиться отличать реальные точки, от подделок. \n",
    "\n",
    "Мы пришли к идее генеративно-состязательных нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generative adversarial network (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G - генератор\n",
    "\n",
    "D - дискриминатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-15.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Математически - это игра двух игроков:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-16.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-17.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теоретические результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-18.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-19.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-20.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преимущества GAN**\n",
    "* Теоретические гарантии сходимости\n",
    "* Можно обучать обычным SGD\n",
    "* Решает в явном виде задачу generative modeling\n",
    "* Но неявным образом (нейросети)\n",
    "\n",
    "\n",
    "**Недостатки GAN**\n",
    "* Нестабильное обучение\n",
    "* Очень долгая сходимость\n",
    "* Mode-collapsing\n",
    "* Generator/Discriminator starvation\n",
    "* Поиск оптимальных параметров - pure luck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тем не менее, на практике GAN почти всегда дает заметные улучшения.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netD_step(netD, D_batch, loss_function, optimizer):\n",
    "    samples, labels = D_batch\n",
    "    optimizer.zero_grad()\n",
    "    outputs = netD(samples)\n",
    "    loss = loss_function(outputs, labels.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netGAN_step(netD, netG, GAN_batch, loss_function, optimizer):\n",
    "    samples, labels = GAN_batch\n",
    "    optimizer.zero_grad()\n",
    "    # netD.train(mode=False)\n",
    "    outputs = netD(netG(samples))\n",
    "    loss = loss_function(outputs, labels.unsqueeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # netD.train(mode=True)\n",
    "\n",
    "def train(netD, netG, num, batch_size, latent_dim, epochs, lossD, lossG, optD, optG):\n",
    "    for epoch in range(epochs+1):\n",
    "        train_loaderD, test_loaderD = getD_dataloaders(num, batch_size, netG, latent_dim)\n",
    "        train_loaderGAN, test_loaderGAN = getGAN_dataloaders(num, batch_size, latent_dim)\n",
    "\n",
    "        for D_batch, GAN_batch in zip(train_loaderD, train_loaderGAN):\n",
    "            netD_step(netD, D_batch, lossD, optD)\n",
    "            netGAN_step(netD, netG, GAN_batch, lossG, optG)\n",
    "\n",
    "        if epoch%500==0:\n",
    "            plot_dis_and_gen(netD, netG, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = gen_real(num = num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_from_gen = G_data_generate(netG, latent_dim, num, label = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как определить лосс функцию \"похожести\" изображения?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Автоэнкодеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея очень похожая на PCA: найти сжимающее отображение исходных данных (Encoder) в пространство меньшей размерности, такое, что из него возможно восстановить исходное изображение (Decoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-08.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наивный подход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Естественно, хочется взять MSE как лосс-функцию и попробовать оптимизировать.\n",
    "\n",
    "Но, к сожалению, результаты **не впечатляют.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-09.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, мы взяли слишком простой лосс, можно придумать что-то лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Глубокое распознавание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-10.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-11.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопросы\n",
    "\n",
    "* Как глубина влияет на степень реконструкции? (текстура, цвет, положение)\n",
    "* Каков эффект max-pooling?\n",
    "* Как можно использовать готовые классификаторы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эмпирические результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На практике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно работает, настроить параметры несложно.\n",
    "\n",
    "* Лучше всего использовать комбинацию loss-функций\n",
    "* Image-to-image loss: L1\n",
    "* Deep features loss: VGG 16/19\n",
    "* Регуляризация: total variation\n",
    "\n",
    "**Но можно еще лучше!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-22.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-23.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary Classifier GAN, или AC-GAN для краткости, является расширением GAN, который изменяет дискриминатор, чтобы предсказать метку класса данного изображения, а не получить его в качестве входных данных. \n",
    "\n",
    "Он имеет эффект стабилизации процесса обучения и позволяет генерировать большие высококачественные изображения, изучая представление в скрытом пространстве, которое не зависит от метки класса.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-51.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был предложен новый метод улучшения обучения выигрышей путем кондиционирования входных данных метками классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-input multi-output network:\n",
    "* Входные данные: встраивание класса и вектор шума\n",
    "* Выходы: двоичный классификатор (поддельные/реальные изображения) и многоклассовый классификатор (классы изображений)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-57.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация:\n",
    "* Generator\n",
    "* Discriminator\n",
    "* dual loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Архитектура описана таким образом, что дискриминатор и вспомогательный классификатор могут рассматриваться как отдельные модели, разделяющие веса моделей. На практике дискриминатор и вспомогательный классификатор могут быть реализованы в виде единой нейросетевой модели с двумя выходами.\n",
    "\n",
    "Первый вывод представляет собой единственную вероятность через сигмоидную функцию активации, которая указывает на “реальность” входного изображения и оптимизируется с использованием двоичной перекрестной энтропии, как обычная модель дискриминатора GAN.\n",
    "\n",
    "Второй вывод-это вероятность принадлежности изображения к каждому классу через функцию активации softmax, как и любая заданная многоклассовая классификационная нейросетевая модель, и оптимизируется с использованием категориальной кросс-энтропии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generator Model:**\n",
    "* Input: Random point from the latent space, and the class label.\n",
    "* Output: Generated image.\n",
    "\n",
    "**Discriminator Model:**\n",
    "* Input: Image.\n",
    "* Output: Probability that the provided image is real, probability of the image belonging to each known class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На приведенном ниже графике суммируются входные и выходные данные ряда условных грантов, включая AC-GAIN, обеспечивая некоторый контекст для различий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-56.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCGAN использует сверточные и сверточно-транспонированные (convolutional and convolutional-transpose) слои в дискриминаторе и генераторе соответственно. \n",
    "\n",
    "Впервые он был описан Рэдфордом и др. в статье \"Обучение неконтролируемому представлению с помощью Глубоких Сверточных генеративных состязательных сетей\". Дискриминатор состоит из чередующихся слоев свертки, слоев пакетной нормы и активаций LeakyReLU. \n",
    "\n",
    "**input ** - это входное изображение размером 3x64x64, а output -скалярная вероятность того, что вход получен из реального распределения данных.** \n",
    "\n",
    "Генератор состоит из сверточно-транспонированных слоев, слоев пакетной нормы и активаций ReLU. Входным сигналом является скрытый вектор z, который берется из стандартного нормального распределения, а выходным-изображение RGB размером 3x64x64.\n",
    "\n",
    "Шаговые конвективные слои позволяют латентному вектору трансформироваться в объем той же формы, что и изображение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-24.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-25.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-50.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-49.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Интерполяция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-26.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain transfer network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-27.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-28.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Super resolution GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-29.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-30.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-31.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-32.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-33.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-34.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-35.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-36.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Иллюстрации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-37.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-38.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблемы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual**\n",
    "* Mode-collapsing\n",
    "* Instability (long run)\n",
    "* Noise generation (L1 лучше по началу)\n",
    "* Bad converging (подбор гиперпараметров - боль)\n",
    "\n",
    "\n",
    "**Возможно, проблема в том, что мы оптимизируем что-то не то?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-40.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-41.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-42.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-43.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Расстояние Вассерштейна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-44.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wasserstein > KL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-45.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-46.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СХОДИМОСТЬ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-47.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L13_GAN_cGAN/img/11-48.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@rangerscience/lets-read-science-stackgan-text-to-photo-realistic-image-synthesis-4562b2b14059\n",
    "\n",
    "https://arxiv.org/pdf/1612.03242v2.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1710.10916.pdf\n",
    "\n",
    "https://www.rulit.me/data/programs/resources/pdf/Generative-Adversarial-Networks-with-Python_RuLit_Me_610886.pdf\n",
    "\n",
    "видео\n",
    "\n",
    "https://www.youtube.com/watch?v=PXWIaLE7_NU\n",
    "\n",
    "https://www.youtube.com/watch?v=crI5K4RCZws\n",
    "\n",
    "гит\n",
    "\n",
    "https://github.com/zeusm9/Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAPGAN (Laplacian Pyramid of Adversarial Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1506.05751.pdf\n",
    "\n",
    "https://paperswithcode.com/method/lapgan\n",
    "\n",
    "https://sh-tsang.medium.com/review-lapgan-laplacian-generative-adversarial-network-gan-e87200bbd827\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ControlGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/mrlibw/ControlGAN\n",
    "\n",
    "https://github.com/taki0112/ControlGAN-Tensorflow\n",
    "\n",
    "статьи\n",
    "\n",
    "https://arxiv.org/pdf/1708.00598.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1909.07083.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1910.05774.pdf  многабукв\n",
    "\n",
    "https://meta-guide.com/data/data-processing/text-to-image-systems/natural-language-text-to-image-2019 множественные ссылки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AC-GAN Auxiliary Classifier Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "статьи\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-an-auxiliary-classifier-gan-ac-gan-from-scratch-with-keras/ можно брать материал\n",
    "https://towardsdatascience.com/understanding-acgans-with-code-pytorch-2de35e05d3e4\n",
    "\n",
    "https://arxiv.org/pdf/1909.05370.pdf\n",
    "\n",
    "https://openaccess.thecvf.com/content/WACV2021/papers/Kavalerov_A_Multi-Class_Hinge_Loss_for_Conditional_GANs_WACV_2021_paper.pdf\n",
    "\n",
    "гит\n",
    "\n",
    "https://github.com/lukedeo/keras-acgan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
