{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Alexander Iovlev.\n",
    "# Edited by Sergey Zapunidi\n",
    "# Edited by Andrey Marakulin\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU, Flatten, Dense\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose, Dropout\n",
    "from tensorflow.keras.layers import Embedding, Concatenate, Input, BatchNormalization\n",
    "from tensorflow.compat.v1.train import AdamOptimizer\n",
    "from tensorflow.keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "try:\n",
    "  logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "  print(f\"Physical GPUs {len(gpus)}\\nLogical GPUs {len(logical_gpus)}\")\n",
    "except RuntimeError as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note: For this case we use the Keras Functional API insted of Sequential API. It more flexible. See links for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(in_shape=(28,28,1), n_classes=10):\n",
    "    in_label = Input(shape=(1,))  # input layer\n",
    "    li = Embedding(n_classes, 50)(in_label)  # embedding for categorical input\n",
    "    n_nodes = in_shape[0] * in_shape[1]  # scale up to image dimensions\n",
    "    li = Dense(n_nodes)(li)\n",
    "    li = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "    in_image = Input(shape=in_shape)  # image input\n",
    "    merge = Concatenate()([in_image, li])\n",
    "    fe = Conv2D(filters=128,\n",
    "                kernel_size=(3,3),\n",
    "                strides=(2,2),\n",
    "                padding='same',\n",
    "                activation=LeakyReLU(alpha=0.2)\n",
    "                )(merge)  # downsample\n",
    "    fe = Conv2D(filters=128,\n",
    "                kernel_size=(3,3),\n",
    "                strides=(2,2),\n",
    "                padding='same',\n",
    "                activation=LeakyReLU(alpha=0.2)\n",
    "                )(fe)\n",
    "    fe = Flatten()(fe)  # Flatten feature maps\n",
    "    fe = Dropout(0.4)(fe)  # Regularization via dropout\n",
    "    out_layer = Dense(1, activation='sigmoid')(fe)  # Output\n",
    "    \n",
    "    model = Model([in_image, in_label], out_layer)  # Creating model\n",
    "    model.compile(optimizer=AdamOptimizer(learning_rate=0.0002, beta1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(latent_dim=100, n_classes=10):\n",
    "    in_label = Input(shape=(1,))  # label input\n",
    "    li = Embedding(n_classes, 50)(in_label) # embedding for categorical input\n",
    "    n_nodes = 7*7  # linear multiplication\n",
    "    li = Dense(n_nodes)(li)\n",
    "    li = Reshape((7, 7, 1))(li)\n",
    "    in_lat = Input(shape=(latent_dim,))  # image generator input\n",
    "    \n",
    "    n_nodes = 128*7*7  # foundation for 7x7 image\n",
    "    gen = Dense(n_nodes, activation=LeakyReLU(alpha=0.2))(in_lat)\n",
    "    gen = Reshape((7, 7, 128))(gen)\n",
    "    merge = Concatenate()([gen, li])  # merge image gen and label input\n",
    "    \n",
    "    gen = Conv2DTranspose(filters=128,\n",
    "                          kernel_size=(3,3),\n",
    "                          strides=(2,2),\n",
    "                          padding='same',\n",
    "                          activation=LeakyReLU(alpha=0.2)\n",
    "                          )(merge)  # upsampling to 14x14\n",
    "    gen = Conv2DTranspose(filters=128,\n",
    "                          kernel_size=(3,3),\n",
    "                          strides=(2,2),\n",
    "                          padding='same',\n",
    "                          activation=LeakyReLU(alpha=0.2)\n",
    "                          )(gen)  # updampling to 28x28\n",
    "    out_layer = Conv2D(filters=1,\n",
    "                       kernel_size=(7,7),\n",
    "                       activation='tanh',\n",
    "                       padding='same'\n",
    "                       )(gen)  # output\n",
    "    model = Model([in_lat, in_label], out_layer)  # define model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    # get noise and label inputs from generator\n",
    "    gen_noise, gen_label = generator.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = generator.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = discriminator([gen_output, gen_label])\n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=AdamOptimizer(learning_rate=0.0002, beta1=0.5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_data(dataset):\n",
    "    # Loading data\n",
    "    (X_train, y_train), (X_test, y_test) = dataset.load_data()\n",
    "    # We don't need separate test data so we can add it to our training data\n",
    "    X_train = np.concatenate((X_train, X_test), axis=0)\n",
    "    y_train = np.concatenate((y_train, y_test), axis=0)\n",
    "    # Conv2D awaits 3-dimensional input data (color channel) so, we must add 1 axis\n",
    "    X_train = np.expand_dims(X_train, axis=-1)\n",
    "    # Rescale our data from [0, 255] to [-1,1]\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_train = (X_train - 127.5) / 127.5\n",
    "    return [X_train, y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_real_batch(dataset, n_samples):\n",
    "    X_train, y_train = dataset\n",
    "    # Generate n random indexes\n",
    "    ix = np.random.randint(0, X_train.shape[0], n_samples)\n",
    "    # Select n random images from our imageset\n",
    "    X = X_train[ix]\n",
    "    labels = y_train[ix]\n",
    "    y = np.ones(n_samples)\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create n random latent-space vectors\n",
    "def gen_latent_vecs(n_samples, latent_dim=100, n_classes=10):\n",
    "    latent_vecs = np.random.normal(0, 1, [n_samples, latent_dim])\n",
    "    labels = np.random.randint(0, n_classes, n_samples)\n",
    "    return [latent_vecs, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fake_batch(generator, n_samples, latent_dim=100, n_classes=10):\n",
    "    [latent_vecs, labels] = gen_latent_vecs(n_samples, latent_dim, n_classes)\n",
    "    X = generator.predict([latent_vecs, labels])\n",
    "    y = np.zeros(n_samples)\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_batch(generator, dataset, batch_size, latent_dim=100, n_classes=10):\n",
    "    half_batch_size = batch_size // 2\n",
    "    # Get a half batch of real samples\n",
    "    [X_real, real_labels], y_real = gen_real_batch(dataset, half_batch_size)\n",
    "    # Get a half batch of fake samples\n",
    "    [X_fake, fake_labels], y_fake = gen_fake_batch(generator, half_batch_size, \\\n",
    "                                                   latent_dim, n_classes)\n",
    "    # Make a mixed batch\n",
    "    X = np.concatenate((X_real, X_fake), axis=0)\n",
    "    y = np.concatenate((y_real, y_fake), axis=0)\n",
    "    labels = np.concatenate((real_labels, fake_labels), axis=0)\n",
    "    # Shuffle real and fake images\n",
    "    shuffle = np.random.randint(0, batch_size, batch_size)\n",
    "    X = X[shuffle]\n",
    "    y = y[shuffle]\n",
    "    labels = labels[shuffle]\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generated_images(generator, h, w, latent_dim=100):\n",
    "    n = h*w\n",
    "    X, _ = gen_latent_vecs(n, latent_dim)\n",
    "    labels = np.asarray([x for _ in range(h) for x in range(w)])\n",
    "    y_p = generator.predict([X, labels])\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    for i in range(n):\n",
    "        plt.subplot(h, w, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"label: {}\".format(labels[i]))\n",
    "        plt.imshow(y_p[i, :, :, 0], cmap='gray_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, gan, dataset, latent_dim, n_epoches=100, \\\n",
    "          batch_size=128, n_classes=10):\n",
    "    X_train, y_train = dataset\n",
    "    n_batches = X_train.shape[0] // batch_size\n",
    "    half_batch_size = batch_size // 2\n",
    "\n",
    "    for i in range(n_epoches):\n",
    "        for j in range(n_batches):\n",
    "            # Train discriminator\n",
    "            [X_d, labels_d], y_d = gen_train_batch(generator, dataset, \\\n",
    "                                                   batch_size, latent_dim)\n",
    "            d_loss, d_acc = discriminator.train_on_batch([X_d, labels_d], y_d)\n",
    "            # Train generator\n",
    "            [X_gan, labels] = gen_latent_vecs(batch_size, latent_dim)\n",
    "            y_gan = np.ones(batch_size)\n",
    "            g_loss = gan.train_on_batch([X_gan, labels], y_gan)\n",
    "\n",
    "            print('\\rEpoch: >%d, Batch: %d/%d, Dis_loss=%.3f, Dis_accuracy=%.3f Gen_loss=%.3f' % (i+1, j+1, n_batches, d_loss, d_acc, g_loss), end='')\n",
    "        print()\n",
    "        if i == 0 or i == 1 or (i+1) % 20 == 0:\n",
    "            print_generated_images(generator, 4, 10, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅Задание\n",
    "\n",
    "С помощью функций написанных выше, задайте генератор, дискриминатор и обучите модель которая будет генерировать цифры Mnist по условию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "# Write down your code here"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 1
}
