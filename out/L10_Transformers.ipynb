{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Ä–æ–∂–¥–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –≤—Ö–æ–¥–Ω–æ–π –Ω–∞—Ö–æ–¥–∏—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤–æ –º–Ω–æ–≥–∏—Ö –æ–±–ª–∞—Å—Ç—è—Ö –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: –æ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ –¥–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏–π –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è—Ö.\n",
    "\n",
    "–î–æ –Ω–µ–¥–∞–≤–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ seq2seq-–º–æ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤—ã–≤–∞–ª–∏—Å—å –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –∏–ª–∏ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö, –±–µ—Ä—è –∑–∞ –æ—Å–Ω–æ–≤—É –ø–æ–¥—Ö–æ–¥ encoder-decoder –∏ –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è. –í 2017 –≥–æ–¥—É –≤ —Å—Ç–∞—Ç—å–µ [¬´Attention Is All You Need¬ª üéì[arxiv]](https://arxiv.org/abs/1706.03762) –±—ã–ª–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ –º–µ—Ö–∞–Ω–∏–∑–º–∞—Ö –≤–Ω–∏–º–∞–Ω–∏—è, –Ω–∞–∑–≤–∞–Ω–Ω–∞—è\n",
    "Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –ø—Ä–æ—Å—Ç–µ–π—à–µ–º –≤–∞—Ä–∏–∞–Ω—Ç–µ –º–æ–¥–µ–ª—å seq2seq –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –¥–≤–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏: **Encoder** –∏ **Decoder**. Encoder –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Ç–æ–∫–µ–Ω–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç **hidden state**, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥–∞–µ—Ç—Å—è –Ω–∞ –≤—Ö–æ–¥ Decoder‚Äô–∞. Decoder, –≤ —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å, —Å–ª—É–∂–∏—Ç –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é.\n",
    "\n",
    "–ù–∞ –ø—Ä–∏–º–µ—Ä–µ –∑–∞–¥–∞—á–∏ –ø–µ—Ä–µ–≤–æ–¥–∞: –Ω–∞ –≤—Ö–æ–¥ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫—É –ø–æ–¥–∞–µ—Ç—Å—è —Ç–µ–∫—Å—Ç –Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–º —è–∑—ã–∫–µ. –¢–æ–≥–¥–∞ hidden state –º–æ–∂–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Å–º—ã—Å–ª —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –∑–∞—Ç–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ü–µ–ª–µ–≤–æ–º —è–∑—ã–∫–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/seq_to_seq_with_rnn.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë—ã–ª–æ –±—ã –∑–¥–æ—Ä–æ–≤–æ —Ç–∞–∫ –∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã —Å–∂–∞—Ç—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ –±—ã–ª–∏ –±–ª–∏–∑–∫–∏ –∫ —Å–∂–∞—Ç—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º.\n",
    "\n",
    "–ê –µ—â—ë —Ö–æ—Ä–æ—à–æ –±—ã –¥–æ–±–∏—Ç—å—Å—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Å–∂–∞—Ç—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–µ—Ä–µ—Å—Ç–∞–ª–∏ –±—ã—Ç—å —Ä–∞–≤–Ω–æ–∑–Ω–∞—á–Ω—ã–º–∏. –ß—Ç–æ–±—ã —É—á–∏—Ç—ã–≤–∞–ª—Å—è –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ–∫—Ä—É–∂–∞—é—â–∏–µ —Å–ª–æ–≤–∞. –¢–∞–∫, –¥–ª—è —Å–ª–æ–≤–∞ \"–º—ã\" –≥–æ—Ä–∞–∑–¥–æ –≤–∞–∂–Ω–µ–µ \"we\", –Ω–µ–∂–µ–ª–∏ \"bread\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/attention_vector.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ $h_N$ ‚Äî –±—É—Ç—ã–ª–æ—á–Ω–æ–µ –≥–æ—Ä–ª—ã—à–∫–æ —Å–µ—Ç–∏.\n",
    "\n",
    "**–ò–¥–µ—è:** –ø–æ—Å—Ç–∞–≤–∏—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å –ø–æ–≤–µ—Ä—Ö $h_1 ... h_4$, —á—Ç–æ–±—ã –≤–µ–∫—Ç–æ—Ä –≤ –¥–µ–∫–æ–¥–µ—Ä —à—ë–ª –∫–∞–∫ –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/seq2seq_encoder_decoder_with_attention.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://www.machinelearning.ru/wiki/images/1/19/Voron-ML-Attention-slides.pdf\">–ö.–í. –í–æ—Ä–æ–Ω—Ü–æ–≤, –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏ –º–æ–¥–µ–ª–∏ –≤–Ω–∏–º–∞–Ω–∏—è</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–æ–Ω—Ü–µ–ø—Ü–∏—è **attention** —Å–æ—Å—Ç–æ–∏—Ç –≤ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–∏, —á—Ç–æ –º–µ–∂–¥—É —Ç–æ–∫–µ–Ω–∞–º–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏. –ü—Ä–∏ —Ç–∞–∫–æ–º –ø–æ–¥—Ö–æ–¥–µ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –ø–µ—Ä–µ–¥–∞–µ—Ç –≤ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –Ω–µ –æ–¥–Ω–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –∫–æ–¥–∏—Ä—É—é—â–µ–µ –≤—Å—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ü–µ–ª–∏–∫–æ–º, –∞ –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏–π –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN + Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –ø—Ä–æ—à–ª–æ–π –ª–µ–∫—Ü–∏–∏ –º—ã —Ä–∞–±–æ—Ç–∞–ª–∏ —Å RNN –±–µ–∑ –≤–Ω–∏–º–∞–Ω–∏—è. –¢–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —ç—Ç–æ –±—É–¥–µ—Ç —Å–æ —Å–ª–æ–µ–º Attention.\n",
    "\n",
    "–ú–∞—Ç–µ—Ä–∏–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ [–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ PyTorch [doc]](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞, —á—Ç–æ–±—ã –ø–æ–∑–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Ç–∞—Ä–≥–µ—Ç–æ–≤. –°–¥–µ–ª–∞–µ–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å Lang –∏–∑ —Å–ª–æ–≤–∞—Ä–µ–π **—Å–ª–æ–≤–æ ‚Üí –∏–Ω–¥–µ–∫—Å** (`word2index`) **–∏ –∏–Ω–¥–µ–∫—Å ‚Üí —Å–ª–æ–≤–æ** (`index2word`), –∞ —Ç–∞–∫–∂–µ —Å—á–µ—Ç—á–∏–∫ –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ `word2count`, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –∑–∞–º–µ–Ω—ã —Ä–µ–¥–∫–∏—Ö —Å–ª–æ–≤ –ø–æ–∑–∂–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ Unicode, –ø–æ—ç—Ç–æ–º—É –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –º—ã –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–∏–º–≤–æ–ª—ã Unicode –≤ ASCII, —Å–¥–µ–ª–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ—á–Ω—ã–º–∏ –∏ —É–±–µ—Ä—ë–º –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def normalizeStringRu(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-—è–ê-–Ø!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ–ª–∏–º —Ñ–∞–π–ª –Ω–∞ —Å—Ç—Ä–æ–∫–∏, –∞ —Å—Ç—Ä–æ–∫–∏ ‚Äî –Ω–∞ –ø–∞—Ä—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/eng_rus_vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = (\n",
    "        open(\"%s_%s_vocab.txt\" % (lang1, lang2), encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "    )\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [l.split(\"\\t\")[:2] for l in lines]\n",
    "    eng = [normalizeString(s[0]) for s in pairs]\n",
    "    rus = [normalizeStringRu(s[1]) for s in pairs]\n",
    "    pairs = list(zip(rus, eng))\n",
    "\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å–æ–∫—Ä–∞—Ç–∏–º –¥–∞—Ç–∞—Å–µ—Ç –¥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ –¥–ª–∏–Ω–µ–µ 10 —Å–ª–æ–≤ –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \",\n",
    "    \"i m \",\n",
    "    \"he is\",\n",
    "    \"he s \",\n",
    "    \"she is\",\n",
    "    \"she s \",\n",
    "    \"you are\",\n",
    "    \"you re \",\n",
    "    \"we are\",\n",
    "    \"we re \",\n",
    "    \"they are\",\n",
    "    \"they re \",\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return (\n",
    "        len(p[0].split(\" \")) < MAX_LENGTH\n",
    "        and len(p[1].split(\" \")) < MAX_LENGTH\n",
    "        and p[1].startswith(eng_prefixes)\n",
    "    )\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(\"eng\", \"rus\", False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫-–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–∫–æ–¥–µ—Ä—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤—Ö–æ–¥–Ω–æ–π —Ç–æ–∫–µ–Ω –∏ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ. –ù–∞—á–∞–ª—å–Ω—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ç–æ–∫–µ–Ω ‚Äî —Ç–æ–∫–µ–Ω –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫–∏ <SOS>, –ø–µ—Ä–≤–æ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ ‚Äî –≤–µ–∫—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(\n",
    "            batch_size, 1, dtype=torch.long, device=device\n",
    "        ).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = self.forward_step(\n",
    "                decoder_input, decoder_hidden\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(\n",
    "                    -1\n",
    "                ).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return (\n",
    "            decoder_outputs,\n",
    "            decoder_hidden,\n",
    "            None,\n",
    "        )  # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–ª–æ–π Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–Ω–∞—á–∞–ª–∞ –º—ã –≤—ã—á–∏—Å–ª—è–µ–º **–Ω–∞–±–æ—Ä –≤–µ—Å–æ–≤ Attention**. –û–Ω–∏ –±—É–¥—É—Ç —É–º–Ω–æ–∂–µ–Ω—ã –Ω–∞ –≤—ã—Ö–æ–¥–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã —ç–Ω–∫–æ–¥–µ—Ä–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∑–≤–µ—à–µ–Ω–Ω–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏. –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —ç—Ç–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —á–∞—Å—Ç–∏ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø–æ–º–æ–≥–∞—Ç—å –¥–µ–∫–æ–¥–µ—Ä—É –≤—ã–±–∏—Ä–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞.\n",
    "\n",
    "–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ Attention –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è. –í –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤—Å–µ—Ö —Ä–∞–∑–º–µ—Ä–æ–≤, –∏ –¥–ª—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏—è —ç—Ç–æ–≥–æ —Å–ª–æ—è –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –í –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤—Å–µ –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –≤ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ.\n",
    "\n",
    "–ú–µ—Ö–∞–Ω–∏–∑–º **–∞–¥–¥–∏—Ç–∏–≤–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è** —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤:\n",
    "\n",
    "[[arxiv] üéì Neural Machine Translation by Jointly Learning to Align and Translate (Bandanau et al., 2016)](https://arxiv.org/abs/1409.0473)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large a(h, h') = \\color{red}{w}^Tth(\\color{red}{U}h + \\color{red}{V}h')$ ‚Äî –∞–¥–¥–∏—Ç–∏–≤–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —Å $\\color{red}{w, U, V}$.\n",
    "\n",
    "–í –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–µ –≤–µ–∫—Ç–æ—Ä–∞ $h$ –∏ $h'$ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É—é—Ç—Å—è, —Ç.–µ. –æ–ø–µ—Ä–∞—Ü–∏—è –≤—ã—à–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∫:\n",
    "\n",
    "$\\large a(h, h') = \\color{red}{w}^Tth(\\color{red}{\\Omega}[h;h'])$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(\n",
    "            batch_size, 1, dtype=torch.long, device=device\n",
    "        ).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(\n",
    "                    -1\n",
    "                ).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ–±—É—á–µ–Ω–∏—é"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö**\n",
    "\n",
    "–î–ª—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä (–∏–Ω–¥–µ–∫—Å—ã —Å–ª–æ–≤ –≤–æ –≤—Ö–æ–¥–Ω–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏) –∏ —Ü–µ–ª–µ–≤–æ–π —Ç–µ–Ω–∑–æ—Ä (–∏–Ω–¥–µ–∫—Å—ã —Å–ª–æ–≤ –≤ —Ü–µ–ª–µ–≤–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏). –ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç—Ç–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ –º—ã –¥–æ–±–∞–≤–∏–º —Ç–æ–∫–µ–Ω EOS –∫ –æ–±–µ–∏–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData(\"eng\", \"rus\", False)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, : len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, : len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(\n",
    "        torch.LongTensor(input_ids).to(device), torch.LongTensor(target_ids).to(device)\n",
    "    )\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, sampler=train_sampler, batch_size=batch_size\n",
    "    )\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏**\n",
    "\n",
    "–î–ª—è –æ–±—É—á–µ–Ω–∏—è –º—ã –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π –≤—ã—Ö–æ–¥ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ. –ó–∞—Ç–µ–º –¥–µ–∫–æ–¥–µ—Ä –ø–æ–ª—É—á–∞–µ—Ç —Ç–æ–∫–µ–Ω <SOS> –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–¥–∞ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–µ—Ä–≤–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion\n",
    "):\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (- %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è**:\n",
    "\n",
    "* –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–∞–π–º–µ—Ä\n",
    "* –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã –∏ loss\n",
    "* –°–æ–∑–¥–∞—Ç—å –Ω–∞–±–æ—Ä –æ–±—É—á–∞—é—â–∏—Ö –ø–∞—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "\n",
    "def train(\n",
    "    train_dataloader,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    n_epochs,\n",
    "    learning_rate=0.001,\n",
    "    print_every=100,\n",
    "    plot_every=100,\n",
    "):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(\n",
    "            train_dataloader,\n",
    "            encoder,\n",
    "            decoder,\n",
    "            encoder_optimizer,\n",
    "            decoder_optimizer,\n",
    "            criterion,\n",
    "        )\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(\n",
    "                \"%s (%d %d%%) %.4f\"\n",
    "                % (\n",
    "                    timeSince(start, epoch / n_epochs),\n",
    "                    epoch,\n",
    "                    epoch / n_epochs * 100,\n",
    "                    print_loss_avg,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "plt.switch_backend(\"agg\")\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(\n",
    "            encoder_outputs, encoder_hidden\n",
    "        )\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append(\"<EOS>\")\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –º–æ–∂–µ–º –æ—Ü–µ–Ω–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print(\"RUS\", pair[0])\n",
    "        print(\"ENG\", pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = \" \".join(output_words)\n",
    "        print(\"DNN\", output_sentence)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap=\"bone\")\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    # prepare number of positions on the axes\n",
    "    x_ticks = []\n",
    "    y_ticks = []\n",
    "    for i in range(0, len(input_sentence.split(\" \")) + 2):\n",
    "        x_ticks.append(i)\n",
    "    for i in range(0, len(output_words) + 1):\n",
    "        y_ticks.append(i)\n",
    "\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels([\"\"] + input_sentence.split(\" \") + [\"<EOS>\"], rotation=90)\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.set_yticklabels([\"\"] + output_words)\n",
    "\n",
    "    # # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder, decoder, input_sentence, input_lang, output_lang\n",
    "    )\n",
    "    print(\"input =\", input_sentence)\n",
    "    print(\"output =\", \" \".join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, : len(output_words), :])\n",
    "\n",
    "\n",
    "#evaluateAndShowAttention(\"–∑–∞–¥–∞—á–∞ —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ–±—ã —É—á–∏—Ç—å—Å—è\")\n",
    "evaluateAndShowAttention(\"—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–º–µ–Ω —á—Ç–æ–±—ã —ç—Ç–æ–≥–æ –Ω–µ –¥–µ–ª–∞—Ç—å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É \"–∑–∞–±—ã–≤–∞–Ω–∏—è\" –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏. –ù–æ —Ü–µ–Ω–∞ —ç—Ç–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è ‚Äî –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–µ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Å —Ä–æ—Å—Ç–æ–º –¥–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å **–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è RNN** —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç **$O(bn d^2)$**, –≥–¥–µ $b$ ‚Äî —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, $n$ ‚Äî –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ $d$ ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. –ß–∞—Å—Ç—å $d^2$ –æ–±—É—Å–ª–æ–≤–ª–µ–Ω–∞ –º–∞—Ç—Ä–∏—á–Ω—ã–º –ø–µ—Ä–µ–º–Ω–æ–∂–µ–Ω–∏–µ–º –≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞ RNN.\n",
    "\n",
    "–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å **–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è attention** –≤ –ø—Ä–æ—Å—Ç–µ–π—à–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç $O(bn^2 d)$, —Ç–æ –µ—Å—Ç—å —Ä–∞—Å—Ç–µ—Ç –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ –ø—Ä–∏ —Ä–æ—Å—Ç–µ –¥–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ $n$. –≠—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—Ç—Å—è —Ç–µ–º, —á—Ç–æ –¥–ª–∏–Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–≤–Ω–∞ –¥–ª–∏–Ω–µ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ $n$, –∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã attention —Å–æ –≤—Å–µ–º–∏ –≤—Ö–æ–¥–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏. –°–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–∞—Å—á–µ—Ç–∞ –æ–¥–Ω–æ–≥–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –≤ –ø—Ä–æ—Å—Ç–µ–π—à–µ–º —Å–ª—É—á–∞–µ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç $O(d)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/transformer_table.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –æ–¥–Ω–æ–≥–æ —Å–ª–æ—è, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π (–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–ª—å–∑—è —Ä–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏—Ç—å), –º–∞–∫—Å–∏–º–∞–ª—å–Ω—è –¥–ª–∏–Ω–∞ –ø—É—Ç–∏ —Å–∏–≥–Ω–∞–ª–∞ –≤ —Å–µ—Ç–∏ –æ—Ç –≤—ã—Ö–æ–¥–∞ –∫ –≤—ã—Ö–æ–¥—É</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://brunomaga.github.io/AI-Supercomputing-2\"> AI Supercomputing (part 2): Encoder-Decoder, Transformers, BERT, Sharding, and model compression</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ù–∏ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏, –Ω–∏ attention –Ω–µ –º–æ–≥—É—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏.** RNN/LSTM \"–∑–∞–±—ã–≤–∞—é—Ç\" –Ω–∞—á–∞–ª–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∞ attention –ø—Ä–æ—Å—Ç–æ –Ω–µ –º–æ–∂–µ—Ç –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–∞—Å—á–µ—Ç –∑–∞ —Ä–∞–∑—É–º–Ω–æ–µ –≤—Ä–µ–º—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–∞–∑–Ω–æ–≤–∏–¥–Ω–æ—Å—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–π —Å—Ö–æ–¥—Å—Ç–≤–∞\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large a(h, h') = h^Th'$ ‚Äî —Å–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ (–≤–µ–∫—Ç–æ—Ä—ã –±–ª–∏–∑–∫–∏—Ö —Å–ª–æ–≤ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã);\n",
    "\n",
    "$\\large a(h, h') = \\mu * exp(h^Th')$ ‚Äî –≤–æ–∑–º–æ–∂–Ω—ã —Å—Ç–µ–ø–µ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏, –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–ª–º–Ω–æ–∂–µ–Ω–∏—è –Ω–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É;\n",
    "\n",
    "$\\large a(h, h') = h^T\\color{red}{W}h'$ ‚Äî c –º–∞—Ç—Ä–∏—Ü–µ–π –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ $\\color{red}{W}$;\n",
    "\n",
    "$\\large a(h, h') = \\color{red}{w}^Tth(\\color{red}{U}h + \\color{red}{V}h')$ ‚Äî –∞–¥–¥–∏—Ç–∏–≤–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —Å $\\color{red}{w, U, V}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–≤–æ–¥—è –≤–Ω–∏–º–∞–Ω–∏–µ, –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏ –æ –Ω–µ–∫–æ—Ç–æ—Ä–æ–π **—Ñ—É–Ω–∫—Ü–∏–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞** –º–µ–∂–¥—É **—Ç–µ–∫—É—â–∏–º** —Å–∫—Ä—ã—Ç—ã–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ $h'$ –∏ **–≤—Å–µ–º–∏** —Å–∫—Ä—ã—Ç—ã–º–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ $h$. –û–±–æ–±—â–µ–Ω–∏–µ–º –º–µ—Ö–∞–Ω–∏–∑–º–∞ –≤–Ω–∏–º–∞–Ω–∏—è —è–≤–ª—è–µ—Ç—Å—è –≤–≤–µ–¥–µ–Ω–∏–µ  **–æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤**.\n",
    "\n",
    "–ö–∞–∫–∏–µ –≤–æ–æ–±—â–µ –±—ã–≤–∞—é—Ç —Ñ—É–Ω–∫—Ü–∏–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞?\n",
    "\n",
    "\n",
    "1.   –ü–µ—Ä–≤–æ–µ, —á—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç –≥–æ–ª–æ–≤—É ‚Äî –ø—Ä–æ—Å—Ç–æ —Å—á–∏—Ç–∞—Ç—å —Å–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ $h$ –∏ $h'$.\n",
    "2.   –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–µ–ø–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –∏–ª–∏ —É–º–Ω–æ–∂–µ–Ω–∏–µ –Ω–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É.\n",
    "\n",
    "–ü–µ—Ä–≤—ã–µ –¥–≤–∞ —Å–ø–æ—Å–æ–±–∞ –≤–æ–∑–º–æ–∂–Ω—ã, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å, —á—Ç–æ–±—ã $h$ –∏ $h'$ –∏–º–µ–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å.\n",
    "\n",
    "3.   –ú–æ–∂–Ω–æ –≤–≤–æ–¥–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ $W$.\n",
    "4.   –ú–æ–∂–Ω–æ –≤–≤–æ–¥–∏—Ç—å –Ω–µ–±–æ–ª—å—à—É—é –¥–≤—É—Ö—Å–ª–æ–π–Ω—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤–µ—Å–æ–≤—ã–º–∏ –º–∞—Ç—Ä–∏—Ü–∞–º–∏. –¢–∞–∫–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –∞–¥–¥–∏—Ç–∏–≤–Ω—ã–º –≤–Ω–∏–º–∞–Ω–∏–µ–º.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key, Query, Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "–ß–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º –ø–æ–¥—Ö–æ–¥–æ–º —è–≤–ª—è–µ—Ç—Å—è –≤–≤–µ–¥–µ–Ω–∏–µ —Ç—Ä–µ—Ö —Ç–∏–ø–æ–≤ –≤–µ–∫—Ç–æ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–∑—ã–≤–∞—é—Ç **Query**, **Key** –∏ **Value**.\n",
    "\n",
    "$q$ ‚Äî –≤–µ–∫—Ç–æ—Ä-–∑–∞–ø—Ä–æ—Å, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ —Ö–æ—Ç–∏–º –≤—ã—á–∏—Å–ª–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç [–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫]\n",
    "\n",
    "$K = (k_1,..., k_n)$ ‚Äî –≤–µ–∫—Ç–æ—Ä—ã-–∫–ª—é—á–∏, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã–µ —Å –∑–∞–ø—Ä–æ—Å–æ–º [–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫]\n",
    "\n",
    "$V = (v_1,..., v_n)$ ‚Äî –≤–µ–∫—Ç–æ—Ä—ã-–∑–Ω–∞—á–µ–Ω–∏—è, –æ–±—Ä–∞–∑—É—é—â–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç [–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –∑–∞–¥–∞—á—É –ø–µ—Ä–µ–≤–æ–¥–∞**\n",
    "\n",
    "–Ø –≤–∏–¥–µ–ª –º–æ—Ö–Ω–∞—Ç–æ–≥–æ –∫–æ—Ç—é –Ω–∞ –ª–µ–∂–∞–Ω–∫–µ. ------> I saw furry **cat** on the bed.\n",
    "\n",
    "* query: cat\n",
    "\n",
    "* K: ['–Ø', '–≤–∏–¥–µ–ª', '–º–æ—Ö–Ω–∞–Ω—Ç–æ–≥–æ', '–∫–æ—Ç—é', '–Ω–∞', '–ª–µ–∂–∞–Ω–∫–µ', '.'] -> ['0', '0', '0.6', '1', '0', '0', '0']\n",
    "\n",
    "* V: ['–Ø', '–≤–∏–¥–µ–ª', '–º–æ—Ö–Ω–∞–Ω—Ç–æ–≥–æ', '–∫–æ—Ç—é', '–Ω–∞', '–ª–µ–∂–∞–Ω–∫–µ', '.'] -> ['–Ø', '–≤–∏–¥–µ–ª', <font color='coral'>'–º–æ—Ö–Ω–∞–Ω—Ç–æ–≥–æ'</font>, <font color='darkred'>'–∫–æ—Ç—é'</font>, '–Ω–∞', '–º–∞—Ç–µ', '.']\n",
    "\n",
    "**–ò–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\large c = \\text{Attn}(q, K, V) =  \\Sigma_i v_{i} \\text{SoftMax}(a(k_i, q)),$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≥–¥–µ $a(k_i,q)$ ‚Äî –æ—Ü–µ–Ω–∫–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞ –∫–ª—é—á–∞ $k_i$ –∑–∞–ø—Ä–æ—Å—É $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large \\text{Attn}(Q, K, V) =  \\text{SoftMax}(\\dfrac{QK^{T}}{\\sqrt{d_K}})V$ ‚Äî –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ Attention –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –¥–ª—è –Ω–∞–±–æ—Ä–∞ –∑–∞–ø—Ä–æ—Å–æ–≤, —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤ –º–∞—Ç—Ä–∏—Ü—É $Q$. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –º—ã –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –º–∞—Ç—Ä–∏—á–Ω–æ–π —Ñ–æ—Ä–º–µ –∑–∞–ø–∏—Å–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**–õ–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤** **Query**, **Key** –∏ **Value**.\n",
    "\n",
    "–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –≤–µ–∫—Ç–æ—Ä–∞ –≤–≤–æ–¥–∏—Ç—Å—è —Å–≤–æ–µ –ª–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –¥–µ–ª–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä –≤ –∫–∞–∫–æ–º-—Ç–æ –¥—Ä—É–≥–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ. –í—Å–µ —Ç—Ä–∏ –æ–Ω–∏ –æ–±—ã—á–Ω–æ –ø—Ä–∏–≤–æ–¥—è—Ç—Å—è –∫ –æ–¥–Ω–æ–π –∏ —Ç–æ–π –∂–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, –æ–±–æ–∑–Ω–∞—á–µ–Ω–Ω–æ–π $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <table >\n",
    "     <tr>\n",
    "       <td>\n",
    "       \n",
    "$$\\large a(h_i, h^\\prime_{t-1}) = (\\color{red}{W_k}h_i)^T(\\color{red}{W_q}h^\\prime_{t-1}) / \\sqrt d$$\n",
    "\n",
    "$$\\large \\alpha_{ti} = \\text{SoftMax} \\space a(h_i, h^\\prime_{t-1})$$\n",
    "\n",
    "$$\\large c_t = \\Sigma_i \\alpha_{ti} \\color{red}{W_v} h_i$$\n",
    "\n",
    "$$ \\sum_{i=1}^{N}a_{ti} = 1,$$\n",
    "\n",
    "$$  0\\leqslant a_{ti} \\leqslant 1.$$\n",
    "\n",
    "$ \\large \\color{red}{W_q}_{d \\times dim(h^\\prime)}, \\color{red}{W_k}_{d \\times dim(h)}, \\color{red}{W_v}_{d \\times dim(h)}$ ‚Äî –º–∞—Ç—Ä–∏—Ü—ã\n",
    "\n",
    "–≤–µ—Å–æ–≤ Query, Key, Value, –ª–∏–Ω–µ–π–Ω—ã–µ —Å–ª–æ–∏ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ\n",
    "\n",
    " —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ $\\large d$).\n",
    "\n",
    "\n",
    "–í–æ–∑–º–æ–∂–Ω–æ —É–ø—Ä–æ—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: $\\large \\color{red}{W_k} \\equiv \\color{red}{W_v}$\n",
    "       \n",
    "</td>\n",
    "<td>\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/query_key_value.png\" width=\"250\">\n",
    "\n",
    "<center><em>Source: <a href=\"http://www.machinelearning.ru/wiki/images/1/19/Voron-ML-Attention-slides.pdf\">–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: –º–æ–¥–µ–ª–∏ –≤–Ω–∏–º–∞–Ω–∏—è –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã</a></em></center>\n",
    "        </td>\n",
    "     </tr>\n",
    "    </table>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏ Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/transformer_architecture.png\" width=\"450\"></center>\n",
    "\n",
    "<center><em>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/pdf/1706.03762.pdf\"> Attention Is All You Need</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Ü–µ–ª–∏–∫–æ–º –Ω–∞ –º–µ—Ö–∞–Ω–∏–∑–º–µ –≤–Ω–∏–º–∞–Ω–∏—è, –±–µ–∑ —Å–≤—ë—Ä—Ç–æ–∫ –∏ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤, –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º —Ä–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–Ω–∏—è –Ω–∞ GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ê–ª–≥–æ—Ä–∏—Ç–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <table >\n",
    "     <tr>\n",
    "       <td>\n",
    "\n",
    "–ü–æ—Ä—è–¥–æ–∫ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞-–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞:\n",
    "\n",
    "1. –î–æ–±–∞–≤–ª—è—é—Ç—Å—è –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã $p_i$:\n",
    "\n",
    "$\\qquad \\large h_i = x_i + p_i;$\n",
    "\n",
    "$\\qquad \\large H = (h_1, \\dots, h_n).$\n",
    "\n",
    "$\\qquad$ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: $dim \\ x_i, \\ p_i, \\ h_i = 512, \\ dim \\ H = 512 \\times n$\n",
    "\n",
    "2. –ú–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–µ —Å–∞–º–æ–≤–Ω–∏–º–∞–Ω–∏–µ:\n",
    "\n",
    "$\\qquad \\large h^j_i = Attn(\\color{red}{W^j_q}h_i, \\color{red}{W^j_k}H, \\color{red}{W^j_v}H).$\n",
    "\n",
    "$\\qquad$ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: $j = 1, \\dots, J=8, \\ dim \\ h^j_i = 64, \\ dim \\ W^j_q, \\ W^j_k, \\ W^j_k = 64 \\times 512 $\n",
    "\n",
    "3. –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è:\n",
    "\n",
    "$\\qquad \\large h'_i =  MH_j (h^j_i) \\equiv [h^1_i, \\dots, h^J_i].$\n",
    "\n",
    "$\\qquad$ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: $dim \\ h'_i = 512$\n",
    "\n",
    "4. –°–∫–≤–æ–∑–Ω–∞—è —Å–≤—è–∑–∫–∞ + –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞ —É—Ä–æ–≤–Ω—è:\n",
    "\n",
    "$\\qquad \\large h''_i =  LN(h'_i + h_i; \\color{red}{\\mu_1, \\sigma_1}).$\n",
    "\n",
    "$\\qquad$ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: $dim \\ h''_i, \\ \\mu_1, \\ \\sigma_1 = 512$\n",
    "\n",
    "5. –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω–∞—è 2-—Ö—Å–ª–æ–π–Ω–∞—è —Å–µ—Ç—å FFN:\n",
    "\n",
    "$\\qquad \\large h'''_i = \\color{red}{W_2}ReLU(\\color{red}{W_1}h''_i + \\color{red}{b_1}) + \\color{red}{b_2}.$\n",
    "\n",
    "$\\qquad$ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: $dim \\ W_1 = 2048\\times512, \\ dim \\ W_2 = 512\\times2048$\n",
    "\n",
    "6. –°–∫–≤–æ–∑–Ω–∞—è —Å–≤—è–∑—å + –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞ —É—Ä–æ–≤–Ω—è:\n",
    "\n",
    "$\\qquad \\large z_i = LN(h'''_i + h''_i; \\color{red}{\\mu_2, \\sigma_2}).$\n",
    "\n",
    "$\\qquad$ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: $dim \\ z_i, \\ \\mu_2, \\ \\sigma_2 = 512$\n",
    "       </td>\n",
    "        <td>\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/transformer_encoder.png\" width=\"200\"></center>\n",
    "\n",
    "<em>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞-–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞</em>\n",
    "\n",
    "<em>Source: <a href=\"http://www.machinelearning.ru/wiki/images/1/19/Voron-ML-Attention-slides.pdf\"> –ö.–í. –í–æ—Ä–æ–Ω—Ü–æ–≤, –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞\n",
    "\n",
    "–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏ –º–æ–¥–µ–ª–∏ –≤–Ω–∏–º–∞–Ω–∏—è</a></em>\n",
    "        </td>\n",
    "     </tr>\n",
    "    </table>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ —Å–ª–æ—è –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è LayerNorm, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–µ –ø–æ –æ–±—ä–µ–∫—Ç–∞–º –≤ –±–∞—Ç—á–µ, –∞ –ø–æ –∫–∞–∂–¥–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Layer Normalization\n",
    "\n",
    "$\\qquad  \\large x_i, \\ \\color{red}{\\mu}, \\ \\color{red}{\\sigma} \\in \\mathbb{R};$\n",
    "\n",
    "$\\qquad  \\large \\displaystyle LN_s(x; \\color{red}{\\mu}, \\ \\color{red}{\\sigma}) = \\color{red}{\\sigma_s} {{x_s - \\overline x} \\over \\sigma_x} + \\color{red}{\\mu_s}, \\ s = 1, \\dots, d;$\n",
    "\n",
    "$\\qquad \\displaystyle \\overline x = {1 \\over d} \\sum\\limits_{s}x_s$ –∏ $\\displaystyle \\sigma^2_x = {1 \\over d} \\sum\\limits_{s}(x_s - \\overline x)^2$ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏—è $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/power_norm.png\" width=\"400\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://proceedings.mlr.press/v119/shen20e/shen20e.pdf\">PowerNorm: Rethinking Batch Normalization in Transformers</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏—á–∏–Ω–∞: –≤ –∑–∞–¥–∞—á–∞—Ö NLP –¥–ª–∏–Ω—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Ä–∞–∑–Ω—è—Ç—Å—è, –ø–æ—ç—Ç–æ–º—É –Ω–∞ –∫–∞–∫–æ–π $d$ –¥–µ–ª–∏—Ç—å –≤ —Ñ–æ—Ä–º—É–ª–µ –≤—ã—à–µ ‚Äî –≤–æ–ø—Ä–æ—Å –æ—Ç–∫—Ä—ã—Ç—ã–π. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –æ—Ç –±–∞—Ç—á–∞ –∫ –±–∞—Ç—á—É –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏ –±—É–¥–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±—É–¥—É—Ç –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–Ω—É—Ç—Ä–∏ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —Å–ª–æ–∏ \"Self-Attention\", –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è, –∏–ª–∏ –∂–µ —Å–∞–º–æ–≤–Ω–∏–º–∞–Ω–∏—è.\n",
    "\n",
    "–ö–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∏–¥–µ—Ç –ø–æ —Å–≤–æ–µ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –≤ —ç–Ω–∫–æ–¥–µ—Ä–µ. –ò, —Ö–æ—Ç—è —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É —ç—Ç–∏–º–∏ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è–º–∏ –≤ —Å–ª–æ–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è, –≤ —Å–ª–æ–µ —Å–µ—Ç–∏ –ø—Ä—è–º–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —Ç–∞–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –Ω–µ—Ç, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è–º –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –≤–æ –≤—Ä–µ–º—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è —á–µ—Ä–µ–∑ —ç—Ç–æ—Ç —Å–ª–æ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Self-Attention** ‚Äì –∫–ª—é—á–µ–≤–∞—è —á–∞—Å—Ç—å –º–æ–¥–µ–ª–∏, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –Ω–∞—Ö–æ–¥–∏—Ç—å —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ (–∏–ª–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏ –≤ —Å–ª–æ–µ).\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table >\n",
    "     <tr>\n",
    "        <td><b style=\"font-size:60px\">\n",
    "        \n",
    "Attention</b>\n",
    "        </td>\n",
    "        <td><b style=\"font-size:60px\">\n",
    "        \n",
    "Self-attention</b></td>\n",
    "     </tr>\n",
    "     <tr>\n",
    "       <td>\n",
    "\n",
    "**–û—Ç–∫—É–¥–∞:** –∏–∑ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–µ–∫–æ–¥–µ—Ä–∞\n",
    "\n",
    "**–ö—É–¥–∞:** –≤–æ –≤—Å–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞\n",
    "       </td>\n",
    "      <td>\n",
    "\n",
    "**–û—Ç–∫—É–¥–∞:** –∏–∑ –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤ —Å–ª–æ–µ\n",
    "\n",
    "**–ö—É–¥–∞:** –≤–æ –≤—Å–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤ —Ç–æ–º –∂–µ —Å–ª–æ–µ\n",
    "        </td>\n",
    "     </tr>\n",
    "    </table>\n",
    "    </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/encoder_self_attention.gif\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">Lena Voita NLP Course</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[colab] ü•® –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –±–ª–æ–∫–Ω–æ—Ç –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ Self-Attention](https://colab.research.google.com/drive/1hXIQ77A4TYS4y3UthWF-Ci7V7vVUoxmQ?usp=sharing#scrollTo=twSVFOM9SopW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/qkv_explained.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/qkv_attention_formula.png\" width=\"400\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">Lena Voita NLP Course</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihead Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ò–¥–µ—è:** $J$ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤–Ω–∏–º–∞–Ω–∏—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ –æ–±—É—á–∞—é—Ç—Å—è –≤—ã–¥–µ–ª—è—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã –≤—Ö–æ–¥–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–∞—Å—Ç–∏ —Ä–µ—á–∏, —Å–∏–Ω—Ç–∞–∫—Å–∏–º, —Ñ—Ä–∞–∑–µ–æ–ª–æ–≥–∏–∑–º—ã):\n",
    "\n",
    "$\\large c_j = \\text{Attn}(\\color{red}{W^j_q}q, \\color{red}{W^j_k}H,\\color{red}{W^j_v}H, \\ j = 1, \\dots, j)$\n",
    "\n",
    "**–í–∞—Ä–∏–∞–Ω—Ç—ã** –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä:\n",
    "\n",
    "$\\large \\displaystyle c = {1 \\over j} \\sum\\limits^J_{j=1}c^j$ ‚Äî —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ;\n",
    "\n",
    "$\\large \\displaystyle c = [c^1 \\dots c^J]$ ‚Äî –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è;\n",
    "\n",
    "$\\large \\displaystyle c = [c^1 \\dots c^J]\\color{red}{W}$ ‚Äî –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –∫ –Ω—É–∂–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç–æ, –∫ –∫–∞–∫–∏–º —Å–ª–æ–≤–∞–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è gave –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏–µ. –í –æ–±—â–µ–º —Å–ª—É—á–∞–µ –≥–ª–∞–≥–æ–ª –º–æ–∂–µ—Ç –∏–º–µ—Ç—å —Å–≤—è–∑–∫—É —Å–æ –º–Ω–æ–≥–∏–º–∏ —á–∞—Å—Ç—è–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ö–∞–∫, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å –ø–æ–¥–ª–µ–∂–∞—â–∏–º, —Ç–∞–∫ –∏ —Å –ø—Ä–∏—á–∞—Å—Ç–∏—è–º–∏.\n",
    "\n",
    "–í –∏–¥–µ–∞–ª–µ, –Ω–∞–º –±—ã —Ö–æ—Ç–µ–ª–æ—Å—å –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ (attention) –Ω–∞ –≤—Å–µ —ç—Ç–∏ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏. –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–º –ø—Ä–æ—Å—Ç–æ –Ω–∞–¥–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ attention —Å–ª–æ–µ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ. –¢–æ–≥–¥–∞ –∫–∞–∂–¥—ã–π –∏–∑ –Ω–∏—Ö –±—É–¥–µ—Ç —É—á–∏—Ç—å —á—Ç–æ-–Ω–∏–±—É–¥—å —Å–≤–æ–µ –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å–æ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–º–∏ —Å–ª–æ—è–º–∏.\n",
    "\n",
    "* –ß—Ç–æ–±—ã –æ—Å—É—â–µ—Å—Ç–≤–∏—Ç—å –∑–∞–¥—É–º–∞–Ω–Ω–æ–µ, –≤–º–µ—Å—Ç–æ –æ–¥–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ query –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –Ω–∞–±–æ—Ä–æ–≤.\n",
    "\n",
    "* –ü—Ä–∏—á–µ–º –∫–∞–∂–¥—ã–π –Ω–∞–±–æ—Ä –±—É–¥–µ—Ç —Å—á–∏—Ç–∞—Ç—å—Å—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ–π.\n",
    "\n",
    "* –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ —Å–¥–µ–ª–∞–µ–º –¥–ª—è keys –∏ values. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–∫–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –≤–Ω—É—Ç—Ä–∏ keys, queries, values –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å **–æ–¥–∏–Ω–∞–∫–æ–≤—ã–º**.\n",
    "\n",
    "* –û–±–æ–∑–Ω–∞—á–∏–º —ç—Ç–æ —á–∏—Å–ª–æ –∫–∞–∫ $J$, –¥–∞–ª–µ–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏, –ø—Ä–∏ —ç—Ç–æ–º –≤–≤–µ–¥–µ–º –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å h —Ç–∞–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π attention.\n",
    "\n",
    "* –ù–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º —à–∞–≥–µ –º—ã –∏—Ö —Å–æ–µ–¥–∏–Ω—è–µ–º (–∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ–º).\n",
    "\n",
    "* –ü—Ä–∏ —ç—Ç–æ–º –º–æ–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ –ø—Ä–∏ —Ç–∞–∫–æ–º –ø–æ–¥—Ö–æ–¥–µ –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞ –±—É–¥–µ—Ç —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å—Å—è (–µ—Å–ª–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏ key, –∏ value, –∏ query –º—ã –ø–æ–¥–∞–µ–º –æ–¥–Ω–æ –∏ —Ç–æ–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞). –ï—Å–ª–∏ —Ö–æ—Ç–∏–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é —Ç–æ–∫–µ–Ω–∞, —Ç–æ –ø—Ä–∏–¥–µ—Ç—Å—è –ø–æ–ª—É—á–∞—Ç—å –ø–æ –º–µ–Ω—å—à–µ–π –º–µ—Ä–µ value –ø—É—Ç–µ–º –¥–æ–º–Ω–æ–∂–µ–Ω–∏—è –Ω–∞ –º–∞—Ç—Ä–∏—Ü—É, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–æ—Ç–æ—Ä–æ–π –ø–æ –≤—Ç–æ—Ä–æ–π –æ—Å–∏ –º–µ–Ω—å—à–µ ‚Äî **–≤—ã–ø–æ–ª–Ω—è—Ç—å –ø—Ä–æ–µ–∫—Ü–∏—é –Ω–∞—à–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –º–µ–Ω—å—à–µ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏**.\n",
    "\n",
    "* –í —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –º–æ–∂–Ω–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç—Ç–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –ø—Ä–∏ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ —Ä–∞–≤–Ω—è–ª–∞—Å—å –∏—Å—Ö–æ–¥–Ω–æ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/multihead_self_attention_layer.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Positional encoding**\n",
    "\n",
    "–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –≤–æ–∑–º–æ–∂–Ω—ã–π –º–∏–Ω—É—Å ‚Äî –Ω–µ–π—Ä–æ—Å–µ—Ç—å –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ –ø—Ä–∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ embedding. –≠—Ç–æ –º–æ–∂–µ—Ç –Ω–∞–º –º–µ—à–∞—Ç—å. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ –¥–≤–∞ it, —Ç–æ –æ–Ω–∏ —á–∞—Å—Ç–æ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ —Ä–∞–∑–Ω—ã–º —Å–ª–æ–≤–∞–º. –ü–æ—ç—Ç–æ–º—É —Ö–æ—Ç–µ–ª–æ—Å—å –±—ã —É–º–µ—Ç—å —É—á–∏—Ç—ã–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∑–∏—Ü–∏–∏. –î–ª—è —ç—Ç–æ–≥–æ –∫ $X$ –ø—Ä–∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ $Q$ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–∑–∏—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ–ª–∞–µ—Ç—Å—è —ç—Ç–æ —Ö–∏—Ç—Ä—ã–º –æ–±—Ä–∞–∑–æ–º: –º—ã –¥–æ–±–∞–≤–ª—è–µ–º –∫ –∫–∞–∂–¥–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ–∫—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é $sin$ –∏ $cos$ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏. **–ó–Ω–∞—á–µ–Ω–∏—è —Å—É–º–º–∏—Ä—É—é—Ç—Å—è, –∞ –Ω–µ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É—é—Ç—Å—è.**\n",
    "\n",
    "–í–µ–∫—Ç–æ—Ä $PE$, –∫–æ—Ç–æ—Ä—ã–π –º—ã –±—É–¥–µ–º –¥–æ–±–∞–≤–ª—è—Ç—å –∫ $X$, –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å—Å—è –ø–æ —Å–ª–µ–¥—É—é—â–µ–π —Ñ–æ—Ä–º—É–ª–µ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large p_{\\text{pos}, 2i} = \\sin \\left({\\dfrac {\\text{pos}} {10000^{2i/d}}}\\right)$$\n",
    "\n",
    "$$\\large p_{\\text{pos}, 2i+1} = \\cos \\left({\\dfrac {\\text{pos}} {10000^{2i/d}}}\\right)$$\n",
    "\n",
    "$\\text{pos}$ ‚Äî —ç—Ç–æ –ø–æ–∑–∏—Ü–∏—è —Ç–æ–∫–µ–Ω–∞\n",
    "\n",
    "$d$ ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π —Ç–æ–∫–µ–Ω–∞\n",
    "\n",
    "$i$ ‚Äî $i$-—Ç–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].detach()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(20)\n",
    "y = pe(\n",
    "    torch.zeros(1, 100, 20)\n",
    ")  # sequence of shape 100, every token of sequence has shape 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(np.arange(100), y[0, :, 0:4].data.numpy())\n",
    "plt.legend([\"dim %d\" % p for p in [1, 2, 3, 4]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∫–∞–∂–¥–∞—è –ø–æ–∑–∏—Ü–∏—è –∫–æ–¥–∏—Ä—É–µ—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º. –ü—Ä–∏ —ç—Ç–æ–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª–µ–≥–∫–æ –Ω–∞—Ö–æ–¥–∏—Ç—å —Å–ª–æ–≤–∞ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏ –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ (—É –Ω–∏—Ö –±—É–¥–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤–æ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –ø–æ –∫–∞–∫–æ–π-—Ç–æ –æ—Å–∏)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
    "plt.legend([\"dim %d\" % p for p in [4, 5, 6, 7]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—É –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –∫–∞–∂–¥—É—é –ø–æ–∑–∏—Ü–∏—é –∏ –ø–æ–Ω–∏–º–∞—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü–æ—á–µ–º—É –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–¥–Ω–æ —á–∏—Å–ª–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞?**\n",
    "\n",
    "–î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏–Ω–¥–µ–∫—Å—ã –º–æ–≥—É—Ç —Å–∏–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å—Å—è –ø–æ –≤–µ–ª–∏—á–∏–Ω–µ. –ï—Å–ª–∏ –≤—ã –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–æ –ª–µ–∂–∞–ª–æ –º–µ–∂–¥—É $0$ –∏ $1$, —ç—Ç–æ –º–æ–∂–µ—Ç —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω–∏ –±—É–¥—É—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –ø–æ-—Ä–∞–∑–Ω–æ–º—É.\n",
    "\n",
    "–ü–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ –≤–∏–¥–µ –≤–µ–∫—Ç–æ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏–±–∞–≤–ª—è–µ—Ç—Å—è –∫ —ç–º–±–µ–¥–¥–∏–Ω–≥—É —Ç–æ–∫–µ–Ω–∞. –≠—Ç–∏ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–æ–∂–Ω–æ –∫–∞–∫ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –∑–∞—Ä–∞–Ω–µ–µ (—Ç–∞–∫ –¥–µ–ª–∞–µ—Ç—Å—è –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–µ, —Å–º. –ø—Ä–∏–º–µ—Ä –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ), —Ç–∞–∫ –∏ –æ–±—É—á–∞—Ç—å, –∫–∞–∫ –≤ —Å–ª—É—á–∞–µ GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å —Ä–µ—à–∞–µ—Ç –¥–≤–µ –∑–∞–¥–∞—á–∏.\n",
    "\n",
    "1. MLM (masked language model), –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤. –î–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ –ø–æ—è–≤–ª—è–µ—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω **[MASK]**.\n",
    "\n",
    "2. NSP (Next Sentence Prediction), –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, —Å–ª–µ–¥—É–µ—Ç –ª–∏ —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–º. –î–ª—è —ç—Ç–æ–≥–æ –ø–æ—è–≤–ª—è–µ—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã [CLS] (–¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏) –∏ [SEP] (–¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–∞—é—Ç—Å—è –ø–∞—Ä–æ–π –∏ —Å–ª–µ–¥—É—é—Ç –¥—Ä—É–≥ –∑–∞ –¥—Ä—É–≥–æ–º).\n",
    "\n",
    "\n",
    "–°–µ—Ç—å —É—á–∏–ª–∞—Å—å –Ω–∞ –æ–±–æ–∏—Ö –∑–∞–¥–∞—á–∞—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.\n",
    "\n",
    "–î–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–ª–æ–π - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä. –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ, –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ NSP –≤—ã—Ö–æ–¥ —Ç–æ–∫–µ–Ω–∞ [CLS] –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –Ω–∞ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—É—é —Å–µ—Ç—å.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/bert.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–ª–∞–≥–æ–¥–∞—Ä—è –ø—Ä–æ—Ü–µ–¥—É—Ä–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏—è, BERT-–ø–æ–¥–æ–±–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –æ–±—É—á–∞—Ç—å—Å—è –±–µ–∑ —É—á–∏—Ç–µ–ª—è –Ω–∞ –æ–≥—Ä–æ–º–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–∞—Ö —Ç–µ–∫—Å—Ç–æ–≤, —Ç–µ–º —Å–∞–º—ã–º –∏–∑—É—á–∞–µ —Å—Ç—É–∫—Ç—É—Ä—É —è–∑—ã–∫–∞.\n",
    "\n",
    "–î–∞–ª–µ–µ, –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ BERT-–ø–æ–¥–æ–±–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–∞–∫:\n",
    "\n",
    "* –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏—Ö –≤—ã—Ö–æ–¥—ã –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π;\n",
    "\n",
    "* –¥–æ–æ–±—É—á–∞—Ç—å –ø–æ–¥ –Ω–∞—à–∏ –∑–∞–¥–∞—á–∏.\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ, –¥–ª—è –Ω–∞—á–∞–ª–∞ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "# model.cuda()  # uncomment it if you have a GPU\n",
    "\n",
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('BERT output shape:', embed_bert_cls('–ü—Ä–∏–≤–µ—Ç –º–∏—Ä', model, tokenizer).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–ª–∏ –∂–µ —á–µ—Ä–µ–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∑–∞–ø—É—Å–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –ø–æ–¥–∞–¥–∏–º 3 –ø—Ä–µ–¥–æ–∂–µ–Ω–∏—è –∏ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∏—Ö –≤–µ–∫—Ç–æ—Ä-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–æ–≤–ø–∞–¥–∞—é—Ç –ø–æ —Ä–∞–∑–º–µ—Ä—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('cointegrated/rubert-tiny2')\n",
    "sentences = [\"–ø—Ä–∏–≤–µ—Ç –º–∏—Ä\", \"hello world\", \"–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ–¥–ª–∏–Ω–Ω–µ–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\"]\n",
    "embeddings = model.encode(sentences)\n",
    "print('BERT output shape:', embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–æ—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ - –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å [pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task = \"sentiment-analysis\", model = 'blanchefort/rubert-base-cased-sentiment')\n",
    "type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\"–û—Ç–ª–∏—á–Ω–æ–µ –º–æ—Ä–æ–∑–Ω–æ–µ —É—Ç—Ä–æ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\"–û—Ç–ª–∏—á–Ω–æ–µ –º–æ—Ä–æ–∑–Ω–æ–µ —É—Ç—Ä–æ, —Ö–æ–ª–æ–¥ —Å–æ–±–∞—á–∏–π!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê —Ç–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –≤–æ–∑—å–º—ë–º –∑–∞–¥–∞—á–∫—É –ø–æ—Å–ª–æ–∂–Ω–µ–µ. –ò –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∑–≤—É–∫.\n",
    "\n",
    "–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ - \"zero-short learning\", —Ç.–µ. –º–æ–¥–µ–ª—å –Ω–µ –≤–∏–¥–µ–ª–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –ø–æ–¥–æ–±–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ashraq/esc50\")\n",
    "audio = next(iter(dataset[\"train\"][\"audio\"]))[\"array\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "display(Audio(audio, rate = 16000, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task=\"zero-shot-audio-classification\", model=\"laion/clap-htsat-unfused\")\n",
    "classifier(audio, candidate_labels=[\"Sound of a dog\", \"Sound of a bird\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á**\n",
    "\n",
    "–í [—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ HuggingFace](https://huggingface.co/docs/transformers/model_doc/bert) —É–∂–µ –∏–º–µ–µ—Ç—Å—è –º–Ω–æ–∂–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π, –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á:\n",
    "\n",
    "* Text Classification\n",
    "* Fill-Mask\n",
    "* Question Answering\n",
    "* ...\n",
    "\n",
    "–î–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏ –µ—Å—Ç—å —à–∞–±–ª–æ–Ω –º–æ–¥–µ–ª–∏, –≤ –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ –ø–æ–¥–∞—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç (–Ω–∞–∑–≤–∞–Ω–∏–µ).\n",
    "\n",
    "–ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ 6 –∫–ª–∞—Å—Å–æ–≤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-large')\n",
    "model = BertForSequenceClassification.from_pretrained('sberbank-ai/ruBert-large', num_labels=6).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ—Ä—ã —Å –æ–±—É—á–µ–Ω–∏–µ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "\n",
    "#from google.colab import files\n",
    "#files.upload()\n",
    "\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d 'shivamkushwaha/bbc-full-text-document-classification'\n",
    "!unzip DIRECTORY_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-large')\n",
    "model = BertForSequenceClassification.from_pretrained('sberbank-ai/ruBert-large').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"stevhliu/my_awesome_model\")\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stevhliu/my_awesome_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass your inputs to the model and return the `logits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"stevhliu/my_awesome_model\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the class with the highest probability, and use the model's `id2label` mapping to convert it to a text label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BertScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BERTScore**\n",
    "\n",
    "–û–¥–Ω–∞ –∏–∑ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫, [–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–∞—è Zhang et al.](https://arxiv.org/pdf/1904.09675.pdf) –≤ 2019 –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞. –û—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ –æ—Ü–µ–Ω–∫–µ –±–ª–∏–∑–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∏–∑ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏ BERT. –ß–∞—Å—Ç–∏—á–Ω–æ **—Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏ –æ–ø–µ—á–∞—Ç–æ–∫** –º–µ—Ç—Ä–∏–∫ BLEU –∏ ROUGE.\n",
    "\n",
    "–î–ª—è —Ä–∞—Å—á–µ—Ç–∞ BERTScore –±–ª–∏–∑–æ—Å—Ç—å –¥–≤—É—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π ‚Äì —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –º–æ–¥–µ–ª—å—é –∏ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ ‚Äì –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ —Å—É–º–º–∞ –∫–æ—Å–∏–Ω—É—Å–Ω—ã—Ö –ø–æ–¥–æ–±–∏–π –º–µ–∂–¥—É —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ —Å–ª–æ–≤, —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏—Ö —ç—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/architecture_bertscore.png\" width=\"1000\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://wiki.math.uwaterloo.ca/statwiki/index.php?title=BERTScore:_Evaluating_Text_Generation_with_BERT\">The Illustrated GPT-2 (BERTScore: Evaluating Text Generation with BERT)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ –æ—Å–Ω–æ–≤–µ –æ–±–æ–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è **Recall**, **Precision** –∏ **F1**:\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/bertscore_equations.png\" width=\"1000\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://wiki.math.uwaterloo.ca/statwiki/index.php?title=BERTScore:_Evaluating_Text_Generation_with_BERT\">The Illustrated GPT-2 (BERTScore: Evaluating Text Generation with BERT)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞—É—á–∏–º—Å—è —ç—Ç–æ –¥–µ–ª–∞—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "\n",
    "\n",
    "def getpreferredencoding(do_setlocale=True):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "\n",
    "!pip install -q evaluate\n",
    "!pip install -q bert_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–∑ –≤–∞–∂–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å—Ç–æ–∏—Ç [—É–ø–æ–º—è–Ω—É—Ç—å](https://huggingface.co/spaces/evaluate-metric/bertscore) –≤—ã–±–æ—Ä —è–∑—ã–∫–∞ –∏ —Ç–∏–ø –º–æ–¥–µ–ª–∏. –ü–æ-—É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `roberta-large`, –∏, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å 1.4G –ì–±, –º—ã –≤—ã—Å—Ç–∞–≤–ª—è–µ–º –±–æ–ª–µ–µ –º–µ–ª–∫—É—é –º–æ–¥–µ–ª—å –º–µ–Ω–µ–µ —á–µ–º –≤ 300 –ú–±."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "bertscore = load(\"bertscore\")\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = bertscore.compute(\n",
    "    predictions=predictions,\n",
    "    references=references,\n",
    "    lang=\"en\",\n",
    "    nthreads=-1,\n",
    "    batch_size=128,\n",
    "    model_type=\"distilbert-base-uncased\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ç–º–µ—Ç–∏–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–æ–≥–æ, —á—Ç–æ –º—ã –ø—Ä–∏–Ω–∏–º–∞–µ–º –∑–∞ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å. –ü–æ—ç—Ç–æ–º—É –Ω–∞–º –∏ –≤—ã–¥–∞—é—Ç –ø–∞—Ä—É —á–∏—Å–µ–ª."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n",
    "\n",
    "$\\large y_0 = \\langle {BOS} \\rangle$ ‚Äî —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–∏–º–≤–æ–ª–∞ –Ω–∞—á–∞–ª–∞.\n",
    "\n",
    "–î–ª—è –≤—Å–µ—Ö $t = 1, 2, \\dots$ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π:\n",
    "\n",
    "1. –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ \"–¥–∞–Ω–Ω—ã—Ö –∏–∑ –±—É–¥—É—â–µ–≥–æ\":\n",
    "\n",
    "$\\qquad \\large h_t = y_{t-1} + p_t;$\n",
    "\n",
    "$\\qquad \\large H_t = (h_1, \\dots, h_t).$\n",
    "\n",
    "2. –ú–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–µ —Å–∞–º–æ–≤–Ω–∏–º–∞–Ω–∏–µ:\n",
    "\n",
    "$\\qquad \\large h'_t = LN \\circ MH_j \\circ Attn(\\color{red}{W^j_q}h_t, \\color{red}{W^j_k}H_t, \\color{red}{W^j_v}H_t).$\n",
    "\n",
    "3. –ú–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫—É $Z$:\n",
    "\n",
    "$\\qquad \\large h''_t = LN \\circ MH_j \\circ Attn(\\color{red}{W^j_q}h'_t, \\color{red}{W^j_k}Z, \\color{red}{W^j_v}Z).$\n",
    "\n",
    "4. –î–≤—É—Ö—Å–ª–æ–π–Ω–∞—è –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–∞—è —Å–µ—Ç—å:\n",
    "\n",
    "$\\qquad \\large y_t = LN \\circ FFN(h''_t).$\n",
    "\n",
    "5. –õ–∏–Ω–µ–π–Ω—ã–π –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—â–∏–π —Å–ª–æ–π:\n",
    "\n",
    "$\\qquad \\large p(\\tilde w | t) SoftMax_{\\tilde w}(\\color{red}{W_y}y_t + b_y).$\n",
    "\n",
    "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è $\\tilde w_t = argmax(p(\\tilde w | t))$ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –ø–æ–∫–∞ $\\tilde w_t \\neq \\langle {EOS} \\rangle$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/transformer_decoder.png\" width=\"350\">\n",
    "\n",
    "<em>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞-–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞</em>\n",
    "\n",
    "<em>Source: <a href=\"http://www.machinelearning.ru/wiki/images/1/19/Voron-ML-Attention-slides.pdf\"> –ö.–í. –í–æ—Ä–æ–Ω—Ü–æ–≤, –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏ –º–æ–¥–µ–ª–∏ –≤–Ω–∏–º–∞–Ω–∏—è</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Self-Attention Layer\n",
    "\n",
    "\n",
    "–î–æ–ø—É—Å—Ç–∏–º,  —É –Ω–∞—Å —Å—Ç–æ–∏—Ç –ø—Ä–æ–±–ª–µ–º–∞, —á—Ç–æ –º—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –≤–∏–¥–µ—Ç—å —á–∞—Å—Ç—å —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ ‚Äî –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (–ø–æ —Ç–µ–∫—É—â–∏–º —Å–ª–æ–≤–∞–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ). –ù–∞–ø—Ä–∏–º–µ—Ä, —Ö–æ—Ç–∏–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ñ—Ä–∞–∑—É \"robot must obey orders\" –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ–≤–∞.\n",
    "\n",
    "–ï—Å–ª–∏ –º—ã –ø–æ–¥–∞–¥–∏–º –≤ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è —Å—Ä–∞–∑—É –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—Ç–∏–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å, —Ç–æ —É –Ω–∞—Å –≤ –ø–µ—Ä–≤—ã—Ö —Å–ª–æ–≤–∞—Ö –±—É–¥–µ—Ç \"–ø—Ä–æ—Ç–µ–∫–∞—Ç—å\" –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/queries_keys_scores_before_softmax.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –º—ã –º–æ–∂–µ–º –ø—Ä–æ—Å—Ç–æ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Å—Ç–∞—Ö –º–∞—Ç—Ä–∏—Ü—ã $E$ –ø–æ—Å—Ç–∞–≤–∏—Ç—å –º–∏–Ω—É—Å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏. –¢–æ–≥–¥–∞ –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –¥–æ–ª–∂–Ω—ã –∑–Ω–∞—Ç—å –æ –∫–∞–∫–∏—Ö-—Ç–æ —Å–ª–æ–≤–∞—Ö, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —ç—Ç–∏—Ö —Å–ª–æ–≤–∞—Ö –Ω–µ –±—É–¥–µ—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/scores_before_softmax_apply_attention_mask_masked_scores_before_softmax.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–æ—Å–ª–µ SoftMax \"–ª–∏—à–Ω—è—è\" –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/masked_scores_softmax_along_rows_scores.png\" width=\"800\">\n",
    "\n",
    "<em>Source: <a href=\"https://jalammar.github.io/illustrated-gpt2/\">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–ª–∞–≥–æ–¥–∞—Ä—è —ç—Ç–æ–º—É —Ç—Ä—é–∫—É —É –Ω–∞—Å –ø–æ–ª—É—á–∞–µ—Ç—Å—è –æ–±—É—á–∞—Ç—å transfomer –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –∫–∞–∫ –ø—Ä–æ—Å—Ç—É—é single-pass –Ω–µ–π—Ä–æ—Å–µ—Ç—å, –∞ –Ω–µ \"—Å–∫–∞—Ç—ã–≤–∞—Ç—å—Å—è\" –≤ RNN, –≥–¥–µ —É –Ω–∞—Å –≤–æ–∑–Ω–∏–∫–Ω—É—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ –∏ –≤—Ä–µ–º–µ–Ω–µ–º —Ä–∞–±–æ—Ç—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–ª–µ–µ —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ —Å—Ç–∞—Ç—å–µ [GPT –¥–ª—è —á–∞–π–Ω–∏–∫–æ–≤: –æ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –¥–æ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞](https://habr.com/ru/articles/599673/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–¢–∞–∫ —á—Ç–æ –∂–µ —Ç–∞–∫–æ–µ GPT?**\n",
    "* –≠—Ç–æ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è) —Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "* –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ ‚Äî —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –∏ –æ–±—É—á–µ–Ω–Ω–∞—è –≤ self-supervised —Ä–µ–∂–∏–º–µ –Ω–∞ –æ–≥—Ä–æ–º–Ω–æ–º [–∫–æ—Ä–ø—É—Å–µ](https://philology.by/about/yaskevich/corpus-linguistics-yaskevich) —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "**–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è GPT:**\n",
    "* [Improving Language Understanding by Generative Pre-Training (2018)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n",
    "* [Language Models are Unsupervised Multitask Learners (2019)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "* [Language Models are Few-Shot Learners (2020)](https://arxiv.org/pdf/2005.14165.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —Ä–∞–±–æ—Ç—ã —Å GPT –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å. –õ—É—á—à–∏–π –≤—ã–±–æ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞–º–∏ ‚Äî –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –æ—Ç **Hugging Face**: `transformers`, `tokenizers`, `datasets`.\n",
    "\n",
    "Hugging Face –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–µ–π –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤, –∞ —Ç–∞–∫–∂–µ —Ö—Ä–∞–Ω–∏—Ç –Ω–∞–±–æ—Ä—ã –≤–µ—Å–æ–≤ –∏ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö NLP-–∑–∞–¥–∞—á. –í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–π –º–æ–¥–µ–ª—å—é ruGPT3 –∏ –¥–æ–æ–±—É—á–∏–º –µ—ë.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£—Å—Ç–∞–Ω–æ–≤–∏–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers[torch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–±–µ—Ä–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –º–æ–¥–µ–ª—å. API –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π, –¥–ª—è –ø–æ–¥–º–µ–Ω—ã –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ `model_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loading and initialization of model and tokenizer\n",
    "model_name = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–Ø–∑—ã–∫–æ–≤–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ** ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞ (–∏–ª–∏ —á–∞—Å—Ç–∏ —Å–ª–æ–≤–∞) —Å —É—á—ë—Ç–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/yandex_search.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/599673/\">GPT –¥–ª—è —á–∞–π–Ω–∏–∫–æ–≤: –æ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –¥–æ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º–æ–¥–µ–ª—å—é –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –±—ã–ª–æ –≤–µ—Ä–Ω—ã–º –Ω–µ —Ç–æ–ª—å–∫–æ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏, –Ω–æ –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏, –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ —Ö–æ—Ä–æ—à–æ –ø–æ–Ω–∏–º–∞—Ç—å —Å–º—ã—Å–ª –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏, –∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ, –¥–∞–∂–µ –∏–º–µ—Ç—å –∑–Ω–∞–Ω–∏—è –æ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ.\n",
    "\n",
    "–≠—Ç–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∑–Ω–∞–Ω–∏—è –ø–æ–∑–≤–æ–ª—è—é—Ç –º–æ–¥–µ–ª–∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, —Å–æ–∑–¥–∞–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –º—ã —Ö–æ—Ç–∏–º –ø—Ä–∏ –ø–æ–º–æ—â–∏ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: **¬´–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2?¬ª**, —Ç–æ –º–æ–∂–µ–º –ø–æ–¥–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç:\\\n",
    "`¬´–í–æ–ø—Ä–æ—Å: –°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2? –û—Ç–≤–µ—Ç: ‚Ä¶ ¬ª`\\\n",
    "–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º —Ç–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –±—É–¥–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å, –ø–æ—ç—Ç–æ–º—É –º–æ–¥–µ–ª—å –¥–æ–ø–∏—à–µ—Ç `¬´4¬ª`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"–í–æ–ø—Ä–æ—Å: '–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2?'\\n–û—Ç–≤–µ—Ç:\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "out = model.generate(input_ids, do_sample=False, max_length=20, pad_token_id=20)\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Ö–æ–∂–∏–º —Å–ø–æ—Å–æ–±–æ–º –º–æ–∂–Ω–æ –∫—Ä–∞—Ç–∫–æ –ø–µ—Ä–µ—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ–∫—Å—Ç—ã, –µ—Å–ª–∏ –≤ –∫–æ–Ω—Ü–µ –¥–æ–ø–∏—Å—ã–≤–∞—Ç—å `¬´TL:DR¬ª`, —Ç.–∫. –º–æ–¥–µ–ª—å –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –∑–∞–ø–æ–º–Ω–∏–ª–∞, —á—Ç–æ –ø–æ—Å–ª–µ —ç—Ç–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏–¥—ë—Ç –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ. –ü–æ–¥–±–æ—Ä –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–π —Ç–µ–∫—Å—Ç–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è **¬´Prompt Engineering¬ª**. –¢–∞–∫–∞—è –ø—Ä–æ—Å—Ç–∞—è –∏–¥–µ—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–µ—à–∞—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á. –ò–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –º–Ω–æ–≥–∏–µ —Å—á–∏—Ç–∞—é—Ç GPT-3 –ø–æ–¥–æ–±–∏–µ–º —Å–∏–ª—å–Ω–æ–≥–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–∏–Ω –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —ç—Ç–∞–ø–æ–≤ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞ ‚Äî **—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è**. –ù–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã ‚Äî –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ —Å–ª–æ–≤–∞. –ó–∞—Ç–µ–º —Å–æ–∑–¥–∞–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä—å, –≤ –∫–æ—Ç–æ—Ä—ã–π –∑–∞–Ω–æ—Å—è—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ª–µ–∫—Å–µ–º—ã, –≤—Å—Ç—Ä–µ—Ç–∏–≤—à–∏–µ—Å—è –≤ –∫–æ—Ä–ø—É—Å–µ –∏–ª–∏ —Ç–µ–∫—Å—Ç–µ. –ù–∞ —ç—Ç–∏—Ö —ç—Ç–∞–ø–∞—Ö –º–æ–∂–Ω–æ —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º–∞ 1. –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è**\n",
    "\n",
    "–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ ‚Äî –Ω–∞–∑–Ω–∞—á–∏—Ç—å –∫–∞–∂–¥–æ–º—É —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É —Å–ª–æ–≤—É —Å–≤–æ—ë —á–∏—Å–ª–æ. –ù–æ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º–∞: —Å–ª–æ–≤ –∏ –∏—Ö —Ñ–æ—Ä–º –º–∏–ª–ª–∏–æ–Ω—ã, –∏ –ø–æ—ç—Ç–æ–º—É —Å–ª–æ–≤–∞—Ä—å —Ç–∞–∫–∏—Ö —Å–ª–æ–≤ –ø–æ–ª—É—á–∏—Ç—Å—è —á–µ—Ä–µ—Å—á—É—Ä –±–æ–ª—å—à–∏–º, –∞ —ç—Ç–æ –±—É–¥–µ—Ç –∑–∞—Ç—Ä—É–¥–Ω—è—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–ú–æ–∂–Ω–æ —Ä–∞–∑–±–∏–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞ —Å–ª–æ–≤–∞, –∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –±—É–∫–≤—ã (char-level tokenization), —Ç–æ–≥–¥–∞ –≤ —Å–ª–æ–≤–∞—Ä–µ –±—É–¥–µ—Ç –≤—Å–µ–≥–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–µ—Å—è—Ç–∫–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤, –ù–û –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ —É–∂–µ —Å–∞–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –±—É–¥–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º, –∞ —ç—Ç–æ —Ç–æ–∂–µ –∑–∞—Ç—Ä—É–¥–Ω—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º–∞ 2. –ë–æ–≥–∞—Ç–∞—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è**\n",
    "\n",
    "\"–ù–µ–π—Ä–æ—Å–µ—Ç—å\", \"—Å–µ—Ç–∫–∞\", \"—Å–µ—Ç—å\" —è–≤–ª—è—é—Ç—Å—è —Ä–∞–∑–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –Ω–æ –∏–º–µ—é—Ç —Å—Ö–æ–∂–∏–π —Å–º—ã—Å–ª. –≠—Ç—É –ø—Ä–æ–±–ª–µ–º—É –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏ –≤—Å–µ–≥–¥–∞ —Ä–µ—à–∞–ª —ç—Ç–∞–ø **—Å—Ç–µ–º–º–∏–Ω–≥–∞** (—É–¥–∞–ª–µ–Ω–∏–µ —Å—É—Ñ—Ñ–∏–∫—Å–∞, –ø—Ä–∏—Å—Ç–∞–≤–∫–∏, –æ–∫–æ–Ω—á–∞–Ω–∏—è) –∏–ª–∏ **–ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏** (–ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å–ª–æ–≤–∞ –∫ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–π —Ñ–æ—Ä–º–µ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º–∞ 3. –°–ª–æ–∂–Ω—ã–µ —Å–ª–æ–≤–∞**\n",
    "\n",
    "–ù–æ –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã —ç—Ç–∏ —ç—Ç–∞–ø—ã –Ω–µ —Ä–µ—à–∞—é—Ç. –í –≥–µ—Ä–º–∞–Ω—Å–∫–∏—Ö —è–∑—ã–∫–∞—Ö (–≤ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –Ω–µ–º–µ—Ü–∫–æ–º, —à–≤–µ–¥—Å–∫–æ–º –∏ —Ç.–¥.) –æ—á–µ–Ω—å –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ –æ–±—Ä–∞–∑—É—é—Ç—Å—è –Ω–æ–≤—ã–µ —Å–ª–æ–∂–Ω—ã–µ —Å–ª–æ–≤–∞. –ó–Ω–∞—á–µ–Ω–∏—è —Ç–∞–∫–∏—Ö —Å–ª–æ–≤ –≤—ã–≤–æ–¥—è—Ç—Å—è –∏–∑ –∑–Ω–∞—á–µ–Ω–∏—è –∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –ò—Ö –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ –¥–æ–ª–≥–æ, –∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∏–∑ –Ω–∏—Ö –Ω–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –≤ ¬´–±—É–º–∞–∂–Ω–æ–º¬ª —Å–ª–æ–≤–∞—Ä–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/swedish_word_example.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ü—Ä–∏–º–µ—Ä —à–≤–µ–¥—Å–∫–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –≥–∞–µ—á–Ω–æ–≥–æ –∫–ª—é—á–∞ –¥–ª—è –∫–æ–ª–µ—Å–∞ –º–æ—Ç–æ—Ü–∏–∫–ª–∞</a></em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://sysblok.ru/nlp/7250/\">–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —ç—Ç–∏–º–∏ —è–∑—ã–∫–∞–º–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–∞–∫–∂–µ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –Ω–∞ —ç—Ç–∞–ø–µ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è. –ü—Ä–∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ —Å–ª–æ–≤–∞—Ä—è –º–æ–¥–µ–ª–∏ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—É—é—Ç—Å—è –Ω–∞ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–æ, –µ—Å–ª–∏ –æ–Ω–æ –≤—Å—Ç—Ä–µ—Ç–∏–ª–æ—Å—å —á–∞—â–µ –ø—è—Ç–∏ —Ä–∞–∑), –ø–æ—ç—Ç–æ–º—É –Ω–µ –±—É–¥—É—Ç –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å —Ç–∞–∫–æ–µ –¥–ª–∏–Ω–Ω–æ–µ –∏ —Å–ª–æ–∂–Ω–æ–µ —Å–ª–æ–≤–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º–∞ 4: –ì—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤–∞**\n",
    "\n",
    "–î–ª—è –Ω–∞—Å, –ø—Ä–∏–≤—ã–∫—à–∏—Ö –∫ —è–∑—ã–∫–∞–º –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–≥–æ —Ç–∏–ø–∞, —Å–ª–æ–≤–æ ‚Äî —ç—Ç–æ –Ω–∞–±–æ—Ä –±—É–∫–≤ –º–µ–∂–¥—É –ø—Ä–æ–±–µ–ª–∞–º–∏ –∏ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è. –ù–æ –≤ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ –º–Ω–æ–≥–∏–µ —Å–ª–æ–∂–Ω—ã–µ —Å–ª–æ–≤–∞ –ø–∏—à—É—Ç—Å—è —Ä–∞–∑–¥–µ–ª—å–Ω–æ, –∞ –≤ —è–ø–æ–Ω—Å–∫–æ–º, –Ω–∞–æ–±–æ—Ä–æ—Ç, –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ –≤–æ–æ–±—â–µ –Ω–µ—Ç –ø—Ä–æ–±–µ–ª–æ–≤. –ü–æ—ç—Ç–æ–º—É —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ–∑–¥–∞—Ç—å –±—ã–ª–æ –Ω–µ–ª–µ–≥–∫–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–†–µ—à–µ–Ω–∏–µ ‚Äî Byte Pair Encoding**\n",
    "\n",
    "–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –∞–ª–≥–æ—Ä–∏—Ç–º –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ BPE –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª—è–º —É–∑–Ω–∞–≤–∞—Ç—å –∫–∞–∫ –º–æ–∂–Ω–æ –±–æ–ª—å—à–µ —Å–ª–æ–≤ –ø—Ä–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º –æ–±—ä–µ–º–µ —Å–ª–æ–≤–∞—Ä—è.\n",
    "\n",
    "1.   –°–ª–æ–≤–æ = –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤\n",
    "2.   –°–ª–æ–≤–∞—Ä—å = –≤—Å–µ —Ç–æ–∫–µ–Ω—ã\n",
    "3.   –ü–æ–≤—Ç–æ—Ä—è—Ç—å, –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è:\n",
    "\n",
    "     –ù–∞–∑–Ω–∞—á–∞–µ–º –Ω–æ–≤—ã–º —Ç–æ–∫–µ–Ω–æ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–≤—É—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä–æ–µ\n",
    "–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —á–∞—â–µ –¥—Ä—É–≥–∏—Ö –ø–∞—Ä –≤ –∫–æ—Ä–ø—É—Å–µ (–≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤–º–µ—Å—Ç–µ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ BPE –≤–æ–∑–º–æ–∂–Ω—ã —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã. –û–¥–∏–Ω –∏–∑ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö ‚Äì –∏–¥—ë–º –ø–æ –≤—Å–µ–º —Ç–æ–∫–µ–Ω–∞–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –Ω–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ —Ç–æ–∫–µ–Ω."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/subword_tokenization.png\" width = \"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://alexanderdyakonov.wordpress.com/2019/11/29/—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è-–Ω–∞-–ø–æ–¥—Å–ª–æ–≤–∞-subword-tokenization/\">–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –Ω–∞ –ø–æ–¥—Å–ª–æ–≤–∞ (Subword Tokenization)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–æ—Ç –∂–µ —Å–ø–æ—Å–æ–± –ø–æ–º–æ–≥–∞–µ—Ç —Ä–µ—à–∏—Ç—å **–ø—Ä–æ–±–ª–µ–º—É** **OOV (out of vocabulary)**. –í –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ –º–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å —Å–ª–æ–≤–∞ *Unfriendly*, –Ω–æ –ø–æ—Å–∫–æ–ª—å–∫—É **Unfriendly** = **Un** + **friend** + **ly**, –º—ã –º–æ–∂–µ–º —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—å, —á—Ç–æ —Å–µ—Ç—å –±—É–¥–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å / –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏ —Å–ª–æ–≤–æ —Ü–µ–ª–∏–∫–æ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/token_unfriendly.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.thoughtvector.io/blog/subword-tokenization/\">Subword Tokenization ‚Äî Handling Misspellings and Multilingual Data</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–æ –¥–∞–∂–µ —ç—Ç–æ –∏–Ω–æ–≥–¥–∞ –Ω–µ —Å–∞–º—ã–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä. –ß—Ç–æ–±—ã —Å–∂–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å –µ—â—ë —Å–∏–ª—å–Ω–µ–µ, –¥–ª—è –æ–±—É—á–µ–Ω–∏—è GPT OpenAI –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ **byte-level BPE** —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é. –≠—Ç–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è BPE —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ —Å —Ç–µ–∫—Å—Ç–æ–º, –∞ –Ω–∞–ø—Ä—è–º—É—é —Å –µ–≥–æ –±–∞–π—Ç–æ–≤—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–∞–∫–æ–≥–æ —Ç—Ä—é–∫–∞ –ø–æ–∑–≤–æ–ª–∏–ª–æ —Å–∂–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å –¥–æ –≤—Å–µ–≥–æ-–ª–∏—à—å ~50k —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–∏ —Ç–æ–º, —á—Ç–æ —Å –µ–≥–æ –ø–æ–º–æ—â—å—é –≤—Å—ë –µ—â—ë –º–æ–∂–Ω–æ –≤—ã—Ä–∞–∑–∏—Ç—å –ª—é–±–æ–µ —Å–ª–æ–≤–æ –Ω–∞ –ª—é–±–æ–º —è–∑—ã–∫–µ –º–∏—Ä–∞ (–∏ –¥–∞–∂–µ —ç–º–æ–¥–∑–∏)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -q transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loading and initialization of model and tokenizer\n",
    "model_name_or_path = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path).to(device)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–∏–º–µ—Ä —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ - —ç—Ç–æ –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ –∏ —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ\"\n",
    "tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in tokens]\n",
    "\n",
    "print(\"Original text:\", text)\n",
    "print(\"Tokens: \", tokens)\n",
    "print(\"Decoded tokens: \", decoded_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Byte-level —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä **–Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç**, —á—Ç–æ –¥–ª—è –ª—é–±–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –Ω–∞–π–¥–µ—Ç—Å—è **—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π** —Å–∏–º–≤–æ–ª –∏–ª–∏ —Å–ª–æ–≤–æ. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ **—Ç–æ–∫–µ–Ω—ã** **—Å—É—â–µ—Å—Ç–≤—É—é—Ç** —Ç–æ–ª—å–∫–æ **–≤ –∫–æ–º–±–∏–Ω–∞—Ü–∏—è—Ö**. –¢–∞–∫, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –Ω–µ –¥–µ–∫–æ–¥–∏—Ä—É—é—Ç—Å—è –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode([167]))\n",
    "print(tokenizer.decode([245]))\n",
    "print(tokenizer.decode([256]))\n",
    "\n",
    "print(tokenizer.decode([167, 245, 256]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é GPT –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å–ª–µ–¥—É—é—â–µ–µ:\n",
    "\n",
    "1. –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç—Å—è –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–∏—Å–µ–ª (—Ç–æ–∫–µ–Ω–æ–≤).\n",
    "2. –°–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ Embedding layer (–ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π) –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ —Å–ø–∏—Å–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\n",
    "3. –ö –∫–∞–∂–¥–æ–º—É —ç–º–±–µ–¥–¥–∏–Ω–≥—É –ø—Ä–∏–±–∞–≤–ª—è–µ—Ç—Å—è **positional embedding**.\n",
    "4. –°–ø–∏—Å–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ (Transformer Decoder Block).\n",
    "5. –ü–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø—Ä–æ–π–¥—ë—Ç —á–µ—Ä–µ–∑ –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫, —ç–º–±–µ–¥–¥–∏–Ω–≥, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Ç–æ–∫–µ–Ω—É, –º–∞—Ç—Ä–∏—á–Ω–æ —É–º–Ω–æ–∂–∞–µ—Ç—Å—è –Ω–∞ –≤—Å—ë —Ç–æ—Ç –∂–µ –≤—Ö–æ–¥–Ω–æ–π, –Ω–æ —É–∂–µ —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Embedding Layer, –∏ –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è SoftMax –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞.\n",
    "6. –ò–∑ —ç—Ç–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å –ø–æ–º–æ—â—å—é argmax)\n",
    "7. –ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Å–ø–∏—Å–∫—É —Ç–æ–∫–µ–Ω–æ–≤, —à–∞–≥–∏ 1-6 –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/gpt3.gif\" width=\"800\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://jalammar.github.io/how-gpt3-works-visualizations-animations/\">How GPT3 Works ‚Äî Visualizations and Animations</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–µ—Ç–µ–π, –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –Ω–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ –ø–æ—Ä—è–¥–∫—É –≤—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤, —Ç–æ –µ—Å—Ç—å –ø—Ä–∏ –ø–µ—Ä–µ–º–µ—à–µ–≤–∞–Ω–∏–∏ —Å–ª–æ–≤ –º–µ—Å—Ç–∞–º–∏ –≤—ã—Ö–æ–¥ –±—É–¥–µ—Ç –ø–æ–ª—É—á–∞—Ç—å—Å—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º (permutation invarience).\n",
    "\n",
    "–ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø–æ–∑–∏—Ü–∏—é –æ–±—ä–µ–∫—Ç–∞ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–∞–∫,  —á—Ç–æ –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü–æ—á–µ–º—É –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–¥–Ω–æ —á–∏—Å–ª–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞?**\n",
    "\n",
    "–î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏–Ω–¥–µ–∫—Å—ã –º–æ–≥—É—Ç —Å–∏–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å—Å—è –ø–æ –≤–µ–ª–∏—á–∏–Ω–µ. –ï—Å–ª–∏ –≤—ã –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–æ –ª–µ–∂–∞–ª–æ –º–µ–∂–¥—É $0$ –∏ $1$, —ç—Ç–æ –º–æ–∂–µ—Ç —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω–∏ –±—É–¥—É—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –ø–æ-—Ä–∞–∑–Ω–æ–º—É.\n",
    "\n",
    "–ü–æ—ç—Ç–æ–º—É –≤ GPT –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ –≤–∏–¥–µ –≤–µ–∫—Ç–æ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏–±–∞–≤–ª—è–µ—Ç—Å—è –∫ —ç–º–±–µ–¥–¥–∏–Ω–≥—É —Ç–æ–∫–µ–Ω–∞. –≠—Ç–∏ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–æ–∂–Ω–æ –∫–∞–∫ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –∑–∞—Ä–∞–Ω–µ–µ (—Ç–∞–∫ –¥–µ–ª–∞–µ—Ç—Å—è –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–µ, —Å–º. –ø—Ä–∏–º–µ—Ä –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ), —Ç–∞–∫ –∏ –æ–±—É—á–∞—Ç—å, –∫–∞–∫ –≤ —Å–ª—É—á–∞–µ GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/pos_encoding_visual.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ü–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/599673/\">GPT –¥–ª—è —á–∞–π–Ω–∏–∫–æ–≤: –æ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –¥–æ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —É –≤–∞—Å –µ—Å—Ç—å –≤—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª–∏–Ω—ã $L$, –∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–¥–∞—Ç—å –ø–æ–ª–æ–∂–µ–Ω–∏–µ $k$-—Ç–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –≤ —ç—Ç–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞–µ—Ç—Å—è —Ñ—É–Ω–∫—Ü–∏—è–º–∏ —Å–∏–Ω—É—Å–∞ –∏ –∫–æ—Å–∏–Ω—É—Å–∞ —Ä–∞–∑–ª–∏—á–Ω–æ–π —á–∞—Å—Ç–æ—Ç—ã:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(k, 2i) = sin (\\frac{k}{2^{2i/d}})$$\n",
    "\n",
    "$$P(k, 2i+1) = cos (\\frac{k}{2^{2i/d}})$$\n",
    "\n",
    "–≥–¥–µ $k$ ‚Äî –ø–æ–∑–∏—Ü–∏—è –æ–±—ä–µ–∫—Ç–∞ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, $\\displaystyle 0\\leq k< \\frac{L}{2}$,\n",
    "\n",
    "$d$ ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤,\n",
    "\n",
    "$P(k,j)$ ‚Äî —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –ø–æ–∑–∏—Ü–∏—é $k$ –≤ –∏–Ω–¥–µ–∫—Å $(k,j)$ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã,\n",
    "\n",
    "$n$ ‚Äî –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞, –æ–±—ã—á–Ω–æ —Ä–∞–≤–Ω–æ $10 000$ —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç–∞—Ç—å–µ *Attention is all You Need*,\n",
    "\n",
    "$i$ ‚Äî –∏–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏, $0 \\leq i < d/2$, –æ–¥–∏–Ω–∞–∫–æ–≤–æ –¥–ª—è —Å–∏–Ω—É—Å–∞ –∏ –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–∞.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Decoder Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ GPT —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Å–ª–æ—ë–≤ self-attention, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏, feed-forward –∏ residual connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/decoder_block.png\" width=\"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://ai-news.ru/2019/06/obobshennye_yazykovye_modeli.html\">–û–±–æ–±—â–µ–Ω–Ω—ã–µ –Ø–∑—ã–∫–æ–≤—ã–µ –ú–æ–¥–µ–ª–∏</a></em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ú–µ—Ç–æ–¥—ã –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞. –û–¥–Ω–∞–∫–æ —Å–ø–æ—Å–æ–±—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è. –î–∞–ª–µ–µ —Ä–∞–∑–±–µ—Ä—ë–º, –∫–∞–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –±—ã–≤–∞—é—Ç.\n",
    "\n",
    "–î–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞  \\\n",
    "`'–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: \"–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å\" ‚Äî —ç—Ç–æ'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: \"–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å\" - —ç—Ç–æ'\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—á–µ–≤–∏–¥–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç ‚Äî ArgMax-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è (–∂–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫). –í—ã–±–∏—Ä–∞–µ—Ç—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω.\n",
    "\n",
    "–ü—Ä–∏ —Ç–∞–∫–æ–º —Å–ø–æ—Å–æ–±–µ –º—ã –Ω–µ –ø–æ–ª—É—á–∏–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –∑–∞–ø—Ä–æ—Å, –∏, —á—Ç–æ –µ—â—ë —Ö—É–∂–µ, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–∂–µ—Ç –∑–∞—Å—Ç—Ä–µ–≤–∞—Ç—å –≤ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–∞—Ö –∏ –≤—ã–¥–∞–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä `the the the the ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArgMax is defaulf behaviour\n",
    "out = model.generate(input_ids, do_sample=False, max_length=30, pad_token_id=30)\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search\n",
    "–ù–µ—Å–∫–æ–ª—å–∫–æ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è ‚Äî **beam search**. –ö–∞–∂–¥—ã–π —Ä–∞–∑ –º—ã –≤—ã–±–∏—Ä–∞–µ–º –Ω–µ –æ–¥–∏–Ω —Å–∞–º—ã–π –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω, –∞ —Å—Ä–∞–∑—É –Ω–µ—Å–∫–æ–ª—å–∫–æ (`beam-size`), –∏ –¥–∞–ª—å—à–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–æ–∏—Å–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "\n",
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º —Å–æ–∑–¥–∞—ë—Ç—Å—è **–≥—Ä–∞—Ñ** —Å–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ **–≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π**. –î–∞–ª–µ–µ –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π **perplexity** (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞).\n",
    "\n",
    "–û–±—ã—á–Ω–æ —ç—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –≤—ã—Å–æ–∫–æ–π —Å–≤—è–∑–Ω–æ—Å—Ç–∏ (–∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏) —Ç–µ–∫—Å—Ç–∞, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –∫ —Å—É—Ö–æ—Å—Ç–∏ –∏ —Å–∫—É—á–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞. –¢–∞–∫–∂–µ —ç—Ç–æ –Ω–µ —Ä–µ—à–∞–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–±–ª–µ–º—É —Å –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º–∏ –∫—É—Å–æ—á–∫–æ–≤ —Ç–µ–∫—Å—Ç–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/beam_search.png\" width=\"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/599673/\">GPT –¥–ª—è —á–∞–π–Ω–∏–∫–æ–≤: –æ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –¥–æ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation with beam-search\n",
    "out = model.generate(\n",
    "    input_ids, do_sample=False, num_beams=5, max_length=30, pad_token_id=30\n",
    ")\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç—É –Ω–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç–∏ –∏ —á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç–∏, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–µ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –Ω–µ —Å–∞–º—ã–π –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω, –∞ —Å–ª—É—á–∞–π–Ω—ã–π, —Å —É—á—ë—Ç–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π.\n",
    "\n",
    "–ü–∞—Ä–∞–º–µ—Ç—Ä —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–µ–ø–µ–Ω—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏. –ü—Ä–∏ –Ω—É–ª–µ–≤–æ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ –º–µ—Ç–æ–¥ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∂–∞–¥–Ω—ã–º —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º, –ø—Ä–∏  –±–æ–ª—å—à–æ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ —Ç–æ–∫–µ–Ω—ã –±—É–¥—É—Ç –≤—ã–±–∏—Ä–∞—Ç—å—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–ª—É—á–∞–π–Ω–æ. –û–±—ã—á–Ω–æ —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ `0.8‚Äì2.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§–æ—Ä–º—É–ª–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∞ –Ω–∞ —Ñ–æ—Ä–º—É–ª—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ë–æ–ª—å—Ü–º–∞–Ω–∞: —á–µ–º –≤—ã—à–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã, —Ç–µ–º –±–æ–ª—å—à–µ \"—Ä–∞–∑–º–∞–∑—ã–≤–∞–µ—Ç—Å—è\" —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –µ—ë –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π, –æ—Ç—Å—é–¥–∞ —Å–ª–æ–≤–æ \"—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞\".\n",
    "\n",
    "$$p=softmax(log(p)/t)$$\n",
    "\n",
    "–°—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ —Å–ª—É—á–∞–π–Ω–∞—è –ø—Ä–∏—Ä–æ–¥–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±—É–¥–µ—Ç –∏–Ω–æ–≥–¥–∞ –ø—Ä–∏–≤–æ–¥–∏—Ç—å –∫ –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.generate(\n",
    "    input_ids, do_sample=True, temperature=1.3, max_length=30, pad_token_id=30\n",
    ")\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ú–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω—ã—Ö –¢–æ–∫–µ–Ω–æ–≤ (Nucleus sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–∂–Ω–æ –≤–≤–µ—Å—Ç–∏ –∑–∞–ø—Ä–µ—Ç –Ω–∞ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–∏–º–µ–Ω–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤:\n",
    "\n",
    "* `top-k` –∑–∞–Ω—É–ª—è–µ—Ç –≤—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –∫—Ä–æ–º–µ $k$ –Ω–∞–∏–±–æ–ª—å—à–∏—Ö;\n",
    "\n",
    "* `top-p` –æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä —Ç–æ–∫–µ–Ω–æ–≤, –ø—Ä–∏—á—ë–º —Å—É–º–º–∞ –∏—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –±—É–¥–µ—Ç –Ω–µ –±–æ–ª—å—à–µ $p$.\n",
    "\n",
    "`top-p` –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞–∑—ã–≤–∞—é—Ç **Nucleus Sampling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=1.3,\n",
    "    top_k=20,\n",
    "    top_p=0.8,\n",
    "    max_length=30,\n",
    "    pad_token_id=30,\n",
    ")\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –º–æ–¥–µ–ª—å—é –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, —á—Ç–æ–±—ã –æ–Ω–∞ –ø–æ–º–µ—Å—Ç–∏–ª–∞—Å—å –Ω–∞ GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -q transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–∞—é—â–∏–π —Ç–µ–∫—Å—Ç –Ω–∞—Ä–µ–∑–∞–µ—Ç—Å—è –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã–µ –±–ª–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ 1024 (2048 —É GPT-3) —Ç–æ–∫–µ–Ω–æ–≤, —Ä–∞–∑–¥–µ–ª—è—è—Å—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º `<|endoftext|>` —Å–∏–º–≤–æ–ª–æ–º. –í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å (–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å) –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–¥–∏–Ω –∑–∞ –¥—Ä—É–≥–∏–º –ø—Ä–∏ –ø–æ–º–æ—â–∏ Cross-Entropy Loss.\n",
    "\n",
    "–¢–∞–∫ –∫–∞–∫ –≤—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—Å–µ–≥–¥–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∞ –¥–æ –∫–æ–Ω—Ü–∞, padding –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è. –ù–æ –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–ª–∏–Ω–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π, –ø–æ—ç—Ç–æ–º—É –Ω–∞–¥–æ —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å, —á–µ–º –ø–∞–¥–¥–∏—Ç—å –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø–æ–∑–∏—Ü–∏–∏. –ü–æ –¥–µ—Ñ–æ–ª—Ç—É –∏—Å–ø–æ–ª—å–∑—É—Ç–µ—Å—è —Ç–æ—Ç –∂–µ `<|endoftext|>`.\n",
    "\n",
    "–í –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –≤–µ—Ä—Å–∏—è—Ö GPT –≤—ã—à–µ—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –º–æ–∂–µ—Ç –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å—Å—è. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ ruGPT3 –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: `<s\\>`, `<s>`, `<pad>`, `<unk>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ\n",
    "–ë—É–¥–µ–º —É—á–∏—Ç—å GPT –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∏—Ö–∏ –ú–∞—è–∫–æ–≤—Å–∫–æ–≥–æ. –í –∫–∞—á–µ—Å—Ç–≤–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤–æ–∑—å–º—ë–º –≤—Å–µ–≥–æ –ª–∏—à—å –æ–¥–∏–Ω —Å—Ç–∏—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"–î—ã–º —Ç–∞–±–∞—á–Ω—ã–π –≤–æ–∑–¥—É—Ö –≤—ã–µ–ª.\n",
    "–ö–æ–º–Ω–∞—Ç–∞ ‚Äî\n",
    "–≥–ª–∞–≤–∞ –≤ –∫—Ä—É—á–µ–Ω—ã—Ö–æ–≤—Å–∫–æ–º –∞–¥–µ.\n",
    "–í—Å–ø–æ–º–Ω–∏ ‚Äî\n",
    "–∑–∞ —ç—Ç–∏–º –æ–∫–Ω–æ–º\n",
    "–≤–ø–µ—Ä–≤—ã–µ\n",
    "—Ä—É–∫–∏ —Ç–≤–æ–∏, –∏—Å—Å—Ç—É–ø–ª–µ–Ω–Ω—ã–π, –≥–ª–∞–¥–∏–ª.\n",
    "–°–µ–≥–æ–¥–Ω—è —Å–∏–¥–∏—à—å –≤–æ—Ç,\n",
    "—Å–µ—Ä–¥—Ü–µ –≤ –∂–µ–ª–µ–∑–µ.\n",
    "–î–µ–Ω—å –µ—â–µ ‚Äî\n",
    "–≤—ã–≥–æ–Ω–∏—à—å,\n",
    "–º–æ–∂–µ—Ç –±—ã—Ç—å, –∏–∑—Ä—É–≥–∞–≤.\n",
    "–í –º—É—Ç–Ω–æ–π –ø–µ—Ä–µ–¥–Ω–µ–π –¥–æ–ª–≥–æ –Ω–µ –≤–ª–µ–∑–µ—Ç\n",
    "—Å–ª–æ–º–∞–Ω–Ω–∞—è –¥—Ä–æ–∂—å—é —Ä—É–∫–∞ –≤ —Ä—É–∫–∞–≤.\n",
    "–í—ã–±–µ–≥—É,\n",
    "—Ç–µ–ª–æ –≤ —É–ª–∏—Ü—É –±—Ä–æ—à—É —è.\n",
    "–î–∏–∫–∏–π,\n",
    "–æ–±–µ–∑—É–º–ª—é—Å—å,\n",
    "–æ—Ç—á–∞—è–Ω—å–µ–º –∏—Å—Å–µ—á–∞ÃÅ—Å—å.\n",
    "–ù–µ –Ω–∞–¥–æ —ç—Ç–æ–≥–æ,\n",
    "–¥–æ—Ä–æ–≥–∞—è,\n",
    "—Ö–æ—Ä–æ—à–∞—è,\n",
    "–¥–∞–π –ø—Ä–æ—Å—Ç–∏–º—Å—è —Å–µ–π—á–∞—Å.\n",
    "–í—Å–µ —Ä–∞–≤–Ω–æ\n",
    "–ª—é–±–æ–≤—å –º–æ—è ‚Äî\n",
    "—Ç—è–∂–∫–∞—è –≥–∏—Ä—è –≤–µ–¥—å ‚Äî\n",
    "–≤–∏—Å–∏—Ç –Ω–∞ —Ç–µ–±–µ,\n",
    "–∫—É–¥–∞ –Ω–∏ –±–µ–∂–∞–ª–∞ –±.\n",
    "–î–∞–π –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º –∫—Ä–∏–∫–µ –≤—ã—Ä–µ–≤–µ—Ç—å\n",
    "–≥–æ—Ä–µ—á—å –æ–±–∏–∂–µ–Ω–Ω—ã—Ö –∂–∞–ª–æ–±.\n",
    "–ï—Å–ª–∏ –±—ã–∫–∞ —Ç—Ä—É–¥–æ–º —É–º–æ—Ä—è—Ç ‚Äî\n",
    "–æ–Ω —É–π–¥–µ—Ç,\n",
    "—Ä–∞–∑–ª—è–∂–µ—Ç—Å—è –≤ —Ö–æ–ª–æ–¥–Ω—ã—Ö –≤–æ–¥–∞—Ö.\n",
    "–ö—Ä–æ–º–µ –ª—é–±–≤–∏ —Ç–≤–æ–µ–π,\n",
    "–º–Ω–µ\n",
    "–Ω–µ—Ç—É –º–æ—Ä—è,\n",
    "–∞ —É –ª—é–±–≤–∏ —Ç–≤–æ–µ–π –∏ –ø–ª–∞—á–µ–º –Ω–µ –≤—ã–º–æ–ª–∏—à—å –æ—Ç–¥—ã—Ö.\n",
    "–ó–∞—Ö–æ—á–µ—Ç –ø–æ–∫–æ—è —É—Å—Ç–∞–≤—à–∏–π —Å–ª–æ–Ω ‚Äî\n",
    "—Ü–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –ª—è–∂–µ—Ç –≤ –æ–ø–æ–∂–∞—Ä–µ–Ω–Ω–æ–º –ø–µ—Å–∫–µ.\n",
    "–ö—Ä–æ–º–µ –ª—é–±–≤–∏ —Ç–≤–æ–µ–π,\n",
    "–º–Ω–µ\n",
    "–Ω–µ—Ç—É —Å–æ–ª–Ω—Ü–∞,\n",
    "–∞ —è –∏ –Ω–µ –∑–Ω–∞—é, –≥–¥–µ —Ç—ã –∏ —Å –∫–µ–º.\n",
    "–ï—Å–ª–∏ –± —Ç–∞–∫ –ø–æ—ç—Ç–∞ –∏–∑–º—É—á–∏–ª–∞,\n",
    "–æ–Ω\n",
    "–ª—é–±–∏–º—É—é –Ω–∞ –¥–µ–Ω—å–≥–∏ –± –∏ —Å–ª–∞–≤—É –≤—ã–º–µ–Ω—è–ª,\n",
    "–∞ –º–Ω–µ\n",
    "–Ω–∏ –æ–¥–∏–Ω –Ω–µ —Ä–∞–¥–æ—Å—Ç–µ–Ω –∑–≤–æ–Ω,\n",
    "–∫—Ä–æ–º–µ –∑–≤–æ–Ω–∞ —Ç–≤–æ–µ–≥–æ –ª—é–±–∏–º–æ–≥–æ –∏–º–µ–Ω–∏.\n",
    "–ò –≤ –ø—Ä–æ–ª–µ—Ç –Ω–µ –±—Ä–æ—à—É—Å—å,\n",
    "–∏ –Ω–µ –≤—ã–ø—å—é —è–¥–∞,\n",
    "–∏ –∫—É—Ä–æ–∫ –Ω–µ —Å–º–æ–≥—É –Ω–∞–¥ –≤–∏—Å–∫–æ–º –Ω–∞–∂–∞—Ç—å.\n",
    "–ù–∞–¥–æ –º–Ω–æ—é,\n",
    "–∫—Ä–æ–º–µ —Ç–≤–æ–µ–≥–æ –≤–∑–≥–ª—è–¥–∞,\n",
    "–Ω–µ –≤–ª–∞—Å—Ç–Ω–æ –ª–µ–∑–≤–∏–µ –Ω–∏ –æ–¥–Ω–æ–≥–æ –Ω–æ–∂–∞.\n",
    "–ó–∞–≤—Ç—Ä–∞ –∑–∞–±—É–¥–µ—à—å,\n",
    "—á—Ç–æ —Ç–µ–±—è –∫–æ—Ä–æ–Ω–æ–≤–∞–ª,\n",
    "—á—Ç–æ –¥—É—à—É —Ü–≤–µ—Ç—É—â—É—é –ª—é–±–æ–≤—å—é –≤—ã–∂–µ–≥,\n",
    "–∏ —Å—ÉÃÅ–µ—Ç–Ω—ã—Ö –¥–Ω–µ–π –≤–∑–º–µ—Ç–µ–Ω–Ω—ã–π –∫–∞—Ä–Ω–∞–≤–∞–ª\n",
    "—Ä–∞—Å—Ç—Ä–µ–ø–ª–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–æ–∏—Ö –∫–Ω–∏–∂–µ–∫‚Ä¶\n",
    "–°–ª–æ–≤ –º–æ–∏—Ö —Å—É—Ö–∏–µ –ª–∏—Å—Ç—å—è –ª–∏\n",
    "–∑–∞—Å—Ç–∞–≤—è—Ç –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è,\n",
    "–∂–∞–¥–Ω–æ –¥—ã—à–∞?\n",
    "–î–∞–π —Ö–æ—Ç—å\n",
    "–ø–æ—Å–ª–µ–¥–Ω–µ–π –Ω–µ–∂–Ω–æ—Å—Ç—å—é –≤—ã—Å—Ç–µ–ª–∏—Ç—å\n",
    "—Ç–≤–æ–π —É—Ö–æ–¥—è—â–∏–π —à–∞–≥..\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –±–∏–±–ª–∏–æ—Ç–µ–∫–µ transformers –µ—Å—Ç—å –≥–æ—Ç–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –¥–∞—Ç–∞–ª–æ–¥–µ—Ä–∞. –ù–∞ –≤—Ö–æ–¥ –Ω—É–∂–µ–Ω –≤—Å–µ–≥–æ –ª–∏—à—å –æ–¥–∏–Ω `.txt` —Ñ–∞–π–ª —Å –æ–±—É—á–∞—é—â–∏–º —Ç–µ–∫—Å—Ç–æ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save text train data as .txt file\n",
    "train_path = \"train_dataset.txt\"\n",
    "with open(train_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Creating Dataset\n",
    "train_dataset = TextDataset(tokenizer=tokenizer, file_path=train_path, block_size=64)\n",
    "\n",
    "# –°reating DataLoader (crop the text into optimal length pieces)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "–î–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º –æ–±—ä–µ–∫—Ç –∫–ª–∞—Å—Å–∞ Trainer, –∫–æ—Ç–æ—Ä—ã–π —Å–¥–µ–ª–∞–µ—Ç –≤—Å—é —Ä–∞–±–æ—Ç—É –∑–∞ –Ω–∞—Å. –î–∞–ª–µ–µ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –≤—Å–µ–≥–æ –ª–∏—à—å –∑–∞–ø—É—Å—Ç–∏—Ç—å `trainer.train()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned\",  # The output directory\n",
    "    overwrite_output_dir=True,  # overwrite the content of the output directory\n",
    "    num_train_epochs=200,  # number of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size for training\n",
    "    per_device_eval_batch_size=32,  # batch size for evaluation\n",
    "    warmup_steps=10,  # number of warmup steps for learning rate scheduler\n",
    "    gradient_accumulation_steps=16,  # to make \"virtual\" batch size larger\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    optimizers=(\n",
    "        torch.optim.AdamW(model.parameters(), lr=1e-5),\n",
    "        None,\n",
    "    ),  # Optimizer and learnig rate scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–µ–∑—É–ª—å—Ç–∞—Ç —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞\n",
    "–ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ –∂–µ —Å–æ—á–∏–Ω–∏—Ç GPT –≤ —Å—Ç–∏–ª–µ –ú–∞—è–∫–æ–≤—Å–∫–æ–≥–æ, –µ—Å–ª–∏ –Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞—Ç—å —Ç–∞–∫—É—é —Å—Ç—Ä–æ—á–∫—É:\n",
    "\n",
    "\"–£—á–∏–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å –∑–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability sampling with limit example\n",
    "text = \"–ö–∞–∫ –∂–µ —Å–ª–æ–∂–Ω–æ —É—á–∏—Ç—å –º–∞—Ç–∞–Ω–∞–ª–∏–∑!\\n\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        num_beams=2,\n",
    "        temperature=1.5,\n",
    "        top_p=0.9,\n",
    "        max_length=100,\n",
    "        pad_token_id=512,\n",
    "    )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏**\n",
    "1. [GPT –≤ –∫–∞—Ä—Ç–∏–Ω–∫–∞—Ö](https://habr.com/ru/post/490842/) ‚Äî –æ—á–µ–Ω—å –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã GPT-2 —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏.\n",
    "2. [–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –≤ –∫–∞—Ä—Ç–∏–Ω–∫–∞—Ö](https://habr.com/ru/post/486358/) ‚Äî –æ—á–µ–Ω—å –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Transformer —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏.\n",
    "3. [Tokenizers tutorial](https://huggingface.co/docs/transformers/tokenizer_summary) ‚Äî –∫—Ä–∞—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤ –æ—Ç Huggingface —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏.\n",
    "4. [–ö–∞–∫ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç](https://huggingface.co/blog/how-to-generate) ‚Äî –æ–±–∑–æ—Ä —Å–ø–æ—Å–æ–±–æ–≤ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (–±–∏–º—Å—ë—Ä—á –∏ —Ç–¥).\n",
    "5. [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf) ‚Äî –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–æ –ø–µ—Ä–≤—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä.\n",
    "6. [GPT-1](https://openai.com/blog/language-unsupervised/) ‚Äî —Å—Ç–∞—Ç—å—è –≤ –±–ª–æ–≥–µ OpenAI –ø—Ä–æ GPT-1.\n",
    "7. [GPT-2](https://openai.com/blog/better-language-models/) ‚Äî —Å—Ç–∞—Ç—å—è –≤ –±–ª–æ–≥–µ OpenAI –ø—Ä–æ GPT-2.\n",
    "8. [GPT-3](https://openai.com/blog/gpt-3-apps/) ‚Äî —Å—Ç–∞—Ç—å—è –≤ –±–ª–æ–≥–µ OpenAI –ø—Ä–æ GPT-3.\n",
    "9. [WebGPT](https://openai.com/blog/improving-factual-accuracy/) ‚Äî —Å—Ç–∞—Ç—å—è –≤ –±–ª–æ–≥–µ OpenAI –ø—Ä–æ GPT-3, –æ–±—É—á–µ–Ω–Ω—É—é –≥—É–≥–ª–∏—Ç—å.\n",
    "10. [Codex](https://openai.com/blog/openai-codex/) ‚Äî —Å—Ç–∞—Ç—å—è –≤ –±–ª–æ–≥–µ OpenAI –ø—Ä–æ GPT-3, –æ–±—É—á–µ–Ω–Ω—É—é –ø–∏—Å–∞—Ç—å –∫–æ–¥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NLP –º–µ—Ç—Ä–∏–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>–í—ã–±–∏—Ä–∞–π—Ç–µ –º–µ—Ç—Ä–∏–∫—É –ø–æ–¥ —Å–≤–æ—é –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É!</font> –ò–ª–∏ –¥–∞–∂–µ –∫–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–π—Ç–µ –µ—ë —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–º–Ω–∏—Ç–µ —ç—Ç—É –∫–∞—Ä—Ç–∏–Ω–∫—É —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –ª–µ–∫—Ü–∏–∏? –°–µ–≥–æ–¥–Ω—è –º—ã —Ä–∞–∑–±–µ—Ä—ë–º –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏.\n",
    "\n",
    "**BLEURT, Prism** - –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª–æ–∏ –ø—Ä–∏–Ω–∏–º–∞—é—Ç –Ω–∞ –≤—Ö–æ–¥ **—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –∏ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–æ–≤**, –∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –¥–∞—é—Ç –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–≤–æ–¥–∞.\n",
    "\n",
    "**COMET, UniTE** - –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, **—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –∏ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–æ–≤**, **–æ—Ä–∏–≥–∏–Ω–∞–ª** –ø–µ—Ä–µ–≤–æ–¥–∏–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "**–ë–µ–∑—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏** - –º–æ–¥–µ–ª–∏, —Å—Ä–∞–≤–Ω–∏–≤–∞—é—â–∏–µ **–Ω–∞–ø—Ä—è–º—É—é –º–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –∏ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫** (reference-free metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/nlp_metrics.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[–ü–µ—Ä–µ—á–µ–Ω—å –º–µ—Ç—Ä–∏–∫ –∏ –∏—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π](https://habr.com/ru/articles/745642/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"6\">–•–æ—Ä–æ—à–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏</font>\n",
    "\n",
    "[–ü—Ä–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã](https://arig23498.notion.site/Transformers-969f4b27c48147778c1e2dbda0c83ce0)\n",
    "\n",
    "[–ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\n",
    "\n",
    "[–ö–æ–¥ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π —Å –∫—Ä–∞—Å–∏–≤—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏](https://nn.labml.ai/)\n",
    "\n",
    "[–ó–æ–æ–ø–∞—Ä–∫ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤: –±–æ–ª—å—à–æ–π –æ–±–∑–æ—Ä –º–æ–¥–µ–ª–µ–π –æ—Ç BERT –¥–æ Alpaca](https://habr.com/ru/companies/just_ai/articles/733110/)\n",
    "\n",
    "[Transformers in computer vision: ViT architectures, tips, tricks and improvements](https://theaisummer.com/transformers-computer-vision/)\n",
    "\n",
    "[Illustrated transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "[Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/)\n",
    "\n",
    "[Open-source —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è GPT-3](https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/)\n",
    "\n",
    "[Transformer –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞](https://github.com/vlarine/transformers-ru)\n",
    "\n",
    "[NLP Course for you](https://lena-voita.github.io/nlp_course.html)\n",
    "\n",
    "[–ö—É—Ä—Å –ø–æ NLP –æ—Ç –®–ê–î](https://github.com/yandexdataschool/nlp_course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ú–æ–¥–µ–ª–∏ –≤–Ω–∏–º–∞–Ω–∏—è –≤ –º–∞—à–∏–Ω–Ω–æ–º –ø–µ—Ä–µ–≤–æ–¥–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —Ç–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥  —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π.\n",
    "\n",
    "–ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –Ω–∞–±–æ—Ä –≤–µ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–≤–µ—á–∞—é—Ç –∑–∞ —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫—É –Ω–∞ —Ç–æ–º –∏–ª–∏ –∏–Ω–æ–º –º–µ—Å—Ç–µ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ö–∞–∫ –º—ã –≤–∏–¥–∏–º, –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–º–µ–µ—Ç –∏–Ω–æ–π –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–≥–æ. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –≤–∞—Ä–∏–∞–Ω—Ç–µ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–µ **European Economic Area**, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –≤–æ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–º **zone √©conomique europ√©enne**.\n",
    "\n",
    "–í –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–¥—É—Ç –ø–µ—Ä–µ–¥ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –≤–æ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–º —è–∑—ã–∫–µ –Ω–∞–æ–±–æ—Ä–æ—Ç.\n",
    "\n",
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –±–ª–∞–≥–æ–¥–∞—Ä—è –≥–∏–±–∫–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –º—ã –º–æ–∂–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –≤ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/visualize_attention_weights.png\" width=\"700\">\n",
    "\n",
    "<em>Source: <a href=\"https://arxiv.org/pdf/1409.0473.pdf\">Neural machine translation by jointly learning to align and translate</a></em>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* –ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–µ–Ω –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å.\n",
    "\n",
    "* –ú—ã –º–æ–∂–µ–º –ø—Ä–∏–º–µ–Ω—è—Ç—å –µ–≥–æ –≤ —Ç–æ–º —á–∏—Å–ª–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥–ø–∏—Å–µ–π –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫. –í—Ö–æ–¥–æ–º –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –±—É–¥–µ—Ç —è–≤–ª—è—Ç—å—Å—è –º–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∫–æ—Ç–æ—Ä–∞—è –±—ã–ª–∞ –ø–æ–ª—É—á–µ–Ω–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–π —Å–µ—Ç–∏ –∫ –∫–∞—Ä—Ç–∏–Ω–∫–µ.\n",
    "\n",
    "* –î–∞–ª–µ–µ –ø–æ —ç—Ç–æ–π –º–∞—Ç—Ä–∏—Ü–µ –º—ã —Å—á–∏—Ç–∞–µ–º –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è –∏ –¥–µ–ª–∞–µ–º –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø–µ—Ä–≤–æ–º—É –ø—Ä–∏–º–µ—Ä—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –±—É–¥–µ—Ç —Ç–∞–∫–∂–µ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ –¥–ª—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞—à–∞ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∑–∞–±—ã—Ç—å –∏ —Ç–æ, —á—Ç–æ –æ–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç. –ü–æ—Ç–æ–º—É –º—ã –º–æ–∂–µ–º —Å–¥–µ–ª–∞—Ç—å –¥–≤–∞ attention: –æ–¥–∏–Ω ‚Äî –Ω–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∞ –≤—Ç–æ—Ä–æ–π ‚Äî –Ω–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ —É–∂–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ (—á—Ç–æ –µ—â–µ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–º–µ–Ω—è–µ–º –Ω—É–ª—è–º–∏)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Captioning with RNNs and Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –≤–Ω–∏–º–∞–Ω–∏–∏ (attention), –Ω–∞–º–Ω–æ–≥–æ –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ, –Ω–µ–∂–µ–ª–∏ –æ–±—ã—á–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏. –û–Ω–∏ –º–æ–≥—É—Ç –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —á–∞—Å—Ç—è—Ö –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –∑–∞—à—É–º–ª–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π.\n",
    "\n",
    "–ò–¥–µ—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –≤ —Ä–∞–∑–Ω–æ–π —Å—Ç–µ–ø–µ–Ω–∏ –æ–±—Ä–∞—â–∞–µ—Ç –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–µ –∏–ª–∏ –∏–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å–ª–µ–¥—É—é—â–µ–º—É —Å–ª–æ–≤—É –≤ –æ–ø–∏—Å–∞–Ω–∏–∏.\n",
    "\n",
    "–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å, —á—Ç–æ –æ–Ω–∞ –∫–∞–∫ –±—ã –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç —Å–≤–æ—ë –≤–Ω–∏–º–∞–Ω–∏–µ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ —Å–ª–æ–≤–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/image_captioning_with_rnn_and_attention_example_step_1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/image_captioning_with_rnn_and_attention_example_step_2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/image_captioning_with_rnn_and_attention_example_step_3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/image_captioning_with_rnn_and_attention_example_step_4.png\" width=\"700\">\n",
    "\n",
    "<em>Source: <a href=\"http://cs231n.stanford.edu/slides/2022/lecture_11_ruohan.pdf\">Stanford University CS231n: lectures</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ê –µ—Å–ª–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏?**\n",
    "\n",
    "–ö –ø—Ä–∏–º–µ—Ä—É, —É –Ω–∞—Å –µ—Å—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∞. –ù–∞ —ç—Ç–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ —É –Ω–∞—Å –µ—Å—Ç—å –æ–±–ª–∞—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º ‚Äî **key**. –ù–∞–ø—Ä–∏–º–µ—Ä, —Ñ–æ–Ω–∞—Ä—å/–¥–µ–≤—É—à–∫–∞/...\n",
    "\n",
    "–°–∞–º–∏ —ç—Ç–∏ –æ–±–ª–∞—Å—Ç–∏ ‚Äî —ç—Ç–æ **value**, –∫–æ—Ç–æ—Ä—ã–µ –≤–≤–µ–¥–µ–Ω–Ω—ã–º **key** —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç.\n",
    "\n",
    "–î–∞–ª–µ–µ –Ω–∞–º –ø—Ä–∏—Ö–æ–¥–∏—Ç **query**, –Ω–∞–ø—Ä–∏–º–µ—Ä, running. –ú—ã –º–æ–∂–µ–º –ø–æ—Å—á–∏—Ç–∞—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ –∏–∑ –∫–ª—é—á–µ–π, –∫–æ—Ç–æ—Ä—ã–µ —É –Ω–∞—Å –µ—Å—Ç—å, –Ω–∞ query.\n",
    "\n",
    "–ò –¥–∞–ª–µ–µ –≤—ã–¥–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Ç–æ–ª—å–∫–æ –ø–æ **value**, –ø–æ—Ö–æ–∂–∏–º –Ω–∞ –Ω–∞—à **query**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/key_query_value_example.jpg\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ —Å—É—Ç–∏ –º—ã –æ–ø–∏—Å–∞–ª–∏ —Ç–æ, –∫–∞–∫ –±—É–¥–µ–º –¥–µ–ª–∞—Ç—å –ø—Ä–∏ –ø–æ–º–æ—â–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –ø–∏—Ç–æ–Ω–æ–≤—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å. –° —Ç–æ–π —Ä–∞–∑–Ω–∏—Ü–µ–π, —á—Ç–æ –ø–∏—Ç–æ–Ω–æ–≤—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å –º–æ–∂–µ—Ç –≤—ã–¥–∞–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ—Ö –∫–ª—é—á–µ–π, —á—Ç–æ –≤ –Ω–µ–º –µ—Å—Ç—å, –∞ –Ω–∞—à —Å–ª–æ–≤–∞—Ä—å –≤—ã–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –¥–ª—è –ª—é–±–æ–≥–æ –∫–ª—é—á–∞-–∑–∞–ø—Ä–æ—Å–∞, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –µ–≥–æ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ –Ω–∞ –∫–ª—é—á–∏ —Å–ª–æ–≤–∞—Ä—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ú–æ–¥–µ–ª–∏ –≤–Ω–∏–º–∞–Ω–∏—è –≤ –∑–∞–¥–∞—á–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥–ø–∏—Å–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å —Å –≤–Ω–∏–º–∞–Ω–∏–µ–º —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –≤ –∑–∞–¥–∞—á–µ, –∫–æ–≥–¥–∞ –æ—Ç –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥–ø–∏—Å—å.\n",
    "\n",
    "–ò–º–µ–µ–º –Ω–∞–±–æ—Ä –ø–∞—Ä \"–∫–∞—Ä—Ç–∏–Ω–∫–∞ : –ø–æ–¥–ø–∏—Å—å\"\n",
    "\n",
    "–í–º–µ—Å—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–≤–µ—Ä—Ç–æ—á–Ω—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å. –í–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º –Ω–∞ –∫–∞—Ä—Ç–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤. –ü–æ–ª—É—á–∞–µ—Ç—Å—è \"–º–∞—Å–∫–∞\" –≤–Ω–∏–º–∞–Ω–∏—è.\n",
    "\n",
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –¥–µ–∫–æ–¥–µ—Ä –∏–º–µ–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—Ä–∞—â–∞—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ä–∞–∑–Ω—ã–µ —É—á–∞—Å—Ç–∫–∏ –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞.\n",
    "\n",
    "–ù–∞ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –≤—Ö–æ–¥–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –Ω–∞–ª–æ–∂–µ–Ω–Ω—ã–µ –Ω–∞ –Ω–∏—Ö –º–∞—Å–∫–∏ –≤–Ω–∏–º–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –≤–æ–∑–Ω–∏–∫–ª–∏ –≤ —Å–µ—Ç–∏ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç–æ–≥–æ —Å–ª–æ–≤–∞.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/visulize_attention_map_examples.png\" width=\"700\">\n",
    "\n",
    "<em>Source: <a href=\"https://arxiv.org/pdf/1502.03044.pdf\">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ ‚Äú–ø—Ä–∏–≤–ª–µ–∫–∞–µ—Ç –≤–Ω–∏–º–∞–Ω–∏–µ‚Äù –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –ø—Ä–∏ –Ω–∞–ø–∏—Å–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/visulize_attention_map.png\" width=\"700\">\n",
    "\n",
    "<em>Source: <a href=\"https://arxiv.org/pdf/1502.03044.pdf\">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è (attention), –∞–∫—Ç–∏–≤–Ω–æ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ [Visual Question Answering](https://paperswithcode.com/paper/vqa-visual-question-answering). –í –¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–æ–ª–∂–Ω–∞ –Ω–∞—É—á–∏—Ç—å—Å—è –¥–∞–≤–∞—Ç—å —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é. –ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –Ω–æ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ü–≤–µ—Ç, —Ñ–æ—Ä–º–∞, —Ä–∞–∑–º–µ—Ä, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ —Ç.–¥.) –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, —Ä–∞–∑–ª–∏—á–∞—Ç—å, –≤ –∫–∞–∫–æ–π —á–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø—Ä–µ–¥–º–µ—Ç –∏ –µ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥—Ä—É–≥–∏—Ö –ø—Ä–µ–¥–º–µ—Ç–æ–≤. –†–µ—à–µ–Ω–∏–µ —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å –ª—é–¥—è–º —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏ —Å–æ –∑—Ä–µ–Ω–∏–µ–º –ª—É—á—à–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.\n",
    "\n",
    "–ü–æ–¥—Ä–æ–±–Ω–µ–µ:\n",
    "1. [–ù–µ–π—Ä–æ—Å–µ—Ç—å –æ–ø–∏—Å—ã–≤–∞–µ—Ç –º–∏—Ä –Ω–µ–∑—Ä—è—á–∏–º –ª—é–¥—è–º](https://www.reg.ru/blog/nejroset-opisyvaet-mir-nezryachim-lyudyam/)\n",
    "2. [–£—á–∏–º –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —Ä–∞—Å—Å—É–∂–¥–∞—Ç—å –æ —Ç–æ–º, —á—Ç–æ –æ–Ω–∏ –≤–∏–¥—è—Ç](https://www.reg.ru/blog/uchim-nejroseti-rassuzhdat-o-tom-chto-oni-vidyat/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Attention (ViT 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Visual Transformers: Token-based Image Representation and Processing for Computer Vision (Wu et al., 2020)](https://arxiv.org/abs/2006.03677)\n",
    "\n",
    "[–†–µ–∞–ª–∏–∑–∞—Ü–∏—è](https://github.com/lucidrains/vit-pytorch)\n",
    "\n",
    "[–†–∞–∑–±–æ—Ä ViT](https://viso.ai/deep-learning/vision-transformer-vit/)\n",
    "\n",
    "\n",
    "**Vision Transformer** ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞. –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è, –∫–∞–∫ –æ–Ω–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç.\n",
    "\n",
    "–í 2020 –≥–æ–¥—É —Å—Ç–∞–ª–∏ –ø–æ—è–≤–ª—è—Ç—å—Å—è —Ä–∞–±–æ—Ç—ã, –≥–¥–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –±–∞–∑–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä —Å–º–æ–≥–ª–∏ –ø–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª—É—á—à–µ, —á–µ–º —É **CNN** –º–æ–¥–µ–ª–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/cited_vit_accuracy.png\"  width=\"650\"></center>\n",
    "\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/abs/2010.11929\">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (Dosovitskiy et al., 2020</a></em></center>\n",
    "\n",
    "BiT ‚Äî —ç—Ç–æ baseline –º–æ–¥–µ–ª—å –Ω–∞ –±–∞–∑–µ **ResNet**, ViT ‚Äî **Visual Transformer**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê–≤—Ç–æ—Ä—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–∞–∑–∞–ª–∏—Å—å –æ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–≤–µ—Ä—Ç–æ–∫,  –∑–∞–º–µ–Ω–∏–≤ –∏—Ö —Å–ª–æ—è–º–∏ **self-attention**.  –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–Ω—è—Ç—å, –ø–æ—á–µ–º—É —ç—Ç–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ.\n",
    "\n",
    "–î–æ–±–∞–≤–ª—è—è –≤ –º–æ–¥–µ–ª—å —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π, –º—ã —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É–µ–º—Å—è —Ä–µ–∑–æ–Ω–Ω—ã–º –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ–º: —á–µ–º –±–ª–∏–∂–µ –ø–∏–∫—Å–µ–ª–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, —Ç–µ–º –±–æ–ª—å—à–µ –±—É–¥–µ—Ç –∏—Ö –≤–∑–∞–∏–º–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ.\n",
    "\n",
    "–í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/cnn_ok.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - –ù–∞ —Å–ª–æ–µ n (–∫—Ä–∞—Å–Ω—ã–π) –∞–∫—Ç–∏–≤–∏—Ä—É—é—Ç—Å—è –Ω–µ–π—Ä–æ–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–≥–∏—Ä—É—é—Ç –Ω–∞ –º–æ—Ä–¥—É –∏ –Ω–∞ —Ö–≤–æ—Å—Ç –∫–æ—Ç–∞.\n",
    "\n",
    " - –í –∫–∞—Ä—Ç–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –∏—Ö –≤—ã—Ö–æ–¥—ã –æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è —Ä—è–¥–æ–º, –∏ –≤ —Å–ª–æ–µ n + 1 (—Å–∏–Ω–∏–π) –æ–Ω–∏ –ø–æ–ø–∞–¥–∞—é—Ç –≤ –æ–¥–Ω—É —Å–≤–µ—Ä—Ç–∫—É, –∫–æ—Ç–æ—Ä–∞—è –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –æ–±—ä–µ–∫—Ç–∞—Ö —Ç–∏–ø–∞ \"–∫–æ—Ç\".\n",
    "\n",
    "–¢–∞–∫ —Å–ª—É—á–∞–µ—Ç—Å—è —á–∞—Å—Ç–æ, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/cnn_fail.jpg\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ–Ω–æ–≤, —Ä–µ–∞–≥–∏—Ä—É—é—â–∏—Ö –Ω–∞ –º–æ—Ä–¥—É –∏ —Ö–≤–æ—Å—Ç, –Ω–µ –ø–æ–ø–∞–¥—É—Ç –≤ –æ–¥–Ω—É —Å–≤–µ—Ä—Ç–∫—É –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º —Å–ª–æ–µ. –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Ç–æ–º—É, —á—Ç–æ –Ω–µ–π—Ä–æ–Ω, –æ–±—É—á–∏–≤—à–∏–π—Å—è —Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –∫–æ—à–µ–∫, –Ω–µ –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è.\n",
    "\n",
    "–ü—Ä–∏—á–∏–Ω–æ–π —ç—Ç–æ–≥–æ —è–≤–ª—è–µ—Ç—Å—è –¥–æ–ø—É—â–µ–Ω–∏–µ ([Inductive bias](https://en.wikipedia.org/wiki/Inductive_bias)) –æ –≤–∑–∞–∏–º–Ω–æ–º –≤–ª–∏—è–Ω–∏–∏ —Å–æ—Å–µ–¥–Ω–∏—Ö –ø–∏–∫—Å–µ–ª–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/global_attention.png\" width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Self-attention** —Å–ª–æ–π –ª–∏—à–µ–Ω —ç—Ç–æ–≥–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∞. –û–Ω –æ–±—É—á–∞–µ—Ç—Å—è –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –≤–∑–∞–∏–º–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ –≤—Ö–æ–¥–æ–≤ –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–∞. –ù–æ –∫–∞–∫ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –µ–≥–æ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º?\n",
    "\n",
    "–í —Å—Ç–∞—Ç—å–µ [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (Dosovitskiy et al., 2020)](https://arxiv.org/pdf/2010.11929.pdf) –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è —Ä–∞–∑–±–∏–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–∞ –∫—É—Å–æ—á–∫–∏ (patches) —Ä–∞–∑–º–µ—Ä–æ–º 16x16 –ø–∏–∫—Å–µ–ª–µ–π –∏ –ø–æ–¥–∞–≤–∞—Ç—å –∏—Ö –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–ü—Ä–æ–¥–µ–ª–∞–µ–º —ç—Ç–æ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/cat.jpeg\"\n",
    "!wget -q $URL -O image.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä, –ø–æ—Ä–µ–∂–µ–º –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏ –æ—Ç–æ–±—Ä–∞–∑–∏–º –∏—Ö, –∏—Å–ø–æ–ª—å–∑—É—è image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"image.jpg\")\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "\n",
    "img = transform(img)\n",
    "patches = []\n",
    "sz = 64\n",
    "for r in range(0, img.shape[1], sz):\n",
    "    for c in range(0, img.shape[2], sz):\n",
    "        patches.append(img[:, r : r + sz, c : c + sz])\n",
    "\n",
    "patches = torch.stack(patches).type(torch.float)\n",
    "\n",
    "img_grid = utils.make_grid(patches, pad_value=10, normalize=True, nrow=4)\n",
    "plt.imshow(transforms.ToPILImage()(img_grid).convert(\"RGB\"))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –æ–Ω–∏ –ø–æ—Å—Ç—É–ø—è—Ç –≤ –≤–∏–¥–µ –≤–µ–∫—Ç–æ—Ä–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "img_grid = utils.make_grid(patches, pad_value=10, normalize=True, nrow=256 // 16)\n",
    "plt.imshow(transforms.ToPILImage()(img_grid).convert(\"RGB\"))\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞—Ç–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ –º–æ–¥–µ–ª—å, –≥–¥–µ –ø–æ—Å–ª–µ —Ä—è–¥–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π –ø–æ–ø–∞–¥–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ —Å–ª–æ—è **self-attention**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/self_attention.png\" width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞—Ä—Ç–∏–Ω–∫–∏ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏, –≤ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ª–æ–π —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è —Å—Ç–æ–ª—å –æ—á–µ–≤–∏–¥–Ω–æ. –û–¥–Ω–∞–∫–æ –∫—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ —Å–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è –≤–µ–∫—Ç–æ—Ä–∞-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –æ—Ç—Ä–∞–∂–∞—é—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ —Å —É—á–µ—Ç–æ–º –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –≤—Ö–æ–¥–æ–≤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ —Å–≤–µ—Ä—Ç–∫–æ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/conv_vs_self_attention1.png\" width=\"400\">\n",
    "\n",
    "–ü—Ä–∏ —Å–≤–µ—Ä—Ç–∫–µ –∫–∞–∂–¥—ã–π –ø—Ä–∏–∑–Ω–∞–∫ —É–º–Ω–æ–∂–∞–µ—Ç—Å—è –Ω–∞ —Å–≤–æ–π –≤–µ—Å, –∏ –∑–∞—Ç–µ–º –æ–Ω–∏ —Å—É–º–º–∏—Ä—É—é—Ç—Å—è. –í–∞–∂–Ω–æ —á—Ç–æ –≤–∫–ª–∞–¥ –≤–∑–≤–µ—à–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Å—É–º–º—É –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "–¢–æ –µ—Å—Ç—å —è–≥–æ–¥–∞ –∫–ª—É–±–Ω–∏–∫–∏, –ª–µ–∂–∞—â–∞—è –Ω–∞ —Å—Ç–æ–ª–µ (–≥–¥–µ —Ä—è–¥–æ–º —Å –Ω–µ–π –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—Å–µ, —á—Ç–æ —É–≥–æ–¥–Ω–æ), –¥–∞—Å—Ç —Ç–∞–∫–æ–π –∂–µ –≤–∫–ª–∞–¥ –≤ —Å—É–º–º—É, –∫–∞–∫ –∏ —è–≥–æ–¥–∞ —Å –∫–ª—É–±–Ω–∏—á–Ω–æ–≥–æ –∫—É—Å—Ç–∞.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/conv_vs_self_attention2.png\"  width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–ª–æ–π self-attention –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ç—É –∂–µ –∑–∞–¥–∞—á—É, —á—Ç–æ –∏ —Å–≤–µ—Ä—Ç–∫–∞: –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥—Ä—É–≥–æ–π, –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π.  –ù–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ –±–æ–ª–µ–µ —É–º–Ω–æ:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/conv_vs_self_attention3.png\"  width=\"900\"></center>\n",
    "\n",
    "*–í–º–µ—Å—Ç–æ —á–∏—Å–µ–ª –∑–¥–µ—Å—å –≤–µ–∫—Ç–æ—Ä–∞, –Ω–æ –ø—Ä–∏–Ω—Ü–∏–ø–∏–ª—å–Ω–æ —ç—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ –º–µ–Ω—è–µ—Ç, –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å self-attention –∏ –∫ –æ—Ç–¥–µ–ª—å–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º (—è—Ä–∫–æ—Å—Ç—è–º, –ø–∏–∫—Å–µ–ª—è–º), –ø—Ä–æ—Å—Ç–æ –¥–ª—è —ç—Ç–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ—á–µ–Ω—å –º–Ω–æ–≥–æ —Ä–µ—Å—É—Ä—Å–æ–≤.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–∞–∂–¥—ã–π –ø—Ä–∏–∑–Ω–∞–∫** —É—á–∞—Å—Ç–≤—É–µ—Ç –≤ –∫–∞–∂–¥–æ–π —Å—É–º–º–µ, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –ø–æ–ø–∞–ª–∏ –≤ —Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞.\n",
    "–ö—Ä–æ–º–µ —ç—Ç–æ–≥–æ, —Å—É–º–º–∏—Ä—É—é—Ç—Å—è –æ–Ω–∏ —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏ $a$, –∫–æ—Ç–æ—Ä—ã–µ **–∑–∞–≤–∏—Å—è—Ç –æ—Ç –≤—Ö–æ–¥–æ–≤** –∏ —Ä–∞–∑–ª–∏—á–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–π —Å—É–º–º—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç—Ç–∏—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –∏ –Ω—É–∂–Ω–∞ –±–æ–ª—å—à–∞—è —á–∞—Å—Ç—å —Å–ª–æ—è self-attention. –ù–∞ —Ä–∏—Å—É–Ω–∫–µ –≤—ã–¥–µ–ª–µ–Ω–æ –∫—Ä–∞—Å–Ω—ã–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/conv_vs_self_attention5.png\"  width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(x)\n",
    "        values = self.value(x)\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / (self.input_dim**0.5)\n",
    "        attention = scores.softmax(dim=2)\n",
    "        print(\"Scores shape\", scores.shape)\n",
    "        weighted = torch.bmm(attention, values)\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "self_attention_layer = SelfAttention(embed_dim)\n",
    "dummy_x = torch.randn(1, 4 * 4, embed_dim)  # Batch_size x Sequence_len x Embedding_size\n",
    "out = self_attention_layer(dummy_x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –°–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–º–µ—Ä–∞ patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã —Ä–∞–±–æ—Ç–∞—é—Ç —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏ –∑–∞ —Å—á—ë—Ç –º–µ—Ö–∞–Ω–∏–∑–º–∞ –≤–Ω–∏–º–∞–Ω–∏—è (**self-attention**). –ò —á—Ç–æ–±—ã –ø–æ–¥–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –µ–≥–æ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å.\n",
    "\n",
    "–°–¥–µ–ª–∞—Ç—å —ç—Ç–æ –º–æ–∂–Ω–æ —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ –≤—Å–µ—Ö –ø–∏–∫—Å–µ–ª–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ï—ë –¥–ª–∏–Ω–∞ $n =  H*W$ (–≤—ã—Å–æ—Ç–∞ –Ω–∞ —à–∏—Ä–∏–Ω—É)\n",
    "\n",
    "[–°–ª–æ–∂–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è](https://www.researchgate.net/figure/Compare-the-computational-complexity-for-self-attention-where-n-is-the-length-of-input_tbl7_347999026) –æ–¥–Ω–æ–≥–æ–ª–æ–≤–æ–≥–æ —Å–ª–æ—è **self-attention** $O(n^2 d )$,  –≥–¥–µ $n$ ‚Äî —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤ –∏ $d$ ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–∞ (embedding)  (–¥–ª—è –ª—é–±–æ–∑–Ω–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞—Å—á–µ—Ç—ã [—Ç—É—Ç](https://stackoverflow.com/questions/65703260/computational-complexity-of-self-attention-in-the-transformer-model)).\n",
    "\n",
    "–¢–æ –µ—Å—Ç—å –¥–ª—è –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π $(H==W)$ –ø–æ–ª—É—á–∏–º $O(H^3 d )$\n",
    "\n",
    "1. –¢–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –±—É–¥–µ—Ç –æ—á–µ–Ω—å –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ —Å–ª–æ–∂–µ–Ω.\n",
    "\n",
    "2. –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ –ø–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ –∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–∏–º embedding-–æ–º –Ω–µ –æ—á–µ–Ω—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ.\n",
    "\n",
    "\n",
    "*–î–ª—è —Ç–µ—Ö, –∫—Ç–æ –∑–∞–±—ã–ª, –Ω–∞–ø–æ–º–Ω–∏–º —á—Ç–æ $O()$ ‚Äî —ç—Ç–æ Big O notation, –∫–æ—Ç–æ—Ä–∞—è –æ—Ç—Ä–∞–∂–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã, —Ç—Ä–µ–±—É–µ–º—ã–µ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è. –¢–∞–∫ –¥–ª—è $O(1)$ ‚Äî –≤—Ä–µ–º—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –±—É–¥–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–º, –≤–Ω–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö, –∞ –¥–ª—è $O(N)$ ‚Äî —Ä–∞—Å—Ç–∏ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –¥–∞–Ω–Ω—ã—Ö.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–±–µ—Ä—ë–º –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ: –î–æ–ø—É—Å—Ç–∏–º, –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª–∏–Ω–æ–π –≤ 4 —Å–ª–æ–≤–∞ ‚Äî \"–ú–∞–º–∞ –º—ã–ª–æ–º –º—ã–ª–∞ —Ä–∞–º—É\" => —É –Ω–∞—Å –µ—Å—Ç—å `4 —Ç–æ–∫–µ–Ω–∞`. –ó–∞–∫–æ–¥–∏—Ä—É–µ–º –∏—Ö –≤ *embeddings* —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é `256`. –ü–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ—Ä—è–¥–∫–∞ $4^2*256 = 4096$ –æ–ø–µ—Ä–∞—Ü–∏–π.\n",
    "\n",
    "–ê —Ç–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ–≤–µ—Ä–Ω—É—Ç—å —Ç–æ –∂–µ —Å–∞–º–æ–µ –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏ 256 –Ω–∞ 256.\n",
    "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤\n",
    "\n",
    " $256^3*256  = 256^4 =  4 294 967 296 $. –£–ø—Å... –ö–∞–∂–µ—Ç—Å—è, –Ω–∞–º —Ç–∞–∫ –Ω–∏–∫–∞–∫–∏—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–µ —Ö–≤–∞—Ç–∏—Ç ‚Äî —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã —Å –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "–ü–æ—Å—á–∏—Ç–∞–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Ä–∞–∑–º–µ—Ä–æ–º 256x256, —Ä–∞–∑–±–∏—Ç–æ–π –Ω–∞ –∫—É—Å–æ—á–∫–∏ –ø–æ 16px. –ø—Ä–∏ —Ç–æ–º –∂–µ —Ä–∞–∑–º–µ—Ä–µ —Ç–æ–∫–µ–Ω–∞ (256) $n = 16$.\n",
    "$16^2*256 = 256^2 = 65536 $. –ò –≤–ø—Ä—è–º—å! ~65000 —Ä–∞–∑ –º–µ–Ω—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤ —Ç—Ä–µ–±—É–µ—Ç—Å—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[–ö–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω  self-attention](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html)\n",
    "\n",
    "[Self-attention —Å–ª–æ–π –≤ PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–µ —Ç–µ—Ä—è–µ–º –ª–∏ –º—ã –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Ä–∞–∑–±–∏–≤–∞—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã? –ù–∞ –ø–µ—Ä–≤—ã–π –≤–∑–≥–ª—è–¥ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å —Å–º–æ–∂–µ—Ç –Ω–∞—É—á–∏—Ç—å—Å—è –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –ø–æ—Ä—è–¥–æ–∫, –≤ –∫–æ—Ç–æ—Ä–æ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —à–ª–∏ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.\n",
    "\n",
    "–í—Å–µ–≥–¥–∞ –ª–∏?\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≥–¥–µ –Ω–µ—Ç —è—Ä–∫–æ –≤—ã—Ä–∞–∂–µ–Ω–Ω–æ–π —Ç–µ–∫—Å—Ç—É—Ä—ã:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/positional_transformer_explanation.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ —Ä–∏—Å—É–Ω–∫–µ –∞) –Ω–∞–∫–æ–≤–∞–ª—å–Ω—è –ø–∞–¥–∞–µ—Ç –Ω–∞ —Ä–µ–±–µ–Ω–∫–∞, –Ω–∞ —Ä–∏—Å—É–Ω–∫–µ –±) —Ä–µ–±–µ–Ω–æ–∫ –ø—Ä—ã–≥–∞–µ—Ç –Ω–∞ –Ω–∞–∫–æ–≤–∞–ª—å–Ω–µ.\n",
    "\n",
    "–°—É—Ç—å –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è, –Ω–æ —á—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –ª—é–±–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞–±–æ—Ä –ø–∞—Ç—á–µ–π:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/positional_vec_transformer_explanation.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ –Ω–µ–º—É –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –ª—é–±–æ–π –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤!\n",
    "\n",
    "–¢–∞–∫ –∫–∞–∫ **self-attention** –±–ª–æ–∫ –Ω–∏–∫–∞–∫ –Ω–µ –∫–æ–¥–∏—Ä—É–µ—Ç –ø–æ–∑–∏—Ü–∏—é —ç–ª–µ–º–µ–Ω—Ç–∞ –Ω–∞ –≤—Ö–æ–¥–µ, —Ç–æ –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ—Ç–µ—Ä—è–µ—Ç—Å—è.\n",
    "\n",
    "–ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ç–∞–∫–∏—Ö –ø–æ—Ç–µ—Ä—å, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ–¥–∏—Ä—É—é—â—É—é –ø–æ–∑–∏—Ü–∏—é —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (patch),  –¥–æ–±–∞–≤–ª—è—é—Ç –∫ –≤—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º **self-attention** —Å–ª–æ—è –≤ —è–≤–Ω–æ–º –≤–∏–¥–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/linear_projection_of_flattened_patches.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[–ú–µ—Ç–æ–¥—ã –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –º—ã –º–æ–∂–µ–º –≥—Ä—É–∑–∏—Ç—å –Ω–∞—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ **Vi**sual **T**ransformer.\n",
    "\n",
    "**Self-attention** –±–ª–æ–∫ –º—ã —Ä–∞–∑–æ–±—Ä–∞–ª–∏, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–∞–º –∑–Ω–∞–∫–æ–º—ã:\n",
    "\n",
    "> **MLP** (Multi layer perceptron) ‚Äî –ë–ª–æ–∫ –∏–∑ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ–µ–≤\n",
    "\n",
    "> **Norm** ‚Äî Layer Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/visual_transformer_architecture.png\" width=\"1000\"></center>\n",
    "<center><em>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Visual Transformer </em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∂–µ—Ç—Å—è –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (patch).\n",
    "2.   –§—Ä–∞–≥–º–µ–Ω—Ç—ã (patch) –ø–æ–¥–≤–µ—Ä–≥–∞—é—Ç—Å—è –ª–∏–Ω–µ–π–Ω–æ–π –ø—Ä–æ–µ–∫—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é **MLP**.\n",
    "3.   –° –ø–æ–ª—É—á–µ–Ω–Ω—ã–º–∏ –Ω–∞ –≤—ã—Ö–æ–¥–µ **MLP** –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É—é—Ç—Å—è **positional embeddings** (–∫–æ–¥–∏—Ä—É—é—â–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∑–∏—Ü–∏–∏ path, –∫–∞–∫ –∏ –≤ –æ–±—ã—á–Ω–æ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–µ –¥–ª—è —Ç–µ–∫—Å—Ç–∞).\n",
    "4. –ö –ø–æ–ª—É—á–µ–Ω–Ω—ã–º –≤–µ–∫—Ç–æ—Ä–∞–º –¥–æ–±–∞–≤–ª—è—é—Ç –µ—â–µ –æ–¥–∏–Ω **0***, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞–∑—ã–≤–∞—é—Ç **class embedding**.\n",
    "\n",
    "–õ—é–±–æ–ø—ã—Ç–Ω–æ, —á—Ç–æ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥. –û–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º—É **class embedding**.  –û—Å—Ç–∞–ª—å–Ω—ã–µ –≤—ã—Ö–æ–¥—ã (–∞ –¥–ª—è –∫–∞–∂–¥–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–µ –µ—Å—Ç—å —Å–≤–æ–π –≤—ã—Ö–æ–¥) –æ—Ç–±—Ä–∞—Å—ã–≤–∞—é—Ç—Å—è –∑–∞ –Ω–µ–Ω–∞–¥–æ–±–Ω–æ—Å—Ç—å—é.\n",
    "\n",
    "–í —Ñ–∏–Ω–∞–ª–µ —ç—Ç–æ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω **0*** –ø—Ä–æ–≥–æ–Ω—è—é—Ç —á–µ—Ä–µ–∑ **MLP** –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—Ç –∫–ª–∞—Å—Å—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–æ–≥–∏—é —Å–æ —Å–≤–µ—Ä—Ç–∫–∞–º–∏. –ï—Å–ª–∏ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —Å–≤–µ—Ä—Ç–æ—á–Ω—É—é —Å–µ—Ç—å –±–µ–∑ —Å–ª–æ–µ–≤ –ø—É–ª–∏–Ω–≥–∞ –∏ –¥—Ä—É–≥–∏—Ö —Å–ø–æ—Å–æ–±–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –∫–∞—Ä—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —Ç–æ –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å —Ç–∞–∫—É—é —Å–µ—Ç—å –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–ª—É—á—à–∞—é—à–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L10/out/selfattention_feature_flow.png\" width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é ViT\n",
    "\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–∫–µ—Ç [ViT PyTorch](https://pypi.org/project/pytorch-pretrained-vit/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pytorch_pretrained_vit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –ø–∞–∫–µ—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ [–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π](https://github.com/lukemelas/PyTorch-Pretrained-ViT#loading-pretrained-models):\n",
    "\n",
    "B_16, B_32, B_16_imagenet1k, ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_vit import ViT\n",
    "\n",
    "model = ViT(\"B_16_imagenet1k\", pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –∫–ª–∞—Å—Å—ã –¥–ª—è –Ω–µ–±–æ–ª—å—à–æ–π —á–∞—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ ImageNet –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω–∏—Ö:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full list of labels\n",
    "#'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
    "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/imagenet_class_index.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=41, compact=True)\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_labels = json.load(f)\n",
    "\n",
    "classes = np.array(list(imagenet_labels.values()))[:, 1]\n",
    "\n",
    "pp.pprint(\n",
    "    dict(list(imagenet_labels.items())[:10])\n",
    ")  # Use Pretty Print to display long dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò –∑–∞–≥—Ä—É–∑–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —Å –∫–æ—Ç–æ—Ä—ã–º –±—É–¥–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/capybara.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capybara_in_pil = Image.open(\"capybara.jpg\")\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((384, 384)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "capybara_in_tensor = transforms(capybara_in_pil)\n",
    "print(capybara_in_tensor.shape)  # torch.Size([1, 3, 384, 384])\n",
    "\n",
    "# Classify\n",
    "with torch.no_grad():\n",
    "    outputs = model(capybara_in_tensor.unsqueeze(0))\n",
    "print(outputs.shape)  # (1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ –Ω–∞–º –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç ViT. –î–ª—è —ç—Ç–æ–≥–æ –ø–æ–¥–≥—Ä—É–∑–∏–º dict —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º –∏–Ω–¥–µ–∫—Å–æ–≤ –≤ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò, —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ, –ø–µ—Ä–µ–≤–µ–¥–µ–º –∏–Ω–¥–µ–∫—Å –≤ –Ω–∞–∑–≤–∞–Ω–∏–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3 = outputs[0].topk(3).indices\n",
    "top3 = top3.tolist()\n",
    "\n",
    "\n",
    "print(\"Top 3 predictions:\")\n",
    "for class_num in top3:\n",
    "    print(class_num, classes[class_num])\n",
    "display(capybara_in_pil.resize((384, 384)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù—É —á—Ç–æ –∂, –ø–æ—á—Ç–∏ (–∫–∞–ø–∏–±–∞—Ä –≤ –∫–ª–∞—Å—Å–∞—Ö ImageNet 1k, –∫–∞–∫ –≤—ã –º–æ–≥–ª–∏ –¥–æ–≥–∞–¥–∞—Ç—å—Å—è, –ø—Ä–æ—Å—Ç–æ –Ω–µ—Ç)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–µ—Å—É—Ä—Å–æ–≤\n",
    "\n",
    "–ö–∞–∫ —Å–ª–µ–¥—É–µ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ [—Å—Ç–∞—Ç—å–∏](https://arxiv.org/abs/2010.11929), **ViT**, –æ–±—É—á–µ–Ω–Ω—ã–π –Ω–∞ **ImageNet**, —É—Å—Ç—É–ø–∞–ª baseline CNN-–º–æ–¥–µ–ª–∏\n",
    "–Ω–∞ –±–∞–∑–µ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–π —Å–µ—Ç–∏ (**ResNet**). –ò —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –±–æ–ª—å—à–µ, —á–µ–º **ImageNet**, –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ —Å—Ç–∞–ª–æ –∑–∞–º–µ—Ç–Ω—ã–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/cited_vit_accuracy.png\"  width=\"400\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/abs/2010.11929\">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (Dosovitskiy et al., 2020)</a></em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Ä—è–¥ –ª–∏ –≤ –≤–∞—à–µ–º —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –æ–∫–∞–∂–µ—Ç—Å—è –¥–∞—Ç–∞—Å–µ—Ç, —Å—Ä–∞–≤–Ω–∏–º—ã–π —Å [JFT-300M](https://paperswithcode.com/dataset/jft-300m) (300 –º–∏–ª–ª–∏–æ–Ω–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π),\n",
    "–∏ GPU/TPU —Ä–µ—Å—É—Ä—Å—ã, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –Ω—É–ª—è (*it could be trained using a standard cloud TPUv3 with 8 cores in approximately 30 days*)\n",
    "\n",
    "–ü–æ—ç—Ç–æ–º—É –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–µ—Ö–Ω–∏–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è —Ä–∞–Ω–µ–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (**fine-tuning**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeiT: Data-efficient Image Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é. –ê–≤—Ç–æ—Ä—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –ø–æ–¥—Ö–æ–¥, –±–ª–∞–≥–æ–¥–∞—Ä—è –∫–æ—Ç–æ—Ä–æ–º—É —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω—ã–º –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º **ImageNet** (ImageNet1k) –Ω–∞ –æ–¥–Ω–æ–π —Ä–∞–±–æ—á–µ–π —Å—Ç–∞–Ω—Ü–∏–∏ –∑–∞ 3 –¥–Ω—è.\n",
    "\n",
    "*We train them on a single computer in less than 3 days. Our reference vision transformer (86M parameters) achieves top-1 accuracy of 83.1% (single-crop evaluation) on ImageNet with no external data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/cited_deit_vit.png\"  width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/abs/2012.12877\">Training data-efficient image transformers & distillation through attention</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–±–æ—Ä —ç—Ç–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ —É–∂–µ –Ω–µ –≤—Ö–æ–¥–∏—Ç –≤ –Ω–∞—à –∫—É—Ä—Å –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–º—É –∏–∑—É—á–µ–Ω–∏—é.\n",
    "\n",
    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ:\n",
    "\n",
    "[[arxiv] üéìTraining data-efficient image transformers\n",
    "& distillation through attention](https://arxiv.org/pdf/2012.12877v2.pdf)\n",
    "\n",
    "–°—Ç–∞—Ç—å–∏, –ø—Ä–µ–¥—à–µ—Å—Ç–≤–æ–≤–∞–≤—à–∏–µ –ø–æ—è–≤–ª–µ–Ω–∏—é **ViT**:\n",
    "\n",
    "[Non-local Neural Networks](https://arxiv.org/abs/1711.07971)\n",
    "\n",
    "[CCNet: Criss-Cross Attention for Semantic Segmentation](https://arxiv.org/abs/1811.11721)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ViT —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è **ViT** —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –Ω–µ –æ–±—É—á–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å –Ω—É–ª—è, –∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–∂–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é.\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º —ç—Ç–æ—Ç –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ. –ï—Å—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π –Ω–∞ **ImageNet** **Visual Transformer**, –Ω–∞–ø—Ä–∏–º–µ—Ä: [deit_tiny_patch16_224](https://github.com/facebookresearch/deit)\n",
    "\n",
    "–ò –º—ã —Ö–æ—Ç–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–µ —Å–æ —Å–≤–æ–∏–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –æ—Ç **ImageNet**.\n",
    "\n",
    "–î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –≤–æ–∑—å–º–µ–º **CIFAR-10**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –º–æ–¥–µ–ª—å. –ö–∞–∫ —É–∫–∞–∑–∞–Ω–æ –Ω–∞ [github](https://github.com/facebookresearch/deit), –º–æ–¥–µ–ª—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ [timm](https://fastai.github.io/timmdocs/), –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å [pytorch-hub](https://pytorch.org/hub/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\n",
    "    \"facebookresearch/deit:main\", \"deit_tiny_patch16_224\", pretrained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è.\n",
    "–ó–∞–≥—Ä—É–∑–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L10/capybara.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò –ø–æ–¥–∞–¥–∏–º –µ–≥–æ –Ω–∞ –≤—Ö–æ–¥ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—É:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "pil = Image.open(\"capybara.jpg\")\n",
    "\n",
    "# create the data transform that DeiT expects\n",
    "imagenet_transform = T.Compose(\n",
    "    [\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "    ]\n",
    ")\n",
    "\n",
    "out = model(imagenet_transform(pil).unsqueeze(0))\n",
    "print(out.shape)\n",
    "pil.resize((224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å —Å **CIFAR-10**, –Ω—É–∂–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–æ–≤ —Å–ª–æ—è, –æ—Ç–≤–µ—á–∞—é—â–∏—Ö –∑–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é. –¢–∞–∫ –∫–∞–∫ –≤ **CIFAR-10** –¥–µ—Å—è—Ç—å –∫–ª–∞—Å—Å–æ–≤, –∞ –≤ **ImageNet** ‚Äî —Ç—ã—Å—è—á–∞.\n",
    "\n",
    "–ß—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, –∫–∞–∫ –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–ª–æ—é, –≤—ã–≤–µ–¥–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–¥–∏–º, —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è head –∏, —Å—É–¥—è –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ –≤—ã—Ö–æ–¥–µ (1000), –∫–æ—Ç–æ—Ä–æ–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–ª–∞—Å—Å–æ–≤ **ImageNet**, –∏–º–µ–Ω–Ω–æ –æ–Ω –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–º–µ–Ω–∏–º –µ–≥–æ —Å–ª–æ–µ–º —Å 10-—é –≤—ã—Ö–æ–¥–∞–º–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–ª–∞—Å—Å–æ–≤ –≤ CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.head = torch.nn.Linear(192, 10, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–µ —Å–ª–æ–º–∞–ª–∞—Å—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(imagenet_transform(pil).unsqueeze(0))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –∑–∞–≥—Ä—É–∑–∏–º **CIFAR-10** –∏ –ø—Ä–æ–≤–µ—Ä–∏–º, –∫–∞–∫ –¥–æ–æ–±—É—á–∏—Ç—Å—è –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "cifar10 = CIFAR10(root=\"./\", train=True, download=True, transform=imagenet_transform)\n",
    "\n",
    "# We use only part of CIFAR10 to reduce training time\n",
    "trainset, _ = torch.utils.data.random_split(cifar10, [10000, 40000])\n",
    "train_loader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = CIFAR10(root=\"./\", train=False, download=True, transform=imagenet_transform)\n",
    "test_loader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " –ü—Ä–æ–≤–µ–¥–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, num_epochs=1):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in tqdm_notebook(train_loader):\n",
    "            inputs, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–æ–æ–±—É—á–∞–µ–º (**fine tune**) —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–π –º—ã –∏–∑–º–µ–Ω–∏–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.head.parameters(), lr=0.001, momentum=0.9)\n",
    "train(model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ—Ä–∏–º —Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–∞ –≤—Å–µ–π —Ç–µ—Å—Ç–æ–≤–æ–π –ø–æ–¥–≤—ã–±–æ—Ä–∫–µ **CIFAR-10**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def accuracy(model, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in testloader:\n",
    "        images, labels = batch\n",
    "        outputs = model(images.to(device))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy of fine-tuned network : {accuracy(model, test_loader):.2f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–æ–æ–±—É—á–∏–≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –Ω–∞ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º 20% –¥–∞–Ω–Ω—ã—Ö, –º—ã –ø–æ–ª—É—á–∏–ª–∏ —Ç–æ—á–Ω–æ—Å—Ç—å ~0.75\n",
    "\n",
    "–ï—Å–ª–∏ –¥–æ–æ–±—É—á–∏—Ç—å –≤—Å–µ —Å–ª–æ–∏ –Ω–∞ 2-—Ö —ç–ø–æ—Ö–∞—Ö, –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ—Ä—è–¥–∫–∞ 0.95.\n",
    "\n",
    "–≠—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞–º–Ω–æ–≥–æ –ª—É—á—à–µ —á–µ–º —Ç–æ—Ç, —á—Ç–æ –º—ã –ø–æ–ª—É—á–∞–ª–∏ –Ω–∞ —Å–µ–º–∏–Ω–∞—Ä–∞—Ö.\n",
    "\n",
    "–î–ª—è —ç—Ç–æ–≥–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ—Ä—è–¥–∫–∞ 10 –º–∏–Ω (–Ω–∞ GPU). –°–µ–π—á–∞—Å –º—ã —ç—Ç–æ–≥–æ –¥–µ–ª–∞—Ç—å –Ω–µ –±—É–¥–µ–º.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò –æ–¥–Ω–æ–π –∏–∑ –ø—Ä–∏—á–∏–Ω —Ç–æ–≥–æ, —á—Ç–æ –æ–±—É—á–µ–Ω–∏–µ –∏–¥–µ—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –º–µ–¥–ª–µ–Ω–Ω–æ, —è–≤–ª—è–µ—Ç—Å—è —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ä–∞–∑–º–µ—Ä–æ–º 32x32 –¥–æ 224x224.\n",
    "\n",
    "–ï—Å–ª–∏ –±—ã –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è **CIFAR-10** –≤ –∏—Ö —Ä–æ–¥–Ω–æ–º —Ä–∞–∑–º–µ—Ä–µ, –º—ã –±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è–ª–∏ –Ω–∏–∫–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –Ω–æ –º–æ–≥–ª–∏ –±—ã –≤ —Ä–∞–∑—ã —É—Å–∫–æ—Ä–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ –≤—Ö–æ–¥–∞ ViT\n",
    "\n",
    "–ù–∞ –ø–µ—Ä–≤—ã–π –≤–∑–≥–ª—è–¥, –Ω–∏—á–µ–≥–æ –Ω–µ –º–µ—à–∞–µ—Ç —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å: **self-attention** —Å–ª–æ–π —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤—Ö–æ–¥–æ–≤.\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ –ø–æ–¥–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –æ—Ç–ª–∏—á–Ω–æ–µ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º –æ—Ç 224x224.\n",
    "\n",
    "–î–ª—è —ç—Ç–æ–≥–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏–º –º–æ–¥–µ–ª—å:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = torch.hub.load(\n",
    "        \"facebookresearch/deit:main\", \"deit_tiny_patch16_224\", pretrained=True\n",
    "    )\n",
    "    model.head = torch.nn.Linear(192, 10, bias=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò —É–±–µ—Ä–µ–º –∏–∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π Resize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transform = T.Compose(\n",
    "    [\n",
    "        # T.Resize((224, 224)),    don't remove this line\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Change transformation in base dataset\n",
    "cifar10.transform = cifar_transform\n",
    "first_img = trainset[0][0]\n",
    "\n",
    "model.to(torch.device(\"cpu\"))\n",
    "try:\n",
    "    out = model(first_img.unsqueeze(0))\n",
    "except Exception as e:\n",
    "    print(\"Exception:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ª—É—á–∞–µ–º –æ—à–∏–±–∫—É.\n",
    "\n",
    "–û—à–∏–±–∫–∞ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –≤ –æ–±—ä–µ–∫—Ç–µ [PatchEmbed](https://huggingface.co/spaces/Andy1621/uniformer_image_demo/blob/main/uniformer.py#L169), –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –Ω–∞–±–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\n",
    "\n",
    "–£ –æ–±—ä–µ–∫—Ç–∞ –µ—Å—Ç—å —Å–≤–æ–π—Å—Ç–≤–æ `img_size`, –ø–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ –ø–æ–º–µ–Ω—è—Ç—å –µ–≥–æ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.patch_embed.img_size = (32, 32)\n",
    "try:\n",
    "    out = model(first_img.unsqueeze(0))\n",
    "except Exception as e:\n",
    "    print(\"Exception:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—É—é –æ—à–∏–±–∫—É.\n",
    "\n",
    "–ò –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –æ–Ω–∞ –≤ —Å—Ç—Ä–æ–∫–µ\n",
    "`x = self.pos_drop(x + self.pos_embed)`\n",
    "\n",
    "x ‚Äî —ç—Ç–æ –Ω–∞—à–∏ –Ω–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è CIFAR-10 –∫–∞—Ä—Ç–∏–Ω–æ–∫\n",
    "\n",
    "–û—Ç–∫—É–¥–∞ –≤–∑—è–ª–æ—Å—å —á–∏—Å–ª–æ 5?\n",
    "\n",
    "4 ‚Äî —ç—Ç–æ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (patch) –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ 32—Ö32, –∏—Ö –≤—Å–µ–≥–æ 4 (16x16) + –æ–¥–∏–Ω embedding –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º–æ–≥–æ –∫–ª–∞—Å—Å–∞(class embedding).\n",
    "\n",
    "–ê 197 ‚Äî —ç—Ç–æ positional encoding ‚Äî —ç–º–±–µ–¥–¥–∏–Ω–≥–∏, –∫–æ–¥–∏—Ä—É—é—â–∏–µ –ø–æ–∑–∏—Ü–∏—é —ç–ª–µ–º–µ–Ω—Ç–∞. –û–Ω–∏ –æ—Å—Ç–∞–ª–∏—Å—å –æ—Ç **ImageNet**.\n",
    "\n",
    "–¢–∞–∫ –∫–∞–∫ –≤ ImageNet –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Ä–∞–∑–º–µ—Ä–∞ 224x224, —Ç–æ –≤ –∫–∞–∂–¥–æ–π –ø–æ–º–µ—â–∞–ª–æ—Å—å 14x14 = 196 —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏ –µ—â–µ embedding –¥–ª—è –∫–ª–∞—Å—Å–∞, –∏—Ç–æ–≥–æ 197 –ø–æ–∑–∏—Ü–∏–π.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –ø–æ–∑–∏—Ü–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ —Å–≤–æ–π—Å—Ç–≤–æ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pos_embed.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω–∞–º –Ω–∞–¥–æ –∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ pos embeddings —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–æ –±—ã–ª–æ —Ä–∞–≤–Ω–æ 5  (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ patch + 1).\n",
    "–í–æ–∑—å–º–µ–º 5 –ø–µ—Ä–≤—ã—Ö:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pos_embed.data = model.pos_embed.data[:, :5, :]\n",
    "out = model(first_img.unsqueeze(0))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞—Ä–∞–±–æ—Ç–∞–ª–æ!\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å –æ–±—É—á–∏–º –º–æ–¥–µ–ª—å. –¢–∞–∫ –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç–∞–ª–∏ –Ω–∞–º–Ω–æ–≥–æ –º–µ–Ω—å—à–µ, —Ç–æ –º—ã –º–æ–∂–µ–º —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä batch –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç. –¢–∞–∫–∂–µ –±—É–¥–µ–º –æ–±—É—á–∞—Ç—å –≤—Å–µ —Å–ª–æ–∏, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10.transform = cifar_transform\n",
    "train_loader = DataLoader(cifar10, batch_size=512, shuffle=True, num_workers=2)\n",
    "\n",
    "# Now we train all parameters because model altered\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "train(model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∏–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ.\n",
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.transform = cifar_transform\n",
    "print(f\"Accuracy of altered network : {accuracy(model,test_loader):.2f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∏–ª—å–Ω–æ —Ö—É–∂–µ.\n",
    "\n",
    "–≠—Ç–æ –º–æ–∂–Ω–æ –æ–±—ä—è—Å–Ω–∏—Ç—å —Ç–µ–º, —á—Ç–æ  –º–∞–ª–µ–Ω—å–∫–∏–µ patch  ImageNet(1/196) —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —á–µ—Ç–≤–µ—Ä—Ç–∏–Ω–æ–∫ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –∏–∑ CIFAR-10 (1/4).\n",
    "\n",
    "–ù–æ –µ—Å—Ç—å –∏ –¥—Ä—É–≥–∞—è –ø—Ä–∏—á–∏–Ω–∞: –º—ã –≤–∑—è–ª–∏ –ª–∏—à—å –ø–µ—Ä–≤—ã–µ 4 pos_embedding –∞ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –æ—Ç–±—Ä–æ—Å–∏–ª–∏. –í –∏—Ç–æ–≥–µ –º–æ–¥–µ–ª—å –≤—ã–Ω—É–∂–¥–µ–Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∑–∞–Ω–æ–≤–æ –æ–±—É—á–∞—Ç—å—Å—è —Ä–∞–±–æ—Ç–∞—Ç—å —Å –º–∞–ª—ã–º pos_embedding, –∏ –¥–≤—É—Ö —ç–ø–æ—Ö –¥–ª—è —ç—Ç–æ–≥–æ –º–∞–ª–æ.\n",
    "\n",
    "–ó–∞—Ç–æ —Ç–µ–ø–µ—Ä—å –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –ª—é–±–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
