{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Машинное обучение <a class=\"anchor\" id=\"ml\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. ML и DL и AI в Computer Science <a class=\"anchor\" id=\"ml_dl_al\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Место глубокого обучения и нейронных сетей в ИИ**\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/Intro1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует множество разных определений, однако большая часть из них завязана на человеко-машинном взаимодействии, то есть это алгоритмы или методы, которые либо имитируют поведение людей, либо позволяют машине вести себя аналогично людям (то есть проявлять некоторое интеллектуальное-разумное поведение). Область ИИ не ограничивается исключительно машинным обучением, которое состоит из обучения на примерах. В ИИ входит целый ряд алгоритмов, например многоагентные системы (расшифровка) или базы знаний, в которых люди создают связи между разными понятиями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Искусственный интеллект (AI/ИИ)**  ≈ область ИТ/Computer science, связанная с моделированием интеллектуальных или творческих видов человеческой деятельности.\n",
    "\n",
    "**Машинное обучение(ML)** — подраздел ИИ, основыванный на концепции, что система с искусственным интеллектом должна уметь самостоятельно накапливать знания, отыскивая закономерности в исходных данных, что позволяет компьютерной системе совершенствоваться по мере накопления опыта. Машинное обучение &mdash;не единственный раздел ИИ. Например, базы знаний или многоагентные системы также относят к разделам ИИ.\n",
    "\n",
    "**Глубокое обучение (Deep Learning, DL)** ≈ Многослойная нейросеть (MLP = multi layer perceptron). Частный случай машинного обучения, позволяющий достичь большей эффективности и гибкости за счет представления мира в виде иерархии понятий, каждое из которых определено через более простые понятия.  Иерархическая организация организация дает компьютеру возможность учиться более сложным концепциям путем построения их из более простых.\n",
    "\n",
    "Модели, которые имеют подобную иерархию, называются глубокими или нейросетевыми. Хотя, если мы возьмем один уровень (слой) такой модели (например линейный классификатор, он же перцептрон), он перестанет быть глубокой моделью, хотя по факту он и является простейшей нейросетью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Области применения DL <a class=\"anchor\" id=\"dl\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/Intro2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последнее время именно такого рода модели показывают высокую эффективность в тех областях, в которых влияние человека казалось превалирующим. В частности, это человеко-компьютерное зрение (Computer Vision, CV), распознавание естественного языка (NLP, извлечение смысла, машинный перевод) и речи. В рамках курса мы рассмотрим, как эта область может применяться на практических задачах и моделях, их решающих. Также мы познакомимся с результатами самых современных исследований по теме. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Связь DL с наукой <a class=\"anchor\" id=\"dl_sci\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/Intro3.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо прикладных задач существуют еще и научные исследования, результаты которых до известной степени непредсказуемы. Нельзя исключать то, что они окажутся применимы к решению новых задач, в том числе в областях, где применяются технологии DL, где до сих пор активно не использовались. Поддержка такого рода исследований и есть основная задача нашего курса. \n",
    "\n",
    "В первую очередь для нас важны задачи аспирантов, на которых и будет построены дальнейшие исследования. И именно на основе ваших задач будут сделаны выводы о моделях, рекомендованных под конкретно ваш случай."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. История глубокого обучения <a class=\"anchor\" id=\"hist\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретические основы искусственных нейронных сетей были заложены более 50 лет назад."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/hist.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему же для решения практических задач их начали активно стали применять только в последние 10 лет?\n",
    "\n",
    "Давайте разберемся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Перцептрон<a class=\"anchor\" id=\"ml_4_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предшественниками современных глубоких нейронных сетей были простые линейные модели на основе нейробиологических аналогий. Они принимали множество $n$ входных значений $x_1,...,x_n$ и ассоциировали с ними выход $y$. В ходе обучения такой линейной модели нужно было подобрать такие веса $w_1,...,w_n$, чтобы приблизить выход модели $f(x,w)=x_1w_1+...+x_nw_n$ к желаемому $y$. Веса задавал человек.\n",
    "\n",
    "Первая модель, которая могла находить нужные веса в процессе обучения, имея примеры входных данных &mdash; **перцептрон**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/histperceptron.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перцептро́н, или персептрон (англ. perceptron от лат. perceptio — восприятие; нем. Perzeptron) — математическая или компьютерная модель восприятия информации мозгом (кибернетическая модель мозга), предложенная Фрэнком Розенблаттом в 1957 году и впервые реализованная в виде электронной машины «Марк-1» в 1960 году. Перцептрон стал одной из первых моделей нейросетей, а «Марк-1» — первым в мире нейрокомпьютером. \n",
    "\n",
    "Классический метод обучения перцептрона — это метод коррекции ошибки. Он представляет собой такой вид обучения с учителем, при котором вес связи не изменяется до тех пор, пока текущая реакция перцептрона остаётся правильной. При появлении неправильной реакции вес изменяется на единицу, а знак (+/-) определяется противоположным от знака ошибки. \n",
    "\n",
    "У перцептрона имеется ряд ограничений. Самое известное состоит в невозможности обучить функцию XOR &mdash; разделения объектов на два класса на основании двух признаков, принимающих значения 1 или 0, для которой объекты с признаками [0,1] и [1,0] относятся к категории 1, а объекты с признаками [1,1] и [0,0] &mdash; к категории 0. В данной задаче объекты категории 1 и 0 линейно неразделимы, т.е не существует прямой на плоскости, для которой все точки объекты одного класса расположены с одной стороны, а другого — с другой.\n",
    "\n",
    "На фоне роста популярности нейронных сетей в 1969 году вышла книга Марвина Минского и Сеймура Паперта, которая показала принципиальные ограничения перцептронов. Это привело к смещению интереса исследователей искусственного интеллекта в противоположную от нейросетей область символьных вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/histcat.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной из важнейших работ, связанных с глубоким обучением, является эксперимент американских биологов из Гарварда. В 1959 были изучены реакции определенных участков кошачьего мозга на определенные простые визуальные стимулы. Как и большая часть открытий, это выяснилось абсолютно случайно. \n",
    "\n",
    "В мозг кошке был вживлен электрод для того, чтобы определить, на какой рисунок будет реакция. Однако стоит вспомнить, что в то время слайды переключались последовательным движением и именно на это движение случилась реакция. Как только менялся слайд и по экрану проходила граница затвора, по сути простая прямая линия, реакция передавалась и записывалась.\n",
    "\n",
    "После ряда экспериментов выяснилось, что существуют клетки, реагирующие на простые формы (линии и углы), на движение и движение в определенном направлении или определенной формы. Слои этих клеток образуют определенного рода иерархию, которая лежит в основе концепции нейросетевых методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img_license/fukushima.png\" width=\"400\" >\n",
    "\n",
    "\n",
    "<center><em>1975 - Cognitron: A self-organizing multilayered neural network K.Fukushima</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом мы можем подчерпнуть некоторые концепции из нейробиологии. Основная заимствованная идея &mdash; наличие большого числа вычислительных блоков, взаимодействующих друг с другом.\r\n",
    "\r\n",
    "Модель **неокогнитрона** — иерархическая многослойная искусственная нейронная сеть, была предложена Кунихико Фукусима для эффективной обработки изображений на основании структуры зрительной системы млекопитающих. Эта модель впоследствии легла в основу современных **сверточных нейронных сетей** &mdash; специального вида нейронных сетей для обработки данных с сетчатой структурой (например, изображений, представимых в виде сетки пикселей).\r\n",
    "\r\n",
    "На момент описания не было ни компьютерных ресурсов для обучения такой модели, ни эффективного алгоритма обучения. Несмотря на то, что нейробиология легла в основу нескольких успешных архитектур нейронных сетей, мы до сих пор знаем недостаточно об обучении биологических нейронных сетей, чтобы использовать эти знания для построения алогритмов обучения искуственных нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Метод обратного распространения ошибки<a class=\"anchor\" id=\"ml_4_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении нейронной сети, информация передается по ней в одном направлении &mdash; от входных данных до следующих слоев и далее, порождая некий выход $\\hat{y}$. Такой поток информации называется **прямым распространением**. На основании этого выхода нейронной сети вычисляется функция ошибки $L(\\hat{y},y)$, которая говорит о том, насколько предсказание $\\hat{y}$, сделанное нейронной сетью, отличается от настоящего значения $y$. В простейшем случае $L(\\hat{y},y)=\\hat{y}-y$. Для дальнейшего обучения необходимо учесть эту ошибку, чтобы скорректировать предсказание нейронной сети. **Градиент** функции ошибки показывает направление её наискорейшего возрастания. Соответственно, отрицательный градиент может быть использован для поиска минимума функции ошибки. В современных нейронных сетях для вычисления градиента используется метод обратного распространения ошибки (англ. backpropagation).\n",
    "\n",
    "**Метод обратного распространения ошибки** позволяет передавать сигналы об ошибке, сделанной нейронной сетью, от выходов сети к её входам, в направлении, обратном прямому распространению. Эти сигналы затем используются для вычисления градиента, используемого для корректировки предсказания нейронной сети. \n",
    "\n",
    "Для возможности применения метода обратного распространения ошибки передаточные функции нейронов, используемые при прямом распространении, должны быть дифференцируемы.\n",
    "\n",
    "<img src =\"https://camo.githubusercontent.com/74e8378ad0f412ad39f53e5ef4d0f1d4fa69250585cd60e97d12a4c601d82fe9/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f312a71314d374c47694454697277552d344c634671375f512e706e67\" width=\"700\" >\n",
    "\n",
    "Впервые метод был описан в 1974 г. А. И. Галушкиным, а также независимо и одновременно Полом Дж. Вербосом. Далее существенно развит в 1986 г. Дэвидом И. Румельхартом, Дж. Е. Хинтоном и Рональдом Дж. Вильямсом.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По <a href=\"https://scholar.google.ru/citations?user=3F4eOJMAAAAJ&hl=ru\">ссылке</a> можно найти полный перечень работ А.И. Галушкина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Успехи современных нейронных сетей<a class=\"anchor\" id=\"ml_4_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/histlecun.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появление алгоритма обратного распространения ошибки вкупе с возрастающими компьютерными мощностиями позволило обучить многослойную нейронную сеть, которую можно было применять для решения практических задач.\n",
    "\n",
    "Архитектура такой сети была разработана в 1989 г. Яном Ле Куном. \n",
    "Сеть имела **5** слоёв, из них **2** свёрточных.\n",
    "\n",
    "Применялась в США для распознавания рукописных букв на почтовых конвертах до начала 2000г."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Победа нейросети AlexNet на соревновании ImageNet в 2012**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img_license/histimagenet.png\" width=\"900\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 2012 году свёрточная нейронная сеть **AlexNet** (Alex Krizhevsky in collaboration with Ilya Sutskever and Geoffrey Hinton) победила на ImageNet c большим отрывом от конкурентов.\r\n",
    "Это событие породило новую волну интереса к алгоритмам глубокого обучения и, в частности, к свёрточным нейронным сетям.\r\n",
    "\r\n",
    "**AlexNet** — свёрточная нейронная сеть, которая оказала большое влияние на развитие машинного обучения, в особенности — на алгоритмы компьютерного зрения. Сеть с большим отрывом выиграла конкурс по распознаванию изображений ImageNet LSVRC-2012 в 2012 году (с количеством ошибок 15,3% против 26,2% у второго места). Архитектура AlexNet схожа с созданной Yann LeCum сетью LeNet. Однако у AlexNet больше фильтров на слое и вложенных свёрточных слоев.\r\n",
    "\r\n",
    "<a href=\"https://neurohive.io/ru/vidy-nejrosetej/alexnet-svjortochnaja-nejronnaja-set-dlja-raspoznavanija-izobrazhenij/\">Ссылка</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ImageNet: Large Scale Visual Recognition Challenge (ILSVRC)**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/imagenet1.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://en.wikipedia.org/wiki/Fei-Fei_Li\">Fei-Fei Li </a>\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Christiane_Fellbaum\">Christiane Fellbaum</a>\n",
    "\n",
    "\n",
    "С 2010 года в рамках проекта ILSVRC проводятся соревнования между исследовательскими группами по классификации объектов. ILSVCR возникла по аналогии с небольшой кампанией 2005 года PASCAL VOC, которая располагала набором из 20 тысяч изображений и 20 классов объектов. Существенный прогресс в распознавании образов был достигнут в 2010 году. В 2011 году хорошим результатом считалась ошибка классификации 25 %. В 2012 году система глубокого обучения на основе свёрточной нейронной сети смогла достичь 16 % ошибки, а в следующие годы ошибка упала до нескольких процентов. В 2015 году исследователи констатировали, что программы в определённых задачах проекта ILSVRC превзошли человеческие способности. \n",
    "\n",
    "**Условия соревнования:**\n",
    "На каждом изображении может быть один или несколько предметов, относящихся к одному из **1000** классов.\n",
    "Для метрики *Тop5* алгоритм выдает метки 5 классов. Если предмет, относящийся к одному из этих классов, есть на изображении, то ответ засчитывается как верный.\n",
    "Для *Top1* соответственно принимается только метка одного класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/alexnetcitation.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы понять важность победы AlexNet в 2012г., достаточно посмотреть на количество ссылок на данную работу.\n",
    "\n",
    "Оно сравнимо с количеством цитирований основополагающих трудов в различных областях науки и продолжает расти.\n",
    "\n",
    "• Клод Шеннон “Математическая теория связи” — позволила решить основные задачи теории информации;\n",
    "\n",
    "• Фрэнсис Криком и Джеймсом Д. Уотсон  “Молекулярная структура нуклеиновых кислот: структура дезоксирибонуклеиновой кислоты” - первая статья, в которой было опубликовано описание открытия двойной спирали структуры ДНК;\n",
    "\n",
    "• Обнаружение бозона Хиггса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Количество Цитирований\n",
    "\n",
    "Ч. Дарвин, \"О происхождении видов\", 1859: **50,007**\n",
    "\n",
    "К. Шеннон, “Математическая теория связи”, 1953: **69,351**\n",
    "\n",
    "Д. Уотсон и Ф. Крик, “Молекулярная структура нуклеиновых кислот”, 1953: **13,111**\n",
    "\n",
    "ATLAS Collaboration, \"Наблюдение новой частицы в поисках Стандартной модели бозона Хиггса с детектором ATLAS на баке\", 2012: **14 429**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ML — Подход к научным проблемам <a class=\"anchor\" id=\"ml_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Извлечение закономерностей — закон Ньютона <a class=\"anchor\" id=\"ml_4_1\"></a>\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img_license/tasks.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе наблюдений люди выявляют закономерности и делают обобщение, наблюдая за реальным миром.\n",
    "Результатом такой умственной деятельности является модель, описывающая некоторые процессы реального мира.\n",
    "\n",
    "Она может быть описана при помощи математических формул или алгоритмического языка.\n",
    "\n",
    "Сейчас появилась технология, которая может это делать вместо человека."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img_license/ml.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Это ML**\n",
    "\n",
    "**ML** — это технология, которая позволяет выявлять закономерности в данных и обобщать их. \n",
    "\n",
    "Вы можете использовать её для поиска закономерностей, которые люди ещё не обнаружили и таким образом совершить открытие.\n",
    "Правда, результатом обучения такой модели будет не компактная формула, а набор весов. \n",
    "По сути это набор коэффициентов для некоторого математического выражения.\n",
    "\n",
    "Для этого нужно две вещи: **данные** и **валидация результата.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/prepare.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как человеку, так и алгоритму машинного обучения требуется подготовка данных.\n",
    "\n",
    "Законы Ньютоны **не** сформулированы для яблок. Для описания закономерностей в науке используются абстракции: *сила, масса, ускорение.*\n",
    "\n",
    "Данные для **ML** моделей тоже должны быть подготовлены. Типичная форма такой абстракции — вектор или n-мерный массив чисел.\n",
    "\n",
    "Именно с такой формой представления данных работают большинство современных моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img_license/appraisal.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй элемент, который потребуется для процесса обучения —  разработка способа оценки результата (*валидации*).\n",
    "\n",
    "Вне зависимости от того, какой метод обучения используется — с учителем или без, требуется некий критерий, по которому будет оцениваться выход модели и впоследствии корректироваться веса.\n",
    "\n",
    "В базовом варианте: полученный результат сравнивают с эталонным и если разница велика — корректируют модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Пример <a class=\"anchor\" id=\"first-bullet\"></a> <a class=\"anchor\" id=\"example \"></a>\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img_license/ex1.jpg\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Поясним эту идею на конкретном примере. Допустим, у нас есть наручный шагомер, который фиксирует перемещения в пространстве. Скорее всего в нем встроен акселерометр, который способен фиксировать перемещения по трем осям. На выходе мы получаем сигнал с нескольких(3-х) датчиков.\n",
    "\n",
    "Если задача состоит в том, чтобы подсчитать количество шагов, то к её решению можно подойти двумя способами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классический: напишем программу. \n",
    "Если появилось ускорение по одной из осей, которое больше определенного порога, то мы создаем то условие, которое срабатывает. Позже мы выясним, что подобные сигнатурные сигналы с датчика могут поступить и при других определенных движениях, не связанных с шагами, например, во время плавания.\n",
    " Добавляется дополнительное условие, которое фильтрует подобные ситуации. \n",
    "\n",
    "Находятся всё новые и новые исключения из общего правила, программа и ее алгоритмическая сложность будет расти.\n",
    "\n",
    "Программу будет сложнее поддерживать из-за большого объема кода в ней. \n",
    "Изменение в одной из частей потребует внесение правок в другой код  и.т.п."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"https:///edunet.kea.su/repo/src/L01_Intro/img_license/ex2.png\" width=\"700\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант №2\n",
    "\n",
    "\n",
    "С появлением машинного обучения мы можем применить принципиально другой подход. \n",
    "Не задумываясь о том, что значат показания каждого из акселерометров, мы можем просто собрать некоторый архив данных за определенное время (возможно разбив на более короткие промежутки времени). Всё, что нам потребуется помимо этих данных — это информация о том, сколько было сделано реальных шагов. После этого данные загружаются в модель и она на этих данных учится. При достаточном количестве данных и адекватно подобранной модели (чем мы и будем заниматься) мы сможем научить ее решать конкретные задачи (в данном случае — считать шаги). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img_license/ex3.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что по сути модели всё равно, что считать: шаги, сердечный ритм, количество калорий, ударов по клавиатуре и пр. Нет необходимости писать под каждый пример отдельную программу, достаточно собрать данные и мы сможем решить множество абсолютно разных задач. \n",
    "\n",
    "Важно лишь понимать, какую модель предпочтительнее выбрать. С этим мы и будем разбираться в ходе курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img_license/ex4.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Базовые задачи машинного обучения <a class=\"anchor\" id=\"basic\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/exall.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://scikit-learn.org/stable/\">Ссылка </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все многообразие практических задач базируются на трех базовых.\r\n",
    "\r\n",
    "* Регрессия — предсказание числового значения, характеризующего объект, на основании признаков объекта; \r\n",
    "* Классификация — предсказание класса, к которому принадлежит объект на основании признаков объекта;\r\n",
    "* Кластеризация — разбиение объектов на заранее неизвестное число классов (близка к классификации, но не эквивалентна ей).\r\n",
    "\r\n",
    "Умея решать эти задачи, можно перейти почти к любой, рассматриваемой в примерах (детекции, сегментации и.т.п.). Начнем с них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/class.png\" width=\"700\" >\n",
    "\n",
    "Решение задачи классификации является одним из важнейших способов применения нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача классификации представляет собой отнесение объекта к одному из нескольких попарно не пересекающихся множеств.\n",
    "\n",
    "Объекты могут быть различны по своей природе: символы текста, изображения, образцы звуков и т. д. При обучении, модели подаются на вход различные объекты с указанием того, к какому классу они относятся. Объект характеризуется некоторыми признаками, используемыми для построения модели. Образец подается на вход модели как вектор значений признаков. При этом совокупность всех признаков должна однозначно определять класс, к которому относится образец. В случае, если признаков недостаточно, модель может соотнести один и тот же образец с несколькими классами, что неверно. \n",
    "\n",
    "По окончании обучения модели, ей можно предъявлять неизвестные ранее образы и получать ответ об их принадлежности к определённому классу.\n",
    "\n",
    "Примером задачи классификации может служить предсказание ответа пациента на терапию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/regress.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задаче регрессии  модель должна предсказать некоторое числовое значение по входным данным. Регрессия отличается от классификации форматом выхода.\n",
    "\n",
    "При обучении, регрессионной модели также подаются на вход различные объекты (в виде вектора значений призаков) с указанием числового, которое модель будет учиться предсказывать. После обучения модель способна предсказать значение искомого признака объекта на основе зависимостей между входными и выходными данными, выявленных в процессе обучения. \n",
    "\n",
    "Примером задачи регрессии может служить предсказание стоимости жилья, или прогнозирование котировок акций.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогнозирование возможно только тогда, когда предыдущие изменения действительно в какой-то степени предопределяют будущие. В частности, прогнозирование котировок акций на основе котировок за прошлую неделю может оказаться успешным (а может и не оказаться), тогда как прогнозирование результатов завтрашней лотереи на основе данных за последние 50 лет почти наверняка не даст никаких результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/clust.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под кластеризацией понимается разбиение множества входных объектов на классы, при том, что ни количество, ни признаки классов заранее не известны. После обучения модель способна определять, к какому классу относится входной объект. Модель также может сигнализировать о том, что входной объект не относится ни к одному из выделенных классов — это является признаком новых, отсутствующих в обучающей выборке, данных. Таким образом, подобная модель может выявлять новые, неизвестные ранее классы объектов. Соответствие между классами, выделенными сетью, и классами, существующими в предметной области, устанавливается человеком. Задача кластеризации относится к  к широкому классу задач обучения без учителя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Данные <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/types.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большинство процессов и объектов, с которыми научились работать ML/DL модели, можно отнести к одному из перечисленных типов. Наша задача будет состоять в том, как данные из вашей предметной области свести к одному из них и представить в виде набора чисел. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с различными типами данных используют разные типы моделей:\n",
    "\n",
    "**Табличный**  — классические ML модели либо полносвязанные NN;\n",
    "\n",
    " **Последовательности** — рекуррентные сети + свёртка;\n",
    " \n",
    " **Изображения/видео** — 2,3 .. ND свёрточные сети.\n",
    " \n",
    "\n",
    "\n",
    "В разных типах данных количество связей между элементами разное и зависит только от типа этих данных. Важно НЕ количество элементов, а СВЯЗИ между ними.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/types2.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Данные мы можем условно делить по степени связанности. Это степень взаимного влияния между соседними элементами. \n",
    "Например, в таблице, в которой есть определенные параметры (например: рост, вес) данные между собой связаны, но порядок столбцов значения не имеет.\n",
    "Если мы поменяем столбцы местами, то не потеряем никакой важной информации. \n",
    "\n",
    "Такие данные можно представить в виде вектора, но порядок элементов в нем не важен.\n",
    "\n",
    "При работе с изображениями нам становится важно, как связаны между собой пиксели и по горизонтали, и по вертикали. \n",
    "При добавлении цвета появляются 3 RGB канала, и значения в каждом канале также связаны между собой. Эту связь нельзя терять, если мы хотим корректно извлечь максимум информации из данных. Соответственно, если дано цветное изображение, то у нас уже есть три измерения, в которых мы должны эти связи учитывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Области применения и технологии <a class=\"anchor\" id=\"tech\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.  Робототехника <a class=\"anchor\" id=\"robo\"></a>\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img_license/robo.jpg\"  width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросети широко применяются для решения задач технического зрения. Различным роботизированным устройствам от таких, как беспилотные транспортные средства, до промышленных роботов или домашнего пылесоса, требуется определять своё местоположение в пространстве и/или местоположение окружающих объектов. \r\n",
    "\r\n",
    "Эту задачу можно решать путем обработки изображений с камер. Здесь очень эффективными оказались свёрточные нейросети, подобные AlexNet. \r\n",
    "\r\n",
    "Роботы присутствуют в нашей жизни в виде дронов, машин, пылесосов. Для моделирования их зрения используется задачи детекции, треккинга на видео, сегментации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Детектирование (object detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img_license/detectionrobo.jpg\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8\"> КЛАССИФИКАЦИЯ </a> + <a href=\"https://proglib.io/p/ml-regression/\\\">РЕГРЕССИЯ </a> ~ = <a href=\"http://robocraft.ru/blog/computervision/3640.html\\\">ДЕТЕКТИРОВАНИЕ </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://blogs.nvidia.com/blog/2019/04/15/how-does-a-self-driving-car-see/\">Ссылка </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача поиска местоположения объекта в кадре — это задача детектирования. Она тесно связана с задачей классификации:\n",
    "\n",
    "Сначала обучается сеть, которая классифицирует изображения. То есть определяет, что на изображении присутствует человек. \n",
    "\n",
    "Затем к такой сети добавляются несколько слоев, которые предсказывают координаты объектов. То есть решают задачу регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знание координат объектов вокруг позволяет решать различные более сложные задачи: \n",
    "\n",
    "• Трекинг (отслеживание перемещения);\n",
    "\n",
    "• Предсказание действий;\n",
    "\n",
    "• SLAM (*simultaneous localization and mapping* — одновременная локализация и построение карты);\n",
    "\n",
    "• Оценка расстояний до объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic whale counting in satellite images with deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/whales.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот пример использования аналогичного подхода у биологов. Авторы статьи обучили нейронную сеть искать на спутниковых снимках китов и подсчитывать их количество. \n",
    "Отдельно можно использовать классификатор для определения вида кита по <a href=\"https://arxiv.org/pdf/1604.05605.pdf\">ссылке</a>. \n",
    "Аналогичным образом можно обучить сеть искать объекты любых других категорий. Совсем не обязательно на изображениях в видимом диапазоне.\n",
    "\n",
    "Ссылка на репозиторий с реализацией: https://github.com/EGuirado/CNN-Whales-from-Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Безопасность <a class=\"anchor\" id=\"security\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img_license/video.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видеоаналитика.\n",
    "\n",
    "Про системы распознавания лиц все вероятно слышали.\n",
    " Что скрывается “под капотом”?\n",
    "Несколько моделей. Одна ищет лицо на изображении. Кстати, с этим достаточно успешно справлялись и алгоритмы без применения глубокого обучения (ViolaJones 2001). \n",
    "Другая ищет ключевые точки, чтобы потом изображение выронить. \n",
    "\n",
    "Решаются те же две задачи (классификация + регрессия).\n",
    "\n",
    "Но количество людей, проходящих мимо камеры в метрополитене, огромно. И что хуже, их список заранее не известен. Поэтому мы не можем использовать классификатор, чтобы отличить лицо одного человека от другого. Нам просто неизвестно количество классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img_license/clustrobo.jpg\" width=\"1100\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому при распознавании лиц применяется другая техника: по вырезанному и выравненному прямоугольнику с лицом строится вектор-признак “embedding” — некое компактное представление.\r\n",
    "\r\n",
    "По сути сильно снижается размерность изображения.\r\n",
    "\r\n",
    "А дальше можно сравнить между собой полученные векторы, использовав любую метрику расстояния. \r\n",
    "\r\n",
    "То есть к классификации и регрессии добавляется 3-я базовая задача: **кластеризация**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Анализ медицинских изображений </a>  <a class=\"anchor\" id=\"img\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/medskan_.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"\n",
    "https://neurohive.io/ru/vidy-nejrosetej/u-net-image-segmentation/\n",
    "\">Ссылка </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: поиск аномалий (опухолей) и определение их четких границ.\r\n",
    "\r\n",
    "В данном примере приведена задача сегментации. Эта задача очень похожа на детектирование. Нужно найти, где находится объект. Но в данном случае нужно найти четкие границы. Желательно с точностью до пикселя.\r\n",
    "\r\n",
    "То есть для каждого пикселя нужно предсказать, к какому объекту он относится. \r\n",
    "\r\n",
    "**Получается попиксельный классификатор.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но проблема состоит в том, что пикселей много, и решать её в лоб — неэффективно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому при сегментации используется подход, подобный тому, что при **кластеризации лиц:**\n",
    "\n",
    "• Часть нейросети сжимает изображение — получается карта признаков (карта, потому что структура сохраняется);\n",
    "\n",
    "• На этой карте (см. выше) предсказываются границы объектов;\n",
    "\n",
    "• Вторая часть сети (симметрично первой восстанавливает размеры)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Это концепция энкодер - декодер.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img_license/gan1.png\" width=\"1000\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На базе концепции энкодер - декодер появились так называемые генеративно-состязательные сети.\n",
    "Сжатое представление, которое получается на внутреннем слое сети, содержит какие-то ключевые признаки изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но не всю информацию об изображении и в зависимости от того как будет идти процедура восстановления мы можем получить разные вариации изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Почему состязательные?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку сеть генерирует совершенно новое изображение, у нас нет шаблона, с которым мы могли бы его сравнить и дать оценку работы модели.\n",
    "Поэтому для оценки качества работы первой сети (генератора) обучается вторая (дискриминатор), которая дает ответ на вопрос: похоже ли полученное изображение на настоящее или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/gan3.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С результатами работы таких моделей вы все хорошо знакомы по соцсетям и мобильным приложениям.\n",
    "Помимо использования в развлекательных целях, эта технология широко используется и в научных работах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка изображений галактик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/galaxy.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://academic.oup.com/mnrasl/article/467/1/L110/2931732\">Ссылка </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения, полученные при помощи телескопов, оказываются зашумленными по причинам:\n",
    "- атмосферных помех;\n",
    "- шумам, которые даёт сенсор телескопа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классический способ борьбы с этой проблемой состоит в подборе сигнала похожего на суммарный шум: point spread function (PSF) и последующей сверке изображения с этим сигналом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе для решения той же проблемы авторы статьи обучили GAN.\n",
    "В качестве входных данных использовались изображения галактик.\n",
    "\n",
    "*4550 galaxies from the Sloan Digital Sky Survey Data Release 12 (York et al. 2000; Alam et al. 2015)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/galaxy2.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения преобразовывались в RGB формат. И к ним искусственно добавлялись искажения, имитирующие шум от сенсора и размытие, возникающее за счёт потоков воздуха в атмосфере(PSF).\n",
    "Датасет состоял из пар зашумленных и чистых изображений.\n",
    "\n",
    "Генератор обучался на основе изображения с шумом генерировать чистое изображение, а дискриминатор отличал зашумленные изображения от чистых.\n",
    "\n",
    "На первый взгляд результат впечатляет. Однако авторы признают что на фотографиях, где присутствуют объекты, редко появляющиеся в датасете, результат хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://academic.oup.com/mnrasl/article/467/1/L110/2931732\">Ссылка </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN & OneShot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/oneshot.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели, которые мы рассматривали, до сих обучаются на большом количестве данных. \n",
    "В ряде областей (например, в медицине) их может не хватать.\n",
    "\n",
    "Вот пример статьи, в которой авторы обучили GAN сегметировать МРТ снимках мозга с признаками рассеянного склероза, а затем использовали её для поиска опухолей, дообучив модель всего на 5 снимках.\n",
    "\n",
    "<a href=\"https://indico.cern.ch/event/967970/contributions/4118959/attachments/2151681/3628080/Burnaev_Manifold_Knowledge_Transfer_v2.pdf\">Ссылка</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Применение сегментации МРТ в медицине:**\r\n",
    "\r\n",
    "• анализ и мониторинг опухолей (например, головного мозга, печени);\r\n",
    "\r\n",
    "• обнаружение бляшек рассеянного склероза;\r\n",
    "\r\n",
    "• обнаружение гиперестезии белого вещества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Человеко-машинное взаимодействие <a class=\"anchor\" id=\"npl\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP & Speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img_license/npl1.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Область применения DL не ограничивается только изображениями. \r\n",
    "\r\n",
    "Они так же весьма эффективны для распознавания голоса и машинного перевода.\r\n",
    "В отличие от изображений, входные данные имеют другую структуру: это последовательность, длина которой заранее неизвестна.\r\n",
    "\r\n",
    "Для работы с такого рода данными используются сети другого типа — **рекуррентные**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img_license/rnn.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nature.com/articles/s41598-019-48909-4\n",
    "\">Ссылка </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекуррентные нейронные стеи &mdash; это семейство нейронных сетей для обработки последовательных данных. Примером таких данных может быть предложение, состоящие из слов, записанных в определенном порядке. Порядок слов учитывается при подаче предложения в сеть таким образом, что\r\n",
    "каждое слово (каждый элемент данных) может оказывать влияние на выход модели и менять ее состояние. \r\n",
    "\r\n",
    "Ниже можно найти статью, в которой авторы использовали эту технологию для анализа сигналов, которыми общаются киты.\r\n",
    "\r\n",
    "<a href=\"https://www.nature.com/articles/s41598-019-48909-4\">Ссылка</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Наука <a class=\"anchor\" id=\"sci1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Фолдинг белка "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/protein.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент существует важный процесс — фолдинг (укладка) белка. Белок синтезируются в клетке в виде соединённых последовательно аминокислот. Эта последовательность обычно известна и кодируется в геноме.\r\n",
    "\r\n",
    "Однако после синтеза цепочка будет складываться в сложные пространственные структуры и, в зависимости от того, как эта структура будет выглядеть, зависит то, как белок будет себя вести в дальнейшем. Соответственно, понимание особенностей фолдинга белка служит ключом для производства лекарств и интерпретации генетических аномалий. \r\n",
    "\r\n",
    "В геноме человека могут происходить мутации — ошибки в геноме, которые могут приводить к изменению аминокислотной последовательности белка. \r\n",
    "\r\n",
    "Далеко не все мутации, которые есть в геноме, приведут к проблемам в конечной структуре, и если мы заранее будем знать, что одна мутация белка с дефектом, а другая безопасная, мы сможем предсказать вероятность развития болезни. \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку эти связи обусловлены достаточно сложными внутримолекулярными взаимодействиями, просчитать заранее, как будет выглядеть молекула, достаточно трудозатратно. На каждом этапе формирования действуют разные связи между аминокислотами (водородные связи, гидрофобные взаимодействия и пр.), тем самым образуя сложную структуру.\r\n",
    "\r\n",
    "Рассчитать аналитически структуру, которая образуется в ходе этих взаимодействий, сложно, но можно применить для этого нейросеть, подав ей аминокислотную последовательность белка. \r\n",
    "\r\n",
    "Автора AlphaFold2 обучают нейросеть, которая предсказывает расстояния и углы между атомами аминокислот в конечном белке, причем делает это итеративно, улучшая предсказание с предыдущего шага. Далее специальный алгоритм преобразует это в набор координат атомов, что и является пространственной структурой белка. \r\n",
    "Этот трехмерный массив координат атомов можно визуализировать, и дальше структурные биологи могут делать вывод о том, получится конкретный белок дефектным или нет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А эти знания уже применяются в области производства лекарств. Например, есть база веществ и известно, какая у них структура. Имея структуру белка, можно предсказать, в каком месте и с какой формой белка они могут и должны соединяться. Соответственно, по базе данных можно найти вещества, которые будут с этим белком связаны и уже подобрать из имеющихся “претендентов” тот, который наилучшим образом будет работать. \r\n",
    "\r\n",
    "Про мутации. Есть базы данных нормальных и мутагенных белков, и мы можем сравнить то, что получилось у нас в результате фолдинга с эталоном и посмотреть, насколько большая разница в структурах (опять же, для этого нужны структурные биологи, так как не все части структуры белка равнозначны). И на основе этого уже предсказать, насколько опасна будет та или иная мутация. \r\n",
    "\r\n",
    "\r\n",
    "<a href=\"https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery\">Заявление от deepmind</a>\r\n",
    "\r\n",
    "[Мнение структурных биологов 1](https://yakovlev.me/para-slov-za-alphafold2/?fbclid=IwAR23L8XigP7byPcx10o-4y5L3VTLRzDmuioqw99iKZ0SkPrauezrJJJayiM)\r\n",
    "\r\n",
    "[Мнение структурных биологов 2]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/protein1.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://www.nature.com/articles/s41586-019-1923-7\">Ссылка</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Причины успехов технологий на основе DL <a class=\"anchor\" id=\"succeed\"></a>\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/dl.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему всё это произошло так внезапно?**\n",
    "\n",
    "1. Чтобы модель могла извлечь и запомнить все важные закономерности, все они должны присутствовать в данных. Доступные цифровые фотокамеры и быстрый интернет, обеспечивший исследователям доступ к данным и возможность коллаборативной разметки, стали появляться только в начале 2000-х годов.\n",
    "\n",
    "\n",
    "2. Вычислительные мощности:\n",
    "\n",
    "* Lenet обучали на Pentium2  это примерно $10^7$ транзисторов;\n",
    "\n",
    "* AlexNet на двух GPU GTX580 это уже примерно $10^{14}$;\n",
    "\n",
    "С данными у ученых дела обстоят не так хорошо.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/dataset1_1.jpg\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://coggle.it/diagram/Xmcn5GVe0zfnM4aS/t/dataset\">Ссылка </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/datasetimagenet_1.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNet &mdash; массивная база данных аннотированных изображений предназначенная для построения и тестирования моделей компьютерного зрения. На этом датасете предобученны все модели для классификации, которые присутствуют в “зоопарке моделей” Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://image-net.org/download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/datasetcoco_1.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coco содержит сложные бытовые сцены предметов в их естественном контексте. Используется для обучения моделей, решающих задачи классификации, сегментации и детектирования. В нём намного меньше категорий объектов, чем в ImageNet, но присутствует разметка по bounding box и маскам.\n",
    "\n",
    "http://cocodataset.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Набор данных MosMedData: COVID19_1110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img_license/datasetmed.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор содержит результаты исследований компьютерной томографии органов грудной клетки с признаками COVID-19\n",
    "\n",
    "Предыдущие два датасета были исследовательские. На них соревнуются, проверяют гипотезы,  качество работы новых моделей.\n",
    "Для них много примеров и хорошие описания.\n",
    "\n",
    "<a href=\"https://mosmed.ai/\">По ссылке можно найти пример реального датасета</a>\n",
    "\n",
    "Скорее всего разобраться с тем, как использовать эти данные, будет сложнее.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/datasetmnist_1.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "База данных рукописных цифр."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/datasetcifar_1.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "Маленькие изображения в низком разрешении, разделённые на 10 классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10/100 и MNIST — это **учебные датасеты.**\n",
    "\n",
    "В них изображения размечены по нескольким классам. Чтобы загрузка и обучение проходили быстро, картинки имеют небольшое разрешение, а количество классов невелико.\n",
    "В остальном всё как у взрослых.\n",
    "\n",
    "И авторы статей, посвящённых разработке новых нейросетевых моделей, достаточно часто приводят результаты работы своих моделей на этих датасетах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Оценка результата <a class=\"anchor\" id=\"accuracy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/accuracy2.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая часть работы — это оценка точности. Нам нужно определиться с тем, как оценивать результат.\n",
    "Очень часто приходится слышать от заказчика вопрос со слайда.\n",
    "Чаще всего ответ “99%” их более чем устраивает. \n",
    "\n",
    "\n",
    "В большинстве случаев такой ответ воспринимается неверно, что в дальнейшем приводит к проблемам. Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/accuracy3car.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/accuracy4.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Скорость перемещения  машины зависит от дороги: на дорогах бывают пробки, ограничивающие знаки, наконец, дороги бывают очень разного качества.\n",
    "\n",
    "Всё это влияет на скорость перемещения и порой радикально.\n",
    "\n",
    "Так же и точность наших моделей в первую очередь зависит от данных, на которых мы будем их оценивать. Модель, которая отлично работает на одном датасете, может намного хуже работать на другом или не работать вовсе. В том числе в силу технических причин (пример про Resnet и CIFAR10).\n",
    "\n",
    "2. Машина может быть подвергнута тюнингу. Например, внедорожный тюнинг поможет преодолеть участок бездорожья, на котором неподготовленный автомобиль застрянет. Но при этом скорость на дорогах общего пользования может снизиться. Так же и модель, как правило, имеет ряд параметров (гиперпараметров), от которых зависит её работа. Они могут подбираться в зависимости от задачи (ошибки первого и второго рода) и качества данных.\n",
    "\n",
    "3. Само понятие скорости допускает вариации: речь идет о средней или максимальной скорости? Аналогично и для оценки моделей существует несколько метрик, применение которых, опять же, зависит от целей заказчика и особенностей данных.\n",
    "\n",
    "Поэтому честный ответ на вопрос о точности должен звучать так: «На датасете X модель Y по метрике Z показала точность 99%».\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/accuracy0.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ подсчёта точности модели — это деление количества правильно распознанных элементов на общее их количество.\n",
    "\n",
    "**Какие есть недостатки у такого способа?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/accuracy1.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy нельзя использовать, если данные не сбалансированы. То есть в одном из классов больше представителей, чем в другом.\n",
    "\n",
    "Также она не подойдет для задач сегментации и детектирования, если требуется не только определить наличие объекта на изображении, но и найти место, где он находится, то весьма желательно учитывать разницу в координатах.\n",
    "\n",
    "Сегодня же мы будем решать задачу классификации на учебных датасетах, где данные либо сбалансированы, либо дисбалансом можно пренебречь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Демонстрация работы с данными <a class=\"anchor\" id=\"demonstration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Табличные данные <a class=\"anchor\" id=\"demonstration_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Обзор инструментов <a class=\"anchor\" id=\"demonstration_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим примеры решения задач классификации на различных типах данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать библиотеки:\r\n",
    "\r\n",
    "* [numpy](https://numpy.org/) &mdash; Работа с многомерными массивами данных и высокоуровневыми математическими функциями;\r\n",
    "* [sklearn](https://scikit-learn.org/stable/) — ML алгоритмы, 'toy' — датасеты;\r\n",
    "* [pandas](https://pandas.pydata.org/) — Удобная работа с табличными данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [**Pytorch**](https://pytorch.org/) — Основной фреймворк машинного обучения, который будет использоваться на протяжении всего курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Познакомимся с инструментом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Tensorboard](https://www.tensorflow.org/tensorboard) — визуализация данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Загрузка данных  <a class=\"anchor\" id=\"demonstration_1_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Классификация вин \n",
    "\n",
    "Пример работы с табличными данными. \n",
    "Классифицируем вина из датасета : https://archive.ics.uci.edu/ml/machine-learning-databases/wine/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача будет состоять в том, чтобы по химическому составу определить производителя вина.\n",
    "\n",
    "Количество экземпляров, полученных на тест от каждого из трех производителей, не одинаково."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производитель №1 (class_1) 59 бутылок  \n",
    "Производитель №2 (class_2) 71 бутылка  \n",
    "Производитель №3 (class_3) 48 бутылок  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот датасет можно загрузить, используя модуль sklearn.datasets библиотеки [sklearn](https://scikit-learn.org/stable/), чем мы и воспользуемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \r\n",
    "from sklearn.datasets import load_wine\r\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\r\n",
    "\r\n",
    "# Download dataset \r\n",
    "data = load_wine(return_X_y=True) # Так же можно получить данные в Bunch(словарь) или pandas DataFrame\r\n",
    "\r\n",
    "features = data[0] # Массив 178x13 178 бутылок у каждой 13 признаков\r\n",
    "class_labels = data[1] # Массив из 178 элементов каждый элемент это число обозначающее класс к которому относиться данная бутылка : 0,1 2  \r\n",
    "print(\"Размерность массива с данными:\", features.shape)\r\n",
    "print(\"Размерность массива с номерами классов:\", class_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3 Визуализация данных  <a class=\"anchor\" id=\"demonstration_1_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Если параметр \n",
    "    \n",
    "    return_X_y == False\n",
    "\n",
    "то данные вернуться не в виде массива, а в объекте [Bunch](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch).\n",
    "\n",
    "Обращаться к нему можно, как к обычному словарю в Python. Кроме того, у него есть свойство, соответствующее каждому полю данных.\n",
    "\n",
    "Чтобы отобразить данные в виде таблицы, преобразуем их в формат pandas.DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключим библиотеку для работы с табличнымии данными: https://pandas.pydata.org/\r\n",
    "import pandas as pd \r\n",
    "\r\n",
    "data_bunch = load_wine(return_X_y=False) # Загрузим данные в виде объекта Bunch\r\n",
    "print(data_bunch.keys()) # Ключи соответствуют различным данным, которые находятся в нашем объекте\r\n",
    "\r\n",
    "df = pd.DataFrame(data_bunch.data, columns=data_bunch.feature_names) # data_bunch.data - набор признаков для каждого объекта \r\n",
    "                                                                     # data_bunch.feature_names - номер класса для каждого объекта\r\n",
    "\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая строка в таблице представляет собой один объект (бутылка вина), представленный как вектор из 13 признаков. Можно интерпретировать такой вектор как координаты точки в 13-мерном пространстве. Именно с таким представлением данных работают большинство алгоритмов машинного обучения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализировать 13-мерное пространство не получится :(. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но можно визуализировать проекцию данных в трёхмерное пространство. Для этого воспользуемся инструментом projector из tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск Tensorboard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Локальный запуск\n",
    "Для локального запуска tensorboard:\n",
    "\n",
    "* Нужно установить пакет: https://pypi.org/project/tensorboard/; \n",
    "\n",
    "* Затем выполнить команду:\n",
    "\n",
    "    `tensorboard --logdir <path> --port 6006`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "где <path> — путь к каталогу, в котором будут храниться файлы логов.\n",
    " В результате выполнения этой команды будет запущен локальный web-сервер на порту 6060.\n",
    "\n",
    "\n",
    "* Затем в браузере открыть адрес: localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запуск в Colab\n",
    "\n",
    "До некоторого времени запуск Tensorboard в Colab был сопряжен с некоторыми сложностями ввиду того, что виртуальная машина (docker-container), которую предоставляет нам Colab, не имеет постоянного IP адреса. И в интернете много устаревших инструкций по поводу того, как обойти эту проблемму. \n",
    "Но в настоящее время этот инструмент встроили в Colab и для его запуска прямо в ячейке достаточно двух 'магических строк':\n",
    "\n",
    "\n",
    "```\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir {logs_base_dir}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но так как Tensorboard работает только с логами на диске, то периодически приходится их очищать, для чего рекомендуется использовать метод \n",
    "\n",
    "`reinit_tensorboard`\n",
    "\n",
    "из ячейки ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, если существует ячейка, в которой уже выполняется код (например, идёт процесс обучения), то другие ячейки блокируются. В том числе мы не сможем воспользоваться Tensorboard, если он запущен в другой ячейке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому, если требуется мониторинг блока кода, который исполняется долгое время, то можно создать Tensorboard в ячейке с этим блоком кода, добавив в конце вызов: `reinit_tensorboard(clear_log = False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательный метод для запуска Tensorboard в Colab\r\n",
    "\r\n",
    "# Fix: https://stackoverflow.com/questions/60730544/tensorboard-colab-tensorflow-api-v1-io-gfile-has-no-attribute-get-filesystem\r\n",
    "import tensorflow as tf\r\n",
    "import tensorboard as tb\r\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\r\n",
    "\r\n",
    "import os\r\n",
    "import shutil\r\n",
    "\r\n",
    "# Запуск Tensorboard в Colab\r\n",
    "def reinit_tensorboard(clear_log = True):\r\n",
    "  # Лог-файлы читаются из этого каталога: \r\n",
    "  logs_base_dir = \"runs\"\r\n",
    "  if clear_log:\r\n",
    "    # Очистка логов\r\n",
    "    #!rm -rfv {logs_base_dir}/*\r\n",
    "    shutil.rmtree(logs_base_dir, ignore_errors = True)\r\n",
    "    os.makedirs(logs_base_dir, exist_ok=True)\r\n",
    "  # Магия Colab\r\n",
    "  %load_ext tensorboard\r\n",
    "  %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После загрузки Tensorboard измените значение опции \"Color by\" на \"label 3 colors\" чтобы объекты, принадлежащие к разным классам, отображались разными цветами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "import numpy\r\n",
    "\r\n",
    "reinit_tensorboard()\r\n",
    "\r\n",
    "writer = SummaryWriter(comment = \"wine\") # объект SummaryWriter() служит для записи результатов в лог tehsorboard\r\n",
    "np_f = numpy.array(features)\r\n",
    "writer.add_embedding(np_f, metadata=class_labels) # метод add_embeddings() добавляет в объект класса SummaryWriter() \r\n",
    "                                                  # проекцию данных в пространство меньшей размерности\r\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что объекты классов 1 и 2 линейно неразделимы в 2-х измерениях. По этой причине так популярен переход к пространствам большей размерности. \n",
    "\n",
    "Обратите внимание, что данные центрированны около нуля — это результат нормализации, которой они подверглись в Tensorboard.\n",
    "\n",
    "Нам тоже потребуется нормализовывать данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.4 Нормализация данных <a class=\"anchor\" id=\"demonstration_1_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, какие масштабы имеют значения разных признаков. \n",
    "Для сохранения в формат Tensorboard используем модуль torch.utils.tensorboard.\n",
    "\n",
    "Для начала отобразим два признака: malic_acid и alcalinity_of_ash. Их значения отличаются примерно на порядок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "\r\n",
    "f_names = data_bunch.feature_names\r\n",
    "for i, feature in enumerate(features):\r\n",
    "  # Pass a dictinary with name:value pairs to writer\r\n",
    "  writer.add_scalars(\"Raw_2_par\",{ \r\n",
    "      f_names[1]:feature[1], # malic_acid\r\n",
    "      f_names[3]:feature[3], # alcalinity_of_ash\r\n",
    "     } )\r\n",
    "writer.close()\r\n",
    "# Uncomment if need\r\n",
    "# reinit_tensorboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "После выполнения кода в этой ячейке, в Tensorboard выберите пункт меню \"SCALARS\" и нажмите иконку \"Обновить\" и затем 'Horizontal Axis' = Relative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в лог tensorboard ещё один признак, значения которого отличается от второго на 2 порядка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(features):\r\n",
    "  writer.add_scalars(\"Raw_3par\",{ \r\n",
    "                                     f_names[1]:feature[1], # malic_acid\r\n",
    "                                     f_names[3]:feature[3],  # alcalinity_of_ash\r\n",
    "                                     f_names[12]:feature[12] # proline \r\n",
    "                                     } ) \r\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения в разных масштабах — модели будет сложно сравнивать их между собой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Гистограммы в Tensorboard\n",
    "\n",
    "Для наглядности построим гистограмму. Сначала сделаем это для сырых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_histogram(\"1.Raw\" , features[:,3])\r\n",
    "writer.add_histogram(\"1.Raw\" , features[:,1])\r\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы увидеть гистограмму, дождитесь выполнения кода в ячейку выше и затем выберите пункт меню\n",
    "\n",
    "* \"HISTOGRAMS\" в Tensorboard и\n",
    "\n",
    "* Offset time axis = WALL или RELATIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min-Max  нормализация\r\n",
    "\r\n",
    "Нормализация &mdash; это процедура предобработки данных, при которой значения признаков приводятся к некоторому заданному диапазону. Цель нормализации &mdash; приведение данных в разных диапазонах значений к единому виду, позволяющему сравнивать их между собой, а также использовать для рассчета расстояния между объектами в задачах кластеризации.\r\n",
    "\r\n",
    "В качестве примера важности нормализации представим, что у вас есть набор данных с некоторыми признаками. Признаки отличаются по типу распределения и диапазону значений. В большинстве методов кластеризации нужно рассчитать меру \"сходства\" &mdash; расстояние между объектами. Часто в роли такого расстнояния выступает евклидова метрика. Для точек $p$ и $q$ в $n$-мерном пространстве, евклидова метрика рассчитывается как $d(p,q)=\\sqrt{\\sum_{i=1}^{n}(p_i-q_i)^2}$. Если один из признаков лежит в диапазоне [-1;1], а второй &mdash; [-1000;1000], то изменения второго признака могут оказать существенно большее влияние на метрику, а значит он будет в привелигированном положении по сравнению с первым. Нормализация приводит значения признаков к одному диапазону, таким образом делая признаки равными в возможностях своего влияния на результат вычислений.\r\n",
    "\r\n",
    "Простейший способ нормализации — это **Min-Max нормализация**. Вычтем минимальное значение и поделим на среднее. Это преобразование сводится к тому, что данные сначала смещаются, а потом масштабируются.\r\n",
    "\r\n",
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/classnorm.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast data to torch.Tensor \r\n",
    "tensor_f = torch.tensor(features)\r\n",
    "\r\n",
    "# torch.min и torch.max return tuple (values, indexes)\r\n",
    "# https://pytorch.org/docs/stable/generated/torch.min.html#torch.min\r\n",
    "\r\n",
    "min_values, _  = tensor_f.min(dim=0,keepdim=True)  # shape = (1,13)\r\n",
    "max_values, _  = tensor_f.max(dim=0,keepdim=True)  # shape = (1,13)\r\n",
    "\r\n",
    "print(min_values.shape)\r\n",
    "\r\n",
    "# Substract min\r\n",
    "min_max_centered = tensor_f - min_values # shape = (178,13)\r\n",
    "\r\n",
    "# Divide by mean\r\n",
    "min_max_normalized =  min_max_centered / (max_values - min_values) # shape = (1,13)\r\n",
    "\r\n",
    "# Write to Tensorboard logs\r\n",
    "writer.add_histogram(\"2.Min_Max_Centered\" , min_max_centered[:,3])\r\n",
    "writer.add_histogram(\"2.Min_Max_Centered\" , min_max_centered[:,1])\r\n",
    "\r\n",
    "writer.add_histogram(\"2.Min_Max_Normalized\" , min_max_normalized[:,3])\r\n",
    "writer.add_histogram(\"2.Min_Max_Normalized\" , min_max_normalized[:,1])\r\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Tensorboard (выше) можно видеть, что после центрирования значения сместились в сторону нуля, а после нормализации они сильно перекрываются, то есть данные перестали заметно отличаться по масштабу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стандартизация / Z-нормализация\r\n",
    "\r\n",
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img_license/normdistr.png\" width=\"700\" >\r\n",
    "\r\n",
    "При Min-Max нормализации остается проблема выбросов (см. 1-ую гистограмму). Если в данных есть даже единичные выбросы, то они займут значительную часть диапазона. Это происходит потому что, при Min-Max нормализации, все значения признака помещаются в заранее предопределенный диапазон значений от 0 до 1, таким образом Min-Max нормализация влияет только на размах значений признака и после нормализации выбросы останутся выбросами.\r\n",
    "\r\n",
    "**Стандартизация** не имеет определенных границ значений признака. Её цель &mdash; преобразовать исходные данные в новые со средним значением равным 0 и стандартным отклонением равным 1. Соответственно, процедура стандартизации включает в себя два преобразорания: центрирование &mdash; вычитание среднего значения и нормирование &mdash; деление на стандартное отклонение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substract min\r\n",
    "centered = tensor_f - tensor_f.mean(dim=0)\r\n",
    "# Divide by standard deviation\r\n",
    "normalized = centered / tensor_f.std(dim=0)\r\n",
    "\r\n",
    "# Write to Tensorboard logs\r\n",
    "writer.add_histogram(\"3.Z-Centered\" , centered[:,3])\r\n",
    "writer.add_histogram(\"3.Z-Centered\" , centered[:,1])\r\n",
    "\r\n",
    "writer.add_histogram(\"3.Z-Normalized\" , normalized[:,3])\r\n",
    "writer.add_histogram(\"3.Z-Normalized\" , normalized[:,1])\r\n",
    "\r\n",
    "\r\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , features[:,1])\r\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , min_max_normalized[:,1])\r\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , normalized[:,1])\r\n",
    "\r\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрите на гистограммы в Tensorboard.\n",
    "\n",
    "Наглядное приемущество стандартизации перед Max-Min нормализацией.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.5 Обучение<a class=\"anchor\" id=\"demonstration_1_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовая документация:\n",
    "https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "Используем простую модель, пример использования SVM классификатора: \n",
    "https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
    "\n",
    "Её устройство будет рассмотрено на следующих лекциях, сейчас будем считать модель чёрным ящиком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  5.1.6 Разбиение данных на обучающую и тестовую выборки <a class=\"anchor\" id=\"demonstration_1_6\"></a>\n",
    "\n",
    "Самым простым способом научиться чему-либо является \"запомнить всё\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним \"Таблицу умножения\". Если мы хотим проверить умение умножать, то проверки примерами из таблицы умножения будет недостаточно, ведь она может быть полностью запомнена. Нужно давать новые примеры, которых не было в таблице умножения (обучающей выборке)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если модель \"запомнит всё\", то она будет идеально работать на данных, которые мы ей показали, но может вообще не работать на любых других данных.\n",
    "\n",
    "С практической точки зрения важно, как модель будет вести себя именно на незнакомых для неё данных. То есть насколько хорошо она научилась обобщать закономерности, которые в данных присутствовали (если они вообще существуют)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки этой способности набор данных разделяют на две, а иногда даже на три части:\n",
    "\n",
    "* train — Данные, на которых модель учится;\n",
    "* validation/test — Данные, на которых идет проверка.\n",
    "\n",
    "В `sklearn.model_selection` есть модель для разделения массива данных на тренировочную и тестовую часть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, class_labels, test_size=0.2) # 80% training and 20% test\r\n",
    "\r\n",
    "print(\"X_train\",X_train.shape)\r\n",
    "print(\"X_test\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А мы в дальнейшем будем пользоваться аналогичными инструментами библиотеки PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.7 Обучим модель и посчитаем точность (Accuracy) <a class=\"anchor\" id=\"demonstration_1_7\"></a>\n",
    "\n",
    "Теперь можно запустить процесс обучения и посчитать точность работы модели на данном датасете.\n",
    "\n",
    "То есть понять, насколько хорошо по химическому составу модель определит винодела, поставившего это вино.\n",
    "\n",
    "accuracy = p/N\n",
    "\n",
    "где p — количество верных ответов, а N — общее число примеров, использовавшихся в тесте. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\r\n",
    "from sklearn import metrics\r\n",
    "\r\n",
    "# Создаем модель\r\n",
    "lin_clf = svm.LinearSVC()\r\n",
    "\r\n",
    "# Обучаем модель на части данных\r\n",
    "lin_clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Получаем предсказания\r\n",
    "y_pred = lin_clf.predict(X_test)\r\n",
    "\r\n",
    "print(\"y_pred\",y_pred.shape)\r\n",
    "\r\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\r\n",
    "\r\n",
    "print(\"Predicted classes: \", y_pred)\r\n",
    "print(\"Real classes:      \", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Последовательности <a class=\"anchor\" id=\"demonstration_5_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным образом можно работать с различными типами данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Загрузка даннных <a class=\"anchor\" id=\"demonstration_2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "В Pytorch есть три библиотеки для работы с разными типами данных:\n",
    "\n",
    "[torchvision](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "[torchaudio](https://pytorch.org/audio/stable/datasets.html)\n",
    "\n",
    "[torchtext](https://pytorch.org/text/stable/index.html)\n",
    "\n",
    "\n",
    "Для загрузки данных  используются классы [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) и [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). \n",
    "\n",
    "Они предоставляют единый интерфейс для доступа к данным различных типов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример загрузки аудио средствами Pytorch**\n",
    "\n",
    "Рассмотрим пример того, как можно загрузить аудиоданные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим библиотеку torch.audio (она не входит в список пакетов, доступных в colab по умолчанию)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove version for local run\r\n",
    "!pip install torchaudio==0.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech Commands:  [A Dataset for Limited-Vocabulary SpeechRecognition](https://arxiv.org/pdf/1804.03209.pdf)\n",
    "\n",
    "Он представляет из себя набор звуковых файлов в формате .wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в которых записан звук голоса разных людей, произносящих одно из 35 слов на английском языке. Часть слов таких как: \n",
    "\n",
    "- left;\n",
    "- right;\n",
    "- on;\n",
    "- off;\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также слова, не являющиеся командами:\n",
    "\n",
    "- cat;\n",
    "- bird;\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/audio/stable/datasets.html#speechcommands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В сравнении с датасетами из torchvision, этот датасет имеет более ограниченный функционал. В частности, в нём нет трансформаций и данные не выровнены. Благодяря этому появляется возможность продемонстрировать необходимость в операциях, которые в дальнейшем будут работать \"из  коробки\".*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\r\n",
    "speech_commands_dataset = torchaudio.datasets.SPEECHCOMMANDS(\"sample_data\",download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После загрузки данные будут распакованы в папку sample_data.\n",
    "Откройте её, используя меню в правой панели Colab. Посмотрите, в каком виде они хранятся на диске.\n",
    "\n",
    "\n",
    "Объект speech_commands_dataset — это экземпляр класса, который является наследником  [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html). Это означает, что в нём реализованы методы: \n",
    "* __getitem__ \n",
    "* __len__\n",
    "\n",
    "Благодаря этому мы можем узнать количество элементов или получить произвольный элемент данных, обращаясь к объекту класса [Dataset](https://pytorch.org/docs/stable/data.html)  так же, как к обычному списку в python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Количество элементов {} \".format(len(speech_commands_dataset)))\r\n",
    "print(\"Первый элемент\",speech_commands_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3. Визуализация  <a class=\"anchor\" id=\"demonstration_2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что представляет из себя элемент аудио-данных?**  \n",
    "Обратимся к документации: https://pytorch.org/audio/stable/datasets.html#speechcommands\n",
    "\n",
    "... returns:\n",
    "\n",
    "    (waveform, sample_rate, label, speaker_id, utterance_number)\n",
    "\n",
    "utterance_number — номер повтора. Больше нуля, если один и тот же человек проговаривает одну и ту же фразу несколько раз. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate, label, speaker_id, utterance_number = speech_commands_dataset[1]\r\n",
    "print(\"Waveform: {}\\nSample rate: {}\\nLabel: {} \\nSpeaker_id: {} \\nutterance_number: {}\".format(waveform.shape, sample_rate, label,speaker_id,utterance_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Размеры тензора waveform:\n",
    "    \n",
    "    [1, 16000] \n",
    "\n",
    "1 — количество каналов, 16000 — количество измерений в секунду.\n",
    "\n",
    "Если частота дискретизации(sample_rate) равна 16000, то этот фрагмент занимает ровно 1 секунду .\n",
    "\n",
    "**Визуализируем их:**  \n",
    "x — время  \n",
    "y — давление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "print(type(waveform))\r\n",
    "plt.figure()\r\n",
    "plt.title(f\"Label: {label}\")\r\n",
    "plt.plot(waveform.t().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Озвучим:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\r\n",
    "ipd.Audio(waveform.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.4 Обзор контейнеров <a class=\"anchor\" id=\"demonstration_2_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итерация по датасету**\n",
    "\n",
    "Запустим простую проверку: убедимся, что все записи одинаковой длины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему это важно**\n",
    "\n",
    "Мы будем работать с массивами 3 типов:\n",
    "\n",
    "* list — стандартный тип в Python\n",
    "* numpy — массив\n",
    "* torch.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расссмотрим, чем они отличаются:\n",
    "\n",
    "## List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_list = ['a',15,123.8,[99,\"I love you\"],[True,True,False]]\r\n",
    "python_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В списке могут быть данные различных типов, в том числе подтипов произвольной длины.\n",
    "\n",
    "## Numpy\n",
    "\n",
    "* Массив может содержать данные только одного типа;   \n",
    "* Размер данных во всех измерениям кроме 0-го должен совпадать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "numpy_arr = np.array([[1,2,3],[4,5,6]],dtype = float)\r\n",
    "print(numpy_arr)\r\n",
    "\r\n",
    "# This code this code will cause an error\r\n",
    "#invalid_numpy_arr = np.array([[1,2,3],[4,5]],dtype = float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря этому над numpy-массивами можно выполнять различные математические операции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([1,0,0])\r\n",
    "row_diff = numpy_arr - vector\r\n",
    "print(\"Substract row from array\",row_diff)\r\n",
    "\r\n",
    "scalar_product = numpy_arr.dot(vector)\r\n",
    "print(\"Scalar product\",scalar_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch.Tensor\n",
    "https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "      'is a multi-dimensional matrix containing elements of a single data type.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С точки зрения ограничений и функционала torch.Tensor эквивалентен numpy-массиву.\n",
    "Но дополнительно этот объект поддерживает две важных операции:\n",
    "\n",
    "* Перенос данных на видеокарту (`my_tensor.to('cuda:0')`)\n",
    "* Автоматический рассчет градиентов  (`my_tensor.backward()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти возможности понадобятся нам в дальнейшем. Поэтому надо разобраться, как  работать с данными в этом формате. Тем более, что torch.Tensor легко преобразуется в numpy-массив и обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "\r\n",
    "my_tensor = torch.tensor(numpy_arr)\r\n",
    "print(\"torch.Tensor\",my_tensor,\"shape = \",my_tensor.shape)\r\n",
    "\r\n",
    "squared_numpy = my_tensor.pow(2).numpy()\r\n",
    "print(\"Numpy \",squared_numpy,\"shape = \",squared_numpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим,  что все записи имеют одинаковую длину: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "\r\n",
    "def_length = 16000\r\n",
    "for i, sample in enumerate(speech_commands_dataset):\r\n",
    "  waveform, sample_rate, label, speaker_id, utterance_number = sample\r\n",
    "  if def_length != waveform.shape[1]: # [1, 16000]\r\n",
    "    print(\"Length of object #{i} not equal {def_length}\")\r\n",
    "    print(\"Waveform: {}\\nSample rate: {}\\nLabel: {} \\nSpeaker_id: {} \\nutterance_number: {}\".format(waveform.shape, sample_rate, label,speaker_id,utterance_number))\r\n",
    "    break\r\n",
    "  if not i% 10000 and i > 0 :\r\n",
    "    print(f\"Processed {i} objects\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.5 Предобработка данных <a class=\"anchor\" id=\"demonstration_2_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если элементы имеют различную длину, то мы не сможем их сравнивать. И даже технически поместить в один массив. \n",
    "\n",
    "\n",
    "Необходимо их выровнять. \n",
    "\n",
    "Так как многие записи начинаются и заканчиваются тишиной, то просто дополним их нулями.\n",
    "\n",
    "\n",
    "Для этого применим концепцию трансформаций (transform), которая широко применяется в Pytorch и встраивается во многие датасеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\r\n",
    "\r\n",
    "# User defined transform\r\n",
    "class PadWaveform(torch.nn.Module):\r\n",
    "  def __init__(self, desired_size = 16000):\r\n",
    "    self.desired_size = desired_size\r\n",
    "    super().__init__()\r\n",
    "\r\n",
    "  # in nn.Module forward method called inside __call__ method\r\n",
    "\r\n",
    "  def forward(self, waveform):\r\n",
    "    if waveform.shape[1] < self.desired_size:\r\n",
    "      # Calculate pad size\r\n",
    "      diff = self.desired_size - waveform.shape[1]\r\n",
    "      pad_left = diff // 2\r\n",
    "      pad_right = diff - pad_left\r\n",
    "      # Add zero pad to tensor\r\n",
    "      # https://pytorch.org/docs/stable/nn.functional.html#pad\r\n",
    "      return torch.nn.functional.pad(waveform,[pad_left, pad_right])\r\n",
    "    else:\r\n",
    "      # If size equal to desired size, do nothing\r\n",
    "      return waveform\r\n",
    "\r\n",
    "# Create custom dataset with transformations support \r\n",
    "# it's common practice in pytorch\r\n",
    "\r\n",
    "class customSpeechCommandsDataset(torchaudio.datasets.SPEECHCOMMANDS):\r\n",
    "  def __init__(self,transform,root = \"sample_data\"):\r\n",
    "    self.transform = transform\r\n",
    "    super().__init__(root)\r\n",
    "\r\n",
    "  # Override \r\n",
    "  def __getitem__(self,n):\r\n",
    "    # Get item\r\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\r\n",
    "    # Apply transform\r\n",
    "    transformed_waveform = self.transform(waveform)\r\n",
    "    # Return ransformed item\r\n",
    "    return (transformed_waveform, sample_rate, label, speaker_id, utterance_number)\r\n",
    "\r\n",
    "\r\n",
    "speech_commands_dataset = customSpeechCommandsDataset(transform = torch.nn.Sequential(PadWaveform(16000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно добавлять дополнительные трансформации. Например, уменьшить частоту дискретизации (sample_rate) чтобы данные занимали меньше места.\n",
    "\n",
    "Для этого в модуле\n",
    "[torchaudio.transforms](https://pytorch.org/audio/stable/transforms.html#resample)  уже есть готовая трансформация:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.transforms import Resample\r\n",
    "\r\n",
    "transform = torch.nn.Sequential(\r\n",
    "    Resample(16000,8000),\r\n",
    "    PadWaveform(8000))\r\n",
    "    \r\n",
    "speech_commands_dataset = customSpeechCommandsDataset(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.6 Пакетная обработка <a class=\"anchor\" id=\"demonstration_2_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Визуализируем данные.**\n",
    "\n",
    "Датасет в архиве занимает > 2Gb и это далеко не предел. Поэтому работать с ним будем по частям. \n",
    "\n",
    "Для этой задачи в pytorch используется класс Dataloader. Одной из его функций является пакетная (batch) загрузка данных.\n",
    "\n",
    "Особенно она будет полезна при обучении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "import numpy\r\n",
    "\r\n",
    "# Clear logs and launch Tensorboard\r\n",
    "reinit_tensorboard(False)\r\n",
    "\r\n",
    "data_loader = torch.utils.data.DataLoader(speech_commands_dataset, batch_size=128, shuffle=True)\r\n",
    "\r\n",
    "writer = SummaryWriter(comment = \"commands\")\r\n",
    "\r\n",
    "for i, batch in enumerate(data_loader):\r\n",
    "  waveforms, sample_rates, labels, speaker_ids, utterance_numbers = batch\r\n",
    "  print(waveforms.shape)\r\n",
    "  print(labels)\r\n",
    "  # Данные преобразовались в тензоры\r\n",
    "  # Убираем 1-е измерение оставшееся от канала\r\n",
    "  writer.add_embedding(torch.squeeze(waveforms), metadata=labels )\r\n",
    "  break\r\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Надо ли нормализовать эти данные?**\n",
    "\n",
    "Загрузим значения 2-х произвольных признаков в Tensorboard и проверим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment = \"commands\")\r\n",
    "for i, batch in enumerate(data_loader):\r\n",
    "  waveforms, sample_rates, labels, speaker_ids, utterance_numbers = batch\r\n",
    "  writer.add_histogram(\"waves\" ,torch.squeeze(waveforms)[:,100])\r\n",
    "  writer.add_histogram(\"waves\" ,torch.squeeze(waveforms)[:,200])\r\n",
    "  break\r\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из гистограммы, данные уже центрированны вокруг нуля и имеют один масшаб. Отчасти это связанно с тем, что они имеют одну и ту же природу, отчасти с форматом хранения звука. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.7 Обучение <a class=\"anchor\" id=\"demonstration_2_7\"></a>\n",
    "\n",
    "Для обучения потребуются метки. Попутно избавимся от лишнего. Создадим очередную трансформацию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customSpeechCommandsDatasetFinal(customSpeechCommandsDataset):\r\n",
    "  def __init__(self,transform = torch.nn.Sequential(),root = \"sample_data\"):\r\n",
    "    super().__init__(transform,root)\r\n",
    "    self.labels = self.get_labels()\r\n",
    "\r\n",
    "  def get_labels(self):\r\n",
    "    # Collect all unique labels\r\n",
    "    labels = set()\r\n",
    "    for i in range(len(self)):\r\n",
    "      item = super(customSpeechCommandsDataset,self).__getitem__(i)\r\n",
    "      labels.add(item[2])\r\n",
    "     # Sort labels and return it as a list\r\n",
    "    return sorted(list(labels)) \r\n",
    "\r\n",
    "  # Override \r\n",
    "  def __getitem__(self,n):\r\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\r\n",
    "    # Return only waveform and class_num\r\n",
    "    return (waveform[0],self.labels.index(label))\r\n",
    "\r\n",
    "transform = torch.nn.Sequential(\r\n",
    "    Resample(16000,8000),\r\n",
    "    PadWaveform(8000))\r\n",
    "\r\n",
    "speech_commands_dataset = customSpeechCommandsDatasetFinal(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes\",speech_commands_dataset.labels)\r\n",
    "print(\"Classes num\",len(speech_commands_dataset.labels))\r\n",
    "\r\n",
    "wave, cls_num = speech_commands_dataset[0]\r\n",
    "print(wave.shape)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и валидационную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(speech_commands_dataset )\r\n",
    "print(\"Total length\",total_len)\r\n",
    "\r\n",
    "# To speedup  use only 10% of data\r\n",
    "use_only = int(total_len*0.1)\r\n",
    "to_skip,to_use = torch.utils.data.random_split(speech_commands_dataset, [total_len - use_only, use_only])\r\n",
    "\r\n",
    "# Split to train and validation set\r\n",
    "val_len = int(len(to_use)*0.1)\r\n",
    "train_set, val_set = torch.utils.data.random_split(to_use, [len(to_use) - val_len, val_len])\r\n",
    "print(\"Train dataset length\",len(train_set))\r\n",
    "print(\"Validation dataset length\",len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\r\n",
    "from sklearn import metrics\r\n",
    "# Another simple black-box model\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "\r\n",
    "reinit_tensorboard(False)\r\n",
    "\r\n",
    "def validate(model):\r\n",
    "  data_loader = torch.utils.data.DataLoader(val_set, batch_size=256, shuffle=False)\r\n",
    "  accuracy = []\r\n",
    "  for batch in data_loader:\r\n",
    "    waveforms, class_nums  = batch \r\n",
    "    y_pred = model.predict(waveforms)\r\n",
    "    accuracy.append(metrics.accuracy_score(class_nums, y_pred))\r\n",
    "  print(\"Accuracy:\",numpy.array(accuracy).mean())\r\n",
    "  return numpy.array(accuracy).mean()\r\n",
    "\r\n",
    "model = SGDClassifier(loss='log')  \r\n",
    "\r\n",
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=1024, shuffle=True)\r\n",
    "\r\n",
    "for epoch in range(5):\r\n",
    "  for batch in data_loader:\r\n",
    "    waveforms, class_nums  = batch\r\n",
    "    model.partial_fit(waveforms, class_nums,range(35))\r\n",
    "  accuracy = validate(model)\r\n",
    "  writer.add_scalar(\"Accuracy\",accuracy,epoch)\r\n",
    "  writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Откройте вкладку \"SCALARS\".\n",
    "\n",
    "\n",
    "Модель не обучается. Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.8 Обзор видов связности данных <a class=\"anchor\" id=\"demonstration_2_8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Причины этого в количестве связей между элементами данных.\n",
    "Мы имеем дело с временным рядом. \n",
    "\n",
    "Аудиозапись — это набор измерений (давления на мембране микрофона), произведённых последовательно. \n",
    "\n",
    "То есть в каждый момент времени сигнал связан с предыдущим. \n",
    "Если мы перемешаем их, получится какофония. \n",
    "\n",
    "Так же, как если перемешать слова в предложении или буквы в слове."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/types3.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таких случаях мы тоже можем представить данные как вектор, но модель, которой мы подадим его на вход, должна учитывать связи между соседними элементами этого вектора.\n",
    "\n",
    "При работе с видео добавляется дополнительное «измерение» — время. \n",
    "\n",
    "Поскольку данные подаются в модель в виде многомерного массива чисел (тензора),  то при работе с видео меняется только размерность этого массива:  в нём появляется дополнительное измерение.\n",
    "\n",
    "С точки зрения PyTorch данные — это некоторый массив, у него может быть 1-2-3 измерения, но нам важно понимать, какие между ними существуют связи. От этого зависит, какой моделью мы будем их обрабатывать.\n",
    "\n",
    "Для работы с этими данными нужна модель, которая эти связи будет учитывать, например рекуррентная  или свёрточная сеть.\n",
    "С её помощью можно получить точность >85%:\n",
    "\n",
    "[Speech Command Recognition with torchaudio](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/d87597d0062580c9ec699193e951e3f4/speech_command_recognition_with_torchaudio.ipynb#scrollTo=tl9K6deU4S10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Работа с изображениями <a class=\"anchor\" id=\"demonstration_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Загрузка <a class=\"anchor\" id=\"demonstration_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет CIFAR-10. Он состоит из 60000 цветных изображений размером 32x32. На картинках объекты 10 классов.\n",
    "\n",
    "Для его загрузки используем билиотеку torchvision.\n",
    "\n",
    "В отличие от torchaudio, пакет torchvision входит в число предустановленных в colab.\n",
    "\n",
    "Датасеты из torcvision изначально поддерживают механизм transforms \n",
    "и разбивку на тестовое и проверочные подмножества. Нам не придется добавлять их вручную.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, datasets, transforms\r\n",
    "\r\n",
    "trainset = datasets.CIFAR10(\"content\", train=True,  download=True)\r\n",
    "valset = datasets.CIFAR10(\"content\", train = False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем несколько картинок вместе с метками. Tensorboard имеет метод для вывода картинок:\n",
    "[torchvision.utils.make_grid](https://pytorch.org/docs/stable/torchvision/utils.html)\n",
    "\n",
    "Однако он не поддерживает метки.\n",
    "\n",
    "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjcxcStpNDtAhWllYsKHa7XDLoQFjAAegQIBBAC&url=https%3A%2F%2Fdiscuss.pytorch.org%2Ft%2Fadd-label-captions-to-make-grid%2F42863&usg=AOvVaw19bkv0_Q8VQxD7WBZ3pFR_\n",
    "\n",
    "Поэтому воспользуемся matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pickle\r\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\r\n",
    "\r\n",
    "# Загрузим названия классов. Исключительно для наглядности, для обучения модели они не нужны.\r\n",
    "with open(\"content/cifar-10-batches-py/batches.meta\",'rb') as infile:\r\n",
    "  cifar_meta = pickle.load(infile)\r\n",
    "labels = cifar_meta['label_names']\r\n",
    "\r\n",
    "for j in range(10):\r\n",
    "  image, class_num = trainset[j]\r\n",
    "  plt.subplot(1, 10 ,j+1)\r\n",
    "  plt.imshow(image)\r\n",
    "  plt.axis('off')  \r\n",
    "  plt.title(labels[class_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, в каком виде хранятся картинки в памяти:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оказывается, в формате [PIL](https://pillow.readthedocs.io/en/stable/reference/Image.html).\n",
    "\n",
    "Чтобы обучать модель, нам придётся преобразовать их в тензоры. \n",
    "Используем для этого transforms и Dataloder.\n",
    "\n",
    "Выведем размеры получившихся тензоров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "valset.transform = transforms.Compose([ transforms.ToTensor() ]) # PIL Image to Pytorch tensor\n",
    "val_dataloder = DataLoader(valset, batch_size=8, shuffle=False)\n",
    "\n",
    "for batch in val_dataloder:\n",
    "  images, class_nums = batch\n",
    "  print(len(batch))\n",
    "  print(\"Images: \",images.shape)\n",
    "  print(\"Class nums: \",class_nums.shape)\n",
    "  print(class_nums)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разберемся с размерностями:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На каждой итерации dataloader возвращает кортеж из двух элементов.\n",
    "* Первый элемент — это изображения;\n",
    "* Второй — метки классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество элементов в каждом равно batch_size, в данном примере — 8.\n",
    "\n",
    "Изображение:  \n",
    "3 - C, каналы (В отличие от PIL и OpenCV они идут сначала);  \n",
    "32 - H, высота;  \n",
    "32 - W, ширина.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки:  \n",
    "числа от 0 до 9 по количеству классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 Создадим модель-заглушку <a class=\"anchor\" id=\"demonstration_3_2\"></a>\n",
    "\n",
    "Она не будет ничего предсказывать, только возвращать случайный номер класса.\n",
    "\n",
    "В методе fit данные просто запоминаются. Этот фрагмент кода можно будет использовать при выполнении практического задания.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FakeModel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.train_data = None\n",
    "    self.train_labels = None\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    # Simple store all data\n",
    "    self.train_data = torch.vstack((self.train_data,x)) if self.train_data != None else x\n",
    "    self.train_labels = torch.hstack((self.train_labels,y)) if self.train_labels != None else y\n",
    "   \n",
    "  def forward(self,x):\n",
    "    # x is a batch, not a single sample!\n",
    "    # Return random number instead of predictions\n",
    "    class_count = torch.unique(self.train_labels).shape[0]\n",
    "    # https://pytorch.org/docs/stable/generated/torch.randint.html#torch-randint\n",
    "    # size is shape of output tensor\n",
    "    class_num = torch.randint(low = 0, high = class_count-1, size = (x.shape[0],)) \n",
    "    return class_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3 Запустим процесс обучения <a class=\"anchor\" id=\"demonstration_3_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.transform = transforms.Compose([ transforms.ToTensor(),  ]) # PIL Image to Pytorch tensor\n",
    "train_dataloder = DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "\n",
    "model = FakeModel()\n",
    "\n",
    "for img_batch, labels_batch in train_dataloder:\n",
    "  model.fit(img_batch, labels_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим работу модели на нескольких изображениях из тестового набора данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, class_num_batch = next(iter(val_dataloder))\n",
    "predicted_cls_nums = model(img_batch)\n",
    "\n",
    "for i, predicted_cls_num in enumerate(predicted_cls_nums):\n",
    "  img = img_batch[i].permute(1,2,0).numpy()*255  \n",
    "  plt.subplot(1, len(predicted_cls_nums),i+1)\n",
    "  plt.imshow(img.astype(int))\n",
    "  plt.axis('off')\n",
    "  plt.title(labels[int(predicted_cls_num)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем точность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = []\n",
    "for img_batch, labels_batch in val_dataloder:\n",
    "  predicted = model(img_batch)\n",
    "  batch_accuracy = accuracy_score(labels_batch, predicted)\n",
    "  accuracy.append(batch_accuracy)\n",
    "\n",
    "print(\"Accuracy\",torch.tensor(accuracy).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем повышать точность. В ходе выполнения практического задания заменим заглушку в методе predict реальным алгоритмом. Используем алгоритм:\n",
    "\n",
    "[K- Nearest Neighbor](https://colab.research.google.com/drive/1_5tGxAoxrWulPmwK2Ht9BHGsS-EpxVo0?usp=sharing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.4. Алгоритм k-nearest neighbors <a class=\"anchor\" id=\"demonstration_3_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу классификации на примере CIFAR 10.\n",
    "В ходе нескольких первых лекций мы будем решать её неоднократно, используя различные модели и постепенно улучшая результат.\n",
    "\n",
    "Цель сегодняшней работы — разобраться с загрузкой данных и общим ходом обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/datasetclass.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое, что мы должны сделать — это представить данные в виде чисел.\n",
    "Но изображения уже хранится в памяти компьютера в виде массива пикселей. \n",
    "\n",
    "При этом соседние пиксели на изображении связаны между собой. Для анализа этих связей требуется относительно сложная логика, \n",
    "попробуем сегодня проигнорировать эти связи и рассматривать изображение просто как массив чисел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img_license/class1.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод ближайшего соседа**  \n",
    "Для классификации используем [Метод ближайшего соседа](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm), или k-ближайших соседей (в части 3, 4).\n",
    "\n",
    "Метод k-ближайших соседей (англ. k-nearest neighbors algorithm, k-NN) — метрический алгоритм для автоматической классификации объектов или регрессии.\n",
    "\n",
    "В случае использования метода для классификации объект присваивается тому классу, который является наиболее распространённым среди k соседей данного элемента, классы которых уже известны.\n",
    "\n",
    "Алгоритм может быть применим к выборкам с большим количеством атрибутов (многомерным). Для этого перед применением нужно определить функцию расстояния; классический вариант такой функции — евклидова метрика. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/knn.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остается вопрос: как определить метрику близости для изображений?\n",
    "\n",
    "Раз изображения в памяти компьютера — это просто массив чисел, давайте поэлементно вычтем одно из другого. \n",
    "А затем оценим суммарную разницу. Для одинаковых изображений она будет нулевой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/class2.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако может возникнуть ситуация, когда разность для одной пары пикселей -100, а для другой — +100. Когда мы их сложим, получится ноль, хотя изображения очень разные.\n",
    "Чтобы избавиться от такого нежелательного эффекта, будем использовать модули разностей.\n",
    "И таким образом получим метрику расстояния L1. Она же — манхэттенское расстояние, метрика прямоугольного города, метрика городского квартала, метрика такси, метрика Манхэттена, прямоугольная метрика, метрика прямого угла.\n",
    "Если вместо модуля использовать возведение в квадрат, а затем из суммы извлекать корень — получим Евклидову метрику.\n",
    "\n",
    "Теперь алгоритм будет выглядеть так: \n",
    "\n",
    "1. На этапе обучения запоминаем все изображения тренировочной выборки;  \n",
    "2. Для определения класса нового изображения:  \n",
    "\n",
    "a. Считаем расстояние L1 от него до всех заученных изображений;\n",
    "\n",
    "b. Находим минимальное;\n",
    "\n",
    "c. Возвращаем метку класса для этого изображения, расстояние до которого оказалось минимальным.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/class3.png\" >"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
