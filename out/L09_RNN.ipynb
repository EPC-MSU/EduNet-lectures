{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (RNN)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ª–µ–∫—Ü–∏—è—Ö –º—ã —Ä–∞–±–æ—Ç–∞–ª–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ **—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã**, —É –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –±—ã–ª–æ **–≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å–≤—è–∑–Ω–æ—Å—Ç–∏**.\n",
    "\n",
    "–ï—Å–ª–∏ —ç—Ç–æ **—Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ**, —Ç–æ –º—ã –∑–∞—Ä–∞–Ω–µ–µ –∑–Ω–∞–µ–º –¥–ª–∏–Ω—É –≤–µ–∫—Ç–æ—Ä-–æ–ø–∏—Å–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞, –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏: –æ–¥–Ω–æ —ç—Ç–æ —á–∏—Å–ª–æ –∏–ª–∏ –≤–µ–∫—Ç–æ—Ä.\n",
    "\n",
    "–í–µ—Ä–Ω–æ —ç—Ç–æ –∏ –ø—Ä–æ **–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è** ‚Äî –æ–±—ã—á–Ω–æ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —É—á–∏—Ç—Å—è –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è. –î–∞, –º—ã –º–æ–∂–µ–º —Å–¥–µ–ª–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å, –∫–æ—Ç–æ—Ä–∞—è —Å–ø–æ—Å–æ–±–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –ø–æ—á—Ç–∏ –ª—é–±–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è, –Ω–æ –¥–æ–±–∏–≤–∞–µ–º—Å—è —ç—Ç–æ–≥–æ –∑–∞ —Å—á–µ—Ç –≤—Å—Ç–∞–≤–∫–∏ —Å–ª–æ–µ–≤ **global pooling**, –∫–æ—Ç–æ—Ä—ã–µ  –ø—Ä–∏–≤–æ–¥—è—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–π —á–∞—Å—Ç—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, –∫ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–Ω–∞–∫–æ –¥–∞–ª–µ–∫–æ **–Ω–µ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –æ–±–ª–∞–¥–∞—é—Ç —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º**. –¢–∏–ø–∏—á–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–µ–º —Ç–∞–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —è–≤–ª—è—é—Ç—Å—è **–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã**.\n",
    "\n",
    "–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –º—ã —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è —Ä—è–¥–∞ –≤ –ø—Ä–æ—à–ª–æ–º —Å–æ–¥–µ—Ä–∂–∞—Ç –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–≤–µ–¥–µ–Ω–∏–∏ —Ä—è–¥–∞ –≤ –±—É–¥—É—â–µ–º —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ (—á—Ç–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö ML-–∑–∞–¥–∞—á, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é—â–∏—Ö –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –Ω–∞–±–ª—é–¥–µ–Ω–∏–π)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/ts_intro.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –Ω–∞—É—á–∏–º—Å—è —Å –Ω–∏–º–∏ —Ä–∞–±–æ—Ç–∞—Ç—å, –Ω–æ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–∑–±–µ—Ä—ë–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π $t \\in R^{N+1}$, –∏–∑–º–µ—Ä–µ–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø—Ä–æ–º–µ–∂—É—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ $\\Delta t$ –¥–æ –º–æ–º–µ–Ω—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ $T$:\n",
    "\n",
    "$$\\large y_i = y(t_i).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–°–æ—Å—Ç–∞–≤–ª—è—é—â–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤.**\n",
    "\n",
    "$$\\large y(t_i) = f(T,S,C,E, t_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–¢—Ä–µ–Ω–¥** $T(t)$ ‚Äî –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞, –æ–ø–∏—Å—ã–≤–∞—é—â–∞—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Ä—è–¥–∞.\n",
    "\n",
    "**–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å** $S(t)$ ‚Äî –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞, –æ–ø–∏—Å—ã–≤–∞—é—â–∞—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è —Ä—è–¥–∞.\n",
    "\n",
    "**–¶–∏–∫–ª–∏—á–Ω–æ—Å—Ç—å** $C(t)$ ‚Äî –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞, –æ–ø–∏—Å—ã–≤–∞—é—â–∞—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è —Ä—è–¥–∞ —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º –ø–µ—Ä–∏–æ–¥–æ–º.\n",
    "\n",
    "**–®—É–º (irregular fluctuations)** $I(t)$ ‚Äî –Ω–µ–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞, –æ–ø–∏—Å—ã–≤–∞—é—â–∞—è –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –¥–∞–Ω–Ω—ã—Ö, –Ω–µ–æ–±—ä—è—Å–Ω–∏–º—ã–µ –¥—Ä—É–≥–∏–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏.\n",
    "\n",
    "$$\\large y_i = T_i + S_i + C_i + I_i$$\n",
    "\n",
    "–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–π –∏ —Å–µ–∑–æ–Ω–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–π —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è –∏–º–µ–µ—Ç —Ä–µ–≥—É–ª—è—Ä–Ω—É—é (—Å–µ–∑–æ–Ω–Ω—É—é) –ø–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç—å, —Ç–æ–≥–¥–∞ –∫–∞–∫ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç –±–æ–ª–µ–µ –¥–ª–∏—Ç–µ–ª—å–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –∫ —Ç–æ–º—É –∂–µ –º–µ–Ω—è–µ—Ç—Å—è –æ—Ç —Ü–∏–∫–ª–∞ –∫ —Ü–∏–∫–ª—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–¥–µ—Å—å –Ω–µ—Ç –µ–¥–∏–Ω–æ–≥–æ –º–Ω–µ–Ω–∏—è: –¥—Ä—É–≥–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç –≤—ã–¥–µ–ª–∏—Ç—å –∏ –∏–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, —Ç–∞–∫–∂–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –∞–¥–¥–∏—Ç–∏–≤–Ω—ã–º–∏, –Ω–æ –∏ –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–∏–≤–Ω—ã–º–∏.\n",
    "\n",
    "$$\\large y_i = T_i * S_i * C_i * I_i$$\n",
    "\n",
    "–û—Ç –∫–æ—Ç–æ—Ä—ã—Ö, –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä—É—è, –º—ã –≤–Ω–æ–≤—å –º–æ–∂–µ–º –ø—Ä–∏–π—Ç–∏ –∫ –∞–¥–¥–∏—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "$$\\large \\ln {y_i} = \\ln T_i + \\ln S_i + \\ln C_i + \\ln I_i$$\n",
    "\n",
    "$$\\large \\hat {y_i} = \\hat T_i + \\hat S_i + \\hat C_i + \\hat I_i$$\n",
    "\n",
    "–í –¥–∞–Ω–Ω–æ–π –ª–µ–∫—Ü–∏–∏ –º—ã –±—É–¥–µ–º –æ–ø–∏—Ä–∞—Ç—å—Å—è –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –Ω–∞ –∞–¥–¥–∏—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å, –æ–¥–Ω–∞–∫–æ —É—á–∏—Ç—ã–≤–∞–π—Ç–µ, —á—Ç–æ –±—ã–≤–∞—é—Ç –∏ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ, —Å–º–µ—à–∞–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/ts_components.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚õî –ï—Å–ª–∏ –≤–∞—à **—Ä—è–¥ –Ω–µ —Ä–∞–≤–Ω–æ–º–µ—Ä—ã–π**, —Ç.–µ. –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –º–µ–∂–¥—É –Ω–∞–±–ª—é–¥–µ–Ω–∏—è–º–∏ –Ω–µ —Ä–∞–≤–Ω—ã, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–¥–µ–ª–∞—Ç—å —Ä—è–¥ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–º. –ù–∞–ø—Ä–∏–º–µ—Ä, –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–µ–π.\n",
    "\n",
    "–ï—Å–ª–∏ —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å –Ω–µ–ª—å–∑—è, –¥–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π –º–∏—Ä [–∞–Ω–∞–ª–∏–∑–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ üìö[book]](https://www.ssau.ru/files/resources/sotrudniki/prohorov/9_pasp.pdf)!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –∞–Ω–∞–ª–∏–∑–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –º–æ–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–¥–∞—á–∏:\n",
    "\n",
    "* –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è (—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–æ–π—Å—Ç–≤)\n",
    "* –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "* –ü–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π\n",
    "* –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
    "* –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "\n",
    "–°–µ–≥–æ–¥–Ω—è –º—ã –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∑–∞–¥–∞—á—É –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è.\n",
    "\n",
    "**–ó–∞–¥–∞—á–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è**: –Ω–∞–π—Ç–∏ —Ñ—É–Ω–∫—Ü–∏—é $\\large f_T$:\n",
    "\n",
    "$$\\large y_{T+h} ‚âà f_T(y_T, \\dots ,y_1, h),$$\n",
    "\n",
    "–≥–¥–µ $h \\in \\{1,2,\\dots, H\\}$, $H$ ‚Äî –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è.\n",
    "\n",
    "–ü–æ–º–∏–º–æ —Å–∞–º–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π, –≤–∞–∂–Ω–æ —Ç–∞–∫–∂–µ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å **–ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª**, –≤ –∫–æ—Ç–æ—Ä–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º–∞—è –≤–µ–ª–∏—á–∏–Ω–∞ –æ–∫–∞–∂–µ—Ç—Å—è —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é, –Ω–µ –º–µ–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω–æ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±—É–¥–µ—Ç **–ø–æ–ª–µ–∑–Ω–æ –∏–º–µ—Ç—å —à–∏—Ä–∏–Ω—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –∑–∞–≤–∏—Å—è—â–µ–π –æ—Ç –≤—Ä–µ–º–µ–Ω–∏**. –î–ª—è —ç—Ç–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–±–∏—Ç—å—Å—è —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏ —Ä—è–¥–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†—è–¥ $y_1, \\dots, y_T$ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω, –µ—Å–ª–∏ –¥–ª—è $\\forall k$ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ $y_t, \\dots, y_{t+k}$ –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç $t$, —Ç–æ –µ—Å—Ç—å —Å–≤–æ–π—Å—Ç–≤–∞ —Ä—è–¥–∞ –Ω–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –≤—Ä–µ–º–µ–Ω–∏.\n",
    "\n",
    "–ù–∞–ª–∏—á–∏–µ —Ç—Ä–µ–Ω–¥–∞, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏, —Ü–∏–∫–ª–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/ts_stationarity.png\" width=\"1000\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–º–∏–º–æ —Ç–æ–≥–æ, —á—Ç–æ —Ä—è–¥ –º–æ–∂–µ—Ç —Å—á–∏—Ç–∞—Ç—å—Å—è —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º –∏–ª–∏ –Ω–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º, –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä—è–¥—ã (–Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–∞—Ö —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–µ, –Ω–∞ –¥—Ä—É–≥–∏—Ö ‚Äî –Ω–µ—Ç). –û–±—â–∏–π —Å–æ–≤–µ—Ç ‚Äî [—Å–µ–≥–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ üõ†Ô∏è[doc]](https://centre-borelli.github.io/ruptures-docs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –Ω–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å –≤–∏–∑—É–∞–ª—å–Ω–æ, —Å—É—â–µ—Å—Ç–≤—É—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–µ—Å—Ç—ã:\n",
    "1. –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –î–∏–∫–∫–∏-–§—É–ª–ª–µ—Ä–∞ (ADF)\n",
    "2. –¢–µ—Å—Ç –§–∏–ª–ª–∏–ø—Å–∞-–ü–µ—Ä—Ä–æ–Ω–∞\n",
    "3. –¢–µ—Å—Ç **–ö–≤—è—Ç–∫–æ–≤—Å–∫–æ–≥–æ-–§–∏–ª–ª–∏–ø—Å–∞-–®–º–∏–¥—Ç–∞-–®–∏–Ω–∞ (KPSS)**\n",
    "\n",
    "–ò –º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥—Ä—É–≥–∏—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –ø—Ä–∏–º–µ–Ω—è—é—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤ —Ä–∞–∑–æ–º, —á—Ç–æ–±—ã —É–¥–æ—Å—Ç–æ–≤–µ—Ä–∏—Ç—å—Å—è –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ. –û–¥–Ω–∏–º –∏–∑ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —è–≤–ª—è–µ—Ç—Å—è KPSS.\n",
    "\n",
    "–¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –≥–∏–ø–æ—Ç–µ–∑—É –æ —Ç–æ–º, —á—Ç–æ —Ä—è–¥ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω, –ø—Ä–æ—Ç–∏–≤ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, —á—Ç–æ —Ä—è–¥ –Ω–µ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω. –û–±—ã—á–Ω–æ –∫—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å—Ç—Ä–æ–µ–Ω—ã –Ω–∞–æ–±–æ—Ä–æ—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table, th, td {\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "}\n",
    "<font size=\"2\" face=\"Times New Romans\" >\n",
    "\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "\n",
    "<td>\n",
    "\n",
    "\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$\\large \\text{KPSS}$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$\\large \\text{ADF}$\n",
    "\n",
    "</td>\n",
    "<tr>\n",
    "\n",
    "<td>\n",
    "\n",
    "—Ä—è–¥:\n",
    "    \n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$\\large y = y_1, \\dots, y_T$\n",
    "\n",
    "</td>  \n",
    "<td>\n",
    "\n",
    "$\\large y = y_1, \\dots, y_T$\n",
    "\n",
    "</td>\n",
    "\n",
    "\n",
    "</tr>\n",
    "<td>\n",
    "\n",
    "–Ω—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞:\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$\\large H_0$: —Ä—è–¥ $\\large y$ **—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω**\n",
    "\n",
    "</td>  \n",
    "\n",
    "<td>\n",
    "\n",
    "$\\large H_0$: —Ä—è–¥ $\\large y$ **–Ω–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω**\n",
    "\n",
    "</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "\n",
    "–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$\\large H_1$: —Ä—è–¥ $\\large y$ –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –º–æ–¥–µ–ª—å—é –≤–∏–¥–∞ $\\large y_t = Œ±y_{t-1}$\n",
    "    \n",
    "</td>  \n",
    "\n",
    "<td>\n",
    "\n",
    "$\\large H_1$: —Ä—è–¥ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω\n",
    "    \n",
    "</td>\n",
    "\n",
    "  </tr>\n",
    "\n",
    "\n",
    "  <tr>\n",
    "    <td>\n",
    "    \n",
    "p-value < 0.05:\n",
    "    \n",
    "</td>\n",
    "\n",
    "<td>\n",
    "    \n",
    "$\\large H_0$ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è, —Ä—è–¥ –Ω–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω.\n",
    "    \n",
    "</td>  \n",
    "\n",
    "<td>\n",
    "    \n",
    "$\\large H_0$ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è, —Ä—è–¥ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω.\n",
    "    \n",
    "</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–∏–º–µ—Ä**\n",
    "\n",
    "–í–æ–∑—å–º–µ–º –¥–∞—Ç–∞—Å–µ—Ç [Air Passengers üõ†Ô∏è[doc]](https://www.kaggle.com/rakannimer/air-passengers), –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –∑–∞ –∫–∞–∂–¥—ã–π –º–µ—Å—è—Ü.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/airline-passengers.csv\"\n",
    ")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = dataset[\"Passengers\"].values  # transform dataframe to numpy.array\n",
    "# plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data, label=\"Airline Passangers Data\")\n",
    "plt.title(\"Number of passengers per month\")\n",
    "plt.ylabel(\"#passengers\")\n",
    "plt.xlabel(\"Month\")\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–°–¥–µ–ª–∞–µ–º —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–µ–µ**\n",
    "\n",
    "–í —Å–µ–∑–æ–Ω–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–µ —Ä–∞–∑–º–∞—Ö —è–≤–Ω–æ —Ä–∞—Å—Ç—ë—Ç —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º. –ü—Ä–∏—á–∏–Ω–∞ –≤ –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–∏–≤–Ω–æ–π –ø—Ä–∏—Ä–æ–¥–µ —Ä—è–¥–∞. –ß—Ç–æ–±—ã –æ—Ç —Ç–∞–∫–æ–≥–æ –∏–∑–±–∞–≤–∏—Ç—å—Å—è, –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —É–∂–µ –∏–∑–≤–µ—Å—Ç–Ω–æ–µ –≤–∞–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞ –∏–ª–∏ –∂–µ –æ–±—ã–∫–Ω–æ–≤–µ–Ω–Ω–æ–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_data = np.log(dataset[\"Passengers\"].values)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data, label=\"Airline Passangers Data\")\n",
    "plt.title(\"Number of passengers per month\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.xlabel(\"Month\")\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –º–æ–∂–µ–º –≤–∏–¥–µ—Ç—å —á–µ—Ç–∫—É—é —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –∏ —Ç–µ–Ω–¥–µ–Ω—Ü–∏—é –∫ —É–≤–µ–ª–∏—á–µ–Ω–∏—é –∑–Ω–∞—á–µ–Ω–∏–π. –ó–Ω–∞—è –ø—Ä–∏—Ä–æ–¥—É –¥–∞–Ω–Ω—ã—Ö, –º—ã —Å—Ä–∞–∑—É –º–æ–∂–µ–º —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –∏–º–µ–µ—Ç –ø–µ—Ä–∏–æ–¥ 12. –û–±—ä–µ–¥–∏–Ω–∏–º –≤—Å–µ –Ω–∞—à–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `seasonal_decompose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result = seasonal_decompose(training_data, model=\"multiplicative\", period=12)\n",
    "\n",
    "fig = result.plot()\n",
    "fig.set_size_inches((12, 4))\n",
    "plt.xlabel(\"Month\")\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "plt.grid()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ç–µ—Å—Ç–µ KPSS –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä `regression`, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–µ–Ω—è—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –Ω—É–ª–µ–≤–æ–π –≥–∏–ø–æ—Ç–µ–∑—ã:\n",
    "* `regression='c'` ‚Äî –Ω—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞ —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ \"—Ä—è–¥ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã\"\n",
    "* `regression='ct'` ‚Äî –Ω—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞ —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ \"—Ä—è–¥ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞\".\n",
    "\n",
    "–ó–∞–º–µ—Ç–∏–º, —á—Ç–æ –≤–æ –≤—Ç–æ—Ä–æ–º —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Ç–µ—Å—Ç–∞ —É –Ω–∞—Å –±—É–¥—É—Ç –æ—Å–Ω–æ–≤–∞–Ω–∏—è –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞—Ç—å –Ω—É–ª–µ–≤—É—é –≥–∏–ø–æ—Ç–µ–∑—É, —Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ –≤ —Ä—è–¥–µ –µ—Å—Ç—å —è–≤–Ω—ã–π –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ –∏ –æ–Ω –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º –≤ —à–∏—Ä–æ–∫–æ–º —Å–º—ã—Å–ª–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from statsmodels.tools.sm_exceptions import InterpolationWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", InterpolationWarning)\n",
    "\n",
    "test = kpss(result.seasonal, regression=\"c\")\n",
    "\n",
    "print(\"kpss:\", test[0])\n",
    "print(\"p-value:\", test[1])\n",
    "\n",
    "if test[1] > 0.05:\n",
    "    print(\"The time series is stationary around a constant\")\n",
    "else:\n",
    "    print(\"The time series is not stationary around a constant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–Ω–∞—á–Ω–∏–µ p-value –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –≥–∏–ø–æ—Ç–µ–∑—É –æ —Ç–æ–º, —á—Ç–æ —Ä—è–¥ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ–¥–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –î–∏–∫–∏-–§—É–ª–ª–µ—Ä–∞ –Ω–∞ —Å–µ–∑–æ–Ω–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "test = adfuller(result.seasonal)\n",
    "\n",
    "print(\"adf: \", test[0])\n",
    "print(\"p-value: \", test[1])\n",
    "# print(\"Critical values: \", test[4])\n",
    "\n",
    "if test[0] > test[4][\"5%\"]:\n",
    "    print(\"The time series is not stationary\")\n",
    "else:\n",
    "    print(\"The time series is stationary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±–∞ —Ç–µ—Å—Ç–∞ –≥–æ–≤–æ—Ä—è—Ç –æ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏ —Å–µ–∑–æ–Ω–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ä—è–¥–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∂–µ –º—ã –º–æ–∂–µ–º –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ —Ç—Ä–µ–Ω–¥–æ–≤–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –Ω–µ –≤–ø–æ–ª–Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä—è–º–æ–π –ª–∏–Ω–∏–µ–π. –î–µ–ª–æ –≤ —Ç–æ–º, —á—Ç–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –≤ –Ω–µ—ë –≤—Ö–æ–¥–∏—Ç —Ü–∏–∫–ª–∏—á–µ—Å–∫–∞—è —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∞—è. –ü–æ–ø—Ä–æ–±—É–µ–º –∏—Ö —Ä–∞–∑–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—é –ø—Ä—è–º–æ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = result.trend[~np.isnan(result.trend)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(trend))\n",
    "y = trend\n",
    "k, b = np.polyfit(x, y, 1)  # y = k*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_trend = np.arange(len(trend)) * k + [b] * len(trend)\n",
    "cycle = trend - real_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "fig.set_size_inches((12, 4))\n",
    "plt.xlabel(\"Month\")\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "plt.grid()\n",
    "fig.tight_layout()\n",
    "\n",
    "ax[0].plot(trend)\n",
    "ax[0].set_title(\"Trend+Cycle\")\n",
    "ax[1].plot(real_trend)\n",
    "ax[1].set_title(\"Trend\")\n",
    "ax[2].plot(cycle)\n",
    "ax[2].set_title(\"Cycle\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–¥–µ–ª–µ–Ω–∏–µ —Ü–∏–∫–ª–æ–≤ ‚Äî –¥–µ–ª–æ –Ω–µ–±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ–µ, –≤ —Ä–µ–¥–∫–∏—Ö —Ä–∞–±–æ—Ç–∞—Ö –≤—ã —ç—Ç–æ –≤—Å—Ç—Ä–µ—Ç–∏—Ç–µ. –î–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ü–∏–∫–ª–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–µ–Ω [—Ñ–∏–ª—å—Ç—Ä –ì–æ–¥—Ä–∏–∫–∞-–ü—Ä–µ—Å–∫–æ—Ç—Ç–∞ üõ†Ô∏è[doc]](https://www.statsmodels.org/stable/generated/statsmodels.tsa.filters.hp_filter.hpfilter.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π —Å–ª–µ–¥—É–µ—Ç –æ–±—Ä–∞—â–∞—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –Ω–∞ **train-val-test**.\n",
    "\n",
    "–ö–∞–∫ –∏ –≤ –∏–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö, –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏ –ø–æ–ª–µ–∑–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏. –ù–∞–ª–∏—á–∏–µ —Å—Ç—Ä–æ–≥–æ–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –Ω–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–º —Å–ª—É—á–∞–π–Ω–æ —Ä–∞–∑–¥–µ–ª—è—Ç—å —Ä—è–¥ –Ω–∞ –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏.\n",
    "\n",
    "–û—Ç–ª–∏—á–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å, —Å–¥–≤–∏–≥–∞—è—Å—å –≤–ø—Ä–∞–≤–æ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –æ—Å–∏, –∫–∞–∂–¥—ã–π —Ä–∞–∑ –¥–æ–±–∞–≤–ª—è—è –æ—Ç—Ä–µ–∑–æ–∫ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –æ–±—É—á–∞—è—Å—å –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å–ª–µ–≤–∞.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/ts_crossval.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://forecastegy.com/posts/time-series-cross-validation-python/\">CHow To Do Time Series Cross-Validation In Python</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–æ –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Ä—è–¥–∞. –¢–∞–∫, –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ, –ø—ã—Ç–ª–∏–≤—ã–π —Å–ª—É—à–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–µ—Ä–≤–æ–º —à–∞–≥–µ –≤–µ—Ä–æ—è—Ç–Ω–æ –±—É–¥–µ—Ç –Ω–∏–∂–µ, —á–µ–º –Ω–∞ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö, –ø—Ä–æ—Å—Ç–æ –ø–æ—Ç–æ–º—É, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–∞ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–∞—Ö –æ–±—É—á–µ–Ω–∞ –Ω–∞ –±–æ–ª—å—à–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö. –ü–æ—ç—Ç–æ–º—É –º–æ–∂–Ω–æ –∏–¥—Ç–∏ –≤–¥–æ–ª—å —Ä—è–¥–∞ –æ–∫–Ω–æ–º –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.\n",
    "\n",
    "–î—Ä—É–≥–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ä–∞–∑–±–∏–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞:\n",
    "\n",
    "[[blog] ‚úèÔ∏è How To Do Time Series Cross-Validation In Python](https://forecastegy.com/posts/time-series-cross-validation-python/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —ç—Ç–∏—Ö —Ü–µ–ª–µ–π –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è —Ñ—É–Ω–∫—Ü–∏–µ–π `TimeSeriesSplit` [üõ†Ô∏è[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Sklearn.\n",
    "\n",
    "–°—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å `gap` ‚Äî –æ—Ç—Å—Ç—É–ø —Å –ø—Ä–∞–≤–æ–≥–æ –∫—Ä–∞—è,  –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –Ω–∞ –∫–∞–∂–¥–æ–º —Ä–∞–∑–±–∏–µ–Ω–∏–∏ `max_train_size`, —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∞ `test_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "x = np.random.randn(17, 2)\n",
    "\n",
    "tscv = TimeSeriesSplit(gap=3, n_splits=3, test_size=2)\n",
    "print(tscv)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(x)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rolling forecasting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –º–æ–∂–µ–º –≤—ã–¥–µ–ª–∏—Ç—å –¥–≤–∞ —Ä–µ–∂–∏–º–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–≥–æ–¥—ã:\n",
    "* –Ω–∞ –∑–∞–≤—Ç—Ä–∞\n",
    "* –≤–ø–µ—Ä—ë–¥ –Ω–∞ –¥–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö –Ω–µ–¥–µ–ª–∏\n",
    "\n",
    "–í –ø–µ—Ä–≤–æ–º —Å–ª—É—á–∞–µ –∏–º–µ–µ—Ç—Å—è —Å–∞–º–∞—è –±–ª–∏–∑–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ—à–∏–±–∫–∞ –±—É–¥–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–∞.\n",
    "\n",
    "–í–æ –≤—Ç–æ—Ä–æ–º —Å–ª—É—á–∞–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∫–∞–∂–¥—ã–º –¥–Ω—ë–º –±—É–¥–µ—Ç –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–º. –°–∫–∞–∂–µ–º, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Ç–æ—Ä–æ–π –¥–µ–Ω—å –±—É–¥–µ—Ç –æ—Å–Ω–æ–≤—ã–≤–∞—Ç—å—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –∏ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "–ì—Ä—É–±–æ –≥–æ–≤–æ—Ä—è, –≤–æ –≤—Ç–æ—Ä–æ–º —Å–ª—É—á–∞–µ –º—ã –æ–ø—É—Å–∫–∞–µ–º –º–æ–¥–µ–ª—å –≤ \"—Å–≤–æ–±–æ–¥–Ω–æ–µ –ø–ª–∞–≤–∞–Ω–∏–µ\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/ts_forecasting.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=3, n_splits=5, max_train_size=5, test_size=2)\n",
    "print(tscv)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(x)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí• –ï—Å–ª–∏ –≤—ã –∏–¥–µ–∞–ª—å–Ω–æ –Ω–∞—É—á–∏–ª–∏—Å—å —Å–º–æ—Ç—Ä–µ—Ç—å –≤ –∑–∞–≤—Ç—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å, —Ç–æ –ø—Ä–æ–±–ª–µ–º –≤ —Ç–æ–º, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–¥—Ä—è–¥, –Ω–µ—Ç.\n",
    "\n",
    "ü§î –ù–æ —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ, –Ω—É–∂–Ω–æ —ç—Ç–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å–∫–∞–∂–µ–º, –Ω–∞ —Ç–µ—Å—Ç–µ.\n",
    "\n",
    "‚ùó–ú–æ–∂–µ—Ç –¥–∞—Ç—å –∑–∞–º–µ—Ç–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –≤ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ—Å—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–ø—Ä–æ—á–µ–º, –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –≤—Å–µ–≥–¥–∞ —Ä–∞–∑—É–º–Ω–æ. –ï—Å–ª–∏ —Ä—è–¥ –æ—á–µ–≤–∏–¥–Ω–æ –Ω–µ –±—É–¥–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—Ç—å —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ —É—á–∞—Å—Ç–∫–∏ —Ä—è–¥–∞, —Å—Ç–æ–∏—Ç –∏—Ö –≤–æ–≤—Å–µ —É–¥–∞–ª–∏—Ç—å.\n",
    "\n",
    "–ò –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ê–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å** (Autoregression method (AR))\n",
    "\n",
    "–õ–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å, –≤ –∫–æ—Ç–æ—Ä–æ–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–∞—è –≤–µ–ª–∏—á–∏–Ω–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ª–∏–Ω–µ–π–Ω—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é **$\\large p$** –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π.\n",
    "\n",
    "$$\\large y_t = Œ± + œï_{1}y_{t-1}+œï_{2}y_{t-2}+...+œï_{p}y_{t-p}+ œµ_t,$$\n",
    "\n",
    "–≥–¥–µ $y_t$ ‚Äî **—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π —Ä—è–¥**, $œµ_t$ ‚Äî –≥–∞—É—Å—Å–æ–≤ —à—É–º —Å–æ —Å—Ä–µ–¥–Ω–∏–º $0$ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π $\\sigma^2_œµ$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ú–µ—Ç–æ–¥ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ** (Moving average method (MA))\n",
    "\n",
    "–õ–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å, –≤ –∫–æ—Ç–æ—Ä–æ–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–∞—è –≤–µ–ª–∏—á–∏–Ω–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –ª–∏–Ω–µ–π–Ω—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é  $\\large q$  –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –æ—Å—Ç–∞—Ç–∫–æ–≤ –æ—Ç AR –º–æ–¥–µ–ª–∏ —Ä—è–¥–∞:\n",
    "\n",
    "$$\\large y_t = Œ± + œµ_t + \\theta_{1}œµ_{t-1}+\\theta_{2}œµ_{t-2}+...+\\theta_{q}œµ_{t-q},$$\n",
    "\n",
    "–≥–¥–µ $y_t$ ‚Äî **—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π —Ä—è–¥**, $œµ_t$ ‚Äî –æ—Å—Ç–∞—Ç–∫–∏ –æ—Ç AR-–º–æ–¥–µ–ª–∏ —Ä—è–¥–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARMA**\n",
    "\n",
    "–¢–µ–æ—Ä–µ–º–∞ –í–æ–ª—å–¥–∞: –ª—é–±–æ–π **—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π** —Ä—è–¥ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø–∏—Å–∞–Ω –º–æ–¥–µ–ª—å—é **ARMA(p,q)** —Å –ª—é–±–æ–π –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é.\n",
    "\n",
    "$$\\large y_t = Œ± + œµ_t + \\sum_{i=1}^p œï_{i}y_{t-i} + \\sum_{j=1}^q\\theta_{j}œµ_{t-j} $$\n",
    "\n",
    "–ú–æ–¥–µ–ª—å –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç, —á—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–≤–µ —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–µ: –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å–∏–æ–Ω–Ω—É—é –∏ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ, –∫–æ—Ç–æ—Ä—ã–µ –≤ –º–æ–¥–µ–ª–∏ –æ–±–æ–∑–Ω–∞—á–µ–Ω—ã $p$ –∏ $q$:\n",
    "\n",
    "* $p$ ‚Äî –ø–æ—Ä—è–¥–æ–∫ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–∏. –ü–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –±—É–¥–µ—Ç –ª–∏ –æ—á–µ—Ä–µ–¥–Ω–æ–π —ç–ª–µ–º–µ–Ω—Ç —Ä—è–¥–∞ –±–ª–∏–∑–æ–∫ –∫ –∑–Ω–∞—á–µ–Ω–∏—é $y$, –µ—Å–ª–∏ –∫ –Ω–µ–º—É –±—ã–ª–∏ –±–ª–∏–∑–∫–∏ $p$ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π.\n",
    "* $q$ ‚Äî –ø–æ—Ä—è–¥–æ–∫ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ. –ü–æ–∑–≤–æ–ª—è–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –∫–∞–∫ –ª–∏–Ω–µ–π–Ω—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –Ω–∞–±–ª—é–¥–∞–≤—à–∏—Ö—Å—è —Ä–∞–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–π –æ—à–∏–±–æ–∫."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARIMA**\n",
    "\n",
    "–ï—Å–ª–∏ —Ä—è–¥ **–ø–æ—Å–ª–µ –≤–∑—è—Ç–∏—è $d$ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–∑–Ω–æ—Å—Ç–µ–π** —Å–≤–æ–¥–∏—Ç—Å—è –∫ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ–º—É, —Ç–æ –¥–ª—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ, –æ–±–æ–∑–Ω–∞—á–∞–µ–º—É—é –∫–∞–∫ **ARIMA(p,d,q)**:\n",
    "\n",
    "$$ \\large (Œî^dy_t) = \\sum ^p _{i=1} œï_t(Œî^dy_{t-i}) + œµ_t + \\sum ^q _{j=1} \\theta_j(Œî^d œµ_{t-j}) $$\n",
    "\n",
    "–ú–æ–¥–µ–ª—å –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç, —á—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç—Ä–∏ —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–µ: –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å–∏–æ–Ω–Ω—É—é, —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –∏ **–∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é**, –∫–æ—Ç–æ—Ä—ã–µ –≤ –º–æ–¥–µ–ª–∏ –æ–±–æ–∑–Ω–∞—á–µ–Ω—ã $p, d$ –∏ $q$. –¢.–µ. –¥–æ–±–∞–≤–∏–ª–æ—Å—å:\n",
    "\n",
    "* $d$ ‚Äî –ø–æ—Ä—è–¥–æ–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏—è. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —ç–ª–µ–º–µ–Ω—Ç —Ä—è–¥–∞ –±–ª–∏–∑–æ–∫ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é –∫ $d$  –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∑–Ω–∞—á–µ–Ω–∏—è–º, –µ—Å–ª–∏ —Ä–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –Ω–∏–º–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SARMA** (Seasonable ARMA)\n",
    "\n",
    "–ï—Å–ª–∏ –≤–∑—è—Ç—å –º–æ–¥–µ–ª—å $\\text{ARMA(p,q)}$ –∏ –¥–æ–±–∞–≤–∏—Ç—å –∫ –Ω–µ–π $P$ –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç:\n",
    "\n",
    "$$\\large + \\sum_{k=1}^{PS}œï_{k}y_{t-k} $$\n",
    "\n",
    "–∏ $Q$ –∫–æ–º–ø–æ–Ω–µ—Ç —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ:\n",
    "\n",
    "$$\\large +  \\sum_{l=1}^{QS}\\theta_{l}œµ_{t-l},$$\n",
    "\n",
    "—Ç–æ –ø–æ–ª—É—á–∏–º $\\text{SARMA}(p,q) √ó (P,Q)$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SARIMA** (Seasonable ARIMA)\n",
    "\n",
    "–ú–æ–¥–µ–ª—å $\\text{SARIMA}(p,d,q) \\times (P,D,Q)$ ‚Äî –º–æ–¥–µ–ª—å $\\text{SARMA}(p,q) \\times (P,Q)$ –¥–ª—è —Ä—è–¥–∞, –∫ –∫–æ—Ç–æ—Ä–æ–º—É $d$ —Ä–∞–∑ –ø—Ä–∏–º–µ–Ω–∏–ª–∏ –æ–±—ã—á–Ω–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ $D$ —Ä–∞–∑ ‚Äî —Å–µ–∑–æ–Ω–Ω–æ–µ.\n",
    "\n",
    "–ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –∏–º–µ–Ω–Ω–æ —ç—Ç—É –º–æ–¥–µ–ª—å –æ–±—ã—á–Ω–æ –Ω–∞–∑—ã–≤–∞—é—Ç $\\text{ARIMA}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–†–∞–∑–±–µ—Ä–µ–º—Å—è —Å —Ç–µ–º, –æ—Ç–∫—É–¥–∞ –±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è $\\text{ARIMA}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°—É—â–µ—Å—Ç–≤—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–∞—è —Ç–µ–æ—Ä–∏—è –æ —Ç–æ–º, –∫–∞–∫ –≤—ã–±–∏—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏, –æ–¥–Ω–∞–∫–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/airline-passengers.csv\"\n",
    ")\n",
    "\n",
    "dataset[\"Month\"] = pd.to_datetime(dataset[\"Month\"])\n",
    "dataset = dataset.set_index([\"Month\"])\n",
    "dataset.index = pd.DatetimeIndex(dataset.index.values, freq=dataset.index.inferred_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = (\n",
    "    dataset[0 : int(len(dataset) * 0.9)],\n",
    "    dataset[int(len(dataset) * 0.9) :],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "stepwise_model = auto_arima(\n",
    "    train_data,\n",
    "    start_p=1,\n",
    "    start_q=1,\n",
    "    max_p=3,\n",
    "    max_q=3,\n",
    "    m=12,\n",
    "    start_P=0,\n",
    "    seasonal=True,\n",
    "    d=1,\n",
    "    D=1,\n",
    "    trace=True,\n",
    "    error_action=\"ignore\",\n",
    "    suppress_warnings=True,\n",
    "    stepwise=True,\n",
    ")\n",
    "print(stepwise_model.aic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_data = train_data.index[-1] + pd.DateOffset(months=1)\n",
    "\n",
    "future_forecast = stepwise_model.predict(start=start_data, n_periods=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_data[\"Passengers\"], color=\"green\", label=\"Train\")\n",
    "plt.plot(test_data[\"Passengers\"], color=\"red\", label=\"Real\")\n",
    "plt.plot(future_forecast, color=\"blue\", label=\"Predicted\")\n",
    "\n",
    "plt.title(\"ARIMA with optimal parameters\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(test_data[\"Passengers\"], future_forecast[: len(test_data)])\n",
    "print(f\"MSE:  {mse:.2f}\")\n",
    "mae = mean_absolute_error(test_data[\"Passengers\"], future_forecast[: len(test_data)])\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "rmse = np.sqrt(\n",
    "    mean_squared_error(test_data[\"Passengers\"], future_forecast[: len(test_data)])\n",
    ")\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ –±—ã –º—ã –ø–æ–¥–±–∏—Ä–∞–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä—É—á–Ω—É—é, –ø–æ–ª—É—á–∏–ª–æ—Å—å –±—ã –ø—Ä–∏–º–µ—Ä–Ω–æ —Ç–∞–∫–∂–µ, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –≥–æ—Ä–∞–∑–¥–æ –±—ã—Å—Ç—Ä–µ–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå ARIMA-–º–æ–¥–µ–ª–∏ —à–∏—Ä–æ–∫–æ –ø—Ä–∏–º–µ–Ω—è—é—Ç –Ω–µ –ø—Ä–æ—Å—Ç–æ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤, –Ω–æ —Å–∫–æ—Ä–µ–µ –∫–∞–∫ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –û–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –æ—Ç—Ä–µ–∑–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –Ω–µ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã ARIMA –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ –≤–µ—Å–æ–≤ –ø—Ä–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö, –ø—Ä–∏ –ø–æ–º–æ—â–∏ –∫–æ—Ç–æ—Ä–æ–≥–æ –º–æ–∂–Ω–æ —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ª–µ–∫—Ü–∏–π –º–µ—Ç–æ–¥–∞–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[blog] ‚úèÔ∏è –û–±—Å—É–∂–¥–µ–Ω–∏–µ –Ω–∞ Machinelearning Mastery](https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/)\n",
    "\n",
    "[[blog] ‚úèÔ∏è Forecasting Time Series with Auto-Arima](https://www.alldatascience.com/time-series/forecasting-time-series-with-auto-arima/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Å—Ç–∞—Ç–∫–æ–≤ (–ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞ –∏ –ø—Ä–æ—á–∏—Ö –∫–æ–º–ø–æ–Ω–µ—Ç), –∏–º–µ—é—â–∏—Ö —Å–ª–æ–∂–Ω—É—é –Ω–µ–ª–∏–Ω–µ–π–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∏–º–µ–µ—Ç —Å–º—ã—Å–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –º–æ—â–Ω—ã–µ, –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/decomposition_series_data.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.researchgate.net/publication/377532793_Improving_long-term_multivariate_time_series_forecasting_with_a_seasonal-trend_decomposition-based_2-dimensional_temporal_convolution_dense_network\">Research Gate</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ —Ç–∞–∫–∏—Ö –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è **—Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ —Å–µ—Ç–∏ (recurrent neural networks, RNN)**. –û–Ω–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –≤ —à–∏—Ä–æ–∫–æ–º –ø–µ—Ä–µ—á–Ω–µ –∑–∞–¥–∞—á: –æ—Ç **—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏** –¥–æ **–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥–ø–∏—Å–µ–π** –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º.\n",
    "\n",
    "–≠—Ç–∏ –∑–∞–¥–∞—á–∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ–¥–Ω–æ–π —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö, –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—Ä—É–≥–∏—Ö —á–∞—Å—Ç–µ–π.\n",
    "\n",
    "–° –º–æ–¥–µ–ª—è–º–∏ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∫–æ–Ω–∫—É—Ä–∏—Ä—É—é—Ç –º–æ–¥–µ–ª–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ (–ø–æ–¥—Ä–æ–±–Ω–µ–µ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –ª–µ–∫—Ü–∏–∏).\n",
    "\n",
    "–•–æ—Ç—è —Å–µ–π—á–∞—Å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –¥–µ—Ä–∂–∞—Ç –ø–µ—Ä–≤–µ–Ω—Å—Ç–≤–æ –≤–æ –º–Ω–æ–≥–∏—Ö –æ–±–ª–∞—Å—Ç—è—Ö, **—Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏ –ª—É—á—à–µ** –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è **–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤**.\n",
    "\n",
    "–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ –≤ —Å–∏–ª—É –∏—Ö —Ä–∞–∑–º–µ—Ä–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–µ—Å–æ–∏–∑–º–µ—Ä–∏–º–æ –±–æ–ª—å—à–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö, –Ω–µ–∂–µ–ª–∏ –¥–ª—è RNN (—Ä–æ–≤–Ω–æ –∫–∞–∫ –∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –∫–∞–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, —Ç–∞–∫ –∏ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å–ª–æ–π –≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/rnn_linear.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table, th, td {\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "}\n",
    "<font size=\"2\" face=\"Times New Romans\" >\n",
    "\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "\n",
    "\n",
    "<td>\n",
    "\n",
    "$$\\text{nn.Linear(in_features=3, out_features=2)}$$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\text{nn.RNN(input_size=3, hidden_size=2)}$$\n",
    "\n",
    "</td>\n",
    "<tr>\n",
    "\n",
    "\n",
    "<td>\n",
    "\n",
    "$$\\large h = f_{\\text{act}}(W_{xh}x)$$\n",
    "\n",
    "</td>  \n",
    "<td>\n",
    "\n",
    "$$\\large h_t = f_{\\text{act}}(W_{hh}h_{t-1} + W_{xh}x_t)$$\n",
    "\n",
    "</td>\n",
    "\n",
    "\n",
    "</tr>\n",
    "\n",
    "<td>\n",
    "\n",
    "$$\\large y = f_{\\text{act}}(W_{hy}h)$$\n",
    "\n",
    "</td>  \n",
    "\n",
    "<td>\n",
    "\n",
    "$$\\large y_t = f_{\\text{act}}(W_{hy}h_t)$$\n",
    "\n",
    "</td>\n",
    "\n",
    "</tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è RNN-—Å–ª–æ—è**: –ø–æ–¥–∞–≤–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ —Å–ª–æ—è –Ω–µ —Ç–æ–ª—å–∫–æ –≤—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –Ω–æ —Ç–∞–∫–∂–µ –∏ –≤—ã—Ö–æ–¥ —ç—Ç–æ–≥–æ –∂–µ —Å–ª–æ—è –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç–∞–∫—Ç –≤—Ä–µ–º–µ–Ω–∏.\n",
    "\n",
    "1) –í—Ö–æ–¥ —Å–ª–æ—è –≤ —Ç–µ–∫—É—â–∏–π —Ç–∞–∫—Ç –≤—Ä–µ–º–µ–Ω–∏ $\\large x_t$ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ —Å–≤–æ—é –º–∞—Ç—Ä–∏—Ü—É –ª–∏–Ω–µ–π–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è $\\large W_{xh}$.\n",
    "\n",
    "2) –í—ã—Ö–æ–¥—ã —Å–ª–æ—è —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ç–∞–∫—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ $\\large h_{t-1}$ –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ —Å–≤–æ—é –º–∞—Ç—Ä–∏—Ü—É –ª–∏–Ω–µ–π–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è $\\large W_{hh}$.\n",
    "\n",
    "3) –ó–Ω–∞—á–µ–Ω–∏—è —Å–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è –∏ –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, —Ñ–æ—Ä–º–∏—Ä—É—è —Ç–µ–∫—É—â–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ $\\large h_t$. **–í –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–æ–≥–æ —Å–ª–æ—è —á–∞—â–µ –≤—Å–µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥–∏–ø–µ—Ä–±–æ–ª–∏—á–µ—Å–∫–∏–π —Ç–∞–Ω–≥–µ–Ω—Å.**\n",
    "\n",
    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–≥–æ —Å–ª–æ—è –º–æ–∂–µ—Ç –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å—Å—è **—á–µ—Ä–µ–∑ –æ–±—ã—á–Ω—ã–π –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π** –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è $\\large y_t$.\n",
    "\n",
    "–û–±—ã—á–Ω–æ $\\large h_0$ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω—É–ª—è–º–∏.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã—á–∏—Å–ª–µ–Ω–∏—è –≤ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –º–æ–∂–Ω–æ \"—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å –≤–æ –≤—Ä–µ–º–µ–Ω–∏\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/linear_to_rnn.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í–µ–∫—Ç–æ—Ä $\\large h_t$ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö $\\large t$ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç.**\n",
    "\n",
    "–°—Ö–µ–º—É –≤—ã—à–µ –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º, —Å–∫–æ–º–ø–æ–Ω–æ–≤–∞–≤ –≤–µ–∫—Ç–æ—Ä–∞ $\\large x_t$, $\\large h_t$ –∏ $\\large y_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/rnn_basic_block.png\" width=\"1000\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º —Ä–∞–±–æ—Ç—É —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:\n",
    "1. –ù–∞ –≤—Ö–æ–¥ –ø–æ—Å—Ç—É–ø–∞–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å $\\large x = \\{x_1,...x_t,...,x_T\\}$, –≥–¥–µ $\\large x_t$ ‚Äî –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏. –í —Ä—è–¥–µ —Å–ª—É—á–∞–µ–≤ —ç—Ç–æ—Ç –≤–µ–∫—Ç–æ—Ä –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å $1$.\n",
    "\n",
    "2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç—É–ø–∏–≤—à–µ–≥–æ $\\large x_t$ —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ $\\large h_t$, –∫–æ—Ç–æ—Ä–æ–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ —è–≤–ª—è–µ—Ç—Å—è –ª–∏–Ω–µ–π–Ω—ã–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è $\\large h_{t-1}$ –∏ —Ç–µ–∫—É—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ $\\large x_t$, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –Ω–µ–ª–∏–Ω–µ–π–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏:\n",
    "$$\\large h_t = f_{\\text{act}}(W_{hh}h_{t-1} + W_{xh}x_t),$$\n",
    "–≥–¥–µ $\\large W_{hh}$ –∏ $\\large W_{xh}$  ‚Äî —ç—Ç–æ –º–∞—Ç—Ä–∏—Ü—ã –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–≤–µ—Å–∞). –¢–∞–∫–∂–µ –º–æ–∂–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å—Å—è –≤–µ–∫—Ç–æ—Ä —Å–º–µ—â–µ–Ω–∏–π (bias).\n",
    "\n",
    "3. –ù–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, —É—á–∏—Ç—ã–≤–∞—é—â–µ–≥–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è  $\\large x_t$, —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –≤—ã—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å $\\large y = \\{y_1,...y_t,...,y_T\\}$. –î–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è $\\large y_t$ –≤ —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ –≤ –º–æ–¥–µ–ª—å –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –æ–±—ã—á–Ω—ã–π –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π, –ø—Ä–∏–Ω–∏–º–∞—é—â–∏–π –Ω–∞ –≤—Ö–æ–¥ —Ç–µ–∫—É—â–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ $\\large h_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—Ä–∞—Ç–∏–º –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
    "\n",
    "$$\\large h_t = f_{\\text{act}}(W_{hh}h_{t-1} + W_{xh}x_t)$$\n",
    "\n",
    "–º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ –≤–∏–¥–µ $$\\large h_t = f_{\\text{act}}(W\\ [h_{t-1},x_t]),$$\n",
    "\n",
    "–≥–¥–µ $\\large [h_{t-1},x_t]$ ‚Äî –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ $\\large h_{t-1}$ –∏ $\\large x_t$, –∞ $\\large W$ ‚Äî —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü $\\large W_{hh}$ –∏ $\\large W_{xh}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN —Å–ª–æ–π –≤ PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í PyTorch –µ—Å—Ç—å —Å–ª–æ–π ‚Äî `torch.nn.RNN` [üõ†Ô∏è[doc]](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html), –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª–∏–∑—É–µ—Ç –ª–æ–≥–∏–∫—É, –æ–ø–∏—Å–∞–Ω–Ω—É—é –≤—ã—à–µ.\n",
    "\n",
    "–¢–∞–∫–∂–µ –µ—Å—Ç—å —Å—É—â–Ω–æ—Å—Ç—å `torch.nn.RNNCell` [üõ†Ô∏è[doc]](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html), –∫–æ—Ç–æ—Ä–∞—è —Ä–µ–∞–ª–∏–∑—É–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ –æ–¥–Ω–æ–º —Ç–∞–∫—Ç–µ –≤—Ä–µ–º–µ–Ω–∏.\n",
    "\n",
    "–°–ª–æ–π `nn.RNN` —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ —è–≤–ª—è–µ—Ç—Å—è –æ–±–µ—Ä—Ç–∫–æ–π, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–∑—ã–≤–∞–µ—Ç `nn.RNNCell` –≤ —Ü–∏–∫–ª–µ –ø–æ –¥–ª–∏–Ω–µ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–ª–æ—è `nn.RNN`:\n",
    "\n",
    "* **`input_size`** ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å $\\large x_t$, —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ.\n",
    "\n",
    "* **`hidden_size`** ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å $\\large h_t$, —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ. –§–∞–∫—Ç–∏—á–µ—Å–∫–∏ —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–º —Å–ª–æ–µ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–ª–æ–µ–≤ –≤ PyTorch: –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–∂–∏–¥–∞–µ–º—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—Ö–æ–¥–∞ —Ç–∞–∫–∏–µ:\n",
    "\n",
    "**`[–¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–∞]`**\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ –µ—Å–ª–∏ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–ª–æ—è —É–∫–∞–∑–∞—Ç—å `batch_first=True`, —Ç–æ –º–æ–∂–Ω–æ –ø–æ–¥–∞–≤–∞—Ç—å –≤—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –±–æ–ª–µ–µ –ø—Ä–∏–≤—ã—á–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –∫–æ–≥–¥–∞ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ —Å—Ç–æ–∏—Ç –Ω–∞ –ø–µ—Ä–≤–æ–º –º–µ—Å—Ç–µ:\n",
    "\n",
    "**`[—Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–∞]`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "rnn = torch.nn.RNN(input_size=3, hidden_size=2, batch_first=True)\n",
    "\n",
    "dummy_batched_seq = torch.randn((16, 57, 3))  # batch_size, seq_len, input_size\n",
    "out, h = rnn(dummy_batched_seq)\n",
    "\n",
    "print(\"Input shape:\".ljust(20), f\"{dummy_batched_seq.shape}\")\n",
    "print(\"Out shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Last hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ –≤—ã–∑–æ–≤–µ —Å–ª–æ–π –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–≤–∞ –æ–±—ä–µ–∫—Ç–∞:\n",
    "* `out` ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π,\n",
    "* `h` ‚Äî —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Ç–∞–∫—Ç–µ.\n",
    "\n",
    "–ú—ã —É–∫–∞–∑–∞–ª–∏ `batch_first=True`, –ø—Ä–∏ —ç—Ç–æ–º `out` —Å–æ—Ö—Ä–∞–Ω–∏–ª –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π, –∫–∞–∫ —É –≤—Ö–æ–¥–∞, –∞ –≤–æ—Ç —É `h` —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞ –≤—Å—Ç–∞–ª–∞ –Ω–∞ –≤—Ç–æ—Ä–æ–µ –º–µ—Å—Ç–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_batch_first = h.permute(1, 0, 2)\n",
    "\n",
    "print(f\"h is last out: {(h_batch_first == out[:, -1:, :]).all().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN-–±–ª–æ–∫–∏ –º–æ–∂–Ω–æ –æ–±—ä–µ–¥–∏–Ω—è—Ç—å –≤ —Å–ª–æ–∏, –Ω–∞–∫–ª–∞–¥—ã–≤–∞—è –∏—Ö –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–∞. –î–ª—è —ç—Ç–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ `torch.nn.RNN` –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç `num_layers`, —Å –ø–æ–º–æ—â—å—é –∫–æ—Ç–æ—Ä–æ–≥–æ –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ—ë–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/rnn_multiple_layers.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((16, 6, 3))  # batch_size, seq_len, input_size\n",
    "rnn = torch.nn.RNN(input_size=3, hidden_size=2, num_layers=2, batch_first=True)\n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print()\n",
    "print(\"Out:\\n\", out.shape)  # Hidden states for all elements from top layer\n",
    "print(\"h:\\n\", h.shape)  # Hidden states for last element for all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ —Å –ø–æ–º–æ—â—å—é RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–∞—è —Å–µ—Ç—å –º–æ–∂–µ—Ç –≤—ã–¥–∞–≤–∞—Ç—å –Ω–µ–∫–∏–π –æ—Ç–≤–µ—Ç –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ, –æ–¥–Ω–∞–∫–æ –º—ã –º–æ–∂–µ–º –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ä–∞–±–æ—Ç—É –≤–æ—Ç –≤ —Ç–∞–∫–æ–π –ª–æ–≥–∏–∫–µ:\n",
    "\n",
    "üü¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π `hidden` –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è. –≠—Ç–æ—Ç —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞–º –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞, –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è **many-to-one**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/many_to_one.png\" width=\"300\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –¥–∞—Ç–∞—Å–µ—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –æ–±—ä–µ–º–µ –µ–∂–µ–º–µ—Å—è—á–Ω—ã—Ö –∞–≤–∏–∞–ø–µ—Ä–µ–≤–æ–∑–æ–∫ —Å 1949 –ø–æ 1960 –≥–æ–¥. –°—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–∞–º–∏ —Å—Ä–∞–∑—É –ø—Ä–∏–≤–µ–¥–µ–º –∫ —Ñ–æ—Ä–º–∞—Ç—É `datetime` [üõ†Ô∏è[doc]](https://pandas.pydata.org/docs/user_guide/timeseries.html) –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/airline-passengers.csv\"\n",
    ")\n",
    "dataset.Month = pd.to_datetime(dataset.Month)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–≤–µ–¥–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def simple_display(data, xticks, label=None):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(xticks, data, label=label)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[\"Passengers\"]\n",
    "simple_display(data=data, xticks=dataset[\"Month\"], label=\"Initial data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–±–ª—é–¥–∞–µ–º, —á—Ç–æ –≤ –¥–∞–Ω–Ω—ã—Ö —è–≤–Ω–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ç—Ä–µ–Ω–¥, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, –∞ —Ç–∞–∫–∂–µ –≥–µ—Ç–µ—Ä–æ—Å–∫–µ–¥–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å (–Ω–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å –ø–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏). –°–¥–µ–ª–∞—Ç—å —Ä—è–¥ –≥–æ–º–æ—Å–∫–µ–¥–∞—Å—Ç–∏—á–Ω—ã–º –º–æ–∂–Ω–æ, –ø—Ä–∏–º–µ–Ω–∏–≤ –∫ –Ω–µ–º—É –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_log = np.log(data)\n",
    "simple_display(data=data_log, xticks=dataset[\"Month\"], label=\"log(Initial data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ train-val-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–¥–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞:\n",
    "* –æ–±—É—á–∞—é—â–∏–µ (—è–Ω–≤–∞—Ä—å 1949 &ndash; –¥–µ–∫–∞–±—Ä—å 1955),\n",
    "* –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ (—è–Ω–≤–∞—Ä—å 1956 &ndash; –¥–µ–∫–∞–±—Ä—å 1958),\n",
    "* —Ç–µ—Å—Ç–æ–≤—ã–µ (—è–Ω–≤–∞—Ä—å 1959 &ndash; –¥–µ–∫–∞–±—Ä—å 1960).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "train_start = datetime.datetime(1949, 1, 1)\n",
    "train_end = datetime.datetime(1955, 12, 1)\n",
    "\n",
    "val_start = datetime.datetime(1956, 1, 1)\n",
    "val_end = datetime.datetime(1958, 12, 1)\n",
    "\n",
    "test_start = datetime.datetime(1959, 1, 1)\n",
    "test_end = datetime.datetime(1960, 12, 1)\n",
    "\n",
    "train_data = dataset.query(\"(`Month` >= @train_start) & (`Month` <= @train_end)\")\n",
    "val_data = dataset.query(\"(`Month` >= @val_start) & (`Month` <= @val_end)\")\n",
    "test_data = dataset.query(\"(`Month` >= @test_start) & (`Month` <= @test_end)\")\n",
    "\n",
    "print(\"Train head and tail:\")\n",
    "display(train_data.iloc[np.r_[0:2, -2:0]])\n",
    "print(\"\\nVal head and tail:\")\n",
    "display(val_data.iloc[np.r_[0:2, -2:0]])\n",
    "print(\"\\nTest head and tail:\")\n",
    "display(test_data.iloc[np.r_[0:2, -2:0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞—á–Ω–µ–º —Å–æ–±–∏—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É. –î–ª—è –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö (`train`, `val`, –∏ `test`) –∑–∞–ø–∏—à–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∏ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = {\"train\": {}, \"val\": {}, \"test\": {}}\n",
    "\n",
    "for part, data_part in zip(split, [train_data, val_data, test_data]):\n",
    "    split[part][\"timestamps\"] = data_part[\"Month\"]\n",
    "    split[part][\"data\"] = data_part[\"Passengers\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ç–æ–±—Ä–∞–∑–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_data_display(split):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for part in split:\n",
    "        plt.plot(split[part][\"timestamps\"], split[part][\"data\"], label=part)\n",
    "    plt.title(\"Initial data\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "initial_data_display(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é —Ç—Ä–µ–±—É–µ—Ç—Å—è, —á—Ç–æ–±—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –∏ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ –æ–±—É—á–∞—é—â–µ–π, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∞—Ö –±—ã–ª–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º.\n",
    "\n",
    "–î–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –≥–µ—Ç–µ—Ä–æ—Å–∫–µ–¥–∞—Å—Ç–∏—á–Ω–æ—Å—Ç–∏ –∏ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞ —Ä–µ–∞–ª–∏–∑—É–µ–º –∫–ª–∞—Å—Å, —Å –ø–æ–º–æ—â—å—é –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã —Å–º–æ–∂–µ–º:\n",
    "\n",
    "* –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –≥–µ—Ç–µ—Ä–æ—Å–∫–µ–¥–∞—Å—Ç–∏—á–Ω–æ—Å—Ç–∏ (—Ñ–ª–∞–≥ `apply_log`),\n",
    "* –ø—Ä–æ–≤–æ–¥–∏—Ç—å –æ—Ü–µ–Ω–∫—É –∏ –≤—ã—á–∏—Ç–∞–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞ —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–æ–≤ `fit` –∏ `transform`,\n",
    "* –ø—Ä–æ–≤–æ–¥–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: –ø—Ä–∏–±–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ –∏ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∏—Ä–æ–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –ø—Ä–æ–≤–æ–¥–∏–ª–æ—Å—å –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ) —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–∞ `inverse_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "class TimeSeriesTransform:\n",
    "    def __init__(self, apply_log=False):\n",
    "        self.slope = None\n",
    "        self.apply_log = apply_log\n",
    "\n",
    "    def fit(self, train_data: np.ndarray):\n",
    "        data = train_data\n",
    "        if self.apply_log:\n",
    "            data = np.log(data + 1)  # to avoid log(0)\n",
    "\n",
    "        x = np.arange(len(data))\n",
    "        x_centered = x - x.mean()\n",
    "\n",
    "        data_centered = data - data.mean()\n",
    "\n",
    "        reg = LinearRegression(fit_intercept=False).fit(\n",
    "            x_centered.reshape(-1, 1), data_centered.reshape(-1, 1)\n",
    "        )\n",
    "\n",
    "        self.slope = reg.coef_[0]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: np.ndarray, window_size: int):\n",
    "        if self.slope is None:\n",
    "            raise ValueError(\"call fit before transform\")\n",
    "\n",
    "        if self.apply_log:\n",
    "            data = np.log(data + 1)  # to avoid log(0)\n",
    "\n",
    "        x = np.arange(len(data))\n",
    "        x_centered = x - x.mean()\n",
    "        trend = self.slope * x_centered\n",
    "\n",
    "        anchor_value = data[window_size]\n",
    "        data_centered = data - data.mean()\n",
    "        data_detrended = data_centered - trend\n",
    "        return anchor_value, data_detrended\n",
    "\n",
    "    def inverse_transform(self, anchor_value: float, data_detrended: np.ndarray):\n",
    "        if self.slope is None:\n",
    "            raise ValueError(\"call fit before inverse_transform\")\n",
    "\n",
    "        x = np.arange(len(data_detrended))\n",
    "        x_centered = x - x.mean()\n",
    "        trend = self.slope * x_centered\n",
    "\n",
    "        data = data_detrended + trend\n",
    "        data = data - data[0] + anchor_value\n",
    "        if self.apply_log:\n",
    "            data = np.exp(data) - 1\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ–Ω–∏–º –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ, –æ—Ü–µ–Ω–∏–º –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–≤–µ–¥–µ–º –µ–≥–æ –≤—ã—á–∏—Ç–∞–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "–ù–µ–æ—á–µ–≤–∏–¥–Ω—ã–π –º–æ–º–µ–Ω—Ç: –Ω–∞–ª–∏—á–∏–µ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞ –ø—Ä–∏–≤–æ–¥–∏—Ç –Ω–∞—Å –∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É–º–µ—Ç—å —ç–∫—Å—Ç—Ä–∞–ø–æ–ª–∏—Ä–æ–≤–∞—Ç—å –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ –≤ –æ–±–ª–∞—Å—Ç—å –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –º—ã –µ–≥–æ –æ—Ü–µ–Ω–∏–≤–∞–µ–º. –ü–æ—Ç–æ–º—É –ø—Ä–∏ –≤—ã–∑–æ–≤–µ `transform` –º—ã —Ö—Ä–∞–Ω–∏–º –æ–ø–æ—Ä–Ω—É—é —Ç–æ—á–∫—É (`anchor_value`) –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ –ø–æ–¥–≤—ã–±–æ—Ä–æ–∫, —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å, –≤ –∫–∞–∫–æ–º –º–∞—Å—à—Ç–∞–±–µ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å —Ç—Ä–µ–Ω–¥ –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º –ø—Ä–∏ –≤—ã–∑–æ–≤–µ `inverse_transform`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 12\n",
    "\n",
    "split[\"train\"][\"transform\"] = TimeSeriesTransform(apply_log=True)\n",
    "\n",
    "split[\"train\"][\"transform\"].fit(split[\"train\"][\"data\"])\n",
    "\n",
    "for part in split:\n",
    "    split[part][\"anchor_value\"], split[part][\"data_transformed\"] = split[\"train\"][\n",
    "        \"transform\"\n",
    "    ].transform(split[part][\"data\"], window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ç–æ–±—Ä–∞–∑–∏–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö —Ç–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å, –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed_data_display(split):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for part in split:\n",
    "        plt.plot(split[part][\"timestamps\"], split[part][\"data_transformed\"], label=part)\n",
    "    plt.title(\"Transformed data\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "transformed_data_display(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –¥–∞—Ç–∞—Å–µ—Ç: –±—É–¥–µ–º –æ–±—É—á–∞—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –ø–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ `seq_len` —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å `seq_len + 1`-–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_length):\n",
    "        super().__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # seq_len elements input\n",
    "        x = self.data[idx : (idx + self.seq_length)].view(-1, 1)\n",
    "        # one element output\n",
    "        y = self.data[idx + self.seq_length]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–¥–∏–º `Dataset` –∏ `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "for part in split:\n",
    "    split[part][\"dataset\"] = TimeSeriesDataset(\n",
    "        data=split[part][\"data_transformed\"], seq_length=window_size\n",
    "    )\n",
    "\n",
    "    shuffle = True if part == \"train\" else False\n",
    "\n",
    "    split[part][\"dataloader\"] = DataLoader(\n",
    "        dataset=split[part][\"dataset\"], batch_size=16, shuffle=shuffle\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –æ–¥–∏–Ω –±–∞—Ç—á –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ —Ç–∞–∫–∂–µ –≤—ã–≤–µ–¥–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞—é—â–∏—Ö –±–∞—Ç—á–µ–π:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(split[\"train\"][\"dataloader\"]))\n",
    "\n",
    "print(f\"one batch input shape:   {x.shape}\")\n",
    "print(f\"one batch output shape:  {y.shape}\")\n",
    "print(f\"number of train batches: {len(split['train']['dataloader'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –¥–≤–∞ —Å–ª–æ—è:\n",
    "\n",
    "* —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π –∏–∑ `hidden_size` —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø–æ–ª—É—á–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ `seq_len` –æ—Ç—Å—á–µ—Ç–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ (—Ç–∞–∫ –∫–∞–∫ –º—ã –∏–º–µ–µ–º –¥–µ–ª–æ —Å–æ —Å–∫–∞–ª—è—Ä–Ω—ã–º —Ä—è–¥–æ–º, —Ç–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å `input_size` –≤ –¥–∞–Ω–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ —Ä–∞–≤–Ω–∞ $1$) –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å `seq_len` —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π,\n",
    "* –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–∫—Ä—ã—Ç–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ–¥–Ω–æ —á–∏—Å–ª–æ &mdash; —Å–ª–µ–¥—É—é—â–∏–π –æ—Ç—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TimeSeriesPredictor(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=16):\n",
    "        # hidden_size it is number of hidden neurons\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size, hidden_size=hidden_size, batch_first=True\n",
    "        )\n",
    "        # Predict only one value\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [b_s, seq_len, input_size]  b_s <= batch_size\n",
    "        out, h = self.rnn(x)  # [b_s, seq_len, hidden_size], [1, b_s, hidden_size]\n",
    "        y = self.fc(h)  # [1, b_s, 1]\n",
    "        y = y.flatten()  # [b_s]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞ –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeSeriesPredictor()\n",
    "out = model(x)\n",
    "\n",
    "print(f\"Model output size: {out.shape} (bach_size x out_dim)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –≤ –¥–≤—É—Ö —Ä–µ–∂–∏–º–∞—Ö:\n",
    "\n",
    "* \"forced prediction\" ‚Äî –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –≤—Ö–æ–¥ –≤—Å–µ–≥–¥–∞ –ø–æ–¥–∞—é—Ç—Å—è –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ä—è–¥–∞,\n",
    "* \"rolling prediction\" ‚Äî –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–µ, –∫–æ–≥–¥–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Ä—è–¥–∞ –Ω–µ—Ç –Ω–∞ —Ä—É–∫–∞—Ö, –º–æ–∂–Ω–æ –ø–æ–¥–∞–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Ö–æ–¥ –µ–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏ –≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç—Å—á–µ—Ç–æ–≤ –≤ –±—É–¥—É—â–µ–µ.\n",
    "\n",
    "–î–ª—è —á–µ—Å—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω—É–∂–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∏–º–µ–Ω–Ω–æ \"rolling prediction\": –ø–æ–¥–∞–µ–º –º–æ–¥–µ–ª–∏ –ø–µ—Ä–≤—ã–µ `seq_len` –æ—Ç—Å—á–µ—Ç–æ–≤ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ–¥–∞–µ–º –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Ö–æ–¥ –µ–µ –∂–µ –≤—ã—Ö–æ–¥.\n",
    "\n",
    "–û–±—Ä–∞—Ç–∏–º –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –ø–æ—ç—Ç–æ–º—É –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤—ã–∑–≤–∞—Ç—å `inverse_transform` –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forced_predict(model, split, part):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    dataset = split[part][\"dataset\"]\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataset:\n",
    "            out = model(x)\n",
    "            y_true.append(y.item())\n",
    "            y_pred.append(out.item())\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    transform = split[\"train\"][\"transform\"]\n",
    "    y_true = transform.inverse_transform(split[part][\"anchor_value\"], y_true)\n",
    "    y_pred = transform.inverse_transform(split[part][\"anchor_value\"], y_pred)\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_predict(model, split, part, forecast_horizon):\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    dataset = split[part][\"dataset\"]\n",
    "    x, _ = dataset[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(forecast_horizon):\n",
    "            out = model(x).view(-1, 1)  # for concatenation shape compatibility\n",
    "            y_pred.append(out.item())\n",
    "\n",
    "            # drop first element and add new prediction\n",
    "            x = torch.cat([x[1:], out])\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    transform = split[\"train\"][\"transform\"]\n",
    "    y_pred = transform.inverse_transform(split[part][\"anchor_value\"], y_pred)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª—É—á–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: –≤ —Ä–µ–∂–∏–º–µ \"forced prediction\" –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –≤ —Ä–µ–∂–∏–º–µ \"rolling prediction\" –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in split:\n",
    "    if part in (\"train\", \"val\"):\n",
    "        y_true, y_pred = forced_predict(model, split, part)\n",
    "\n",
    "    if part == \"test\":\n",
    "        y_true, _ = forced_predict(model, split, part)\n",
    "        y_pred = rolling_predict(model, split, part, forecast_horizon=len(y_true))\n",
    "\n",
    "    split[part][\"y_true\"] = y_true\n",
    "    split[part][\"y_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ç–æ–±—Ä–∞–∑–∏–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. –¢–∞–∫ –∫–∞–∫ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º—ã –º–æ–∂–µ–º –ø–æ–ª—É—á–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–µ–µ, —á–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–∞—Ç –ø–æ –æ—Å–∏ `x` —Å–æ–∑–¥–∞–µ—Ç—Å—è `pd.date_range` [üõ†Ô∏è[doc]](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html) —Å –Ω–∞—á–∞–ª–æ–º, —Å–æ–≤–ø–∞–¥–∞—é—â–∏–º —Å –Ω–∞—á–∞–ª–æ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∏ –¥–ª–∏–Ω–æ–π —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pred_with_rolling_test(split):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for part in split:\n",
    "        timestamps = split[part][\"timestamps\"][window_size:]\n",
    "        real_data = split[part][\"y_true\"]\n",
    "        pred_data = split[part][\"y_pred\"]\n",
    "\n",
    "        if part in (\"train\", \"val\"):\n",
    "\n",
    "            plt.plot(timestamps, real_data, label=f\"{part}/real\")\n",
    "            plt.plot(timestamps, pred_data, label=f\"{part}/predicted\")\n",
    "\n",
    "        if part == \"test\":\n",
    "            plt.plot(timestamps, real_data, label=f\"{part}/real\")\n",
    "\n",
    "            future_timestamps = pd.date_range(\n",
    "                timestamps.iloc[0], periods=len(pred_data), freq=\"MS\"\n",
    "            )\n",
    "            plt.plot(future_timestamps, pred_data, label=f\"{part}/predicted\")\n",
    "\n",
    "    plt.title(\"Real vs Predicted\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "display_pred_with_rolling_test(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ü–µ–Ω–∏–º –æ—à–∏–±–∫—É RMSE –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for part in split:\n",
    "    part_rmse = np.sqrt(\n",
    "        mean_squared_error(\n",
    "            y_true=split[part][\"y_true\"], y_pred=split[part][\"y_pred\"], squared=False\n",
    "        )\n",
    "    )\n",
    "    print(f\"{part:<5} RMSE: {part_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–µ–∞–ª–∏–∑—É–µ–º –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞ Lightning. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –º–µ—Ç—Ä–∏–∫–∏ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q lightning tbparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "\n",
    "\n",
    "class TimeSeriesPipeline(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        exp_name=\"baseline\",\n",
    "        criterion=nn.MSELoss(),\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        metrics = MetricCollection([MeanSquaredError()])\n",
    "        self.train_metrics = metrics.clone(postfix=\"/train\")\n",
    "        self.valid_metrics = metrics.clone(postfix=\"/val\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer_class(self.model.parameters())\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.model(x)\n",
    "        loss = self.criterion(out, y)\n",
    "\n",
    "        self.log(\"Loss/train\", loss, prog_bar=True)\n",
    "        self.train_metrics.update(out, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.model(x)\n",
    "        loss = self.criterion(out, y)\n",
    "        self.log(\"Loss/val\", loss, prog_bar=True)\n",
    "        self.valid_metrics.update(out, y)\n",
    "\n",
    "    def on_training_epoch_end(self):\n",
    "        train_metrics = self.train_metrics.compute()\n",
    "        self.log_dict(train_metrics)\n",
    "        self.train_metrics.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        valid_metrics = self.valid_metrics.compute()\n",
    "        self.log_dict(valid_metrics)\n",
    "        self.valid_metrics.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –ø–∞–π–ø–ª–∞–π–Ω –∏ –∑–∞–ø—É—Å—Ç–∏–º –æ–±—É—á–µ–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É MSE –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "L.seed_everything(42)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"MeanSquaredError/val\", mode=\"min\", filename=\"best\"\n",
    ")\n",
    "\n",
    "exp_name = f\"baseline\"\n",
    "trainer = Trainer(\n",
    "    max_epochs=3000,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/time_series_prediction\", name=exp_name),\n",
    "    num_sanity_val_steps=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    log_every_n_steps=5,\n",
    "    enable_progress_bar=False,\n",
    ")\n",
    "\n",
    "model = TimeSeriesPredictor()\n",
    "\n",
    "pipeline = TimeSeriesPipeline(\n",
    "    model=model,\n",
    "    optimizer_class=torch.optim.Adam,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=pipeline,\n",
    "    train_dataloaders=split[\"train\"][\"dataloader\"],\n",
    "    val_dataloaders=split[\"val\"][\"dataloader\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbparse import SummaryReader\n",
    "\n",
    "\n",
    "def tbparse_visual(log_path):\n",
    "    reader = SummaryReader(log_path)\n",
    "    df = reader.scalars\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for tag in df.tag.unique():\n",
    "        if \"Loss\" in tag:\n",
    "            tag_data = df.query(\"`tag` == @tag\").sort_values(by=\"step\")\n",
    "            tag_data = tag_data.value.values\n",
    "            plt.plot(tag_data, label=tag)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_path = f\"/content/logs/time_series_prediction/{exp_name}\"\n",
    "last_version = sorted(os.listdir(base_path))[-1]\n",
    "log_path = f\"{base_path}/{last_version}\"\n",
    "\n",
    "tbparse_visual(log_path)\n",
    "\n",
    "# or simply uncomment these two lines\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs/time_series_prediction --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ç–æ—á–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å –º–æ–≥–ª–∞ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å—Å—è, –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º MSE –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f\"{log_path}/checkpoints/best.ckpt\"\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "\n",
    "print(f\"Checkpoint has been loaded from {ckpt_path}\")\n",
    "print(f\"Best model has been saved on the {checkpoint['epoch']} epoch\")\n",
    "\n",
    "state_dict = {}\n",
    "for key in checkpoint[\"state_dict\"].keys():\n",
    "    key_new = key.lstrip(\"model.\")\n",
    "    state_dict[key_new] = checkpoint[\"state_dict\"][key]\n",
    "\n",
    "model = TimeSeriesPredictor()\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ª—É—á–∏–º –∏ –æ—Ç–æ–±—Ä–∞–∑–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: –≤ —Ä–µ–∂–∏–º–µ \"forced prediction\" –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –≤ —Ä–µ–∂–∏–º–µ \"rolling prediction\" –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in split:\n",
    "    if part in (\"train\", \"val\"):\n",
    "        y_true, y_pred = forced_predict(model, split, part)\n",
    "\n",
    "    if part == \"test\":\n",
    "        y_true, _ = forced_predict(model, split, part)\n",
    "        y_pred = rolling_predict(model, split, part, forecast_horizon=len(y_true))\n",
    "\n",
    "    split[part][\"y_true\"] = y_true\n",
    "    split[part][\"y_pred\"] = y_pred\n",
    "\n",
    "display_pred_with_rolling_test(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ü–µ–Ω–∏–º –æ—à–∏–±–∫—É RMSE –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in split:\n",
    "    part_rmse = mean_squared_error(\n",
    "        y_true=split[part][\"y_true\"], y_pred=split[part][\"y_pred\"], squared=False\n",
    "    )\n",
    "    print(f\"{part:<5} RMSE: {part_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Ä–µ–∂–∏–º–µ \"rolling prediction\" –∏ –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ —Ç–∞–∫–∂–µ –ø–æ–ª—É—á–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –µ—â–µ –Ω–∞ 4 –≥–æ–¥–∞ –≤–ø–µ—Ä–µ–¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in split:\n",
    "    if part in (\"train\", \"val\"):\n",
    "        y_true, _ = forced_predict(model, split, part)\n",
    "        y_pred = rolling_predict(model, split, part, forecast_horizon=len(y_true))\n",
    "\n",
    "    if part == \"test\":\n",
    "        y_true, _ = forced_predict(model, split, part)\n",
    "        y_pred = rolling_predict(model, split, part, forecast_horizon=64)\n",
    "\n",
    "    split[part][\"y_true\"] = y_true\n",
    "    split[part][\"y_pred\"] = y_pred\n",
    "\n",
    "display_pred_with_rolling_test(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ \"—á–µ—Å—Ç–Ω–æ–º\" –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤–∏–¥–Ω–æ, —á—Ç–æ —á–µ–º –¥–∞–ª—å—à–µ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ —Å–≤–æ–∏–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º, —Ç–µ–º –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–º —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø—Ä–æ–≥–Ω–æ–∑. –¢–∞–∫–∂–µ –º—ã –Ω–∞–±–ª—é–¥–∞–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å —Å–º–æ–≥–ª–∞ –≤—ã—É—á–∏—Ç—å —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö: –≥–æ–¥–∏—á–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ó–∞–º–µ—á–∞–Ω–∏—è:**\n",
    "\n",
    "1. –°–ª–æ–∂–Ω–æ—Å—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –¥–æ–ª–∂–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ–¥–∞–≤–∞–µ–º—ã—Ö –≤ –Ω–µ–µ –¥–∞–Ω–Ω—ã—Ö. –° —Ä–æ—Å—Ç–æ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è (—á–∏—Å–ª–∞ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤) —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Ä–∞—Å—Ç–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –∑–∞—É—á–∏–≤–∞—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –≤—ã–±–æ—Ä–∫—É –∏ —Ç–µ—Ä—è–µ—Ç—Å—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ –æ–±–æ–±—â–µ–Ω–∏—é.\n",
    "2. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–∏–∫–ª–∏—á–Ω–æ—Å—Ç–∏ –≤ –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å) –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∞–Ω—Å–∞–º–±–ª—è (—Ç—É—Ç –≤–∏–¥–Ω–æ, —á—Ç–æ —Ü–∏–∫–ª –≤ —Å—Ä–µ–¥–Ω–µ–º —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 12 –æ—Ç—Å—á–µ—Ç–æ–≤).\n",
    "3. –ö–∞–∫ –º–æ–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, –æ—Å–Ω–æ–≤–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ä—è–¥–æ–º –ª–µ–∂–∏—Ç –≤ –ø—Ä–µ–¥- –∏ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–∏–≥–Ω–∞–ª–æ–≤. –°–∞–º–∞ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∏ –µ–µ –æ–±—É—á–µ–Ω–∏–µ —è–≤–ª—è—é—Ç—Å—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –º–æ–º–µ–Ω—Ç–æ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ–±–ª–µ–º—ã RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏, –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã —Å—Ä–∞–∑—É –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ —Å–µ—Ç—å –∏ –∑–∞—Ç–µ–º –≤—ã—á–∏—Å–ª–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç, –æ–¥–Ω–∞–∫–æ –≤–æ–∑–Ω–∏–∫–Ω—É—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:\n",
    "\n",
    " - –±–æ–ª—å—à–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ –ø–æ–º–µ—Å—Ç—è—Ç—Å—è –≤ –ø–∞–º—è—Ç–∏,\n",
    " - —Ç–∞–∫ –∫–∞–∫ —Ü–µ–ø–æ—á–∫–∞ –±—É–¥–µ—Ç –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–π, –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏–µ/–≤–∑—Ä—ã–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞,\n",
    " - –ø–æ –º–µ—Ä–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞ –ø–æ —Ü–µ–ø–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞—Ç–∏—Ä–∞–µ—Ç—Å—è.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–æ–ø—É—Å—Ç–∏–º, —É –Ω–∞—Å –µ—Å—Ç—å –¥–ª–∏–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å. –ï—Å–ª–∏ –º—ã —Å—Ä–∞–∑—É –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º, —Ç–æ –≤ –∫–∞–∂–¥—ã–π –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω—É–∂–Ω–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–∏—Ç—å Loss. –ò –≤—Å–µ —è—á–µ–π–∫–∏ –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –≤–æ –≤—Ä–µ–º—è backpropogation. –í—Å–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω—É–∂–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å. –í–æ–∑–Ω–∏–∫–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –Ω–µ—Ö–≤–∞—Ç–∫–æ–π –ø–∞–º—è—Ç–∏.\n",
    "\n",
    "–ï—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–∞–∫–æ–π –¥–ª–∏–Ω—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç RNN –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏. –ï—Å–ª–∏ –º—ã –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π —è—á–µ–π–∫–µ, –º–æ–∂–µ—Ç –æ–∫–∞–∑–∞—Ç—å—Å—è, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, —Å–∫–∞–∂–µ–º, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 10 —Å–ª–æ–≤–∞—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ Tanh –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –∑–∞—Ç–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/backprop_through_time.png\"><center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://cs231n.stanford.edu/slides/2021/lecture_10.pdf\">CS231n: Recurrent Neural Network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞—Ç—É—Ö–∞—é—â–∏–π/–≤–∑—Ä—ã–≤–∞—é—â–∏–π—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç (Vanishing/exploding gradient) ‚Äî —è–≤–ª–µ–Ω–∏—è –∑–∞—Ç—É—Ö–∞—é—â–µ–≥–æ –∏ –≤–∑—Ä—ã–≤–∞—é—â–µ–≥–æ—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ RNN. –ò –ø—Ä–∏ –±–æ–ª—å—à–æ–π –¥–ª–∏–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —ç—Ç–æ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∫—Ä–∏—Ç–∏—á–Ω—ã–º. –ü—Ä–∏—á–∏–Ω–∞ –≤ —Ç–æ–º, —á—Ç–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –≤–µ–ª–∏—á–∏–Ω—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ –æ—Ç —á–∏—Å–ª–∞ —Å–ª–æ—ë–≤ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è, –ø–æ—Å–∫–æ–ª—å–∫—É –≤–µ—Å–∞ —É–º–Ω–æ–∂–∞—é—Ç—Å—è –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ.\n",
    "\n",
    "$dL ‚àù (W)^N:$\n",
    "\n",
    "$W > 1 \\rightarrow$ –≤–∑—Ä—ã–≤, $W < 1 \\rightarrow$ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/simple_rnn_backprop.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–∏–Ω –∏–∑ –ø—É—Ç–µ–π —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã ‚Äî **–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–µ –æ—Ç—Å–µ—á–µ–Ω–∏–µ** (Gradient truncating) ‚Äî –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞, –ø–æ–∑–≤–æ–ª—è—è –∏–∑–±–µ–∂–∞—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –≤–∑—Ä—ã–≤–∞.\n",
    "\n",
    "–ê –æ—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å **–ø—Ä–æ–ø—É—Å–∫–∞–Ω–∏–µ** **–≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ –ø–æ —á–∞—Å—Ç—è–º**, –Ω–∞ —Å–∫–æ–ª—å–∫–æ-—Ç–æ —à–∞–≥–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞–∑–∞–¥ –∏–ª–∏ –≤–ø–µ—Ä—ë–¥, –∞ –Ω–µ —á–µ—Ä–µ–∑ –≤—Å—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å. –î–∞, –≥—Ä–∞–¥–∏–µ–Ω—Ç –±—É–¥–µ—Ç –Ω–µ —Å–æ–≤—Å–µ–º —Ç–æ—á–Ω–æ —Å—á–∏—Ç–∞—Ç—å—Å—è, –∏ –º—ã –±—É–¥–µ–º —Ç–µ—Ä—è—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ. –ù–æ —ç—Ç–æ —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/truncated_backprop.png\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://cs231n.stanford.edu/slides/2021/lecture_10.pdf\">CS231n: Recurrent Neural Network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—ã—á–Ω–∞—è RNN –∏–º–µ–ª–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º, –≤ —Ç–æ–º —á–∏—Å–ª–µ –≤ –Ω–µ–π –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ –∑–∞—Ç—É—Ö–∞–ª–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ü–æ–º–∏–º–æ —ç—Ç–æ–≥–æ –±—ã–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å –∑–∞—Ç—É—Ö–∞–Ω–∏–µ–º/–≤–∑—Ä—ã–≤–æ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞.\n",
    "\n",
    "–≠—Ç–∏ –ø—Ä–æ–±–ª–µ–º—ã –±—ã–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ —Ä–µ—à–µ–Ω—ã –≤ LSTM, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–æ–π –≤ [Long Short-Term Memory (Hochreiter & Schmidhuber, 1997) üéì[article]](http://www.bioinf.jku.at/publications/older/2604.pdf).\n",
    "\n",
    "–í –æ–±—ã—á–Ω–æ–π RNN-—è—á–µ–π–∫–µ –±—ã–ª —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—É—Ç—å –ø–µ—Ä–µ–¥–∞—á–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –º—ã –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä–æ–≤–∞–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å —Ç–µ–∫—É—â–∏–º –≤—Ö–æ–¥–æ–º –∏ –ø—Ä–æ–ø—É—Å–∫–∞–ª–∏ –∏—Ö —á–µ—Ä–µ–∑ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table, th, td {\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "}\n",
    "<font size=\"2\" face=\"Times New Romans\" >\n",
    "\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table >\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "<center><img src = \"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/simple_rnn_h_state.png\" width=\"500\"></center>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large h_t = \\tanh(W \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "\n",
    "</table>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ —ç—Ç–æ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ –∑–∞—Ç—É—Ö–∞–µ—Ç –∏ —Ç–µ—Ä—è–µ—Ç—Å—è –æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏.\n",
    "\n",
    "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —è—á–µ–π–∫–∏ LSTM –Ω–∞–º–Ω–æ–≥–æ —Å–ª–æ–∂–Ω–µ–µ. –ó–¥–µ—Å—å –µ—Å—Ç—å —Ü–µ–ª—ã—Ö 4 –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ—è, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–∞–∑–Ω—ã–µ –∑–∞–¥–∞—á–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table, th, td {\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "}\n",
    "<font size=\"2\" face=\"Times New Romans\" >\n",
    "\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/lstm_chain.png\" width=\"500\"></center>\n",
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/lstm_chain_notation.png\" width=\"700\"></center>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large f_t = œÉ(W_f \\cdot [h_{t-1}, x_t])\\ \\ \\ \\ $\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large \\text{forget  gate}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large i_t = œÉ(W_i \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large \\text{input gate}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large o_t = œÉ(W_o \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large \\text{output gate}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large c^\\prime_t = \\tanh(W_c \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large \\text{candidate cell state}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large c_t = f_t\\otimes c_{t-1} + i_t \\otimes c^\\prime_t$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large \\text{cell state}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large h_t = o_t\\otimes \\tanh(c_t)$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large  \\text{hidden state}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ì–ª–∞–≤–Ω–æ–µ –Ω–æ–≤–æ–≤–≤–µ–¥–µ–Ω–∏–µ: –≤ LSTM –¥–æ–±–∞–≤–ª–µ–Ω –ø—É—Ç—å $c$, –∫–æ—Ç–æ—Ä—ã–π –ø–æ –∑–∞–¥—É–º–∫–µ –¥–æ–ª–∂–µ–Ω —ç—Ç–æ—Ç –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/lstm_c_state_highway.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, –ø—É—Ç—å $c$ (cell state, –∏–Ω–æ–≥–¥–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è highway, –º–∞–≥–∏—Å—Ç—Ä–∞–ª—å)  –ø–æ–º–æ–≥–∞–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –≤—Å—Ç—Ä–µ—Ç–∏–≤—à—É—é—Å—è –≤ –∫–∞–∫–æ–π-—Ç–æ –º–æ–º–µ–Ω—Ç –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ—à–ª–æ–º, –≤—Å–µ –≤—Ä–µ–º—è, –ø–æ–∫–∞ —ç—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç—Ä–µ–±—É–µ—Ç—Å—è.\n",
    "\n",
    "–ü–æ —Ñ–æ—Ä–º—É–ª–∞–º —Ç–∞–∫–∂–µ –≤–∏–¥–Ω–æ, –∫–∞–∫ –≤–æ–∑—Ä–æ—Å–ª–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ç–ª–∏—á–∏–µ –æ—Ç RNN —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –∫—Ä–æ–º–µ $h$ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –µ—â–µ –∏ $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "lstm = nn.LSTM(input_size=3, hidden_size=2, batch_first=True)\n",
    "input = torch.randn(16, 57, 3)  # batch_size, seq_len, input_size\n",
    "out, (h, c) = lstm(input)  # h and c returned in tuple\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h\".ljust(15), h.shape)  # 1, batch_size, hidden_size\n",
    "print(\"Shape of c\".ljust(15), c.shape)  # 1, batch_size, hidden_size\n",
    "print(\"Output shape:\".ljust(15), out.shape)  # batch_size, seq_len, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∞–º–∞—è –∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è LSTM ‚Äî GRU. –û–Ω–∞ –±–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω–∞ –∑–∞ —Å—á–µ—Ç —Å–∏–ª—å–Ω—ã—Ö —É–ø—Ä–æ—â–µ–Ω–∏–π –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π LSTM.\n",
    "\n",
    "–ì–ª–∞–≤–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è: –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã forget –∏ input gates, —Å–ª–∏—Ç—ã $h_t$ –∏ $c_t$, –∫–æ—Ç–æ—Ä—ã–µ –≤ –æ–±—ã—á–Ω–æ–π LSTM —Ç–æ–ª—å–∫–æ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∏ –≤ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥—Ä—É–≥ –¥—Ä—É–≥–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table, th, td {\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "}\n",
    "<font size=\"2\" face=\"Times New Romans\" >\n",
    "\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/gru_basic_block.png\" width=\"500\"></center>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large \\tilde h_t = \\tanh(W \\cdot [r_t \\otimes h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large h_t = (1-z_t) \\otimes h_{t-1} + z_t \\otimes \\tilde h_t$\n",
    "\n",
    "</td>\n",
    "\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(input_size=3, hidden_size=2, batch_first=True)\n",
    "input = torch.randn(16, 57, 3)  # batch_size, seq_len, input_size\n",
    "out, h = gru(input)\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h:\".ljust(15), h.shape)  # 1, batch_size, hidden_size\n",
    "print(\"Output shape:\".ljust(15), out.shape)  # batch_size, seq_len, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–π: –∏–Ω–æ–≥–¥–∞ –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç GRU, –∏–Ω–æ–≥–¥–∞ ‚Äî LSTM. –¢–æ—á–Ω—ã–π —Ä–µ—Ü–µ–ø—Ç —É—Å–ø–µ—Ö–∞ —Å–∫–∞–∑–∞—Ç—å –Ω–µ–ª—å–∑—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î—Ä—É–≥–∏–º —Ç–∏–ø–æ–º –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ —Å–≤–æ–µ–π –ø—Ä–∏—Ä–æ–¥–µ —è–≤–ª—è—é—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏, —è–≤–ª—è—é—Ç—Å—è **—Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ**. –¢–µ–∫—Å—Ç—ã —è–≤–ª—è—é—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏ —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –º–µ–∂–¥—É —Å–æ–±–æ–π –≤ —Å–ª–æ–∂–Ω—ã—Ö –≤–∑–∞–∏–º–æ—Å–≤—è–∑—è—Ö: —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö, —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏—Ö, –æ—Ä—Ñ–æ—Ä–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ.\n",
    "\n",
    "–° –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ —Ä–µ—à–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á: –∞–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—à–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞, –º–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥, —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π (—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è), —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º (—á–∞—Ç-–±–æ—Ç–æ–≤), –∏ –º–Ω–æ–≥–æ–µ-–º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ.\n",
    "\n",
    "–î–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —ç—Ç–∏—Ö –∑–∞–¥–∞—á –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω—è—Ç—å —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –û–±–ª–∞—Å—Ç—å, —Å–≤—è–∑–∞–Ω–Ω–∞—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ, –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è NLP ‚Äî Natural language processing. C —á–∞—Å—Ç—å—é –ø–æ–¥—Ö–æ–¥–æ–≤ NLP –º—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏–º—Å—è –Ω–∞ –ª–µ–∫—Ü–∏—è—Ö –∏ —Å–µ–º–∏–Ω–∞—Ä–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/nlp_tasks.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º —Ä—è–¥–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –±—ã–ª–∞ —Ç–æ–ª—å–∫–æ —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ. –ù–æ –≤ —Ç–µ–∫—Å—Ç–∞—Ö –Ω–∞—á–∞–ª–æ –∏–ª–∏ –æ–∫–æ–Ω—á–∞–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–æ–≥—É—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–º–µ–Ω–∏—Ç—å –µ–≥–æ —Å–º—ã—Å–ª. –¢–∞–∫, –≤ –∑–∞–¥–∞—á–∞—Ö –æ—Ü–µ–Ω–∫–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏, –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ –æ—à–∏–±–∏—Ç—å—Å—è, –µ—Å–ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –≤ –æ–¥–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏, –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –∑–∞–±—ã–≤–∞—è –Ω–∞—á–∞–ª–æ.\n",
    "\n",
    "–î–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —è–≤–ª—è–µ—Ç—Å—è –≤–∞–∂–Ω–µ–π—à–µ–π –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å—é, –∫–æ—Ç–æ—Ä—É—é –º—ã –±—É–¥–µ–º —É—á–∏—Ç—ã–≤–∞—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/movie_sentiment.png\" width=\"650\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —á–µ—Ä–µ–∑ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—É—é —Å–µ—Ç—å –¥–≤–∞ —Ä–∞–∑–∞: –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ —Å–ª–æ–≤ –≤ –ø—Ä—è–º–æ–º –∏ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏. –î–ª—è —ç—Ç–æ–≥–æ —Å–æ–∑–¥–∞—ë—Ç—Å—è –µ—â–µ –æ–¥–∏–Ω —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å–ª–æ–π, –∫–æ—Ç–æ—Ä—ã–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏, –∞ —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–≤—É—Ö —Å–ª–æ—ë–≤ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ—Ç—Å—è.\n",
    "\n",
    "[[blog] ‚úèÔ∏è Recurrent Neural Networks with PyTorch](https://www.kaggle.com/code/kanncaa1/recurrent-neural-network-with-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/bidirectional.png\" width=\"650\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é —Ç–∞–∫–æ–π –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–ª–æ—è—Ö –æ—Ç–≤–µ—á–∞–µ—Ç —Ñ–ª–∞–≥ `bidirectional=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn((16, 57, 3))  # batch_size, seq_len, input_size\n",
    "rnn = torch.nn.RNN(3, 2, bidirectional=True, batch_first=True)\n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "# Concatenated Hidden states from both layers\n",
    "print(\"Out:\\n\", out.shape)\n",
    "# Hidden states last element from  both : 2*num_layers*hidden_state\n",
    "print(\"h:\\n\", h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –∏ –≤ –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á–∞—Ö, –ø–µ—Ä–≤—ã–º —ç—Ç–∞–ø–æ–º –∏–¥—ë—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö. –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –≤–≤–æ–¥–∞ –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±—É–¥–µ—Ç –æ–±–ª–∞–¥–∞—Ç—å —Å–≤–æ–∏–º–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏. –¢–∞–∫, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –æ—à–∏–±–∫–∞–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏ —Ä–∞–∑–º–µ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü; —Ç–µ–∫—Å—Ç –∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π ‚Äî –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π, —Å–º–∞–π–ª–æ–≤, —Ö—ç—à—Ç–µ–≥–æ–≤, —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏ –ø—Ä."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫—É—é –±—ã –º—ã –∑–∞–¥–∞—á—É –Ω–∏ —Ä–µ—à–∞–ª–∏, –≤ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –Ω—É–∂–Ω–æ –ø–æ–¥–∞–≤–∞—Ç—å —á–∏—Å–ª–∞. –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –º—ã –º–æ–∂–µ–º –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/bag_of_words_representation.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF** ‚Äî —Å–ø–æ—Å–æ–± —á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞, –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç  **–≤–∞–∂–Ω–æ—Å—Ç—å —Å–ª–æ–≤–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞**. –°–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö –º–Ω–æ–∂–∏—Ç–µ–ª–µ–π: **TF** –∏ **IDF**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/tf_idf.png\" width=\"500\"></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–≤–∞—è –∏–¥–µ—è **TF-IDF** ‚Äî **–µ—Å–ª–∏ —Å–ª–æ–≤–æ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ, –æ–Ω–æ –≤–∞–∂–Ω–æ–µ**. –ó–∞ —ç—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç TF.\n",
    "\n",
    "**TF (term frequency)** ‚Äî —á–∞—Å—Ç–æ—Ç–∞ –≤—Ö–æ–∂–¥–µ–Ω–∏—è —Å–ª–æ–≤–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ:\n",
    "\n",
    "$$\\large \\text{TF}(t, d) = \\frac{n_t}{\\sum_{k}n_k},$$\n",
    "\n",
    "–≥–¥–µ $n_t$ ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ —Å–ª–æ–≤–∞ $t$ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ $d$,\n",
    "\n",
    "$\\sum_{k}n_k$ ‚Äî –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤  $t$ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ $d$ —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Ç–æ—Ä–∞—è –∏–¥–µ—è **TF-IDF** ‚Äî **–µ—Å–ª–∏ —Å–ª–æ–≤–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤–æ –º–Ω–æ–≥–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, –µ–≥–æ —Ü–µ–Ω–Ω–æ—Å—Ç—å —Å–Ω–∏–∂–∞–µ—Ç—Å—è**.\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä: –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Ç–µ–∫—Å—Ç–æ–≤, –Ω–æ –Ω–µ –Ω–µ—Å—É—Ç —Å–º—ã—Å–ª–æ–≤–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏. –ó–∞ —ç—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç IDF.\n",
    "\n",
    "**IDF (inverse document frequency)** ‚Äî –ª–æ–≥–∞—Ä–∏—Ñ–º –æ–±—Ä–∞—Ç–Ω–æ–π —á–∞—Å—Ç–æ—Ç—ã –≤—Ö–æ–∂–¥–µ–Ω–∏—è —Å–ª–æ–≤–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç—ã:\n",
    "\n",
    "$$\\large \\text{IDF}(t, D) = \\log{\\frac{|D|}{|\\{d_i \\in D| t \\in d_i \\}|}},$$\n",
    "\n",
    "–≥–¥–µ $|D|$ ‚Äî —á–∏—Å–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏,\n",
    "$|\\{d_i \\in D| t \\in d_i \\}|$ ‚Äî —á–∏—Å–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Å–æ —Å–ª–æ–≤–æ–º $t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Ç–æ–≥–æ–≤–∞—è —Ñ–æ—Ä–º—É–ª–∞:\n",
    "$$\\large \\text{TF-IDF}(t, d, D) = \\text{TF}(t,d)‚ãÖ\\text{IDF}(t, D)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã `TfidfVectorizer` [üõ†Ô∏è[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) –∏–∑ Sklearn.\n",
    "–ö–∞–∂–¥–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤–µ–∫—Ç–æ—Ä, —Ä–∞–≤–Ω—ã–π –¥–ª–∏–Ω–µ —Å–ª–æ–≤–∞—Ä—è. –ù–µ–Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –≤–∏–¥–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü `scipy.sparse.csr_matrix` [üõ†Ô∏è[doc]](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"Tf-idf dictionary:\", vectorizer.get_feature_names_out())\n",
    "print(\"Tf-idf dictionary len:\", len(vectorizer.get_feature_names_out()))\n",
    "print(\"Tf-idf shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ:**\n",
    "\n",
    "1. –¢–µ–∫—Å—Ç—ã —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É—é—Ç—Å—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—Ç—Å—è. –ï—Å–ª–∏ –º—ã —Ä–µ—à–∞–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å N-–≥—Ä–∞–º–º–∞–º–∏, —Ç–æ –≤–º–µ—Å—Ç–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –ø–æ—Å–ª–µ –Ω–µ—ë –≤—ã–¥–µ–ª—è–µ–º N-–≥—Ä–∞–º–º—ã.\n",
    "\n",
    "2. –ü—Ä–æ—Ö–æ–¥–∏–º—Å—è –ø–æ –≤—Å–µ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º, –≤ –∫–∞–∫–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ–Ω–æ –≤—Å—Ç—Ä–µ—Ç–∏–ª–æ—Å—å. –ï—Å–ª–∏ —É –Ω–∞—Å –±–æ–ª—å—à–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è, —Ç–æ —Å–ª–æ–≤–∞—Ä—å –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å—Å—è –ø—Ä–æ—Å—Ç–æ –≥–∏–≥–∞–Ω—Ç—Å–∫–∏–º, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –º—ã —Ä–∞–±–æ—Ç–∞–µ–º —Å N-–≥—Ä–∞–º–º–∞–º–∏, –ø–æ—ç—Ç–æ–º—É –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏, –≤–æ –≤—Ä–µ–º—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–ª–∏ –ø–æ—Å–ª–µ —ç—Ç–æ–π –ø—Ä–æ—Ü–µ–¥—É—Ä—ã, –º—ã –¥–æ–ª–∂–Ω—ã –≤—ã–±—Ä–æ—Å–∏—Ç—å –∏–∑ —Å–ª–æ–≤–∞—Ä—è –≤—Å—ë, —á—Ç–æ —Å—á–∏—Ç–∞–µ–º –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º ‚Äî —Å–ª–∏—à–∫–æ–º —Ä–µ–¥–∫–∏–µ –∏ —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞.\n",
    "\n",
    "3. –ó–∞—Ç–µ–º –Ω–∞—á–∏–Ω–∞–µ–º —Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –ö–∞–∂–¥–∞—è —Å—Ç—Ä–æ—á–∫–∞ —ç—Ç–æ–π –º–∞—Ç—Ä–∏—Ü—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—É, –∞ –∫–∞–∂–¥—ã–π —Å—Ç–æ–ª–±–µ—Ü ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ —ç—Ç–æ–≥–æ —Å–ª–æ–≤–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –º—ã —Å—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –≤ –Ω—ë–º –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —è—á–µ–π–∫–∏ —Ç–∞–±–ª–∏—Ü—ã –≤–µ—Å–∞ —Å–ª–æ–≤ –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ñ–æ—Ä–º—É–ª–µ.\n",
    "\n",
    "4. –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, TF-IDF ‚Äî —ç—Ç–æ —Å–ø–æ—Å–æ–± –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è –∏ –æ—Ç–±–æ—Ä–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –∑–∞–¥–∞—á–∞—Ö –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –Ω–µ —Ç–æ–ª—å–∫–æ –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –Ω–µ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤. –ù–∞–¥–æ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ TF-IDF –Ω–∏–∫–∞–∫ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ—Ç–∫–µ –æ–±—ä–µ–∫—Ç–∞ ‚Äî —ç—Ç–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ, –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫. –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TF-IDF, –Ω–µ –∏–º–µ—è –º–µ—Ç–æ–∫, —Ç–æ –µ—Å—Ç—å –≤ –∑–∞–¥–∞—á–∞—Ö –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ —É—á–∏—Ç–µ–ª—è. –ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ ‚Äî –≤ —Ç–æ–º, —á—Ç–æ –º—ã —Ç–µ—Ä—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –µ—ë –∏—Å–ø–æ–ª—å–∑—É–µ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–æ–≥–¥–∞ TF-IDF –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω:**\n",
    "\n",
    "1. **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏**: TF-IDF –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏, —á—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å–º—ã—Å–ª–∞ —Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "2. **–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –¥–ª–∏–Ω–µ** –¥–æ–∫—É–º–µ–Ω—Ç–∞: –¥–ª–∏–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –º–æ–≥—É—Ç –∏–º–µ—Ç—å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è TF, –¥–∞–∂–µ –µ—Å–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ä–µ–∂–µ. –í —Ç–∞–∫–∏—Ö —Å–ª—É—á–∞—è—Ö TF-IDF –º–æ–∂–µ—Ç –Ω–µ–¥–æ–æ—Ü–µ–Ω–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–ª–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/w2v_example.png\" width=\"350\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/585838/\">–°–µ–º–∞–Ω—Ç–∏–∫–∞ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è Word2Vec</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec (w2v) ‚Äî —Å–ø–æ—Å–æ–± –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤ –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.\n",
    "\n",
    "**–í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤ –Ω–∞–∑–≤–∞—é—Ç—Å—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏.**\n",
    "\n",
    "Word2Vec —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è –ø—Ä–∏ –ø–æ–º–æ—â–∏ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –∏–∑ –¥–≤—É—Ö —Å–ª–æ–µ–≤, –∫–æ—Ç–æ—Ä–∞—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è –µ–≥–æ –≤ —á–∏—Å–ª–æ–≤—ã–µ ‚Äú–≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ‚Äù —Å–ª–æ–≤–∞. –û—Å–Ω–æ–≤–Ω–æ–π –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å—é w2v —Å—Ç–∞–ª–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: –Ω–µ–π—Ä–æ—Å–µ—Ç—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –∫–∞–∫–∏–µ —Å–ª–æ–≤–∞ –Ω–∞—Ö–æ–¥—è—Ç—Å—è —Ä—è–¥–æ–º –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –æ–∫–Ω–µ.\n",
    "\n",
    "–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ w2v ‚Äî —ç—Ç–æ –≥—Ä–æ–º–∞–¥–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ—Ä–ø—É—Å, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞ –≤—ã—Ö–æ–¥–µ –º—ã –ø–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–±—ã—á–Ω–æ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç —Å–æ—Ç–µ–Ω, –≥–¥–µ –∫–∞–∂–¥–æ–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ –≤ –∫–æ—Ä–ø—É—Å–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ –≤–µ–∫—Ç–æ—Ä–æ–º –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å—Ç—å –¥–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å–ø–æ—Å–æ–±–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ Word2Vec: **Skip-Gram** –∏ **CBOW**.\n",
    "\n",
    "* **–°–ª–µ–≤–∞** —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –º–µ—Ç–æ–¥ **Skip-Gram**, –≤ –∫–æ—Ç–æ—Ä–æ–º –º—ã –ø–µ—Ä–µ–¥–∞–µ–º –∫–∞–∫–æ–µ-—Ç–æ —Å–ª–æ–≤–æ –Ω–∞—à–µ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –∏ –ø—Ä–æ—Å–∏–º –µ–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç. $w[i]$ ‚Äî —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –Ω–∞ –≤—Ö–æ–¥ –∏ –∫–æ—Ç–æ—Ä–æ–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ $i$ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏. –ù–∞ –≤—ã—Ö–æ–¥–µ –∏–º–µ–µ–º –¥–≤–∞ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–ª–æ–≤–∞ –∏ –¥–≤–∞ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Å–ª–æ–≤–∞ —Å —É—á–µ—Ç–æ–º –ø–æ–∑–∏—Ü–∏–∏ $i$.\n",
    "\n",
    "* **–°–ø—Ä–∞–≤–∞ ‚Äî CBOW** (Continuous Bag of Words). –ó–¥–µ—Å—å, –≤–º–µ—Å—Ç–æ —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø—Ä–µ–¥—É–≥–∞–¥—ã–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Å–ª–æ–≤–∞, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –≤ –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ—Å–∏–º –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–ª–æ–≤–æ.\n",
    "\n",
    "–§–æ–∫—É—Å —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –Ω–∏–∫–∞–∫–æ–π –æ–±—É—á–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —É –Ω–∞—Å –Ω–µ—Ç. –ó–¥–µ—Å—å –¥—Ä—É–≥–∞—è —Ü–µ–ª—å ‚Äî –∏–∑—É—á–∏—Ç—å –≤–µ—Å–∞ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è –ø–æ –º–µ—Ä–µ —Ç–æ–≥–æ, –∫–∞–∫ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—Ç—Å—è —Å–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –æ–∫—Ä—É–∂–∞—é—â–∏—Ö —Å–ª–æ–≤. –≠—Ç–∏ –≤–µ—Å–∞ –∏ –µ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/skip_gram.jpeg\" width=\"400\"></center>\n",
    "    \n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/cbow.jpeg\" width=\"400\"></center>\n",
    "\n",
    "</td>  \n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/778048/\">Skip-Gram</a></em></center>\n",
    "    \n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/778048/\">CBOW</a></em></center>\n",
    "\n",
    "\n",
    "</td>  \n",
    "\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–î–∞–Ω–Ω—ã–µ**\n",
    "\n",
    "–ò—Å—Ö–æ–¥–Ω—ã–µ, \"—Å—ã—Ä—ã–µ\" –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ\n",
    "\n",
    "**The quick brown fox jumps over the lazy dog**.\n",
    "\n",
    "–û—Å—Ç–∞–≤–ª—è—è –∑–∞ —Å–∫–æ–±–∫–∞–º–∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –∫–∞–Ω–æ–Ω–∏—á–Ω—ã–º —Ñ–æ—Ä–º–∞–º, —Å–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç —Ç–∞–∫:\n",
    "1. –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Ç–µ–∫—Å—Ç—É –æ–∫–Ω–æ–º –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (–≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ 2 –æ–∑–Ω–∞—á–∞–µ—Ç 2 —Å–ª–æ–≤–∞ —Å–ª–µ–≤–∞ –∏ –¥–≤–∞ —Å–ª–æ–≤–∞ —Å–ø—Ä–∞–≤–∞ –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ).\n",
    "2. –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø–∞—Ä—ã \"—Ç–µ–∫—É—â–µ–µ —Å–ª–æ–≤–æ-—Å–æ—Å–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ\" (–±–∏–≥—Ä–∞–º–º—ã).\n",
    "3. –°–º–µ—â–∞–µ–º –æ–∫–Ω–æ –≤–ø—Ä–∞–≤–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/vectorization_example.jpeg\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/778048/\">–ö—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä —Ç–µ—Ö–Ω–∏–∫ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –≤ NLP</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —É—á–∏—Ç—Å—è —Å–µ—Ç—å –¥–ª—è –≤–∞—Ä–∏–∞–Ω—Ç–∞ Skip-Gram. –ù–∞ –≤—Ö–æ–¥ —Å–µ—Ç–∏ –ø—Ä–∏—Ö–æ–¥–∏—Ç One-Hot –≤–µ–∫—Ç–æ—Ä –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ–≤–∞ –∏–∑ –±–∏–≥—Ä–∞–º–º—ã, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞–µ—Ç—Å—è –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ —Å–∫—Ä—ã—Ç–æ–º —Å–ª–æ–µ –∏ –ø–æ—Å—Ç—É–ø–∞–µ—Ç –Ω–∞ —Å–ª–æ–π SoftMax (—Ä–∞–∑–º–µ—Ä–æ–º —Å –≤–µ—Å—å —Å–ª–æ–≤–∞—Ä—å, —Ç.–µ. —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ —Ä–∞–≤–µ–Ω —Ä–∞–∑–º–µ—Ä—É –≤—ã—Ö–æ–¥–∞).\n",
    "\n",
    "–ü–æ —Ñ–∞–∫—Ç—É –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–æ–ª–∂–Ω–∞ –≤—ã—É—á–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Å–ª–æ–≤–∞ *quick* –ø—Ä–∏ –ø—Ä–∏—Ö–æ–¥–µ –Ω–∞ –≤—Ö–æ–¥ —Å–ª–æ–≤–∞ *fox*. –ü—Ä–∏ —ç—Ç–æ–º –º–æ–∂–Ω–æ –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ —Å–ª–æ–≤—É *fox* —Ç–∞–∫–∂–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å–ª–æ–≤–∞ *brown, jumps, over*. –û–±—É—á–∞—è—Å—å –ø–æ –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏–∏, –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –¥–æ–ª–∂–µ–Ω –≤—ã–¥–∞–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö —ç—Ç–∏—Ö —Å–ª–æ–≤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/skip_gram_example.jpeg\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/778048/\">–ö—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä —Ç–µ—Ö–Ω–∏–∫ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –≤ NLP</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å–µ—Ç—å –≤—ã—É—á–∏–≤–∞–µ—Ç —Ç–∞–∫–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, —á—Ç–æ –≤–µ–∫—Ç–æ—Ä–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ—Ö–æ–∂–∏–º —Å–ª–æ–≤–∞–º, —Ä–∞—Å–ø–æ–ª–∞–≥–∞—é—Ç—Å—è –±–ª–∏–∑–∫–æ –≤ –Ω–æ–≤–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ, –∏ –Ω–∞–¥ –Ω–∏–º–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/w2v_example_2.png\" width=\"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/446530/\">Word2vec –≤ –∫–∞—Ä—Ç–∏–Ω–∫–∞—Ö</a></em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑—É–º–µ–µ—Ç—Å—è, —ç—Ç–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–µ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ —Ç–æ—á–Ω–æ–º—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—é, –æ–¥–Ω–∞–∫–æ –ø–æ–ª—É—á–∞–µ–º—ã–µ –≤–µ–∫—Ç–æ—Ä–∞ –æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è —Å–∞–º—ã–º–∏ –ø–æ—Ö–æ–∂–∏–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ CBOW –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è. –ù–∞ –≤—Ö–æ–¥ —Å–µ—Ç–∏ –ø–æ–¥–∞—ë—Ç—Å—è $C$ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å–ª–æ–≤ –≤ –≤–∏–¥–µ One-Hot, –ø–æ—Å–ª–µ –ø–µ—Ä–µ–º–Ω–æ–∂–µ–Ω–∏—è —Å –ª–∏–Ω–µ–π–Ω—ã–º —Å–ª–æ–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É—Å—Ä–µ–¥–Ω—è–µ—Ç—Å—è. –ù–∞ –≤—ã—Ö–æ–¥–µ —Å–ª–æ–π SoftMax —Ç–∞–∫–æ–≥–æ –∂–µ —Ä–∞–∑–º–µ—Ä–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[colab] ü•® –ü–æ–¥—Ä–æ–±–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é Word2Vec](https://colab.research.google.com/drive/1OJF0k-E60sp9Vyoj1yWuoedGTrwRiTyj?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–ª–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–Ω–µ–µ –º—ã –ø—Ä–∏–º–µ–Ω—è–ª–∏ OneHotEncoding –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –Ω–∞—à–∏—Ö —Å–ª–æ–≤. –ü—Ä–æ–±–ª–µ–º—ã –≤–æ–∑–Ω–∏–∫–∞—é—Ç, –∫–æ–≥–¥–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞—á–∏–Ω–∞–µ—Ç —Ä–∞—Å—Ç–∏ –∏ —É –Ω–∞—Å –≤–æ–∑–Ω–∏–∫–∞—é—Ç –æ–≥—Ä–æ–º–Ω—ã–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã.\n",
    "\n",
    "–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–±—ä–µ–∫—Ç—ã —É –Ω–∞—Å —Å—Ä–∞–∑—É –º–æ–≥—É—Ç –±—ã—Ç—å –±–ª–∏–∂–µ: —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ \"–∫–æ—Ä–æ–ª—å\" –∏ \"–∫–æ—Ä–æ–ª–µ–≤–∞\" –æ—Ç–ª–∏—á–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ–ª–æ–º, —Ä–∞–∑–ª–∏—á–∏–µ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ \"–∫–æ—Ä–æ–ª—å\" –∏ \"—Å—Ç—É–ª\" –∑–∞–º–µ—Ç–Ω–æ –≤—ã—à–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—ç—Ç–æ–º—É –º—ã –º–æ–∂–µ–º –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –Ω–∞—à–∏ —Å–ª–æ–≤–∞ –≤ –≤–µ–∫—Ç–æ—Ä–∞ –º–µ–Ω—å—à–µ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏ —ç—Ç–æ–º –±—É–¥—É—Ç —Å—Ä–∞–≤–Ω–∏–º—ã –º–µ–∂–¥—É —Å–æ–±–æ–π —Å –ø–æ–º–æ—â—å—é –º–æ–¥—É–ª—è `nn.Embedding` [üõ†Ô∏è[doc]](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html).\n",
    "\n",
    "[[doc] üõ†Ô∏è –¢—É—Ç–æ—Ä–∏–∞–ª PyTorch –ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –≤ NLP](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)\n",
    "\n",
    "[[blog] ‚úèÔ∏è Lena Voita NLP Course](https://lena-voita.github.io/nlp_course.html)\n",
    "\n",
    "[[git] üêæ –ö—É—Ä—Å –ø–æ NLP –æ—Ç –®–ê–î](https://github.com/yandexdataschool/nlp_course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/word_representation_intro_min.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/lookup_table.gif\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://lena-voita.github.io/nlp_course/word_embeddings.html\">Lena Voita NLP Course</a></em></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say you have 2 sentences (lowercased, punctuations removed):\n",
    "sentences = \"i am new to pytorch i am having fun\"\n",
    "\n",
    "words = sentences.split(\" \")\n",
    "\n",
    "print(f\"All words: {words} \\n\")\n",
    "\n",
    "vocab = set(words)  # create a vocabulary\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"Vocabulary (unique words): {vocab} \\n\")\n",
    "print(f\"Vocabulary size: {vocab_size} \\n\")\n",
    "\n",
    "# map words to unique indices\n",
    "word2idx = {word: ind for ind, word in enumerate(vocab)}\n",
    "\n",
    "print(f\"Word-to-id dictionary: {word2idx} \\n\")\n",
    "\n",
    "encoded_sentences = [word2idx[word] for word in words]\n",
    "\n",
    "print(f\"Encoded sentences: {encoded_sentences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π —Å–ª–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø—Ä–µ–¥–µ–ª—ë–Ω —Ç–∞–∫:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# let's say you want embedding dimension to be 3\n",
    "emb_dim = 3\n",
    "\n",
    "emb_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "word_vectors = emb_layer(torch.LongTensor(encoded_sentences))\n",
    "\n",
    "print(f\"Shape of encoded sentences: {word_vectors.shape} \\n\")\n",
    "print(f\"Shape of weigths: {emb_layer.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–æ—Ç –∫–æ–¥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é (—Å–æ —Å—Ä–µ–¥–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º 0 –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π 1). –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –ø–æ–∫–∞ —á—Ç–æ –Ω–∏–∫–∞–∫–æ–≥–æ —Ä–∞–∑–ª–∏—á–∏—è –∏–ª–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –Ω–µ—Ç.\n",
    "\n",
    "`word_vectors` ‚Äî —Ç–µ–Ω–∑–æ—Ä —Ä–∞–∑–º–µ—Ä–æ–º (9, 3). 9 —Å–ª–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ, —Ä–∞–∑–º–µ—Ä 3 –∑–∞–¥–∞–Ω –Ω–∞–º–∏.\n",
    "\n",
    "`emb_layer` –∏–º–µ–µ—Ç 1 –æ–±—É—á–∞–µ–º—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä `weight`, –∫–æ—Ç–æ—Ä—ã–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True. –ú–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–∞–∫:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ –º—ã –Ω–µ —Ö–æ—Ç–∏–º –æ–±—É—á–∞—Ç—å —ç—Ç–æ–π —Å–ª–æ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞—Ä–∞–Ω–µ–µ –æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏), –º—ã –º–æ–∂–µ–º –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å –µ–≥–æ –≤–µ—Å–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ –º—ã —Ö–æ—Ç–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞—Ä–∞–Ω–µ–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ –≤–µ—Å–∞, –º—ã –º–æ–∂–µ–º –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π [Gensim üõ†Ô∏è[doc]](https://radimrehurek.com/gensim/auto_examples/index.html#documentation). –í–æ–∑—å–º—ë–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å –¥–ª–∏–Ω–æ–π 25.\n",
    "\n",
    "–ï—Å–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, –º—ã —É–≤–∏–¥–∏–º, —á—Ç–æ —ç—Ç–æ –ª–∏—à—å –æ–¥–∏–Ω –∏–∑ [–≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –≤–µ—Å–æ–≤ üêæ[git]](https://github.com/piskvorky/gensim-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Download the model and return as object ready for use\n",
    "glove = api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£ –º–æ–¥—É–ª—è `nn.Embedding` –µ—Å—Ç—å –º–µ—Ç–æ–¥ `from_pretrained`, –≤ –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. –ü—Ä–∏ —ç—Ç–æ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–Ω–∏ –Ω–µ –±—É–¥—É—Ç –æ–±—É—á–∞—Ç—å—Å—è ‚Äî –∑–∞ —ç—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç —Ñ–ª–∞–≥ `freeze`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"glove.vectors.shape is {glove.vectors.shape}\")\n",
    "\n",
    "weights = torch.FloatTensor(glove.vectors)\n",
    "glove_emb = nn.Embedding.from_pretrained(weights, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.LongTensor(encoded_sentences)\n",
    "glove_emb(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–æ–¥ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —Å–æ —Å–ª–æ–µ–º `nn.Embedding` –≤—ã–≥–ª—è–¥–∏—Ç —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_with_Embedding_Layer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(weights)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Look up the embedding\n",
    "        x = self.emb(x)\n",
    "        # Forward propagate the RNN\n",
    "        out, _ = self.rnn(x)\n",
    "        # Pass the output of the last time step to the classifier\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "model = RNN_with_Embedding_Layer(input_size=25, hidden_size=128, num_classes=3)\n",
    "\n",
    "input = input.unsqueeze(0)\n",
    "print(model(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–∏–Ω –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —ç—Ç–∞–ø–æ–≤ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞ ‚Äî **—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è**. –ù–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã ‚Äî –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ —Å–ª–æ–≤–∞. –ó–∞—Ç–µ–º —Å–æ–∑–¥–∞–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä—å, –≤ –∫–æ—Ç–æ—Ä—ã–π –∑–∞–Ω–æ—Å—è—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ª–µ–∫—Å–µ–º—ã, –≤—Å—Ç—Ä–µ—Ç–∏–≤—à–∏–µ—Å—è –≤ –∫–æ—Ä–ø—É—Å–µ –∏–ª–∏ —Ç–µ–∫—Å—Ç–µ. –ù–∞ —ç—Ç–∏—Ö —ç—Ç–∞–ø–∞—Ö –º–æ–∂–Ω–æ —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º–∞ 1. –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è**\n",
    "\n",
    "–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ ‚Äî –Ω–∞–∑–Ω–∞—á–∏—Ç—å –∫–∞–∂–¥–æ–º—É —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É —Å–ª–æ–≤—É —Å–≤–æ—ë —á–∏—Å–ª–æ. –ù–æ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º–∞: —Å–ª–æ–≤ –∏ –∏—Ö —Ñ–æ—Ä–º –º–∏–ª–ª–∏–æ–Ω—ã, –∏ –ø–æ—ç—Ç–æ–º—É —Å–ª–æ–≤–∞—Ä—å —Ç–∞–∫–∏—Ö —Å–ª–æ–≤ –ø–æ–ª—É—á–∏—Ç—Å—è —á–µ—Ä–µ—Å—á—É—Ä –±–æ–ª—å—à–∏–º, –∞ —ç—Ç–æ –±—É–¥–µ—Ç –∑–∞—Ç—Ä—É–¥–Ω—è—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–ú–æ–∂–Ω–æ —Ä–∞–∑–±–∏–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞ —Å–ª–æ–≤–∞, –∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –±—É–∫–≤—ã (char-level tokenization), —Ç–æ–≥–¥–∞ –≤ —Å–ª–æ–≤–∞—Ä–µ –±—É–¥–µ—Ç –≤—Å–µ–≥–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–µ—Å—è—Ç–∫–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤, –ù–û –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ —É–∂–µ —Å–∞–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –±—É–¥–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º, –∞ —ç—Ç–æ —Ç–æ–∂–µ –∑–∞—Ç—Ä—É–¥–Ω—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º–∞ 2. –ë–æ–≥–∞—Ç–∞—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è**\n",
    "\n",
    "\"–ù–µ–π—Ä–æ—Å–µ—Ç—å\", \"—Å–µ—Ç–∫–∞\", \"—Å–µ—Ç—å\" —è–≤–ª—è—é—Ç—Å—è —Ä–∞–∑–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –Ω–æ –∏–º–µ—é—Ç —Å—Ö–æ–∂–∏–π —Å–º—ã—Å–ª. –≠—Ç—É –ø—Ä–æ–±–ª–µ–º—É –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏ –≤—Å–µ–≥–¥–∞ —Ä–µ—à–∞–ª —ç—Ç–∞–ø **—Å—Ç–µ–º–º–∏–Ω–≥–∞** (—É–¥–∞–ª–µ–Ω–∏–µ —Å—É—Ñ—Ñ–∏–∫—Å–∞, –ø—Ä–∏—Å—Ç–∞–≤–∫–∏, –æ–∫–æ–Ω—á–∞–Ω–∏—è) –∏–ª–∏ **–ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏** (–ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å–ª–æ–≤–∞ –∫ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–π —Ñ–æ—Ä–º–µ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º–∞ 3. –°–ª–æ–∂–Ω—ã–µ —Å–ª–æ–≤–∞**\n",
    "\n",
    "–ù–æ –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã —ç—Ç–∏ —ç—Ç–∞–ø—ã –Ω–µ —Ä–µ—à–∞—é—Ç. –í –≥–µ—Ä–º–∞–Ω—Å–∫–∏—Ö —è–∑—ã–∫–∞—Ö (–≤ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –Ω–µ–º–µ—Ü–∫–æ–º, —à–≤–µ–¥—Å–∫–æ–º –∏ —Ç.–¥.) –æ—á–µ–Ω—å –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ –æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—é—Ç—Å—è –Ω–æ–≤—ã–µ —Å–ª–æ–∂–Ω—ã–µ —Å–ª–æ–≤–∞. –ó–Ω–∞—á–µ–Ω–∏—è —Ç–∞–∫–∏—Ö —Å–ª–æ–≤ –≤—ã–≤–æ–¥—è—Ç—Å—è –∏–∑ –∑–Ω–∞—á–µ–Ω–∏—è –∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –ò—Ö –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ –¥–æ–ª–≥–æ, –∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∏–∑ –Ω–∏—Ö –Ω–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –≤ ¬´–±—É–º–∞–∂–Ω–æ–º¬ª —Å–ª–æ–≤–∞—Ä–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/swedish_word_example.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ü—Ä–∏–º–µ—Ä —à–≤–µ–¥—Å–∫–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –≥–∞–µ—á–Ω–æ–≥–æ –∫–ª—é—á–∞ –¥–ª—è –∫–æ–ª–µ—Å–∞ –º–æ—Ç–æ—Ü–∏–∫–ª–∞</a></em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://sysblok.ru/nlp/7250/\">–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —ç—Ç–∏–º–∏ —è–∑—ã–∫–∞–º–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–∞–∫–∂–µ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –Ω–∞ —ç—Ç–∞–ø–µ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è. –ü—Ä–∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ —Å–ª–æ–≤–∞—Ä—è –º–æ–¥–µ–ª–∏ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—É—é—Ç—Å—è –Ω–∞ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–æ, –µ—Å–ª–∏ –æ–Ω–æ –≤—Å—Ç—Ä–µ—Ç–∏–ª–æ—Å—å —á–∞—â–µ –ø—è—Ç–∏ —Ä–∞–∑), –ø–æ—ç—Ç–æ–º—É –Ω–µ –±—É–¥—É—Ç –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å —Ç–∞–∫–æ–µ –¥–ª–∏–Ω–Ω–æ–µ –∏ —Å–ª–æ–∂–Ω–æ–µ —Å–ª–æ–≤–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º–∞ 4: –ì—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤–∞**\n",
    "\n",
    "–î–ª—è –Ω–∞—Å, –ø—Ä–∏–≤—ã–∫—à–∏—Ö –∫ —è–∑—ã–∫–∞–º –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–≥–æ —Ç–∏–ø–∞, —Å–ª–æ–≤–æ ‚Äî —ç—Ç–æ –Ω–∞–±–æ—Ä –±—É–∫–≤ –º–µ–∂–¥—É –ø—Ä–æ–±–µ–ª–∞–º–∏ –∏ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è. –ù–æ –≤ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ –º–Ω–æ–≥–∏–µ —Å–ª–æ–∂–Ω—ã–µ —Å–ª–æ–≤–∞ –ø–∏—à—É—Ç—Å—è —Ä–∞–∑–¥–µ–ª—å–Ω–æ, –∞ –≤ —è–ø–æ–Ω—Å–∫–æ–º, –Ω–∞–æ–±–æ—Ä–æ—Ç, –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ –≤–æ–æ–±—â–µ –Ω–µ—Ç –ø—Ä–æ–±–µ–ª–æ–≤. –ü–æ—ç—Ç–æ–º—É —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ–∑–¥–∞—Ç—å –±—ã–ª–æ –Ω–µ–ª–µ–≥–∫–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte Pair Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –∞–ª–≥–æ—Ä–∏—Ç–º –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ BPE –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª—è–º —É–∑–Ω–∞–≤–∞—Ç—å –∫–∞–∫ –º–æ–∂–Ω–æ –±–æ–ª—å—à–µ —Å–ª–æ–≤ –ø—Ä–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º –æ–±—ä–µ–º–µ —Å–ª–æ–≤–∞—Ä—è.\n",
    "\n",
    "1.   –°–ª–æ–≤–æ = –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤\n",
    "2.   –°–ª–æ–≤–∞—Ä—å = –≤—Å–µ —Ç–æ–∫–µ–Ω—ã\n",
    "3.   –ü–æ–≤—Ç–æ—Ä—è—Ç—å, –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è:\n",
    "\n",
    "     –ù–∞–∑–Ω–∞—á–∞–µ–º –Ω–æ–≤—ã–º —Ç–æ–∫–µ–Ω–æ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–≤—É—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä–æ–µ\n",
    "–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —á–∞—â–µ –¥—Ä—É–≥–∏—Ö –ø–∞—Ä –≤ –∫–æ—Ä–ø—É—Å–µ (–≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤–º–µ—Å—Ç–µ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ BPE –≤–æ–∑–º–æ–∂–Ω—ã —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã. –û–¥–∏–Ω –∏–∑ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö ‚Äì –∏–¥—ë–º –ø–æ –≤—Å–µ–º —Ç–æ–∫–µ–Ω–∞–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –Ω–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ —Ç–æ–∫–µ–Ω."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/subword_tokenization.png\" width = \"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://alexanderdyakonov.wordpress.com/2019/11/29/—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è-–Ω–∞-–ø–æ–¥—Å–ª–æ–≤–∞-subword-tokenization/\">–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –Ω–∞ –ø–æ–¥—Å–ª–æ–≤–∞ (Subword Tokenization)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–æ—Ç –∂–µ —Å–ø–æ—Å–æ–± –ø–æ–º–æ–≥–∞–µ—Ç —Ä–µ—à–∏—Ç—å **–ø—Ä–æ–±–ª–µ–º—É** **OOV (out of vocabulary)**. –í –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ –º–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å —Å–ª–æ–≤–∞ *Unfriendly*, –Ω–æ –ø–æ—Å–∫–æ–ª—å–∫—É **Unfriendly** = **Un** + **friend** + **ly**, –º—ã –º–æ–∂–µ–º —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—å, —á—Ç–æ —Å–µ—Ç—å –±—É–¥–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å / –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏ —Å–ª–æ–≤–æ —Ü–µ–ª–∏–∫–æ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/token_unfriendly.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.thoughtvector.io/blog/subword-tokenization/\">Subword Tokenization ‚Äî Handling Misspellings and Multilingual Data</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, —Ç–æ –µ—Å—Ç—å –∏–∑—É—á–∏—Ç—å —Å–≤–æ–π—Å—Ç–≤–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —è–∑—ã–∫–∞, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å–ª–µ–¥—É—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[git] üêæ RNN-walkthrough](https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb)\n",
    "\n",
    "–≠—Ç–∞ –∑–∞–¥–∞—á–∞ —Å–≤–æ–¥–∏—Ç—Å—è –∫ –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –ö–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –∫–æ–Ω–≤–µ–π–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤ —Å–µ–±–µ —Å–ª–µ–¥—É—é—â–∏–µ 5 –±–ª–æ–∫–æ–≤. –ö –Ω–∏–º, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞—á–∏, –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É–Ω–∫—Ç—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/base_nlp_pipeline.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏:** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Å–∏–º–≤–æ–ª:\n",
    "\n",
    "- –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: `hey how are you`,\n",
    "- –≤—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: `hey how are yo`,\n",
    "- —Ü–µ–ª–µ–≤–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: `ey how are you`.\n",
    "\n",
    "–û—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ –Ω–∞ —Ç–æ, —á—Ç–æ –º—ã –¥–µ–ª–∞–ª–∏ —Ä–∞–Ω–µ–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏. –û–¥–Ω–∞–∫–æ —Ç–µ–ø–µ—Ä—å –Ω–∞–º –Ω—É–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –±—É–∫–≤—É –∫–∞–∂–¥—ã–π —Ä–∞–∑, –Ω–∞ –∫–∞–∂–¥—ã–π `hidden`. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –º—ã –ø—Ä–∏—Ö–æ–¥–∏–º –∫ —Å—Ö–µ–º–µ **many-to-many**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/one_to_many_same.png\" width=\"300\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏ –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–∞–∫:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/character_by_character_generation_example.gif\" width=\"400\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">The Unreasonable Effectiveness of Recurrent Neural Networks</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –Ω–∞—à–µ–π —É—á–µ–±–Ω–æ–π –∑–∞–¥–∞—á–µ –º—ã —Å–æ–∫—Ä–∞—Ç–∏–º –¥–æ –º–∏–Ω–∏–º—É–º–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –ø–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/simple_pipeline.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://tatoeba.org/ru/downloads\n",
    "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/eng_sentences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "with open(\"eng_sentences.txt\", \"r\") as input_file:\n",
    "    text = [line.strip().lower() for line in input_file.readlines()]\n",
    "\n",
    "pprint.pprint(text[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the sentences together and extract the unique characters\n",
    "# from the combined sentences\n",
    "chars = set(\"\".join(text))\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}\n",
    "\n",
    "print(\"Dictionary for mapping character to the integer:\")\n",
    "pprint.pprint(char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–º–µ—Å—Ç–æ ASCII —Å–∏–º–≤–æ–ª–∞, –∫–∞–∂–¥–æ–π –±—É–∫–≤–µ –º—ã —Å–æ–ø–æ—Å—Ç–∞–≤–∏–ª–∏ –Ω–æ–º–µ—Ä."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN –¥–æ–ø—É—Å–∫–∞—é—Ç —Ä–∞–±–æ—Ç—É —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã. –ù–æ —á—Ç–æ–±—ã –ø–æ–º–µ—Å—Ç–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ batch, –Ω–∞–¥–æ –∏—Ö –≤—ã—Ä–æ–≤–Ω—è—Ç—å.\n",
    "\n",
    "–û–±—ã—á–Ω–æ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–µ–ª–∞—é—Ç —Ä–∞–≤–Ω—ã–º —Å–∞–º–æ–º—É –¥–ª–∏–Ω–Ω–æ–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é, –∞ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Å—Ç–æ –¥–æ–ø–æ–ª–Ω—è—é—Ç –ø—Ä–æ–±–µ–ª–∞–º–∏ (–∏–ª–∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–∞–º–∏) –¥–æ —ç—Ç–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.  –¢–∞–∫–∂–µ —Ö–æ—Ä–æ—à–µ–π –∏–¥–µ–µ–π –±—É–¥–µ—Ç –æ—Ç–º–µ—Ç–∏—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º —Å–∏–º–≤–æ–ª–æ–º –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sent) for sent in text]\n",
    "maxlen = max(lengths)\n",
    "print(f\"The longest string has {maxlen} characters.\\n\")\n",
    "\n",
    "print(f\"Initial texts:\\n{text}\")\n",
    "# A simple loop that loops through the list of sentences and adds\n",
    "# a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "for i in range(len(text)):\n",
    "    while len(text[i]) < maxlen:\n",
    "        text[i] += \" \"\n",
    "\n",
    "print(f\"Resulting texts:\\n{text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ: Sequence bucketing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –º—ã –ø–æ—Å—Ç—É–ø–∏–ª–∏ —Å–∞–º—ã–º –ø—Ä–æ—Å—Ç—ã–º –æ–±—Ä–∞–∑–æ–º: –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–æ –≤—Å–µ–º –∫–æ—Ä–ø—É—Å–µ –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ–ø–æ–ª–Ω–∏–ª–∏ –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø—Ä–æ–±–µ–ª–∞–º–∏ –¥–æ —ç—Ç–æ–π –¥–ª–∏–Ω—ã.\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ —Å—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ —ç—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –Ω–µ–æ–ø—Ç–∏–º–∞–ª–µ–Ω. –ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–∏–∑–±–µ–∂–Ω–æ –±—É–¥—É—Ç –≤–æ–∑–Ω–∏–∫–∞—Ç—å —Ç–∞–∫–∏–µ –±–∞—Ç—á–∏, –¥–ª–∏–Ω–∞ –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥–µ—Ç –º–µ–Ω—å—à–µ, —á–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É. –ü–æ—ç—Ç–æ–º—É –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞ –±—É–¥–µ—Ç –≤–ø—É—Å—Ç—É—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –ø—Ä–æ–±–µ–ª–æ–≤.\n",
    "\n",
    "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–±–µ—Å–ø–µ—á–∏—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–æ–ª—å–∫–æ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞.\n",
    "\n",
    "–ü–æ—ç—Ç–æ–º—É —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ø–æ–¥—Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è **Sequence bucketing**. –û–Ω –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ–±—ã –¥–æ–ø–æ–ª–Ω—è—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–∞–º–∏ –¥–æ –µ–¥–∏–Ω–æ–π –¥–ª–∏–Ω—ã –Ω–µ –≥–ª–æ–±–∞–ª—å–Ω–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ –¥–∞—Ç–∞—Å–µ—Ç–∞, –∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É—Å–∫–æ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —ç—Ç–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –≤–Ω–µ —Ä–∞–º–æ–∫ –Ω–∞—à–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞.\n",
    "\n",
    "[[blog] ‚úèÔ∏è Guide: Pytorch data Samplers & Sequence bucketing](https://www.kaggle.com/code/shahules/guide-pytorch-data-samplers-sequence-bucketing)\n",
    "\n",
    "[[blog] ‚úèÔ∏è Speed up your RNN with Sequence Bucketing](https://www.kaggle.com/code/bminixhofer/speed-up-your-rnn-with-sequence-bucketing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/rnn_batch.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–∞ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –±–µ–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∏–º–≤–æ–ª–∞:\n",
    "\n",
    "**`hey how are yo`**\n",
    "\n",
    "–í –∫–∞—á–µ—Å—Ç–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ‚Äî –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–Ω —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω:\n",
    "\n",
    "**`ey how are you`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "\n",
    "    # Remove first character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "\n",
    "    if i < 5:\n",
    "        print(\"Input sequence:\".ljust(18), f\"'{input_seq[i]}'\")\n",
    "        print(\"Target sequence:\".ljust(18), f\"'{target_seq[i]}'\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å —Å–∏–º–≤–æ–ª—ã –Ω–∞–¥–æ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤ —á–∏—Å–ª–∞. –î–ª—è —ç—Ç–æ–≥–æ –º—ã —É–∂–µ –ø–æ—Å—Ç—Ä–æ–∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å.\n",
    "\n",
    "P.S. –ó–∞–ø—É—Å–∫–∞—Ç—å –±–ª–æ–∫ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "    if i < 5:\n",
    "        print(\"Encoded input sequence:\".ljust(25), input_seq[i])\n",
    "        print(\"Encoded target sequence:\".ljust(25), target_seq[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –∏–∑ —á–∏—Å–µ–ª –Ω–∞–¥–æ —Å–¥–µ–ª–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–∞.\n",
    "\n",
    "–ü—Ä–∏—á–∏–Ω–∞ ‚Äî –ø–æ–¥–∞—á–∞ —á–∏—Å–µ–ª –¥–∞—Å—Ç –º–æ–¥–µ–ª–∏ –ª–æ–∂–Ω–æ–µ –∑–Ω–∞–Ω–∏–µ –æ–± –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏ –ø–æ —Ç–∏–ø—É \"*–±—É–∫–≤–∞ –∞ –≤ –¥–≤–∞ —Ä–∞–∑–∞ –±–æ–ª—å—à–µ –±—É–∫–≤—ã –±*\". –ù–∞–º –∂–µ –Ω—É–∂–Ω–æ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞—à–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤ –Ω–µ–∫–æ—Ç–æ—Ä–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ c –ø–æ–º–æ—â—å—é `nn.Embedding()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∂–¥—ã–π —Å–∏–º–≤–æ–ª –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–ª–∏ –≤–µ–∫—Ç–æ—Ä–æ–º.\n",
    "–ù–µ —Å–ª–∏—à–∫–æ–º —ç–∫–æ–Ω–æ–º–Ω–æ, –∑–∞—Ç–æ —É–¥–æ–±–Ω–æ —É–º–Ω–æ–∂–∞—Ç—å –Ω–∞ –º–∞—Ç—Ä–∏—Ü—É –≤–µ—Å–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/language_modeling.png\" width=\"550\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = 2048\n",
    "\n",
    "# Convert data to tensor\n",
    "input_seq = torch.Tensor(input_seq).int()\n",
    "target_seq = torch.Tensor(target_seq)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(input_seq, target_seq)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"number of train batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NextCharacterGenerator(nn.Module):\n",
    "    def __init__(self, num_chars, embedding_dim, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        # symbols coding\n",
    "        self.emb = nn.Embedding(num_embeddings=num_chars, embedding_dim=embedding_dim)\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.GRU(\n",
    "            embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, num_chars)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.emb(x)\n",
    "        out, _ = self.rnn(x)  #\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # Need Only if num_layers > 1\n",
    "        out = out.contiguous().view(-1, self.rnn.hidden_size)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instantiate the model with hyperparameters\n",
    "model = NextCharacterGenerator(\n",
    "    num_chars=dict_size, embedding_dim=32, hidden_dim=128, num_layers=1\n",
    ").to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "num_epochs = 800\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training Run\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for input, target in train_loader:\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        optimizer.zero_grad()  # Clears existing gradients from previous epoch\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target.view(-1).long())\n",
    "        loss.backward()  # Does backpropagation and calculates gradients\n",
    "        optimizer.step()  # Updates the weights accordingly\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch}/{num_epochs}\".ljust(20), end=\" \")\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def predict(model, character, explore=False):\n",
    "    # –ïncoding our input to feed into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = torch.Tensor(character).int()\n",
    "\n",
    "    out = model(character)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    if explore:\n",
    "        # Taking k chars with the highest probability score\n",
    "        k = 3\n",
    "    else:\n",
    "        # Taking 1 char with the highest probability score\n",
    "        k = 1\n",
    "    top_prob_chars = torch.topk(prob, k).indices.numpy()\n",
    "    char_ind = np.random.choice(top_prob_chars)\n",
    "\n",
    "    return int2char[char_ind]\n",
    "\n",
    "\n",
    "def sample(model, out_len, start=\"hey\", explore=False):\n",
    "    model.eval()  # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for _ in range(size):\n",
    "        char = predict(model, chars, explore=explore)\n",
    "        chars.append(char)\n",
    "\n",
    "    return \"\".join(chars)\n",
    "\n",
    "\n",
    "model = model.cpu()\n",
    "sample(model=model, out_len=maxlen, start=\"hey, how are\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ø—Ä–æ–±—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    print(sample(model=model, out_len=maxlen, start=\"hey, how are\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –ø–æ—Ç–æ–º—É —á—Ç–æ —Å–µ—Ç—å –≤—ã–±–∏—Ä–∞–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω –Ω–∞ –≤—ã—Ö–æ–¥–µ. –û–¥–Ω–∞–∫–æ –º–æ–∂–Ω–æ –Ω–µ–º–Ω–æ–≥–æ –ø–æ–¥–≤–∏–≥–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤ –∏ –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    print(sample(model=model, out_len=maxlen, start=\"hey, how are\", explore=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª—É—á–∞–π–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±—ã–ª –±–æ–ª–µ–µ —Ä–∞–∑—É–º–Ω—ã–º, –º–æ–∂–Ω–æ –≤–æ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–∏–º–≤–æ–ª–∞ –ø–æ—Å—Ç—É–ø–∞—Ç—å —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º: –≤—ã–±–∏—Ä–∞—Ç—å –Ω–µ —Å–ª—É—á–∞–π–Ω—ã–π –∏–∑ —Ç–æ–ø-3 –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤, –∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –ø–æ—Å–ª–µ softmax —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∫–∞–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Å–∏–º–≤–æ–ª–æ–≤ (—Å–º. –ø–∞—Ä–∞–º–µ—Ç—Ä `p` –≤ `numpy.random.choice` [üõ†Ô∏è[doc]](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ó–∞–¥–∞—á–∞ Sequence-to-Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–æ–±—Ä–∞–≤—à–∏—Å—å, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ–¥–Ω–∏–º —è–∑—ã–∫–æ–º, –ø–µ—Ä–µ–π–¥—ë–º –∫ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—é –¥–≤—É—Ö —è–∑—ã–∫–æ–≤. –ö–∞–∫ –º—ã —É–∂–µ –ø—Ä–æ–≤–µ—Ä–∏–ª–∏, –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤—ã—É—á–∏—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –¥–≤—É—Ö —è–∑—ã–∫–æ–≤.\n",
    "\n",
    "–†–∞–∑–≤–∏–≤–∞—è –ø–æ–¥—Ö–æ–¥ word2vec, –¥–∞–≤–∞–π—Ç–µ —Ç–∞–∫ –±—É–¥–µ–º —É—á–∏—Ç—å —Å–µ—Ç—å, —á—Ç–æ–±—ã –æ–±–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å –≤ –æ–¥–Ω–æ–º –∏ —Ç–æ–º –∂–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ, –ø—Ä–∏—á—ë–º —Ç–æ–∫–µ–Ω—ã –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ —Å–ª–æ–≤ —Ä–∞—Å–ø–æ–ª–∞–≥–∞–ª–∏—Å—å –±–ª–∏–∑–∫–æ. –¢–∞–∫ –∫–∞–∫ —è–∑—ã–∫–∏ —Ä–∞–∑–ª–∏—á–Ω—ã–µ, –≤–≤–µ–¥—ë–º –¥–≤–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, –æ–¥–Ω—É –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞, –¥—Ä—É–≥—É—é ‚Äî –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π.\n",
    "\n",
    "–ó–¥–µ—Å—å, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –æ–±—â–µ–º —Å–ª—É—á–∞–µ –∏–º–µ—é—Ç —Ä–∞–∑–Ω—É—é –¥–ª–∏–Ω—É –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö, –º—ã –ø—Ä–∏—Ö–æ–¥–∏–º –∫ —Å—Ö–µ–º–µ **many-to-many** c —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏ –≤—Ö–æ–¥–∞ –∏ –≤—ã—Ö–æ–¥–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/one_to_many_var.png\" width=\"350\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  –ó–∞–¥–∞—á–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–±–µ—Ä–µ–º –∑–∞–¥–∞—á—É **sequence-to-sequence**: –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ $X$ –¥–ª–∏–Ω—ã $N$ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å $Y$ –¥–ª–∏–Ω—ã $T$.\n",
    "<br>$T$ **–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —Ä–∞–≤–Ω–æ** $N$.\n",
    "\n",
    "–î–ª—è —Ä–µ—à–µ–Ω–∏—è —Ç–∞–∫–∏—Ö –∑–∞–¥–∞—á –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–≤–µ **RNN**: **–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫** –∏ **–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫**.\n",
    "* –ó–∞–¥–∞—á–∞ **–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞**: –æ–±–æ–±—â–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ **–≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏** $X = (x_1,..., x_N)$, —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–≤ **–≤–µ–∫—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞** $C$ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.\n",
    "* –ó–∞–¥–∞—á–∞ **–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞**: –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ $C$, —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å **–≤—ã—Ö–æ–¥–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å** $Y = (y_1, ..., y_T)$.\n",
    "\n",
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –≤–µ–∫—Ç–æ—Ä–∞ $C$ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ **—Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ** –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ $h_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
    "\n",
    "* **–≤—Ö–æ–¥** ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å  $\\large x_1, \\dots, x_N$;\n",
    "* **–≤—ã—Ö–æ–¥** ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å  $\\large y_1, \\dots, y_T$.\n",
    "\n",
    "–ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç **–Ω—É–ª–µ–≤–æ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –∏ –≤–µ–∫—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞** $\\large c$, –∫–æ—Ç–æ—Ä—ã–π —á–∞—Å—Ç–æ —Ä–∞–≤–µ–Ω —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É —Å–∫—Ä—ã—Ç–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞.\n",
    "\n",
    "**–ö–æ–¥–∏—Ä–æ–≤—â–∏–∫:** $\\large h_i = f_w(x_i, h_{i_1})$\n",
    "\n",
    "**–î–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫:** $\\large s_t = g_u(y_{t-1}, s_{t-1}, c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/seq_to_seq_with_rnn.png\" width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ —ç—Ç–æ–º –≤–æ–∑–Ω–∏–∫–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∞—è **–ø—Ä–æ–±–ª–µ–º–∞:** –º—ã –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –±—É—Ç—ã–ª–æ—á–Ω–æ–µ –≥–æ—Ä–ª—ã—à–∫–æ ‚Äî –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ $h_N$. –ß—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ 1000?\n",
    "\n",
    "**–ò–¥–µ—è:** –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π –≤–µ–∫—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –¥–∞–Ω–Ω–æ–º –ø–æ–¥—Ö–æ–¥–µ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω **–≤–µ–∫—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞** —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã $c$, –≤ –∫–æ—Ç–æ—Ä—ã–π —Å–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å–æ –≤—Å–µ–π **–≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏** $(x_1,...,x_N)$.\n",
    "\n",
    "**–í—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å** –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–∞–∫ –µ–¥–∏–Ω–∏—Ü—ã, —Ç–∞–∫ –∏ —Ç—ã—Å—è—á–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –í –∑–∞–¥–∞—á–µ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ **–≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é** –º–æ–∂–µ—Ç –±—ã—Ç—å:\n",
    "* –∫–æ—Ä–æ—Ç–∫–∞—è —Ñ—Ä–∞–∑–∞,\n",
    "* –∞–±–∑–∞—Ü ‚Äú–í–æ–π–Ω—ã –∏ –º–∏—Ä–∞‚Äù.\n",
    "\n",
    "–ö–æ–Ω—Ç–µ–∫—Å—Ç –≤–∞–∂–µ–Ω. –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–ª–∞–≥–æ–ª–∞ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ –Ω—É–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å, –∫ –∫–∞–∫–æ–º—É —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–º—É –æ–Ω –æ—Ç–Ω–æ—Å–∏—Ç—Å—è, –∞ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –∫–æ–Ω—Ü–∞ –∞–±–∑–∞—Ü–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–Ω–∏–º–∞—Ç—å, –æ —á–µ–º —à–ª–∞ —Ä–µ—á—å –≤ –µ–≥–æ –Ω–∞—á–∞–ª–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º—ã Sequence-to-Sequence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **–í–µ–∫—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞** $c$ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã –Ω–µ –º–æ–∂–µ—Ç –≤–º–µ—Å—Ç–∏—Ç—å –ª—é–±–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –ø–æ—ç—Ç–æ–º—É –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∫–∞—á–µ—Å—Ç–≤–æ –±—É–¥–µ—Ç —É—Ö—É–¥—à–∞—Ç—å—Å—è.\n",
    "- –ù–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ **—Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ** $s_t$ –¥–æ–ª–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –∫–∞–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã **–≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏** —É–∂–µ –±—ã–ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã. –ï—Å–ª–∏ $s_t$ –Ω–µ —Å–ø–æ—Å–æ–±–Ω–æ –≤–º–µ—Å—Ç–∏—Ç—å —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∑–∞—Ü–∏–∫–ª–∏—Ç—å—Å—è –∏–ª–∏ –ø–æ—Ç–µ—Ä—è—Ç—å —á–∞—Å—Ç—å **–≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**.\n",
    "\n",
    "**–í–µ–∫—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞** $c$ –∏ **—Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è** –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ $s_t$ —è–≤–ª—è—é—Ç—Å—è ‚Äú–±—É—Ç—ã–ª–æ—á–Ω—ã–º–∏ –≥–æ—Ä–ª—ã—à–∫–∞–º–∏‚Äù –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–∏–º–µ—Ä —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] üõ†Ô∏è –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Ç—É—Ç–æ—Ä–∏–∞–ª –æ—Ç PyTorch](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "\n",
    "[[doc] üõ†Ô∏è Language translation with TorchText](\n",
    "https://pytorch.org/tutorials/beginner/torchtext_translation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ Unicode, –ø–æ—ç—Ç–æ–º—É –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –º—ã –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–∏–º–≤–æ–ª—ã Unicode –≤ ASCII, —Å–¥–µ–ª–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ—á–Ω—ã–º–∏ –∏ —É–±–µ—Ä—ë–º –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def normalizeStringRu(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-—è–ê-–Ø!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º seeds –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ–ª–∏–º —Ñ–∞–π–ª –Ω–∞ —Å—Ç—Ä–æ–∫–∏, –∞ —Å—Ç—Ä–æ–∫–∏ ‚Äî –Ω–∞ –ø–∞—Ä—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.manythings.org/anki/\n",
    "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/eng_rus_vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = (\n",
    "        open(\"%s_%s_vocab.txt\" % (lang1, lang2), encoding=\"utf-8\")\n",
    "        .read()\n",
    "        .strip()\n",
    "        .split(\"\\n\")\n",
    "    )\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [l.split(\"\\t\")[:2] for l in lines]\n",
    "    eng = [normalizeString(s[0]) for s in pairs]\n",
    "    rus = [normalizeStringRu(s[1]) for s in pairs]\n",
    "    pairs = list(zip(rus, eng))\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å–æ–∫—Ä–∞—Ç–∏–º –¥–∞—Ç–∞—Å–µ—Ç –¥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ –¥–ª–∏–Ω–µ–µ 10 —Å–ª–æ–≤ –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \",\n",
    "    \"i m \",\n",
    "    \"he is\",\n",
    "    \"he s \",\n",
    "    \"she is\",\n",
    "    \"she s \",\n",
    "    \"you are\",\n",
    "    \"you re \",\n",
    "    \"we are\",\n",
    "    \"we re \",\n",
    "    \"they are\",\n",
    "    \"they re \",\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return (\n",
    "        len(p[0].split(\" \")) < max_length\n",
    "        and len(p[1].split(\" \")) < max_length\n",
    "        and p[1].startswith(eng_prefixes)\n",
    "    )\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(\"eng\", \"rus\", False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –≤ –Ω–∞—à–µ–º —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –µ—Å—Ç—å –¥–≤–∞ —Å–ª–æ–≤–∞—Ä—è –∏ –Ω–∞–±–æ—Ä –ø–∞—Ä —Å—Ç—Ä–æ–∫.\n",
    "–û–ø—Ä–µ–¥–µ–ª–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫-–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–º–µ—Å—Ç–æ one_hot-–≤–µ–∫—Ç–æ—Ä–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è [—ç–º–±–µ–¥–¥–∏–Ω–≥–∏ üõ†Ô∏è[doc]](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html) —Ä–∞–∑–º–µ—Ä–æ–º 1√ó256 (hidden size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(\n",
    "            batch_size, 1, dtype=torch.long, device=device\n",
    "        ).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(max_length):\n",
    "            decoder_output, decoder_hidden = self.forward_step(\n",
    "                decoder_input, decoder_hidden\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                # detach from history as input\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return (\n",
    "            decoder_outputs,\n",
    "            decoder_hidden,\n",
    "            None,\n",
    "        )  # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –±—É–¥–µ–º –ø–æ–¥–∞–≤–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã —Å–ª–æ–≤ –¥–ª—è –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –ø–∞—Ä—ã –∏–∑ –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è, –∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –æ–∂–∏–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –ø–∞—Ä—ã –∏–∑ –¥—Ä—É–≥–æ–≥–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData(\"eng\", \"rus\", False)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, max_length), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, max_length), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, : len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, : len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(\n",
    "        torch.LongTensor(input_ids).to(device), torch.LongTensor(target_ids).to(device)\n",
    "    )\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, sampler=train_sampler, batch_size=batch_size\n",
    "    )\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion\n",
    "):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (- %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "\n",
    "def train(\n",
    "    train_dataloader,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    num_epochs,\n",
    "    learning_rate=0.001,\n",
    "    print_every=100,\n",
    "    plot_every=100,\n",
    "):\n",
    "\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        loss = train_epoch(\n",
    "            train_dataloader,\n",
    "            encoder,\n",
    "            decoder,\n",
    "            encoder_optimizer,\n",
    "            decoder_optimizer,\n",
    "            criterion,\n",
    "        )\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(\n",
    "                \"%s (%d %d%%) %.4f\"\n",
    "                % (\n",
    "                    timeSince(start, epoch / num_epochs),\n",
    "                    epoch,\n",
    "                    epoch / num_epochs * 100,\n",
    "                    print_loss_avg,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "plt.switch_backend(\"agg\")\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 15 –º–∏–Ω—É—Ç. –î–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Å—Ç—Ä–æ—á–∫—É –≤ –∫–æ–¥–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "# train(train_dataloader, encoder, decoder, num_epochs=80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –∑–∞—Ä–∞–Ω–µ–µ –æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞ –∏ –¥–µ–∫–æ–¥–µ—Ä–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/weights/encoder_weights.pth\n",
    "!wget -q https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/weights/decoder_weights.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load(\"/content/encoder_weights.pth\", map_location=device))\n",
    "decoder.load_state_dict(torch.load(\"/content/decoder_weights.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, _ = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append(\"<EOS>\")\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –º–æ–∂–µ–º –æ—Ü–µ–Ω–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    eng = []\n",
    "    dnn = []\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print(\"RUS\", pair[0])\n",
    "        print(\"ENG\", pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        eng.append(pair[1])\n",
    "        dnn.append(output_words[:-1])  # remove <eos> token\n",
    "        output_sentence = \" \".join(output_words)\n",
    "        print(\"DNN\", output_sentence)\n",
    "        print(\"\")\n",
    "\n",
    "    return eng, dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "with torch.no_grad():\n",
    "    eng, dnn = evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP –º–µ—Ç—Ä–∏–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[blog] ‚úèÔ∏è –¶–∏–∫–ª –ø–æ—Å—Ç–æ–≤ –æ–± NLP-–º–µ—Ç—Ä–∏–∫–∞—Ö](https://habr.com/ru/articles/745642/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ì–ª–æ–±–∞–ª—å–Ω–æ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –º–æ–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ **—Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ** –∏ **–Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ**.\n",
    "\n",
    "1. –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Å—Ç—ã –≤ —Ä–∞—Å—á–µ—Ç–µ –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã, –Ω–∞–∏–±–æ–ª–µ–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∏–∑ –Ω–∏—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã –¥–æ –±—É–º–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π. –ß–∞—â–µ –≤—Å–µ–≥–æ —Ç–∞–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ –ø–æ–¥—Å—á–µ—Ç–µ —á–∏—Å–ª–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å–∏–º–≤–æ–ª–æ–≤ / —Å–ª–æ–≤ / c–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–π ‚Äî –∏—Ö –Ω–∞–∑—ã–≤–∞—é—Ç ¬´lexic overlap metrics¬ª.\n",
    "\n",
    "2. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–µ—Ç—Ä–∏–∫, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ 2016 –≥–æ–¥–∞, ‚Äî –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ. –ü–µ—Ä–≤—ã–º —à–∞–≥–æ–º –≤ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –≤ —Ä–∞—Å—á–µ—Ç–µ –º–µ—Ç—Ä–∏–∫ —Å—Ç–∞–ª–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Å–ª–æ–≤ (embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/nlp_metrics.png\" width=\"1000\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/745642/\">–≠–≤–æ–ª—é—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–µ–≥–æ–¥–Ω—è –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –º–µ—Ç—Ä–∏–∫–∏, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–µ –¥–æ 2010 –≥–æ–¥–∞, –ø—Ä–∏—á–µ–º –∏–∑ –Ω–∏—Ö —á–∞—â–µ –≤—Å–µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è BLEU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–∏–±–æ–ª–µ–µ –∏–∑–≤–µ—Å—Ç–Ω—ã –∏ —É–ø–æ—Ç—Ä–µ–±–∏–º—ã —Ç–∞–∫–∏–µ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏, –∫–∞–∫ BLEU, NIST, ROUGE, METEOR, TER, chrF, chrF++, RIBES.\n",
    "\n",
    "**BLEU**\n",
    "\n",
    "BLEU (BiLingual Evaluation Understudy) ‚Äî –º–µ—Ç—Ä–∏–∫–∞, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –≤ IBM (Papineni et al.) –≤ 2001. –û—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ –ø–æ–¥—Å—á–µ—Ç–µ —Å–ª–æ–≤ (unigrams) –∏ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–π (n‚Äëgrams) –∏–∑ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞, —Ç–∞–∫–∂–µ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è –≤ —ç—Ç–∞–ª–æ–Ω–µ. –î–∞–ª–µ–µ —ç—Ç–æ —á–∏—Å–ª–æ –¥–µ–ª–∏—Ç—Å—è –Ω–∞ –æ–±—â–µ–µ —á–∏—Å–ª–æ —Å–ª–æ–≤ –∏ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–π –≤ –º–∞—à–∏–Ω–Ω–æ–º –ø–µ—Ä–µ–≤–æ–¥–µ ‚Äî –ø–æ–ª—É—á–∞–µ—Ç—Å—è precision. –ö –∏—Ç–æ–≥–æ–≤–æ–º—É precision –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ ‚Äî —à—Ç—Ä–∞—Ñ –∑–∞ –∫—Ä–∞—Ç–∫–æ—Å—Ç—å (brevity penalty), —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏—Ö –æ—Ü–µ–Ω–æ–∫ BLEU –¥–ª—è –∫—Ä–∞—Ç–∫–∏—Ö –∏ –Ω–µ–ø–æ–ª–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ñ–æ—Ä–º–∞—Ç –ø–æ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –º–µ—Ç—Ä–∏–∫—É. –ü–µ—Ä–≤—ã–º –ø–æ–¥–∞–µ—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞, –≤—Ç–æ—Ä—ã–º ‚Äî —ç—Ç–∞–ª–æ–Ω. –û–Ω–∏ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å —Ñ–æ—Ä–º–∞—Ç —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä–æ–∫, –ø–æ—ç—Ç–æ–º—É –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º `dnn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_for_bleu = [[\" \".join(x)] for x in dnn]  # Make a string from separated words\n",
    "dnn_for_bleu = [\n",
    "    item for sublist in dnn_for_bleu for item in sublist\n",
    "]  # Make a list from list of lists\n",
    "\n",
    "dnn_for_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torcheval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torcheval\n",
    "from torcheval.metrics.functional import bleu_score\n",
    "\n",
    "print(bleu_score(dnn_for_bleu, eng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> –ó–∞–∫–ª—é—á–µ–Ω–∏–µ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L09/out/time_series_data.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–µ —Ç–æ–ª—å–∫–æ —É –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –∏ —Ç–µ–∫—Å—Ç–æ–≤ –µ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å. –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–∏, –∏ –∫–∞–¥—Ä—ã –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞, –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–•–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–º –ø—Ä–∏–º–µ—Ä–æ–º –º–æ–∂–µ—Ç —Å–ª—É–∂–∏—Ç—å —Ä–∞–±–æ—Ç–∞ –Ω–∞—à–µ–≥–æ –≤—ã–ø—É—Å–∫–Ω–∏–∫–∞, –≤ –∫–æ—Ç–æ—Ä–æ–π —Å –ø–æ–º–æ—â—å—é RNN –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∞—Å—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –æ—Ç–¥–µ–ª—å–Ω—ã–º –∫–∞–¥—Ä–∞–º –≤–∏–¥–µ–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5> –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º RNN –≤ —Ä–∞–±–æ—Ç–µ –≤—ã–ø—É—Å–∫–Ω–∏–∫–∞ –∫—É—Ä—Å–∞ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ä–∞–±–æ—Ç–µ **–ü–æ–∏—Å–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –æ–±–∑–æ—Ä–∞ ZTF –ø—Ä–∏ –ø–æ–º–æ—â–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π** —Ä–µ—à–∞–ª–∞—Å—å –ø—Ä–æ–±–ª–µ–º–∞ —Ç—Ä–∞—Ç—ã –æ–≥—Ä–æ–º–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ä—É—á–Ω–æ–µ –∏–∑—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º–∏ –Ω–∞ –∑–Ω–∞—á–∏–º—ã–µ –∞—Å—Ç—Ä–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è.\n",
    "\n",
    "–ó–∞–≥–≤–æ–∑–¥–∫–∞ –∑–∞–∫–ª—é—á–∞–ª–∞—Å—å –≤ —Ç–æ–º, —á—Ç–æ:\n",
    "\n",
    "* –ø–æ—Å–ª–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Å—Ç–∞–≤–∞–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –ø–æ —Ç–∏–ø—É –ø—Ä–æ–ª–µ—Ç–µ–≤—à–µ–≥–æ –Ω–∞–¥ —Ç–µ–ª–µ—Å–∫–æ–ø–æ–º —Å–∞–º–æ–ª—ë—Ç–∞;\n",
    "* –∫–∞–∂–¥—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç ‚Äî —Å–µ—Ä–∏—è –∫–∞–¥—Ä–æ–≤ –≤–æ –≤—Ä–µ–º–µ–Ω–∏, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –Ω–∞ –æ–¥–Ω–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω–æ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/astro_encoder.png\"></center>\n",
    "\n",
    "\n",
    "<center><em>–ü—Ä–∏–º–µ—Ä—ã –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://github.com/EduNetArchive/Semenikhin_RB_ZTF\">–°–µ–º–µ–Ω–∏—Ö–∏–Ω –¢. –ê., et al</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/astro_rnn.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–°—Ö–µ–º–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://github.com/EduNetArchive/Semenikhin_RB_ZTF\">–°–µ–º–µ–Ω–∏—Ö–∏–Ω –¢. –ê., et al</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–¥—Ä–æ–±–Ω–µ–µ:\n",
    "\n",
    "[[video] üì∫ –í–∏–¥–µ–æ–∑–∞–ø–∏—Å—å –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è](https://www.youtube.com/watch?v=g_WeSLmyVO8)\n",
    "\n",
    "[[slides] üìä –ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è](https://docs.google.com/presentation/d/1BRhcv8GweaEFZVNrecarHlX6OyGxurDc/edit#slide=id.p2)\n",
    "\n",
    "[[git] üêæ –ö–æ–¥](https://github.com/EduNetArchive/Semenikhin_RB_ZTF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞</font>\n",
    "\n",
    "<font size=5>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö:</font>\n",
    "* [[blog] ‚úèÔ∏è –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤, –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π (1 —á–∞—Å—Ç—å)](https://habr.com/ru/articles/693562/)\n",
    "* [[blog] ‚úèÔ∏è Forecasting Time Series with Auto-Arima](https://www.alldatascience.com/time-series/forecasting-time-series-with-auto-arima/)\n",
    "\n",
    "<font size=5>–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏:</font>\n",
    "* [[article] üéì Session-based Recommendations with Recurrent Neural Networks](https://www.researchgate.net/publication/284579100_Session-based_Recommendations_with_Recurrent_Neural_Networks)\n",
    "* [[blog] ‚úèÔ∏è How to Remove Non-Stationarity From Time Series](https://www.kaggle.com/code/bextuychiev/how-to-remove-non-stationarity-from-time-series)\n",
    "* [[blog] ‚úèÔ∏è A Guide to Time Series Forecasting in Python](https://builtin.com/data-science/time-series-forecasting-python)\n",
    "* [[blog] ‚úèÔ∏è How to Check if Time Series Data is Stationary with Python?](https://www.geeksforgeeks.org/how-to-check-if-time-series-data-is-stationary-with-python/)\n",
    "* [[blog] ‚úèÔ∏è Complete Guide on Time Series Analysis in Python](https://www.kaggle.com/code/prashant111/complete-guide-on-time-series-analysis-in-python)\n",
    "* [[doc] üõ†Ô∏è Data transformations and forecasting models: what to use and when](https://people.duke.edu/~rnau/whatuse.htm)\n",
    "* [[colab] ü•® Time Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n",
    "\n",
    "<font size=5>LSTM:</font>\n",
    "* [[article] üìö Long Short-Term Memory (Hochreiter & Schmidhuber, 1997)](http://www.bioinf.jku.at/publications/older/2604.pdf)\n",
    "* [[blog] ‚úèÔ∏è Feature Scaling Data with Scikit-Learn for Machine Learning in Python](https://stackabuse.com/feature-scaling-data-with-scikit-learn-for-machine-learning-in-python/)\n",
    "* [[blog] ‚úèÔ∏è Hands-On Machine Learning with Scikit-Learn and TensorFlow, —á.4](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/ch04.html)\n",
    "* [[arxiv] üéì How to avoid machine learning pitfalls:\n",
    "a guide for academic researchers (Lones, 2023)](https://arxiv.org/pdf/2108.02497.pdf)\n",
    "* [[blog] ‚úèÔ∏è Recurrent Neural Networks with PyTorch](https://www.kaggle.com/code/kanncaa1/recurrent-neural-network-with-pytorch)\n",
    "\n",
    "<font size=5>–ü—Ä–∏–º–µ—Ä –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞:</font>\n",
    "* [[git] üêæ RNN-walkthrough](https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb)\n",
    "* [[blog] ‚úèÔ∏è The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "\n",
    "<font size=5>–†–∞–±–æ—Ç–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏:</font>\n",
    "- [[blog] ‚úèÔ∏è How to Remove Non-Stationarity From Time Series](https://www.kaggle.com/code/bextuychiev/how-to-remove-non-stationarity-from-time-series)\n",
    "- [[blog] ‚úèÔ∏è A Guide to Time Series Forecasting in Python](https://builtin.com/data-science/time-series-forecasting-python)\n",
    "- [[blog] ‚úèÔ∏è How to Check if Time Series Data is Stationary with Python?](https://www.geeksforgeeks.org/how-to-check-if-time-series-data-is-stationary-with-python/)\n",
    "- [[blog] ‚úèÔ∏è Complete Guide on Time Series Analysis in Python](https://www.kaggle.com/code/prashant111/complete-guide-on-time-series-analysis-in-python)\n",
    "- [[doc] üõ†Ô∏è Data transformations and forecasting models: what to use and when](https://people.duke.edu/~rnau/whatuse.htm)\n",
    "\n",
    "<font size=5>–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:</font>\n",
    "* [[wiki] üìö TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF)\n",
    "* [[doc] üõ†Ô∏è sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "* [[doc] üõ†Ô∏è –ï—â—ë –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–æ—Å–æ–±–æ–≤ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è –∏ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "* [[doc] üõ†Ô∏è TF-IDF Vectorizer scikit-learn](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)\n",
    "* [[colab] ü•® –ü–æ–¥—Ä–æ–±–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é Word2Vec](https://colab.research.google.com/drive/1OJF0k-E60sp9Vyoj1yWuoedGTrwRiTyj?usp=sharing)\n",
    "* [[doc] üõ†Ô∏è –¢—É—Ç–æ—Ä–∏–∞–ª PyTorch –ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é —ç–º–±–µ–¥–∏–Ω–≥–æ–≤ –≤ NLP](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)\n",
    "* [[blog] ‚úèÔ∏è NLP Course for you](https://lena-voita.github.io/nlp_course.html)\n",
    "* [[git] üêæ –ö—É—Ä—Å –ø–æ NLP –æ—Ç –®–ê–î](https://github.com/yandexdataschool/nlp_course)\n",
    "\n",
    "<font size=5>–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è:</font>\n",
    "* [[git] üêæ audiomentations](https://github.com/iver56/audiomentations)\n",
    "* [[doc] üõ†Ô∏è torchaudio](https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html)\n",
    "* [[git] üêæ torch-audiomentations](https://github.com/asteroid-team/torch-audiomentations)\n",
    "* [[git] üêæ AugLy](https://github.com/facebookresearch/AugLy)\n",
    "* [[git] üêæ nlpaug](https://github.com/makcedward/nlpaug)\n",
    "* [[git] üêæ TextAugment](https://github.com/dsfsi/textaugment)\n",
    "* [[blog] ‚úèÔ∏è –û–±–∑–æ—Ä –º–µ—Ç–æ–¥–æ–≤ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏](https://amitness.com/2020/05/data-augmentation-for-nlp/)\n",
    "\n",
    "<font size=5>NLP –º–µ—Ç—Ä–∏–∫–∏:</font>\n",
    "* [[blog] ‚úèÔ∏è –¶–∏–∫–ª –ø–æ—Å—Ç–æ–≤ –æ–± NLP-–º–µ—Ç—Ä–∏–∫–∞—Ö](https://habr.com/ru/articles/745642/)\n",
    "\n",
    "<font size=5>TF-IDF:</font>\n",
    "* [[wiki] üìö TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF)\n",
    "\n",
    "* [[doc] üõ†Ô∏è sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "\n",
    "* [[doc] üõ†Ô∏è –ï—â—ë –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–æ—Å–æ–±–æ–≤ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è –∏ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "\n",
    "* [[doc] üõ†Ô∏è TF-IDF Vectorizer scikit-learn](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
