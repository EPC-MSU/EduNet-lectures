{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Рекуррентные нейронные сети (RNN)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Особенности данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предыдущих лекциях мы работали с данными, у которых не было **временной связности**. И они были **фиксированной длины**.\n",
    "\n",
    "Если это **табличные данные**, то мы заранее знаем длину вектор-описания объекта, а также размер выхода модели, одно это число или вектор.\n",
    "\n",
    "Верно это и про **изображения** — обычно нейронная сеть учится на изображениях определенного разрешения. Да, мы можем сделать нейросеть, которая способна работать с изображением почти любого разрешения, но добиваемся мы этого за счет вставки слоев **global pooling**, которые  приводят признаковое описание, полученное сверточную частью нейросети, к фиксированному размеру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако далеко **не все данные фиксированного размера**. К примеру, **тексты**. Возьмем все абзацы из \"Войны и Мира\". Какие-то будут больше, какие-то меньше. А ещё нам важна последовательность слов и предложений.\n",
    "\n",
    "Или если на основе абзаца текста нам необходимо сгенерировать его **краткое содержание**? То, что нужно предсказать, может быть разной длины. Аналогичный вопрос возникает также в случае, если мы хотим по данным о курсе валюты за прошлый год спрогнозировать **курс валюты на следующий месяц** по дням."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/time_series_data.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но, может, справимся уже имеющимися инструментами?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория и классические подходы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Разделение данных\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на разбиение временного ряда на **train-val-test**.\n",
    "\n",
    "Если мы поделим ряд на отрезки, точки склейки будут легко предсказываться либо предыдущим, либо средним значением по отрезку. Нужно предсказывать крупные отрезки ряда. И помнить о том, что перемешивать данные нельзя — есть \"прошлое\" и \"будущее\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/fixed_partitioning.jpg\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://yuting3656.github.io/yutingblog/coursera-tensorflow-developer-professional-certificate/sequences-time-series-and-prediction/week01-03\">Coursera: Sequences, Time Series and Prediction with TensorFlow</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Компоненты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные понятия в статистическом анализе временных рядов:\n",
    "\n",
    "**Тренд** - компонента, описывающая долгосрочное изменение уровня ряда.\n",
    "\n",
    "**Сезонность** - компонента, обозначаемая как Q, описывает циклические изменения уровня ряда.\n",
    "\n",
    "**Ошибка (random noise)** - непрогнозируемая случайная компонента, описывает нерегулярные изменения в данных, необъяснимые другими компонентами.\n",
    "\n",
    "$$y_i = T + S + ϵ_i$$\n",
    "\n",
    "**Автокорреляция** — статистическая взаимосвязь между последовательностями величин одного ряда. Это один из самых важных коэффициентов в анализе временного ряда. Чтобы посчитать автокорреляцию, используется корреляция между временным рядом и её сдвинутой копией от величины временного сдвига. Сдвиг ряда называется лагом.\n",
    "\n",
    "**Автокорреляционная функция** - автокорреляция при разных лагах, помогает находить повторяющиеся участки сигнала. График называется **коррелограммой**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/autocorrelation_graph.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/693562/\">Анализ временных рядов, применение нейросетей (1 часть)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример\n",
    "\n",
    "Данные о количестве пассажиров за каждый месяц.\n",
    "[Dataset Air Passengers Number of air passengers per month](https://www.kaggle.com/rakannimer/air-passengers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/airline-passengers.csv\"\n",
    ")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = dataset.iloc[:, 1:2].values  # transform dataframe to numpy.array\n",
    "# plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data, label=\"Airline Passangers Data\")\n",
    "plt.title(\"Number of passengers per month\")\n",
    "plt.ylabel(\"#passengers\")\n",
    "plt.xlabel(\"Month\")\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделаем стационарнее**\n",
    "\n",
    "Мы можем видеть четкую сезонность и тенденцию к увеличению в данных.\n",
    "\n",
    "Тенденция и сезонность являются фиксированными компонентами, которые могут быть добавлены к любому нашему прогнозу. Они полезны, но должны быть удалены, чтобы изучить любые другие систематические сигналы, которые могут помочь сделать прогнозы.\n",
    "\n",
    "Временной ряд с сезонностью и удаленными трендами называется стационарным.\n",
    "\n",
    "Чтобы убрать сезонность, мы можем взять сезонную разницу, которая приведет к так называемым сезонно скорректированным временным рядам.\n",
    "\n",
    "Период сезонности составляет один год (12 месяцев). Приведенный ниже код рассчитывает сезонно скорректированный временной ряд и сохраняет его в файл «сезонно-adjusted.csv«."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal difference\n",
    "differenced = dataset.iloc[:, 1:2].diff(12)\n",
    "# trim off the first year of empty data\n",
    "differenced = differenced[12:]\n",
    "# save differenced dataset to file\n",
    "differenced.to_csv(\"seasonally_adjusted.csv\", header=None, index=False)\n",
    "# plot differenced dataset\n",
    "differenced.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку данные за первые 12 месяцев не имеют предварительных данных, с которыми можно было бы провести различие, они должны быть отброшены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Коррелограмма**\n",
    "\n",
    "Показывают корреляцию каждого отсроченного наблюдения и является ли корреляция статистически значимой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "sa = pd.read_csv(\"seasonally_adjusted.csv\", header=None)\n",
    "plot_acf(sa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике показаны значения запаздывания по оси X и корреляции по оси Y между -1 и 1 для отрицательно и положительно коррелированных лагов соответственно. Точки над синей областью указывают на статистическую значимость. Это зона достоверности, по-умолчанию на 0.05.\n",
    "\n",
    "* Корреляция 1 для значения отставания 0 указывает на 100% положительную корреляцию наблюдения с самим собой.\n",
    "* Вторая точка находится в районе 0,75, что означает, что следующая точка на 75% описывается предыдущим значением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Статистические модели предсказания\n",
    "\n",
    "**Авторегрессионная модель** (Auto regression method (AR))\n",
    "\n",
    "Линейная модель, в которой прогнозированная величина является суммой прошлых значений, умноженных на числовой множитель.\n",
    "\n",
    "$$X_t = C + ϕ_1X_{t-1}+ϕ_2X_{t-2}...+ ϵ_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Скользящее среднее** (Moving average method (MA))\n",
    "\n",
    "$$MA_k=  \\frac {p_{n-k+1} + p_{n-k+2} ... p_{n}} {k} = \\frac {1}{k} \\sum ^ {n} _{i= n-k+1} p_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет точек путем создания ряда средних значений различных подмножеств полного набора данных. Скользящее среднее часто применяется для анализа временных рядов акций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/moving_average_method.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/693562/\">Анализ временных рядов, применение нейросетей (1 часть)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARIMA**\n",
    "\n",
    "Метод скользящего среднего с авторегрессией и интегрированием (Auto regressive integrated moving average (ARIMA). И разновидности Seasonable ARIMA, ARIMAX и пр.\n",
    "\n",
    "Для использования модели временной ряд должен быть **стационарным**, т.е. его **среднее и дисперсия должны быть постоянны**.\n",
    "\n",
    "Модель предполагает, что временной ряд содержит три составляющие: авторегресионную, интегрированную и скользящее среднее, которые в модели обозначены $p, d$ и $q$  соответственно:\n",
    "\n",
    "* $p$ - порядок авторегрессии. Позволяет ответить на вопрос, будет ли очередной элемент ряда близок к значению $X$, если к нему были близки $p$ предыдущих значений.\n",
    "* $d$ - порядок интегрирования. Показывает, насколько элемент ряда близок по значению к $d$  предыдущим значениям, если разность между ними минимальна.\n",
    "* $q$ — порядок скользящего среднего. Позволяет установить погрешность модели как линейную комбинацию наблюдавшихся ранее значений ошибок.\n",
    "\n",
    "В общем виде модель ARMA(p,q) выглядит следующим образом:\n",
    "$$y_t = α_1y_{t-1} + ⋯ + α_py_{t-p}\t + ε_t + θ_1y_{t-1} + ⋯ + θ_qy_{t-q}$$, где $a_t$ — коэффициенты авторегрессионной части модели, $ε_t$ — значения ошибки (полагаются независимыми одинаково распределёнными случайными величинами из нормального распределения с нулевым средним), $θ_j$ — коэффициенты скользящего среднего.\n",
    "\n",
    "Если процесс оказывается нестационарным и для приведения его к\n",
    "стационарному виду потребовалось взять несколько разностей, то модель\n",
    "становится **ARIMA(p,d,q)**:\n",
    "\n",
    "$$(Δ^dy_t) = \\sum ^p _{t=1} α_t(Δ^dy_{t-1}) + ε_t + \\sum ^q _{j=1} θ_j(Δ^d ε_{t-j}) $$\n",
    "\n",
    "[Обсуждение на Machinelearning Mastery](https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся библиотечной реализацией. Тем более, что период мы уже вычислили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plotly.plotly import plot_mpl\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "data = dataset.iloc[:, 1:2]\n",
    "result = seasonal_decompose(\n",
    "    x=data, model=\"multiplicative\", extrapolate_trend=\"freq\", period=2\n",
    ")\n",
    "# result_add = seasonal_decompose(x=df_test['listData'], model='additive', extrapolate_trend='freq', period=1)\n",
    "fig = result.plot()\n",
    "# plot_mpl(fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся библиотечной версией ARIMA. Разобьём данные и поставим параметры произвольно. Обучим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "train_data, test_data = data[0 : int(len(data) * 0.9)], data[int(len(data) * 0.9) :]\n",
    "\n",
    "train_arima, test_arima = train_data.values, test_data.values\n",
    "\n",
    "history = [x for x in train_arima]\n",
    "\n",
    "y = test_arima\n",
    "# make first prediction\n",
    "predictions = list()\n",
    "model = ARIMA(history, order=(1, 1, 0))\n",
    "model_fit = model.fit()\n",
    "yhat = model_fit.forecast()[0]\n",
    "predictions.append(yhat)\n",
    "history.append(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling forecasts\n",
    "for i in range(1, len(y)):\n",
    "    # predict\n",
    "    model = ARIMA(history, order=(1, 1, 0))\n",
    "    model_fit = model.fit()\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    # invert transformed prediction\n",
    "    predictions.append(yhat)\n",
    "    # observation\n",
    "    obs = y[i]\n",
    "    history.append(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим метрики. Здесь они нужны лишь для того, чтобы оценивать измнения между моделями с различными параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "mse = mean_squared_error(y, predictions)\n",
    "print(\"MSE: \" + str(mse))\n",
    "mae = mean_absolute_error(y, predictions)\n",
    "print(\"MAE: \" + str(mae))\n",
    "rmse = math.sqrt(mean_squared_error(y, predictions))\n",
    "print(\"RMSE: \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(data.index, data, color=\"green\", label=\"Train\")\n",
    "plt.plot(test_data.index, y, color=\"red\", label=\"Real\")\n",
    "plt.plot(test_data.index, predictions, color=\"blue\", label=\"Predicted\")\n",
    "plt.title(\"ARIMA default prediction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Forecasting Time Series with Auto-Arima](https://www.alldatascience.com/time-series/forecasting-time-series-with-auto-arima/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание есть, однако можно как-то улучшить? Да так, чтобы без ручного анализа и подбора параметров?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "stepwise_model = auto_arima(\n",
    "    data,\n",
    "    start_p=1,\n",
    "    start_q=1,\n",
    "    max_p=3,\n",
    "    max_q=3,\n",
    "    m=12,\n",
    "    start_P=0,\n",
    "    seasonal=True,\n",
    "    d=1,\n",
    "    D=1,\n",
    "    trace=True,\n",
    "    error_action=\"ignore\",\n",
    "    suppress_warnings=True,\n",
    "    stepwise=True,\n",
    ")\n",
    "print(stepwise_model.aic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_model.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_forecast = stepwise_model.predict(n_periods=len(test_data))\n",
    "# This returns an array of predictions:\n",
    "print(future_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_forecast = pd.DataFrame(\n",
    "    future_forecast, index=test_data.index, columns=[\"Prediction\"]\n",
    ")\n",
    "test_preds = pd.concat([test_data, future_forecast], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(data.index, data, color=\"green\", label=\"Train\")\n",
    "plt.plot(test_preds.index, test_preds[\"Passengers\"], color=\"red\", label=\"Real\")\n",
    "plt.plot(test_preds.index, test_preds[\"Prediction\"], color=\"blue\", label=\"Predicted\")\n",
    "plt.title(\"ARIMA with optimal parameters\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "mse = mean_squared_error(test_preds[\"Passengers\"], test_preds[\"Prediction\"])\n",
    "print(\"MSE: \" + str(mse))\n",
    "mae = mean_absolute_error(test_preds[\"Passengers\"], test_preds[\"Prediction\"])\n",
    "print(\"MAE: \" + str(mae))\n",
    "rmse = math.sqrt(mean_squared_error(test_preds[\"Passengers\"], test_preds[\"Prediction\"]))\n",
    "print(\"RMSE: \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось лучше по-метрикам и визуально."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Области применения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<center><img src =\"https://www.researchgate.net/profile/Kelen-Dornelles/publication/280041456/figure/fig2/AS:670020073959445@1536756642860/Standard-solar-spectrum.ppm\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.researchgate.net/publication/280041456_THERMAL_PERFORMANCE_OF_WHITE_SOLAR-REFLECTIVE_PAINTS_FOR_COOL_ROOFS_AND_THE_INFLUENCE_ON_THE_THERMAL_COMFORT_AND_BUILDING_ENERGY_USE_IN_HOT_CLIMATES?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ\">Research Gate</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До бурного развития архитектуры **Трансформер**, о которой будет рассказано в соответствующей лекции, **рекуррентные сети** применялись в широком перечне задач, **от распознавания речи до генерации подписей** к изображениям. Общее для задач — мы имеем возможность сохранять информацию, сформированную при обработке одной части объекта (**токена**), и использовать ее, когда мы анализируем другие части.\n",
    "\n",
    "В настоящий момент рекурентные сети держат первенство **в обработке временных рядов**, а также являются частью гибридных моделей.\n",
    "\n",
    "Хотя Трансформеры, как правило, превосходят RNN с точки зрения точности, важно помнить о необходимых вычислительных ресурсах. По своей сути большое количество параметров и слоев в приводит к критическому увеличению объема необходимой памяти и вычислительных требований по сравнению с RNN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Основная идея"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основная идея**, на которой основано RNN, состоит в следующем: взять всю последовательность и пропустить через одну и ту же нейросеть.\n",
    "Но при этом сама нейросеть кроме следующего элемента последовательности (например, слова в тексте), будет принимать еще один параметр — некий $h$, который в начале будет, например, вектором из нулей, а далее — значением, которое выдает сама нейросеть после обработки очередного элемента последовательности (**токена**).\n",
    "\n",
    "Также далее мы будем использовать понятие **нулевого токена** — токена, который символизирует заплатку, токен, не несущий никакого смысла, но который иногда нужно передать модели. Например, как сигнал начала работы.\n",
    "\n",
    "В сети появляется новая сущность — **hidden state** ($h$) — вектор, хранящий состояние, учитывающее и локальный, и глобальный контекст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/rnn_basic_block.png\" width=\"700\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Базовый RNN блок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим работу рекуррентной нейронной сети:\n",
    "1. На вход поступает некоторая последовательность $x = \\{x_1,...x_t,...,x_n\\}$, где $x_i$ — вектор фиксированной размерности. В ряде случаев этот вектор имеет размерность 1.\n",
    "\n",
    "2. Для каждого поступившего $x_t$ формируем скрытое состояние $h_t$, которое является функцией от предыдущего состояния $h_{t-1}$ и текущего элемента последовательности $x_t$:\n",
    "$$\\large h_t = f_W(h_{t-1}, x_t),$$\n",
    "где $W$  — это обучаемые параметры (веса).\n",
    "\n",
    "3. На основании рассчитанного скрытого состояния, учитывающего предыдущие значения  $x_i$, формируется выходная последовательность $y = \\{y_1,...y_t,...,y_k\\}$. Для формирования предсказания $y_t$ в текущий момент времени в модель могут быть добавлены полносвязные слои, принимающие на вход текущее скрытое состояние $h_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Простейшая RNN**. Мы можем обрабатывать последовательность элементов вектора $x$ за счет применения рекуррентной формулы на каждом шаге:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large h_t = f_W(h_{t-1}, x_t),$\n",
    "\n",
    "$\\large \\quad \\quad \\quad \\color{grey}{\\downarrow \\text{(также может добавляться bias)}}$\n",
    "\n",
    "$\\large h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large y_t = W_{hy}h_t.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отличие** от слоев, с которыми мы уже сталкивались, состоит в том, что **на выходе мы получаем два объекта**: $y_t$ и $h_t$:\n",
    "\n",
    "$y_t$ — предсказание в текущий момент времени, например, метка класса,\n",
    "\n",
    "$h_t$ — контекст, в котором предсказание было сделано. Он может использоваться для дальнейших предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PyTorch для вычисления $h_t$ используется модуль [RNNCell](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html)\n",
    "\n",
    "$y_t$ в нем не вычисляется: предполагается, что для его получения в модель должен быть добавлен дополнительный линейный слой.\n",
    "\n",
    "**`input_size`** — размер элемента последовательности.\n",
    "\n",
    "В отличие от сверточных слоёв, это всегда вектор, а не тензор, поэтому **`input_size`** — скаляр.\n",
    "\n",
    "**`hidden_size`** — тоже скаляр. Он задает размер скрытого состояния, которое тоже является вектором. Фактически это количество нейронов в слое.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "rnn_cell = torch.nn.RNNCell(input_size=3, hidden_size=2)\n",
    "dummy_sequence = torch.randn((1, 3))  # batch, input_size\n",
    "h = rnn_cell(dummy_sequence)\n",
    "print(\"Inital shape:\".ljust(17), f\"{dummy_sequence.shape}\")\n",
    "print(\"Resulting shape:\".ljust(17), f\"{h.shape}\")  # hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно то, что описано в коде ниже.\n",
    "Для понятности в данном примере опущена батчевая обработка. Также для того, чтобы подобный код корректно заработал, [необходимо обернуть веса](https://stackoverflow.com/questions/50935345/understanding-torch-nn-parameter) в `torch.nn.Parameter` для регистрации параметров в модели.\n",
    "\n",
    "Начальное значение может быть инициализировано нулями, но лучше инициализировать случайными значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "# Simple RNNcell without a bias and batch support\n",
    "class SimplifiedRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        # Init weight matrix, for simplicity omit bias\n",
    "        self.W_hx = (\n",
    "            torch.randn(input_size, hidden_size) * 0.0001\n",
    "        )  # hidden_size == number of neurons\n",
    "        self.W_hh = (\n",
    "            torch.randn(hidden_size, hidden_size) * 0.0001\n",
    "        )  # naive initialization\n",
    "        self.h0 = torch.zeros((hidden_size))  # Initial hidden state\n",
    "\n",
    "    def forward(self, x, h=None):  # Without a batch dimension\n",
    "        if h is None:\n",
    "            h = self.h0\n",
    "        h = torch.tanh(torch.matmul(self.W_hx.T, x) + torch.matmul(self.W_hh.T, h))\n",
    "        return h\n",
    "\n",
    "\n",
    "simple_rnn_cell = SimplifiedRNNCell(input_size=3, hidden_size=2)\n",
    "h = simple_rnn_cell(dummy_sequence[0])  # No batch\n",
    "print(f\"Out = h\\n{h.shape} \\n{h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в последовательности всегда **несколько элементов**. И надо применить алгоритм к каждому.\n",
    "\n",
    "\n",
    "Поэтому RNNCell напрямую не используется. Для него есть обертка — [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html), которая обеспечивает последовательный вызов RNNCell для всех элементов последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN блок в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning: формат данных для RNN: длина последовательности, батч, размер объекта**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(input_size=3, hidden_size=2, batch_first = False)  # batch_first = True\n",
    "dummy_batched_seq = torch.randn((2, 1, 3))  # seq_len, batch, input_size\n",
    "out, h = rnn(dummy_batched_seq)\n",
    "\n",
    "print(\"Inital shape:\".ljust(20), f\"{dummy_batched_seq.shape}\")\n",
    "print(\"Resulting shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Simple RNN without batching\n",
    "class SimplifiedRNNLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn_cell = SimplifiedRNNCell(input_size, hidden_size)\n",
    "\n",
    "    # Without a batch dimension x have shape seq_len * input_size\n",
    "    def forward(self, x, h=None):\n",
    "        all_h = []\n",
    "        for i in range(x.shape[0]):  # iterating over timestamps\n",
    "            h = self.rnn_cell(torch.Tensor(x[i]), h)\n",
    "            all_h.append(h)\n",
    "        return np.stack(all_h), h\n",
    "\n",
    "\n",
    "simple_rnn = SimplifiedRNNLayer(input_size=4, hidden_size=2)\n",
    "\n",
    "sequence = np.array(\n",
    "    [[0, 1, 2, 0], [3, 4, 5, 0]]\n",
    ")  # batch with one sequence of two elements\n",
    "\n",
    "out, h = simple_rnn(sequence)\n",
    "print(\"Inital shape:\".ljust(20), f\"{sequence.shape}\")\n",
    "print(\"Resulting shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберемся.\n",
    "\n",
    "Если у нас есть две последовательности:\n",
    "\n",
    "*   [1, 3, 2]\n",
    "*   [0, 4, 2]\n",
    "\n",
    "Чтобы обработать элемент \"3\", нам нужен hidden state, вычисленный по \"1\".\n",
    "\n",
    "То же самое для \"4\" — нужно обработать \"0\". Таким образом, по горизонтальной оси мы не можем паралелиться. Придётся параллелиться по вертикальной. Мы можем паралельно обработать первые элементы первой и второй последовательностей.\n",
    "\n",
    "К данным добавляется еще одно измерение — **размер последовательности**. Batch из 5 последовательностей по 6 объектов (размер объекта 3) в каждой будет выглядеть так (время идёт первой размерностью, поэтому поэлементно идём \"сверху вниз\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/rnn_batch.png\" width=\"700\">\n",
    "\n",
    "<em>Source: <a href=\"https://www.researchgate.net/publication/284579100_Session-based_Recommendations_with_Recurrent_Neural_Networks\">Session-based Recommendations with Recurrent Neural Networks</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри RNN модуля элементы последовательности обрабатываются последовательно:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/simple_rnn_h_state.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса при этом используются одни и те же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_seq = torch.randn((2, 1, 3))  #  seq_len, batch, input_size\n",
    "\n",
    "print(\"RNNCell\")\n",
    "rnn_cell = torch.nn.RNNCell(3, 2)\n",
    "print(\"Parameter\".ljust(10), \"Shape\")\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "    print(t.ljust(10), p.shape)\n",
    "\n",
    "cell_out = rnn_cell(dummy_seq[0, :, :])  # take first element from sequence\n",
    "print()\n",
    "print(\"Result shape =\".ljust(20), cell_out.shape)\n",
    "print(\"Hidden state shape =\".ljust(20), cell_out.shape)  # one hidden state\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "print(\"RNN\")\n",
    "rnn = torch.nn.RNN(3, 2)\n",
    "print(\"Parameter\".ljust(15), \"Shape\")\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t.ljust(15), p.shape)\n",
    "\n",
    "out, h = rnn(dummy_seq)\n",
    "\n",
    "print()\n",
    "print(\"Result shape =\".ljust(20), out.shape)  # h for all timestamps element\n",
    "print(\"Hidden state shape =\".ljust(20), cell_out.shape)  # h for last element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обратимся к [документации PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) и посмотрим, какие параметры есть у модуля RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слои (Stacked RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN блоки можно объединять в слои, накладывая их друг на друга. Для этой операции в `torch.nn.RNN` есть аргумент `num_layers`, с помощью которого можно указать количество слоёв.\n",
    "\n",
    "В представленной архитектуре нижний слой (а это всё ещё одна RNN-ячейка) обрабатывает букву *h*, передаёт свой hidden state в саму себя (направо, `h[0]`) и обрабатывает *е* и т.д. Кроме того, эта же ячейка передаёт своё состояние на вторую RNN-ячейку (наверх, `h[1]`), которая уже обрабатывает результат работы первой ячейки.\n",
    "\n",
    "На практике такая схема может приводить к взрыву или затуханию градиента, причём при проходе как по горизонтали, так и по вертикали. Об этом ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/layers.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр **num_layers** задаёт количество RNN-ячеек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((2, 1, 3))  # seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3, 2, num_layers=3)\n",
    "\n",
    "# Weights matrix sizes not changed!\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t, p.shape)\n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print()\n",
    "print(\"Out:\\n\", out.shape)  # Hidden states for all elements from top layer\n",
    "print(\"h:\\n\", h.shape)  # Hidden states for last element for all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример прогнозирования временного ряда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- [How to Remove Non-Stationarity From Time Series](https://www.kaggle.com/code/bextuychiev/how-to-remove-non-stationarity-from-time-series)\n",
    "- [A Guide to Time Series Forecasting in Python](https://builtin.com/data-science/time-series-forecasting-python)\n",
    "- [How to Check if Time Series Data is Stationary with Python?](https://www.geeksforgeeks.org/how-to-check-if-time-series-data-is-stationary-with-python/)\n",
    "- [Complete Guide on Time Series Analysis in Python](https://www.kaggle.com/code/prashant111/complete-guide-on-time-series-analysis-in-python)\n",
    "- [Data transformations and forecasting models: what to use and when](https://people.duke.edu/~rnau/whatuse.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что общего у прогнозирования потребления электроэнергии домохозяйствами, оценки трафика на дорогах в определенные периоды, прогнозировании паводков и прогнозировании цены, по которой акции будут торговаться на фондовой бирже?\n",
    "\n",
    "Все они попадают под понятие данных временных рядов! Вы не можете точно предсказать любой из этих результатов без компонента «время». И по мере того, как в мире вокруг нас генерируется все больше и больше данных, прогнозирование временных рядов становится все более важной областью применения методов ML и DL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейросетевой подход\n",
    "[Time Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шкалирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max normalization\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "print(\"Initial statistics:\")\n",
    "print(\"Minimum value:\", repr(td_min).rjust(5))\n",
    "print(\"Maximum value:\", repr(td_max).rjust(5))\n",
    "\n",
    "training_data = (training_data - td_min) / (td_max - td_min)\n",
    "print(\"\\nResulting statistics:\")\n",
    "print(\"Minimum value:\", repr(training_data.min()).rjust(5))\n",
    "print(\"Maximum value:\", repr(training_data.max()).rjust(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование ансамблей данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы хотим научиться предсказывать следующие значение на основе предыдущих, нам нужно подготовить данные соответствующим образом.\n",
    "\n",
    "Разобьем весь массив данных на фрагменты вида\n",
    "\n",
    "$x \\to y$,\n",
    "\n",
    "где $x$ — это подпоследовательность, например, записи с 1-й по 8-ю, а $y$ — это значение из 9-й записи, то самое, которое мы хотим предсказать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# create data \"ensemble\"\n",
    "\n",
    "\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "        _x = data[i : (i + seq_length)]  # picking several sequential observations\n",
    "        _y = data[i + seq_length]  # picking the subsequent observation\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return torch.Tensor(np.array(x)), torch.Tensor(np.array(y))\n",
    "\n",
    "\n",
    "# set length of the ensemble; accuracy of the predictions and\n",
    "# speed perfomance almost always depend on it size\n",
    "seq_length = 8  # compare 2 and 32\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "print(\"Example of the obtained data:\\n\")\n",
    "print(\"Data corresponding to the first x:\")\n",
    "print(x[0])\n",
    "print(\"Data corresponding to the first y:\")\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря такому подходу мы можем работать с RNN моделью так же, как работали со сверточными моделями, подавая на вход такую подпоследовательность + результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разобьем на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(y) * 0.8)\n",
    "\n",
    "x_train = x[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "x_test = x[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"x shape:\", x_train.shape)\n",
    "print(\"y shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "print(\"x shape:\", x_test.shape)\n",
    "print(\"y shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на параметр **batch_first**. Он позволяет записывать данные в привычном формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AirTrafficPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size, hidden_size=hidden_size, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x: \",x.shape) # 108 x 8 x 1 : [batch_size, seq_len, input_size]\n",
    "        out, h = self.rnn(x)\n",
    "        # print(\"out: \", out.shape) # 108 x 8 x 4 : [batch_size, seq_len, hidden_size] Useless!\n",
    "        # print(\"h : \", h.shape) # 1 x 108 x 4 [ num_layers, batch_size, hidden_size]\n",
    "        y = self.fc(h)\n",
    "        # print(\"y\",y.shape) # 1 x 108 x 1\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря подготовке данных процесс обучения не будет отличаться от того, что мы использовали на прошедших занятиях.\n",
    "\n",
    "В силу того, что датасет маленький и все данные поместились в один batch, итерирования по batch-ам в явном виде здесь не происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_train(model, num_epochs=2000, learning_rate=0.01):\n",
    "    criterion = torch.nn.MSELoss()  # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        y_pred, h = model(x_train)  # we don't use h there, but we can!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # obtain the loss\n",
    "        loss = criterion(y_pred[0], y_train)  # for shape compatibility\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch},\".ljust(15), \"loss: %1.5f\" % (loss.item()))\n",
    "\n",
    "\n",
    "print(\"Simple RNN training process with MSE loss:\")\n",
    "input_size = 1\n",
    "hidden_size = 8\n",
    "rnn = AirTrafficPredictor(input_size, hidden_size)\n",
    "time_series_train(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_plot(train_predict):\n",
    "    data_predict = train_predict.data\n",
    "    y_data_plot = y.data\n",
    "\n",
    "    # Denormalize\n",
    "    data_predict = data_predict[0] * (td_max - td_min) + td_min\n",
    "    y_data_plot = y_data_plot * (td_max - td_min) + td_min\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.axvline(x=train_size, c=\"r\", linestyle=\"--\")\n",
    "    # shifting the curve as first y-value not correspond first value overall\n",
    "    plt.plot(seq_length + np.arange(y_data_plot.shape[0]), y_data_plot)################\n",
    "    #plt.plot(np.arange(y_data_plot.shape[0]), y_data_plot)################\n",
    "    plt.plot(seq_length + np.arange(y_data_plot.shape[0]), data_predict)\n",
    "\n",
    "    plt.title(\"Number of passengers per month\")\n",
    "    plt.ylabel(\"#passengers\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "\n",
    "    plt.legend([\"Train/Test separation\", \"Real\", \"Predicted\"])\n",
    "    plt.grid(axis=\"x\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "rnn.eval()\n",
    "train_predict, h = rnn(x)\n",
    "time_series_plot(train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что модель в принципе справляется с задачей. Если подбирать размер hidden size, качество станет лучше. Или мы добьёмся того, что нейросеть будет предсказывать просто линию (большой hidden size — нейросеть выучивает, что нужно предсказывать следующее значение по предыщущему).\n",
    "\n",
    "Но посмотрим, как далее справятся более мощные архитектуры, и уже позднее напишем окончательные выводы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблемы RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретически, можно было бы сразу пропустить все данные через сеть и затем вычислить градиент, однако возникнут следующие проблемы:\n",
    "\n",
    " - большие последовательности не поместятся в памяти;\n",
    " - так как цепочка будет очень длинной, возникнет затухание/взрыв градиента;\n",
    " - по мере прохождения сигнала по цепи контекст затирается.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть длинная последовательность. Если мы сразу предсказываем, то в каждый момент времени нужно распространить Loss. И все ячейки нужно обновить во время backpropogation. Все градиенты нужно посчитать. Возникают проблемы, связанные с нехваткой памяти.\n",
    "\n",
    "Есть специальные тесты для проверки, контекст какой длины использует RNN при предсказании. Если мы делаем предсказание только в последней ячейке, может оказаться, что используется, скажем, информация только о последних 10 словах предложения.\n",
    "\n",
    "Функция активации Tanh постепенно затирает контекст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/backprop_through_time.png\"><center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://cs231n.stanford.edu/slides/2021/lecture_10.pdf\">CS231n: Recurrent Neural Network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затухающий/взрывающийся градиент (Vanishing/exploding gradient) — явления затухающего и взрывающегося градиента часто встречаются в контексте RNN. И при большой длине последовательности это становится критичным. Причина в том, что зависимость величины градиента от числа слоёв экспоненциальная, поскольку веса умножаются многократно.\n",
    "\n",
    "$dL ∝ (W)^N$.\n",
    "\n",
    "$W > 1$ => взрыв\n",
    "\n",
    "$W < 1$ => затухание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/simple_rnn_backprop.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из путей решения проблемы: **градиентное отсечение** (Gradient clipping) — метод, который ограничивает максимально допустимое значение градиента, позволяя избежать градиентного взрыва.\n",
    "\n",
    "А от затухания градиента может помочь **пропускание** **градиента по частям**, на сколько-то шагов по времени назад или вперёд. А не через всю нейросеть. Да, градиент будет не совсем точо считаться, и мы будем терять в качестве. И это нам спасает память."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/truncated_backprop.png\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://cs231n.stanford.edu/slides/2021/lecture_10.pdf\">CS231n: Recurrent Neural Network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычная RNN имела множество проблем, в том числе, в ней очень быстро затухала информация о предыдущих словах в предложении. Помимо этого были проблемы с затуханием/взрывом самого градиента.\n",
    "\n",
    "Эти проблемы были частично решены в LSTM, предложенной в [Hochreiter & Schmidhuber (1997)](http://www.bioinf.jku.at/publications/older/2604.pdf)\n",
    "\n",
    "В обычной RNN в ячейке был только один путь передачи информации. На каждом шаге мы сливали информацию, накопленную с предыдущих шагов, с текущей:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/simple_rnn_h_state.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом информация о предыдущих токенах очень быстро затухает, и теряется общая информация о предложении.\n",
    "\n",
    "Структура ячейки LSTM намного сложнее. Здесь есть целых 4 линейных слоя, каждый из которых выполняет разные задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/lstm_chain.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/lstm_chain_notation.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large f_t = σ(W_f \\cdot [h_{t-1}, x_t] + b_f) - forget \\quad gate$\n",
    "\n",
    "$\\large i_t = σ(W_i \\cdot [h_{t-1}, x_t] + b_i) - input \\quad gate$\n",
    "\n",
    "$\\large C^\\prime_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_{C^\\prime}) - candidate \\quad cell \\quad state$\n",
    "\n",
    "$\\large C_t = f_t\\otimes C_{t-1} + i_t \\otimes C^\\prime_t - cell \\quad state$\n",
    "\n",
    "$\\large o_t = σ(W_o \\cdot [h_{t-1}, x_t] + b_o) - output \\quad gate$\n",
    "\n",
    "$\\large h_t = o_t\\otimes \\tanh(C_t) - block \\quad output$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главное нововведение: в LSTM добавлен путь $c$, который по задумке должен этот общий контекст сохранять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/lstm_c_state_highway.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другими словами, путь $c$ (cell state, иногда называется highway, магистраль)  помогает нейросети сохранять важную информацию, встретившуюся в какой-то момент в предложении, все время, пока эта информация требуется.\n",
    "\n",
    "По формулам также видно, как возросла сложность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyTorch LSTMCELL](https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
    "\n",
    "Интерфейс отличается от RNNCell количеством входов и выходов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lstm_cell = torch.nn.LSTMCell(input_size=3, hidden_size=4)\n",
    "input = torch.randn(1, 3)  # batch, input_size\n",
    "h_0 = torch.randn(1, 4)\n",
    "c_0 = torch.randn(1, 4)\n",
    "h, c = lstm_cell(input, (h_0, c_0))  # second arg is tuple\n",
    "print(\"Shape of h:\", h.shape)  # batch, hidden_size\n",
    "print(\"Shape of c:\", c.shape)  # batch, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличие от RNN состоит в том, что кроме $h$ возвращается еще и $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "lstm = nn.LSTM(input_size=4, hidden_size=5)\n",
    "input = torch.randn(3, 2, 4)  # seq_len, batch, input_size\n",
    "out, (h, c) = lstm(input)  # h and c returned in tuple\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h\".ljust(15), h.shape)  # batch, hidden_size\n",
    "print(\"Shape of c\".ljust(15), c.shape)  # batch, hidden_size\n",
    "print(\n",
    "    \"Output shape:\".ljust(15), out.shape\n",
    ")  # seq_len, batch, hidden_size : h for each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечаения**\n",
    "\n",
    "\n",
    "1. Сложность нейронной сети должна соответствовать сложности подаваемых в нее данных. С ростом ансамбля и числа нейронов увеличивается заучивание тренировочной выборки и теряется способность к обобщению.\n",
    "2. Предварительный анализ цикличности в данных (если она есть) помогает понять оптимальный размер ансамбля (тут видно, что цикл, в среднем, составляет 8 интервалов).\n",
    "3. Также результат может зависеть от типа масштабирования, который Вы применяете. Нужно знать принципы работы scaler'ов и не стесняться экспериментировать с ними. См. [Feature Scaling Data with Scikit-Learn for Machine Learning in Python](https://stackabuse.com/feature-scaling-data-with-scikit-learn-for-machine-learning-in-python/) и [Hands-On Machine Learning with Scikit-Learn and TensorFlow, ч.4](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/ch04.html).\n",
    "4. При всей выгодности применения нейронных сетей, необходимо быть осторожным с автокорреляцией (см. статью [How to avoid machine learning pitfalls:\n",
    "a guide for academic researchers](https://arxiv.org/pdf/2108.02497.pdf))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сразу посмотрим, как эта идея реализуется на практике. Далее в лекции подробно разберём работу отдельных блоков.\n",
    "\n",
    "Сгенерируем 30 различных синусоид, каждая с одинаковой частотой и амплитудой, но начинающаясянемного с разных точек на оси Х."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "N = 30 # number of samples\n",
    "L = 300 # length of each sample (number of values for each sine wave)\n",
    "T = 10 # width of the wave\n",
    "x = np.empty((N,L), np.float32) # instantiate empty array\n",
    "x[:] = np.arange(L) + np.random.randint(-4*T, 4*T, N).reshape(N,1)\n",
    "y = np.sin(x/1.0/T).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сеть будет обучаться на 10 различных синусоидах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y[0], label=\"Sequense1\")\n",
    "plt.plot(y[1], label=\"Sequense2\")\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим класс модели и пройдёмся по его частям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_layers=512):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        # lstm1, lstm2, linear are all layers in the network\n",
    "        self.lstm1 = nn.LSTMCell(1, self.hidden_layers)\n",
    "        self.lstm2 = nn.LSTMCell(self.hidden_layers, self.hidden_layers)\n",
    "        self.linear = nn.Linear(self.hidden_layers, 1)\n",
    "\n",
    "    def forward(self, y, future_preds=0):\n",
    "        outputs, n_samples = [], y.size(0)\n",
    "        h_t = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        c_t = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        h_t2 = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        c_t2 = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "\n",
    "        for time_step in y.split(1, dim=1):\n",
    "            # N, 1\n",
    "            h_t, c_t = self.lstm1(time_step, (h_t, c_t)) # initial hidden and cell states\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2)) # new hidden and cell states\n",
    "            output = self.linear(h_t2) # output from the last FC layer\n",
    "            outputs.append(output)\n",
    "\n",
    "        for i in range(future_preds):\n",
    "            # this only generates future predictions if we pass in future_preds>0\n",
    "            # mirrors the code above, using last output/prediction as input\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs.append(output)\n",
    "        # transform list to tensor\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация:\n",
    "\n",
    "* `time_step` - количество признаков, описывающих входящий объект $x$\n",
    "* `hidden_layers` - размер вектора контекста $h$\n",
    "\n",
    "Мы определяем два слоя RNN, используя две ячейки RNNCell.  В первую ячейку RNN мы подаём входные данные размером 1.\n",
    "\n",
    "В RNN нам не нужно передавать нарезанный массив входных данных. Нам не нужно скользящее окно для данных, поскольку вектора контекста обеспечивают сохранение состояния ячейки за нас.\n",
    "\n",
    "* `h_0` - тензор, содержащий начальное скрытое состояние для каждого элемента в тюпле размера `(batch, hidden_size).`\n",
    "\n",
    "Размер батча равен 30, это определяется первым измерением входных данных; следовательно, берем `n_samples = x.size(0)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий шаг, пожалуй, самый трудный. Мы должны подать тензор соответствующей формы. Это будет тензор из m точек, где m — размер `train` в каждой последовательности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.from_numpy(y[3:, :-1])\n",
    "b = a.split(1, dim=1)\n",
    "b[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё один момент - мы обрабатываем 1 элемент в строке, и, чтобы предсказать 300й элемент (и посчитать ошибку), мы должны остановиться на 299м. То же самое касается начала последовательности. По первому элементу предсказываем второй."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = torch.from_numpy(y[3:, :-1]) # (27, 299)\n",
    "train_target = torch.from_numpy(y[3:, 1:]) # (27, 299)\n",
    "test_input = torch.from_numpy(y[:3, :-1]) # (3, 299)\n",
    "test_target = torch.from_numpy(y[:3, 1:]) # (3, 299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цикл обучения приближен к стандартному.\n",
    "\n",
    "Добавлена функция отрисовки предсказываемых синусоид для визуализации сходимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(yi, n, i, future):\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(12,3))\n",
    "\n",
    "    plt.title(f\"Step {i+1}\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    ax1.plot(np.arange(n), yi[0][:n], 'r', linewidth=2.0)\n",
    "    ax1.plot(np.arange(n, n+future), yi[0][n:], 'r'+\":\", linewidth=2.0)\n",
    "\n",
    "    ax2.plot(np.arange(n), yi[1][:n], 'g', linewidth=2.0)\n",
    "    ax2.plot(np.arange(n, n+future), yi[1][n:], 'g'+\":\", linewidth=2.0)\n",
    "\n",
    "    ax3.plot(np.arange(n), yi[2][:n], 'b', linewidth=2.0)\n",
    "    ax3.plot(np.arange(n, n+future), yi[2][n:], 'b'+\":\", linewidth=2.0)\n",
    "\n",
    "    plt.savefig(\"predict%d.png\"%i, dpi=200)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def training_loop(n_epochs, model, optimiser, loss_fn,\n",
    "                  train_input, train_target, test_input, test_target):\n",
    "    for i in range(n_epochs):\n",
    "        def closure():\n",
    "            optimiser.zero_grad()\n",
    "            out = model(train_input)\n",
    "            loss = loss_fn(out, train_target)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimiser.step(closure)\n",
    "        with torch.no_grad():\n",
    "            future = 100\n",
    "            pred = model(test_input, future_preds=future)\n",
    "            # use all pred samples, but only go to 299\n",
    "            loss = loss_fn(pred[:, :-future], test_target)\n",
    "            y = pred.detach().numpy()\n",
    "        # draw figures\n",
    "        n = train_input.shape[1] # 299\n",
    "        draw(y, n, i, future)\n",
    "\n",
    "        # print the loss\n",
    "        out = model(train_input)\n",
    "        loss_print = loss_fn(out, train_target)\n",
    "        print(\"Step: {}, Loss: {}\".format(i, loss_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = optim.LBFGS(model.parameters(), lr=0.01)\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "training_loop(\n",
    "              n_epochs,\n",
    "              model,\n",
    "              optimiser,\n",
    "              criterion,\n",
    "              train_input,\n",
    "              train_target,\n",
    "              test_input,\n",
    "              test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо бы ещё как-то улучишть обучение модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"http://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/signal.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательность можно пропустить через сеть два раза: в прямом и обратном направлении. Для этого создаётся слой, аналогичный входному, для обратного направления, и результат двух слоёв конкатенируется.\n",
    "\n",
    "[A Beginner’s Guide on Recurrent Neural Networks with PyTorch](https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"http://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/bidirectional.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((2, 1, 3))  # seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3, 2, bidirectional=True)\n",
    "\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t, p.shape)\n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print()\n",
    "print(\"Out:\\n\", out.shape)  # Concatenated Hidden states from both layers\n",
    "print(\n",
    "    \"h:\\n\", h.shape\n",
    ")  # Hidden states last element from  both : 2*num_layers*hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скрытое состояние\n",
    "\n",
    "Как вы уже могли отметить, RNN ячейку можно инициализировать собственным начальным вектором. А затем подавать туда скрытое состояние на каждой итерации. **Или не подавать.**\n",
    "\n",
    "Как так-то?\n",
    "\n",
    "Да, цель скрытого состояния — закодировать историю. Допустим, ваши входные данные представляют собой последовательность данных со 2 по 11 день, и закодированная история в скрытом состоянии связана только с данными со 2 по 11 день. Таким образом, ваши батчи должны содержать всю историю, необходимую для каждого выходного прогноза.\n",
    "\n",
    "При этом **обязательно** нужно **сбросить** скрытое состояние между батчами, если данные в них независимы. Вы не хотите, чтобы ваше скрытое состояние из вашего прошлого предсказания повлияло на следующее?\n",
    "\n",
    "[Обсуждение на Stackexchange](https://stats.stackexchange.com/questions/470382/what-is-the-use-of-the-hidden-state-in-an-lstm-network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модификации LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRU (Gated reccurent unit)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая известная модификация LSTM — GRU. Она более компактна за счет сильных упрощений в сравнении со стандартной LSTM.\n",
    "\n",
    "Главные изменения: объединены forget и input gates, слиты $h_t$ и $C_t$, которые в обычной LSTM только участвовали в формировании друг друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/gru_basic_block.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "$\\large r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "$\\large \\tilde h_t = tanh(W \\cdot [r_t * h_{t-1}, x_t])$\n",
    "\n",
    "$\\large h_t = (1-z_t) * h_{t-1} + z_t * \\tilde h_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = torch.nn.GRU(input_size=4, hidden_size=3)\n",
    "input = torch.randn(2, 1, 4)  # seq_len, batch, input_size\n",
    "h0 = torch.randn(1, 1, 3)\n",
    "output, h = gru(input, h0)\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h:\".ljust(15), h.shape)  # last h\n",
    "print(\"Output shape:\".ljust(15), output.shape)  # seq_len = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практический опыт исследователей: иногда лучше работает GRU, иногда — LSTM. Точный рецепт успеха сказать нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Типы задач"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекуррентная сеть может выдавать некий ответ на каждом шаге, однако мы можем:\n",
    "\n",
    " 1. Использовать только выданный на последнем (если нам нужно предсказать одно значение) — **many-to-one**.\n",
    "\n",
    " 2. Мы можем подавать в наше нейросетку токены (когда кончился исходный сигнал, подаем нулевые токены), пока она не сгенерирует токен, символизирующий остановку (**many-to-many, one-to-many**).\n",
    "\n",
    " 3. Можем делать различные комбинации, игнорируя часть выходов нейросети в начале её работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **«One to one»** — обычная нейронная сеть, не обязательно применять RNN в таком случае.\n",
    "\n",
    "*   Более сложной является реализация **«one to many»**, когда у нас есть всего один вход, и нам необходимо сформировать несколько выходов. Такой тип нейронной сети актуален, когда мы говорим о **генерации музыки** или **текстов**. Мы задаем начальное слово или начальный звук, а дальше модель начинает самостоятельно генерировать выходы, в качестве входа к очередной ячейке рассматривая выход с прошлой ячейки нейронной сети.\n",
    "\n",
    "*   Если мы рассматриваем задачу **классификации**, то актуальна схема **«many to one»**. Мы должны проанализировать все входы нейронной сети и только в конце определиться с классом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/one_or_many_to_one_or_many_ways_1.png\" width=\"8000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Схема **«many to many»**, в которой количество выходов **равно** количеству входов нейронной сети. Обычно это задачи типа разметки исходной последовательности. Например, указать столицы городов, названия важных объектов, веществ и т.д., что относится к задачам вида NER (Named entity recogition).\n",
    "\n",
    "*   Схема **«many to many»**, в которой количество выходов нейронной сети **не равно** количеству входов. Это актуально в машинном переводе, когда одна и та же фраза может иметь разное количество слов в разных языках (т.е. это реализует схему кодировщик-декодировщик). Кодировщик получает данные различной длины — например, предложение на английском языке. С помощью скрытых состояний он формирует из исходных данных вектор, который затем передаётся в декодировщик. Последний, в свою очередь, генерирует из полученного вектора выходные данные — исходную фразу, переведённую на другой язык."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/one_or_many_to_one_or_many_ways_2.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно объединять разные подходы. Сначала генерируем некий $h$, который содержит сжатую информацию о том, что было подано в нейросеть, а затем подаем его в нейросеть «one to many», которая генерирует, к примеру, перевод того текста, что был подан первой части нейросети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди NLP-задач можно выделить такие группы:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<center><img src =\"https://imageup.ru/img253/4647937/nlpdrawio.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В зависимости от источника ввода полученный текст может иметь свои особенности. Автоматическое распознавание приводят к ошибкам распознавания и разметки страниц; текст из социальных сетей - большое количество сокращений, смайлов, хэштегов, упоминаний и пр."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример посимвольной генерации текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Github RNN-walkthrough](https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb)\n",
    "\n",
    "Начнем с относительно простой задачи — посимвольной генерации текста. Как правило, конвейер обработки текста содержит в себя следующие 5 блоков. К ним, в зависимости от задачи, добавляются дополнительные пункты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://imageup.ru/img81/4648055/copy-of-untitled-diagram-page-1.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постановка задачи:** предсказать следующий символ в последовательности.\n",
    "\n",
    "- исходный текст:\n",
    "'hey how are you'\n",
    "\n",
    "- искаженный текст:\n",
    "'hey how are yo'\n",
    "\n",
    "- Верное предсказание:\n",
    "'u'\n",
    "\n",
    "Очень похоже на то, что мы делали ранее с временными рядами. Инференс модели будет выглядеть как на гифке ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/character_by_character_generation_example.gif\" width=\"400\">\n",
    "\n",
    "<em>Source: <a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">The Unreasonable Effectiveness of Recurrent Neural Networks</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей учебной задаче мы сократим до минимума выполняемые операции по подготовке данных для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<center><img src =\"https://imageup.ru/img259/4648062/simple_pipeline.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "text = [\"hey how are you\", \"good i am fine\", \"have a nice day\"]\n",
    "\n",
    "# Join all the sentences together and extract the unique characters\n",
    "# from the combined sentences\n",
    "chars = set(\"\".join(text))\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}\n",
    "\n",
    "print(\"Dictionary for mapping character to the integer:\")\n",
    "pprint.pprint(char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо ASCII символа, каждой букве мы сопоставили номер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выравнивание данных (Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN допускают работу с данными переменной длины. Но чтобы поместить предложения в batch, надо их выровнять.\n",
    "\n",
    "Обычно размер батча делают равным самому длинному предложению, а остальные просто дополняют пробелами (или спецсимволами) до этого размера.  Также хорошей идеей будет отметить специальным символом начало предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sent) for sent in text]\n",
    "maxlen = max(lengths)\n",
    "print(f\"The longest string has {maxlen} characters.\\n\")\n",
    "\n",
    "print(f\"Initial texts:\\n{text}\")\n",
    "# A simple loop that loops through the list of sentences and adds\n",
    "# a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "for i in range(len(text)):\n",
    "    while len(text[i]) < maxlen:\n",
    "        text[i] += \" \"\n",
    "\n",
    "print(f\"Resulting texts:\\n{text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве входа будем использовать предложение без последнего символа:\n",
    "\n",
    "**'hey how are yo'**\n",
    "\n",
    "В качестве результата — предложение, в котором он сгенерирован:\n",
    "\n",
    "**'ey how are you'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "\n",
    "    # Remove first character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "\n",
    "    print(\"Input sequence:\".ljust(18), f\"'{input_seq[i]}'\")\n",
    "    print(\"Target sequence:\".ljust(18), f\"'{target_seq[i]}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь символы надо перевести в числа. Для этого мы уже построили словарь.\n",
    "\n",
    "P.S. Запускать блок только один раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "    print(\"Encodded input sequence:\".ljust(25), input_seq[i])\n",
    "    print(\"Encodded target sequence:\".ljust(25), target_seq[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь из чисел надо сделать вектора.\n",
    "\n",
    "Причина - подача чисел даст модели ложное знание об отношениях между объектами по типу \"*буква а в два раза больше буквы б*\". Нам же нужно равномерно распределить наши представления в некотором пространстве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/one_hot_encoding_softmax.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(text)\n",
    "\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "\n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features\n",
    "\n",
    "\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
    "print(\n",
    "    \"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(\n",
    "        input_seq.shape\n",
    "    )\n",
    ")\n",
    "print(input_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый символ закодировали вектором.\n",
    "Не слишком экономно, зато удобно умножать на матрицу весов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример: Language Modeling**\n",
    "\n",
    "Кодируем буквы при помощи **one-hot кодирования** и подаем на входной слой.\n",
    "\n",
    "$\\begin{bmatrix} w_{11} & w_{12} & w_{13} & w_{14} \\\\ w_{21} & w_{22} & w_{23} & w_{24} \\\\ w_{31} & w_{32} & w_{33} & w_{34} \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 0\\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} w_{11} \\\\ w_{21} \\\\ w_{31}\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, обработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/language_modeling.png\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Умножение матрицы на one-hot представление просто достает соответствующую ненулевому значению колонку из матрицы весов.\n",
    "Поэтому часто вместо напсания двух отдельных слоев (one-hot + линейного) делают просто слой, называемый **Embedding Layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "import torch\n",
    "\n",
    "input_seq = torch.Tensor(input_seq)\n",
    "target_seq = torch.Tensor(target_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NextCharacterGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size=hidden_dim, batch_first=True)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden_0 = torch.zeros(\n",
    "            1, batch_size, self.rnn.hidden_size\n",
    "        )  # 1 correspond to number of layers\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden_0)\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # Need Only if n_layers > 1\n",
    "        out = out.contiguous().view(-1, self.rnn.hidden_size)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = NextCharacterGenerator(\n",
    "    input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1\n",
    ")\n",
    "\n",
    "# Define hyperparameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training Run\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    optimizer.zero_grad()  # Clears existing gradients from previous epoch\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward()  # Does backpropagation and calculates gradients\n",
    "    optimizer.step()  # Updates the weights accordingly\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}/{num_epochs}\".ljust(20), end=\" \")\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "\n",
    "    out, hidden = model(character)\n",
    "    # print(out.shape)\n",
    "    # print(out)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden\n",
    "\n",
    "\n",
    "def sample(model, out_len, start=\"hey\"):\n",
    "    model.eval()  # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for _ in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return \"\".join(chars)\n",
    "\n",
    "\n",
    "sample(model, 15, \"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сгенерировать несколько вариантов предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    print(sample(model, 15, \"good\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так получается, потому что сеть инициализирована нулями и никакой случайности нет. Даже если мы добавим в датасет ещё предложение, начинающиеся с *good*, результат не изменится. Также сеть переобучилась на небольшом датасете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Представление данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из ключевых этапов в обработке текста — **токенизация**. На этом этапе происходит разделение текста на отдельные единицы — предложения и слова. Затем создается словарь, в который заносятся уникальные лексемы, встретившиеся в корпусе или тексте. На этих этапах можно столкнуться с несколькими проблемами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблема 1. Размер словаря**\n",
    "\n",
    "Самый простой способ токенизации — назначить каждому уникальному слову своё число. Но есть проблема: слов и их форм миллионы, и поэтому словарь таких слов получится чересчур большим, а это будет затруднять обучение модели.\n",
    "\n",
    "Можно разбивать текст не на слова, а на отдельные буквы (char-level tokenization), тогда в словаре будет всего несколько десятков токенов, НО в таком случае уже сам текст после токенизации будет слишком длинным, а это тоже затрудняет обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблема 2. Богатая морфология**\n",
    "\n",
    "\"Нейросеть\", \"сетка\", \"сеть\" являются разными словами, но имеют схожий смысл. Эту проблему классически всегда решал этап **стемминга** (удаление суффикса, приставки, окончания) или **лемматизации** (приведение слова к канонической форме)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблема 3. Сложные слова**\n",
    "\n",
    "Но все проблемы эти этапы не решают. В германских языках (в английском, немецком, шведском и т.д.) очень продуктивно образуются новые сложные слова. Значения таких слов выводятся из значения их элементов. Их можно создавать бесконечно долго, и большинство из них не зафиксировано в «бумажном» словаре."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/swedish_word_example.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Пример шведского названия гаечного ключа для колеса мотоцикла</a></em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://sysblok.ru/nlp/7250/\">Как работает алгоритм токенизации текстов для нейросетей</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с этими языками сложность также возникает на этапе составления словаря. При составлении словаря модели ориентируются на частотность (например, сохраняем слово, если оно встретилось чаще пяти раз), поэтому не будут запоминать такое длинное и сложное слово."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблема 4: Границы слова**\n",
    "\n",
    "Для нас, привыкших к языкам европейского типа, слово — это набор букв между пробелами и знаками препинания. Но в английском языке многие сложные слова пишутся раздельно, а в японском, наоборот, между словами вообще нет пробелов. Поэтому универсальный токенизатор создать было нелегко."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "**TF-IDF** — способ численного представления документа, оценивает  **важность слова в контексте документа**. Состоит из двух множителей $TF$ и $IDF$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://blog.kakaocdn.net/dn/xhdum/btqUcAe9hDS/JhnUIdWxKuhZOrNYjbV3PK/img.png\" width=\"500\"></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая идея, которая стоит за **TF-IDF** — это **если слово часто встречается в документе, оно важное**. За это отвечает $TF$.\n",
    "\n",
    "$TF$ (term frequency) — частота вхождения слова в документ, для которого рассчитывается значение:\n",
    "\n",
    "$$\\large TF(t, d) = \\frac{n_t}{\\sum_{k}n_k}$$\n",
    "\n",
    "$n_t$ — количество повторов слова $t$ в документе $d$,\n",
    "\n",
    "$\\sum_{k}n_k$ — общее количество слов  $t$ в документе $d$ с повторами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая идея **TF-IDF** — **если слово встречается во многих документах, его ценность снижается**.\n",
    "\n",
    "Пример: местоимения встречаются в большинстве текстов, но не несут смысловой нагрузки.\n",
    "\n",
    "За это отвечает $IDF$.\n",
    "\n",
    "$IDF$ (inverse document frequency) — логарифм обратной частоты вхождения слова в документы.\n",
    "$$\\large IDF(t, D) = \\log{\\frac{|D|}{|\\{d_i \\in D| t_i \\in d_i \\}|}}$$\n",
    "\n",
    "где $|D|$ — число документов в коллекции,\n",
    "$|\\{d_i \\in D| t_i \\in d_i \\}|$ — число документов в коллекции со словом $t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая формула:\n",
    "$$\\large TF-IDF(t, d, D) = TF(t,d)⋅IDF(t, D)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Пример работы `TfidfVectorizer` из [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "Каждому документу сопоставляется вектор, равный длине словаря. Ненулевые значения вектора хранятся в виде разреженных матриц [‘scipy.sparse.csr_matrix’](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"Tf-idf dictionary:\", vectorizer.get_feature_names_out())\n",
    "print(\"Tf-idf dictionary len:\", len(vectorizer.get_feature_names_out()))\n",
    "print(\"Tf-idf shape:\", x.shape)\n",
    "print(\"Tf-idf type:\", type(x))\n",
    "print(\"Tf-idf values:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На практике**\n",
    "\n",
    "1. Тексты токенизируются и нормализуются. Если мы решаем работать с N-граммами, то вместо токенизации или после неё выделяем N-граммы.\n",
    "\n",
    "2. Проходимся по всей коллекции документов и, для каждого слова, подсчитываем, в каком количестве документов оно встретилось. Если у нас большая коллекция, то словарь может получиться просто гигантским, особенно если мы работаем с N-граммами, поэтому периодически, во время построения, или после этой процедуры, мы должны выбросить из словаря всё, что считаем неинформативным — слишком редкие и слишком частые слова.\n",
    "\n",
    "3. Затем начинаем строить матрицу признаков. Каждая строчка этой матрицы соответствует документу, а каждый столбец — статистике встречаемости этого слова в документе. Таким образом, для каждого документа мы считаем частоты слов в нём и записываем в соответствующие ячейки таблички веса слов по указанной формуле.\n",
    "\n",
    "4. Переходим к следующему документу.\n",
    "\n",
    "Таким образом, TF-IDF — это способ взвешивания и отбора категориальных признаков в задачах машинного обучения — не только в классификации и не только для текстов. Надо заметить, что TF-IDF никак не использует информацию о метке объекта — это одновременно и преимущество, и недостаток. Преимущество заключается в том, что мы можем использовать TF-IDF, не имея меток, то есть задачах обучения без учителя. Недостаток — в том, что мы теряем информацию или недостаточно эффективно её используем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[wiki] TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF)\n",
    "\n",
    "[[code] sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "\n",
    "[Ещё несколько способов взвешивания и отбора признаков](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "\n",
    "[TF-IDF Vectorizer scikit-learn](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Когда TF-IDF может быть неэффективен:**\n",
    "\n",
    "1. **Отсутствие семантической информации**: TF-IDF не учитывает семантические связи между словами, что может привести к ограниченной способности понимания смысла текста.\n",
    "\n",
    "2. **Чувствительность к длине** документа: Длинные документы могут иметь более высокие значения TF, даже если ключевые слова встречаются реже. В таких случаях, TF-IDF может недооценить важность конкретных слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/3da/0ff/e98/3da0ffe9857230b81b0a037120285550.png\" width=\"400\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/585838/\">Семантика и технология Word2Vec</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec — нейронная сеть из двух слоев, которая обрабатывает текст, преобразуя его в числовые “векторизованные” слова. Входные данные w2v — это громадный текстовый корпус, из которого на выходе мы получаем пространство векторов (линейное пространство), размерность которого обычно достигает сотен, где каждое уникальное слово в корпусе представлено вектором из сгенерированного пространства.\n",
    "\n",
    "Мы учим сеть так, что вектора, соответствующие похожим словам, располагаются близко в новом пространстве. И над ними работают векторные операции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://habrastorage.org/r/w1560/getpro/habr/post_images/a19/84b/fea/a1984bfeab5a597c6fb6300f7d694901.png\" width=\"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/446530/\">Word2vec в картинках</a></em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такие операции не приводят к точному соответствию, однако получаемые вектора оказываются самыми похожими."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Подробное руководство по использованию Word2Vec](https://colab.research.google.com/drive/1OJF0k-E60sp9Vyoj1yWuoedGTrwRiTyj?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Слой эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы применяли OneHotEncoding для представления наших слов. Проблемы возникают, когда пространство объектов начинает расти и у нас возникают огромные разреженные матрицы.\n",
    "\n",
    "Кроме того, некоторые объекты у нас сразу могут быть ближе: семантически \"король\" и \"королева\" отличаются только полом, различие между словами \"король\" и \"стул\" заметно выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому мы можем переводить наши слова в вектора меньшей размерности, которые при этом будут сравнимы между собой с помощью модуля [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html).\n",
    "\n",
    "[Туториал PyTorch по применению эмбедингов в NLP](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html).\n",
    "\n",
    "[NLP Course for you](https://lena-voita.github.io/nlp_course.html)\n",
    "\n",
    "[Курс по NLP от ШАД](https://github.com/yandexdataschool/nlp_course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/word_representation_intro_min.png\" width=\"600\">\n",
    "\n",
    "<em>Source: <a href=\"https://lena-voita.github.io/nlp_course/word_embeddings.html\">Lena Voita NLP Course</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/lookup_table.gif\" width=\"600\">\n",
    "\n",
    "<em>Source: <a href=\"https://lena-voita.github.io/nlp_course/word_embeddings.html\">Lena Voita NLP Course</a></em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say you have 2 sentences (lowercased, punctuations removed):\n",
    "sentences = \"i am new to pytorch i am having fun\"\n",
    "\n",
    "words = sentences.split(\" \")\n",
    "\n",
    "print(f\"All words: {words} \\n\")\n",
    "\n",
    "vocab = set(words)  # create a vocabulary\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"Vocabulary (unique words): {vocab} \\n\")\n",
    "print(f\"Vocabulary size: {vocab_size} \\n\")\n",
    "\n",
    "# map words to unique indices\n",
    "word2idx = {word: ind for ind, word in enumerate(vocab)}\n",
    "\n",
    "print(f\"Word-to-id dictionary: {word2idx} \\n\")\n",
    "\n",
    "encoded_sentences = [word2idx[word] for word in words]\n",
    "\n",
    "print(f\"Encoded sentences: {encoded_sentences}\")\n",
    "\n",
    "# let's say you want embedding dimension to be 3\n",
    "emb_dim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нейросетевой слой эмбеддингов может быть определён так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "emb_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "\n",
    "word_vectors = emb_layer(torch.LongTensor(encoded_sentences))\n",
    "\n",
    "print(f\"Shape of encoded sentences: {word_vectors.shape} \\n\")\n",
    "\n",
    "print(f\"Shape of weigths: {emb_layer.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этод код инициализирует эмбеддинги согласно нормальному распределению (со средним значением 0 и дисперсией 1). Таким образом, пока что никакого различия или сходства между векторами нет.\n",
    "\n",
    "`word_vectors` — тензор размером (9,3). 9 слов в датасете, размер 3 задан нами.\n",
    "\n",
    "`emb_layer` имеет 1 обучаемый параметр `weight`, который по умолчанию True. Можем проверить так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы не хотим обучать этой слой (например, используем заранее обученные эмбеддинги), мы можем заморозить его веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы хотим использовать заранее определённые веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predefined weights\n",
    "weight = torch.FloatTensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])\n",
    "print(weight.shape)\n",
    "embedding = nn.Embedding.from_pretrained(weight)\n",
    "# get embeddings for ind 0 and 1\n",
    "embedding(torch.LongTensor([0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем уже готовые веса модели Word2Vec, обученные на датасете Google News, состоящeм из 100 миллиардов слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this way for fast loading from Google Drive\n",
    "!gdown \"1ooLZnU8J54YzHtG5xXb3iDnY_TwIOY2K\"\n",
    "\n",
    "# Use this way for loading from our host\n",
    "# !wget https://edunet.kea.su/repo/EduNet-web_dependencies/weights/GoogleNews-vectors-negative300.bin.gz\n",
    "\n",
    "!gunzip -q GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wordvector_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "word_vectors = KeyedVectors.load_word2vec_format(wordvector_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor(word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding.from_pretrained(weight)\n",
    "\n",
    "input = torch.LongTensor([0, 1])\n",
    "\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также мы можем воспользоваться библиотектой [torchtext](https://pytorch.org/text/stable/index.html). Возьмём таблицу весов поменьше, всего 10000 наиболее встречающихся слов. Зададим длину тензора — 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "\n",
    "glove = torchtext.vocab.GloVe(\n",
    "    name=\"6B\", dim=50, max_vectors=10000\n",
    ")  # use 10k most common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если обратиться к документации, мы увидим, что 6В — это [лишь один из вариантов весов](https://pytorch.org/text/stable/_modules/torchtext/vocab/vectors.html#GloVe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_emb = nn.Embedding.from_pretrained(glove.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.LongTensor([0, 1])\n",
    "glove_emb(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код нейросети со слоем nn.Embedding выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_with_Embedding_Layer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNN_with_Embedding_Layer, self).__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(glove.vectors)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Look up the embedding\n",
    "        x = self.emb(x)\n",
    "        # Set an initial hidden state\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        # Forward propagate the RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Pass the output of the last time step to the classifier\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "model = RNN_with_Embedding_Layer(input_size=50, hidden_size=128, num_classes=3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Размер словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер словаря - гиперпараметр. Как его выбрать?\n",
    "\n",
    "**Закон Ципфа**  — эмпирическая закономерность распределения частоты слов естественного языка: если все слова языка в достаточно большом осмысленном тексте упорядочить по убыванию частоты их использования, то частота слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру. Плотность распределения Ципфа:\n",
    "\n",
    "$$f(rank, s, N) = \\frac {1}{Z(s,N)rank^s}$$\n",
    "\n",
    "где $rank$ - порядковый номер слова после сортировки по убыванию частоты, $s$ - коэффициент скорости убывания вероятности, $N$ - количество слов, $Z(s,N)= \\sum ^N _{i=1} i^{-s}$ - нормализационная константа.\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/zipfs_law.jpg\" width=\"500\"></center>\n",
    "\n",
    "[Zipf’s law in 50 languages](https://arxiv.org/ftp/arxiv/papers/1807/1807.01855.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из этого всего можно сделать два практических вывода:\n",
    "\n",
    "* частотных слов очень мало\n",
    "* редких слов очень много.\n",
    "\n",
    "**Частотные** - слабо информативны, так как встречаются практически во всех документах.\n",
    "\n",
    "**Редкие** - слова очень редки, и поэтому они **ненадёжны** в качестве факторов при принятии решений.\n",
    "\n",
    "Следовательно, нужно придерживаться баланса **частотности** и **информативности**. Основная идея в том, что чем чаще слово встречается в документе, тем более оно характерно для этого документа, тем лучше описывает его тематику. С другой стороны, чем это слово реже встречается в корпусе, в выборке документов, тем оно более специфично и информативно. За этот баланс отвечают две величины: TF и IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byte Pair Encoding\n",
    "\n",
    "Изначально алгоритм компрессии BPE позволяет моделям узнавать как можно больше слов при ограниченном объеме словаря.\n",
    "\n",
    "1.   Слово = последовательность токенов\n",
    "2.   Словарь = все токены\n",
    "3.   Повторять, пока не достигли ограничения на размер словаря:\n",
    "\n",
    "     Назначаем новым токеном объединение двух существующих токенов, которое\n",
    "встречается чаще других пар в корпусе (встречаются вместе)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В применении BPE возможны разные варианты. Один из естественных – идём по всем токенам по убыванию частоты, находим соответствующую последовательность символов в корпусе, заменяем на токен."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/subword_tokenization.png\" width = \"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://alexanderdyakonov.wordpress.com/2019/11/29/токенизация-на-подслова-subword-tokenization/\">Токенизация на подслова (Subword Tokenization)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот же способ помогает решить **проблему** **OOV (out of vocabulary)**. В обучающей выборке может не быть слова *Unfriendly*, но поскольку **Unfriendly** = **Un** + **friend** + **ly**, мы можем рассчитывать, что сеть будет правильно обрабатывать / генерировать и слово целиком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/token_unfriendly.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.thoughtvector.io/blog/subword-tokenization/\">Subword Tokenization — Handling Misspellings and Multilingual Data</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аугментация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели глубокого обучения обычно требуют большого количества данных для обучения.\n",
    "\n",
    "Вместо того, чтобы тратить дни на сбор данных вручную, мы можем использовать методы аугментации для автоматической генерации новых примеров из уже имеющихся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важный момент**: при обучении модели мы используем разбиение данных на `train-val-test`. Аугментации стоит применять только на `train`. Почему так? Конечная цель обучения нейросети — это применение на реальных данных, которые сеть не видела. Поэтому для адекватной оценки качества модели валидационные и тестовые данные изменять не нужно.\n",
    "\n",
    "В любом случае, `test` должен быть отделен от данных еще до того, как они попали в `DataLoader` или нейросеть.\n",
    "\n",
    "Другое дело, что аугментации на тесте можно использовать как метод ансамблирования в случае классификации. Можно взять sample → создать несколько его копий → по-разному их аугментировать → предсказать класс на каждой из этих аугментированных копий → а потом выбрать наиболее вероятный класс голосованием (такой функционал реализован, например, в [YOLOv5](https://github.com/ultralytics/yolov5/blob/d204a61834d0f6b2e73c1f43facf32fbadb6b284/models/yolo.py#L121), о которой речь пойдет в следующих лекциях)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аудио"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим несколько примеров аугментаций аудио. С полным списком можно ознакомиться здесь: [[git] audiomentations](https://github.com/iver56/audiomentations).\n",
    "\n",
    "Импортируем библиотеку и посмотрим на пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/content\")\n",
    "\n",
    "!pip install -q audiomentations\n",
    "\n",
    "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/audio_example.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Get input audio\n",
    "input_audio = \"/content/audio_example.wav\"\n",
    "\n",
    "display(Audio(input_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "data, sr = librosa.load(\"/content/audio_example.wav\")  # sr - sampling rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background Noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import AddGaussianSNR\n",
    "\n",
    "augment = AddGaussianSNR(min_snr_in_db=3, max_snr_in_db=7, p=1)\n",
    "\n",
    "# Augment/transform the audio data\n",
    "augmented_data = augment(samples=data, sample_rate=sr)\n",
    "\n",
    "display(Audio(augmented_data, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним волновые картины и спектрограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import spectrogram\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def produce_plots(input_audio_arr, aug_audio, sr):\n",
    "    f, t, Sxx_in = spectrogram(\n",
    "        input_audio_arr, fs=sr\n",
    "    )  # Compute spectrogram for the original signal (f - frequency, t - time)\n",
    "    f, t, Sxx_aug = spectrogram(aug_audio, fs=sr)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 5))\n",
    "\n",
    "    ax[0, 0].plot(input_audio_arr)\n",
    "    ax[0, 0].set_xlim(0, len(input_audio_arr))\n",
    "    ax[0, 0].set_xticks([])\n",
    "    ax[0, 0].set_title(\"Original audio\")\n",
    "\n",
    "    ax[0, 1].plot(aug_audio)\n",
    "    ax[0, 1].set_xlim(0, len(input_audio_arr))\n",
    "    ax[0, 1].set_xticks([])\n",
    "    ax[0, 1].set_title(\"Augmented  audio\")\n",
    "\n",
    "    ax[1, 0].imshow(\n",
    "        np.log(Sxx_in),\n",
    "        extent=[t.min(), t.max(), f.min(), f.max()],\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"inferno\",\n",
    "    )\n",
    "    ax[1, 0].set_ylabel(\"Frequecny, Hz\")\n",
    "    ax[1, 0].set_xlabel(\"Time,s\")\n",
    "\n",
    "    ax[1, 1].imshow(\n",
    "        np.log(Sxx_aug, where=Sxx_aug > 0),\n",
    "        extent=[t.min(), t.max(), f.min(), f.max()],\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"inferno\",\n",
    "    )\n",
    "    ax[1, 1].set_ylabel(\"Frequecny, Hz\")\n",
    "    ax[1, 1].set_xlabel(\"Time,s\")\n",
    "\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "produce_plots(data, augmented_data, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import TimeStretch\n",
    "\n",
    "augment = TimeStretch(min_rate=0.8, max_rate=1.5, p=1)\n",
    "augmented_data = augment(data, sample_rate=sr)\n",
    "\n",
    "display(Audio(augmented_data, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_plots(data, augmented_data, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitch Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение тональности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import PitchShift\n",
    "\n",
    "augment = PitchShift(min_semitones=1, max_semitones=12, p=1)\n",
    "augmented_data = augment(data, sample_rate=sr)\n",
    "\n",
    "display(Audio(augmented_data, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Совмещаем несколько аугментаций вместе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае с картинками, мы можем совмещать несколько аугментаций вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, Shift\n",
    "\n",
    "augment = Compose(\n",
    "    [\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=1),\n",
    "        TimeStretch(min_rate=0.8, max_rate=1.25, p=1),\n",
    "        PitchShift(min_semitones=-4, max_semitones=4, p=1),\n",
    "        # Shift(min_fraction=-0.5, max_fraction=0.5, p=1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmented_data = augment(data, sample_rate=sr)\n",
    "\n",
    "display(Audio(augmented_data, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_plots(data, augmented_data, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительные библиотеки для аугментации звука (и волновых функций в целом):\n",
    "- [torchaudio](https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html)\n",
    "- [torch-audiomentations](https://github.com/asteroid-team/torch-audiomentations)\n",
    "- [AugLy](https://github.com/facebookresearch/AugLy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь рассмотрим несколько примеров аугментаций текста. С полным списком можно ознакомиться здесь: [[git] библиотеки](https://github.com/makcedward/nlpaug)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input text\n",
    "text = \"Hello, future of AI for Science! How are you today?\"\n",
    "print(f\"input text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аугментация символов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменой на похоже выглядящие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "\n",
    "augment = nac.OcrAug()\n",
    "augmented_text = augment.augment(text)\n",
    "\n",
    "print(f\"Original:\\n{text}\")\n",
    "print(f\"Augmented Texts:\\n{augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С опечатками, которые учитывают расположение символов на клавиатуре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = nac.KeyboardAug()\n",
    "augmented_text = augment.augment(text)\n",
    "\n",
    "print(f\"Original:\\n{text}\")\n",
    "print(f\"Augmented Texts:\\n{augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аугментация слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С орфографическими ошибками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "augment = naw.SpellingAug()\n",
    "augmented_text = augment.augment(text, n=3)\n",
    "\n",
    "print(f\"Original:\\n{text}\")\n",
    "print(f\"Augmented Texts:\\n{augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием модели для предсказания новых слов в зависимости от контекста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# model_type: word2vec, glove or fasttext\n",
    "augment = naw.ContextualWordEmbsAug(model_path=\"bert-base-uncased\", action=\"insert\")\n",
    "augmented_text = augment.augment(text)\n",
    "\n",
    "clear_output()\n",
    "print(f\"Original:\\n{text}\")\n",
    "print(f\"Augmented Texts:\\n{augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аугментация предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем перевести текстовые данные на какой-либо язык, а затем перевести их обратно на язык оригинала. Это может помочь сгенерировать текстовые данные с разными словами, сохраняя при этом контекст текстовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name=\"facebook/wmt19-en-de\", to_model_name=\"facebook/wmt19-de-en\"\n",
    ")\n",
    "augmented_text = back_translation_aug.augment(text)\n",
    "\n",
    "clear_output()\n",
    "print(f\"Original:\\n{text}\")\n",
    "print(f\"Augmented Texts:\\n{augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Instance Crossover Augmentation* — составление новых объектов класса из отдельных предложений того же класса. Например, есть два объекта одного класса \"положительный отзыв\":\n",
    "- <font color='red'>очень удобное приложение. Мне понравилось им пользоваться</font>\n",
    "- <font color='green'>класс! Отличный интерфейс</font>\n",
    "\n",
    "Тогда можно составить новый объект того же класса из их частей:\n",
    "- <font color='red'>очень удобное приложение!</font> <font color='green'>Отличный интерфейс</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно: при любых аугментациях текста на уровне предложений есть шанс создать странные и нелогичные объекты, поэтому использовать их следует с особой осторожностью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительные  библиотеки для аугментации текста:\n",
    "\n",
    "- [TextAugment](https://github.com/dsfsi/textaugment)\n",
    "- [AugLy](https://github.com/facebookresearch/AugLy)\n",
    "\n",
    "[Обзор методов аугментации текста с примерами](https://amitness.com/2020/05/data-augmentation-for-nlp/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NLP метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Цикл постов об NLP-метриках](https://habr.com/ru/articles/745642/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глобально метрики качества машинного перевода можно подразделить на **традиционные** и **нейросетевые**.\n",
    "\n",
    "1. Традиционные метрики сравнительно просты в расчете и прозрачны, наиболее известные из них разработаны до бума нейросетей. Чаще всего такие метрики основаны на подсчете числа совпадений символов / слов / cловосочетаний – их называют «lexic overlap metrics».\n",
    "\n",
    "2. Большинство метрик, предложенных после 2016 года – нейросетевые. Первым шагом в применении нейросетей в расчете метрик стало использование векторных представлений слов (embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/nlp_metrics.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня наиболее используемые – метрики, предложенные до 2010 года, причем в 99% это BLEU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Традиционные метрики\n",
    "\n",
    "Наиболее известны и употребимы такие традиционные метрики как: BLEU, NIST, ROUGE, METEOR, TER, chrF, chrF++, RIBES.\n",
    "\n",
    "**BLEU**\n",
    "\n",
    "BLEU (BiLingual Evaluation Understudy) — метрика, разработанная в IBM (Papineni et al.) в 2001. Основана на подсчете слов (unigrams) и словосочетаний (n‑grams) из машинного перевода, также встречающихся в эталоне. Далее это число делится на общее число слов и словосочетаний в машинном переводе — получается precision. К итоговому precision применяется корректировка — штраф за краткость (brevity penalty), чтобы избежать слишком высоких оценок BLEU для кратких и неполных переводов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "candidate_corpus = [['My', 'full', 'pytorch', 'test'], ['Another', 'Sentence']]\n",
    "references_corpus = [[['My', 'full', 'pytorch', 'test'], ['Completely', 'Different']], [['No', 'Match']]]\n",
    "print (bleu_score(candidate_corpus, references_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROUGE**\n",
    "\n",
    "ROUGE (Recall-Oriented Understudy for Gisting Evaluation) – серия метрик, предложенная Chin-Yew Lin в 2004 для оценки качества решения задачи суммаризации текста.\n",
    "\n",
    "Как и BLEU, ROUGE основаны на подсчете совпадений слов и словосочетаний в машинном переводе и в эталоне. Но для ROUGE считается не только precision, но и recall, а также параметр F1. Это позволяет обойтись без штрафа за краткость.\n",
    "\n",
    "Разные метрики серии ROUGE различаются количеством слов, для которых ищутся совпадения:\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/rouge.png\" width=\"500\"> </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METEOR**\n",
    "\n",
    "METEOR (Metric for Evaluation of Translation with Explicit ORdering) – метрика качества машинного перевода, предложенная Banerjee and Lavie в 2005.\n",
    "\n",
    "Оценка основана на подсчете совпадений отдельных слов (unigrams), c расчетом precision, recall, а также обобщающего показателя гармонического среднего (Fmean). В качестве совпадений учитываются не только точные соответствия слов (как в BLEU или ROUGE), но и наличие однокоренных слов или синонимов.\n",
    "\n",
    "Итоговая метрика METEOR рассчитывается путем применения к Fmean штрафа за малую длину либо отсутствие совпадающих n-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача Sequence-to-Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем решить задачу **sequence-to-sequence**: преобразование последовательности $X$ длины $N$ в последовательность $Y$ длины $T$. $T$ **может быть не равно** $N$.\n",
    "\n",
    "Примеры **sequence-to-sequence** задач:\n",
    "*   машинный перевод,\n",
    "*   генерация ответа на вопрос,\n",
    "*   генерация описания картинки или видео.\n",
    "\n",
    "Для решения таких задач  можно использовать две **RNN**: **кодировщик** и **декодировщик**.\n",
    "* Задача **кодировщика**: обобщить информацию о **входной последовательности** $X = (x_1,..., x_N)$, сформировав **вектор контекста** $C$ фиксированного размера.\n",
    "* Задача **декодировщика**: используя информацию из $C$, сформировать **выходную последовательность** $Y = (y_1, ..., y_T)$.\n",
    "\n",
    "В качестве вектора $C$ можно использовать последнее **скрытое состояние** кодировщика $h_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом:\n",
    "\n",
    "* **вход** — последовательность  $\\large x_1, \\dots, x_N$;\n",
    "* **выход** — последовательность  $\\large y_1, \\dots, y_T$.\n",
    "\n",
    "Кодировщик на основании входной последовательности предсказывает **нулевое скрытое состояние декодировщика и вектор контекста** $\\large с$, который часто равен финальному скрытому состоянию кодировщика.\n",
    "\n",
    "**Кодировщик:** $\\large h_i = f_w(x_i, h_{i_1})$\n",
    "\n",
    "**Декодировщик:** $\\large s_t = g_u(y_{t-1}, s_{t-1}, c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/seq_to_seq_with_rnn.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом возникает следующая **проблема:** мы пропускаем информацию из входной последовательности через бутылочное горлышко — вектор фиксированного размера $h_N$. Что будет, если размер последовательности 1000?\n",
    "\n",
    "**Идея:** использовать новый вектор контекста на каждом шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном подходе мы используем один **вектор контекста** фиксированной длины $c$, в который собираем информацию со всей **входной последовательности** $(x_1,...,x_N)$.\n",
    "\n",
    "**Входная последовательность** может содержать как единицы, так и тысячи элементов. В задаче машинного перевода **входной последовательностью** может быть:\n",
    "* короткая фраза,\n",
    "* абзац “Войны и мира”.\n",
    "\n",
    "Контекст важен. Для генерации глагола в правильной форме нужно понимать, к какому существительному он относится, а для качественного перевода конца абзаца необходимо понимать, о чем шла речь в его начале."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблемы Sequence-to-Sequence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом возникают проблемы:\n",
    "- **Вектор контекста** $c$ фиксированной длины не может вместить любое количество информации, поэтому для длинных последовательностей качество будет ухудшаться.\n",
    "- На каждой итерации декодировщика **скрытое состояние** $s_t$ должно сохранять информацию о том, какие элементы **выходной последовательности** уже были сгенерированы. Если $s_t$ не способно вместить эту информацию, модель может зациклиться или потерять часть **выходной последовательности**.\n",
    "\n",
    "**Вектор контекста** $c$ и **скрытые состояния** декодировщика $s_t$ являются “бутылочными горлышками” модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Официальный туториал от Pytorch](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "\n",
    "[Дополнительно](\n",
    "https://pytorch.org/tutorials/beginner/torchtext_translation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все файлы представлены в формате Unicode, поэтому для упрощения мы преобразуем символы Unicode в ASCII, сделаем все строчными и уберём большую часть знаков препинания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим файл на строки, а строки на пары."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -q https://raw.githubusercontent.com/L1aoXingyu/seq2seq-translation/master/data/eng-fra.txt\n",
    "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/eng-fra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = (\n",
    "        open(\"%s-%s.txt\" % (lang1, lang2), encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "    )\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split(\"\\t\")] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для скорости сократим датасет до предложений не длинее 10 слов, и отфильтруем апострофы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \",\n",
    "    \"i m \",\n",
    "    \"he is\",\n",
    "    \"he s \",\n",
    "    \"she is\",\n",
    "    \"she s \",\n",
    "    \"you are\",\n",
    "    \"you re \",\n",
    "    \"we are\",\n",
    "    \"we re \",\n",
    "    \"they are\",\n",
    "    \"they re \",\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return (\n",
    "        len(p[0].split(\" \")) < MAX_LENGTH\n",
    "        and len(p[1].split(\" \")) < MAX_LENGTH\n",
    "        and p[1].startswith(eng_prefixes)\n",
    "    )\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(\"eng\", \"fra\", True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь в нашем распоряжении есть два словаря и набор пар строк.\n",
    "Определим структуру модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодировщик-декодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо one_hot - векторов, используются [эмбеддинги](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html) размером 1x256 (hidden size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(\n",
    "            batch_size, 1, dtype=torch.long, device=device\n",
    "        ).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = self.forward_step(\n",
    "                decoder_input, decoder_hidden\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(\n",
    "                    -1\n",
    "                ).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return (\n",
    "            decoder_outputs,\n",
    "            decoder_hidden,\n",
    "            None,\n",
    "        )  # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение\n",
    "\n",
    "В на вход модели будем подавать индексы слов для первой части пары из одного словаря, а на выходе ожидать индексы для соответствующей пары из другого."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData(\"eng\", \"fra\", True)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, : len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, : len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(\n",
    "        torch.LongTensor(input_ids).to(device), torch.LongTensor(target_ids).to(device)\n",
    "    )\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, sampler=train_sampler, batch_size=batch_size\n",
    "    )\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion\n",
    "):\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (- %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "\n",
    "def train(\n",
    "    train_dataloader,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    n_epochs,\n",
    "    learning_rate=0.001,\n",
    "    print_every=100,\n",
    "    plot_every=100,\n",
    "):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(\n",
    "            train_dataloader,\n",
    "            encoder,\n",
    "            decoder,\n",
    "            encoder_optimizer,\n",
    "            decoder_optimizer,\n",
    "            criterion,\n",
    "        )\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(\n",
    "                \"%s (%d %d%%) %.4f\"\n",
    "                % (\n",
    "                    timeSince(start, epoch / n_epochs),\n",
    "                    epoch,\n",
    "                    epoch / n_epochs * 100,\n",
    "                    print_loss_avg,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "plt.switch_backend(\"agg\")\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(\n",
    "            encoder_outputs, encoder_hidden\n",
    "        )\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append(\"<EOS>\")\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print(\">\", pair[0])\n",
    "        print(\"=\", pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = \" \".join(output_words)\n",
    "        print(\"<\", output_sentence)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, n_epochs=80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "plt.switch_backend(\"agg\")\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, _ = decoder(\n",
    "            encoder_outputs, encoder_hidden\n",
    "        )\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append(\"<EOS>\")\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print(\">\", pair[0])\n",
    "        print(\"=\", pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = \" \".join(output_words)\n",
    "        print(\"<\", output_sentence)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Пример работы с применением RNN в работе выпускника курса*\n",
    "\n",
    "В работе **Поиск артефактов на изображениях обзора ZTF при помощи нейронных сетей** решалась проблема траты огромного количества времени на ручное изучение изображений с кандидатами на значимые астрономические события.\n",
    "\n",
    "Загвоздка заключалась в том, что:\n",
    "\n",
    "* после алгоритмической предобработки слишком много артефактов в по типу проетевшего над телескопом самолёта;\n",
    "\n",
    "* каждый кандидат - серия кадров во времени, количество кадров на одно наблюдение различно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<center><img src =\"https://imageup.ru/img70/4648133/astro_encoder.png\"></center>\n",
    "\n",
    "\n",
    "\n",
    "<center><em>Source: <a href=\"https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fthumb.tildacdn.com%2Ftild3638-6534-4162-b637-383166656363%2F-%2Fresize%2F42x%2F-%2Fformat%2Fwebp%2Fpresentation.png\">Примеры артефактов и архитектура кодировщика. Семенихин Т. А., et al</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<center><img src =\"https://imageup.ru/img37/4648121/astro_rnn.png\" width=\"800\"></center>\n",
    "\n",
    "\n",
    "\n",
    "<center><em>Source: <a href=\"https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fthumb.tildacdn.com%2Ftild3638-6534-4162-b637-383166656363%2F-%2Fresize%2F42x%2F-%2Fformat%2Fwebp%2Fpresentation.png\">Семенихин Т. А., et al</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее:\n",
    "\n",
    "[[video] 📺 Видеозапись выступления](https://youtu.be/g_WeSLmyVO8)\n",
    "\n",
    "[[slides] 📊 Презентация](https://thumb.tildacdn.com/tild3638-6534-4162-b637-383166656363/-/resize/42x/-/format/webp/presentation.png)\n",
    "\n",
    "[[git] 🐾 Код](https://github.com/EduNetArchive/Semenikhin_RB_ZTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Литература</font>\n",
    "\n",
    "<font size = \"5\">Обучение на реальных данных</font>\n",
    "\n",
    "[How to avoid machine learning pitfalls: a guide for academic researchers (Lones, 2021)](https://arxiv.org/abs/2108.02497)\n",
    "\n",
    "[Understanding data augmentation for classification: when to warp? (Wong et al., 2016)](https://arxiv.org/abs/1609.08764)\n",
    "\n",
    "[Learning from class-imbalanced data: Review of methods and applications (Haixiang et al., 2017)](https://www.sciencedirect.com/science/article/abs/pii/S0957417416307175?via%3Dihub)\n",
    "\n",
    "<font size = \"5\">Как решить проблему маленького количества данных?</font>\n",
    "\n",
    "[Пост о том, как решать проблему малого количества данных](https://www.kaggle.com/code/rafjaa/dealing-with-very-small-datasets/notebook)\n",
    "\n",
    "<font size = \"5\">Несбалансированные данные</font>\n",
    "\n",
    "[SMOTE explained for noobs - Synthetic Minority Over-sampling TEchnique line by line](https://rikunert.com/SMOTE_explained)\n",
    "\n",
    "[Блог пост про 8 тактик борьбы с несбалансированными классами в наборе данных машинного обучения](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)\n",
    "\n",
    "[Метрики, разработаные для работы с несбалансированными классами.](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/#:~:text=Classification%20Accuracy%20is%20Not%20Enough%3A%20More%20Performance%20Measures%20You%20Can%20Use,-By%20Jason%20Brownlee&text=When%20you%20build%20a%20model,This%20is%20the%20classification%20accuracy)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
