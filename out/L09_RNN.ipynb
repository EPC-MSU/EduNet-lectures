{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Рекуррентные нейронные сети (RNN)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Особенности рекуррентных нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого мы работали с методами машинного обучения, которые работают с признаковым описанием **фиксированной длины**.\n",
    "\n",
    "Так правильно делать в случае **табличных данных** — обычно каждый объект в таблицах описан фиксированным набором признаков, и новые признаки не могут появиться \"вдруг\". Мы точно знаем, что на вход нам приходит объект размера 100, а на выходе мы должны для него предсказать 1 число.\n",
    "\n",
    "Верно это и про **изображения** — обычно нейронная сеть учится на изображениях определенного разрешения. Да, мы можем сделать нейросеть, которая способна работать с изображением почти любого разрешения, но добиваемся мы этого за счет вставки слоев **global pooling**, которые  приводят признаковое описание, полученное сверточную частью нейросети, к фиксированному размеру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако многие данные структурой фиксированной длины не обладают. К примеру, **тексты**. Возьмем все абзацы из \"Войны и Мира\". Какие-то будут больше, какие-то меньше. И обрезать их как-то нельзя. Аналогично будет и для текстов из Твиттера. И что делать, если мы хотим предсказывать, например, эмоциональную окрашенность текста?\n",
    "\n",
    "Или если на основе абзаца текста нам необходимо сгенерировать его **краткое содержание**? То, что нужно предсказать, может быть разной длины. Аналогичный вопрос возникает также в случае, если мы хотим по данным о курсе валюты за прошлый год спрогнозировать **курс валюты на следующий месяц** по дням."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/time_series_data.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует ряд задач, для которых необходима особая структура нейронной сети, позволяющая **принимать данные разного размера**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры задач"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Анализ временных рядов**\n",
    "- Табличные данные\n",
    "- Аннотирование изображений и видео (Image/Video captioning)\n",
    "- Машинный перевод\n",
    "- Распознавание текста\n",
    "- Распознавание речи\n",
    "\n",
    "\n",
    "**Генеративные модели**\n",
    "- Генерация текста/речи (например, чат-боты)\n",
    "- Генерация изображений\n",
    "\n",
    "**Классификация**\n",
    "- Изображения\n",
    "- Блоки текста (Sentiment analysis)\n",
    "\n",
    "**Анализ последовательностей**\n",
    "- Анализ текстов\n",
    "- Биологические последовательности\n",
    "- Химические последовательности\n",
    "\n",
    "\n",
    "Общее для задач — мы имеем возможность сохранять информацию, сформированную при обработке одной части объекта (**токена**), и использовать ее, когда мы анализируем другие части."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До прихода нейронных сетей предложения пытались описать при помощи набора правил — грамматик, которые довольно успешно могли генерировать новые осмысленные предложения. Так выглядит разбор при помощи грамматик простого предложения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/parse_tree.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увы, грамматики плохо учитывали высокоуровневые связи. Например, очень тяжело было добиться того, чтобы в абзаце текста:\n",
    "\n",
    "\"Леша пришел домой. Он будет есть рыбу.\"\n",
    "\n",
    "компьютер понял, что во втором предложении \"Он\" соответствует \"Леше\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основная идея**, на которой основано RNN, состоит в следующем: взять всю последовательность и пропустить через одну и ту же нейросеть.\n",
    "Но при этом сама нейросеть кроме следующего элемента последовательности (например, слова в тексте), будет принимать еще один параметр — некий $h$, который в начале будет, например, вектором из нулей, а далее — значением, которое выдает сама нейросеть после обработки очередного элемента последовательности (**токена**).\n",
    "\n",
    "Также далее мы будем использовать понятие **нулевого токена** — токена, который символизирует заплатку, токен, не несущий никакого смысла, но который иногда нужно передать модели. Например, как сигнал начала работы.\n",
    "\n",
    "В сети появляется новая сущность — **hidden state** ($h$) — вектор, хранящий состояние, учитывающее и локальный, и глобальный контекст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/rnn_idea.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network\">Recurrent neural network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом наша нейросеть может выдавать некий ответ на каждом шаге, но мы можем:\n",
    "\n",
    " 1. Использовать только выданный на последнем (если нам нужно предсказать одно значение) — **many-to-one**.\n",
    "\n",
    " 2. Мы можем подавать в наше нейросетку токены (когда кончился исходный сигнал, подаем нулевые токены), пока она не сгенерирует токен, символизирующий остановку (**many-to-many, one-to-many**).\n",
    "\n",
    " 3. Можем делать различные комбинации, игнорируя часть выходов нейросети в начале её работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **«One to one»** — обычная нейронная сеть, не обязательно применять RNN в таком случае.\n",
    "\n",
    "*   Более сложной является реализация **«one to many»**, когда у нас есть всего один вход, и нам необходимо сформировать несколько выходов. Такой тип нейронной сети актуален, когда мы говорим о **генерации музыки** или **текстов**. Мы задаем начальное слово или начальный звук, а дальше модель начинает самостоятельно генерировать выходы, в качестве входа к очередной ячейке рассматривая выход с прошлой ячейки нейронной сети.\n",
    "\n",
    "*   Если мы рассматриваем задачу **классификации**, то актуальна схема **«many to one»**. Мы должны проанализировать все входы нейронной сети и только в конце определиться с классом.\n",
    "\n",
    "*   Схема **«many to many»**, в которой количество выходов **равно** количеству входов нейронной сети. Обычно это задачи типа разметки исходной последовательности. Например, указать столицы городов, названия важных объектов, веществ и т.д., что относится к задачам вида NER (Named entity recogition).\n",
    "\n",
    "*   Схема **«many to many»**, в которой количество выходов нейронной сети **не равно** количеству входов. Это актуально в машинном переводе, когда одна и та же фраза может иметь разное количество слов в разных языках (т.е. это реализует схему кодировщик-декодировщик). Кодировщик получает данные различной длины — например, предложение на английском языке. С помощью скрытых состояний он формирует из исходных данных вектор, который затем передаётся в декодировщик. Последний, в свою очередь, генерирует из полученного вектора выходные данные — исходную фразу, переведённую на другой язык."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/one_or_many_to_one_or_many_ways.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно объединять разные подходы. Сначала генерируем некий $h$, который содержит сжатую информацию о том, что было подано в нейросеть, а затем подаем его в нейросеть «one to many», которая генерирует, к примеру, перевод того текста, что был подан первой части нейросети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/sequence_to_sequence.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Базовый RNN блок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим работу рекуррентной нейронной сети:\n",
    "1. На вход поступает некоторая последовательность $x = \\{x_1,...x_t,...,x_n\\}$, где $x_i$ — вектор фиксированной размерности. В ряде случаев этот вектор имеет размерность 1.\n",
    "\n",
    "2. Для каждого поступившего $x_t$ формируем скрытое состояние $h_t$, которое является функцией от предыдущего состояния $h_{t-1}$ и текущего элемента последовательности $x_t$:\n",
    "$$\\large h_t = f_W(h_{t-1}, x_t),$$\n",
    "где $W$  — это обучаемые параметры (веса).\n",
    "\n",
    "3. На основании рассчитанного скрытого состояния, учитывающего предыдущие значения  $x_i$, формируется выходная последовательность $y = \\{y_1,...y_t,...,y_k\\}$. Для формирования предсказания $y_t$ в текущий момент времени в модель могут быть добавлены полносвязные слои, принимающие на вход текущее скрытое состояние $h_t$.\n",
    "\n",
    "Ниже представлена простая RNN. В качестве функции активации используется тангенс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем обрабатывать последовательность элементов вектора $x$ за счет применения рекуррентной формулы на каждом шаге:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/rnn_basic_block.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Состояние состоит из вектора $h$, называемого скрытым состоянием:\n",
    "\n",
    "$\\large h_t = f_W(h_{t-1}, x_t),$\n",
    "\n",
    "$\\large \\quad \\quad \\quad \\color{grey}{\\downarrow \\text{(также может добавляться bias)}}$\n",
    "\n",
    "$\\large h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large y_t = W_{hy}h_t.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отличие** от слоев, с которыми мы уже сталкивались, состоит в том, что **на выходе мы получаем два объекта**: $y_t$ и $h_t$:\n",
    "\n",
    "$y_t$ — предсказание в текущий момент времени, например, метка класса,\n",
    "\n",
    "$h_t$ — контекст, в котором предсказание было сделано. Он может использоваться для дальнейших предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PyTorch для вычисления $h_t$ используется модуль [RNNCell](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html)\n",
    "\n",
    "$y_t$ в нем не вычисляется: предполагается, что для его получения в модель должен быть добавлен дополнительный линейный слой.\n",
    "\n",
    "**`input_size`** — размер элемента последовательности.\n",
    "\n",
    "В отличие от сверточных слоёв, это всегда вектор, а не тензор, поэтому **`input_size`** — скаляр.\n",
    "\n",
    "**`hidden_size`** — тоже скаляр. Он задает размер скрытого состояния, которое тоже является вектором. Фактически это количество нейронов в слое.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "rnn_cell = torch.nn.RNNCell(input_size=3, hidden_size=2)\n",
    "dummy_sequence = torch.randn((1, 3))  # batch, input_size\n",
    "h = rnn_cell(dummy_sequence)\n",
    "print(\"Inital shape:\".ljust(17), f\"{dummy_sequence.shape}\")\n",
    "print(\"Resulting shape:\".ljust(17), f\"{h.shape}\")  # hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно то, что описано в коде ниже.\n",
    "Для понятности в данном примере опущена батчевая обработка. Также для того, чтобы подобный код корректно заработал, [необходимо обернуть веса](https://stackoverflow.com/questions/50935345/understanding-torch-nn-parameter) в `torch.nn.Parameter` для регистрации параметров в модели.\n",
    "\n",
    "Начальное значение может быть инициализировано нулями, но лучше инициализировать случайными значениями, чтобы нейросеть хоть как-то меняла своё поведение. Или даже чем-то осмысленным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "# Simple RNNcell without a bias and batch support\n",
    "class SimplifiedRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        # Init weight matrix, for simplicity omit bias\n",
    "        self.W_hx = (\n",
    "            torch.randn(input_size, hidden_size) * 0.0001\n",
    "        )  # hidden_size == number of neurons\n",
    "        self.W_hh = (\n",
    "            torch.randn(hidden_size, hidden_size) * 0.0001\n",
    "        )  # naive initialization\n",
    "        self.h0 = torch.zeros((hidden_size))  # Initial hidden state\n",
    "\n",
    "    def forward(self, x, h=None):  # Without a batch dimension\n",
    "        if h is None:\n",
    "            h = self.h0\n",
    "        h = torch.tanh(torch.matmul(self.W_hx.T, x) + torch.matmul(self.W_hh.T, h))\n",
    "        return h\n",
    "\n",
    "\n",
    "simple_rnn_cell = SimplifiedRNNCell(input_size=3, hidden_size=2)\n",
    "h = simple_rnn_cell(dummy_sequence[0])  # No batch\n",
    "print(f\"Out = h\\n{h.shape} \\n{h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в последовательности всегда **несколько элементов**. И надо применить алгоритм к каждому.\n",
    "\n",
    "\n",
    "Поэтому RNNCell напрямую не используется. Для него есть обертка — [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html), которая обеспечивает последовательный вызов RNNCell для всех элементов последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN блок в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning: формат данных для RNN: длина последовательности, батч, размер объекта**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(input_size=3, hidden_size=2)  # batch_first = True\n",
    "dummy_batched_seq = torch.randn((2, 1, 3))  # seq_len, batch, input_size\n",
    "out, h = rnn(dummy_batched_seq)\n",
    "\n",
    "print(\"Inital shape:\".ljust(20), f\"{dummy_batched_seq.shape}\")\n",
    "print(\"Resulting shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Simple RNN without batching\n",
    "class SimplifiedRNNLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn_cell = SimplifiedRNNCell(input_size, hidden_size)\n",
    "\n",
    "    # Without a batch dimension x have shape seq_len * input_size\n",
    "    def forward(self, x, h=None):\n",
    "        all_h = []\n",
    "        for i in range(x.shape[0]):  # iterating over timestamps\n",
    "            h = self.rnn_cell(torch.Tensor(x[i]), h)\n",
    "            all_h.append(h)\n",
    "        return np.stack(all_h), h\n",
    "\n",
    "\n",
    "simple_rnn = SimplifiedRNNLayer(input_size=4, hidden_size=2)\n",
    "sequence = np.array(\n",
    "    [[0, 1, 2, 0], [3, 4, 5, 0]]\n",
    ")  # batch with one sequence of two elements\n",
    "\n",
    "out, h = simple_rnn(sequence)\n",
    "print(\"Inital shape:\".ljust(20), f\"{sequence.shape}\")\n",
    "print(\"Resulting shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберемся.\n",
    "\n",
    "Если у нас есть две последовательности:\n",
    "\n",
    "*   [1, 3, 2]\n",
    "*   [0, 4, 2]\n",
    "\n",
    "Чтобы обработать элемент \"3\", нам нужен hidden state, вычисленный по \"1\".\n",
    "\n",
    "То же самое для \"4\" — нужно обработать \"0\". Таким образом, по горизонтальной оси мы не можем паралелиться. Придётся параллелиться по вертикальной. Мы можем паралельно обработать первые элементы первой и второй последовательностей.\n",
    "\n",
    "К данным добавляется еще одно измерение — **размер последовательности**. Batch из 5 последовательностей по 6 объектов (размер объекта 3) в каждой будет выглядеть так (время идёт первой размерностью, поэтому поэлементно идём \"сверху вниз\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/rnn_batch.png\" width=\"700\">\n",
    "\n",
    "<em>Source: <a href=\"https://www.researchgate.net/publication/284579100_Session-based_Recommendations_with_Recurrent_Neural_Networks\">Session-based Recommendations with Recurrent Neural Networks</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри RNN модуля элементы последовательности обрабатываются последовательно:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://edunet.kea.su/repo/EduNet-content/L08/out/simple_rnn_h_state.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса при этом используются одни и те же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_seq = torch.randn((2, 1, 3))  #  seq_len, batch, input_size\n",
    "\n",
    "print(\"RNNCell\")\n",
    "rnn_cell = torch.nn.RNNCell(3, 2)\n",
    "print(\"Parameter\".ljust(10), \"Shape\")\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "    print(t.ljust(10), p.shape)\n",
    "\n",
    "cell_out = rnn_cell(dummy_seq[0, :, :])  # take first element from sequence\n",
    "print()\n",
    "print(\"Result shape =\".ljust(20), cell_out.shape)\n",
    "print(\"Hidden state shape =\".ljust(20), cell_out.shape)  # one hidden state\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "print(\"RNN\")\n",
    "rnn = torch.nn.RNN(3, 2)\n",
    "print(\"Parameter\".ljust(15), \"Shape\")\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t.ljust(15), p.shape)\n",
    "\n",
    "out, h = rnn(dummy_seq)\n",
    "\n",
    "print()\n",
    "print(\"Result shape =\".ljust(20), out.shape)  # h for all timestamps element\n",
    "print(\"Hidden state shape =\".ljust(20), cell_out.shape)  # h for last element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обратимся к [документации PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) и посмотрим, какие параметры есть у модуля RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слои (Stacked RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN блоки можно объединять в слои, накладывая их друг на друга. Для этой операции в `torch.nn.RNN` есть аргумент `num_layers`, с помощью которого можно указать количество слоёв.\n",
    "\n",
    "В представленной архитектуре нижний слой (а это всё ещё одна RNN-ячейка) обрабатывает букву *h*, передаёт свой hidden state в саму себя (направо, `h[0]`) и обрабатывает *е* и т.д. Кроме того, эта же ячейка передаёт своё состояние на вторую RNN-ячейку (наверх, `h[1]`), которая уже обрабатывает результат работы первой ячейки.\n",
    "\n",
    "На практике такая схема может приводить к взрыву или затуханию градиента, причём при проходе как по горизонтали, так и по вертикали. Об этом ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/L08/out/layers.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр **num_layers** задаёт количество RNN-ячеек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((2, 1, 3))  # seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3, 2, num_layers=3)\n",
    "\n",
    "# Weights matrix sizes not changed!\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t, p.shape)\n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print()\n",
    "print(\"Out:\\n\", out.shape)  # Hidden states for all elements from top layer\n",
    "print(\"h:\\n\", h.shape)  # Hidden states for last element for all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательность можно пропустить через сеть два раза: в прямом и обратном направлении. Для этого создаётся слой, аналогичный входному, для обратного направления, и результат двух слоёв конкатенируется.\n",
    "\n",
    "[A Beginner’s Guide on Recurrent Neural Networks with PyTorch](https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/L08/out/bidirectional.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((2, 1, 3))  # seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3, 2, bidirectional=True)\n",
    "\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t, p.shape)\n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print()\n",
    "print(\"Out:\\n\", out.shape)  # Concatenated Hidden states from both layers\n",
    "print(\n",
    "    \"h:\\n\", h.shape\n",
    ")  # Hidden states last element from  both : 2*num_layers*hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример прогнозирования временного ряда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- [How to Remove Non-Stationarity From Time Series](https://www.kaggle.com/code/bextuychiev/how-to-remove-non-stationarity-from-time-series)\n",
    "- [A Guide to Time Series Forecasting in Python](https://builtin.com/data-science/time-series-forecasting-python)\n",
    "- [How to Check if Time Series Data is Stationary with Python?](https://www.geeksforgeeks.org/how-to-check-if-time-series-data-is-stationary-with-python/)\n",
    "- [Complete Guide on Time Series Analysis in Python](https://www.kaggle.com/code/prashant111/complete-guide-on-time-series-analysis-in-python)\n",
    "- [Data transformations and forecasting models: what to use and when](https://people.duke.edu/~rnau/whatuse.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что общего у прогнозирования потребления электроэнергии домохозяйствами, оценки трафика на дорогах в определенные периоды, прогнозировании паводков и прогнозировании цены, по которой акции будут торговаться на фондовой бирже?\n",
    "\n",
    "Все они попадают под понятие данных временных рядов! Вы не можете точно предсказать любой из этих результатов без компонента «время». И по мере того, как в мире вокруг нас генерируется все больше и больше данных, прогнозирование временных рядов становится все более важной областью применения методов ML и DL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных\n",
    "[Time Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных\n",
    "\n",
    "Данные о количестве пассажиров за каждый месяц.\n",
    "[Dataset Air Passengers Number of air passengers per month](https://www.kaggle.com/rakannimer/air-passengers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/airline-passengers.csv\"\n",
    ")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = dataset.iloc[:, 1:2].values  # transform dataframe to numpy.array\n",
    "# plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data, label=\"Airline Passangers Data\")\n",
    "plt.title(\"Number of passengers per month\")\n",
    "plt.ylabel(\"#passengers\")\n",
    "plt.xlabel(\"Month\")\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на разбиение временного ряда на **train-val-test**.\n",
    "\n",
    "Если мы поделим ряд на отрезки, точки склейки будут легко предсказываться либо предыдущим, либо средним значением по отрезку. Нужно предсказывать крупные отрезки ряда. И помнить о том, что перемешивать данные нельзя — есть \"прошлое\" и \"будущее\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/fixed_partitioning.jpg\" width=\"700\">\n",
    "\n",
    "<em>Source: <a href=\"https://yuting3656.github.io/yutingblog/coursera-tensorflow-developer-professional-certificate/sequences-time-series-and-prediction/week01-03\">Coursera: Sequences, Time Series and Prediction with TensorFlow</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шкалирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max normalization\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "print(\"Initial statistics:\")\n",
    "print(\"Minimum value:\", repr(td_min).rjust(5))\n",
    "print(\"Maximum value:\", repr(td_max).rjust(5))\n",
    "\n",
    "training_data = (training_data - td_min) / (td_max - td_min)\n",
    "print(\"\\nResulting statistics:\")\n",
    "print(\"Minimum value:\", repr(training_data.min()).rjust(5))\n",
    "print(\"Maximum value:\", repr(training_data.max()).rjust(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование ансамблей данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы хотим научиться предсказывать следующие значение на основе предыдущих, нам нужно подготовить данные соответствующим образом.\n",
    "\n",
    "Разобьем весь массив данных на фрагменты вида\n",
    "\n",
    "$x \\to y$,\n",
    "\n",
    "где $x$ — это подпоследовательность, например, записи с 1-й по 8-ю, а $y$ — это значение из 9-й записи, то самое, которое мы хотим предсказать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# create data \"ensemble\"\n",
    "\n",
    "\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "        _x = data[i : (i + seq_length)]  # picking several sequential observations\n",
    "        _y = data[i + seq_length]  # picking the subsequent observation\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return torch.Tensor(np.array(x)), torch.Tensor(np.array(y))\n",
    "\n",
    "\n",
    "# set length of the ensemble; accuracy of the predictions and\n",
    "# speed perfomance almost always depend on it size\n",
    "seq_length = 8  # compare 2 and 32\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "print(\"Example of the obtained data:\\n\")\n",
    "print(\"Data corresponding to the first x:\")\n",
    "print(x[0])\n",
    "print(\"Data corresponding to the first y:\")\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря такому подходу мы можем работать с RNN моделью так же, как работали со сверточными моделями, подавая на вход такую подпоследовательность + результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разобьем на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(y) * 0.8)\n",
    "\n",
    "x_train = x[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "x_test = x[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"x shape:\", x_train.shape)\n",
    "print(\"y shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "print(\"x shape:\", x_test.shape)\n",
    "print(\"y shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на параметр **batch_first**. Он позволяет записывать данные в привычном формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AirTrafficPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size, hidden_size=hidden_size, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x: \",x.shape) # 108 x 8 x 1 : [batch_size, seq_len, input_size]\n",
    "        out, h = self.rnn(x)\n",
    "        # print(\"out: \", out.shape) # 108 x 8 x 4 : [batch_size, seq_len, hidden_size] Useless!\n",
    "        # print(\"h : \", h.shape) # 1 x 108 x 4 [ num_layers, batch_size, hidden_size]\n",
    "        y = self.fc(h)\n",
    "        # print(\"y\",y.shape) # 1 x 108 x 1\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря подготовке данных процесс обучения не будет отличаться от того, что мы использовали на прошедших занятиях.\n",
    "\n",
    "В силу того, что датасет маленький и все данные поместились в один batch, итерирования по batch-ам в явном виде здесь не происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_train(model, num_epochs=2000, learning_rate=0.01):\n",
    "    criterion = torch.nn.MSELoss()  # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        y_pred, h = model(x_train)  # we don't use h there, but we can!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # obtain the loss\n",
    "        loss = criterion(y_pred[0], y_train)  # for shape compatibility\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch},\".ljust(15), \"loss: %1.5f\" % (loss.item()))\n",
    "\n",
    "\n",
    "print(\"Simple RNN training process with MSE loss:\")\n",
    "input_size = 1\n",
    "hidden_size = 4\n",
    "rnn = AirTrafficPredictor(input_size, hidden_size)\n",
    "time_series_train(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_plot(train_predict):\n",
    "    data_predict = train_predict.data\n",
    "    y_data_plot = y.data\n",
    "\n",
    "    # Denormalize\n",
    "    data_predict = data_predict[0] * (td_max - td_min) + td_min\n",
    "    y_data_plot = y_data_plot * (td_max - td_min) + td_min\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.axvline(x=train_size, c=\"r\", linestyle=\"--\")\n",
    "    # shifting the curve as first y-value not correspond first value overall\n",
    "    plt.plot(seq_length + np.arange(y_data_plot.shape[0]), y_data_plot)\n",
    "    plt.plot(seq_length + np.arange(y_data_plot.shape[0]), data_predict)\n",
    "\n",
    "    plt.title(\"Number of passengers per month\")\n",
    "    plt.ylabel(\"#passengers\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "\n",
    "    plt.legend([\"Train/Test separation\", \"Real\", \"Predicted\"])\n",
    "    plt.grid(axis=\"x\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "rnn.eval()\n",
    "train_predict, h = rnn(x)\n",
    "time_series_plot(train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что модель в принципе справляется с задачей. Если подбирать размер hidden size, качество станет лучше. Или мы добьёмся того, что нейросеть будет предсказывать просто линию (большой hidden size — нейросеть выучивает, что нужно предсказывать следующее значение по предыщущему).\n",
    "\n",
    "Но посмотрим, как далее справятся более мощные архитектуры, и уже позднее напишем окончательные выводы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблемы RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретически, можно было бы сразу пропустить все данные через сеть и затем вычислить градиент, однако возникнут следующие проблемы:\n",
    "\n",
    " - большие последовательности не поместятся в памяти;\n",
    " - так как цепочка будет очень длинной, возникнет затухание/взрыв градиента;\n",
    " - по мере прохождения сигнала по цепи контекст затирается.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть длинная последовательность. Если мы сразу предсказываем, то в каждый момент времени нужно распространить Loss. И все ячейки нужно обновить во время backpropogation. Все градиенты нужно посчитать. Возникают проблемы, связанные с нехваткой памяти.\n",
    "\n",
    "Есть специальные тесты для проверки, контекст какой длины использует RNN при предсказании. Если мы делаем предсказание только в последней ячейке, может оказаться, что используется, скажем, информация только о последних 10 словах предложения.\n",
    "\n",
    "Функция активации Tanh постепенно затирает контекст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/backprop_through_time.png\"><center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://cs231n.stanford.edu/slides/2021/lecture_10.pdf\">CS231n: Recurrent Neural Network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затухающий/взрывающийся градиент (Vanishing/exploding gradient) — явления затухающего и взрывающегося градиента часто встречаются в контексте RNN. И при большой длине последовательности это становится критичным. Причина в том, что зависимость величины градиента от числа слоёв экспоненциальная, поскольку веса умножаются многократно.\n",
    "\n",
    "$dL ∝ (W)^N$.\n",
    "\n",
    "$W > 1$ => взрыв\n",
    "\n",
    "$W < 1$ => затухание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/L08/out/simple_rnn_backprop.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из путей решения проблемы: **градиентное отсечение** (Gradient clipping) — метод, который ограничивает максимально допустимое значение градиента, позволяя избежать градиентного взрыва.\n",
    "\n",
    "А от затухания градиента может помочь **пропускание** **градиента по частям**, на сколько-то шагов по времени назад или вперёд. А не через всю нейросеть. Да, градиент будет не совсем точо считаться, и мы будем терять в качестве. И это нам спасает память."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/truncated_backprop.png\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://cs231n.stanford.edu/slides/2021/lecture_10.pdf\">CS231n: Recurrent Neural Network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычная RNN имела множество проблем, в том числе, в ней очень быстро затухала информация о предыдущих словах в предложении. Помимо этого были проблемы с затуханием/взрывом самого градиента.\n",
    "\n",
    "Эти проблемы были частично решены в LSTM, предложенной в [Hochreiter & Schmidhuber (1997)](http://www.bioinf.jku.at/publications/older/2604.pdf)\n",
    "\n",
    "В обычной RNN в ячейке был только один путь передачи информации. На каждом шаге мы сливали информацию, накопленную с предыдущих шагов, с текущей:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://edunet.kea.su/repo/EduNet-content/L08/out/simple_rnn_h_state.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом информация о предыдущих токенах очень быстро затухает, и теряется общая информация о предложении.\n",
    "\n",
    "Структура ячейки LSTM намного сложнее. Здесь есть целых 4 линейных слоя, каждый из которых выполняет разные задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L08/out/lstm_chain.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L08/out/lstm_chain_notation.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large f_t = σ(W_f \\cdot [h_{t-1}, x_t] + b_f) - forget \\quad gate$\n",
    "\n",
    "$\\large i_t = σ(W_i \\cdot [h_{t-1}, x_t] + b_i) - input \\quad gate$\n",
    "\n",
    "$\\large C^\\prime_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_{C^\\prime}) - candidate \\quad cell \\quad state$\n",
    "\n",
    "$\\large C_t = f_t\\otimes C_{t-1} + i_t \\otimes C^\\prime_t - cell \\quad state$\n",
    "\n",
    "$\\large o_t = σ(W_o \\cdot [h_{t-1}, x_t] + b_o) - output \\quad gate$\n",
    "\n",
    "$\\large h_t = o_t\\otimes \\tanh(C_t) - block \\quad output$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главное нововведение: в LSTM добавлен путь $c$, который по задумке должен этот общий контекст сохранять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L08/out/lstm_c_state_highway.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другими словами, путь $c$ (cell state, иногда называется highway, магистраль)  помогает нейросети сохранять важную информацию, встретившуюся в какой-то момент в предложении, все время, пока эта информация требуется.\n",
    "\n",
    "По формулам также видно, как возросла сложность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vanilla RNN:**\n",
    "\n",
    "$\\large h_t = tanh \\begin{pmatrix} W \\begin{pmatrix} h_{t-1}\\\\ x_t \\end {pmatrix}\\end{pmatrix}$\n",
    "\n",
    "**LSTM:**\n",
    "\n",
    "$\\large \\begin{pmatrix} i\\\\ f\\\\ o\\\\ g \\end{pmatrix} = \\begin{pmatrix} \\sigma \\\\ \\sigma \\\\ \\sigma \\\\ \\tanh \\end{pmatrix} W \\begin{pmatrix} h_{t-1}\\\\ x_t \\end{pmatrix}$\n",
    "\n",
    "Два вектора на каждом временном промежутке:\n",
    "\n",
    "$c_t = f \\odot c_{t-1} + i \\odot g$ — сell state\n",
    "\n",
    "$h_t = o \\odot tanh(c_t)$ — hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyTorch LSTMCELL](https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
    "\n",
    "Интерфейс отличается от RNNCell количеством входов и выходов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lstm_cell = torch.nn.LSTMCell(input_size=3, hidden_size=4)\n",
    "input = torch.randn(1, 3)  # batch, input_size\n",
    "h_0 = torch.randn(1, 4)\n",
    "c_0 = torch.randn(1, 4)\n",
    "h, c = lstm_cell(input, (h_0, c_0))  # second arg is tuple\n",
    "print(\"Shape of h:\", h.shape)  # batch, hidden_size\n",
    "print(\"Shape of c:\", c.shape)  # batch, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличие от RNN состоит в том, что кроме $h$ возвращается еще и $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "lstm = nn.LSTM(input_size=4, hidden_size=5)\n",
    "input = torch.randn(3, 2, 4)  # seq_len, batch, input_size\n",
    "out, (h, c) = lstm(input)  # h and c returned in tuple\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h\".ljust(15), h.shape)  # batch, hidden_size\n",
    "print(\"Shape of c\".ljust(15), c.shape)  # batch, hidden_size\n",
    "print(\n",
    "    \"Output shape:\".ljust(15), out.shape\n",
    ")  # seq_len, batch, hidden_size : h for each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример использования на задаче с временным рядом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы убедиться в работоспособности конструкции, заменим RNN блок на LSTM в задаче предсказания временного ряда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/airline-passengers.csv\"\n",
    ")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max normalization\n",
    "training_data = dataset.iloc[:, 1:2].values\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "print(\"Initial statistics:\")\n",
    "print(\"Minimum value:\", repr(td_min).rjust(5))\n",
    "print(\"Maximum value:\", repr(td_max).rjust(5))\n",
    "\n",
    "training_data = (training_data - td_min) / (td_max - td_min)\n",
    "print(\"\\nResulting statistics:\")\n",
    "print(\"Minimum value:\", repr(training_data.min()).rjust(5))\n",
    "print(\"Maximum value:\", repr(training_data.max()).rjust(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create data \"ensemble\"\n",
    "\n",
    "\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "        _x = data[i : (i + seq_length)]  # picking several sequential observations\n",
    "        _y = data[i + seq_length]  # picking the subsequent observation\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return torch.Tensor(np.array(x)), torch.Tensor(np.array(y))\n",
    "\n",
    "\n",
    "# set length of the ensemble; accuracy of the predictions and\n",
    "# speed perfomance almost always depend on it size\n",
    "seq_length = 8  # compare 2 and 32\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "\n",
    "train_size = int(len(y) * 0.8)\n",
    "\n",
    "x_train = x[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "x_test = x[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"x shape:\", x_train.shape)\n",
    "print(\"y shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "print(\"x shape:\", x_test.shape)\n",
    "print(\"y shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_plot(train_predict):\n",
    "    data_predict = train_predict.data\n",
    "    y_data_plot = y.data\n",
    "\n",
    "    # Denormalize\n",
    "    data_predict = data_predict[0] * (td_max - td_min) + td_min\n",
    "    y_data_plot = y_data_plot * (td_max - td_min) + td_min\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.axvline(x=train_size, c=\"r\", linestyle=\"--\")\n",
    "    # shifting the curve as first y-value not correspond first value overall\n",
    "    plt.plot(seq_length + np.arange(y_data_plot.shape[0]), y_data_plot)\n",
    "    plt.plot(seq_length + np.arange(y_data_plot.shape[0]), data_predict)\n",
    "\n",
    "    plt.title(\"Number of passengers per month\")\n",
    "    plt.ylabel(\"#passengers\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "\n",
    "    plt.legend([\"Train/Test separation\", \"Real\", \"Predicted\"])\n",
    "    plt.grid(axis=\"x\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new LSTM based model\n",
    "\n",
    "\n",
    "class LSTMAirTrafficPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, hidden_size=hidden_size, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h, c) = self.lstm(x)\n",
    "        y = self.fc(h)\n",
    "        return y\n",
    "\n",
    "\n",
    "lstm = LSTMAirTrafficPredictor(input_size=1, hidden_size=4)\n",
    "input = torch.randn((108, 8, 1))\n",
    "out = lstm(input)\n",
    "\n",
    "print(\n",
    "    \"LSTM model we use consider first input dimension as a batch dimension, output dimension logic has not changed:\"\n",
    ")\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Output shape:\".ljust(15), out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.train()\n",
    "\n",
    "print(\"LSTM training process with MSE loss:\")\n",
    "\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = lstm(x_train)\n",
    "    optimizer.zero_grad()\n",
    "    # print(outputs.shape)\n",
    "    loss = criterion(y_pred, y_train.unsqueeze(0))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch},\".ljust(15), \"loss: %1.5f\" % (loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lstm.eval()\n",
    "train_predict = lstm(x)\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "time_series_plot(train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "1. Использование LSTM слоев при прогнозировании нестационарных временных рядов — отличное решение, т.к. нейронная сеть способна самостоятельно выделить динамики изменениях составляющих временного ряда. Правда, в более сложных случаях (трейдинге, например, или чтении и расшифровки волн мозга) приходится прибегать к feature engineering.\n",
    "2. Сложность нейронной сети должна соответствовать сложности подаваемых в нее данных. С ростом ансамбля и числа нейронов увеличивается заучивание тренировочной выборки и теряется способность к обобщению.\n",
    "3. Предварительный анализ цикличности в данных (если она есть) помогает понять оптимальный размер ансамбля (тут видно, что цикл, в среднем, составляет 8 интервалов).\n",
    "4. Также результат может зависеть от типа масштабирования, который Вы применяете. Нужно знать принципы работы scaler'ов и не стесняться экспериментировать с ними. См. [Feature Scaling Data with Scikit-Learn for Machine Learning in Python](https://stackabuse.com/feature-scaling-data-with-scikit-learn-for-machine-learning-in-python/) и [Hands-On Machine Learning with Scikit-Learn and TensorFlow, ч.4](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/ch04.html1).\n",
    "5. При всей выгодности применения нейронных сетей, необходимо быть осторожным с автокорреляцией (см. статью [How to avoid machine learning pitfalls:\n",
    "a guide for academic researchers](https://arxiv.org/pdf/2108.02497.pdf))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модификации LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было предложено множество модификаций структуры LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peephole connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, введение возможности всем gates напрямую подсматривать в вектор контекста $C$. Что, безусловно, логично: сложно решать, что делать с вектором $C$ (что из него стирать, что в него добавлять, что из него брать), если видишь его только опосредованно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L08/out/lstm_peepholes_connections.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large f_t = \\sigma(W_f \\cdot [C_{t-1}, h_{t-1}, x_t] + b_f)$\n",
    "\n",
    "$\\large i_t = \\sigma(W_i \\cdot [C_{t-1}, h_{t-1}, x_t] + b_i)$\n",
    "\n",
    "$\\large o_t = \\sigma(W_o \\cdot [C_t, h_{t-1}, x_t] + b_o)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение forget и input gates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также кажется, что правильно требовать от нейросети принимать решение о записи в вектор и стирании из него информации $C$ одновременно. Если что-то стираем, надо что-то записать. И наоборот."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L08/out/lstm_join_input_and_forget_gate.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large C_t = f_t * C_{t-1} + (1-f_t) * \\tilde C_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU (Gated reccurent unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая известная модификация LSTM — GRU. Она более компактна за счет сильных упрощений в сравнении со стандартной LSTM.\n",
    "\n",
    "Главные изменения: объединены forget и input gates, слиты $h_t$ и $C_t$, которые в обычной LSTM только участвовали в формировании друг друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/gru_basic_block.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "$\\large r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "$\\large \\tilde h_t = tanh(W \\cdot [r_t * h_{t-1}, x_t])$\n",
    "\n",
    "$\\large h_t = (1-z_t) * h_{t-1} + z_t * \\tilde h_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = torch.nn.GRU(input_size=4, hidden_size=3)\n",
    "input = torch.randn(2, 1, 4)  # seq_len, batch, input_size\n",
    "h0 = torch.randn(1, 1, 3)\n",
    "output, h = gru(input, h0)\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h:\".ljust(15), h.shape)  # last h\n",
    "print(\"Output shape:\".ljust(15), output.shape)  # seq_len = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практический опыт исследователей: иногда лучше работает GRU, иногда — LSTM. Точный рецепт успеха сказать нельзя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример посимвольной генерации текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Github RNN-walkthrough](https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb)\n",
    "\n",
    "Одним из основных направлений использования рекуррентных сетей является работа с текстами:\n",
    "- генерация (Language modeling)\n",
    "- перевод (Machine Translation)\n",
    "\n",
    "Давайте посмотрим, как решаются такого рода задачи.\n",
    "\n",
    "Начнем с относительно простой задачи — посимвольной генерации текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постановка задачи:** предсказать следующий символ в последовательности.\n",
    "\n",
    "- исходный текст:\n",
    "'hey how are you'\n",
    "\n",
    "- искаженный текст:\n",
    "'hey how are yo'\n",
    "\n",
    "- Верное предсказание:\n",
    "'u'\n",
    "\n",
    "Теоретически эту технику можно использовать для генерации подсказок при наборе текстов, исправления ошибок или восстановления частично утраченного текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/character_by_character_generation_example.gif\" width=\"400\">\n",
    "\n",
    "<em>Source: <a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">The Unreasonable Effectiveness of Recurrent Neural Networks</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Зафиксировать словарь\n",
    "2. Разбить данные\n",
    "3. Выполнить кодирование символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "text = [\"hey how are you\", \"good i am fine\", \"have a nice day\"]\n",
    "\n",
    "# Join all the sentences together and extract the unique characters\n",
    "# from the combined sentences\n",
    "chars = set(\"\".join(text))\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}\n",
    "\n",
    "print(\"Dictionary for mapping character to the integer:\")\n",
    "pprint.pprint(char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо ASCII символа, каждой букве мы сопоставили номер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выравнивание данных (Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN допускают работу с данными переменной длины. Но чтобы поместить предложения в batch, надо их выровнять.\n",
    "\n",
    "Обычно размер батча делают равным самому длинному предложению, а остальные просто дополняют пробелами (или спецсимволами) до этого размера.  Также хорошей идеей будет отметить специальным символом начало предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sent) for sent in text]\n",
    "maxlen = max(lengths)\n",
    "print(f\"The longest string has {maxlen} characters.\\n\")\n",
    "\n",
    "print(f\"Initial texts:\\n{text}\")\n",
    "# A simple loop that loops through the list of sentences and adds\n",
    "# a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "for i in range(len(text)):\n",
    "    while len(text[i]) < maxlen:\n",
    "        text[i] += \" \"\n",
    "\n",
    "print(f\"Resulting texts:\\n{text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве входа будем использовать предложение без последнего символа:\n",
    "\n",
    "**'hey how are yo'**\n",
    "\n",
    "В качестве результата — предложение, в котором он сгенерирован:\n",
    "\n",
    "**'ey how are you'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "\n",
    "    # Remove first character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "\n",
    "    print(\"Input sequence:\".ljust(18), f\"'{input_seq[i]}'\")\n",
    "    print(\"Target sequence:\".ljust(18), f\"'{target_seq[i]}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь символы надо перевести в числа. Для этого мы уже построили словарь.\n",
    "\n",
    "P.S. Запускать блок только один раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "    print(\"Encodded input sequence:\".ljust(25), input_seq[i])\n",
    "    print(\"Encodded target sequence:\".ljust(25), target_seq[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь из чисел надо сделать вектора.\n",
    "\n",
    "Почему бы не оставить числа?\n",
    "В прошлом примере модель хорошо с ними работала.\n",
    "\n",
    "В прошлом примере использовался MSE, и на выходе было число.\n",
    "\n",
    "Если бы мы определили отношение порядка над номерами букв, то что-то подобное можно было бы сделать.\n",
    "\n",
    "Однако сейчас мы предсказываем класс буквы.\n",
    "Поэтому на входе и на выходе должен быть вектор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/one_hot_encoding_softmax.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(text)\n",
    "\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "\n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features\n",
    "\n",
    "\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
    "print(\n",
    "    \"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(\n",
    "        input_seq.shape\n",
    "    )\n",
    ")\n",
    "print(input_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый символ закодировали вектором.\n",
    "Не слишком экономно, зато удобно умножать на матрицу весов.\n",
    "\n",
    "P.S. Запускать только один раз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример: Language Modeling**\n",
    "\n",
    "Кодируем буквы при помощи **one-hot кодирования** и подаем на входной слой.\n",
    "\n",
    "$\\begin{bmatrix} w_{11} & w_{12} & w_{13} & w_{14} \\\\ w_{21} & w_{22} & w_{23} & w_{24} \\\\ w_{31} & w_{32} & w_{33} & w_{34} \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 0\\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} w_{11} \\\\ w_{21} \\\\ w_{31}\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/language_modeling.png\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Умножение матрицы на one-hot представление просто достает соответствующую ненулевому значению колонку из матрицы весов.\n",
    "Поэтому часто вместо напсания двух отдельных слоев (one-hot + линейного) делают просто слой, называемый **Embedding Layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "import torch\n",
    "\n",
    "input_seq = torch.Tensor(input_seq)\n",
    "target_seq = torch.Tensor(target_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NextCharacterGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size=hidden_dim, batch_first=True)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden_0 = torch.zeros(\n",
    "            1, batch_size, self.rnn.hidden_size\n",
    "        )  # 1 correspond to number of layers\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden_0)\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # Need Only if n_layers > 1\n",
    "        out = out.contiguous().view(-1, self.rnn.hidden_size)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = NextCharacterGenerator(\n",
    "    input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1\n",
    ")\n",
    "\n",
    "# Define hyperparameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training Run\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    optimizer.zero_grad()  # Clears existing gradients from previous epoch\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward()  # Does backpropagation and calculates gradients\n",
    "    optimizer.step()  # Updates the weights accordingly\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}/{num_epochs}\".ljust(20), end=\" \")\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "\n",
    "    out, hidden = model(character)\n",
    "    # print(out.shape)\n",
    "    # print(out)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden\n",
    "\n",
    "\n",
    "def sample(model, out_len, start=\"hey\"):\n",
    "    model.eval()  # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for _ in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return \"\".join(chars)\n",
    "\n",
    "\n",
    "sample(model, 15, \"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сгенерировать несколько вариантов предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    print(sample(model, 15, \"good\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так получается, потому что сеть инициализирована нулями и никакой случайности нет. Даже если мы добавим в датасет ещё предложение, начинающиеся с *good*, результат не изменится. Также сеть переобучилась на небольшом датасете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы применяли OneHotEncoding для представления наших слов. Проблемы возникают, когда пространство объектов начинает расти и у нас возникают огромные разреженные матрицы.\n",
    "\n",
    "Кроме того, некоторые объекты у нас сразу могут быть ближе: семантически \"король\" и \"королева\" отличаются только полом, различие между словами \"король\" и \"стул\" заметно выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому мы можем переводить наши слова в вектора меньшей размерности, которые при этом будут сравнимы между собой с помощью модуля [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html).\n",
    "\n",
    "[Туториал PyTorch по применению эмбедингов в NLP](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html).\n",
    "\n",
    "[NLP Course for you](https://lena-voita.github.io/nlp_course.html)\n",
    "\n",
    "[Курс по NLP от ШАД](https://github.com/yandexdataschool/nlp_course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/word_representation_intro_min.png\" width=\"600\">\n",
    "\n",
    "<em>Source: <a href=\"https://lena-voita.github.io/nlp_course/word_embeddings.html\">Lena Voita NLP Course</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L08/lookup_table.gif\" width=\"600\">\n",
    "\n",
    "<em>Source: <a href=\"https://lena-voita.github.io/nlp_course/word_embeddings.html\">Lena Voita NLP Course</a></em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say you have 2 sentences (lowercased, punctuations removed):\n",
    "sentences = \"i am new to pytorch i am having fun\"\n",
    "\n",
    "words = sentences.split(\" \")\n",
    "\n",
    "print(f\"All words: {words} \\n\")\n",
    "\n",
    "vocab = set(words)  # create a vocabulary\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"Vocabulary (unique words): {vocab} \\n\")\n",
    "print(f\"Vocabulary size: {vocab_size} \\n\")\n",
    "\n",
    "# map words to unique indices\n",
    "word2idx = {word: ind for ind, word in enumerate(vocab)}\n",
    "\n",
    "print(f\"Word-to-id dictionary: {word2idx} \\n\")\n",
    "\n",
    "encoded_sentences = [word2idx[word] for word in words]\n",
    "\n",
    "print(f\"Encoded sentences: {encoded_sentences}\")\n",
    "\n",
    "# let's say you want embedding dimension to be 3\n",
    "emb_dim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нейросетевой слой эмбеддингов может быть определён так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "emb_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "\n",
    "word_vectors = emb_layer(torch.LongTensor(encoded_sentences))\n",
    "\n",
    "print(f\"Shape of encoded sentences: {word_vectors.shape} \\n\")\n",
    "\n",
    "print(f\"Shape of weigths: {emb_layer.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этод код инициализирует эмбеддинги согласно нормальному распределению (со средним значением 0 и дисперсией 1). Таким образом, пока что никакого различия или сходства между векторами нет.\n",
    "\n",
    "`word_vectors` — тензор размером (9,3). 9 слов в датасете, размер 3 задан нами.\n",
    "\n",
    "`emb_layer` имеет 1 обучаемый параметр `weight`, который по умолчанию True. Можем проверить так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы не хотим обучать этой слой (например, используем заранее обученные эмбеддинги), мы можем заморозить его веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы хотим использовать заранее определённые веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predefined weights\n",
    "weight = torch.FloatTensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])\n",
    "print(weight.shape)\n",
    "embedding = nn.Embedding.from_pretrained(weight)\n",
    "# get embeddings for ind 0 and 1\n",
    "embedding(torch.LongTensor([0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем уже готовые веса модели Word2Vec, обученные на датасете Google News, состоящeм из 100 миллиардов слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://www.dropbox.com/s/699kgut7hdb5tg9/GoogleNews-vectors-negative300.bin.gz?dl=1\n",
    "!mv 'GoogleNews-vectors-negative300.bin.gz?dl=1' GoogleNews-vectors-negative300.bin.gz\n",
    "\n",
    "# Use this way for loading from our host\n",
    "# !wget https://edunet.kea.su/repo/EduNet-web_dependencies/weights/GoogleNews-vectors-negative300.bin.gz\n",
    "# !mv 'GoogleNews-vectors-negative300.bin.gz' GoogleNews-vectors-negative300.bin.gz\n",
    "\n",
    "!gunzip -q GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wordvector_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "word_vectors = KeyedVectors.load_word2vec_format(wordvector_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor(word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding.from_pretrained(weight)\n",
    "\n",
    "input = torch.LongTensor([0, 1])\n",
    "\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также мы можем воспользоваться библиотектой [torchtext](https://pytorch.org/text/stable/index.html). Возьмём таблицу весов поменьше, всего 10000 наиболее встречающихся слов. Зададим длину тензора — 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "\n",
    "glove = torchtext.vocab.GloVe(\n",
    "    name=\"6B\", dim=50, max_vectors=10000\n",
    ")  # use 10k most common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если обратиться к документации, мы увидим, что 6В — это [лишь один из вариантов весов](https://pytorch.org/text/stable/_modules/torchtext/vocab/vectors.html#GloVe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_emb = nn.Embedding.from_pretrained(glove.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.LongTensor([0, 1])\n",
    "glove_emb(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код нейросети со слоем nn.Embedding выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_with_Embedding_Layer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNN_with_Embedding_Layer, self).__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(glove.vectors)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Look up the embedding\n",
    "        x = self.emb(x)\n",
    "        # Set an initial hidden state\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        # Forward propagate the RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Pass the output of the last time step to the classifier\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "model = RNN_with_Embedding_Layer(input_size=50, hidden_size=128, num_classes=3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике часто встает вопрос о том, как делить текст на естественном языке на токены. Должны ли это быть символы, слова, или части слов? Рассмотрим подходы к тому, как производится токенизация в современных языковых моделях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наивная токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим предложение: `Я люблю Natural Language Processing (NLP). А ты?`\n",
    "\n",
    "Присваивать отдельный индекс каждому предложению, кажется, совсем не оптимально. Что тогда? Мы можем разбить предложение на слова (*токенезировать предложение*) по пробелам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Я люблю Natural Language Processing (NLP). А ты?\"\n",
    "tokenized = input.split(\" \")\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неплохо, но можно обратить внимание, что мы не учли пунктуацию. Кажется неразумным создавать отдельный индекс для каждой комбинации NLP и знаков препинания. Давайте проведём токенизацию с учётом знаков препинания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# initializing string\n",
    "input = \"Я люблю Natural Language Processing (NLP). А ты?\"\n",
    "\n",
    "# using findall() to get all regex matches.\n",
    "res = re.findall(r\"\\w+|[^\\s\\w]+\", input)\n",
    "\n",
    "# printing result\n",
    "print(str(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше, но представьте себе размер словаря, если мы будем токенизировать таким образом все слова в Википедии. Такой большой объём словаря приведёт к тому, что у модели будет огромный размер эмбеддингов в качестве входного и выходного слоя, что приведёт к увеличению необходимой памяти. Обычно размер словаря трансформеров не превышает 50 000 токенов. Почему бы тогда не использовать посимвольную токенезацию, как раньше?\n",
    "\n",
    "Хотя посимвольная токенизация очень проста и значительно снижает требования к памяти, она значительно усложняет обучение модели осмысленным представлениям входных данных. Например, выучить осмысленное контекстно-независимое представление для буквы `\"с\"` гораздо сложнее, чем выучить контекстно-независимое представление для слова `\"сегодня\"`. Поэтому токенизация символов часто сопровождается потерей производительности. Чтобы получить лучшее из двух миров, используют что-то среднее между токенизацией на уровне слов и на уровне символов, называемый токенизацией подслова (*subword tokenization*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subword Tokenization (Токенизация подслова)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритмы токенизации подслова основываются на принципе, что часто используемые слова не должны разбиваться на более мелкие подслова, а редкие слова должны быть разложены на значимые подслова. Например, слово \"*annoyingly*\" может считаться редким словом и может быть разложено на \"*annoying*\" и \"*ly*\". И \"*annoying*\", и \"*ly*\" как самостоятельные подслова будут встречаться чаще, и в то же время значение слова \"*annoyingly*\" сохранится за счёт составного значения \"*annoying*\" и \"*ly*\".\n",
    "\n",
    "Токенизация подслова позволяет модели иметь разумный объём словаря и при этом обучаться значимым контекстно-независимым представлениям. Кроме того, токенизация подслова позволяет модели обрабатывать слова, которые она никогда раньше не видела, путём разложения их на известные подслова.\n",
    "\n",
    "Воспользуемся популярной библиотекой для токенизации от команды Hugging Face `transformers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer.tokenize(\n",
    "    \"I have a new neighbor. Every morning he annoyingly drills the wall.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предложение сначала было приведено к нижнему регистру. Мы видим, что слова [\"i\", \"have\", \"a\", \"new\"] присутствуют в словаре токенизатора, а слово \"annoyingly\" — нет. Следовательно, токенизатор разбивает \"annoyingly\" на известные подслова: [\"annoying\" и \"##ly\"]. \"##\" означает, что остальная часть лексемы должна быть присоединена к предыдущей без пробела (для декодирования или обратного хода токенизации)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte-Pair Encoding (BPE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодирование байт-парой (BPE) опирается на претокенизатор, который разбивает обучающие данные на слова. Примером простой претокенизации может быть разбивка по пробелам. Более продвинутая предварительная токенизация включает токенизацию на основе каких-то правил.\n",
    "\n",
    "После предварительной токенизации у нас получится набор уникальных слов и будет определена частота встречаемости каждого слова в обучающих данных. Затем BPE создаёт базовый словарь, состоящий из всех символов, которые встречаются в наборе уникальных слов, и изучает правила слияния для формирования нового символа из двух символов базового словаря. Так происходит до тех пор, пока словарный запас не достигнет желаемого размера. Обратите внимание, что желаемый объём словаря — это гиперпараметр, который необходимо определить перед обучением токенизатора.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример**: после предварительной токенизации был определён набор слов, включая их частоту:\n",
    "\n",
    "`(\"hug\", 10), (\"pug\", 5), (\"pun\", 12), (\"bun\", 4), (\"hugs\", 5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что базовый словарь —  `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\"]`.\n",
    "\n",
    "Разделим все слова на отдельные буквы:\n",
    "\n",
    "`(\"h\" \"u\" \"g\", 10), (\"p\" \"u\" \"g\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"u\" \"g\" \"s\", 5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BPE подсчитывает **частоту** каждой возможной пары символов и **выбирает** ту пару символов, которая встречается наиболее часто. В приведённом выше примере `\"h\"`, за которым следует `\"u\"`, встречается 10 + 5 = 15 раз. Однако наиболее частой парой символов является `\"u\"`, за которой следует `\"g\"`, встречающаяся 10 + 5 + 5 = 20 раз. Таким образом, первое правило слияния, которому обучается токенизатор, — сгруппировать все символы `\"u\"`, за которыми следует символ `\"g\"`, вместе. Затем `\"ug\"` добавляется в словарь. После этого набор слов становится следующим:\n",
    "\n",
    "`(\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"ug\" \"s\", 5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем BPE определяет следующую наиболее часто встречающуюся пару символов. Это `\"u\"`, за которым следует `\"n\"`, который встречается 16 раз. `\"u\"`, `\"n\"` объединяются в `\"un\"` и добавляются в словарь. Следующая по частоте пара символов — `\"h\"`, за которой следует `\"ug\"`, 15 раз. Снова пара объединяется, и `\"hug\"` может быть добавлен в словарь.\n",
    "\n",
    "На данном этапе словарь состоит из `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"]`, а наш набор уникальных слов представлен как\n",
    "\n",
    "`(\"hug\", 10), (\"p\" \"ug\", 5), (\"p\" \"un\", 12), (\"b\" \"un\", 4), (\"hug\" \"s\", 5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если остановить обучение BPE на этом моменте, то выученные правила слияния будут применяться к новым словам (при условии, что эти новые слова не содержат символов, которых не было в базовом словаре).\n",
    "\n",
    "Например, слово `\"bug\"` будет токенизировано как `[\"b\", \"ug\"]`, а `\"mug\"` будет токенизировано как `[\"<unk>\", \"ug\"]`, поскольку символ `\"m\"` отсутствует в базовом словаре. Как правило, отдельные буквы, такие как `\"m\"`, не заменяются символом `\"<unk>\"`, поскольку обучающие данные обычно включают хотя бы одно вхождение каждой буквы, но это может произойти и для специальных символов, таких как эмодзи.\n",
    "\n",
    "Размер словаря, т.е. размер базового словаря + количество слияний, является **гиперпараметром**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть и множество других форм токенизации, подробнее о них можно прочитать в [Summary of the tokenizers](https://huggingface.co/docs/transformers/tokenizer_summary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем решить задачу **sequence-to-sequence**: преобразование последовательности $X$ длины $N$ в последовательность $Y$ длины $T$. $T$ **может быть не равно** $N$.\n",
    "\n",
    "Примеры **sequence-to-sequence** задач:\n",
    "*   машинный перевод,\n",
    "*   генерация ответа на вопрос,\n",
    "*   генерация описания картинки или видео.\n",
    "\n",
    "Для решения таких задач  можно использовать две **RNN**: **кодировщик** и **декодировщик**.\n",
    "* Задача **кодировщика**: обобщить информацию о **входной последовательности** $X = (x_1,..., x_N)$, сформировав **вектор контекста** $C$ фиксированного размера.\n",
    "* Задача **декодировщика**: используя информацию из $C$, сформировать **выходную последовательность** $Y = (y_1, ..., y_T)$.\n",
    "\n",
    "В качестве вектора $C$ можно использовать последнее **скрытое состояние** кодировщика $h_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом:\n",
    "\n",
    "* **вход** — последовательность  $\\large x_1, \\dots, x_N$;\n",
    "* **выход** — последовательность  $\\large y_1, \\dots, y_T$.\n",
    "\n",
    "Кодировщик на основании входной последовательности предсказывает **нулевое скрытое состояние декодировщика и вектор контекста** $\\large с$, который часто равен финальному скрытому состоянию кодировщика.\n",
    "\n",
    "**Кодировщик:** $\\large h_i = f_w(x_i, h_{i_1})$\n",
    "\n",
    "**Декодировщик:** $\\large s_t = g_u(y_{t-1}, s_{t-1}, c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/seq_to_seq_with_rnn.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом возникает следующая **проблема:** мы пропускаем информацию из входной последовательности через бутылочное горлышко — вектор фиксированного размера $h_N$. Что будет, если размер последовательности 1000?\n",
    "\n",
    "**Идея:** использовать новый вектор контекста на каждом шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном подходе мы используем один **вектор контекста** фиксированной длины $c$, в который собираем информацию со всей **входной последовательности** $(x_1,...,x_N)$.\n",
    "\n",
    "**Входная последовательность** может содержать как единицы, так и тысячи элементов. В задаче машинного перевода **входной последовательностью** может быть:\n",
    "* короткая фраза,\n",
    "* абзац “Войны и мира”.\n",
    "\n",
    "Контекст важен. Для генерации глагола в правильной форме нужно понимать, к какому существительному он относится, а для качественного перевода конца абзаца необходимо понимать, о чем шла речь в его начале."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблемы Sequence-to-Sequence with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом возникают проблемы:\n",
    "- **Вектор контекста** $c$ фиксированной длины не может вместить любое количество информации, поэтому для длинных последовательностей качество будет ухудшаться.\n",
    "- На каждой итерации декодировщика **скрытое состояние** $s_t$ должно сохранять информацию о том, какие элементы **выходной последовательности** уже были сгенерированы. Если $s_t$ не способно вместить эту информацию, модель может зациклиться или потерять часть **выходной последовательности**.\n",
    "\n",
    "**Вектор контекста** $c$ и **скрытые состояния** декодировщика $s_t$ являются “бутылочными горлышками” модели."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
