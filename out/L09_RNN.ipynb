{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Рекуррентные нейронные сети (RNN)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Особенности данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого мы работали с методами машинного обучения, которые работают с признаковым описанием **фиксированной длины**.\n",
    "\n",
    "Так правильно делать в случае **табличных данных** — обычно каждый объект в таблицах описан фиксированным набором признаков, и новые признаки не могут появиться \"вдруг\". Мы точно знаем, что на вход нам приходит объект размера 100, а на выходе мы должны для него предсказать 1 число.\n",
    "\n",
    "Верно это и про **изображения** — обычно нейронная сеть учится на изображениях определенного разрешения. Да, мы можем сделать нейросеть, которая способна работать с изображением почти любого разрешения, но добиваемся мы этого за счет вставки слоев **global pooling**, которые  приводят признаковое описание, полученное сверточную частью нейросети, к фиксированному размеру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако многие данные структурой фиксированной длины не обладают. К примеру, **тексты**. Возьмем все абзацы из \"Войны и Мира\". Какие-то будут больше, какие-то меньше. И обрезать их как-то нельзя. Аналогично будет и для текстов из Твиттера. И что делать, если мы хотим предсказывать, например, эмоциональную окрашенность текста?\n",
    "\n",
    "Или если на основе абзаца текста нам необходимо сгенерировать его **краткое содержание**? То, что нужно предсказать, может быть разной длины. Аналогичный вопрос возникает также в случае, если мы хотим по данным о курсе валюты за прошлый год спрогнозировать **курс валюты на следующий месяц** по дням."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/time_series_data.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует ряд задач, для которых необходима особая структура нейронной сети, позволяющая **принимать данные разного размера**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры задач"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Анализ временных рядов**\n",
    "- Табличные данные\n",
    "- Аннотирование изображений и видео (Image/Video captioning)\n",
    "- Машинный перевод\n",
    "- Распознавание текста\n",
    "- Распознавание речи\n",
    "\n",
    "\n",
    "**Генеративные модели**\n",
    "- Генерация текста/речи (например, чат-боты)\n",
    "- Генерация изображений\n",
    "\n",
    "**Классификация**\n",
    "- Изображения\n",
    "- Блоки текста (Sentiment analysis)\n",
    "\n",
    "**Анализ последовательностей**\n",
    "- Анализ текстов\n",
    "- Биологические последовательности\n",
    "- Химические последовательности\n",
    "\n",
    "\n",
    "Общее для задач — мы имеем возможность сохранять информацию, сформированную при обработке одной части объекта (**токена**), и использовать ее, когда мы анализируем другие части."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До прихода нейронных сетей предложения пытались описать при помощи набора правил — грамматик, которые довольно успешно могли генерировать новые осмысленные предложения. Так выглядит разбор при помощи грамматик простого предложения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/parse_tree.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увы, грамматики плохо учитывали высокоуровневые связи. Например, очень тяжело было добиться того, чтобы в абзаце текста:\n",
    "\n",
    "\"Леша пришел домой. Он будет есть рыбу.\"\n",
    "\n",
    "компьютер понял, что во втором предложении \"Он\" соответствует \"Леше\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основная идея**, на которой основано RNN, состоит в следующем: взять всю последовательность и пропустить через одну и ту же нейросеть.\n",
    "Но при этом сама нейросеть кроме следующего элемента последовательности (например, слова в тексте), будет принимать еще один параметр — некий $h$, который в начале будет, например, вектором из нулей, а далее — значением, которое выдает сама нейросеть после обработки очередного элемента последовательности (**токена**).\n",
    "\n",
    "Также далее мы будем использовать понятие **нулевого токена** — токена, который символизирует заплатку, токен, не несущий никакого смысла, но который иногда нужно передать модели. Например, как сигнал начала работы.\n",
    "\n",
    "В сети появляется новая сущность — **hidden state** ($h$) — вектор, хранящий состояние, учитывающее и локальный, и глобальный контекст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/rnn_idea.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network\">Recurrent neural network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом наша нейросеть может выдавать некий ответ на каждом шаге, но мы можем:\n",
    "\n",
    " 1. Использовать только выданный на последнем (если нам нужно предсказать одно значение) — **many-to-one**.\n",
    "\n",
    " 2. Мы можем подавать в наше нейросетку токены (когда кончился исходный сигнал, подаем нулевые токены), пока она не сгенерирует токен, символизирующий остановку (**many-to-many, one-to-many**).\n",
    "\n",
    " 3. Можем делать различные комбинации, игнорируя часть выходов нейросети в начале её работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **«One to one»** — обычная нейронная сеть, не обязательно применять RNN в таком случае.\n",
    "\n",
    "*   Более сложной является реализация **«one to many»**, когда у нас есть всего один вход, и нам необходимо сформировать несколько выходов. Такой тип нейронной сети актуален, когда мы говорим о **генерации музыки** или **текстов**. Мы задаем начальное слово или начальный звук, а дальше модель начинает самостоятельно генерировать выходы, в качестве входа к очередной ячейке рассматривая выход с прошлой ячейки нейронной сети.\n",
    "\n",
    "*   Если мы рассматриваем задачу **классификации**, то актуальна схема **«many to one»**. Мы должны проанализировать все входы нейронной сети и только в конце определиться с классом.\n",
    "\n",
    "*   Схема **«many to many»**, в которой количество выходов **равно** количеству входов нейронной сети. Обычно это задачи типа разметки исходной последовательности. Например, указать столицы городов, названия важных объектов, веществ и т.д., что относится к задачам вида NER (Named entity recogition).\n",
    "\n",
    "*   Схема **«many to many»**, в которой количество выходов нейронной сети **не равно** количеству входов. Это актуально в машинном переводе, когда одна и та же фраза может иметь разное количество слов в разных языках (т.е. это реализует схему кодировщик-декодировщик). Кодировщик получает данные различной длины — например, предложение на английском языке. С помощью скрытых состояний он формирует из исходных данных вектор, который затем передаётся в декодировщик. Последний, в свою очередь, генерирует из полученного вектора выходные данные — исходную фразу, переведённую на другой язык."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/one_or_many_to_one_or_many_ways.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно объединять разные подходы. Сначала генерируем некий $h$, который содержит сжатую информацию о том, что было подано в нейросеть, а затем подаем его в нейросеть «one to many», которая генерирует, к примеру, перевод того текста, что был подан первой части нейросети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/sequence_to_sequence.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Базовый RNN блок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим работу рекуррентной нейронной сети:\n",
    "1. На вход поступает некоторая последовательность $x = \\{x_1,...x_t,...,x_n\\}$, где $x_i$ — вектор фиксированной размерности. В ряде случаев этот вектор имеет размерность 1.\n",
    "\n",
    "2. Для каждого поступившего $x_t$ формируем скрытое состояние $h_t$, которое является функцией от предыдущего состояния $h_{t-1}$ и текущего элемента последовательности $x_t$:\n",
    "$$\\large h_t = f_W(h_{t-1}, x_t),$$\n",
    "где $W$  — это обучаемые параметры (веса).\n",
    "\n",
    "3. На основании рассчитанного скрытого состояния, учитывающего предыдущие значения  $x_i$, формируется выходная последовательность $y = \\{y_1,...y_t,...,y_k\\}$. Для формирования предсказания $y_t$ в текущий момент времени в модель могут быть добавлены полносвязные слои, принимающие на вход текущее скрытое состояние $h_t$.\n",
    "\n",
    "Ниже представлена простая RNN. В качестве функции активации используется тангенс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем обрабатывать последовательность элементов вектора $x$ за счет применения рекуррентной формулы на каждом шаге:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/rnn_basic_block.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Состояние состоит из вектора $h$, называемого скрытым состоянием:\n",
    "\n",
    "$\\large h_t = f_W(h_{t-1}, x_t),$\n",
    "\n",
    "$\\large \\quad \\quad \\quad \\color{grey}{\\downarrow \\text{(также может добавляться bias)}}$\n",
    "\n",
    "$\\large h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large y_t = W_{hy}h_t.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отличие** от слоев, с которыми мы уже сталкивались, состоит в том, что **на выходе мы получаем два объекта**: $y_t$ и $h_t$:\n",
    "\n",
    "$y_t$ — предсказание в текущий момент времени, например, метка класса,\n",
    "\n",
    "$h_t$ — контекст, в котором предсказание было сделано. Он может использоваться для дальнейших предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PyTorch для вычисления $h_t$ используется модуль [RNNCell](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html)\n",
    "\n",
    "$y_t$ в нем не вычисляется: предполагается, что для его получения в модель должен быть добавлен дополнительный линейный слой.\n",
    "\n",
    "**`input_size`** — размер элемента последовательности.\n",
    "\n",
    "В отличие от сверточных слоёв, это всегда вектор, а не тензор, поэтому **`input_size`** — скаляр.\n",
    "\n",
    "**`hidden_size`** — тоже скаляр. Он задает размер скрытого состояния, которое тоже является вектором. Фактически это количество нейронов в слое.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "rnn_cell = torch.nn.RNNCell(input_size=3, hidden_size=2)\n",
    "dummy_sequence = torch.randn((1, 3))  # batch, input_size\n",
    "h = rnn_cell(dummy_sequence)\n",
    "print(\"Inital shape:\".ljust(17), f\"{dummy_sequence.shape}\")\n",
    "print(\"Resulting shape:\".ljust(17), f\"{h.shape}\")  # hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно то, что описано в коде ниже.\n",
    "Для понятности в данном примере опущена батчевая обработка. Также для того, чтобы подобный код корректно заработал, [необходимо обернуть веса](https://stackoverflow.com/questions/50935345/understanding-torch-nn-parameter) в `torch.nn.Parameter` для регистрации параметров в модели.\n",
    "\n",
    "Начальное значение может быть инициализировано нулями, но лучше инициализировать случайными значениями, чтобы нейросеть хоть как-то меняла своё поведение. Или даже чем-то осмысленным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "# Simple RNNcell without a bias and batch support\n",
    "class SimplifiedRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        # Init weight matrix, for simplicity omit bias\n",
    "        self.W_hx = (\n",
    "            torch.randn(input_size, hidden_size) * 0.0001\n",
    "        )  # hidden_size == number of neurons\n",
    "        self.W_hh = (\n",
    "            torch.randn(hidden_size, hidden_size) * 0.0001\n",
    "        )  # naive initialization\n",
    "        self.h0 = torch.zeros((hidden_size))  # Initial hidden state\n",
    "\n",
    "    def forward(self, x, h=None):  # Without a batch dimension\n",
    "        if h is None:\n",
    "            h = self.h0\n",
    "        h = torch.tanh(torch.matmul(self.W_hx.T, x) + torch.matmul(self.W_hh.T, h))\n",
    "        return h\n",
    "\n",
    "\n",
    "simple_rnn_cell = SimplifiedRNNCell(input_size=3, hidden_size=2)\n",
    "h = simple_rnn_cell(dummy_sequence[0])  # No batch\n",
    "print(f\"Out = h\\n{h.shape} \\n{h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в последовательности всегда **несколько элементов**. И надо применить алгоритм к каждому.\n",
    "\n",
    "\n",
    "Поэтому RNNCell напрямую не используется. Для него есть обертка — [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html), которая обеспечивает последовательный вызов RNNCell для всех элементов последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN блок в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning: формат данных для RNN: длина последовательности, батч, размер объекта**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(input_size=3, hidden_size=2)  # batch_first = True\n",
    "dummy_batched_seq = torch.randn((2, 1, 3))  # seq_len, batch, input_size\n",
    "out, h = rnn(dummy_batched_seq)\n",
    "\n",
    "print(\"Inital shape:\".ljust(20), f\"{dummy_batched_seq.shape}\")\n",
    "print(\"Resulting shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Simple RNN without batching\n",
    "class SimplifiedRNNLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn_cell = SimplifiedRNNCell(input_size, hidden_size)\n",
    "\n",
    "    # Without a batch dimension x have shape seq_len * input_size\n",
    "    def forward(self, x, h=None):\n",
    "        all_h = []\n",
    "        for i in range(x.shape[0]):  # iterating over timestamps\n",
    "            h = self.rnn_cell(torch.Tensor(x[i]), h)\n",
    "            all_h.append(h)\n",
    "        return np.stack(all_h), h\n",
    "\n",
    "\n",
    "simple_rnn = SimplifiedRNNLayer(input_size=4, hidden_size=2)\n",
    "sequence = np.array(\n",
    "    [[0, 1, 2, 0], [3, 4, 5, 0]]\n",
    ")  # batch with one sequence of two elements\n",
    "\n",
    "out, h = simple_rnn(sequence)\n",
    "print(\"Inital shape:\".ljust(20), f\"{sequence.shape}\")\n",
    "print(\"Resulting shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберемся.\n",
    "\n",
    "Если у нас есть две последовательности:\n",
    "\n",
    "*   [1, 3, 2]\n",
    "*   [0, 4, 2]\n",
    "\n",
    "Чтобы обработать элемент \"3\", нам нужен hidden state, вычисленный по \"1\".\n",
    "\n",
    "То же самое для \"4\" — нужно обработать \"0\". Таким образом, по горизонтальной оси мы не можем паралелиться. Придётся параллелиться по вертикальной. Мы можем паралельно обработать первые элементы первой и второй последовательностей.\n",
    "\n",
    "К данным добавляется еще одно измерение — **размер последовательности**. Batch из 5 последовательностей по 6 объектов (размер объекта 3) в каждой будет выглядеть так (время идёт первой размерностью, поэтому поэлементно идём \"сверху вниз\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/rnn_batch.png\" width=\"700\">\n",
    "\n",
    "<em>Source: <a href=\"https://www.researchgate.net/publication/284579100_Session-based_Recommendations_with_Recurrent_Neural_Networks\">Session-based Recommendations with Recurrent Neural Networks</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри RNN модуля элементы последовательности обрабатываются последовательно:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/simple_rnn_h_state.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса при этом используются одни и те же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_seq = torch.randn((2, 1, 3))  #  seq_len, batch, input_size\n",
    "\n",
    "print(\"RNNCell\")\n",
    "rnn_cell = torch.nn.RNNCell(3, 2)\n",
    "print(\"Parameter\".ljust(10), \"Shape\")\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "    print(t.ljust(10), p.shape)\n",
    "\n",
    "cell_out = rnn_cell(dummy_seq[0, :, :])  # take first element from sequence\n",
    "print()\n",
    "print(\"Result shape =\".ljust(20), cell_out.shape)\n",
    "print(\"Hidden state shape =\".ljust(20), cell_out.shape)  # one hidden state\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "print(\"RNN\")\n",
    "rnn = torch.nn.RNN(3, 2)\n",
    "print(\"Parameter\".ljust(15), \"Shape\")\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t.ljust(15), p.shape)\n",
    "\n",
    "out, h = rnn(dummy_seq)\n",
    "\n",
    "print()\n",
    "print(\"Result shape =\".ljust(20), out.shape)  # h for all timestamps element\n",
    "print(\"Hidden state shape =\".ljust(20), cell_out.shape)  # h for last element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обратимся к [документации PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) и посмотрим, какие параметры есть у модуля RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слои (Stacked RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN блоки можно объединять в слои, накладывая их друг на друга. Для этой операции в `torch.nn.RNN` есть аргумент `num_layers`, с помощью которого можно указать количество слоёв.\n",
    "\n",
    "В представленной архитектуре нижний слой (а это всё ещё одна RNN-ячейка) обрабатывает букву *h*, передаёт свой hidden state в саму себя (направо, `h[0]`) и обрабатывает *е* и т.д. Кроме того, эта же ячейка передаёт своё состояние на вторую RNN-ячейку (наверх, `h[1]`), которая уже обрабатывает результат работы первой ячейки.\n",
    "\n",
    "На практике такая схема может приводить к взрыву или затуханию градиента, причём при проходе как по горизонтали, так и по вертикали. Об этом ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/layers.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр **num_layers** задаёт количество RNN-ячеек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((2, 1, 3))  # seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3, 2, num_layers=3)\n",
    "\n",
    "# Weights matrix sizes not changed!\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t, p.shape)\n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print()\n",
    "print(\"Out:\\n\", out.shape)  # Hidden states for all elements from top layer\n",
    "print(\"h:\\n\", h.shape)  # Hidden states for last element for all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательность можно пропустить через сеть два раза: в прямом и обратном направлении. Для этого создаётся слой, аналогичный входному, для обратного направления, и результат двух слоёв конкатенируется.\n",
    "\n",
    "[A Beginner’s Guide on Recurrent Neural Networks with PyTorch](https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/bidirectional.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((2, 1, 3))  # seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3, 2, bidirectional=True)\n",
    "\n",
    "for t, p in rnn.named_parameters():\n",
    "    print(t, p.shape)\n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print()\n",
    "print(\"Out:\\n\", out.shape)  # Concatenated Hidden states from both layers\n",
    "print(\n",
    "    \"h:\\n\", h.shape\n",
    ")  # Hidden states last element from  both : 2*num_layers*hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скрытое состояние\n",
    "\n",
    "Как вы уже могли отметить, RNN ячейку можно инициализировать собственным начальным вектором. А затем подавать туда скрытое состояние на каждой итерации. **Или не подавать.**\n",
    "\n",
    "Как так-то?\n",
    "\n",
    "Да, цель скрытого состояния — закодировать историю. Допустим, ваши входные данные представляют собой последовательность данных со 2 по 11 день, и закодированная история в скрытом состоянии связана только с данными со 2 по 11 день. Таким образом, ваши батчи должны содержать всю историю, необходимую для каждого выходного прогноза.\n",
    "\n",
    "При этом **обязательно** нужно **сбросить** скрытое состояние между батчами, если данные в них независимы. Вы не хотите, чтобы ваше скрытое состояние из вашего прошлого предсказания повлияло на следующее?\n",
    "\n",
    "https://stats.stackexchange.com/questions/470382/what-is-the-use-of-the-hidden-state-in-an-lstm-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример прогнозирования временного ряда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- [How to Remove Non-Stationarity From Time Series](https://www.kaggle.com/code/bextuychiev/how-to-remove-non-stationarity-from-time-series)\n",
    "- [A Guide to Time Series Forecasting in Python](https://builtin.com/data-science/time-series-forecasting-python)\n",
    "- [How to Check if Time Series Data is Stationary with Python?](https://www.geeksforgeeks.org/how-to-check-if-time-series-data-is-stationary-with-python/)\n",
    "- [Complete Guide on Time Series Analysis in Python](https://www.kaggle.com/code/prashant111/complete-guide-on-time-series-analysis-in-python)\n",
    "- [Data transformations and forecasting models: what to use and when](https://people.duke.edu/~rnau/whatuse.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что общего у прогнозирования потребления электроэнергии домохозяйствами, оценки трафика на дорогах в определенные периоды, прогнозировании паводков и прогнозировании цены, по которой акции будут торговаться на фондовой бирже?\n",
    "\n",
    "Все они попадают под понятие данных временных рядов! Вы не можете точно предсказать любой из этих результатов без компонента «время». И по мере того, как в мире вокруг нас генерируется все больше и больше данных, прогнозирование временных рядов становится все более важной областью применения методов ML и DL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория и классические подходы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Разделение данных\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на разбиение временного ряда на **train-val-test**.\n",
    "\n",
    "Если мы поделим ряд на отрезки, точки склейки будут легко предсказываться либо предыдущим, либо средним значением по отрезку. Нужно предсказывать крупные отрезки ряда. И помнить о том, что перемешивать данные нельзя — есть \"прошлое\" и \"будущее\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/fixed_partitioning.jpg\" width=\"700\">\n",
    "\n",
    "<em>Source: <a href=\"https://yuting3656.github.io/yutingblog/coursera-tensorflow-developer-professional-certificate/sequences-time-series-and-prediction/week01-03\">Coursera: Sequences, Time Series and Prediction with TensorFlow</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Компоненты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные понятия в статистическом анализе временных рядов:\n",
    "\n",
    "**Тренд** - компонента, описывающая долгосрочное изменение уровня ряда.\n",
    "\n",
    "**Сезонность** - компонента, обозначаемая как Q, описывает циклические изменения уровня ряда.\n",
    "\n",
    "**Ошибка (random noise)** - непрогнозируемая случайная компонента, описывает нерегулярные изменения в данных, необъяснимые другими компонентами.\n",
    "\n",
    "$$y_i = T + S + ϵ_i$$\n",
    "\n",
    "**Автокорреляция** — статистическая взаимосвязь между последовательностями величин одного ряда. Это один из самых важных коэффициентов в анализе временного ряда. Чтобы посчитать автокорреляцию, используется корреляция между временным рядом и её сдвинутой копией от величины временного сдвига. Сдвиг ряда называется лагом.\n",
    "\n",
    "**Автокорреляционная функция** - автокорреляция при разных лагах, помогает находить повторяющиеся участки сигнала. График называется **коррелограммой**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/autocorrelation_graph.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/693562/\">Анализ временных рядов, применение нейросетей (1 часть)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример\n",
    "\n",
    "Данные о количестве пассажиров за каждый месяц.\n",
    "[Dataset Air Passengers Number of air passengers per month](https://www.kaggle.com/rakannimer/air-passengers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/airline-passengers.csv\"\n",
    ")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = dataset.iloc[:, 1:2].values  # transform dataframe to numpy.array\n",
    "# plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data, label=\"Airline Passangers Data\")\n",
    "plt.title(\"Number of passengers per month\")\n",
    "plt.ylabel(\"#passengers\")\n",
    "plt.xlabel(\"Month\")\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделаем стационарнее**\n",
    "\n",
    "Мы можем видеть четкую сезонность и тенденцию к увеличению в данных.\n",
    "\n",
    "Тенденция и сезонность являются фиксированными компонентами, которые могут быть добавлены к любому нашему прогнозу. Они полезны, но должны быть удалены, чтобы изучить любые другие систематические сигналы, которые могут помочь сделать прогнозы.\n",
    "\n",
    "Временной ряд с сезонностью и удаленными трендами называется стационарным.\n",
    "\n",
    "Чтобы убрать сезонность, мы можем взять сезонную разницу, которая приведет к так называемым сезонно скорректированным временным рядам.\n",
    "\n",
    "Период сезонности составляет один год (12 месяцев). Приведенный ниже код рассчитывает сезонно скорректированный временной ряд и сохраняет его в файл «сезонно-adjusted.csv«."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal difference\n",
    "differenced = dataset.iloc[:, 1:2].diff(12)\n",
    "# trim off the first year of empty data\n",
    "differenced = differenced[12:]\n",
    "# save differenced dataset to file\n",
    "differenced.to_csv(\"seasonally_adjusted.csv\", header=None, index=False)\n",
    "# plot differenced dataset\n",
    "differenced.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку данные за первые 12 месяцев не имеют предварительных данных, с которыми можно было бы провести различие, они должны быть отброшены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Коррелограмма**\n",
    "\n",
    "Показывают корреляцию каждого отсроченного наблюдения и является ли корреляция статистически значимой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "sa = pd.read_csv(\"seasonally_adjusted.csv\", header=None)\n",
    "plot_acf(sa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике показаны значения запаздывания по оси X и корреляции по оси Y между -1 и 1 для отрицательно и положительно коррелированных лагов соответственно. Точки над синей областью указывают на статистическую значимость. Это зона достоверности, по-умолчанию на 0.05.\n",
    "\n",
    "* Корреляция 1 для значения отставания 0 указывает на 100% положительную корреляцию наблюдения с самим собой.\n",
    "* Вторая точка находится в районе 0,75, что означает, что следующая точка на 75% описывается предыдущим значением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Статистические модели предсказания\n",
    "\n",
    "**Авторегрессионная модель** (Auto regression method (AR))\n",
    "\n",
    "Линейная модель, в которой прогнозированная величина является суммой прошлых значений, умноженных на числовой множитель.\n",
    "\n",
    "$$X_t = C + ϕ_1X_{t-1}+ϕ_2X_{t-2}...+ ϵ_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Скользящее среднее** (Moving average method (MA))\n",
    "\n",
    "$$MA_k=  \\frac {p_{n-k+1} + p_{n-k+2} ... p_{n}} {k} = \\frac {1}{k} \\sum ^ {n} _{i= n-k+1} p_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет точек путем создания ряда средних значений различных подмножеств полного набора данных. Скользящее среднее часто применяется для анализа временных рядов акций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/moving_average_method.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/articles/693562/\">Анализ временных рядов, применение нейросетей (1 часть)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARIMA**\n",
    "\n",
    "Метод скользящего среднего с авторегрессией и интегрированием (Auto regressive integrated moving average (ARIMA). И разновидности Seasonable ARIMA, ARIMAX и пр.\n",
    "\n",
    "Для использования модели временной ряд должен быть **стационарным**, т.е. его **среднее и дисперсия должны быть постоянны**.\n",
    "\n",
    "Модель предполагает, что временной ряд содержит три составляющие: авторегресионную, интегрированную и скользящее среднее, которые в модели обозначены $p, d$ и $q$  соответственно:\n",
    "\n",
    "* $p$ - порядок авторегрессии. Позволяет ответить на вопрос, будет ли очередной элемент ряда близок к значению $X$, если к нему были близки $p$ предыдущих значений.\n",
    "* $d$ - порядок интегрирования. Показывает, насколько элемент ряда близок по значению к $d$  предыдущим значениям, если разность между ними минимальна.\n",
    "* $q$ — порядок скользящего среднего. Позволяет установить погрешность модели как линейную комбинацию наблюдавшихся ранее значений ошибок.\n",
    "\n",
    "В общем виде модель ARMA(p,q) выглядит следующим образом:\n",
    "$$y_t = α_1y_{t-1} + ⋯ + α_py_{t-p}\t + ε_t + θ_1y_{t-1} + ⋯ + θ_qy_{t-q}$$, где $a_t$ — коэффициенты авторегрессионной части модели, $ε_t$ — значения ошибки (полагаются независимыми одинаково распределёнными случайными величинами из нормального распределения с нулевым средним), $θ_j$ — коэффициенты скользящего среднего.\n",
    "\n",
    "Если процесс оказывается нестационарным и для приведения его к\n",
    "стационарному виду потребовалось взять несколько разностей, то модель\n",
    "становится **ARIMA(p,d,q)**:\n",
    "\n",
    "$$(Δ^dy_t) = \\sum ^p _{t=1} α_t(Δ^dy_{t-1}) + ε_t + \\sum ^q _{j=1} θ_j(Δ^d ε_{t-j}) $$\n",
    "\n",
    "https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/\n",
    "\n",
    "Проверки на стационарность, примеры https://economy.bsu.by/wp-content/uploads/2016/10/naft_ar_ma.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся библиотечной реализацией. Тем более, что период мы уже вычислили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plotly.plotly import plot_mpl\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "data = dataset.iloc[:, 1:2]\n",
    "result = seasonal_decompose(\n",
    "    x=data, model=\"multiplicative\", extrapolate_trend=\"freq\", period=2\n",
    ")\n",
    "# result_add = seasonal_decompose(x=df_test['listData'], model='additive', extrapolate_trend='freq', period=1)\n",
    "fig = result.plot()\n",
    "# plot_mpl(fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся библиотечной версией ARIMA. Разобьём данные и поставим параметры произвольно. Обучим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "train_data, test_data = data[0 : int(len(data) * 0.9)], data[int(len(data) * 0.9) :]\n",
    "\n",
    "train_arima, test_arima = train_data.values, test_data.values\n",
    "\n",
    "history = [x for x in train_arima]\n",
    "\n",
    "y = test_arima\n",
    "# make first prediction\n",
    "predictions = list()\n",
    "model = ARIMA(history, order=(1, 1, 0))\n",
    "model_fit = model.fit()\n",
    "yhat = model_fit.forecast()[0]\n",
    "predictions.append(yhat)\n",
    "history.append(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling forecasts\n",
    "for i in range(1, len(y)):\n",
    "    # predict\n",
    "    model = ARIMA(history, order=(1, 1, 0))\n",
    "    model_fit = model.fit()\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    # invert transformed prediction\n",
    "    predictions.append(yhat)\n",
    "    # observation\n",
    "    obs = y[i]\n",
    "    history.append(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим метрики. Здесь они нужны лишь для того, чтобы оценивать измнения между моделями с различными параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "mse = mean_squared_error(y, predictions)\n",
    "print(\"MSE: \" + str(mse))\n",
    "mae = mean_absolute_error(y, predictions)\n",
    "print(\"MAE: \" + str(mae))\n",
    "rmse = math.sqrt(mean_squared_error(y, predictions))\n",
    "print(\"RMSE: \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(data.index, data, color=\"green\", label=\"Train\")\n",
    "plt.plot(test_data.index, y, color=\"red\", label=\"Real\")\n",
    "plt.plot(test_data.index, predictions, color=\"blue\", label=\"Predicted\")\n",
    "plt.title(\"ARIMA default prediction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@josemarcialportilla/using-python-and-auto-arima-to-forecast-seasonal-time-series-90877adff03c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание есть, однако можно как-то улучшить? Да так, чтобы без ручного анализа и подбора параметров?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "stepwise_model = auto_arima(\n",
    "    data,\n",
    "    start_p=1,\n",
    "    start_q=1,\n",
    "    max_p=3,\n",
    "    max_q=3,\n",
    "    m=12,\n",
    "    start_P=0,\n",
    "    seasonal=True,\n",
    "    d=1,\n",
    "    D=1,\n",
    "    trace=True,\n",
    "    error_action=\"ignore\",\n",
    "    suppress_warnings=True,\n",
    "    stepwise=True,\n",
    ")\n",
    "print(stepwise_model.aic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_model.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_forecast = stepwise_model.predict(n_periods=len(test_data))\n",
    "# This returns an array of predictions:\n",
    "print(future_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_forecast = pd.DataFrame(\n",
    "    future_forecast, index=test_data.index, columns=[\"Prediction\"]\n",
    ")\n",
    "test_preds = pd.concat([test_data, future_forecast], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(data.index, data, color=\"green\", label=\"Train\")\n",
    "plt.plot(test_preds.index, test_preds[\"Passengers\"], color=\"red\", label=\"Real\")\n",
    "plt.plot(test_preds.index, test_preds[\"Prediction\"], color=\"blue\", label=\"Predicted\")\n",
    "plt.title(\"ARIMA with optimal parameters\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "mse = mean_squared_error(test_preds[\"Passengers\"], test_preds[\"Prediction\"])\n",
    "print(\"MSE: \" + str(mse))\n",
    "mae = mean_absolute_error(test_preds[\"Passengers\"], test_preds[\"Prediction\"])\n",
    "print(\"MAE: \" + str(mae))\n",
    "rmse = math.sqrt(mean_squared_error(test_preds[\"Passengers\"], test_preds[\"Prediction\"]))\n",
    "print(\"RMSE: \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось лучше по-метрикам и визуально."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Фильтр Калмана**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иным мощным методом является Фильтр Калмана."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/kalman_filter_scheme.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://habr.com/ru/articles/166693/\n",
    "\n",
    "https://habr.com/ru/articles/140274/\n",
    "\n",
    "https://habr.com/ru/companies/singularis/articles/516798/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейросетевой подход\n",
    "[Time Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шкалирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max normalization\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "print(\"Initial statistics:\")\n",
    "print(\"Minimum value:\", repr(td_min).rjust(5))\n",
    "print(\"Maximum value:\", repr(td_max).rjust(5))\n",
    "\n",
    "training_data = (training_data - td_min) / (td_max - td_min)\n",
    "print(\"\\nResulting statistics:\")\n",
    "print(\"Minimum value:\", repr(training_data.min()).rjust(5))\n",
    "print(\"Maximum value:\", repr(training_data.max()).rjust(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование ансамблей данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы хотим научиться предсказывать следующие значение на основе предыдущих, нам нужно подготовить данные соответствующим образом.\n",
    "\n",
    "Разобьем весь массив данных на фрагменты вида\n",
    "\n",
    "$x \\to y$,\n",
    "\n",
    "где $x$ — это подпоследовательность, например, записи с 1-й по 8-ю, а $y$ — это значение из 9-й записи, то самое, которое мы хотим предсказать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# create data \"ensemble\"\n",
    "\n",
    "\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "        _x = data[i : (i + seq_length)]  # picking several sequential observations\n",
    "        _y = data[i + seq_length]  # picking the subsequent observation\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return torch.Tensor(np.array(x)), torch.Tensor(np.array(y))\n",
    "\n",
    "\n",
    "# set length of the ensemble; accuracy of the predictions and\n",
    "# speed perfomance almost always depend on it size\n",
    "seq_length = 8  # compare 2 and 32\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "print(\"Example of the obtained data:\\n\")\n",
    "print(\"Data corresponding to the first x:\")\n",
    "print(x[0])\n",
    "print(\"Data corresponding to the first y:\")\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря такому подходу мы можем работать с RNN моделью так же, как работали со сверточными моделями, подавая на вход такую подпоследовательность + результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разобьем на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(y) * 0.8)\n",
    "\n",
    "x_train = x[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "x_test = x[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"x shape:\", x_train.shape)\n",
    "print(\"y shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "print(\"x shape:\", x_test.shape)\n",
    "print(\"y shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на параметр **batch_first**. Он позволяет записывать данные в привычном формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AirTrafficPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size, hidden_size=hidden_size, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x: \",x.shape) # 108 x 8 x 1 : [batch_size, seq_len, input_size]\n",
    "        out, h = self.rnn(x)\n",
    "        # print(\"out: \", out.shape) # 108 x 8 x 4 : [batch_size, seq_len, hidden_size] Useless!\n",
    "        # print(\"h : \", h.shape) # 1 x 108 x 4 [ num_layers, batch_size, hidden_size]\n",
    "        y = self.fc(h)\n",
    "        # print(\"y\",y.shape) # 1 x 108 x 1\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря подготовке данных процесс обучения не будет отличаться от того, что мы использовали на прошедших занятиях.\n",
    "\n",
    "В силу того, что датасет маленький и все данные поместились в один batch, итерирования по batch-ам в явном виде здесь не происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_train(model, num_epochs=2000, learning_rate=0.01):\n",
    "    criterion = torch.nn.MSELoss()  # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        y_pred, h = model(x_train)  # we don't use h there, but we can!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # obtain the loss\n",
    "        loss = criterion(y_pred[0], y_train)  # for shape compatibility\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch},\".ljust(15), \"loss: %1.5f\" % (loss.item()))\n",
    "\n",
    "\n",
    "print(\"Simple RNN training process with MSE loss:\")\n",
    "input_size = 1\n",
    "hidden_size = 4\n",
    "rnn = AirTrafficPredictor(input_size, hidden_size)\n",
    "time_series_train(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_plot(train_predict):\n",
    "    data_predict = train_predict.data\n",
    "    y_data_plot = y.data\n",
    "\n",
    "    # Denormalize\n",
    "    data_predict = data_predict[0] * (td_max - td_min) + td_min\n",
    "    y_data_plot = y_data_plot * (td_max - td_min) + td_min\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.axvline(x=train_size, c=\"r\", linestyle=\"--\")\n",
    "    # shifting the curve as first y-value not correspond first value overall\n",
    "    plt.plot(seq_length + np.arange(y_data_plot.shape[0]), y_data_plot)\n",
    "    plt.plot(seq_length + np.arange(y_data_plot.shape[0]), data_predict)\n",
    "\n",
    "    plt.title(\"Number of passengers per month\")\n",
    "    plt.ylabel(\"#passengers\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "\n",
    "    plt.legend([\"Train/Test separation\", \"Real\", \"Predicted\"])\n",
    "    plt.grid(axis=\"x\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "rnn.eval()\n",
    "train_predict, h = rnn(x)\n",
    "time_series_plot(train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что модель в принципе справляется с задачей. Если подбирать размер hidden size, качество станет лучше. Или мы добьёмся того, что нейросеть будет предсказывать просто линию (большой hidden size — нейросеть выучивает, что нужно предсказывать следующее значение по предыщущему).\n",
    "\n",
    "Но посмотрим, как далее справятся более мощные архитектуры, и уже позднее напишем окончательные выводы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблемы RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретически, можно было бы сразу пропустить все данные через сеть и затем вычислить градиент, однако возникнут следующие проблемы:\n",
    "\n",
    " - большие последовательности не поместятся в памяти;\n",
    " - так как цепочка будет очень длинной, возникнет затухание/взрыв градиента;\n",
    " - по мере прохождения сигнала по цепи контекст затирается.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть длинная последовательность. Если мы сразу предсказываем, то в каждый момент времени нужно распространить Loss. И все ячейки нужно обновить во время backpropogation. Все градиенты нужно посчитать. Возникают проблемы, связанные с нехваткой памяти.\n",
    "\n",
    "Есть специальные тесты для проверки, контекст какой длины использует RNN при предсказании. Если мы делаем предсказание только в последней ячейке, может оказаться, что используется, скажем, информация только о последних 10 словах предложения.\n",
    "\n",
    "Функция активации Tanh постепенно затирает контекст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/backprop_through_time.png\"><center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://cs231n.stanford.edu/slides/2021/lecture_10.pdf\">CS231n: Recurrent Neural Network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затухающий/взрывающийся градиент (Vanishing/exploding gradient) — явления затухающего и взрывающегося градиента часто встречаются в контексте RNN. И при большой длине последовательности это становится критичным. Причина в том, что зависимость величины градиента от числа слоёв экспоненциальная, поскольку веса умножаются многократно.\n",
    "\n",
    "$dL ∝ (W)^N$.\n",
    "\n",
    "$W > 1$ => взрыв\n",
    "\n",
    "$W < 1$ => затухание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/simple_rnn_backprop.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из путей решения проблемы: **градиентное отсечение** (Gradient clipping) — метод, который ограничивает максимально допустимое значение градиента, позволяя избежать градиентного взрыва.\n",
    "\n",
    "А от затухания градиента может помочь **пропускание** **градиента по частям**, на сколько-то шагов по времени назад или вперёд. А не через всю нейросеть. Да, градиент будет не совсем точо считаться, и мы будем терять в качестве. И это нам спасает память."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/truncated_backprop.png\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://cs231n.stanford.edu/slides/2021/lecture_10.pdf\">CS231n: Recurrent Neural Network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычная RNN имела множество проблем, в том числе, в ней очень быстро затухала информация о предыдущих словах в предложении. Помимо этого были проблемы с затуханием/взрывом самого градиента.\n",
    "\n",
    "Эти проблемы были частично решены в LSTM, предложенной в [Hochreiter & Schmidhuber (1997)](http://www.bioinf.jku.at/publications/older/2604.pdf)\n",
    "\n",
    "В обычной RNN в ячейке был только один путь передачи информации. На каждом шаге мы сливали информацию, накопленную с предыдущих шагов, с текущей:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/simple_rnn_h_state.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом информация о предыдущих токенах очень быстро затухает, и теряется общая информация о предложении.\n",
    "\n",
    "Структура ячейки LSTM намного сложнее. Здесь есть целых 4 линейных слоя, каждый из которых выполняет разные задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/lstm_chain.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/lstm_chain_notation.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large f_t = σ(W_f \\cdot [h_{t-1}, x_t] + b_f) - forget \\quad gate$\n",
    "\n",
    "$\\large i_t = σ(W_i \\cdot [h_{t-1}, x_t] + b_i) - input \\quad gate$\n",
    "\n",
    "$\\large C^\\prime_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_{C^\\prime}) - candidate \\quad cell \\quad state$\n",
    "\n",
    "$\\large C_t = f_t\\otimes C_{t-1} + i_t \\otimes C^\\prime_t - cell \\quad state$\n",
    "\n",
    "$\\large o_t = σ(W_o \\cdot [h_{t-1}, x_t] + b_o) - output \\quad gate$\n",
    "\n",
    "$\\large h_t = o_t\\otimes \\tanh(C_t) - block \\quad output$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главное нововведение: в LSTM добавлен путь $c$, который по задумке должен этот общий контекст сохранять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/lstm_c_state_highway.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другими словами, путь $c$ (cell state, иногда называется highway, магистраль)  помогает нейросети сохранять важную информацию, встретившуюся в какой-то момент в предложении, все время, пока эта информация требуется.\n",
    "\n",
    "По формулам также видно, как возросла сложность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vanilla RNN:**\n",
    "\n",
    "$\\large h_t = tanh \\begin{pmatrix} W \\begin{pmatrix} h_{t-1}\\\\ x_t \\end {pmatrix}\\end{pmatrix}$\n",
    "\n",
    "**LSTM:**\n",
    "\n",
    "$\\large \\begin{pmatrix} i\\\\ f\\\\ o\\\\ g \\end{pmatrix} = \\begin{pmatrix} \\sigma \\\\ \\sigma \\\\ \\sigma \\\\ \\tanh \\end{pmatrix} W \\begin{pmatrix} h_{t-1}\\\\ x_t \\end{pmatrix}$\n",
    "\n",
    "Два вектора на каждом временном промежутке:\n",
    "\n",
    "$c_t = f \\odot c_{t-1} + i \\odot g$ — сell state\n",
    "\n",
    "$h_t = o \\odot tanh(c_t)$ — hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyTorch LSTMCELL](https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
    "\n",
    "Интерфейс отличается от RNNCell количеством входов и выходов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lstm_cell = torch.nn.LSTMCell(input_size=3, hidden_size=4)\n",
    "input = torch.randn(1, 3)  # batch, input_size\n",
    "h_0 = torch.randn(1, 4)\n",
    "c_0 = torch.randn(1, 4)\n",
    "h, c = lstm_cell(input, (h_0, c_0))  # second arg is tuple\n",
    "print(\"Shape of h:\", h.shape)  # batch, hidden_size\n",
    "print(\"Shape of c:\", c.shape)  # batch, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличие от RNN состоит в том, что кроме $h$ возвращается еще и $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "lstm = nn.LSTM(input_size=4, hidden_size=5)\n",
    "input = torch.randn(3, 2, 4)  # seq_len, batch, input_size\n",
    "out, (h, c) = lstm(input)  # h and c returned in tuple\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h\".ljust(15), h.shape)  # batch, hidden_size\n",
    "print(\"Shape of c\".ljust(15), c.shape)  # batch, hidden_size\n",
    "print(\n",
    "    \"Output shape:\".ljust(15), out.shape\n",
    ")  # seq_len, batch, hidden_size : h for each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример использования на задаче с временным рядом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы убедиться в работоспособности конструкции, заменим RNN блок на LSTM в задаче предсказания временного ряда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/airline-passengers.csv\"\n",
    ")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max normalization\n",
    "training_data = dataset.iloc[:, 1:2].values\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "print(\"Initial statistics:\")\n",
    "print(\"Minimum value:\", repr(td_min).rjust(5))\n",
    "print(\"Maximum value:\", repr(td_max).rjust(5))\n",
    "\n",
    "training_data = (training_data - td_min) / (td_max - td_min)\n",
    "print(\"\\nResulting statistics:\")\n",
    "print(\"Minimum value:\", repr(training_data.min()).rjust(5))\n",
    "print(\"Maximum value:\", repr(training_data.max()).rjust(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create data \"ensemble\"\n",
    "\n",
    "\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - seq_length):\n",
    "        _x = data[i : (i + seq_length)]  # picking several sequential observations\n",
    "        _y = data[i + seq_length]  # picking the subsequent observation\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return torch.Tensor(np.array(x)), torch.Tensor(np.array(y))\n",
    "\n",
    "\n",
    "# set length of the ensemble; accuracy of the predictions and\n",
    "# speed perfomance almost always depend on it size\n",
    "seq_length = 8  # compare 2 and 32\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "\n",
    "train_size = int(len(y) * 0.8)\n",
    "\n",
    "x_train = x[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "x_test = x[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(\"Train data:\")\n",
    "print(\"x shape:\", x_train.shape)\n",
    "print(\"y shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\nTest data:\")\n",
    "print(\"x shape:\", x_test.shape)\n",
    "print(\"y shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_plot(train_predict):\n",
    "    data_predict = train_predict.data\n",
    "    y_data_plot = y.data\n",
    "\n",
    "    # Denormalize\n",
    "    data_predict = data_predict[0] * (td_max - td_min) + td_min\n",
    "    y_data_plot = y_data_plot * (td_max - td_min) + td_min\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.axvline(x=train_size, c=\"r\", linestyle=\"--\")\n",
    "    # shifting the curve as first y-value not correspond first value overall\n",
    "    plt.plot(seq_length + np.arange(y_data_plot.shape[0]), y_data_plot)\n",
    "    plt.plot(seq_length + np.arange(y_data_plot.shape[0]), data_predict)\n",
    "\n",
    "    plt.title(\"Number of passengers per month\")\n",
    "    plt.ylabel(\"#passengers\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.xticks(labels_to_display, dataset[\"Month\"][labels_to_display])\n",
    "\n",
    "    plt.legend([\"Train/Test separation\", \"Real\", \"Predicted\"])\n",
    "    plt.grid(axis=\"x\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new LSTM based model\n",
    "\n",
    "\n",
    "class LSTMAirTrafficPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, hidden_size=hidden_size, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h, c) = self.lstm(x)\n",
    "        y = self.fc(h)\n",
    "        return y\n",
    "\n",
    "\n",
    "lstm = LSTMAirTrafficPredictor(input_size=1, hidden_size=4)\n",
    "input = torch.randn((108, 8, 1))\n",
    "out = lstm(input)\n",
    "\n",
    "print(\n",
    "    \"LSTM model we use consider first input dimension as a batch dimension, output dimension logic has not changed:\"\n",
    ")\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Output shape:\".ljust(15), out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.train()\n",
    "\n",
    "print(\"LSTM training process with MSE loss:\")\n",
    "\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = lstm(x_train)\n",
    "    optimizer.zero_grad()\n",
    "    # print(outputs.shape)\n",
    "    loss = criterion(y_pred, y_train.unsqueeze(0))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch},\".ljust(15), \"loss: %1.5f\" % (loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lstm.eval()\n",
    "train_predict = lstm(x)\n",
    "labels_to_display = [i for i in range(training_data.shape[0]) if i % 12 == 0]\n",
    "time_series_plot(train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "1. Использование LSTM слоев при прогнозировании нестационарных временных рядов — отличное решение, т.к. нейронная сеть способна самостоятельно выделить динамики изменениях составляющих временного ряда. Правда, в более сложных случаях (трейдинге, например, или чтении и расшифровки волн мозга) приходится прибегать к feature engineering.\n",
    "2. Сложность нейронной сети должна соответствовать сложности подаваемых в нее данных. С ростом ансамбля и числа нейронов увеличивается заучивание тренировочной выборки и теряется способность к обобщению.\n",
    "3. Предварительный анализ цикличности в данных (если она есть) помогает понять оптимальный размер ансамбля (тут видно, что цикл, в среднем, составляет 8 интервалов).\n",
    "4. Также результат может зависеть от типа масштабирования, который Вы применяете. Нужно знать принципы работы scaler'ов и не стесняться экспериментировать с ними. См. [Feature Scaling Data with Scikit-Learn for Machine Learning in Python](https://stackabuse.com/feature-scaling-data-with-scikit-learn-for-machine-learning-in-python/) и [Hands-On Machine Learning with Scikit-Learn and TensorFlow, ч.4](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/ch04.html1).\n",
    "5. При всей выгодности применения нейронных сетей, необходимо быть осторожным с автокорреляцией (см. статью [How to avoid machine learning pitfalls:\n",
    "a guide for academic researchers](https://arxiv.org/pdf/2108.02497.pdf))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модификации LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было предложено множество модификаций структуры LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peephole connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, введение возможности всем gates напрямую подсматривать в вектор контекста $C$. Что, безусловно, логично: сложно решать, что делать с вектором $C$ (что из него стирать, что в него добавлять, что из него брать), если видишь его только опосредованно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/lstm_peepholes_connections.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large f_t = \\sigma(W_f \\cdot [C_{t-1}, h_{t-1}, x_t] + b_f)$\n",
    "\n",
    "$\\large i_t = \\sigma(W_i \\cdot [C_{t-1}, h_{t-1}, x_t] + b_i)$\n",
    "\n",
    "$\\large o_t = \\sigma(W_o \\cdot [C_t, h_{t-1}, x_t] + b_o)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение forget и input gates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также кажется, что правильно требовать от нейросети принимать решение о записи в вектор и стирании из него информации $C$ одновременно. Если что-то стираем, надо что-то записать. И наоборот."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/lstm_join_input_and_forget_gate.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large C_t = f_t * C_{t-1} + (1-f_t) * \\tilde C_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU (Gated reccurent unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая известная модификация LSTM — GRU. Она более компактна за счет сильных упрощений в сравнении со стандартной LSTM.\n",
    "\n",
    "Главные изменения: объединены forget и input gates, слиты $h_t$ и $C_t$, которые в обычной LSTM только участвовали в формировании друг друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/gru_basic_block.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "$\\large r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "$\\large \\tilde h_t = tanh(W \\cdot [r_t * h_{t-1}, x_t])$\n",
    "\n",
    "$\\large h_t = (1-z_t) * h_{t-1} + z_t * \\tilde h_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = torch.nn.GRU(input_size=4, hidden_size=3)\n",
    "input = torch.randn(2, 1, 4)  # seq_len, batch, input_size\n",
    "h0 = torch.randn(1, 1, 3)\n",
    "output, h = gru(input, h0)\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h:\".ljust(15), h.shape)  # last h\n",
    "print(\"Output shape:\".ljust(15), output.shape)  # seq_len = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практический опыт исследователей: иногда лучше работает GRU, иногда — LSTM. Точный рецепт успеха сказать нельзя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример посимвольной генерации текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Github RNN-walkthrough](https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb)\n",
    "\n",
    "Одним из основных направлений использования рекуррентных сетей является работа с текстами:\n",
    "- генерация (Language modeling)\n",
    "- перевод (Machine Translation)\n",
    "\n",
    "Давайте посмотрим, как решаются такого рода задачи.\n",
    "\n",
    "Начнем с относительно простой задачи — посимвольной генерации текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постановка задачи:** предсказать следующий символ в последовательности.\n",
    "\n",
    "- исходный текст:\n",
    "'hey how are you'\n",
    "\n",
    "- искаженный текст:\n",
    "'hey how are yo'\n",
    "\n",
    "- Верное предсказание:\n",
    "'u'\n",
    "\n",
    "Теоретически эту технику можно использовать для генерации подсказок при наборе текстов, исправления ошибок или восстановления частично утраченного текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/character_by_character_generation_example.gif\" width=\"400\">\n",
    "\n",
    "<em>Source: <a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">The Unreasonable Effectiveness of Recurrent Neural Networks</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Зафиксировать словарь\n",
    "2. Разбить данные\n",
    "3. Выполнить кодирование символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "text = [\"hey how are you\", \"good i am fine\", \"have a nice day\"]\n",
    "\n",
    "# Join all the sentences together and extract the unique characters\n",
    "# from the combined sentences\n",
    "chars = set(\"\".join(text))\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}\n",
    "\n",
    "print(\"Dictionary for mapping character to the integer:\")\n",
    "pprint.pprint(char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо ASCII символа, каждой букве мы сопоставили номер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выравнивание данных (Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN допускают работу с данными переменной длины. Но чтобы поместить предложения в batch, надо их выровнять.\n",
    "\n",
    "Обычно размер батча делают равным самому длинному предложению, а остальные просто дополняют пробелами (или спецсимволами) до этого размера.  Также хорошей идеей будет отметить специальным символом начало предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sent) for sent in text]\n",
    "maxlen = max(lengths)\n",
    "print(f\"The longest string has {maxlen} characters.\\n\")\n",
    "\n",
    "print(f\"Initial texts:\\n{text}\")\n",
    "# A simple loop that loops through the list of sentences and adds\n",
    "# a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "for i in range(len(text)):\n",
    "    while len(text[i]) < maxlen:\n",
    "        text[i] += \" \"\n",
    "\n",
    "print(f\"Resulting texts:\\n{text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве входа будем использовать предложение без последнего символа:\n",
    "\n",
    "**'hey how are yo'**\n",
    "\n",
    "В качестве результата — предложение, в котором он сгенерирован:\n",
    "\n",
    "**'ey how are you'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "\n",
    "    # Remove first character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "\n",
    "    print(\"Input sequence:\".ljust(18), f\"'{input_seq[i]}'\")\n",
    "    print(\"Target sequence:\".ljust(18), f\"'{target_seq[i]}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь символы надо перевести в числа. Для этого мы уже построили словарь.\n",
    "\n",
    "P.S. Запускать блок только один раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "    print(\"Encodded input sequence:\".ljust(25), input_seq[i])\n",
    "    print(\"Encodded target sequence:\".ljust(25), target_seq[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь из чисел надо сделать вектора.\n",
    "\n",
    "Почему бы не оставить числа?\n",
    "В прошлом примере модель хорошо с ними работала.\n",
    "\n",
    "В прошлом примере использовался MSE, и на выходе было число.\n",
    "\n",
    "Если бы мы определили отношение порядка над номерами букв, то что-то подобное можно было бы сделать.\n",
    "\n",
    "Однако сейчас мы предсказываем класс буквы.\n",
    "Поэтому на входе и на выходе должен быть вектор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/one_hot_encoding_softmax.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(text)\n",
    "\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "\n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features\n",
    "\n",
    "\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
    "print(\n",
    "    \"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(\n",
    "        input_seq.shape\n",
    "    )\n",
    ")\n",
    "print(input_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый символ закодировали вектором.\n",
    "Не слишком экономно, зато удобно умножать на матрицу весов.\n",
    "\n",
    "P.S. Запускать только один раз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример: Language Modeling**\n",
    "\n",
    "Кодируем буквы при помощи **one-hot кодирования** и подаем на входной слой.\n",
    "\n",
    "$\\begin{bmatrix} w_{11} & w_{12} & w_{13} & w_{14} \\\\ w_{21} & w_{22} & w_{23} & w_{24} \\\\ w_{31} & w_{32} & w_{33} & w_{34} \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 0\\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} w_{11} \\\\ w_{21} \\\\ w_{31}\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/language_modeling.png\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Умножение матрицы на one-hot представление просто достает соответствующую ненулевому значению колонку из матрицы весов.\n",
    "Поэтому часто вместо напсания двух отдельных слоев (one-hot + линейного) делают просто слой, называемый **Embedding Layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "import torch\n",
    "\n",
    "input_seq = torch.Tensor(input_seq)\n",
    "target_seq = torch.Tensor(target_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NextCharacterGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size=hidden_dim, batch_first=True)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden_0 = torch.zeros(\n",
    "            1, batch_size, self.rnn.hidden_size\n",
    "        )  # 1 correspond to number of layers\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden_0)\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # Need Only if n_layers > 1\n",
    "        out = out.contiguous().view(-1, self.rnn.hidden_size)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = NextCharacterGenerator(\n",
    "    input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1\n",
    ")\n",
    "\n",
    "# Define hyperparameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training Run\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    optimizer.zero_grad()  # Clears existing gradients from previous epoch\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward()  # Does backpropagation and calculates gradients\n",
    "    optimizer.step()  # Updates the weights accordingly\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}/{num_epochs}\".ljust(20), end=\" \")\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "\n",
    "    out, hidden = model(character)\n",
    "    # print(out.shape)\n",
    "    # print(out)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden\n",
    "\n",
    "\n",
    "def sample(model, out_len, start=\"hey\"):\n",
    "    model.eval()  # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for _ in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return \"\".join(chars)\n",
    "\n",
    "\n",
    "sample(model, 15, \"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сгенерировать несколько вариантов предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    print(sample(model, 15, \"good\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так получается, потому что сеть инициализирована нулями и никакой случайности нет. Даже если мы добавим в датасет ещё предложение, начинающиеся с *good*, результат не изменится. Также сеть переобучилась на небольшом датасете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы применяли OneHotEncoding для представления наших слов. Проблемы возникают, когда пространство объектов начинает расти и у нас возникают огромные разреженные матрицы.\n",
    "\n",
    "Кроме того, некоторые объекты у нас сразу могут быть ближе: семантически \"король\" и \"королева\" отличаются только полом, различие между словами \"король\" и \"стул\" заметно выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому мы можем переводить наши слова в вектора меньшей размерности, которые при этом будут сравнимы между собой с помощью модуля [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html).\n",
    "\n",
    "[Туториал PyTorch по применению эмбедингов в NLP](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html).\n",
    "\n",
    "[NLP Course for you](https://lena-voita.github.io/nlp_course.html)\n",
    "\n",
    "[Курс по NLP от ШАД](https://github.com/yandexdataschool/nlp_course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/word_representation_intro_min.png\" width=\"600\">\n",
    "\n",
    "<em>Source: <a href=\"https://lena-voita.github.io/nlp_course/word_embeddings.html\">Lena Voita NLP Course</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/lookup_table.gif\" width=\"600\">\n",
    "\n",
    "<em>Source: <a href=\"https://lena-voita.github.io/nlp_course/word_embeddings.html\">Lena Voita NLP Course</a></em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say you have 2 sentences (lowercased, punctuations removed):\n",
    "sentences = \"i am new to pytorch i am having fun\"\n",
    "\n",
    "words = sentences.split(\" \")\n",
    "\n",
    "print(f\"All words: {words} \\n\")\n",
    "\n",
    "vocab = set(words)  # create a vocabulary\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"Vocabulary (unique words): {vocab} \\n\")\n",
    "print(f\"Vocabulary size: {vocab_size} \\n\")\n",
    "\n",
    "# map words to unique indices\n",
    "word2idx = {word: ind for ind, word in enumerate(vocab)}\n",
    "\n",
    "print(f\"Word-to-id dictionary: {word2idx} \\n\")\n",
    "\n",
    "encoded_sentences = [word2idx[word] for word in words]\n",
    "\n",
    "print(f\"Encoded sentences: {encoded_sentences}\")\n",
    "\n",
    "# let's say you want embedding dimension to be 3\n",
    "emb_dim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нейросетевой слой эмбеддингов может быть определён так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "emb_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "\n",
    "word_vectors = emb_layer(torch.LongTensor(encoded_sentences))\n",
    "\n",
    "print(f\"Shape of encoded sentences: {word_vectors.shape} \\n\")\n",
    "\n",
    "print(f\"Shape of weigths: {emb_layer.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этод код инициализирует эмбеддинги согласно нормальному распределению (со средним значением 0 и дисперсией 1). Таким образом, пока что никакого различия или сходства между векторами нет.\n",
    "\n",
    "`word_vectors` — тензор размером (9,3). 9 слов в датасете, размер 3 задан нами.\n",
    "\n",
    "`emb_layer` имеет 1 обучаемый параметр `weight`, который по умолчанию True. Можем проверить так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы не хотим обучать этой слой (например, используем заранее обученные эмбеддинги), мы можем заморозить его веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы хотим использовать заранее определённые веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predefined weights\n",
    "weight = torch.FloatTensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])\n",
    "print(weight.shape)\n",
    "embedding = nn.Embedding.from_pretrained(weight)\n",
    "# get embeddings for ind 0 and 1\n",
    "embedding(torch.LongTensor([0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем уже готовые веса модели Word2Vec, обученные на датасете Google News, состоящeм из 100 миллиардов слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this way for fast loading from Google Drive\n",
    "!gdown \"1ooLZnU8J54YzHtG5xXb3iDnY_TwIOY2K\"\n",
    "\n",
    "# Use this way for loading from our host\n",
    "# !wget https://edunet.kea.su/repo/EduNet-web_dependencies/weights/GoogleNews-vectors-negative300.bin.gz\n",
    "\n",
    "!gunzip -q GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wordvector_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "word_vectors = KeyedVectors.load_word2vec_format(wordvector_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor(word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding.from_pretrained(weight)\n",
    "\n",
    "input = torch.LongTensor([0, 1])\n",
    "\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также мы можем воспользоваться библиотектой [torchtext](https://pytorch.org/text/stable/index.html). Возьмём таблицу весов поменьше, всего 10000 наиболее встречающихся слов. Зададим длину тензора — 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "\n",
    "glove = torchtext.vocab.GloVe(\n",
    "    name=\"6B\", dim=50, max_vectors=10000\n",
    ")  # use 10k most common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если обратиться к документации, мы увидим, что 6В — это [лишь один из вариантов весов](https://pytorch.org/text/stable/_modules/torchtext/vocab/vectors.html#GloVe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_emb = nn.Embedding.from_pretrained(glove.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.LongTensor([0, 1])\n",
    "glove_emb(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код нейросети со слоем nn.Embedding выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_with_Embedding_Layer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNN_with_Embedding_Layer, self).__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(glove.vectors)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Look up the embedding\n",
    "        x = self.emb(x)\n",
    "        # Set an initial hidden state\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        # Forward propagate the RNN\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Pass the output of the last time step to the classifier\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "model = RNN_with_Embedding_Layer(input_size=50, hidden_size=128, num_classes=3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из ключевых этапов в обработке текста — **токенизация**. На этом этапе происходит разделение текста на отдельные единицы — предложения и слова. Затем создается словарь, в который заносятся уникальные лексемы, встретившиеся в корпусе или тексте. На этих этапах можно столкнуться с несколькими проблемами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблема 1. Размер словаря**\n",
    "\n",
    "Самый простой способ токенизации — назначить каждому уникальному слову своё число. Но есть проблема: слов и их форм миллионы, и поэтому словарь таких слов получится чересчур большим, а это будет затруднять обучение модели.\n",
    "\n",
    "Можно разбивать текст не на слова, а на отдельные буквы (char-level tokenization), тогда в словаре будет всего несколько десятков токенов, НО в таком случае уже сам текст после токенизации будет слишком длинным, а это тоже затрудняет обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблема 2. Богатая морфология**\n",
    "\n",
    "\"Нейросеть\", \"сетка\", \"сеть\" являются разными словами, но имеют схожий смысл. Эту проблему классически всегда решал этап **стемминга** (удаление суффикса, приставки, окончания) или **лемматизации** (приведение слова к канонической форме)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблема 3. Сложные слова**\n",
    "\n",
    "Но все проблемы эти этапы не решают. В германских языках (в английском, немецком, шведском и т.д.) очень продуктивно образуются новые сложные слова. Значения таких слов выводятся из значения их элементов. Их можно создавать бесконечно долго, и большинство из них не зафиксировано в «бумажном» словаре."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/swedish_word_example.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Пример шведского названия гаечного ключа для колеса мотоцикла</a></em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://sysblok.ru/nlp/7250/\">Как работает алгоритм токенизации текстов для нейросетей</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с этими языками сложность также возникает на этапе составления словаря. При составлении словаря модели ориентируются на частотность (например, сохраняем слово, если оно встретилось чаще пяти раз), поэтому не будут запоминать такое длинное и сложное слово."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблема 4: Границы слова**\n",
    "\n",
    "Для нас, привыкших к языкам европейского типа, слово — это набор букв между пробелами и знаками препинания. Но в английском языке многие сложные слова пишутся раздельно, а в японском, наоборот, между словами вообще нет пробелов. Поэтому универсальный токенизатор создать было нелегко."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение — Byte Pair Encoding**\n",
    "\n",
    "Изначально алгоритм компрессии BPE позволяет моделям узнавать как можно больше слов при ограниченном объеме словаря.\n",
    "\n",
    "1.   Слово = последовательность токенов\n",
    "2.   Словарь = все токены\n",
    "3.   Повторять, пока не достигли ограничения на размер словаря:\n",
    "\n",
    "     Назначаем новым токеном объединение двух существующих токенов, которое\n",
    "встречается чаще других пар в корпусе (встречаются вместе)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В применении BPE возможны разные варианты. Один из естественных – идём по всем токенам по убыванию частоты, находим соответствующую последовательность символов в корпусе, заменяем на токен."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/subword_tokenization.png\" width = \"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://alexanderdyakonov.wordpress.com/2019/11/29/токенизация-на-подслова-subword-tokenization/\">Токенизация на подслова (Subword Tokenization)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот же способ помогает решить **проблему** **OOV (out of vocabulary)**. В обучающей выборке может не быть слова *Unfriendly*, но поскольку **Unfriendly** = **Un** + **friend** + **ly**, мы можем рассчитывать, что сеть будет правильно обрабатывать / генерировать и слово целиком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/token_unfriendly.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.thoughtvector.io/blog/subword-tokenization/\">Subword Tokenization — Handling Misspellings and Multilingual Data</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но даже это иногда не самый оптимальный выбор. Чтобы сжать словарь ещё сильнее, для обучения GPT OpenAI использовали **byte-level BPE** токенизацию. Эта модификация BPE работает не с текстом, а напрямую с его байтовым представлением. Использование такого трюка позволило сжать словарь до всего-лишь ~50k токенов при том, что с его помощью всё ещё можно выразить любое слово на любом языке мира (и даже эмодзи)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я вам покажу, как это выглядит в трансформерах, но подробнее о них - в следующей лекции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loading and initialization of model and tokenizer\n",
    "model_name_or_path = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path).to(device)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример токенизации**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Нейронные сети - это очень просто и увлекательно\"\n",
    "tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in tokens]\n",
    "\n",
    "print(\"Original text:\", text)\n",
    "print(\"Tokens: \", tokens)\n",
    "print(\"Decoded tokens: \", decoded_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Byte-level токенизатор **не гарантирует**, что для любого токена найдется **соответствующий** символ или слово. Некоторые **токены** **существуют** только **в комбинациях**. Так, представленные токены не декодируются по отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode([167]))\n",
    "print(tokenizer.decode([245]))\n",
    "print(tokenizer.decode([256]))\n",
    "\n",
    "print(tokenizer.decode([167, 245, 256]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть и множество других форм токенизации, подробнее о них можно прочитать в [Summary of the tokenizers](https://huggingface.co/docs/transformers/tokenizer_summary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Размер словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, размер словаря - гиперпараметр. Как его выбрать?\n",
    "\n",
    "Закон Ципфа  — эмпирическая закономерность распределения частоты слов естественного языка: если все слова языка в достаточно большом осмысленном тексте упорядочить по убыванию частоты их использования, то частота слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру. Плотность распределения Ципфа:\n",
    "\n",
    "$$f(rank, s, N) = \\frac {1}{Z(s,N)rank^s}$$\n",
    "\n",
    "где $rank$ - порядковый номер слова после сортировки по убыванию частоты, $s$ - коэффициент скорости убывания вероятности, $N$ - количество слов, $Z(s,N)= \\sum ^N _{i=1} i^{-s}$ - нормализационная константа.\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/zipfs_law.jpg\" width=\"500\">\n",
    "\n",
    "\n",
    "\n",
    "https://arxiv.org/ftp/arxiv/papers/1807/1807.01855.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из этого всего можно сделать два практических вывода: во-первых, частотных слов очень мало. Они слабо информативны, так как встречаются практически во всех документах. А вот редких слов очень много — если мы какое-нибудь редкое слово встречаем в документе, то мы с большой уверенностью можем сказать, к какой тематике он относится. Но проблема в том, что такие слова очень редки, и поэтому они ненадёжны в качестве факторов при принятии решений. Следовательно, нам нужно придерживаться баланса частотности и информативности. Основная идея в том, что чем чаще слово встречается в документе, тем более оно характерно для этого документа, тем лучше описывает его тематику. С другой стороны, чем это слово реже встречается в корпусе, в выборке документов, тем оно более специфично и информативно. За этот баланс отвечают две величины: TF и IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "**TF-IDF** — способ численного представления документа, оценивает  **важность слова в контексте документа**. Состоит из двух множителей $TF$ и $IDF$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая идея, которая стоит за **TF-IDF** — это **если слово часто встречается в документе, оно важное**. За это отвечает $TF$.\n",
    "\n",
    "$TF$ (term frequency) — частота вхождения слова в документ, для которого рассчитывается значение:\n",
    "\n",
    "$$\\large TF(t, d) = \\frac{n_t}{\\sum_{k}n_k}$$\n",
    "\n",
    "$n_t$ — количество повторов слова $t$ в документе $d$,\n",
    "\n",
    "$\\sum_{k}n_k$ — общее количество слов  $t$ в документе $d$ с повторами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая идея **TF-IDF** — **если слово встречается во многих документах, его ценность снижается**.\n",
    "\n",
    "Пример: местоимения встречаются в большинстве текстов, но не несут смысловой нагрузки.\n",
    "\n",
    "За это отвечает $IDF$.\n",
    "\n",
    "$IDF$ (inverse document frequency) — логарифм обратной частоты вхождения слова в документы.\n",
    "$$\\large IDF(t, D) = \\log{\\frac{|D|}{|\\{d_i \\in D| t_i \\in d_i \\}|}}$$\n",
    "\n",
    "где $|D|$ — число документов в коллекции,\n",
    "$|\\{d_i \\in D| t_i \\in d_i \\}|$ — число документов в коллекции со словом $t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая формула:\n",
    "$$\\large TF-IDF(t, d, D) = TF(t,d)⋅IDF(t, D)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Пример работы `TfidfVectorizer` из [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "Каждому документу сопоставляется вектор, равный длине словаря. Ненулевые значения вектора хранятся в виде разреженных матриц [‘scipy.sparse.csr_matrix’](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"Tf-idf dictionary:\", vectorizer.get_feature_names_out())\n",
    "print(\"Tf-idf dictionary len:\", len(vectorizer.get_feature_names_out()))\n",
    "print(\"Tf-idf shape:\", x.shape)\n",
    "print(\"Tf-idf type:\", type(x))\n",
    "print(\"Tf-idf values:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На практике**\n",
    "\n",
    "1. Тексты токенизируются и нормализуются. Если мы решаем работать с N-граммами, то вместо токенизации или после неё выделяем N-граммы.\n",
    "\n",
    "2. Проходимся по всей коллекции документов и, для каждого слова, подсчитываем, в каком количестве документов оно встретилось. Если у нас большая коллекция, то словарь может получиться просто гигантским, особенно если мы работаем с N-граммами, поэтому периодически, во время построения, или после этой процедуры, мы должны выбросить из словаря всё, что считаем неинформативным — слишком редкие и слишком частые слова.\n",
    "\n",
    "3. Затем начинаем строить матрицу признаков. Каждая строчка этой матрицы соответствует документу, а каждый столбец — статистике встречаемости этого слова в документе. Таким образом, для каждого документа мы считаем частоты слов в нём и записываем в соответствующие ячейки таблички веса слов по указанной формуле.\n",
    "\n",
    "4. Переходим к следующему документу.\n",
    "\n",
    "Таким образом, TF-IDF — это способ взвешивания и отбора категориальных признаков в задачах машинного обучения — не только в классификации и не только для текстов. Надо заметить, что TF-IDF никак не использует информацию о метке объекта — это одновременно и преимущество, и недостаток. Преимущество заключается в том, что мы можем использовать TF-IDF, не имея меток, то есть задачах обучения без учителя. Недостаток — в том, что мы теряем информацию или недостаточно эффективно её используем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (TF — term frequency, IDF — inverse document frequency):\n",
    "\n",
    "\n",
    "[[wiki] TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF)\n",
    "\n",
    "[[code] sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "\n",
    "[Ещё несколько способов взвешивания и отбора признаков](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "\n",
    "[TF-IDF Vectorizer scikit-learn](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем решить задачу **sequence-to-sequence**: преобразование последовательности $X$ длины $N$ в последовательность $Y$ длины $T$. $T$ **может быть не равно** $N$.\n",
    "\n",
    "Примеры **sequence-to-sequence** задач:\n",
    "*   машинный перевод,\n",
    "*   генерация ответа на вопрос,\n",
    "*   генерация описания картинки или видео.\n",
    "\n",
    "Для решения таких задач  можно использовать две **RNN**: **кодировщик** и **декодировщик**.\n",
    "* Задача **кодировщика**: обобщить информацию о **входной последовательности** $X = (x_1,..., x_N)$, сформировав **вектор контекста** $C$ фиксированного размера.\n",
    "* Задача **декодировщика**: используя информацию из $C$, сформировать **выходную последовательность** $Y = (y_1, ..., y_T)$.\n",
    "\n",
    "В качестве вектора $C$ можно использовать последнее **скрытое состояние** кодировщика $h_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом:\n",
    "\n",
    "* **вход** — последовательность  $\\large x_1, \\dots, x_N$;\n",
    "* **выход** — последовательность  $\\large y_1, \\dots, y_T$.\n",
    "\n",
    "Кодировщик на основании входной последовательности предсказывает **нулевое скрытое состояние декодировщика и вектор контекста** $\\large с$, который часто равен финальному скрытому состоянию кодировщика.\n",
    "\n",
    "**Кодировщик:** $\\large h_i = f_w(x_i, h_{i_1})$\n",
    "\n",
    "**Декодировщик:** $\\large s_t = g_u(y_{t-1}, s_{t-1}, c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L09/out/seq_to_seq_with_rnn.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом возникает следующая **проблема:** мы пропускаем информацию из входной последовательности через бутылочное горлышко — вектор фиксированного размера $h_N$. Что будет, если размер последовательности 1000?\n",
    "\n",
    "**Идея:** использовать новый вектор контекста на каждом шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном подходе мы используем один **вектор контекста** фиксированной длины $c$, в который собираем информацию со всей **входной последовательности** $(x_1,...,x_N)$.\n",
    "\n",
    "**Входная последовательность** может содержать как единицы, так и тысячи элементов. В задаче машинного перевода **входной последовательностью** может быть:\n",
    "* короткая фраза,\n",
    "* абзац “Войны и мира”.\n",
    "\n",
    "Контекст важен. Для генерации глагола в правильной форме нужно понимать, к какому существительному он относится, а для качественного перевода конца абзаца необходимо понимать, о чем шла речь в его начале."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблемы Sequence-to-Sequence with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом возникают проблемы:\n",
    "- **Вектор контекста** $c$ фиксированной длины не может вместить любое количество информации, поэтому для длинных последовательностей качество будет ухудшаться.\n",
    "- На каждой итерации декодировщика **скрытое состояние** $s_t$ должно сохранять информацию о том, какие элементы **выходной последовательности** уже были сгенерированы. Если $s_t$ не способно вместить эту информацию, модель может зациклиться или потерять часть **выходной последовательности**.\n",
    "\n",
    "**Вектор контекста** $c$ и **скрытые состояния** декодировщика $s_t$ являются “бутылочными горлышками” модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аугментация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели глубокого обучения обычно требуют большого количества данных для обучения.\n",
    "\n",
    "Вместо того, чтобы тратить дни на сбор данных вручную, мы можем использовать методы аугментации для автоматической генерации новых примеров из уже имеющихся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важный момент**: при обучении модели мы используем разбиение данных на `train-val-test`. Аугментации стоит применять только на `train`. Почему так? Конечная цель обучения нейросети — это применение на реальных данных, которые сеть не видела. Поэтому для адекватной оценки качества модели валидационные и тестовые данные изменять не нужно.\n",
    "\n",
    "В любом случае, `test` должен быть отделен от данных еще до того, как они попали в `DataLoader` или нейросеть.\n",
    "\n",
    "Другое дело, что аугментации на тесте можно использовать как метод ансамблирования в случае классификации. Можно взять sample → создать несколько его копий → по-разному их аугментировать → предсказать класс на каждой из этих аугментированных копий → а потом выбрать наиболее вероятный класс голосованием (такой функционал реализован, например, в [YOLOv5](https://github.com/ultralytics/yolov5/blob/d204a61834d0f6b2e73c1f43facf32fbadb6b284/models/yolo.py#L121), о которой речь пойдет в следующих лекциях)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аудио"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим несколько примеров аугментаций аудио. С полным списком можно ознакомиться здесь: [[git] audiomentations](https://github.com/iver56/audiomentations).\n",
    "\n",
    "Импортируем библиотеку и посмотрим на пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/content\")\n",
    "\n",
    "!pip install -q audiomentations\n",
    "\n",
    "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/audio_example.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Get input audio\n",
    "input_audio = \"/content/audio_example.wav\"\n",
    "\n",
    "display(Audio(input_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "data, sr = librosa.load(\"/content/audio_example.wav\")  # sr - sampling rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background Noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import AddGaussianSNR\n",
    "\n",
    "augment = AddGaussianSNR(min_snr_in_db=3, max_snr_in_db=7, p=1)\n",
    "\n",
    "# Augment/transform the audio data\n",
    "augmented_data = augment(samples=data, sample_rate=sr)\n",
    "\n",
    "display(Audio(augmented_data, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним волновые картины и спектрограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import spectrogram\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def produce_plots(input_audio_arr, aug_audio, sr):\n",
    "    f, t, Sxx_in = spectrogram(\n",
    "        input_audio_arr, fs=sr\n",
    "    )  # Compute spectrogram for the original signal (f - frequency, t - time)\n",
    "    f, t, Sxx_aug = spectrogram(aug_audio, fs=sr)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 5))\n",
    "\n",
    "    ax[0, 0].plot(input_audio_arr)\n",
    "    ax[0, 0].set_xlim(0, len(input_audio_arr))\n",
    "    ax[0, 0].set_xticks([])\n",
    "    ax[0, 0].set_title(\"Original audio\")\n",
    "\n",
    "    ax[0, 1].plot(aug_audio)\n",
    "    ax[0, 1].set_xlim(0, len(input_audio_arr))\n",
    "    ax[0, 1].set_xticks([])\n",
    "    ax[0, 1].set_title(\"Augmented  audio\")\n",
    "\n",
    "    ax[1, 0].imshow(\n",
    "        np.log(Sxx_in),\n",
    "        extent=[t.min(), t.max(), f.min(), f.max()],\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"inferno\",\n",
    "    )\n",
    "    ax[1, 0].set_ylabel(\"Frequecny, Hz\")\n",
    "    ax[1, 0].set_xlabel(\"Time,s\")\n",
    "\n",
    "    ax[1, 1].imshow(\n",
    "        np.log(Sxx_aug, where=Sxx_aug > 0),\n",
    "        extent=[t.min(), t.max(), f.min(), f.max()],\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"inferno\",\n",
    "    )\n",
    "    ax[1, 1].set_ylabel(\"Frequecny, Hz\")\n",
    "    ax[1, 1].set_xlabel(\"Time,s\")\n",
    "\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "produce_plots(data, augmented_data, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import TimeStretch\n",
    "\n",
    "augment = TimeStretch(min_rate=0.8, max_rate=1.5, p=1)\n",
    "augmented_data = augment(data, sample_rate=sr)\n",
    "\n",
    "display(Audio(augmented_data, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_plots(data, augmented_data, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitch Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение тональности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import PitchShift\n",
    "\n",
    "augment = PitchShift(min_semitones=1, max_semitones=12, p=1)\n",
    "augmented_data = augment(data, sample_rate=sr)\n",
    "\n",
    "display(Audio(augmented_data, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Совмещаем несколько аугментаций вместе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае с картинками, мы можем совмещать несколько аугментаций вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, Shift\n",
    "\n",
    "augment = Compose(\n",
    "    [\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=1),\n",
    "        TimeStretch(min_rate=0.8, max_rate=1.25, p=1),\n",
    "        PitchShift(min_semitones=-4, max_semitones=4, p=1),\n",
    "        # Shift(min_fraction=-0.5, max_fraction=0.5, p=1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmented_data = augment(data, sample_rate=sr)\n",
    "\n",
    "display(Audio(augmented_data, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_plots(data, augmented_data, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительные библиотеки для аугментации звука (и волновых функций в целом):\n",
    "- [torchaudio](https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html)\n",
    "- [torch-audiomentations](https://github.com/asteroid-team/torch-audiomentations)\n",
    "- [AugLy](https://github.com/facebookresearch/AugLy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь рассмотрим несколько примеров аугментаций текста. С полным списком можно ознакомиться здесь: [[git] библиотеки](https://github.com/makcedward/nlpaug)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input text\n",
    "text = \"Hello, future of AI for Science! How are you today?\"\n",
    "print(f\"input text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аугментация символов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменой на похоже выглядящие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "\n",
    "augment = nac.OcrAug()\n",
    "augmented_text = augment.augment(text)\n",
    "\n",
    "print(f\"Original:\\n{text}\")\n",
    "print(f\"Augmented Texts:\\n{augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С опечатками, которые учитывают расположение символов на клавиатуре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = nac.KeyboardAug()\n",
    "augmented_text = augment.augment(text)\n",
    "\n",
    "print(f\"Original:\\n{text}\")\n",
    "print(f\"Augmented Texts:\\n{augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аугментация слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С орфографическими ошибками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "augment = naw.SpellingAug()\n",
    "augmented_text = augment.augment(text, n=3)\n",
    "\n",
    "print(f\"Original:\\n{text}\")\n",
    "print(f\"Augmented Texts:\\n{augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием модели для предсказания новых слов в зависимости от контекста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# model_type: word2vec, glove or fasttext\n",
    "augment = naw.ContextualWordEmbsAug(model_path=\"bert-base-uncased\", action=\"insert\")\n",
    "augmented_text = augment.augment(text)\n",
    "\n",
    "clear_output()\n",
    "print(f\"Original:\\n{text}\")\n",
    "print(f\"Augmented Texts:\\n{augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аугментация предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем перевести текстовые данные на какой-либо язык, а затем перевести их обратно на язык оригинала. Это может помочь сгенерировать текстовые данные с разными словами, сохраняя при этом контекст текстовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name=\"facebook/wmt19-en-de\", to_model_name=\"facebook/wmt19-de-en\"\n",
    ")\n",
    "augmented_text = back_translation_aug.augment(text)\n",
    "\n",
    "clear_output()\n",
    "print(f\"Original:\\n{text}\")\n",
    "print(f\"Augmented Texts:\\n{augmented_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Instance Crossover Augmentation* — составление новых объектов класса из отдельных предложений того же класса. Например, есть два объекта одного класса \"положительный отзыв\":\n",
    "- <font color='red'>очень удобное приложение. Мне понравилось им пользоваться</font>\n",
    "- <font color='green'>класс! Отличный интерфейс</font>\n",
    "\n",
    "Тогда можно составить новый объект того же класса из их частей:\n",
    "- <font color='red'>очень удобное приложение!</font> <font color='green'>Отличный интерфейс</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно: при любых аугментациях текста на уровне предложений есть шанс создать странные и нелогичные объекты, поэтому использовать их следует с особой осторожностью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительные  библиотеки для аугментации текста:\n",
    "\n",
    "- [TextAugment](https://github.com/dsfsi/textaugment)\n",
    "- [AugLy](https://github.com/facebookresearch/AugLy)\n",
    "\n",
    "[Обзор методов аугментации текста с примерами](https://amitness.com/2020/05/data-augmentation-for-nlp/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NLP метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://habr.com/ru/articles/745642/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глобально метрики качества машинного перевода можно подразделить на **традиционные** и **нейросетевые**.\n",
    "\n",
    "1. Традиционные метрики сравнительно просты в расчете и прозрачны, наиболее известные из них разработаны до бума нейросетей. Чаще всего такие метрики основаны на подсчете числа совпадений символов / слов / cловосочетаний – их называют «lexic overlap metrics».\n",
    "\n",
    "2. Большинство метрик, предложенных после 2016 года – нейросетевые. Первым шагом в применении нейросетей в расчете метрик стало использование векторных представлений слов (embeddings).\n",
    "\n",
    "Сначала близость embeddings машинного и эталонного переводов оценивалась  эвристическими методами (например, для метрик WMD, BERTScore, YiSi).\n",
    "\n",
    "Далее появились нейросети, последние слои которых принимают на вход embeddings машинного и эталонного переводов, а на выходе дают оценку качества перевода (такие как BLEURT, Prism).\n",
    "\n",
    "Затем возникли модели, на вход которых, помимо машинного и эталонного перевода, также может подаваться первоисточник – оригинал переводимого текста (COMET, UniTE).\n",
    "\n",
    "В параллель в рамках решения задачи Quality Estimation развивались модели, сравнивающие напрямую машинный перевод и первоисточник, без эталонного перевода. Так появилось то, что можно назвать безреференсными метриками (reference-free metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/nlp_metrics.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня наиболее используемые – метрики, предложенные до 2010 года, причем в 99% это BLEU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Традиционные метрики\n",
    "\n",
    "Наиболее известны и употребимы такие традиционные метрики как: BLEU, NIST, ROUGE, METEOR, TER, chrF, chrF++, RIBES.\n",
    "\n",
    "**BLEU**\n",
    "\n",
    "BLEU (BiLingual Evaluation Understudy) — метрика, разработанная в IBM (Papineni et al.) в 2001. Основана на подсчете слов (unigrams) и словосочетаний (n‑grams) из машинного перевода, также встречающихся в эталоне. Далее это число делится на общее число слов и словосочетаний в машинном переводе — получается precision. К итоговому precision применяется корректировка — штраф за краткость (brevity penalty), чтобы избежать слишком высоких оценок BLEU для кратких и неполных переводов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROUGE**\n",
    "\n",
    "ROUGE (Recall-Oriented Understudy for Gisting Evaluation) – серия метрик, предложенная Chin-Yew Lin в 2004 для оценки качества решения задачи суммаризации текста.\n",
    "\n",
    "Как и BLEU, ROUGE основаны на подсчете совпадений слов и словосочетаний в машинном переводе и в эталоне. Но для ROUGE считается не только precision, но и recall, а также параметр F1. Это позволяет обойтись без штрафа за краткость.\n",
    "\n",
    "Разные метрики серии ROUGE различаются количеством слов, для которых ищутся совпадения:\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L09/rouge.png\" width=\"500\"> </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METEOR**\n",
    "\n",
    "METEOR (Metric for Evaluation of Translation with Explicit ORdering) – метрика качества машинного перевода, предложенная Banerjee and Lavie в 2005.\n",
    "\n",
    "Оценка основана на подсчете совпадений отдельных слов (unigrams), c расчетом precision, recall, а также обобщающего показателя гармонического среднего (Fmean). В качестве совпадений учитываются не только точные соответствия слов (как в BLEU или ROUGE), но и наличие однокоренных слов или синонимов.\n",
    "\n",
    "Итоговая метрика METEOR рассчитывается путем применения к Fmean штрафа за малую длину либо отсутствие совпадающих n-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Референсные нейросетевые метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BERTScore**\n",
    "\n",
    "BERTScore – метрика, предложенная Zhang et al. в 2019 для оценки качества генерируемого текста. Основана на оценке близости контекстных эмбеддингов, полученных из предобученной нейросетевой модели BERT.\n",
    "\n",
    "Для расчета BERTScore близость двух предложений – сгенерированного моделью и эталонного – оценивается как сумма косинусных подобий между эмбеддингами слов, составляющих эти предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UniTE**\n",
    "\n",
    "UniTE (Unified Translation Evaluation) – метрика, предложенная Wan et al. в 2022 на базе собственной модели. Как и COMET, UniTE использует энкодер XLM-RoBERTa, c дополнительными слоями.\n",
    "\n",
    "Архитектура UniTE предусматривает возможность подать на вход одну из следующих комбинаций: 1) машинный перевод и эталонный перевод, 2) машинный перевод и первоисточник, 3) все три вида данных.\n",
    "\n",
    "В отличие от COMET, где энкодинг каждого из входов выполняется отдельно, в UniTE reference, prediction и source кодируются совместно, и уже в виде единой структуры поступают в расчет оценки качества перевода. В версии UniTE-MRA задействован механизм внимания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Безреференсные метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "НАЙТИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"6\">Литература</font>\n",
    "\n",
    "<font size = \"5\">Обучение на реальных данных</font>\n",
    "\n",
    "[How to avoid machine learning pitfalls: a guide for academic researchers (Lones, 2021)](https://arxiv.org/abs/2108.02497)\n",
    "\n",
    "[Understanding data augmentation for classification: when to warp? (Wong et al., 2016)](https://arxiv.org/abs/1609.08764)\n",
    "\n",
    "[Learning from class-imbalanced data: Review of methods and applications (Haixiang et al., 2017)](https://www.sciencedirect.com/science/article/abs/pii/S0957417416307175?via%3Dihub)\n",
    "\n",
    "<font size = \"5\">Как решить проблему маленького количества данных?</font>\n",
    "\n",
    "[Пост о том, как решать проблему малого количества данных](https://www.kaggle.com/code/rafjaa/dealing-with-very-small-datasets/notebook)\n",
    "\n",
    "<font size = \"5\">Несбалансированные данные</font>\n",
    "\n",
    "[SMOTE explained for noobs - Synthetic Minority Over-sampling TEchnique line by line](https://rikunert.com/SMOTE_explained)\n",
    "\n",
    "[Блог пост про 8 тактик борьбы с несбалансированными классами в наборе данных машинного обучения](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)\n",
    "\n",
    "[Метрики, разработаные для работы с несбалансированными классами.](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/#:~:text=Classification%20Accuracy%20is%20Not%20Enough%3A%20More%20Performance%20Measures%20You%20Can%20Use,-By%20Jason%20Brownlee&text=When%20you%20build%20a%20model,This%20is%20the%20classification%20accuracy)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
