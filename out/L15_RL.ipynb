{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=\"6\">–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning (RL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –∑–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–π –ª–µ–∫—Ü–∏–∏ –Ω–∞—à–µ–≥–æ –∫—É—Ä—Å–∞ –º—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—Å—è —Å –µ—â—ë –æ–¥–Ω–æ–π –ø–∞—Ä–∞–¥–∏–≥–º–æ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, ***–æ–±—É—á–µ–Ω–∏–µ–º —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º***, –∫–æ—Ç–æ—Ä–∞—è –≤ –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è –∫—Ä–∞–π–Ω–µ –∞–∫—Ç–∏–≤–Ω–æ —Ä–∞–∑–≤–∏–≤–∞–µ—Ç—Å—è –∏ –∏–º–µ–µ—Ç —Å–≤–æ–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–µ–¥–º–µ—Ç–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö. –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∏ –Ω–µ–ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤–æ—Å—Ç–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω–æ–π –ø–∞—Ä–∞–¥–∏–≥–º—ã, —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —Å–ø–µ—Ä–≤–∞ –∫–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —É–∂–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –Ω–∞–º –ø–æ–¥—Ö–æ–¥–æ–≤. –í –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ª–µ–∫—Ü–∏—è—Ö –º—ã —Å –≤–∞–º–∏ –ø–æ–∑–Ω–∞–∫–æ–º–∏–ª–∏—Å—å —Å —Ç–∞–∫–∏–º–∏ –ø–∞—Ä–∞–¥–∏–≥–º–∞–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∫–∞–∫ –æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º (supervised learning) –∏ –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ —É—á–∏—Ç–µ–ª—è (unsupervised learning):\n",
    "\n",
    "**–û–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º**:\n",
    "- –°—É—â–µ—Å—Ç–≤—É–µ—Ç –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (–¥–∞—Ç–∞—Å–µ—Ç), –∫–æ—Ç–æ—Ä—ã–π —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏ –∑–∞–¥–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è *–æ–±—ä–µ–∫—Ç–æ–≤* –≤ —Ä–µ—à–∞–µ–º–æ–π –∑–∞–¥–∞—á–µ\n",
    "- –î–ª—è –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–∑–≤–µ—Å—Ç–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ—Ç–∫–æ–π –Ω–æ–º–µ—Ä–∞ –∫–ª–∞—Å—Å–∞, –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —á–∏—Å–ª–æ–º –∏ —Ç–æ–º—É –ø–æ–¥–æ–±–Ω—ã–º) \n",
    "- –ù—É–∂–Ω–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å—Ç–∞–≤–∏—Ç –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é –Ω–µ–∫–æ—Ç–æ—Ä–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ —á–∏—Å–ª–æ -- —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é\n",
    "- –ú–æ–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º—É—é —Ñ—É–Ω–∫—Ü–∏—é (—Ç–∞–∫ –Ω–∞–∑—ã–≤–∞–µ–º—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å, loss), –∫–æ—Ç–æ—Ä–∞—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–¥–æ–±—Ä–∞–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏, –∫–∞–∫ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ç–æ—Ä–∞ –∏—Å–∫–æ–º–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π \n",
    "\n",
    "*–¢–∏–ø–∏—á–Ω—ã–π –ø—Ä–∏–º–µ—Ä* -- —Ä–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ MNIST –ø—Ä–∏ –ø–æ–º–æ—â–∏ CNN.\n",
    "\n",
    "**–û–±—É—á–µ–Ω–∏–µ –±–µ–∑ —É—á–∏—Ç–µ–ª—è**:\n",
    "- –°—É—â–µ—Å—Ç–≤—É–µ—Ç –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (–¥–∞—Ç–∞—Å–µ—Ç), –∫–æ—Ç–æ—Ä—ã–π —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏ –∑–∞–¥–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è *–æ–±—ä–µ–∫—Ç–æ–≤* –≤ —Ä–µ—à–∞–µ–º–æ–π –∑–∞–¥–∞—á–µ\n",
    "- –î–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ ***–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ*** —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "- –ù—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏–º–µ—é—â–∏–µ—Å—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏–π –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –Ω–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥—É—Ç –≤–∏–¥–Ω—ã –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –∏ —Å–∫—Ä—ã—Ç—ã–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –Ω–∏–º–∏\n",
    "\n",
    "*–¢–∏–ø–∏—á–Ω—ã–π –ø—Ä–∏–º–µ—Ä* -- –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥ k-—Å—Ä–µ–¥–Ω–∏—Ö –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ–µ–≥–∫–æ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ –∫–ª—é—á–µ–≤–æ–π –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å—é —ç—Ç–∏—Ö ML-–ø–∞—Ä–∞–¥–∏–≥–º —è–≤–ª—è–µ—Ç—Å—è —Ä–∞–±–æ—Ç–∞ —Å ***–¥–∞—Ç–∞—Å–µ—Ç–æ–º***, –∫–∞–∫ —Å –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–µ–π –∏ –Ω–µ –∏–∑–º–µ–Ω—è—é—â–µ–π—Å—è —Å—É—â–Ω–æ—Å—Ç—å—é. –ü–æ-—Å—É—Ç–∏ –∏–º–µ–Ω–Ω–æ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ—à–∞–µ–º—É—é –≤ —ç—Ç–∏—Ö –ø–æ–¥—Ö–æ–¥–∞—Ö –∑–∞–¥–∞—á—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://fls.avasiliev.xyz/repo/EduNet-content/dev-2.0/L15/out/su_rl_comp.jpg\" alt=\"Drawing\" width=\"650\">\n",
    "\n",
    "\n",
    "<center><em> –û–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º vs –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º  <em><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ–µ–≥–∫–æ –ø—Ä–∏–¥—É–º–∞—Ç—å –ø–æ—Å—Ç–∞–Ω–æ–≤–∫—É –∑–∞–¥–∞—á–∏, –≤ –∫–æ—Ç–æ—Ä–æ–π –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ—Å—Ç–∞–≤–∏—Ç—å —Ç–∞–∫–æ–π –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç. –ù–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—è –∞–≤—Ç–æ–ø–∏–ª–æ—Ç –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è, –º—ã –≤—Ä—è–¥ –ª–∏ —Å–º–æ–∂–µ–º —Å–æ—Å—Ç–∞–≤–∏—Ç—å –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É, –≤ –∫–æ—Ç–æ—Ä–æ–π –±—É–¥—É—Ç –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –¥–æ—Ä–æ–∂–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏ –≤ —É—Å–ª–æ–≤–∏—è—Ö –ø–ª–æ—Ç–Ω–æ–≥–æ –≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –∫ —Ç–æ–º—É –∂–µ –±—É–¥–µ—Ç –∏–∑–≤–µ—Å—Ç–Ω–∞ —Ä–∞–∑–º–µ—Ç–∫–∞ \"ground true\" —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ–º —Ä–µ—à–µ–Ω–∏–∏ –∞–≤—Ç–æ–ø–∏–ª–æ—Ç–∞ –≤ –Ω–∏—Ö.\n",
    "\n",
    "–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–æ–±—Ä–∞—Ç—å –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç –≤–æ –º–Ω–æ–≥–æ–º –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω–∞ —Å —Ç–µ–º, –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ —Å –∞–≤—Ç–æ–ø–∏–ª–æ—Ç–æ–º –∞–≤—Ç–æ–º–æ–±–∏–ª—è, —á—Ç–æ ***—Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –º–æ–∂–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∫—Ä—É–∂–∞—é—â–µ–π –µ–≥–æ*** **—Å—Ä–µ–¥—ã*****, –∫–æ—Ç–æ—Ä–∞—è –∏ —è–≤–ª—è–µ—Ç—Å—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º –¥–∞–Ω–Ω—ã—Ö***. –ü—Ä–∏ —ç—Ç–æ–º, –Ω–µ –∏–º–µ—è –≤—Å–µ–π –∫–∞—Ä—Ç–∏–Ω—ã –≤–æ–∑–º–æ–∂–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –∏ –∏—Ö –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π, –º—ã –º–æ–∂–µ–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –Ω–∞—à–µ–º—É –∞–ª–≥–æ—Ä–∏—Ç–º—É –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º –¥–∞–Ω–Ω—ã—Ö (***—Å—Ä–µ–¥–æ–π***) –∏ –ø–æ—Å—Ç—Ñ–∞–∫—Ç—É–º –æ—Ü–µ–Ω–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏—è –Ω–∞—à–µ–π –∞–ª–≥–æ—Ä–∏—Ç–º–∞ (***–∞–≥–µ–Ω—Ç–∞***) –∏, –∏—Å–ø–æ–ª—å–∑—É—è —ç—Ç—É –æ—Ü–µ–Ω–∫—É, –ø–æ–¥—Å—Ç—Ä–æ–∏—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω —á–∞—â–µ —Å–æ–≤–µ—Ä—à–∞–ª–∞ –∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∏ —Ä–µ–∂–µ –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ. –í –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ —Ç–∞–∫—É—é –æ—Ü–µ–Ω–∫—É –Ω–∞–∑—ã–≤–∞—é—Ç –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ–º (***reward***). –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –æ–±—É—á–µ–Ω–∏–µ —Å—Ç—Ä–æ–∏—Ç—Å—è —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –∞–ª–≥–æ—Ä–∏—Ç–º (–∞–≥–µ–Ω—Ç) —Å—Ç—Ä–µ–º–∏–ª—Å—è –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—É—á–∞–µ–º–æ–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏—è –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è ***(reward) –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ —è–≤–ª—è–µ—Ç—Å—è –∞–Ω–∞–ª–æ–≥–æ–º —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å*** –∏–∑ –ø–∞—Ä–∞–¥–∏–≥–º—ã –æ–±—É—á–µ–Ω–∏—è —Å —É—á–∏—Ç–µ–ª–µ–º, –Ω–æ –∏–º–µ–µ—Ç —Ä—è–¥ –æ—Ç–ª–∏—á–∏–π:\n",
    "\n",
    "- ***–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞*** –∫–∞–∫ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ (—Ä–µ—à–µ–Ω–∏—è –∞–≥–∞–Ω—Ç–∞), —Ç–∞–∫ –∏ ***–¥–ª—è —Å–µ—Ä–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π***\n",
    "  \n",
    "*–î–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –≤ –ø–∞—Ä–∞–¥–∏–≥–º–µ –æ–±—É—á–µ–Ω–∏—è —Å —É—á–∏—Ç–µ–ª–µ–º, –Ω–∞–º –±—ã–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–¥–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π. –í —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å, reward –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º–∞ (—Ä–µ—à–µ–Ω–∏–π). –ù–∞–ø—Ä–∏–º–µ—Ä: –ø–æ–ª—É—á–µ–Ω–∏—é –æ—á–∫–æ–≤ –∑–∞ –ø–æ–±–µ–¥—É –≤ —à–∞—Ö–º–∞—Ç–Ω–æ–π –ø–∞—Ä—Ç–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—ã–±–æ—Ä —Ü–µ–ª–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Ö–æ–¥–æ–≤ –∏–≥—Ä–æ–∫–∞; –±–µ–∑–∞–≤–∞—Ä–∏–π–Ω–∞—è –ø–æ–µ–∑–¥–∫–∞ –±–µ—Å–ø–∏–ª–æ—Ç–Ω–æ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–æ—á–∫–∞–º–∏ –Ω–∞ –∫–∞—Ä—Ç–µ —Ä–∞—Å–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –æ–≥—Ä–æ–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ—à–µ–Ω–∏–π –∑–∞–º–µ–¥–ª–µ–Ω–∏–∏, —É—Å–∫–æ—Ä–µ–Ω–∏–∏ –∏ –ø–æ–≤–æ—Ä–æ—Ç–∞—Ö.*\n",
    "\n",
    "- ***–Ω–µ –æ–±—è–∑–∞–Ω–∞ –±—ã—Ç—å –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º–æ–π***\n",
    "\n",
    "*–í–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –Ω–∞–º–∏ —Ä–∞–Ω–µ–µ –∞–ø–ø–∞—Ä–∞—Ç –æ–±—É—á–µ–Ω–∏—è —Å —É—á–∏—Ç–µ–ª–µ–º –æ—Å–Ω–æ–≤—ã–≤–∞–ª—Å—è –Ω–∞ —Ç–æ–º, —á—Ç–æ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –º—ã –ø–æ–¥–±–∏—Ä–∞–ª–∏ —Ç–∞–∫–∏–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, —á—Ç–æ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º–∞—è loss-—Ñ—É–Ω–∫—Ü–∏—è –∏–º–µ–µ—Ç –ø—Ä–∏ –Ω–∏—Ö –ª–æ–∫–∞–ª—å–Ω—ã–π –º–∏–Ω–∏–º—É–º. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–¥–∞—á, —Ç–∞–∫–∏–µ –∫–∞–∫ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ —Ä–∞–Ω–µ–µ –∑–∞–¥–∞—á–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–≤—Ç–æ–ø–∏–ª–æ—Ç–∞ –∏–ª–∏ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ –∏–≥—Ä–∞—é—â–µ–≥–æ –≤ —à–∞—Ö–º–∞—Ç—ã –∞–ª–≥–æ—Ä–∏—Ç–º–∞, –Ω–µ –¥–æ–ø—É—Å–∫–∞—é—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º—É—é —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞–≥—Ä–∞–¥—ã. –£–±–∏—Ä–∞—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º–æ—Å—Ç–∏ reward-—Ñ—É–Ω–∫—Ü–∏–∏, –º—ã –ª–∏—à–∞–µ–º—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –Ω–∞–º –∞–ª–≥–æ—Ä–∏—Ç–º—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ –∏ –µ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å –Ω–∞–±–æ—Ä –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏, —Ç–æ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç—É –≤—ã–±–æ—Ä–∫—É –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏, –∞ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω—è–µ–º –µ—ë –∫ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º. –ò–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥ –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏, –∫–æ–≥–¥–∞ –æ–±—É—á–∞–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è MNIST, –ø–æ–¥–∞–≤–∞—è –Ω–∞ –≤—Ö–æ–¥ —Å–µ—Ç–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ —Ä—É–∫–æ–ø–∏—Å–Ω—ã—Ö —Ü–∏—Ñ—Ä –∏ —Å—á–∏—Ç–∞—è –≥—Ä–∞–¥–∏–µ–Ω—Ç –¥–ª—è –ø–æ–¥—Å—Ç—Ä–æ–π–∫–∏ –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–Ω–∏—Ü—ã –º–µ–∂–¥—É –∏–∑–≤–µ—Å—Ç–Ω—ã–º –ª—ç–π–±–ª–æ–º —Ü–∏—Ñ—Ä—ã –∏ –≤—ã—Ö–æ–¥–æ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –º—ã –º–æ–∂–µ–º —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞—Ç—å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–¥–∏–≥–º—ã –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º.\n",
    "\n",
    "**–û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–ø–ª–µ–Ω–∏–µ–º**:\n",
    "- –°—É—â–µ—Å—Ç–≤—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö -- —Å—Ä–µ–¥–∞.\n",
    "- –°—Ä–µ–¥–∞ **–Ω–µ –æ–±—è–∑–∞–Ω–∞** –±—ã—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –≤ –≤–∏–¥–µ –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–µ–≥–æ –∏ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "- –°—Ä–µ–¥–∞ **–º–æ–∂–µ—Ç** –∏–∑–º–µ–Ω—è—Ç—å—Å—è –≤ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ (—Ä–µ—à–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞)\n",
    "- –°—É—â–µ—Å—Ç–≤—É–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º (–∞–≥–µ–Ω—Ç), –∫–æ—Ç–æ—Ä—ã–π —Å—Ç—Ä–æ–∏—Ç —Å–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∏–∑ —Å—Ä–µ–¥—ã\n",
    "- –ú–æ–∂–Ω–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –∞–≥–µ–Ω—Ç–∞ —Å–æ —Å—Ä–µ–¥–æ–π (reward, —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞–≥—Ä–∞–¥—ã)\n",
    "- –§—É–Ω–∫—Ü–∏—è –Ω–∞–≥—Ä–∞–¥—ã –Ω–µ **–Ω–µ –æ–±—è–∑–∞–Ω–∞** –±—ã—Ç—å –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º–æ–π –ø–æ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (–∞–≥–µ–Ω—Ç–∞)\n",
    "- –§—É–Ω–∫—Ü–∏—è –Ω–∞–≥—Ä–∞–¥—ã **–º–æ–∂–µ—Ç** –±—ã—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–µ—à–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–∞\n",
    "\n",
    "*–¢–∏–ø–∏—á–Ω—ã–π –ø—Ä–∏–º–µ—Ä* -- –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–≤, –∑–∞–¥–∞—á–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è, RLHF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–æ—Å—Ç–∞—Ç–æ—á–Ω—É—é –∏–Ω—Ç—É–∏—Ü–∏—é –æ –ø–∞—Ä–∞–¥–∏–≥–º–µ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –∏ –æ–± –æ–±–ª–∞—Å—Ç–∏ —Ä–µ—à–∞–µ–º—ã—Ö —Å –µ—ë –ø–æ–º–æ—â—å—é –∑–∞–¥–∞—á –º–æ–∂–Ω–æ –º–æ–∂–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å, –µ—Å–ª–∏ –ø–æ—Å—Ç–∞–≤–∏—Ç—å –∑–Ω–∞–∫ **—Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ –º–µ–∂–¥—É —Ç–µ—Ä–º–∏–Ω–∞–º–∏ \"–æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º\" –∏ \"–æ–±—É—á–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–º –ø—Ä–æ–± –∏ –æ—à–∏–±–æ–∫\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://fls.avasiliev.xyz/repo/EduNet-content/dev-2.0/L15/out/rl_def.jpg\" alt=\"Drawing\" width=\"750\">\n",
    "\n",
    "<center><em> –û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º  <em><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á, —Ä–µ—à–∞–µ–º—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —É –≤—ã–ø—É—Å–∫–Ω–∏–∫–æ–≤ –∫—É—Ä—Å–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ä–∞–±–æ—Ç–µ **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏–µ–º —Å—Ñ–µ—Ä–∏—á–µ—Å–∫–æ–≥–æ —Ä–æ–±–æ—Ç–∞ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏** —Ä–µ—à–∞–ª–∞—Å—å –∑–∞–¥–∞—á–∞ –ø–æ–¥–±–æ—Ä–∞ —É–ø—Ä–∞–≤–ª—è—é—â–µ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è —Ä–æ–±–æ—Ç–∞ , –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –µ–º—É –µ–º—É –¥–≤–∏–≥–∞—Ç—å—Å—è –ø–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –∑–∞—Ä–∞–Ω–µ–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://fls.avasiliev.xyz/repo/EduNet-content/dev-2.0/L15/out/nor_0.png\" width=\"500\"></center>\n",
    "\n",
    "<center>–°—Ñ–µ—Ä–∏—á–µ—Å–∫–∏–π —Ä–æ–±–æ—Ç. <em>Source: <a href=\"https://github.com/EduNetArchive/Nor_RL_sphere_robot\">EduNet-archive: RL sphere robot</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://fls.avasiliev.xyz/repo/EduNet-content/dev-2.0/L15/out/nor_1.png\" width=\"800\"></center>\n",
    "\n",
    "<center>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π –¥–≤–∏–∂–µ–Ω–∏—è —Å –ø–æ–ª—É—á–µ–Ω–Ω—ã–º–∏ –≤—Å–ª–µ–¥—Å—Ç–≤–∏–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–æ–±–æ—Ç–æ–º –ø—Ä–∏ –ø–æ–º–æ—â–∏ RL-–∞–ª–≥–æ—Ä–∏—Ç–º–∞.<br><em>Source: <a href=\"https://github.com/EduNetArchive/Nor_RL_sphere_robot\">EduNet-archive: RL sphere robot</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–¥—Ä–æ–±–Ω–µ–µ:\n",
    "\n",
    "[[video] üì∫ –í–∏–¥–µ–æ–∑–∞–ø–∏—Å—å –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è](https://www.youtube.com/watch?v=X_Wywj8lVHM)\n",
    "\n",
    "[[slides] üìä –ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è](https://docs.google.com/presentation/d/1qBizkCjiv2UsAnfdvN7yyOXY7QD0Ni7i/edit#slide=id.p1)\n",
    "\n",
    "[[git] üêæ –ö–æ–¥](https://github.com/EduNetArchive/Nor_RL_sphere_robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ä–∞–±–æ—Ç–µ **–°–∞–º–æ—é—Å—Ç–∏—Ä—É—é—â–∏–µ—Å—è –æ–ø—Ç–∏—á–µ—Å–∫–∏–µ —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º** –±—ã–ª —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω —É–ø—Ä–∞–≤–ª—è—é—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ —É—Å–∫–æ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–ª–æ–∂–Ω–æ–π –æ–ø—Ç–∏—á–µ—Å–∫–æ–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://fls.avasiliev.xyz/repo/EduNet-content/dev-2.0/L15/out/mareev_0.png\" width=\"500\"></center>\n",
    "\n",
    "<center>–°—Ö–µ–º–∞ –æ–ø—Ç–∏—á–µ—Å–∫–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏, –≥–µ–Ω–µ—Ä–∏—Ä—É—é—â–∞—è —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–æ–∏–µ –ª—É—á–∏ <em>Source: <a href=\"https://github.com/EduNetArchive/Mareev_X_ray_AI\">EduNet-archive: NN for controlling z-axis</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://fls.avasiliev.xyz/repo/EduNet-content/dev-2.0/L15/out/mareev_1.png\" width=\"500\"></center>\n",
    "\n",
    "<center>–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Å—Ç–∞–±–∏–ª–∏—Ü–∞–∏–∏ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ RL-–∞–ª–≥–æ—Ä–∏—Ç–º–∞<em>Source: <a href=\"https://github.com/EduNetArchive/Mareev_X_ray_AI\">EduNet-archive: NN for controlling z-axis</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–¥—Ä–æ–±–Ω–µ–µ:\n",
    "\n",
    "[[video] üì∫ –í–∏–¥–µ–æ–∑–∞–ø–∏—Å—å –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è](https://www.youtube.com/watch?v=mYKIvb9Y2z8)\n",
    "\n",
    "[[slides] üìä –ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è](https://docs.google.com/presentation/d/1gfFgQY_gm6eQ3yrL5p2b_CjbFE2xvzAL/edit#slide=id.p1)\n",
    "\n",
    "[[git] üêæ –ö–æ–¥](https://github.com/EduNetArchive/Mareev_X_ray_AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –£—Å—Ç–æ—è–≤—à–∞—Å—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://fls.avasiliev.xyz/repo/EduNet-content/dev-2.0/L15/out/rl_msuai.png\" alt=\"Drawing\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateless environment in RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∏–∑ —á–µ—Ä–Ω–æ–≤–∏–∫–∞ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞—á–∞ –æ –º–Ω–æ–≥–æ—Ä—É–∫–∏—Ö –±–∞–Ω–¥–∏—Ç–∞—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.altera-media.com/images/information/expert/multiarmed_bandit/header.jpg\" alt=\"Drawing\" width=\"500\"/>\n",
    "TODO: –ó–∞–º–µ–Ω–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –≤—ã—à–µ –Ω–∞ –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∑–∞–¥–∞—á–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gymnasium framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "–î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è, —á—Ç–æ —Ç–∞–∫–æ–µ Gymnasium, –∏ –∫–∞–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º.\n",
    "\n",
    "**Gymnasium** ‚Äî —ç—Ç–æ –Ω–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ RL, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏ RL –∏ —Å—Ä–µ–¥–∞–º–∏. –¢–∞–∫–∂–µ –æ–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–±–æ—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç, –≤ —Ç–æ–º —á–∏—Å–ª–µ, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–∞.\n",
    "\n",
    "[Gymnasium projects](https://openai.com/projects/)\n",
    "\n",
    "[–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](https://gymnasium.farama.org/)\n",
    "\n",
    "[Colab demonstration](https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_12_01_ai_gym.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å—Ä–µ–¥—ã Gym –≤ —Ü–µ–ª–æ–º.\n",
    "__–°—Ä–µ–¥–∞__ ‚Äî —ç—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä–∞—è –º–æ–¥–µ–ª—å –º–∏—Ä–∞, –æ—Ç–≤–µ—á–∞—é—â–∞—è –∑–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –∏ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π, –≤ –∫–æ—Ç–æ—Ä–æ–π —Å—É—â–µ—Å—Ç–≤—É–µ—Ç __–∞–≥–µ–Ω—Ç__, –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã –±—É–¥–µ—Ç –∏–∑–º–µ–Ω—è—Ç—å—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–µ–π—Å—Ç–≤–∏–π –∞–≥–µ–Ω—Ç–∞.\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –¥–ª—è –Ω–∞—á–∞–ª–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é —Å—Ä–µ–¥—É MountainCar, –≤ –∫–æ—Ç–æ—Ä–æ–π —Å—Ç–æ–∏—Ç –∑–∞–¥–∞—á–∞ ‚Äî –¥–æ–≤–µ—Å—Ç–∏ –º–∞—à–∏–Ω—É –¥–æ –≤–µ—Ä—à–∏–Ω—ã –≥–æ—Ä—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L15/mountain-car-v0.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"MountainCar-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í Gym —Å—Ä–µ–¥—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –∫–ª–∞—Å—Å–æ–º `gym.Env`, –∫–æ—Ç–æ—Ä—ã–π —è–≤–ª—è–µ—Ç—Å—è —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º —Å—Ä–µ–¥—ã —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏ –∏ –º–µ—Ç–æ–¥–∞–º–∏:\n",
    "* `action_space`: –æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π, –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –≤ –¥–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ;\n",
    "* `observation_space`: —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞–±–ª—é–¥–µ–Ω–∏–π —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—Ä–µ–¥—ã;\n",
    "* `reset()`: —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—Ä–µ–¥—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ;\n",
    "* `step(action)`: –º–µ—Ç–æ–¥, –ø—Ä–æ–¥–≤–∏–≥–∞—é—â–∏–π —Ä–∞–∑–≤–∏—Ç–∏–µ –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã –Ω–∞ –æ–¥–Ω–æ –¥–µ–π—Å—Ç–≤–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—â–∏–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ —ç—Ç–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è, –∞ –∏–º–µ–Ω–Ω–æ:\n",
    "    1. observation &mdash; —Å–ª–µ–¥—É—é—â–µ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ;\n",
    "    2. reward &mdash; –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ;\n",
    "    3. done &mdash; —Ñ–ª–∞–≥ –∫–æ–Ω—Ü–∞ —ç–ø–∏–∑–æ–¥–∞.\n",
    "\n",
    "–¢–∞–∫–∂–µ –≤ –∫–ª–∞—Å—Å–µ `gym.Env` –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä `render()`, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –≤ –ø–æ–Ω—è—Ç–Ω–æ–π —á–µ–ª–æ–≤–µ–∫—É —Ñ–æ—Ä–º–µ, –Ω–æ –º—ã –Ω–µ –±—É–¥–µ–º –∏—Ö –∫–∞—Å–∞—Ç—å—Å—è –≤ –Ω–∞—à–µ–π –ª–µ–∫—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –¥–µ–π—Å—Ç–≤–∏–π –∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ–π—Å—Ç–≤–∏—è –∞–≥–µ–Ω—Ç–∞ –º–æ–≥—É—Ç –±—ã—Ç—å –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–º–∏, –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º–∏ –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏. –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –∏ –≤–∑–∞–∏–º–Ω–æ –∏—Å–∫–ª—é—á–∞—é—Ç –¥—Ä—É–≥ –¥—Ä—É–≥–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä –Ω–∞–∂–∞—Ç–∏–µ/–æ—Ç–ø—É—Å–∫–∞–Ω–∏–µ –∫–ª–∞–≤–∏—à–∏. –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º –¥–µ–π—Å—Ç–≤–∏—è–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ –Ω–µ–∫–æ—Ç–æ—Ä–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–≤–æ—Ä–æ—Ç —Ä—É–ª—è –æ—Ç -720 –¥–æ 720 –≥—Ä–∞–¥—É—Å–æ–≤. –í —Å—Ä–µ–¥–µ –º—ã –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –∫–∞–∫–∏–º-—Ç–æ –æ–¥–Ω–∏–º –¥–µ–π—Å—Ç–≤–∏–µ–º –∏ –≤–ø–æ–ª–Ω–µ –¥–æ–ø—É—Å—Ç–∏–º–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –Ω–∞–∂–∞—Ç–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–Ω–æ–ø–æ–∫ –∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç —Ä—É–ª—è. –ê–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å –¥–∏—Å–∫—Ä–µ—Ç—ã–º–∏ (–ª–∞–º–ø–æ—á–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞/–≤—ã–∫–ª—é—á–µ–Ω–∞) –∏–ª–∏ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º–∏ (—Ç–µ–Ω–∑–æ—Ä—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ü–≤–µ—Ç–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º).\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç–æ, –∫–∞–∫ –≤—ã–≥–ª—è–¥—è—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –¥–µ–π—Å—Ç–≤–∏–π –∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ —Å—Ä–µ–¥–µ MountainCar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# Action and observation space\n",
    "action_space = env.action_space\n",
    "obs_space = env.observation_space\n",
    "\n",
    "print(f\"The action space: {action_space}\")\n",
    "print(f\"The observation space: {obs_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –≤–∏–¥–∏–º, —á—Ç–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –∏ –¥–µ–π—Å—Ç–≤–∏–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏ `Box` –∏ `Discrete` —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ. –ß—Ç–æ –∂–µ —ç—Ç–æ –∑–∞ –∫–ª–∞—Å—Å—ã? –î–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤ –¥–µ–π—Å—Ç–≤–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –∏ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö) –≤ –æ–¥–Ω–æ –¥–µ–π—Å—Ç–≤–∏–µ, –≤ Gym —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤.\n",
    "\n",
    "* –ö–ª–∞—Å—Å `Discrete` –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–±–æ—Ä $n$ –≤–∑–∞–∏–º–æ–∏—Å–∫–ª—é—á–∞—é—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä, `Discrete(n=4)` –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –¥–µ–π—Å—Ç–≤–∏–π —Å 4 –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ –¥–≤–∏–∂–µ–Ω–∏—è ($\\leftarrow \\downarrow \\rightarrow \\uparrow$)\n",
    "* –ö–ª–∞—Å—Å `Box` –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç n-–º–µ—Ä–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä —Ä–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —á–∏—Å–µ–ª –≤ –Ω–µ–∫–æ—Ç–æ—Ä–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ `[low, high]`. –ù–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞–∂–∞—Ç–∏–µ –ø–µ–¥–∞–ª–∏ –≥–∞–∑–∞ –æ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è 0 –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ &mdash; 1, –º–æ–∂–Ω–æ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ `—Å`, –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ —ç–∫—Ä–∞–Ω–∞ –∏–≥—Ä—ã, –º–æ–∂–Ω–æ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ `Box(low=0, high=255, shape=(100, 50, 3), dtype=np.float32)`\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ —Å—Ä–µ–¥–µ MountainCar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Upper Bound for Env Observation\", env.observation_space.high)\n",
    "print(\"Lower Bound for Env Observation\", env.observation_space.low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–∏—Å—Ö–æ–¥—è—Ç –æ—Ç –∫–ª–∞—Å—Å–∞ `gym.Space`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(env.action_space))\n",
    "print(type(env.observation_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∂–µ —Å—Ç–æ–∏—Ç —É–ø–æ–º—è–Ω—É—Ç—å –µ—â–µ –æ–¥–∏–Ω –¥–æ—á–µ—Ä–Ω–∏–π –∫–ª–∞—Å—Å  `gym.Space` &mdash; `Tuple`, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –æ–±—ä–µ–¥–∏–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –∫–ª–∞—Å—Å–∞ `gym.Space` –≤–º–µ—Å—Ç–µ. –ë–ª–∞–≥–æ–¥–∞—Ä—è —ç—Ç–æ–º—É –∫–ª–∞—Å—Å—É –º—ã –º–æ–∂–µ–º —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –¥–µ–π—Å—Ç–≤–∏–π –∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –ª—é–±–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–í –∫–ª–∞—Å—Å–µ `gym.Space` —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –º–µ—Ç–æ–¥—ã, –ø–æ–∑–≤–æ–ª—è—é—â–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞–º–∏ –¥–µ–π—Å—Ç–≤–∏–π –∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π:\n",
    "* `sample()`: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∏–∑ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π\n",
    "* `contains(x)`: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –∫ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤—É –Ω–∞–±–ª—é–¥–µ–Ω–∏–π\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –≤–æ–∑—å–º–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ, –¥–æ—Å—Ç—É–ø–Ω–æ–µ –Ω–∞–º –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å—Ä–µ–¥—ã MountainCar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_action = env.action_space.sample()  # random number from 0 to 2\n",
    "print(random_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å–æ —Å—Ä–µ–¥–æ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–æ–≤–µ—Ä—à–∏—Ç—å —Å–ª—É—á–∞–π–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –º—ã –≤—ã–±—Ä–∞–ª–∏ –≤—ã—à–µ, –¥–ª—è —ç—Ç–æ–≥–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏–º —Å—Ä–µ–¥—É, —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å—Å—è –≤ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –∏ —Å–¥–µ–ª–∞–µ–º —à–∞–≥ —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–∞ `step()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment and see the initial observation\n",
    "obs, info = env.reset()\n",
    "print(f\"The initial observation is {obs}\")\n",
    "\n",
    "# Take the action and get the new observation space\n",
    "new_obs, reward, done, truncated, info = env.step(random_action)\n",
    "print(f\"The new observation is {new_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–µ–π —Å—Ä–µ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–Ω–∞ –∏–∑ –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º ‚Äî –∑–∞–¥–∞—á–∞ –æ –º–Ω–æ–≥–æ—Ä—É–∫–∏—Ö –±–∞–Ω–¥–∏—Ç–∞—Ö. –í —ç—Ç–æ–π –∑–∞–¥–∞—á–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è, –∞ —É –∞–≥–µ–Ω—Ç–∞ –µ—Å—Ç—å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–µ–π—Å—Ç–≤–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω –º–æ–∂–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å.\n",
    "\n",
    "–≠—Ç—É –∑–∞–¥–∞—á—É –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º: –≤—ã –∏–≥—Ä–æ–∫ –≤ –∫–∞–∑–∏–Ω–æ —Å –∏–≥—Ä–æ–≤—ã–º–∏ –∞–≤—Ç–æ–º–∞—Ç–∞–º–∏, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —Å —Ä–∞–∑–ª–∏—á–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –≤–æ–∑–º–æ–∂–Ω–æ –≤—ã–∏–≥—Ä–∞—Ç—å –ø—Ä–∏–∑ —Ä–∞–∑–ª–∏—á–Ω–æ–π –≤–µ–ª–∏—á–∏–Ω—ã. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ –∫–∞–∫ –∞–≥–µ–Ω—Ç–∞ ‚Äî –≤—ã–∏–≥—Ä–∞—Ç—å –∫–∞–∫ –º–æ–∂–Ω–æ –±–æ–ª—å—à–µ –¥–µ–Ω–µ–≥, –±—Ä–æ—Å–∞—è –º–æ–Ω–µ—Ç–∫–∏ –≤ –∞–≤—Ç–æ–º–∞—Ç—ã –Ω–∞ –≤–∞—à –≤—ã–±–æ—Ä.\n",
    "\n",
    "–î–æ–ø—É—Å—Ç–∏–º, –≤ –∫–∞–∑–∏–Ω–æ –Ω–∞—Ö–æ–¥—è—Ç—Å—è 4 –∞–≤—Ç–æ–º–∞—Ç–∞, –ª–∏—à—å –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å—Ä–µ–¥–Ω–∏–π –≤—ã–∏–≥—Ä—ã—à –±—É–¥–µ—Ç > 1.\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –Ω–∞–ø–∏—à–µ–º –∫–ª–∞—Å—Å, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –æ–ø–∏—Å—ã–≤–∞—Ç—å —ç—Ç—É —Å–∏—Ç—É–∞—Ü–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from gym import Env, spaces\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "class MultiArmedBanditEnv(Env):\n",
    "    def __init__(self, n=4):\n",
    "        \"\"\"\n",
    "        n - number of arms in the bandit\n",
    "        \"\"\"\n",
    "        self.num_bandits = n\n",
    "        self.action_space = spaces.Discrete(self.num_bandits)\n",
    "        self.observation_space = spaces.Discrete(1)  # FIXME: just the reward of the last action\n",
    "        self.bandit_success_prob = np.array(\n",
    "            [0.5, 0.1, 0.9, 0.2]\n",
    "        )  # success probabilities\n",
    "        self.bandit_reward = np.array([2, 20, 1, 3])\n",
    "\n",
    "    def step(self, action):\n",
    "        done = True\n",
    "        result_prob = np.random.random()\n",
    "        if result_prob < self.bandit_success_prob[action]:\n",
    "            reward = self.bandit_reward[action]\n",
    "        else:\n",
    "            reward = 0\n",
    "        return reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–µ—à–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ñ–∞–¥–∞–Ω—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –Ω–∞—à–µ–º –∫–∞–∑–∏–Ω–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø—Ä–∏–Ω—è—Ç—å —É—á–∞—Å—Ç–∏–µ –≤ –∏–≥—Ä–µ, –Ω—É–∂–Ω–æ –∑–∞–ø–ª–∞—Ç–∏—Ç—å 1 –º–æ–Ω–µ—Ç—É. –ü–æ—Å–ª–µ –æ–ø–ª–∞—Ç—ã –∏–≥—Ä–æ–∫ –º–æ–∂–µ—Ç –Ω–∞–∂–∞—Ç—å –Ω–∞ –ª—é–±–æ–π —Ä—ã—á–∞–≥ –∏–≥—Ä–æ–≤–æ–≥–æ –∞–≤—Ç–æ–º–∞—Ç–∞ –∏ –ø–æ–ª—É—á–∏—Ç—å –≤—ã–∏–≥—Ä—ã—à —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é.\n",
    "\n",
    "–ö–∞–∫ –∏–º–µ–Ω–Ω–æ –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –º—ã –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∑–∞ –∫–∞–∫–æ–π —Ä—ã—á–∞–≥ –Ω–∞–º —Å—Ç–æ–∏—Ç –¥–µ—Ä–≥–∞—Ç—å, —á—Ç–æ–±—ã –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—ã–∏–≥—Ä—ã—à? –í–µ–¥—å –º—ã –∫–∞–∫ –∏–≥—Ä–æ–∫ –Ω–µ –∑–Ω–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—ã–∏–≥—Ä—ã—à–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä—ã—á–∞–≥–æ–≤.\n",
    "\n",
    "–ü–æ–ø—Ä–æ–±—É–µ–º —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –∂–∞–¥–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º: –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –±—É–¥–µ–º —Å–æ–≤–µ—Ä—à–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ, –∏–º–µ—é—â–µ–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É –∏, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞, –±—É–¥–µ–º –æ–±–Ω–æ–≤–ª—è—Ç—å —ç—Ç—É –æ—Ü–µ–Ω–∫—É.\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è, —á—Ç–æ –æ–Ω–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ü–µ–Ω–∏—Ç—å —Ü–µ–Ω–Ω–æ—Å—Ç—å —Ç–æ–≥–æ –∏–ª–∏ –∏–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –º–æ–∂–Ω–æ –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É –≤—ã–∏–≥—Ä—ã—à—É, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –æ–Ω–æ –ø—Ä–∏–≤–µ–¥–µ—Ç. –ü—É—Å—Ç—å $R_n$ ‚Äî –Ω–∞–≥—Ä–∞–¥–∞, –ø–æ–ª—É—á–µ–Ω–Ω–∞—è –∑–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ $n$-–≥–æ –¥–µ–π—Å—Ç–≤–∏—è. –¢–æ–≥–¥–∞ –æ—Ü–µ–Ω–∫–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏—è –±—É–¥–µ—Ç $\\displaystyle Q_n=\\frac{R_1+R_2+...+R_n}{n}$. –í–µ–ª–∏—á–∏–Ω–∞ $Q_n$ –ø–æ —Å—É—Ç–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø—Ä–æ—Å—Ç–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ (_simple moving average_), –∫–æ—Ç–æ—Ä–æ–µ –º–æ–∂–µ—Ç –≤—ã—á–∏—Å–ª—è—Ç—å—Å—è –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ:\n",
    "\n",
    "$\\displaystyle Q_n = \\frac{1}{n}(R_n+(n-1)Q_{n-1}) = \\frac{1}{n}(R_n+nQ_{n-1}-Q_{n-1}) = Q_{n-1}+\\frac{1}{n}(R_n-Q_{n-1})$\n",
    "\n",
    "–í —Ü–µ–ª–æ–º, –ø–æ–¥–æ–±–Ω–∞—è —Å—Ö–µ–º–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –æ–±—É—á–µ–Ω–∏–∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–º–∞—è –∫–∞–∫ `–Ω–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞:=—Å—Ç–∞—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ + —à–∞–≥[—Ü–µ–ª—å ‚Äî —Å—Ç–∞—Ä–∞—è –æ—Ü–µ–Ω–∫–∞]`, –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –¥–æ–≤–æ–ª—å–Ω–æ —á–∞—Å—Ç–æ –∏ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è _incremental update rule_.\n",
    "\n",
    "–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ü–µ–Ω–æ–∫ –¥–µ–π—Å—Ç–≤–∏–π –∂–∞–¥–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —Ñ—É–Ω–∫—Ü–∏—è `argmax`, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –≤—ã–±–∏—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –æ—Ü–µ–Ω–∫–æ–π, –∞ –≤ —Å–ª—É—á–∞–µ —Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏, –±—É–¥–µ—Ç –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª—É—á–∞–π–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def argmax(x):\n",
    "    return np.random.choice(np.flatnonzero(x == x.max()))\n",
    "\n",
    "\n",
    "class GreedyAgent:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Our agent initializes reward estimates as zeros.\n",
    "        This estimates will be updated incrementally after each\n",
    "        interaction with the environment.\n",
    "        \"\"\"\n",
    "        self.reward_estimates = np.zeros(4)\n",
    "        self.action_count = np.zeros(4)\n",
    "        self.cache = 1000  # initial amount of coins agent posesses\n",
    "\n",
    "    def get_action(self):\n",
    "        # Pay 1 coin for the action\n",
    "        self.cache -= 1\n",
    "\n",
    "        # Select greedy action\n",
    "        action = argmax(self.reward_estimates)\n",
    "\n",
    "        # Add a 1 to action selected in the action count\n",
    "        self.action_count[action] += 1\n",
    "\n",
    "        return action\n",
    "\n",
    "    def update_estimates(self, reward, action):\n",
    "        # Update amount of cache by reward from our previuos action\n",
    "        self.cache += reward\n",
    "\n",
    "        # Compute the difference between the received rewards vs the reward estimates\n",
    "        error = reward - self.reward_estimates[action]\n",
    "\n",
    "        # Update the reward estimate incementally\n",
    "        n = self.action_count[action]\n",
    "        self.reward_estimates[action] += (1 / n) * error\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = MultiArmedBanditEnv()\n",
    "agent = GreedyAgent()\n",
    "\n",
    "mean_reward_greedy = []\n",
    "rewards = []\n",
    "\n",
    "while (agent.cache > 0) and (len(mean_reward_greedy) != 10000):\n",
    "    act = agent.get_action()\n",
    "    reward, done = env.step(act)\n",
    "    agent.update_estimates(reward, act)\n",
    "    rewards.append(reward)\n",
    "    mean_reward_greedy.append(sum(rewards) / (len(rewards)))\n",
    "\n",
    "print(f\"Action counts: {agent.action_count}\")\n",
    "print(f\"Reward estimates: {agent.reward_estimates}\")\n",
    "plt.plot(mean_reward_greedy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration-exploitation tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∏–∑ —Ç–∏–∫–µ—Ç-–≤–µ—Ç–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\epsilon$-–∂–∞–¥–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–¥–Ω–æ, —á—Ç–æ –∂–∞–¥–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –Ω–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–º –¥–æ–±–∏—Ç—å—Å—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ª–µ–≥–∫–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å, –µ—Å–ª–∏ –≤ –Ω–∞—á–∞–ª–µ –∞–≥–µ–Ω—Ç—É –Ω–µ –ø–æ–≤–µ–∑–µ—Ç.\n",
    "\n",
    "–í–º–µ—Å—Ç–æ –∂–∞–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å $\\varepsilon$-–∂–∞–¥–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å –∫–∞–∫ \"–æ–ø—Ç–∏–º–∏–∑–º –ø—Ä–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏\". –°—É—Ç—å $\\varepsilon$-–∂–∞–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–º: –¥–∞–≤–∞–π—Ç–µ —Å –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é $\\varepsilon$ —Å–æ–≤–µ—Ä—à–∞—Ç—å —Å–ª—É—á–∞–π–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ, –∞ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é $1-\\varepsilon$ –≤–µ—Å—Ç–∏ —Å–µ–±—è –∂–∞–¥–Ω–æ.\n",
    "\n",
    "$\\varepsilon$ ‚Äî –≤–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –∞–ª–≥–æ—Ä–∏—Ç–º–∞. –ö–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –≤ –Ω–∞—á–∞–ª–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –±–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è $\\varepsilon$, —Ç–æ–≥–¥–∞ –∞–≥–µ–Ω—Ç –¥–µ–π—Å—Ç–≤—É–µ—Ç –ø–æ—á—Ç–∏ —Å–ª—É—á–∞–π–Ω–æ –∏ \"–∏—Å—Å–ª–µ–¥—É–µ—Ç –º–∏—Ä\", –∞ –∑–∞—Ç–µ–º —É–º–µ–Ω—å—à–∞—é—Ç, –∏ –¥–µ–π—Å—Ç–≤–∏—è –∞–≥–µ–Ω—Ç–∞ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –±–ª–∏–∑–∫–∏–º–∏ –∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º.\n",
    "\n",
    "–í—ã–±–æ—Ä –≤–µ–ª–∏—á–∏–Ω—ã $\\varepsilon$ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è __exploration-exploitation trade-off__. –û–Ω –º–æ–∂–µ—Ç –±—ã—Ç—å –ª–µ–≥–∫–æ –ø—Ä–æ–∏–ª–ª—é—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –ø—Ä–∏–º–µ—Ä–æ–º, –∫–æ–≥–¥–∞ –≤—ã –Ω–µ –º–æ–∂–µ—Ç–µ —Ä–µ—à–∏—Ç—å, –ø–æ–π—Ç–∏ –ª–∏ —Å–µ–≥–æ–¥–Ω—è –≤ –ª—é–±–∏–º—ã–π —Ä–µ—Å—Ç–æ—Ä–∞–Ω –∏–ª–∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å—Ö–æ–¥–∏—Ç—å –≤ –Ω–æ–≤—ã–π?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/exploration_vs_exploitation.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyAgent(GreedyAgent):\n",
    "    def __init__(self, epsilon):\n",
    "        GreedyAgent.__init__(self)\n",
    "        # Store the epsilon value\n",
    "        assert epsilon >= 0 and epsilon <= 1\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def get_action(self):\n",
    "        # We need to redefine this function so that it takes an exploratory action with epsilon probability\n",
    "\n",
    "        # Pay 1 coin for the action\n",
    "        self.cache -= 1\n",
    "        # One hot encoding: 0 if exploratory, 1 otherwise\n",
    "        action_type = int(np.random.random() > self.epsilon)\n",
    "        # Generate both types of actions for every experiment\n",
    "        exploratory_action = np.random.randint(4)\n",
    "        greedy_action = argmax(self.reward_estimates)\n",
    "        # Use the one hot encoding to mask the actions for each experiment\n",
    "        action = greedy_action * action_type + exploratory_action * (1 - action_type)\n",
    "\n",
    "        self.action_count[action] += 1\n",
    "\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = EpsilonGreedyAgent(epsilon=0.25)\n",
    "\n",
    "mean_reward_e_greedy = []\n",
    "rewards = []\n",
    "\n",
    "while (agent.cache > 0) and (len(mean_reward_e_greedy) != 10000):\n",
    "    act = agent.get_action()\n",
    "    reward, done = env.step(act)\n",
    "    agent.update_estimates(reward, act)\n",
    "    rewards.append(reward)\n",
    "    mean_reward_e_greedy.append(sum(rewards) / len(rewards))\n",
    "    # Decrease epsilon with time until we reach 0.01 chanse to perform exploratory action\n",
    "    if agent.epsilon > 0.01:\n",
    "        agent.epsilon -= 0.0001\n",
    "\n",
    "print(f\"Action counts: {agent.action_count}\")\n",
    "print(f\"Reward estimates: {agent.reward_estimates}\")\n",
    "plt.plot(mean_reward_greedy)\n",
    "plt.plot(mean_reward_e_greedy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∏–∑ —Ç–∏–∫–µ—Ç-–≤–µ—Ç–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-entropy method (CEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤–µ—Ä—Å–∏—é h1 –∏–∑ —Ç–∏–∫–µ—Ç-–≤–µ—Ç–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Olivier-Sigaud/publication/220743370/figure/fig2/AS:667802356678667@1536227897809/Schematic-view-of-the-Cross-Entropy-method.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
    "- –û—Ç–±–æ—Ä 5-10% \"–ª—É—á—à–∏—Ö\" -- —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è supervised –æ–±—É—á–µ–Ω–∏—è\n",
    "- –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, —á—Ç–æ–±—ã –ø–æ–≤—ã—Å–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ª—É—á—à–∏—Ö (—à–∞–≥ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å–æ–∑–¥–∞–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–∏–º–µ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–µ–¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ú–∞—Ä–∫–æ–≤—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π (Markov decision process, MDP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://fls.avasiliev.xyz/repo/EduNet-content/dev-2.0/L15/out/mdp.png\" alt=\"Drawing\" width=\"650\">\n",
    "\n",
    "\n",
    "<center><em> –ú–∞—Ä–∫–æ–≤—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π  <em><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Ç–∞–∫, –º—ã —Ä–∞–∑–æ–±—Ä–∞–ª–∏—Å—å —Å —Å–∞–º–æ–π –ø—Ä–æ—Å—Ç–æ–π —Å–∏—Ç—É–∞—Ü–∏–µ–π, –º–Ω–æ–≥–æ—Ä—É–∫–∏–º–∏ –±–∞–Ω–¥–∏—Ç–∞–º–∏, –≤ –∫–æ—Ç–æ—Ä–æ–π —Å—Ä–µ–¥–∞ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –æ–¥–Ω–æ–º –∏ —Ç–æ–º –∂–µ —Å–æ—Å—Ç–æ—è–Ω–∏–∏. –û–¥–Ω–∞–∫–æ –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏, —á–∞—â–µ –≤—Å–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã, –∏–∑ –∫–æ—Ç–æ—Ä–æ–π –∞–≥–µ–Ω—Ç –¥–µ–ª–∞–µ—Ç –Ω–æ–≤—ã–π —Ö–æ–¥, –±—É–¥–µ—Ç –∏–∑–º–µ–Ω—è—Ç—å—Å—è, –∫–∞–∫, –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏ –∏–≥—Ä–µ –≤ —à–∞—Ö–º–∞—Ç—ã, –∞–≥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω —É—á–∏—Ç—ã–≤–∞—Ç—å —Ç–æ, —á—Ç–æ –ø–æ—Å–ª–µ –µ–≥–æ —Ö–æ–¥–∞ –∏ —Ö–æ–¥–∞ –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞ –ø–æ–∑–∏—Ü–∏—è –Ω–∞ –¥–æ—Å–∫–µ –∏–∑–º–µ–Ω–∏—Ç—Å—è.\n",
    "\n",
    "–ù–∞–º –Ω—É–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–µ–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å, –≤ –∫–æ—Ç–æ—Ä–æ–º –∞–≥–µ–Ω—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–≤–æ–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π, –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö –ø–æ–ª—É—á–∞—è –Ω–∞–≥—Ä–∞–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–¥–µ–ª–∞–µ–º —Ç–∞–∫–∂–µ –≤–∞–∂–Ω–æ–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ –ø—Ä–∏—Ä–æ–¥–µ –Ω–∞—à–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞: **–æ–Ω –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è —Å–≤–æ–∏–º —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º**. –í—Å–µ, —á—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –≤ –±—É–¥—É—â–µ–º, –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ, –∫—Ä–æ–º–µ —Ç–æ–π, —á—Ç–æ –º—ã —É–∂–µ –Ω–∞–±–ª—é–¥–∞–µ–º –≤ –Ω–∞—Å—Ç–æ—è—â–µ–º. –¢–∞–∫–æ–π –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è __–º–∞—Ä–∫–æ–≤—Å–∫–∏–º__. –ó–∞–º–µ—Ç–∏–º, —á—Ç–æ –æ–ø–∏—Å–∞–Ω–Ω—ã–π –Ω–∞–º–∏ –ø—Ä–æ—Ü–µ—Å—Å –≤ –ø—Ä–∏–º–µ—Ä–µ —Å –º–Ω–æ–≥–æ—Ä—É–∫–∏–º–∏ –±–∞–Ω–¥–∏—Ç–∞–º–∏ —Ç–∞–∫–∂–µ —è–≤–ª—è–µ—Ç—Å—è –º–∞—Ä–∫–æ–≤—Å–∫–∏–º.\n",
    "\n",
    "–ü—Ä–∏–≤–µ–¥–µ–º –¥—Ä—É–≥–∏–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –º–∞—Ä–∫–æ–≤—Å–∫–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞:\n",
    "\n",
    "1. –ò–≥—Ä–∞–ª—å–Ω—ã–π –∫—É–±–∏–∫. –ú—ã –∑–Ω–∞–µ–º, —á—Ç–æ –Ω–∞ –Ω–µ–º –≤—ã–ø–∞–¥–µ—Ç –ª—é–±–∞—è –∏–∑ –≥—Ä–∞–Ω–µ–π —Å –Ω–µ–∫–æ—Ç–æ—Ä–æ–π —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é. –ù–∞ —ç—Ç–æ –Ω–∏–∫–∞–∫ –Ω–µ –≤–ª–∏—è–µ—Ç —Ç–æ, —á—Ç–æ –¥–æ —ç—Ç–æ–≥–æ –Ω–∞ –∫—É–±–∏–∫–µ –≤—ã–ø–∞–ª–æ 6 —à–µ—Å—Ç–µ—Ä–æ–∫ –ø–æ–¥—Ä—è–¥. –≠—Ç–æ –º–æ–∂–µ—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ –Ω–∞—à—É –æ—Ü–µ–Ω–∫—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –≤—ã–ø–∞–¥–µ–Ω–∏—è —Ç–æ–π –∏–ª–∏ –∏–Ω–æ–π –≥—Ä–∞–Ω–∏, –Ω–æ –Ω–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å.\n",
    "\n",
    "2. –®–∞—Ö–º–∞—Ç—ã. \"–¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è –Ω–∞ –¥–æ—Å–∫–µ + —á–µ–π —Ö–æ–¥\" –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∏–≥—Ä—É.\n",
    "\n",
    "3. –ê –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ –ø–æ–∫–µ—Ä?\n",
    "\n",
    "–° –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, –¥–∞. –¢–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ–Ω–µ–≥ —É –∫–∞–∂–¥–æ–≥–æ –∏–∑ –∏–≥—Ä–æ–∫–æ–≤ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∏–≥—Ä—É. –ù–æ —ç—Ç–æ –µ—Å–ª–∏ –º—ã –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ–º –±–ª–µ—Ñ –∏ –¥—Ä—É–≥–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å—Ä–∞–±–æ—Ç–∞—Ç—å / –Ω–µ —Å—Ä–∞–±–æ—Ç–∞—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–∏—Ç—É–∞—Ü–∏–π –≤ –∏–≥—Ä–µ. –¢–æ –µ—Å—Ç—å, –≤—Å–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫ –∏–º–µ–Ω–Ω–æ –º—ã –±—É–¥–µ–º –æ–ø–∏—Å—ã–≤–∞—Ç—å –ø–æ–∫–µ—Ä –∏ –∫–∞–∫–∏–µ –¥–æ–ø—É—â–µ–Ω–∏—è –Ω–∞–∫–ª–∞–¥—ã–≤–∞–µ–º.\n",
    "\n",
    "–ò –ø–æ–ª—É—á–µ–Ω–∏–µ —Ö–æ—Ä–æ—à–µ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è S ‚Äî —Ç–æ–∂–µ –≤–∞–∂–Ω–∞—è –∑–∞–¥–∞—á–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Markov Property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"*The future is independent of the past given the present*\"\n",
    "\n",
    "–°–æ—Å—Ç–æ—è–Ω–∏–µ $S_{t}$ —è–≤–ª—è–µ—Ç—Å—è –ú–∞—Ä–∫–æ–≤—ã–º —Ç–æ–≥–¥–∞ –∏ —Ç–æ–ª—å–∫–æ —Ç–æ–≥–¥–∞, –∫–æ–≥–¥–∞:\n",
    "$$ \\large\n",
    "p\\left(r_{t}, s_{t+1} \\mid s_{0}, a_{0}, r_{0}, \\ldots, s_{t}, a_{t}\\right)=p\\left(r_{t}, s_{t+1} \\mid s_{t}, a_{t}\\right)\n",
    "$$\n",
    "\n",
    "**–ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ—Ç–æ–º, –∑–∞–≤–∏—Å–∏—Ç —Ç–æ–ª—å–∫–æ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è**\n",
    "- –í—Å—è –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –±–µ—Ä–µ—Ç—Å—è –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏.\n",
    "- –ö–∞–∫ —Ç–æ–ª—å–∫–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã —Å—Ç–∞–Ω–µ—Ç –∏–∑–≤–µ—Å—Ç–Ω–æ, –∏—Å—Ç–æ—Ä–∏—é –º–æ–∂–Ω–æ –≤—ã–±—Ä–æ—Å–∏—Ç—å.\n",
    "- –¢–æ –µ—Å—Ç—å, —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã ‚Äî –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –±—É–¥—É—â–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Ö–æ–¥–∞ –≤ –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–≤–∏—Å–∏—Ç —Ç–æ–ª—å–∫–æ –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ —Ç–µ–∫—É—â–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–∞—Ä–∫–æ–≤—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å –æ–ø–∏—Å—ã–≤–∞–µ—Ç **–ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞–±–ª—é–¥–∞–µ–º—ã–µ (fully observable)** —Å—Ä–µ–¥—ã. –ú–æ–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å –∏—Ö —Ç–∞–∫:\n",
    "\n",
    "* –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—É—é –ø–æ–ª—É—á–∞–µ—Ç –∞–≥–µ–Ω—Ç –≤ –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ t, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á—Ç–æ–±—ã –ø—Ä–∏–Ω—è—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –º–æ–º–µ–Ω—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ t.\n",
    "* –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ.\n",
    "* –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ ‚Äî —ç—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±—É–¥—É—â–µ–≥–æ $\\rightarrow$ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –Ω–∏–∫–∞–∫–æ–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –º–æ–≥–ª–∞ –±—ã —É–ª—É—á—à–∏—Ç—å –Ω–∞—à–µ –æ–ø–∏—Å–∞–Ω–∏–µ –±—É–¥—É—â–µ–≥–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–¥—Å—Ç–∞–≤–∏–º —Å–µ–±–µ, —á—Ç–æ —Å—Ç—É–¥–µ–Ω—Ç –∂–∏–≤–µ—Ç –≤–æ—Ç –ø–æ —Ç–∞–∫–æ–π —Å—Ö–µ–º–µ. –ó–∞–º–µ—Ç–∏–º, —á—Ç–æ –≤–ª–∏—è—Ç—å –≤ —Ç–∞–∫–æ–π —Å—Ö–µ–º–µ –Ω–∞ —Å–≤–æ–∏ —Ä–µ—à–µ–Ω–∏—è –æ–Ω –Ω–µ –º–æ–∂–µ—Ç: –≤—Å–µ —Ä–µ—à–∞–µ—Ç—Å—è –ø–æ–¥–∫–∏–¥—ã–≤–∞–Ω–∏–µ–º –∫—É–±–∏–∫–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/markov_process.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–∞—Ä–∫–æ–≤—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å (—Ü–µ–ø—å) ‚Äî —ç—Ç–æ –∫–æ—Ä—Ç–µ–∂ $(S, P)$, –≥–¥–µ\n",
    "- $S$ ‚Äî –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ (–∫–æ–Ω–µ—á–Ω—ã–µ) –∑–Ω–∞—á–µ–Ω–∏—è,\n",
    "- $P$ ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (transition matrix):\n",
    "$$\\large\n",
    "P_{s s^{\\prime}}=\\operatorname{Pr}\\left(S_{t+1}=s^{\\prime} \\mid S_{t}=s\\right)\n",
    "$$\n",
    "\n",
    "–°—Ç—Ä–æ–≥–æ –≥–æ–≤–æ—Ä—è, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –µ—â–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π (–Ω–æ –º—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –æ–Ω–æ –≤—ã—Ä–æ–∂–¥–µ–Ω–æ, —Ç.–µ. –º—ã –∑–Ω–∞–µ–º, –≥–¥–µ –Ω–∞—á–∏–Ω–∞–µ–º, —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 1).\n",
    "\n",
    "–ú–∞—Ä–∫–æ–≤—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å ‚Äî –æ—Å–Ω–æ–≤–∞ –¥–ª—è RL. –ú—ã –±—É–¥–µ–º –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É—Å–ª–æ–∂–Ω—è—Ç—å —ç—Ç—É –º–æ–¥–µ–ª—å, –¥–æ–±–∞–≤–ª—è—è rewards –∏ actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –Ω–∞–º –≤—Å—Ç—Ä–µ—Ç–∏–ª–∞—Å—å –º–∞—Ç—Ä–∏—Ü–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤, –∑–∞–¥–∞–¥–∏–º –µ–µ —Ç–æ–∂–µ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –§–æ—Ä–º–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDP (MDRP) ‚Äî —ç—Ç–æ –∫–æ—Ä—Ç–µ–∂ $(S, R, P, \\gamma)$, –≥–¥–µ:\n",
    "\n",
    "$S$ ‚Äî –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ (–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è),\n",
    "\n",
    "$R$ ‚Äî —Ñ—É–Ω–∫—Ü–∏—è rewards, $R_s = \\mathbb{E}[R_{t+1}|S_t=s]$,\n",
    "\n",
    "$P$ ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (transition matrix):\n",
    "\n",
    "$P_{ss^`}=Pr(S_{t+1}=s^`|S_t=s)$,\n",
    "\n",
    "$\\gamma$ ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (discount factor).\n",
    "\n",
    "–û—Å—Ç–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å actions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ú–∞—Ä–∫–æ–≤—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π\n",
    "Markov decision process (MDP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–æ —ç—Ç–æ–≥–æ —É –Ω–∞—Å –ø–æ–ª—É—á–∞–ª–æ—Å—å –º–∞–ª–æ—Å—Ç—å –Ω–µ–∞–¥–µ–∫–≤–∞—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ &mdash; —Å—Ç—É–¥–µ–Ω—Ç –Ω–µ –º–æ–≥ –Ω–∏ –Ω–∞ —á—Ç–æ –ø–æ–≤–ª–∏—è—Ç—å. –ù–∞ —Å–∞–º–æ–º –∂–µ –¥–µ–ª–µ —Å—Ç—É–¥–µ–Ω—Ç –º–æ–∂–µ—Ç —Ä–µ—à–∞—Ç—å, –∫—É–¥–∞ –µ–º—É –Ω–∞–¥–æ: –≤ –∞—É–¥–∏—Ç–æ—Ä–∏—é, –¥–æ–º–æ–π —Å–ø–∞—Ç—å –∏–ª–∏ –≤ –±–∞—Ä. –û–¥–Ω–∞–∫–æ –Ω–∞—à–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ –≤—Å–µ–≥–¥–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –≤ –∫–æ—Ç–æ—Ä–æ–µ –º—ã –ø–µ—Ä–µ–π–¥–µ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–•–æ—á–µ—Ç –Ω–∞—à —Å—Ç—É–¥–µ–Ω—Ç –ø–æ–π—Ç–∏ –Ω–∞ –ª–µ–∫—Ü–∏—é, –Ω–æ –ø–æ –ø—É—Ç–∏ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç —Ç–æ–≤–∞—Ä–∏—â–∞, –∏ –∏–¥—É—Ç –æ–Ω–∏ –≤ –±–∞—Ä. –•–æ—á–µ—Ç –æ–Ω –ø–æ–π—Ç–∏ —Å–ø–∞—Ç—å, –∞ –ø–æ –ø—É—Ç–∏ –∫ –≤—ã—Ö–æ–¥—É –∏–∑ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç –ª–µ–∫—Ç–æ—Ä–∞ —Å —Ö–æ—Ä–æ—à–µ–π –ø–∞–º—è—Ç—å—é –∏ –∏–¥–µ—Ç –Ω–∞ –ª–µ–∫—Ü–∏—é.\n",
    "–ò —Ç.–¥.\n",
    "\n",
    "–ö–∞–∫ —ç—Ç–æ –æ—Ç—Ä–∞–∑–∏—Ç—å –Ω–∞ —Å—Ö–µ–º–µ —Ç–∞–∫, —á—Ç–æ–±—ã —ç—Ç–æ –º–æ–∂–Ω–æ –±—ã–ª–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å? –í–≤–µ–¥–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –∫—É–¥–∞ –Ω–∞—Å –ø–µ—Ä–µ–≤–æ–¥—è—Ç –¥–µ–π—Å—Ç–≤–∏—è —Å—Ç—É–¥–µ–Ω—Ç–∞. –ê —É–∂–µ –∏–∑ —ç—Ç–∏—Ö –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π —Å–ª—É—á–∞–π–Ω–æ –±—É–¥–µ–º –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –≤ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—Ä–µ–¥—ã.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/markov_decision_process_return_random.png\" alt=\"Drawing\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –§–æ—Ä–º–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDP ‚Äî —ç—Ç–æ –∫–æ—Ä—Ç–µ–∂ $(S, A, R, P, \\gamma)$, –≥–¥–µ:\n",
    "- $S$ ‚Äî —Å–æ—Å—Ç–æ—è–Ω–∏—è (–¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ),\n",
    "- $A$ ‚Äî –¥–µ–π—Å—Ç–≤–∏—è (–¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ),\n",
    "- $R$ ‚Äî —Ñ—É–Ω–∫—Ü–∏—è rewards: $R_{s}^{a}=\\mathbb{E}\\left[R_{t+1} \\mid S_{t}=s, A_{t}=a\\right]$,\n",
    "- $P$ ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ (transition matrix): $P_{s s^{\\prime}}^{a}=\\operatorname{Pr}\\left(S_{t+1}=s^{\\prime} \\mid S_{t}=s, A_{t}=a\\right)$,\n",
    "- $\\gamma$ ‚Äî discount factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ—Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/markov_decision_process_example.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- —á–µ—Ä–Ω—ã–µ –±–µ–∑–∑–Ω–∞–∫–æ–≤—ã–µ —á–∏—Å–ª–∞ ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤;\n",
    "- –∑–Ω–∞–∫–æ–≤—ã–µ ‚Äî —ç—Ç–æ –Ω–∞–≥—Ä–∞–¥—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è [–ø—Ä–∏–º–µ—Ä–æ–º](https://github.com/yandexdataschool/Practical_RL):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# After this setup we can import mdp package\n",
    "!wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "!wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week02_value_based/mdp.py\n",
    "!touch .setup_complete\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp import MDP\n",
    "\n",
    "transition_probs = {\n",
    "    \"s0\": {\"a0\": {\"s0\": 0.5, \"s2\": 0.5}, \"a1\": {\"s2\": 1}},\n",
    "    \"s1\": {\"a0\": {\"s0\": 0.7, \"s1\": 0.1, \"s2\": 0.2}, \"a1\": {\"s1\": 0.95, \"s2\": 0.05}},\n",
    "    \"s2\": {\"a0\": {\"s0\": 0.4, \"s2\": 0.6}, \"a1\": {\"s0\": 0.3, \"s1\": 0.3, \"s2\": 0.4}},\n",
    "}\n",
    "rewards = {\"s1\": {\"a0\": {\"s0\": +5}}, \"s2\": {\"a1\": {\"s0\": -1}}}\n",
    "\n",
    "mdp = MDP(transition_probs, rewards, initial_state=\"s0\")\n",
    "\n",
    "# We can now use MDP just as any other gym environment:\n",
    "print(\"initial state =\", mdp.reset())\n",
    "next_state, reward, done, info = mdp.step(\"a1\")\n",
    "print(\"next_state = %s, reward = %s, done = %s\" % (next_state, reward, done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDP methods\n",
    "\n",
    "print(\"mdp.get_all_states =\", mdp.get_all_states())\n",
    "print(\"mdp.get_possible_actions('s1') = \", mdp.get_possible_actions(\"s1\"))\n",
    "print(\"mdp.get_next_states('s1', 'a0') = \", mdp.get_next_states(\"s1\", \"a0\"))\n",
    "\n",
    "# state, action, next_state\n",
    "print(\"mdp.get_reward('s1', 'a0', 's0') = \", mdp.get_reward(\"s1\", \"a0\", \"s0\"))\n",
    "\n",
    "# get_transition_prob(self, state, action, next_state)\n",
    "print(\n",
    "    \"mdp.get_transition_prob('s1', 'a0', 's0') = \",\n",
    "    mdp.get_transition_prob(\"s1\", \"a0\", \"s0\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_jpeg\n",
    "import mdp as MDP\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "display_jpeg(MDP.plot_graph(mdp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°—Ä–µ–¥–∞ –∏ –µ—ë —Å–æ—Å—Ç–æ—è–Ω–∏–µ (state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–µ–π—Å—Ç–≤–∏–µ (action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ú–∞—Ç—Ä–∏—Ü–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ –º–∞—Ä–∫–æ–≤—Å–∫–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ (transition probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –§—É–Ω–∫—Ü–∏—è –Ω–∞–≥—Ä–∞–¥—ã (reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞—à–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –æ—á–µ–≤–∏–¥–Ω–æ, –Ω–µ—Ä–∞–≤–Ω–æ—Ü–µ–Ω–Ω—ã. –î–∞–≤–∞–π—Ç–µ –∫ –∫–∞–∂–¥–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é –ø—Ä–∏–≤—è–∂–µ–º –Ω–∞–≥—Ä–∞–¥—É $R_s$.\n",
    "–û–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–∞–∫ –Ω—É–ª–µ–≤–æ–π, —Ç–∞–∫ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –ª–∏–±–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π.\n",
    "\n",
    "–ù–∞–ø—Ä–∏–º–µ—Ä, –≤ –º–∞—Ä–∫–æ–≤—Å–∫–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π (MDP), –æ–ø–∏—Å—ã–≤–∞—é—â–µ–º –∏–≥—Ä—É –≤ —à–∞—Ö–º–∞—Ç—ã –∏–ª–∏ GO, –Ω–∞–≥—Ä–∞–¥–∞ –∞–≥–µ–Ω—Ç–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ \"–ø–∞—Ä—Ç–∏—è –≤—ã–∏–≥—Ä–∞–Ω–∞\"\n",
    "\n",
    "–ù–∞ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ö–æ–¥–∞—Ö –Ω–∞–≥—Ä–∞–¥–∞ –±—É–¥–µ—Ç –Ω—É–ª–µ–≤–æ–π.\n",
    "\n",
    "–î–ª—è –ø–µ—Ä–µ–º–µ—â–∞—é—â–µ–≥–æ—Å—è —Ä–æ–±–æ—Ç–∞ –Ω–∞–≥—Ä–∞–¥–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π, —Ç–∞–∫ –∫–∞–∫ –Ω–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è —ç–Ω–µ—Ä–≥–∏—è –∏ —Ç.–ø.\n",
    "\n",
    "–î–ª—è –ø–æ–∫–µ—Ä–∞ –Ω–∞–≥—Ä–∞–¥–æ–π –º–æ–∂–Ω–æ –Ω–∞–∑–Ω–∞—á–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Å—É–º–º—ã –∏–≥—Ä–æ–∫–∞ –ø–æ—Å–ª–µ —Å—ã–≥—Ä–∞–Ω–Ω–æ–π —Ä–∞–∑–¥–∞—á–∏.\n",
    "\n",
    "–°—Ö–µ–º–∞ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞ –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º. –ó–∞–º–µ—Ç—å—Ç–µ, –Ω–∞–≥—Ä–∞–¥—ã —Ç—É—Ç —Ä–∞—Å—Å—Ç–∞–≤–ª—è—é—Ç—Å—è —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∞–∫—Ç–æ—Ä–∞ ‚Äî —Å—Ç—É–¥–µ–Ω—Ç–∞:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/markov_reward.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –°—É–º–º–∞—Ä–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞ (Return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —Ç—É—Ä–Ω–∏—Ä–∞ –ø–æ —à–∞—Ö–º–∞—Ç–∞–º, –≥–¥–µ –∏–≥—Ä–∞–µ—Ç—Å—è 10 –ø–∞—Ä—Ç–∏–π, —Ñ–∏–Ω–∞–ª—å–Ω—ã–π reward –±—É–¥–µ—Ç —Å–∫–ª–∞–¥—ã–≤–∞—Ç—å—Å—è –∏–∑ reward –∑–∞ –∫–∞–∂–¥—É—é –ø–∞—Ä—Ç–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å —Ç–µ—Å—Ç –∏–∑ 40 –≤–æ–ø—Ä–æ—Å–æ–≤, —Ç–æ –æ–ø—è—Ç—å –∂–µ, –Ω–∞–º –Ω–µ –≤–∞–∂–Ω–æ, –∫–∞–∫ –∏–º–µ–Ω–Ω–æ –º—ã –ø–æ–ª—É—á–∏–ª–∏ 30 –±–∞–ª–ª–æ–≤, –≥–ª–∞–≤–Ω–æ–µ ‚Äî –º—ã –∏—Ö –ø–æ–ª—É—á–∏–ª–∏.\n",
    "\n",
    "–¢–æ –µ—Å—Ç—å, –≤ —Ç–∞–∫–∏—Ö —Å–ª—É—á–∞—è—Ö –º—ã –º–æ–∂–µ–º —Å—á–∏—Ç–∞—Ç—å Return —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
    "\n",
    "$$Return = \\sum_i {R_i}$$\n",
    "\n",
    "\n",
    "–ê —Ç–µ–ø–µ—Ä—å –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–º —Å–µ–±–µ, —á—Ç–æ –º—ã –º–æ–∂–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å 2 –≥–æ–¥–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ –∏ –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–æ–º 5 –º–∏–ª–ª–∏–æ–Ω–æ–≤ —Ä—É–±–ª–µ–π. –ê –º–æ–∂–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å 2 –≥–æ–¥–∞ –∏ –∫–∞–∂–¥—ã–π –≥–æ–¥ –ø–æ–ª—É—á–∞—Ç—å 70 —Ç—ã—Å—è—á.\n",
    "\n",
    "\n",
    "–ò–ª–∏ –º—ã –º–æ–∂–µ–º 6 –ª–µ—Ç —É—á–∏—Ç—å—Å—è, –ø–æ–ª—É—á–∞—è —Å—Ç–æ—Ä–æ–Ω–Ω–∏–º–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—è–º–∏ 20 —Ç—ã—Å—è—á –≤ –º–µ—Å—è—Ü, –∞ –∑–∞—Ç–µ–º —Å—Ä–∞–∑—É –Ω–∞—á–∞—Ç—å –ø–æ–ª—É—á–∞—Ç—å 150 —Ç—ã—Å—è—á –≤ –º–µ—Å—è—Ü, –∞ –∑–∞—Ç–µ–º –∏ –±–æ–ª—å—à–µ. –ê –º–æ–∂–µ–º —Å—Ä–∞–∑—É –ø–æ–π—Ç–∏ –Ω–∞ —Ä–∞–±–æ—Ç—É –∏ –Ω–∞—á–∞—Ç—å –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å 50 —Ç—ã—Å—è—á –≤ –º–µ—Å—è—Ü, –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –¥–æ–π–¥—è –¥–æ 100.\n",
    "\n",
    "–ß—Ç–æ –ª—É—á—à–µ: –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –¥–≤–µ —Å—Ç–∞—Ç—å–∏ –≤ –∂—É—Ä–Ω–∞–ª–µ —Å –∏–º–ø–∞–∫—Ç —Ñ–∞–∫—Ç–æ—Ä–æ–º 5 –≤ —ç—Ç–æ–º –≥–æ–¥—É –∏–ª–∏ 1, –Ω–æ —á–µ—Ä–µ–∑ 2 –≥–æ–¥–∞ –∏ –≤ –∂—É—Ä–Ω–∞–ª–µ —Å –∏–º–ø–∞–∫—Ç-—Ñ–∞–∫—Ç–æ—Ä–æ–º 20?\n",
    "\n",
    "–ß—Ç–æ –≤—ã–≥–æ–¥–Ω–µ–µ?\n",
    "\n",
    "–û—á–µ–≤–∏–¥–Ω–æ, –≤ —Ç–∞–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö –ª—É—á—à–µ —É—á–∏—Ç—ã–≤–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ Reward, –Ω–æ –∏ —Ç–æ, –∫–æ–≥–¥–∞ –æ–Ω –ø–æ–ª—É—á–µ–Ω."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\gamma$-–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—ç—Ç–æ–º—É –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∫—É–º—É–ª—è—Ç–∏–≤–Ω–æ–π –Ω–∞–≥—Ä–∞–¥—ã –Ω–∞ —à–∞–≥–µ $t$ $(G_t)$ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è $\\gamma$, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ü–µ–Ω–Ω—ã–º–∏ —è–≤–ª—è—é—Ç—Å—è –±—É–¥—É—â–∏–µ –Ω–∞–≥—Ä–∞–¥—ã –Ω–∞ —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç (—Å–º. [Markov Decision Processes (David Silver Lectures)](https://www.davidsilver.uk/wp-content/uploads/2020/03/MDP.pdf)):\n",
    "\n",
    "$$\\large G_t = R_{t+1} + \\gamma R_{t+2} + ... =\\sum^{\\infty}_{k=0} \\gamma ^ kR_{t+k+1},\n",
    "$$\n",
    "\n",
    "–≥–¥–µ:\n",
    "- $R_{t+1}, R_{t+1}, \\dots$ ‚Äî –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –ø–æ —Ä—ë–±—Ä–∞–º –ø–µ—Ä–µ—Ö–æ–¥–æ–≤,\n",
    "- –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ $\\gamma \\in[0,1]$ ‚Äî —ç—Ç–æ —Ç–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –±—É–¥—É—â–∏—Ö –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–π,\n",
    "- $\\gamma^{k} R$ ‚Äî —Ü–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞–≥—Ä–∞–¥—ã $R$ –ø–æ—Å–ª–µ $k+1$ —à–∞–≥–æ–≤.\n",
    "\n",
    "–ü—Ä–∏ —ç—Ç–æ–º:\n",
    "- –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ —Ü–µ–Ω–∏—Ç—Å—è –≤—ã—à–µ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–≥–æ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è,\n",
    "- $\\gamma$ –±–ª–∏–∑–∫–æ –∫ 0 –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ ¬´–±–ª–∏–∑–æ—Ä—É–∫–æ—Å—Ç–∏¬ª,\n",
    "- $\\gamma$ –±–ª–∏–∑–∫–æ –∫ 1 –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ ¬´–¥–∞–ª—å–Ω–æ–≤–∏–¥–Ω–æ–π¬ª –æ—Ü–µ–Ω–∫–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "–ö–∞–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ $\\gamma$ –≤—ã–±—Ä–∞—Ç—å?\n",
    "\n",
    "\n",
    "**–ú–æ–∂–Ω–æ –ª–∏ –µ–≥–æ –≤—ã–±—Ä–∞—Ç—å —Ä–∞–≤–Ω—ã–º 1?**\n",
    "\n",
    "–î–∞, –º—ã —É–∂–µ —ç—Ç–æ –¥–µ–ª–∞–ª–∏ —Ä–∞–Ω–µ–µ.\n",
    "\n",
    "**–ú–æ–∂–Ω–æ –ª–∏ –µ–≥–æ –≤—ã–±—Ä–∞—Ç—å —Ä–∞–≤–Ω—ã–º 0?**\n",
    "\n",
    " –¢–æ–∂–µ –¥–∞. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ —É –Ω–∞—Å –ø–æ–ª—É—á–∏—Ç—Å—è \"–∂–∞–¥–Ω—ã–π\" –∞–ª–≥–æ—Ä–∏—Ç–º: –º—ã –≤—Å–µ–≥–¥–∞ –≤—ã–±–∏—Ä–∞–µ–º —Ä–µ—à–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –¥–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –Ω–∞–≥—Ä–∞–¥—É —Å–µ–π—á–∞—Å, –Ω–∞—Å –Ω–µ –≤–æ–ª–Ω—É—é—Ç –±—É–¥—É—â–∏–µ –Ω–∞–≥—Ä–∞–¥—ã.\n",
    "\n",
    "**–ú–æ–∂–µ—Ç $\\gamma = 0$ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø—Ä–æ–±–ª–µ–º–∞–º?**\n",
    "\n",
    "–î–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n",
    "\n",
    "* –í–∞—Ä–∏–∞–Ω—Ç 1: –ü–æ–ª—É—á–∏—Ç—å —Å–µ–≥–æ–¥–Ω—è 1000 —Ä—É–±–ª–µ–π.\n",
    "\n",
    "* –í–∞—Ä–∏–∞–Ω—Ç 2: –ü–æ–ª—É—á–∏—Ç—å –∑–∞–≤—Ç—Ä–∞ 100000 —Ä—É–±–ª–µ–π\n",
    "\n",
    "–û–±—ã—á–Ω–æ, –≤—Ç–æ—Ä–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –±–æ–ª–µ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª–µ–Ω. –ù–æ –∂–∞–¥–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –µ–≥–æ –Ω–µ —É–≤–∏–¥–∏—Ç.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ú–æ–∂–µ—Ç $\\gamma = 1$ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø—Ä–æ–±–ª–µ–º–∞–º?**\n",
    "\n",
    "–ü—Ä–µ–¥—Å—Ç–∞–≤–∏–º —Å–µ–±–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —à—É—Ç–æ–∫ –ø—Ä–æ –º–µ–¥–≤–µ–¥—è. –ë–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –ª—é–¥–µ–π –∑–Ω–∞–µ—Ç —ç—Ç—É —à—É—Ç–∫—É, –ø–æ—ç—Ç–æ–º—É –±—ã–ª–æ –±—ã —Ö–æ—Ä–æ—à–æ –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ –≤—Å—Ç–∞–≤–ª—è—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ &mdash; \"–¥–ª—è —Ü–µ–Ω–∏—Ç–µ–ª–µ–π\". –ù–æ –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è —à—É—Ç–∫–∞ –¥–æ–ª–∂–Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–æ.\n",
    "\n",
    "–ú—ã —Ä–µ—à–∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º—É, –∫–æ—Ç–æ—Ä–∞—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —à—É—Ç–∫–∏ –ø—Ä–æ –º–µ–¥–≤–µ–¥—è. –®—É—Ç–∫–∞ –¥–æ–ª–∂–Ω–∞ –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å \"–®–µ–ª –º–µ–¥–≤–µ–¥—å –ø–æ –ª–µ—Å—É\" –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è \"–°–µ–ª –≤ –º–∞—à–∏–Ω—É –∏ —Å–≥–æ—Ä–µ–ª\". –ö–∞–∫ –±—ã —ç—Ç–æ –æ–ø–∏—Å–∞—Ç—å?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏—è, –∞ –º–æ–¥–µ–ª—å —Å–∞–º–∞ —Ä–µ—à–∞–µ—Ç, –∫—É–¥–∞ –µ–π –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –º—ã —Ç—É—Ç –Ω–µ –¥–æ–±–∞–≤–∏–ª–∏. –ß—Ç–æ –º–æ–¥–µ–ª—å —Ä–µ—à–∏–ª–∞, —Ç–æ –∏ –±—É–¥–µ—Ç.\n",
    "\n",
    "–°—Ä–∞–∑—É –≤–∏–¥–∏–º –∏ –ø—Ä–æ–±–ª–µ–º—É, –∫–æ—Ç–æ—Ä—É—é –º—ã –ø–æ–ª—É—á–∞–µ–º –ø—Ä–∏ $\\gamma = 1$, –ø—É—Å—Ç—å –∏ –≤ —É—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ. –ù–∏—á—Ç–æ –Ω–µ –∑–∞–ø—Ä–µ—â–∞–µ—Ç –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –¥–µ—Ç–∞–ª–∏ –∫ –∞–Ω–µ–∫–¥–æ—Ç—É, —Ç–µ–º —Å–∞–º—ã–º —É–≤–µ–ª–∏—á–∏–≤–∞—è $G_t$.\n",
    "–†–∞–±–æ—Ç–∞—Ç—å —Å —Ç–∞–∫–æ–π –º–æ–¥–µ–ª—å—é –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.\n",
    "\n",
    "–ï—Å–ª–∏ –≤ –∫–∞–∫–æ–π-—Ç–æ –º–æ–º–µ–Ω—Ç –æ–±—É—á–µ–Ω–∏—è –Ω–∞—à–∞ –º–æ–¥–µ–ª—å —Å—Ç–∞–ª–∞ –ø–æ—Ö–æ–¥–∏—Ç—å –Ω–∞ —ç—Ç—É, —Ç–æ –Ω–∏—á–µ–≥–æ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –º—ã –∏ –¥–∞–ª–µ–µ –Ω–µ –ø–æ–ª—É—á–∏–º. –ê –≤–æ—Ç –µ—Å–ª–∏ –≤–≤–µ–¥–µ–Ω–∏–µ–º –¥–∏—Å–∫–∞—É–Ω—Ç–∞ –¥–∞—Ç—å –º–æ–¥–µ–ª–∏ –ø–æ–Ω—è—Ç—å, —á—Ç–æ —Å–ª—É—à–∞—Ç–µ–ª–∏ –∞–Ω–µ–∫–¥–æ—Ç–∞ –≤—Å–µ –∂–µ —Ö–æ—Ç—è—Ç –≤—Å–∫–æ—Ä–µ —É—Å–ª—ã—à–∞—Ç—å –µ–≥–æ –∫–æ–Ω–µ—Ü, —Ç–æ –ø—Ä–æ–±–ª–µ–º–∞ —É–π–¥–µ—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–û–±—ã—á–Ω–æ $0 \\le \\gamma \\le 1$**\n",
    "\n",
    "–û–±—ã—á–Ω–æ $\\gamma$ —Å—Ç–∞–≤—è—Ç —Ä–∞–≤–Ω–æ–π —á–µ–º—É-—Ç–æ –º–µ–∂–¥—É –¥–≤—É–º—è —ç—Ç–∏–º–∏ –∫—Ä–∞–π–Ω–æ—Å—Ç—è–º–∏.\n",
    "\n",
    "–ë–ª–∏–∑–æ—Å—Ç—å $\\gamma$ –∫ 0 –æ—Ç—Ä–∞–∂–∞–µ—Ç –Ω–∞—à—É \"–Ω–µ—Ç–µ—Ä–ø–µ–ª–∏–≤–æ—Å—Ç—å\" ‚Äî –Ω–∞—Å–∫–æ–ª—å–∫–æ –≤–∞–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–≥—Ä–∞–¥—É –∏–º–µ–Ω–Ω–æ —Å–µ–π—á–∞—Å.\n",
    "\n",
    "–ù–∞–ª–∏—á–∏–µ —Ç–∞–∫–æ–≥–æ $\\gamma$ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–º –Ω–µ –¥–µ–ª–∞—Ç—å —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º —á–∏—Å–ª–æ–º —à–∞–≥–æ–≤ –∏ –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º: —Ç–µ–ø–µ—Ä—å –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ return –±—É–¥–µ—Ç –∫–æ–Ω–µ—á–Ω—ã–º —á–∏—Å–ª–æ–º, —Ç.–∫. –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è return –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ —Å–≤–µ—Ä—Ö—É —Å—É–º–º–æ–π –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ —É–±—ã–≤–∞—é—â–µ–π –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–∏.\n",
    "\n",
    "–ü—É—Å—Ç—å $R_{max} = max R_i$ ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞, –∫–æ—Ç–æ—Ä—É—é –º—ã –≤ –ø—Ä–∏–Ω—Ü–∏–ø–µ –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å –≤ –∫–∞–∫–æ–º-—Ç–æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏.\n",
    "\n",
    "$\\displaystyle G_t = R_{t+1} + \\gamma \\cdot R_{t+2} + \\gamma^2 \\cdot R_{t+3} + ... \\le R_{max} + \\gamma \\cdot R_{max} + \\gamma^2 \\cdot R_{max} + ... = R_{max} (1 + \\gamma + \\gamma^2 + ... ) \\le R_{max} \\cdot \\frac{1}{1-\\gamma} = const $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discounting makes sums finite**\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/discounting_makes_sums_finite.png\" alt=\"Drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "G_{0}=\\sum_{k=0}^{\\infty} \\gamma^{k}=\\frac{1}{1-\\gamma}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∞–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å, —á—Ç–æ –≤—ã–±–æ—Ä $\\gamma$ –º–µ–Ω—è–µ—Ç –∑–∞–¥–∞—á—É, –∫–æ—Ç–æ—Ä—É—é –º—ã —Ä–µ—à–∞–µ–º, –∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –º–µ–Ω—è–µ—Ç —Ä–µ—à–µ–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ–±–ª–µ–º–∞ –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Ö–æ–¥–æ–≤, –∫–æ—Ç–æ—Ä–æ–π –±—É–¥–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞ ($G_t$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ü–æ–ª–∏—Ç–∏–∫–∞ (policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ª–∏—Ç–∏–∫–∞ (policy) $\\pi$ ‚Äî —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è $s$ –¥–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ –¥–µ–π—Å—Ç–≤–∏–π $A$.\n",
    "$$ \\large\n",
    "\\pi(a|s)=\\mathbb{P}\\left[A_{t}=a \\mid S_{t}=s\\right]\n",
    "$$\n",
    "- –ü–æ–ª–∏—Ç–∏–∫–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞\n",
    "- –ü–æ–ª–∏—Ç–∏–∫–∏ MDP –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—Ä–µ–¥—ã (–∞ –Ω–µ –æ—Ç –ø—Ä–æ—à–ª—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π)\n",
    "- —Ç. –µ. –ø–æ–ª–∏—Ç–∏–∫–∏ —è–≤–ª—è—é—Ç—Å—è —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–º–∏ (–Ω–µ –∑–∞–≤–∏—Å—è—â–∏–º–∏ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏),\n",
    "$$ \\large\n",
    "A_{t} \\sim \\pi\\left(\\cdot \\mid S_{t}\\right), \\forall t>0\n",
    "$$\n",
    "\n",
    "–î–ª—è –Ω–∞—à–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ —Å–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–º:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/markov_policy_example.png\" alt=\"Drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action-value function $q_{\\pi}(s, a)$ (Q-—Ñ—É–Ω–∫—Ü–∏—è)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $q_\\pi(s,\\color{red}a)$ ‚Äî –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –Ω–æ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏, —á—Ç–æ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ $s (s_0 = s)$ –±—ã–ª–æ –≤—ã–±—Ä–∞–Ω–æ –¥–µ–π—Å—Ç–≤–∏–µ $a$ (–º—ã —Ñ–∏–∫—Å–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ). –¢–æ –µ—Å—Ç—å –≤ $q$ –º—ã, –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç $v$, —Ñ–∏–∫—Å–∏—Ä—É–µ–º –Ω–∞—à–µ –ø–µ—Ä–≤–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –ø–æ–ª–∏—Ç–∏–∫–µ), –∞ –≤ $v$ –º—ã –ø–µ—Ä–≤–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –≤—ã–±–∏—Ä–∞–µ–º —Å–æ–≥–ª–∞—Å–Ω–æ –ø–æ–ª–∏—Ç–∏–∫–µ $\\pi$.\n",
    "\n",
    "–ú–∞—Ç–æ–∂–∏–¥–∞–Ω–∏–µ –∑–¥–µ—Å—å –±–µ—Ä–µ—Ç—Å—è –ø–æ –Ω–∞—à–µ–π –ø–æ–ª–∏—Ç–∏–∫–µ, —Ç.–∫. –æ–Ω–∞ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State-value function $v_{\\pi}(s)$ (V-—Ñ—É–Ω–∫—Ü–∏—è)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $v_\\pi(s)$ ‚Äî –∏–∑–º–µ—Ä—è–µ—Ç —Ü–µ–Ω–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –∞ –∏–º–µ–Ω–Ω–æ –∫–∞–∫–æ–µ –æ–∂–∏–¥–∞–µ–º–æ–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å, –µ—Å–ª–∏ –Ω–∞—á–∞—Ç—å –¥–≤–∏–≥–∞—Ç—å—Å—è –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è $s$ –≤ —Ç–µ—á–µ–Ω–∏–µ –≤—Å–µ–≥–æ –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –≤—Ä–µ–º–µ–Ω–∏, –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞—è—Å—å –ø–æ–ª–∏—Ç–∏–∫–∏ $\\pi$.\n",
    "\n",
    "–¢–∞–∫, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∞–≥–µ–Ω—Ç –º–æ–∂–µ—Ç —Å–ª–µ–¥–æ–≤–∞—Ç—å –ø–æ–ª–∏—Ç–∏–∫–µ, –∑–∞–∫–ª—é—á–∞—é—â–µ–π—Å—è –≤ –ø–µ—Ä–µ—Ö–æ–¥–µ –º–µ–∂–¥—É —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏ —Å –≤—ã—Å–æ–∫–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç—å—é. –û–¥–Ω–∞–∫–æ —Ñ—É–Ω–∫—Ü–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è —É–¥–∞–ª–µ–Ω–∞ –æ—Ç –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–º, –ø–æ—Å–∫–æ–ª—å–∫—É –∞–≥–µ–Ω—Ç –∑–∞—á–∞—Å—Ç—É—é –Ω–µ –º–æ–∂–µ—Ç —Å–∞–º –≤—ã–±—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –≤ –∫–æ—Ç–æ—Ä–æ–µ –ø–µ—Ä–µ–π–¥–µ—Ç, –ø–æ—Å–∫–æ–ª—å–∫—É –Ω–∞ –Ω–µ–≥–æ –±—É–¥–µ—Ç –æ–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –≤–ª–∏—è–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –±—Ä–æ—Å–∫–∏ –∫—É–±–∏–∫–æ–≤) –∏–ª–∏ –≤–Ω–µ—à–Ω–∏—Ö —Å–∏–ª (—Ö–æ–¥ –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞). –ü–æ—ç—Ç–æ–º—É –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç —Ü–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π, –∞ –¥–µ–π—Å—Ç–≤–∏–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://images.chesscomfiles.com/uploads/v1/images_users/tiny_mce/dockers88/phpt0yU5I.png\" alt=\"Drawing\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –£—Ä–∞–≤–Ω–µ–Ω–∏–µ –ë–µ–ª–ª–º–∞–Ω–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[–ë–µ–ª–ª–º–∞–Ω](https://en.wikipedia.org/wiki/Richard_E._Bellman) –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ –∑–∞–¥–∞—á–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤ –¥–∏—Å–∫—Ä–µ—Ç–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∞ –≤ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–π –ø–æ—à–∞–≥–æ–≤–æ–π —Ñ–æ—Ä–º–µ, –ø—É—Ç–µ–º –∑–∞–ø–∏—Å–∏ —Å–≤—è–∑–∏ –º–µ–∂–¥—É **—Ñ—É–Ω–∫—Ü–∏–µ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ç–µ–∫—É—â–∏–π –ø–µ—Ä–∏–æ–¥ –∏ —Ñ—É–Ω–∫—Ü–∏–µ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Å–ª–µ–¥—É—é—â–µ–º –ø–µ—Ä–∏–æ–¥–µ**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "v_{\\pi}(s) &=\\mathbb{E}_{\\pi}\\left[G_{t} \\mid S_{t}=s\\right] \\\\\n",
    "&=\\mathbb{E}_{\\pi}\\left[R_{t+1}+\\gamma R_{t+2}+\\gamma^{2} R_{t+3}+\\ldots \\mid S_{t}=s\\right] \\\\\n",
    "&=\\mathbb{E}_{\\pi}\\left[R_{t+1}+\\gamma\\left(R_{t+2}+\\gamma R_{t+3}+\\ldots\\right) \\mid S_{t}=s\\right] \\\\\n",
    "&=\\mathbb{E}_{\\pi}\\left[R_{t+1}+\\gamma G_{t+1} \\mid S_{t}=s\\right]\\\\\n",
    "&=\\color{red}{R_{t+1}+\\gamma\\mathbb{E}_{\\pi}}\\left[\\color{red}{G_{t+1}\\mid S_{t}=s}\\right]\\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}$$\n",
    "\n",
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–æ, —á—Ç–æ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ –≤—ã–Ω–æ—Å–∏—Ç—Å—è –∏–∑ –ø–æ–¥ –∑–Ω–∞–∫–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–∂–∏–¥–∞–Ω–∏—è, –ø–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—é —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –≤ –≤–∏–¥–µ [—Ä–µ–∑–µ—Ä–≤–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã](https://openreview.net/pdf/45363cfb2c1b1123fc49b52916f8f3a451e09bbd.pdf) (_backup diagram_):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L15/state_value_diagr.png\" alt=\"Drawing\" width=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\mathbf {s} $ ‚Äî **–Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ**, –∏–∑ –Ω–µ–≥–æ –∏—Å—Ö–æ–¥—è—Ç —Å—Ç—Ä–µ–ª–∫–∏, –æ—Ç–æ–±—Ä–∞–∂–∞—é—â–∏–µ **–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å** —Å–æ–≤–µ—Ä—à–∏—Ç—å —Ç–æ –∏–ª–∏ –∏–Ω–æ–µ **–¥–µ–π—Å—Ç–≤–∏–µ** –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å **–ø–æ–ª–∏—Ç–∏–∫–æ–π** $ \\mathbf{\\pi} $, **–¥–µ–π—Å—Ç–≤–∏—è** $\\mathbf{a}$ –æ–±–æ–∑–Ω–∞—á–∞—é—Ç—Å—è –ø–µ—Ä–µ—Ö–æ–¥–æ–º –∏–∑ –∫—Ä—É–∂–∫–∞ –≤ —á—ë—Ä–Ω—É—é —Ç–æ—á–∫—É, —á–µ—Ä–Ω—ã–µ —Ç–æ—á–∫–∏ –æ–±–æ–∑–Ω–∞—á–∞—é—Ç $\\mathbf{q} $.\n",
    "\n",
    "–ü–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –¥–µ–π—Å—Ç–≤–∏–µ –±—ã–ª–æ –ø—Ä–∏–Ω—è—Ç–æ, –≤ _—Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–π_ —Å—Ä–µ–¥–µ –∞–≥–µ–Ω—Ç –º–æ–∂–µ—Ç –æ–∫–∞–∑–∞—Ç—å—Å—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏—è—Ö, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º—ã—Ö **–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ –ø–µ—Ä–µ—Ö–æ–¥–∞** $\\mathbf{p}$,\n",
    "\n",
    "–í _–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π_ —Å—Ä–µ–¥–µ, –∞–≥–µ–Ω—Ç –æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º—É –¥–µ–π—Å—Ç–≤–∏—é. –ù–∞–≥—Ä–∞–¥–∞ $\\mathbf{r}$ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—è $\\mathbf{a}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –º–æ–∂–Ω–æ —Ä–∞–∑–ª–æ–∂–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é **—Ü–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏—è**:\n",
    "$$\n",
    "\\large q_{\\pi}(s, a)=R_{t+1}+\\gamma\\mathbb{E}_{\\pi}\\left[G_{t+1} \\mid S_{t}=s, A_{t}=a\\right]\\\\\n",
    "$$\n",
    "\n",
    "**Q-—Ñ—É–Ω–∫—Ü–∏—è** —É–±–∏—Ä–∞–µ—Ç —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å –ø–æ–ª–∏—Ç–∏–∫–∏ –Ω–∞ –ø–µ—Ä–≤–æ–º —à–∞–≥–µ. –° –ø–æ–º–æ—â—å—é –Ω–µ–µ –º—ã —Ñ–∏–∫—Å–∏—Ä—É–µ–º –Ω–∞—à –ø–µ—Ä–≤—ã–π —à–∞–≥ –∏–∑ —ç—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è.\n",
    "\n",
    "–ú—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∏–Ω–∞–º–∏–∫—É —Å—Ä–µ–¥—ã –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –º–∞—Ç–æ–∂–∏–¥–∞–Ω–∏–µ $E_{\\pi}$, —Å—É–º–º–∏—Ä—É—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö —Å–ª–µ–¥—É—é—â–∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π $P_{ss'}^{a}$ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –Ω–∞–≥—Ä–∞–¥ $R_{ss'}^{a}$:\n",
    "\n",
    "$$\n",
    "\\large v_{\\pi}(s) = \\sum_a\\pi(a|s)\\sum_{s'}P_{ss'}^{a}(R_{ss'}^{a}+\\gamma\\mathbb{E}_{\\pi}\\left[G_{t+1}\\mid S_{t+1}=s'\\right]) = \\sum_a\\pi(a|s)\\sum_{s'}P_{ss'}^{a}(R_{ss'}^{a}+\\gamma v_{\\pi}(s'))\n",
    "$$\n",
    "\n",
    "–ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏—è:\n",
    "\n",
    "$$\n",
    "\\large q_{\\pi}(s) = \\sum_{s'}P_{ss'}^{a}(R_{ss'}^{a}+\\gamma\\sum_{a'}\\pi(a'|s') q_{\\pi}(s'))\n",
    "$$\n",
    "\n",
    "–ü–æ–ª—É—á–∏–≤—à–µ–µ—Å—è –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –∏ –µ—Å—Ç—å _—É—Ä–∞–≤–Ω–µ–Ω–∏–µ –ë–µ–ª–ª–º–∞–Ω–∞_ &mdash; —ç—Ç–æ –ø–æ —Å—É—Ç–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è. –¢–∞–∫–∏–µ —É—Ä–∞–≤–Ω–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –≤ RL, –Ω–æ –∏ –≤–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á.\n",
    "\n",
    "–£—Ä–∞–≤–Ω–µ–Ω–∏–µ –ë–µ–ª–ª–º–∞–Ω–∞ —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å —Å –ø–æ–º–æ—â—å—é —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–∏–Ω—Ü–∏–ø –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ—Å—Ç–∏ –ë–µ–ª–ª–º–∞–Ω–∞**\n",
    "\n",
    "–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ –æ–±–ª–∞–¥–∞–µ—Ç —Ç–µ–º —Å–≤–æ–π—Å—Ç–≤–æ–º, —á—Ç–æ –∫–∞–∫–∏–º–∏ –±—ã –Ω–∏ –±—ã–ª–∏ –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –Ω–∞—á–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å —Å–æ–±–æ–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–µ—Ä–≤–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è.\n",
    " (Bellman, 1957, Chap. III.3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L15/value_diagr.png\" alt=\"Drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. –¶–µ–Ω–Ω–æ—Å—Ç—å (Value) $v$ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ $s$ ‚Äî —ç—Ç–æ $v_{\\pi}(s)$\n",
    "\n",
    "2. –ò–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è $s$ –∞–≥–µ–Ω—Ç –º–æ–∂–µ—Ç —Å–¥–µ–ª–∞—Ç—å 3 –¥–µ–π—Å—Ç–≤–∏—è: $(a_1, a_2, a_3)$\n",
    "\n",
    "3. –¶–µ–Ω–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏—è (Action Value) ‚Äî —ç—Ç–æ $v_{\\pi}(s,a)$, –≥–¥–µ $a = \\{a_1, a_2, a_3\\}$\n",
    "\n",
    "4. –ê–≥–µ–Ω—Ç –ø—Ä–µ–¥–ø—Ä–∏–Ω—è–ª –¥–µ–π—Å—Ç–≤–∏–µ $a3$. –ê —Ç–∞–∫ –æ–Ω –º–æ–∂–µ—Ç –ø–µ—Ä–µ–π—Ç–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏—è $s‚Äô_1$, $s‚Äô_2$ –∏–ª–∏ $s‚Äô_3$ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ—Ö–æ–¥–∞ p1, p2 –∏–ª–∏ p3 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ\n",
    "\n",
    "5. –ü–æ–ª—É—á–µ–Ω–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞ ‚Äî $r_1$, $r_2$ –∏–ª–∏ $r_3$ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–º–µ—Å—Ç–æ —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—å **—Ü–µ–Ω–Ω–æ—Å—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏—è** $ \\mathbf{s}$ **–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π** $ \\mathbf{s'}$, –≤ –∫–æ—Ç–æ—Ä—ã–µ –º—ã –º–æ–∂–µ–º –ø–µ—Ä–µ–π—Ç–∏, –º—ã –º–æ–∂–µ–º —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å —Ü–µ–Ω–Ω–æ—Å—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏—è, —É—á–∏—Ç—ã–≤–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –¥–µ–π—Å—Ç–≤–∏–π $\\mathbf{a}$, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –º–æ–∂–µ–º —Å–æ–≤–µ—Ä—à–∏—Ç—å, –Ω–∞—Ö–æ–¥—è—Å—å –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ $\\mathbf{s}$. –ü–æ–ª—É—á–∞–µ–º —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –æ–¥–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ –¥—Ä—É–≥—É—é:\n",
    "\n",
    "$$\\large v_{\\pi}(s) = \\sum_a\\pi(a|s)q_{\\pi}(s,a)$$\n",
    "\n",
    "–ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ, **—Ü–µ–Ω–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏—è** –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ü–µ–Ω–µ–Ω–∞ **–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–æ—è–Ω–∏–π**, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–∂–Ω–æ –æ–∫–∞–∑–∞—Ç—å—Å—è –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —ç—Ç–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è:\n",
    "\n",
    "$$\\large q_{\\pi}(s,a) = \\sum_{s'}P_{ss'}^{a}(R_{ss'}^{a}+\\gamma v_{\\pi}(s'))\n",
    "$$\n",
    "\n",
    "–ò—Ç–∞–∫, –∫–∞–∫ —Å –ø–æ–º–æ—â—å—é —É—Ä–∞–≤–Ω–µ–Ω–∏—è –ë–µ–ª–ª–º–∞–Ω–∞ –º–æ–∂–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è? –ü–æ —Å—É—Ç–∏, –º—ã –±—É–¥–µ–º –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—Ç—å —É—Ä–∞–≤–Ω–µ–Ω–∏–µ –ë–µ–ª–ª–º–∞–Ω–∞ —Å –º–∞–∫—Å–∏–º—É–º–∞–º–∏ –≤–º–µ—Å—Ç–æ –º–∞—Ç–æ–∂–∏–¥–∞–Ω–∏–π:\n",
    "\n",
    "$$\n",
    "\\large v_*(s) = \\max_a\\sum_{s'}P_{ss'}^{a}(R_{ss'}^{a}+\\gamma v_*(s')) = \\max_{a(s)}q_*(s,a)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§–∞–∫—Ç–∏—á–µ—Å–∫–∏ $\\mathbf{q_*(s,a)}$ –±—É–¥–µ—Ç –∑–∞–¥–∞–≤–∞—Ç—å **–æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É**:\n",
    "\n",
    "$$\\large \\pi^*(s) = argmax_aq_*(s,a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏ –ë–µ–ª–ª–º–∞–Ω–∞ –¥–ª—è MDP (—Ä–µ—à–µ–Ω–∏–µ \"MDP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model-based –∏ model-free –∞–ª–≥–æ—Ä–∏—Ç–º—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ú–µ—Ç–æ–¥—ã –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è, –≤–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å –ø–æ–∏—Å–∫–∞ –º–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞ –¥–≤–µ —á–∞—Å—Ç–∏\n",
    "\n",
    "**Policy evaluation**\n",
    "\n",
    "–£ –Ω–∞—Å –µ—Å—Ç—å –Ω–µ–∫–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞ $\\pi$. –ï—Å–ª–∏ –º—ã –º–Ω–æ–≥–æ —Ä–∞–∑ –ø–æ—Å—á–∏—Ç–∞–µ–º $v_\\pi$ –ø–æ —Ñ–æ—Ä–º—É–ª–µ, —Ç–æ –≤ –∏—Ç–æ–≥–µ –º—ã —Å–æ–π–¥–µ–º—Å—è –∫ —Ö–æ—Ä–æ—à–µ–π –æ—Ü–µ–Ω–∫–µ $v_\\pi(s)$ –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è.\n",
    "\n",
    "**Policy improvement**\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å –º—ã –∑–Ω–∞–µ–º –ø—Ä–∞–≤–∏–ª–æ $v$ –¥–ª—è –Ω–∞—à–µ–π –ø–æ–ª–∏—Ç–∏–∫–∏. –ö–∞–∫ –Ω–∞–º –µ–≥–æ —É–ª—É—á—à–∏—Ç—å?\n",
    "–ë—É–¥–µ–º –≤ –∫–∞–∂–¥–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –º–µ–Ω—è—Ç—å –Ω–∞—à—É –ø–æ–ª–∏—Ç–∏–∫—É —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –º—ã —à–ª–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å –ª—É—á—à–∏–º $q$. –ú—ã –º–æ–≥–ª–∏ –±—ã —É–ª—É—á—à–∏—Ç—å —ç—Ç–æ, –¥–µ–π—Å—Ç–≤—É—è –∂–∞–¥–Ω–æ $\\mathrm{q}(\\mathrm{s}, \\mathrm{a}) !$\n",
    "$$\n",
    "\\large\n",
    "\\pi^{\\prime}(s) \\leftarrow \\underset{a}{\\arg \\max } \\overbrace{\\sum_{r, s^{\\prime}} P_{ss'}^a\\left[r+\\gamma v_{\\pi}\\left(s^{\\prime}\\right)\\right]}^{q_{\\pi}(s, a)}\n",
    "$$\n",
    "\n",
    "–≠—Ç–∞ –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ —É–ª—É—á—à–µ–Ω–∏—é –ø–æ–ª–∏—Ç–∏–∫–∏!\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&\\text { –µ—Å–ª–∏ } \\quad q_{\\pi}\\left(s, \\pi^{\\prime}(s)\\right) \\geq v_{\\pi}(s) \\quad \\text { –¥–ª—è –≤—Å–µ—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π, } \\\\\n",
    "&\\text { —Ç–æ–≥–¥–∞ } \\quad v_{\\pi^{\\prime}}(s) \\geq v_{\\pi}(s) \\text { –æ–∑–Ω–∞—á–∞–µ—Ç, } \\\\\n",
    "&\\text { —á—Ç–æ } \\qquad \\pi^{\\prime} \\geq \\pi\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L15/policy_iteration.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–µ—Ç–æ–¥ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å—Ö–æ–¥–∏—Ç—Å—è:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/convergence_of_method.png\" alt=\"Drawing\" width=\"400\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/random_and_greedy_policy.png\" alt=\"Drawing\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/random_and_greedy_policy_find_optimal_policy.png\" alt=\"Drawing\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§–∞–∫—Ç–∏—á–µ—Å–∫–∏, —ç—Ç–∞–ø policy evaluation –æ—Ç policy iteration  –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–æ–∫—Ä–∞—â–µ–Ω —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –≥–∞—Ä–∞–Ω—Ç–∏–π —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ policy iteration.\n",
    "\n",
    "–û–¥–∏–Ω –≤–∞–∂–Ω—ã–π –æ—Å–æ–±—ã–π —Å–ª—É—á–∞–π &mdash; —ç—Ç–æ –∫–æ–≥–¥–∞ **–æ—Ü–µ–Ω–∫–∞ –ø–æ–ª–∏—Ç–∏–∫–∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è** —Å—Ä–∞–∑—É **–ø–æ—Å–ª–µ –æ–¥–Ω–æ–≥–æ —Ü–∏–∫–ª–∞** (–æ–¥–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è). –≠—Ç–æ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º **–Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è value iteration**. –ï–≥–æ –º–æ–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å –∫–∞–∫ –ø—Ä–æ—Å—Ç—É—é –æ–ø–µ—Ä–∞—Ü–∏—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—á–µ—Ç–∞–µ—Ç –≤ —Å–µ–±–µ —ç—Ç–∞–ø—ã —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ —É—Å–µ—á–µ–Ω–Ω–æ–π policy evaluation (–æ–¥–∏–Ω —à–∞–≥).\n",
    "\n",
    "–≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –≤–æ–æ–±—â–µ –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –ø–æ–ª–∏—Ç–∏–∫—É –≤ —è–≤–Ω–æ–º –≤–∏–¥–µ, —Ç.–∫. –æ–Ω–∞ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è Q-—Ñ—É–Ω–∫—Ü–∏–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value iteration (VI) vs. Policy iteration (PI)\n",
    "\n",
    "- VI –±—ã—Å—Ç—Ä–µ–µ –∑–∞ –æ–¥–Ω—É –∏—Ç–µ—Ä–∞—Ü–∏—é $-\\mathrm{O}\\left(|\\mathrm{A} \\| \\mathrm{S}|^{2}\\right)$\n",
    "- VI —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–Ω–æ–≥–æ –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
    "-PI –º–µ–¥–ª–µ–Ω–Ω–µ–µ –∑–∞ –æ–¥–Ω—É –∏—Ç–µ—Ä–∞—Ü–∏—é $-\\mathrm{O}\\left(|\\mathrm{A} \\| \\mathrm{S}|^{2}+|\\mathrm{S}|^{3}\\right)$\n",
    "- PI —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∞–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
    "\n",
    "–ü—Ä–æ–≤–µ–¥–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å –∫–∞–∫–∏–º-—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —à–∞–≥–æ–≤ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –ª—É—á—à–µ–π –ø–æ–ª–∏—Ç–∏–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ê–ª–≥–æ—Ä–∏—Ç–º**\n",
    "\n",
    "1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "- –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ V —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —Ä–∞–≤–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ—Å—Ç–æ—è–Ω–∏–π.\n",
    "\n",
    "- –ó–∞–ø–æ–ª–Ω—è–µ–º –µ–≥–æ –Ω—É–ª—è–º–∏\n",
    "\n",
    "\n",
    "2. –û—Ü–µ–Ω–∫–∞ –ø–æ–ª–∏—Ç–∏–∫–∏ (Policy evaluation)\n",
    "\n",
    "- –î–ª—è –≤—Å–µ—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π —Å—á–∏—Ç–∞–µ–º Q(s,a)\n",
    "\n",
    "- –û–±–Ω–æ–≤–ª—è–µ–º –º–∞—Å—Å–∏–≤ V[s] $\\rightarrow$ max(Q(s,a))\n",
    "\n",
    "\n",
    "*–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç Policy iteration, —Å–∞–º–∞ –ø–æ–ª–∏—Ç–∏–∫–∞ –≤ –ø–∞–º—è—Ç–∏ –Ω–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è, –æ–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –ø—Ä–∏ –ø–æ–º–æ—â–∏ Q-—Ñ—É–Ω–∫—Ü–∏–∏.\n",
    "\n",
    "\n",
    "3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª–∏—Ç–∏–∫–∏ (Policy improvement)\n",
    "\n",
    "- –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—á–∏—Ç–∞–µ–º Q(s,a) –¥–ª—è –≤—Å–µ—Ö a\n",
    "\n",
    "- –í—ã–±–∏—Ä–∞–µ–º a, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ Q(s,a) –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ\n",
    "\n",
    "- –ï—Å–ª–∏ –ø–æ–ª–∏—Ç–∏–∫–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —à–∞–≥—É 2, –∏–Ω–∞—á–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –ø–æ—Å—Ç—Ä–æ–∏–º —á—Ç–æ-–Ω–∏–±—É–¥—å, —á—Ç–æ–±—ã —Ä–µ—à–∏—Ç—å —ç—Ç—É MDP.\n",
    "\n",
    "–ó–∞–ø–∏—à–µ–º —Ä–µ—à–µ–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ MDP. –°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º —ç—Ç–æ  __V__alue __I__teration\n",
    "\n",
    "–ü—Å–µ–≤–¥–æ –∫–æ–¥ –¥–ª—è VI:\n",
    "\n",
    "---\n",
    "\n",
    "`1.` Initialize $V^{(0)}(s)=0$, for all $s$\n",
    "\n",
    "`2.` For $i=0, 1, 2, \\dots$\n",
    "\n",
    "`3.` $ \\quad V_{(i+1)}(s) = \\max_a \\sum_{s'} P_{ss'}^a \\cdot [ R_{ss'}^a + \\gamma V_{i}(s')]$, for all $s$\n",
    "\n",
    "---\n",
    "\n",
    "$R_{ss'}^a$ ‚Äî –Ω–∞–≥—Ä–∞–¥–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –≤—ã–±–æ—Ä—É –¥–µ–π—Å—Ç–≤–∏—è a –≤ s,\n",
    "\n",
    "$s$ ‚Äî –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ,\n",
    "\n",
    "$s'$ ‚Äî –Ω–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ-–ø–µ—Ä–≤—ã—Ö, –¥–∞–≤–∞–π—Ç–µ –Ω–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è-–¥–µ–π—Å—Ç–≤–∏—è. $Q^{\\pi}$, –∫–æ—Ç–æ—Ä–∞—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
    "\n",
    "$$\\large Q_i(s, a) = \\sum_{s'} P_{ss'}^a \\cdot [ R_{ss'}^a + \\gamma V_{i}(s')]$$\n",
    "\n",
    "$s'$ ‚Äî –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ—Ö–æ–¥–∞.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_value(mdp, state_values, state, action, gamma):\n",
    "    \"\"\"\n",
    "    Computes Q(s,a) as in formula above\n",
    "\n",
    "    mdp : MDP object\n",
    "    state_values : dictionayry of { state_i : V_i }\n",
    "    state: string id of current state\n",
    "    gamma: float discount coeff\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    next_states = mdp.get_next_states(state, action)\n",
    "\n",
    "    Q = 0.0\n",
    "\n",
    "    for next_state in next_states.keys():\n",
    "        p = next_states[next_state]  # FIXME: alternatively p = mdp.get_transition_prob(state, action, next_state)\n",
    "        Q += p * (\n",
    "            mdp.get_reward(state, action, next_state) + gamma * state_values[next_state]\n",
    "        )\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É—è $Q(s,a)$, –º—ã –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å \"—Å–ª–µ–¥—É—é—â–µ–µ\" V(s) –¥–ª—è VI:\n",
    "$$\\large V_{(i+1)}(s) = \\max_a \\sum_{s'} P_{ss'}^a \\cdot [ R_{ss'}^a + \\gamma V_{i}(s')] = \\max_a Q_i(s,a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_state_value(mdp, state_values, state, gamma):\n",
    "    \"\"\"Computes next V(s) as in formula above. Please do not change state_values in process.\"\"\"\n",
    "    if mdp.is_terminal(state):\n",
    "        return 0  # Game over\n",
    "\n",
    "    q_max = float(\"-inf\")\n",
    "    actions = mdp.get_possible_actions(state)\n",
    "    for a in actions:\n",
    "        q = get_action_value(mdp, state_values, state, a, gamma)\n",
    "        q_max = max(q_max, q)\n",
    "    return q_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–∫–æ–Ω–µ—Ü, –¥–∞–≤–∞–π—Ç–µ –æ–±—ä–µ–¥–∏–Ω–∏–º –≤—Å–µ, —á—Ç–æ –º—ã –Ω–∞–ø–∏—Å–∞–ª–∏, –≤ –∞–ª–≥–æ—Ä–∏—Ç–º –∏—Ç–µ—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—á–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "gamma = 0.9  # discount for MDP\n",
    "num_iter = 100  # maximum iterations, excluding initialization\n",
    "# stop VI if new values are this close to old values (or closer)\n",
    "min_difference = 0.001\n",
    "\n",
    "# initialize V(s)\n",
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "display_jpeg(MDP.plot_graph_with_state_values(mdp, state_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–¥–µ—Å—å –Ω–µ—Ç –Ω–∏–∫–∞–∫–æ–≥–æ \"—Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è\"! –î–æ–±–∞–≤–∏–º –º–∞—Ç—Ä–∏—Ü—É —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏ –ø–æ—Å—Ç—Ä–æ–∏–º –Ω–æ–≤—ã–π –≥—Ä–∞—Ñ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_iter):\n",
    "    # Compute new state values using the functions you defined above.\n",
    "    # It must be a dict {state : float V_new(state)}\n",
    "\n",
    "    new_state_values = {}\n",
    "    for s in state_values.keys():\n",
    "        new_state_values[s] = get_new_state_value(mdp, state_values, s, gamma)\n",
    "\n",
    "    # Compute difference\n",
    "    diff = max(abs(new_state_values[s] - state_values[s]) for s in mdp.get_all_states())\n",
    "    print(\"iter %4i   |   diff: %6.5f   |   \" % (i, diff), end=\"\")\n",
    "    print(\"   \".join(\"V(%s) = %.3f\" % (s, v) for s, v in state_values.items()))\n",
    "    state_values = new_state_values\n",
    "\n",
    "    if diff < min_difference:\n",
    "        print(\"Terminated\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_jpeg(MDP.plot_graph_with_state_values(mdp, state_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è —ç—Ç–∏–º $V^{*}(s)$, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –≤ –∫–∞–∂–¥–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏:\n",
    "\n",
    " $$\\pi^*(s) = argmax_a \\sum_{s'} P_{ss'}^a \\cdot [ R_{ss'}^a + \\gamma V_{i}(s')] = argmax_a Q_i(s,a)$$\n",
    "\n",
    "–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ –æ—Ç $V(s)$ –≤ —Ç–æ–º, —á—Ç–æ –∑–¥–µ—Å—å –º—ã –±–µ—Ä–µ–º –Ω–µ max, –∞ argmax: –Ω–∞–π—Ç–∏ –¥–µ–π—Å—Ç–≤–∏–µ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º $Q(s,a)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_action(mdp, state_values, state, gamma=0.9):\n",
    "    \"\"\"Finds optimal action using formula above.\"\"\"\n",
    "    if mdp.is_terminal(state):\n",
    "        return None\n",
    "\n",
    "    best_action = None\n",
    "    q_max = float(\"-inf\")\n",
    "    actions = mdp.get_possible_actions(state)\n",
    "    for a in actions:\n",
    "        q = get_action_value(mdp, state_values, state, a, gamma)\n",
    "        if q > q_max:\n",
    "            best_action = a\n",
    "            q_max = q\n",
    "\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_jpeg(MDP.plot_graph_optimal_strategy_and_state_values(mdp, state_values, get_action_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Measure agent's average reward\n",
    "\n",
    "s = mdp.reset()\n",
    "rewards = []\n",
    "for _ in range(10000):\n",
    "    s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
    "    rewards.append(r)\n",
    "\n",
    "print(\"average reward: \", np.mean(rewards))\n",
    "\n",
    "assert 0.40 < np.mean(rewards) < 0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temporal difference (TD)-–æ–±—É—á–µ–Ω–∏–µ (TD-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Ç–∞–∫, –≤ —Ç–µ—Ö —Å–ª—É—á–∞—è—Ö, –∫–æ–≥–¥–∞ –∏–∑–≤–µ—Å—Ç–Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å $P_{ss'}^a$, –∑–∞–¥–∞—á–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–µ—à–µ–Ω–∞ —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–æ–≤ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–∞–∫ –±—ã–ª–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–æ –≤—ã—à–µ. –í —Ä–µ–∞–ª—å–Ω—ã—Ö –∂–µ –∑–∞–¥–∞—á–∞—Ö –¥–∏–Ω–∞–º–∏–∫–∞ —Å—Ä–µ–¥—ã –∑–∞—á–∞—Å—Ç—É—é –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞. –î–≤–∞ –≥–ª–∞–≤–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞, –ø–æ–∑–≤–æ–ª—è—é—â–∏–µ –æ–±—Ö–æ–¥–∏—Ç—å –Ω–µ–∑–Ω–∞–Ω–∏–µ –¥–∏–Ω–∞–º–∏–∫–∏ —Å—Ä–µ–¥—ã, –≤–∫–ª—é—á–∞—é—Ç __–º–µ—Ç–æ–¥ –ú–æ–Ω—Ç–µ –ö–∞—Ä–ª–æ__ (MC) –∏  __temporal difference (TD)-–æ–±—É—á–µ–Ω–∏–µ__ (TD-learning). –û–±–∞ —ç—Ç–∏ –ø–æ–¥—Ö–æ–¥–∞ –æ—Å–Ω–æ–≤—ã–≤–∞—é—Ç—Å—è –Ω–∞ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ–ø—ã—Ç–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å–æ —Å—Ä–µ–¥–æ–π –≤ –≤–∏–¥–µ __—Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π__ (MDP trajectory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDP trajectory**\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/q_learning_scheme.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∏–∑ —Å–µ–±—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "\n",
    "‚Ä¢ states ($s$)\n",
    "‚Ä¢ actions ($a$)\n",
    "‚Ä¢ rewards ($r$)\n",
    "\n",
    "–ü—Ä–∏ —ç—Ç–æ–º MC –æ–ø–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–º–∏ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è–º–∏, –æ–∫–∞–Ω—á–∏–≤–∞—é—â–∏–º–∏—Å—è –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –∞ TD-learning –ø–æ–∑–≤–æ–ª—è–µ—Ç —É—á–∏—Ç—å—Å—è –Ω–∞ –Ω–µ–ø–æ–ª–Ω—ã—Ö —ç–ø–∏–∑–æ–¥–∞—Ö, –Ω–µ –¥–æ–∂–∏–¥–∞—è—Å—å –∫–æ–Ω–µ—á–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/TD_MC_DP_backups_.png\" alt=\"Drawing\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –≤—Ç–æ—Ä–æ–π –ø–æ–¥—Ö–æ–¥ –ø–æ–¥—Ä–æ–±–Ω–µ–µ.\n",
    "\n",
    "**TD-learning** ‚Äî –æ–¥–∏–Ω –∏–∑ –Ω–∞–∏–±–æ–ª–µ–µ –º–æ—â–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –≤–æ –º–Ω–æ–≥–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö RL. –°–º—ã—Å–ª –≤ —Ç–æ–º, —á—Ç–æ–±—ã **–æ–±–Ω–æ–≤–ª—è—Ç—å –æ—Ü–µ–Ω–∫–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏** (—Å–æ—Å—Ç–æ—è–Ω–∏—è –∏–ª–∏ –¥–µ–π—Å—Ç–≤–∏—è) –Ω–∞ **–æ—Å–Ω–æ–≤–µ —É–∂–µ –æ–±—É—á–µ–Ω–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫** –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π. –≠—Ç—É –ø—Ä–æ—Ü–µ–¥—É—Ä—É –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å–ª–∏ –±—ã –º—ã \"–ø–æ–¥—Ç—è–≥–∏–≤–∞–ª–∏\" –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –≤ –∫–æ—Ç–æ—Ä–æ–º –º—ã –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–º —à–∞–≥–µ, –∫ –∑–Ω–∞—á–µ–Ω–∏—é —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –≤ –∫–æ—Ç–æ—Ä–æ–º –º—ã –Ω–∞—Ö–æ–¥–∏–º—Å—è —Å–µ–π—á–∞—Å. –ö–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º —ç—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–∞–∑–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º TD-–æ–±—É—á–µ–Ω–∏—è ‚Äî $TD(0)$ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–º:\n",
    "\n",
    "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ü–µ–Ω–Ω–æ—Å—Ç–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, $V(s)$, –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é $\\pi$. –ü—É—Å—Ç—å, —É –Ω–∞—Å –µ—Å—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ $s$ –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã:\n",
    "- –≤—ã–±–∏—Ä–∞–µ–º –¥–µ–π—Å—Ç–≤–∏–µ $a$ –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ $\\pi$\n",
    "- —Å–æ–≤–µ—Ä—à–∞–µ–º –¥–µ–π—Å—Ç–≤–∏–µ $a$, –Ω–∞–±–ª—é–¥–∞–µ–º –Ω–∞–≥—Ä–∞–¥—É $r$ –∏ —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ $s'$\n",
    "- –æ–±–Ω–æ–≤–ª—è–µ–º –æ—Ü–µ–Ω–∫—É $V(s)$:\n",
    "\n",
    "$$V(s) := V(s) + \\alpha(\\underbrace{\\overbrace{r+\\gamma V(s')}^{\\text{TD target}} - \\overbrace{V(s)}^{\\text{old estimate}}}_{\\text{TD error}})$$\n",
    "- –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É $s:=s'$\n",
    "\n",
    "–ü—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–µ $\\pi$, $\\overbrace{r+\\gamma V(s')}^{\\text{TD target}} = \\overbrace{V(s)}^{\\text{old estimate}}$, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –∏—Ö —Ä–∞–∑–Ω–∏—Ü—É, –Ω–∞–∑—ã–≤–∞–µ–º—É—é _TD-–æ—à–∏–±–∫–æ–π_ (TD-error), –º—ã –∏ –±—É–¥–µ–º –ø—ã—Ç–∞—Ç—å—Å—è –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—á–µ–º—É —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç? –í–µ–¥—å –º—ã –æ–±—É—á–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É $V(s)$ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥—Ä—É–≥–∏—Ö –æ—Ü–µ–Ω–æ–∫ $V(s')$, –∫–æ—Ç–æ—Ä—ã–µ —Ç–∞–∫–∂–µ –±—ã–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å–ª—É—á–∞–π–Ω–æ. –î–µ–ª–æ –≤ —Ç–æ–º, —á—Ç–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—Ç –ø–æ–ª—É—á–µ–Ω–∏—é —Ä–µ–∞–ª—å–Ω—ã—Ö –Ω–∞–≥—Ä–∞–¥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–∞ –ø–æ–±–µ–¥—É) –±—É–¥—É—Ç –æ–±—É—á–∞—Ç—å—Å—è –ø–µ—Ä–≤—ã–º–∏ –∏ –∑–∞—Ç–µ–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—Ç—å —Å–≤–æ—é —Ü–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏–µ –∏–º.\n",
    "\n",
    "–°—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å —Ç–∞–∫–∂–µ, —á—Ç–æ TD-–æ–±—É—á–µ–Ω–∏–µ –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –æ–¥–∏–Ω —à–∞–≥ –≤–ø–µ—Ä–µ–¥. –ê–ª–≥–æ—Ä–∏—Ç–º, –Ω–∞–∑—ã–≤–∞–µ–º—ã–π $TD(\\lambda)$, –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å –æ—Ü–µ–Ω–∫–∏ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Å—Ä–∞–∑—É –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –Ω–∞–∑–∞–¥.\n",
    "\n",
    "–†–∞–∑–Ω–æ–≤–∏–¥–Ω–æ—Å—Ç—è–º–∏ TD-–æ–±—É—á–µ–Ω–∏—è —è–≤–ª—è—é—Ç—Å—è –∞–ª–≥–æ—Ä–∏—Ç–º—ã __Q-learning__ –∏ __SARSA__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–æ–ø—É—Å—Ç–∏–º, –º—ã —Ö–æ–¥–∏–º –ø–æ –ø–æ–ª—é —Ä–∞–∑–º–µ—Ä–æ–º 12x4. –ù–∞—à–∞ —Ü–µ–ª—å ‚Äî –ø–æ–ø–∞—Å—Ç—å –≤ —è—á–µ–π–∫—É (3,11).\n",
    "**–ú–∞–∫—Å–∏–º–∏–∑–∏—Ä—É—è —Å—É–º–º—É –±—É–¥—É—â–∏—Ö –Ω–∞–≥—Ä–∞–¥**, –º—ã —Ç–∞–∫–∂–µ –Ω–∞—Ö–æ–¥–∏–º **—Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å** –∫ —Ü–µ–ª–∏, –ø–æ—ç—Ç–æ–º—É –Ω–∞—à–∞ —Ü–µ–ª—å —Å–µ–π—á–∞—Å ‚Äî –Ω–∞–π—Ç–∏ —Å–ø–æ—Å–æ–± —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L15/q_learning_field.png\" alt=\"Drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞—á–Ω–µ–º —Å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã, –∫–æ—Ç–æ—Ä–∞—è –∏–∑–º–µ—Ä—è–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –≤ –ª—é–±–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ (—á–µ–º –±–æ–ª—å—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º –ª—É—á—à–µ –¥–µ–π—Å—Ç–≤–∏–µ).\n",
    "\n",
    "* –¢–∞–±–ª–∏—Ü–∞ –±—É–¥–µ—Ç –∏–º–µ—Ç—å –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –æ–¥–∏–Ω —Å—Ç–æ–ª–±–µ—Ü –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è. –°–µ—Ç–∫–∞ –∏–º–µ–µ—Ç 48 (4 –ø–æ Y –Ω–∞ 12 –ø–æ X) —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã 4 –¥–µ–π—Å—Ç–≤–∏—è (–≤–≤–µ—Ä—Ö, –≤–Ω–∏–∑, –≤–ª–µ–≤–æ, –≤–ø—Ä–∞–≤–æ), –ø–æ—ç—Ç–æ–º—É —Ç–∞–±–ª–∏—Ü–∞ –±—É–¥–µ—Ç 48 x 4.\n",
    "\n",
    "* **–ó–Ω–∞—á–µ–Ω–∏—è**, —Ö—Ä–∞–Ω—è—â–∏–µ—Å—è **–≤ —ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü–µ**, –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è **¬´Q-values¬ª**.\n",
    "\n",
    "* –≠—Ç–æ –æ—Ü–µ–Ω–∫–∏ —Å—É–º–º—ã –±—É–¥—É—â–∏—Ö –Ω–∞–≥—Ä–∞–¥. –î—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, –æ–Ω–∏ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç, —Å–∫–æ–ª—å–∫–æ –µ—â–µ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –º—ã –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å –¥–æ –∫–æ–Ω—Ü–∞ –∏–≥—Ä—ã, –Ω–∞—Ö–æ–¥—è—Å—å –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ S –∏ –≤—ã–ø–æ–ª–Ω—è—è –¥–µ–π—Å—Ç–≤–∏–µ A.\n",
    "\n",
    "* –ú—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—É —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (–∏–ª–∏ –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –∫–æ–Ω—Å—Ç–∞–Ω—Ç–æ–π, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤—Å–µ–º–∏ –Ω—É–ª—è–º–∏)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è ¬´Q-table¬ª –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –Ω–∞–º –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç—å –ª—É—á—à–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –≤ –∫–∞–∂–¥–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –¥–∞–≤–∞—è –Ω–∞–º –≤ –∏—Ç–æ–≥–µ –ª—É—á—à–∏–π –ø—É—Ç—å –∫ –ø–æ–±–µ–¥–µ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L15/q_table.png\" alt=\"Drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q-learning** ‚Äî —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º, –∫–æ—Ç–æ—Ä—ã–π ¬´–∏–∑—É—á–∞–µ—Ç¬ª —ç—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è. –ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥—É –º—ã –ø–æ–ª—É—á–∞–µ–º –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–∏—Ä–µ. –≠—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Ç–∞–±–ª–∏—Ü–µ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L15/q_learning.gif\" alt=\"Drawing\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Ç–∞–∫, –º—ã –Ω–µ –∑–Ω–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤. –ú—ã –º–æ–∂–µ–º —Ç–æ–ª—å–∫–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –∏ —É—á–∏—Ç—å—Å—è –Ω–∞ –Ω–∏—Ö.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/q_learning_scheme.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ–∑–Ω–∏–∫–∞–µ—Ç –≤–æ–ø—Ä–æ—Å, –∫–∞–∫—É—é –∏–∑ —Ñ—É–Ω–∫—Ü–∏–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞–º –ª—É—á—à–µ –ø—ã—Ç–∞—Ç—å—Å—è —É—á–∏—Ç—å: $V(s)$ –∏–ª–∏ $Q(s,a)$? –ü–æ—Å–∫–æ–ª—å–∫—É $V(s)$ –Ω–µ –ø–æ–∑–≤–æ–ª–∏—Ç –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –ø–æ–ª–∏—Ç–∏–∫—É –±–µ–∑ –∑–Ω–∞–Ω–∏—è $P_{ss'}^a$, –±—É–¥–µ—Ç –≤—ã–≥–æ–¥–Ω–µ–µ —É—á–∏—Ç—å $Q(s,a)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/q_learning_possible_actions.png\" alt=\"Drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É $Q(s, a)$ –Ω—É–ª—è–º–∏\n",
    "\n",
    "* –¶–∏–∫–ª:\n",
    "   * –°–µ–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å $<s, a, r, s^{'}>$ –∏–∑ —Å—Ä–µ–¥—ã\n",
    "   * –í—ã—á–∏—Å–ª–∏—Ç—å $\\hat{Q}(s, a) = r(s,a) + \\gamma Q(s^{'}, a_{i})$\n",
    "   * –û–±–Ω–æ–≤–∏—Ç—å $Q(s,a) \\longleftarrow \\alpha \\hat{Q}(s, a) + (1-\\alpha)Q(s,a)$\n",
    "\n",
    "$\\color{red}\\triangle$ –ú—ã —Ö–æ—Ç–∏–º **–Ω–µ—Å–º–µ—â—ë–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É —Å –º–µ–Ω—å—à–µ–π –¥–∏—Å–ø–µ—Ä–∏—Å–µ–π**, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º **—Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ**.\n",
    "\n",
    "$\\color{red}\\triangle$ **–ü–µ—Ä–µ—Å—á—ë—Ç** —Ñ—É–Ω–∫—Ü–∏–∏ (–ø–æ–ª–µ –≤ —Ç–∞–±–ª–∏—Ü–µ) –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è **–ø–æ—Å–ª–µ –ø–µ—Ä–µ—Ö–æ–¥–∞**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{Q}$ ‚Äî —Ä–∞—Å—á–µ—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, $Q$ ‚Äî —Ç–æ, —á—Ç–æ –±—ã–ª–æ –≤ —Ç–∞–±–ª–∏—Ü–µ, $\\alpha$ —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "–î–∞–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è __Q-learning__, –æ–Ω –Ω–∞–ø—Ä—è–º—É—é –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é $q_*(s,a)$, –∫–æ—Ç–æ—Ä–∞—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É $\\pi_*$. –í –¥–∞–Ω–Ω–æ–º –∞–ª–≥–æ—Ä–∏—Ç–º–µ –æ—Ü–µ–Ω–∫–∞ $Q(s, a)$ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—Ä–∞–≤–∏–ª–∞–º–∏ TD-–æ–±—É—á–µ–Ω–∏—è:\n",
    "\n",
    "$$\\large Q(s,a) := Q(s,a) + \\alpha(R_{ss'}^a+\\gamma\\max_{a'}Q(s',a') -Q(s,a))$$\n",
    "\n",
    "–í–∏–¥–Ω–æ, —á—Ç–æ –∑–∞ —Å—á–µ—Ç –º–∞–∫—Å–∏–º—É–º–∞ Q-learning –±—É–¥–µ—Ç –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä–æ–≤–∞—Ç—å –∏–º–µ–Ω–Ω–æ $q_*(s,a)$, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏ –º—ã –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞–µ–º—Å—è (–∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –±—ã—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä $\\varepsilon$-–∂–∞–¥–Ω–æ–π), –Ω–∞—à –≤–∞—Ä–∏–∞–Ω—Ç Q-learning –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ–≥–æ, —á—Ç–æ –º—ã —Ö–æ—Ç–∏–º –∏–Ω–æ–≥–¥–∞ \"—Ä–∞–Ω–¥–æ–º–∏—Ç—å\". –ö –ø—Ä–∏–º–µ—Ä—É, –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–∏–∂–µ Q-–æ–±—É—á–µ–Ω–∏–µ –±—É–¥–µ—Ç —Å—Ö–æ–¥–∏—Ç—å—Å—è –Ω–µ –∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø–æ–ª–∏—Ç–∏–∫–µ, –∞ –∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ–π. –í —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ –≥—Ä—É–ø–ø–∞ –º–µ—Ç–æ–¥–æ–≤, –ø—Ä–∏ –∫–æ—Ç–æ—Ä—ã—Ö –º—ã –º–æ–∂–µ–º –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞—Ç—å—Å—è –∞–±—Å–æ–ª—é—Ç–Ω–æ –ª—é–±–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –∞ –æ–±—É—á–∞—Ç—å—Å—è –≤—Å–µ —Ä–∞–≤–Ω–æ –±—É–¥—É—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏, –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è __off-policy__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å—Ç—å –∑–∞–¥–∞—á–∏, –≥–¥–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –æ–≥—Ä–æ–º–Ω–æ, –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω—ã–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L15/large_num_of_states.png\" width=\"700\"/><center>\n",
    "\n",
    "<center><em>–û–∫–Ω–æ –∏–≥—Ä—ã Space Invaders</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è $8$-–º–∏–±–∏—Ç–Ω–æ–π —Ü–≤–µ—Ç–Ω–æ–π ($3$ RGB-–∫–∞–Ω–∞–ª–∞) –∏–≥—Ä—ã Space Invaders —Å —Ä–∞–∑–º–µ—Ä–æ–º –∏–≥—Ä–æ–≤–æ–≥–æ –ø–æ–ª—è $210 \\times 160$ –ø–∏–∫—Å–µ–ª–µ–π:\n",
    "\n",
    "$$\\large |S| = 210\\times160\\times2^{8\\times3}$$\n",
    "\n",
    "–í —Ç–∞–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö Q-—Ñ—É–Ω–∫—Ü–∏—é –Ω–µ —Å—á–∏—Ç–∞—é—Ç –≤ —è–≤–Ω–æ–º –≤–∏–¥–µ, –∞ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É—é—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/approximately_q_function_by_network.png\" alt=\"Drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã —Å—á–∏—Ç–∞—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç, –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ Q-—Ñ—É–Ω–∫—Ü–∏–∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –Ω–µ –∑–∞–≤–∏—Å—è—â–∏–º –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞—à–µ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏. –ß—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, –Ω–µ —Ç–∞–∫.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/deep_q_learning_loss.png\" alt=\"Drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-values:\n",
    "$$\n",
    "\\large \\hat{Q}\\left(s_{t}, a_{t}\\right)=r+\\gamma \\cdot \\max _{a^{\\prime}} Q\\left(s_{t+1}, a^{\\prime}\\right)\n",
    "$$\n",
    "Objective:\n",
    "$$\n",
    "\\large L=\\left(Q\\left(s_{t}, a_{t}\\right)-\\left[r+\\gamma \\cdot \\max _{a^{\\prime}} Q\\left(s_{t+1}, a^{\\prime}\\right)\\right]\\right)^{2}\n",
    "$$\n",
    "Gradient step:\n",
    "$$\n",
    "\\large w_{t+1}=w_{t}-\\alpha \\cdot \\frac{\\delta L}{\\delta w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ê–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic deep Q-learning**\n",
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/basic_deep_q_learning_scheme.png\" alt=\"Drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\varepsilon -greedy$ –Ω—É–∂–Ω–∞ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å—Ä–µ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º–∞**:\n",
    "\n",
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L15/information_about_states_is_unevenly_distributed.png\" alt=\"Drawing\" width=\"500\"/></center>\n",
    "\n",
    "<center><em>–û–∫–Ω–∞ –∏–≥—Ä—ã Space Invaders</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –æ–∫—Ä—É–∂–µ–Ω–∏–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –ø–æ–ª—É—á–∞–µ–º–∞—è –∞–≥–µ–Ω—Ç–æ–º, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –Ω–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ. –¢.–µ. –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ —Å–∏–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω—ã –º–µ–∂–¥—É —Å–æ–±–æ–π (—á—Ç–æ –ø–æ–Ω—è—Ç–Ω–æ –∏–∑ –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω—ã—Ö —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ç.–∫. –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –æ–∫—Ä—É–∂–µ–Ω–∏–π, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è RL, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é—Ç, —á—Ç–æ –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –Ω–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã).\n",
    "\n",
    "–ú—ã –º–æ–∂–µ–º —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è —Å —Ç–∞–∫–æ–π –ø—Ä–æ–±–ª–µ–º–æ–π –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏, –µ—Å–ª–∏ –≤ –∏–≥—Ä–µ –µ—Å—Ç—å –±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏ —Ä–µ–¥–∫–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è \"–±–æ—Å—Å—ã\". –ü–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–∏–ø–æ–≤—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –Ω–µ–π—Ä–æ—Å–µ—Ç—å –±—É–¥–µ—Ç –∑–∞–±—ã–≤–∞—Ç—å, –∫–∞–∫ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –±–æ—Å—Å–æ–≤.\n",
    "\n",
    "–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ —É—Ö—É–¥—à–∞–µ—Ç —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –Ω–∞–º –Ω—É–∂–µ–Ω —Å–ø–æ—Å–æ–±, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–ª—É—á—à–∏—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (—É—Å—Ç—Ä–∞–Ω–∏—Ç—å –∏–ª–∏ —Å–Ω–∏–∑–∏—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –º–µ–∂–¥—É –Ω–∏–º–∏)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/experience_replay_scheme.png\" alt=\"Drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ò–¥–µ—è**: —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π $<s,a,r,s^{'}>$.\n",
    "\n",
    "–û–±—É—á–∞—Ç—å –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö –ø–æ–¥–≤—ã–±–æ—Ä–∫–∞—Ö.\n",
    "\n",
    "**–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è**:\n",
    "* –°—ã–≥—Ä–∞—Ç—å 1 —à–∞–≥ –∏ –∑–∞–ø–∏—Å–∞—Ç—å –µ–≥–æ\n",
    "* –í—ã–±—Ä–∞—Ç—å $N$ —Å–ª—É—á–∞–π–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "**Profit**: –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–Ω–æ–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è –≤ —Ç–µ –∂–µ –ø–∞—Ä—ã *—Å–æ—Å—Ç–æ—è–Ω–∏–µ-–¥–µ–π—Å—Ç–≤–∏–µ* $(s,a)$, —á—Ç–æ–±—ã –≤—ã—É—á–∏—Ç—å –∏—Ö.\n",
    "* –ú–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Ö–æ—Ä–æ—à—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é, —Å–¥–µ–ª–∞–≤ –º–µ–Ω—å—à–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π —Å–æ —Å—Ä–µ–¥–æ–π\n",
    "* –ë–æ—Ä–µ–º—Å—è —Å –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏—á–µ—Å–∫–∏–º –∑–∞–±—ã–≤–∞–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "$\\color{red}\\triangle$ **–†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –∞–ª–≥–æ—Ä—Ç–∏–º–∞–º–∏ –±–µ–∑ –ø–æ–ª–∏—Ç–∏–∫.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ—Ç–æ–¥ **–ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏—è –æ–ø—ã—Ç–∞ (experience replay)**. –°—É—Ç—å —ç—Ç–æ–≥–æ –º–µ—Ç–æ–¥–∞ –≤ —Ç–æ–º, —á—Ç–æ –º—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ (—Å–æ—Å—Ç–æ—è–Ω–∏–µ, –¥–µ–π—Å—Ç–≤–∏—è, –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ) –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–º –±—É—Ñ–µ—Ä–µ –∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –º–∏–Ω–∏-–±–∞—Ç—á–∏ –∏–∑ —ç—Ç–æ–≥–æ –±—É—Ñ–µ—Ä–∞.\n",
    "\n",
    "–¢–∞–∫ –∂–µ **experience replay** –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç—É —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–π –ø—Ä–æ—à–ª—ã–π –æ–ø—ã—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í DQN –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–æ–ª–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–≤–µ —Å–µ—Ç–∏: –æ–¥–Ω–∞ –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –æ–±—É—á–∞–µ—Ç—Å—è, –¥—Ä—É–≥–∞—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ü–µ–ª—å (TD target). –ü–æ—á–µ–º—É –º—ã –Ω–µ –º–æ–∂–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –æ–¥–Ω–æ–π –∏ —Ç–æ–π –∂–µ —Å–µ—Ç—å—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ —Ç–µ–∫—É—â–µ–≥–æ $Q(s', a')$ –∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ $Q(s, a)$ —Å–æ—Å—Ç–æ—è–Ω–∏–π?\n",
    "\n",
    "–ù–∞–ø–æ–º–Ω–∏–º, —á—Ç–æ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ TD-–æ–±—É—á–µ–Ω–∏—è –º—ã \"–ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º\" –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –≤ –∫–æ—Ç–æ—Ä–æ–º –º—ã –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–º —à–∞–≥–µ, –∫ –∑–Ω–∞—á–µ–Ω–∏—é —Ñ—É–Ω–∫—Ü–∏–∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –≤ –∫–æ—Ç–æ—Ä–æ–º –º—ã –Ω–∞—Ö–æ–¥–∏–º—Å—è —Å–µ–π—á–∞—Å, –∞ –≤ DQN –º—ã –¥–µ–ª–∞–µ–º —ç—Ç–æ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏, –∏ –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–Ω—É –∏ —Ç—É –∂–µ —Å–µ—Ç—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ $Q(s', a')$ –∏ $Q(s, a)$, —Ç–æ —ç—Ç–æ—Ç –ø—Ä–æ—Ü–µ—Å—Å –º–æ–∂–µ—Ç –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –Ω–µ—Å–∫–æ–Ω—á–∞–µ–º—É—é –ø–æ–≥–æ–Ω—é –∑–∞ —Ü–µ–ª—å—é, –∫–æ—Ç–æ—Ä—É—é –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –¥–æ—Å—Ç–∏—á—å, –ø–æ—Å–∫–æ–ª—å–∫—É —Å –∫–∞–∂–¥—ã–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –≤–µ—Å–æ–≤, –ø—Ä–∏–±–ª–∏–∂–∞—é—â–∏–º –Ω–∞—Å –∫ —Ü–µ–ª–∏, –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ —Å–∞–º–∞ —Ü–µ–ª—å –±—É–¥–µ—Ç —É–¥–∞–ª—è—Ç—å—Å—è –æ—Ç –Ω–∞—Å (–∫–∞–∫ –Ω–∞ —Ä–∏—Å—É–Ω–∫–µ –Ω–∏–∂–µ):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/At_first_everything_look.png\" alt=\"Drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö —Å—á–∞—Å—Ç—å—é, —ç—Ç–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Ä–µ—à–∞–µ–º–∞: –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Ç–∞–∫, —á—Ç–æ–±—ã —Å–µ—Ç—å –æ–±—É—á–∞–ª–∞—Å—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ü–µ–Ω–∫—É $\\max_{a'} Q(s', a')$, –ø–æ–ª—É—á–µ–Ω–Ω—É—é –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤ Q-—Å–µ—Ç–∏. –î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç __—Ü–µ–ª–µ–≤—É—é —Å–µ—Ç—å__ (target network) —Å –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏, –æ–±–Ω–æ–≤–ª—è–µ–º—ã–º–∏ —Ä–∞–∑ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–ø–∏–∑–æ–¥–æ–≤ –æ–±—É—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, —ç–ø–æ—Ö –∏–ª–∏ –∏–≥—Ä–æ–≤—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤, –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∏–≥—Ä–æ–≤–æ–≥–æ —ç–ø–∏–∑–æ–¥–∞)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/Suppose_we_freeze.png\" alt=\"Drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –±—É–¥—É—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –¥–≤–µ —Å–µ—Ç–∏, –æ–¥–Ω–∞ –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å –∑–∞ –≤—ã–±–æ—Ä –¥–µ–π—Å—Ç–≤–∏—è, –¥—Ä—É–≥–∞—è ‚Äî –∑–∞ —Ü–µ–ª–µ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é, –æ–¥–Ω–∞ –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è —Å –æ—Ç—Å—Ç–∞–≤–∞–Ω–∏–µ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L15/out/DQN-Loss_.png\" alt=\"Drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–∏–º–µ—Ä c CartPole DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–µ—Ç—å Deep Q = DQN (Deep Q-Network).\n",
    "\n",
    "Cartpole &mdash; –ø–µ—Ä–µ–≤–µ—Ä–Ω—É—Ç—ã–π –º–∞—è—Ç–Ω–∏–∫ —Å —Ü–µ–Ω—Ç—Ä–æ–º —Ç—è–∂–µ—Å—Ç–∏ –Ω–∞–¥ —Å–≤–æ–µ–π —Ç–æ—á–∫–æ–π –ø–æ–≤–æ—Ä–æ—Ç–∞. –û–Ω –Ω–µ—Å—Ç–∞–±–∏–ª–µ–Ω, –Ω–æ –µ–≥–æ –º–æ–∂–Ω–æ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å, –ø–µ—Ä–µ–º–µ—â–∞—è —Ç–æ—á–∫—É –ø–æ–≤–æ—Ä–æ—Ç–∞ –ø–æ–¥ —Ü–µ–Ω—Ç—Ä–æ–º –º–∞—Å—Å—ã. –¶–µ–ª—å —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∞–≤–Ω–æ–≤–µ—Å–∏–µ, –ø—Ä–∏–∫–ª–∞–¥—ã–≤–∞—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —É—Å–∏–ª–∏—è –∫ —Ç–æ—á–∫–µ –ø–æ–≤–æ—Ä–æ—Ç–∞.\n",
    "\n",
    "–î—Ä—É–≥–æ–π env –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–µ–∑ –∫–∞–∫–∏—Ö-–ª–∏–±–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π –∫–æ–¥–∞. –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –µ–¥–∏–Ω—ã–º –≤–µ–∫—Ç–æ—Ä–æ–º, –¥–µ–π—Å—Ç–≤–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–º–∏.\n",
    "\n",
    "CartPole &mdash; —Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π. –ù–∞ –µ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —É–π—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.\n",
    "\n",
    "–î–ª—è LunarLander –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è 1-2 —á–∞—Å–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å 200 –±–∞–ª–ª–æ–≤ (—Ö–æ—Ä–æ—à–∏–π –±–∞–ª–ª) –≤ Colab, –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ –≤—ã–≥–ª—è–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "################################################\n",
    "# For CartPole\n",
    "################################################\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/atari_wrappers.py\n",
    "!wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/utils.py\n",
    "!wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/replay_buffer.py\n",
    "!wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/framebuffer.py\n",
    "\n",
    "!pip install swig\n",
    "!pip install gym[box2d]\n",
    "\n",
    "!touch .setup_complete\n",
    "\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ[\"DISPLAY\"] = \":1\"\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "ENV_NAME = \"CartPole-v1\"\n",
    "\n",
    "\n",
    "def make_env(seed=None):\n",
    "    # some envs are wrapped with a time limit wrapper by default\n",
    "    env = gym.make(ENV_NAME, render_mode=\"rgb_array\", new_step_api=True).unwrapped\n",
    "    if seed is not None:\n",
    "        env.seed(seed)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "env = make_env()\n",
    "env.reset()\n",
    "env_img = np.squeeze(env.render())\n",
    "clear_output()\n",
    "plt.imshow(env_img)\n",
    "state_shape, n_actions = env.observation_space.shape, env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω–∞–º –Ω—É–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è—Ç—å –Ω–∞–±–ª—é–¥–µ–Ω–∏—è —Å —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º q-–∑–Ω–∞—á–µ–Ω–∏–π.\n",
    "\n",
    "–ú–æ–¥–µ–ª—å –Ω–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ–π: 1-2 —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è —Å < 200 –Ω–µ–π—Ä–æ–Ω–∞–º–∏ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π ReLU, –≤–µ—Ä–æ—è—Ç–Ω–æ, –±—É–¥–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.\n",
    "\n",
    "Batch normalization –∏ dropout –º–æ–≥—É—Ç –≤—Å–µ –∏—Å–ø–æ—Ä—Ç–∏—Ç—å, –ø–æ—ç—Ç–æ–º—É –∏—Ö –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# those who have a GPU but feel unfair to use it can uncomment:\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "print(state_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class DQNAgent(nn.Module):\n",
    "    def __init__(self, state_shape, n_actions, epsilon=0):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.n_actions = n_actions\n",
    "        self.state_shape = state_shape\n",
    "        # Define your network body here. Please make sure agent is fully contained here\n",
    "        assert len(state_shape) == 1\n",
    "        state_dim = state_shape[0]\n",
    "\n",
    "        # Define NN\n",
    "        ##############################################\n",
    "        hidden_size = 150\n",
    "        self._nn = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        ##############################################\n",
    "\n",
    "    def forward(self, state_t):\n",
    "        \"\"\"\n",
    "        takes agent's observation (tensor), returns qvalues (tensor)\n",
    "        :param state_t: a batch states, shape = [batch_size, *state_dim=4]\n",
    "        \"\"\"\n",
    "        # Use your network to compute qvalues for given state\n",
    "\n",
    "        ##############################################\n",
    "        qvalues = self._nn(state_t)\n",
    "        ##############################################\n",
    "\n",
    "        assert qvalues.requires_grad, \"qvalues must be a torch tensor with grad\"\n",
    "        assert (\n",
    "            len(qvalues.shape) == 2\n",
    "            and qvalues.shape[0] == state_t.shape[0]\n",
    "            and qvalues.shape[1] == n_actions\n",
    "        )\n",
    "\n",
    "        return qvalues\n",
    "\n",
    "    def get_qvalues(self, states):\n",
    "        \"\"\"\n",
    "        like forward, but works on numpy arrays, not tensors\n",
    "        \"\"\"\n",
    "        model_device = next(self.parameters()).device\n",
    "        states = torch.tensor(states, device=model_device, dtype=torch.float32)\n",
    "        qvalues = self.forward(states)\n",
    "        return qvalues.data.cpu().numpy()\n",
    "\n",
    "    def sample_actions(self, qvalues):\n",
    "        \"\"\"pick actions given qvalues. Uses epsilon-greedy exploration strategy.\"\"\"\n",
    "        epsilon = self.epsilon\n",
    "        batch_size, n_actions = qvalues.shape\n",
    "\n",
    "        random_actions = np.random.choice(n_actions, size=batch_size)\n",
    "        best_actions = qvalues.argmax(axis=-1)\n",
    "\n",
    "        should_explore = np.random.choice([0, 1], batch_size, p=[1 - epsilon, epsilon])\n",
    "        return np.where(should_explore, random_actions, best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(state_shape, n_actions, epsilon=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(env, agent, n_games=1, greedy=False, t_max=10000):\n",
    "    \"\"\"Plays n_games full games. If greedy, picks actions as argmax(qvalues). Returns mean reward.\"\"\"\n",
    "    rewards = []\n",
    "    for _ in range(n_games):\n",
    "        s = env.reset()\n",
    "        reward = 0\n",
    "        for _ in range(t_max):\n",
    "            qvalues = agent.get_qvalues([s])\n",
    "            action = (\n",
    "                qvalues.argmax(axis=-1)[0]\n",
    "                if greedy\n",
    "                else agent.sample_actions(qvalues)[0]\n",
    "            )\n",
    "            s, r, done, _, _ = env.step(action)\n",
    "            reward += r\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        rewards.append(reward)\n",
    "    return np.mean(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience Replay Buffer and Target Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–æ–≤–æ–ª—å–Ω–æ –ø—Ä–æ—Å—Ç:**\n",
    "\n",
    "* `exp_replay.add(obs, act, rw, next_obs, done)` ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç (s,a,r,s',done) –∫–æ—Ä—Ç–µ–∂ –≤ –±—É—Ñ—Ñ–µ—Ä\n",
    "* `exp_replay.sample(batch_size)` ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç observations, actions, rewards, next_observations –∏ is_done –¥–ª—è `batch_size` random samples.\n",
    "* `len(exp_replay)` ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —Ö—Ä–∞–Ω—è—â–∏—Ö—Å—è –≤ replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay_buffer import ReplayBuffer\n",
    "\n",
    "exp_replay = ReplayBuffer(2000)\n",
    "\n",
    "\n",
    "target_network = DQNAgent(agent.state_shape, agent.n_actions, epsilon=0.5).to(device)\n",
    "# This is how you can load weights from agent into target network\n",
    "target_network.load_state_dict(agent.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD-Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã—á–∏—Å–ª–∏–º –æ—à–∏–±–∫—É TD Q-learning:\n",
    "\n",
    "$$ \\large L = { 1 \\over N} \\sum_i [ Q_{\\theta}(s,a) - Q_{reference}(s,a) ] ^2 $$\n",
    "\n",
    "–° Q-reference –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º –∫–∞–∫\n",
    "\n",
    "$$ \\large Q_{reference}(s,a) = r(s,a) + \\gamma \\cdot max_{a'} Q_{target}(s', a') $$\n",
    "\n",
    "–≥–¥–µ\n",
    "* $Q_{target}(s',a')$ –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç $Q$-–∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è  __target_network__\n",
    "* $s, a, r, s'$ ‚Äî —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –¥–µ–π—Å—Ç–≤–∏–µ, –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ –∏ —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ\n",
    "* $\\gamma$ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º –¥–≤—É–º—è —è—á–µ–π–∫–∞–º–∏ –≤—ã—à–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_td_loss(\n",
    "    states,\n",
    "    actions,\n",
    "    rewards,\n",
    "    next_states,\n",
    "    is_done,\n",
    "    agent,\n",
    "    target_network,\n",
    "    gamma=0.99,\n",
    "    check_shapes=False,\n",
    "    device=device,\n",
    "):\n",
    "    \"\"\"Compute td loss using torch operations only. Use the formulae above.\"\"\"\n",
    "    states = torch.tensor(\n",
    "        states, device=device, dtype=torch.float32\n",
    "    )  # shape: [batch_size, *state_shape]\n",
    "    actions = torch.tensor(\n",
    "        actions, device=device, dtype=torch.int64\n",
    "    )  # shape: [batch_size]\n",
    "    rewards = torch.tensor(\n",
    "        rewards, device=device, dtype=torch.float32\n",
    "    )  # shape: [batch_size]\n",
    "    # shape: [batch_size, *state_shape]\n",
    "    next_states = torch.tensor(next_states, device=device, dtype=torch.float)\n",
    "    is_done = torch.tensor(\n",
    "        is_done.astype(\"float32\"),\n",
    "        device=device,\n",
    "        dtype=torch.float32,\n",
    "    )  # shape: [batch_size]\n",
    "    is_not_done = 1 - is_done\n",
    "\n",
    "    # get q-values for all actions in current states\n",
    "    predicted_qvalues = agent(states)  # shape: [batch_size, n_actions]\n",
    "\n",
    "    # compute q-values for all actions in next states\n",
    "    # with torch.no_grad():\n",
    "    predicted_next_qvalues = target_network(\n",
    "        next_states\n",
    "    )  # shape: [batch_size, n_actions]\n",
    "\n",
    "    # select q-values for chosen actions\n",
    "    predicted_qvalues_for_actions = predicted_qvalues[\n",
    "        range(len(actions)), actions\n",
    "    ]  # shape: [batch_size]\n",
    "\n",
    "    # compute V*(next_states) using predicted next q-values\n",
    "    ##############################################\n",
    "    next_state_values = predicted_next_qvalues.max(axis=-1)[0]\n",
    "    ##############################################\n",
    "\n",
    "    assert (\n",
    "        next_state_values.dim() == 1 and next_state_values.shape[0] == states.shape[0]\n",
    "    ), \"must predict one value per state\"\n",
    "\n",
    "    # compute \"target q-values\" for loss - it's what's inside square parentheses in the above formula.\n",
    "    # at the last state use the simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
    "    # you can multiply next state values by is_not_done to achieve this.\n",
    "    ###############################################\n",
    "    target_qvalues_for_actions = rewards + gamma * next_state_values * is_not_done\n",
    "    ##############################################\n",
    "\n",
    "    # mean squared error loss to minimize\n",
    "    loss = torch.mean(\n",
    "        (predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2\n",
    "    )\n",
    "\n",
    "    if check_shapes:\n",
    "        assert (\n",
    "            predicted_next_qvalues.data.dim() == 2\n",
    "        ), \"make sure you predicted q-values for all actions in next state\"\n",
    "        assert (\n",
    "            next_state_values.data.dim() == 1\n",
    "        ), \"make sure you computed V(s') as maximum over just the actions axis and not all axes\"\n",
    "        assert (\n",
    "            target_qvalues_for_actions.data.dim() == 1\n",
    "        ), \"there's something wrong with target q-values, they must be a vector\"\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# your favourite random seed\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "env = make_env()\n",
    "env.reset(seed=seed)\n",
    "state_dim = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "state = env.reset()\n",
    "\n",
    "agent = DQNAgent(state_dim, n_actions, epsilon=1).to(device)\n",
    "target_network = DQNAgent(state_dim, n_actions, epsilon=1).to(device)\n",
    "target_network.load_state_dict(agent.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–∏–Ω –∞–≥–µ–Ω—Ç –¥–ª—è –∏–≥—Ä—ã, –≤—Ç–æ—Ä–æ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –≤–µ—Å–∞ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –∫–æ–ø–∏—Ä—É—é—Ç—Å—è –≤ \"–∏–≥—Ä–æ–∫–∞\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_and_record(initial_state, agent, env, exp_replay, n_steps=1):\n",
    "    \"\"\"\n",
    "    Play the game for exactly n_steps, record every (s,a,r,s', done) to replay buffer.\n",
    "    Whenever game ends, add record with done=True and reset the game.\n",
    "    It is guaranteed that env has done=False when passed to this function.\n",
    "\n",
    "    PLEASE DO NOT RESET ENV UNLESS IT IS \"DONE\"\n",
    "\n",
    "    :returns: return sum of rewards over time and the state in which the env stays\n",
    "\n",
    "    hint: use agent.sample.actions\n",
    "    \"\"\"\n",
    "    s = initial_state\n",
    "    sum_rewards = 0\n",
    "\n",
    "    # Play the game for n_steps as per instructions above\n",
    "    for _ in range(n_steps):\n",
    "        qvalues = agent.get_qvalues([s])\n",
    "\n",
    "        action = agent.sample_actions(qvalues)[0]\n",
    "        # action = action.argmax(axis=-1)[0]\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        sum_rewards += reward\n",
    "\n",
    "        exp_replay.add(s, action, reward, state, done)\n",
    "\n",
    "        if done:\n",
    "            state = env.reset()\n",
    "\n",
    "        s = state\n",
    "\n",
    "    return sum_rewards, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "REPLAY_BUFFER_SIZE = 10**4\n",
    "\n",
    "exp_replay = ReplayBuffer(REPLAY_BUFFER_SIZE)\n",
    "for i in range(100):\n",
    "    if not utils.is_enough_ram(min_available_gb=0.1):\n",
    "        print(\n",
    "            \"\"\"\n",
    "            Less than 100 Mb RAM available.\n",
    "            Make sure the buffer size in not too huge.\n",
    "            Also check, maybe other processes consume RAM heavily.\n",
    "            \"\"\"\n",
    "        )\n",
    "        break\n",
    "    play_and_record(state, agent, env, exp_replay, n_steps=10**2)\n",
    "    if len(exp_replay) == REPLAY_BUFFER_SIZE:\n",
    "        break\n",
    "print(len(exp_replay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "timesteps_per_epoch = 1\n",
    "batch_size = 32\n",
    "total_steps = 4 * 10**4\n",
    "decay_steps = 1 * 10**4\n",
    "\n",
    "optimizer = torch.optim.Adam(agent.parameters(), lr=1e-4)\n",
    "\n",
    "init_epsilon = 1\n",
    "final_epsilon = 0.1\n",
    "\n",
    "loss_freq = 20\n",
    "refresh_target_network_freq = 100\n",
    "eval_freq = 1000\n",
    "\n",
    "max_grad_norm = 5000\n",
    "\n",
    "mean_rw_history = []\n",
    "td_loss_history = []\n",
    "grad_norm_history = []\n",
    "initial_state_v_history = []\n",
    "step = 0\n",
    "\n",
    "\n",
    "def wait_for_keyboard_interrupt():\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "state = env.reset()\n",
    "with trange(step, total_steps + 1) as progress_bar:\n",
    "    for step in progress_bar:\n",
    "        if not utils.is_enough_ram():\n",
    "            print(\"less that 100 Mb RAM available, freezing\")\n",
    "            print(\"make sure everything is ok and use KeyboardInterrupt to continue\")\n",
    "            wait_for_keyboard_interrupt()\n",
    "\n",
    "        agent.epsilon = utils.linear_decay(\n",
    "            init_epsilon, final_epsilon, step, decay_steps\n",
    "        )\n",
    "\n",
    "        # play\n",
    "        _, state = play_and_record(state, agent, env, exp_replay, timesteps_per_epoch)\n",
    "\n",
    "        # train\n",
    "        # sample batch_size of data from experience replay\n",
    "        s, a, r, next_s, is_done = exp_replay.sample(batch_size)\n",
    "        # loss = compute TD loss\n",
    "        loss = compute_td_loss(s, a, r, next_s, is_done, agent, target_network)\n",
    "\n",
    "        loss.backward()\n",
    "        grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step % loss_freq == 0:\n",
    "            td_loss_history.append(loss.data.cpu().item())\n",
    "            grad_norm_history.append(grad_norm.data.cpu().item())\n",
    "\n",
    "        if step % refresh_target_network_freq == 0:\n",
    "            # Load agent weights into target_network\n",
    "            target_network.load_state_dict(agent.state_dict())\n",
    "\n",
    "        if step % eval_freq == 0:\n",
    "            mean_rw_history.append(\n",
    "                evaluate(make_env(seed=step), agent, n_games=3, greedy=True, t_max=1000)\n",
    "            )\n",
    "            initial_state_q_values = agent.get_qvalues([make_env(seed=step).reset()])\n",
    "            initial_state_v_history.append(np.max(initial_state_q_values))\n",
    "\n",
    "            clear_output(True)\n",
    "            print(\"buffer size = %i, epsilon = %.5f\" % (len(exp_replay), agent.epsilon))\n",
    "\n",
    "            plt.figure(figsize=[16, 9])\n",
    "\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.title(\"Mean reward per episode\")\n",
    "            plt.plot(mean_rw_history)\n",
    "            plt.grid()\n",
    "\n",
    "            assert not np.isnan(td_loss_history[-1])\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.title(\"TD loss history (smoothened)\")\n",
    "            plt.plot(utils.smoothen(td_loss_history))\n",
    "            plt.grid()\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.title(\"Initial state V\")\n",
    "            plt.plot(initial_state_v_history)\n",
    "            plt.grid()\n",
    "\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.title(\"Grad norm history (smoothened)\")\n",
    "            plt.plot(utils.smoothen(grad_norm_history))\n",
    "            plt.grid()\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = evaluate(make_env(), agent, n_games=30, greedy=True, t_max=1000)\n",
    "print(\"final score:\", final_score)\n",
    "if final_score > 300:\n",
    "    print(\"Well done\")\n",
    "else:\n",
    "    print(\"not good enough for DQN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SARSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∏–ª–∏ —É–¥–∞–ª–∏—Ç—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning with human feedback (RLHF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –∏–∑ —Ç–∏–∫–µ—Ç-–≤–µ—Ç–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://fls.avasiliev.xyz/repo/EduNet-content/dev-2.0/L15/out/RLHF.jpg\" width=\"850\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, –∫–∞–∫ –º–∞—Ä–∫–æ–≤—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≤ –∑–∞–¥–∞—á–µ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–∞–π–ø–ª–∞–π–Ω RLHF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–º–µ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏–µ reward-—Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Rl –∞–ª–≥–æ—Ä–∏—Ç–º–∞ PPO –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ –∫–∞–∂–¥–æ–º –∏–∑ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ —Å–∏–≥–Ω–∞–ª–∞ –æ—Ç PPO –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
