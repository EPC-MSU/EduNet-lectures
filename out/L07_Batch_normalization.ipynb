{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Улучшение сходимости нейросетей и борьба с переобучением</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сигмоида затухает и теоретически и практически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на практике, загрузим данные, создадим сеть, обучим ее и посмотрим, как проходит обучение. \n",
    "\n",
    "Загрузим датасет MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# transforms for data\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "train_set = MNIST(root='./MNIST', train=True, download=True, transform=transform)\n",
    "test_set = MNIST(root='./MNIST', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "clear_output()\n",
    "print(\"Already downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим сеть с сигмоидой в качестве функции активации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleMNIST_NN(nn.Module):\n",
    "    def __init__(self, n_layers, activation=nn.Sigmoid):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers # Num of layers\n",
    "        self.activation = activation()\n",
    "        layers = [nn.Linear(28 * 28, 100), self.activation] # input layer\n",
    "        for _ in range(n_layers - 1): # append num of layers\n",
    "            layers.append(nn.Linear(100, 100))\n",
    "            layers.append(self.activation)\n",
    "        layers.append(nn.Linear(100, 10)) # 10 classes\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28) # reshape to [-1, 784]\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для визуализации результатов обучения моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(scalars, weight):  \n",
    "    last = scalars[0]  \n",
    "    smoothed = []\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  \n",
    "        smoothed.append(smoothed_val)                        \n",
    "        last = smoothed_val                                 \n",
    "\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_history(history, n_epochs=5, smooth_val=0.90):\n",
    "    fig, ax =  plt.subplots(3, 1, figsize=(12, 14))\n",
    "    for stage_idx, (stage_lbl, stage_title) in enumerate(\n",
    "        zip(['loss_on_train', 'loss_on_test'],\n",
    "            ['train loss', 'test loss'])):\n",
    "        # plot history on each learning step\n",
    "        epoch_len = len(history[stage_lbl])//n_epochs\n",
    "        full_stage_len = len(history[stage_lbl])\n",
    "        ax[stage_idx].plot(exponential_smoothing(history[stage_lbl], smooth_val),\n",
    "                           label='smoothed',\n",
    "                           color='m')\n",
    "        ax[stage_idx].plot(history[stage_lbl],\n",
    "                           label='raw',\n",
    "                           alpha=0.2,\n",
    "                           color='c')\n",
    "        ax[stage_idx].set_title(stage_title)\n",
    "        ax[stage_idx].set_xlabel('epochs')\n",
    "        ax[stage_idx].set_ylabel('loss')\n",
    "        epochs_ticks_positions = np.arange(stop=full_stage_len+1,\n",
    "                                           step=epoch_len)\n",
    "        ax[stage_idx].set_xticks(epochs_ticks_positions)\n",
    "        ax[stage_idx].set_xticklabels(np.arange(n_epochs+1))\n",
    "        ax[stage_idx].legend()\n",
    "\n",
    "        # plot mean train and test loss combined\n",
    "        mean_loss_on_epoch = [np.mean(history[stage_lbl][i:i+epoch_len]) \\\n",
    "                              for i in range(0, full_stage_len, epoch_len)]\n",
    "        std_loss_on_epoch = [np.std(history[stage_lbl][i:i+epoch_len]) \\\n",
    "                              for i in range(0, full_stage_len, epoch_len)]\n",
    "\n",
    "        ax[2].set_title('\\nAverage loss per epoch')\n",
    "        ax[2].errorbar(np.arange(n_epochs) + stage_idx / 30.,\n",
    "                       mean_loss_on_epoch,\n",
    "                       yerr=std_loss_on_epoch,\n",
    "                       capsize=5,\n",
    "                       fmt=\"X--\",\n",
    "                       label=stage_title)\n",
    "        ax[2].set_xticks(np.arange(5))\n",
    "        ax[2].set_xticklabels(np.arange(5))\n",
    "        ax[2].set_xlabel('epochs')\n",
    "        ax[2].set_ylabel('loss')\n",
    "        ax[2].legend()\n",
    "\n",
    "    fig.suptitle(history['model_name'], fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения сети на обучающей выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# compute on cpu or gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_epoch(model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                train_loader):\n",
    "    loss_history = []\n",
    "    for batch in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        x_train, y_train = batch # parse data\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "        y_pred = model(x_train) # get predictions\n",
    "        loss = criterion(y_pred, y_train) # compute loss\n",
    "        loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для валидации сети на валидационной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,\n",
    "             criterion,\n",
    "             val_loader):\n",
    "    cumloss = 0\n",
    "    loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_train, y_train = batch # parse data\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "            y_pred = model(x_train) # get predictions\n",
    "            loss = criterion(y_pred, y_train) # compute loss\n",
    "            loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
    "            cumloss += loss\n",
    "    return cumloss / len(val_loader), loss_history # mean loss and history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, optimizer, model_name=None, n_epochs=5):\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history['model_name'] = model_name\n",
    "    train_history['loss_on_train'] = []\n",
    "    train_history['loss_on_test'] = []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        loss_on_train = train_epoch(model,\n",
    "                                    optimizer,\n",
    "                                    criterion,\n",
    "                                    train_loader)\n",
    "        _, loss_on_test = validate(model,\n",
    "                                   criterion,\n",
    "                                   test_loader)\n",
    "        train_history['loss_on_train'].extend(loss_on_train)\n",
    "        train_history['loss_on_test'].extend(loss_on_test)\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим и запустим обучение модели с двумя слоями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = SimpleMNIST_NN(n_layers=2).to(device) \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "history = train_model(model, optimizer, model_name='n_layers2_sigmoid')\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN(n_layers=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "history = train_model(model, optimizer, model_name='n_layers3_sigmoid')\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросеть с тремя слоями вообще не учится. Почему? Можем попробовать разобраться.\n",
    "\n",
    "Для этого напишем функции, которые будут следить за распределением градиентов и активаций на наших слоях.\n",
    "\n",
    "И скажем при помощи метода register_backward_hook пайторчу исполнять эти функции при каждом пропускании градиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_forward_hook(history_dict, key):\n",
    "\n",
    "    def forward_hook(self, input_, output):\n",
    "        history_dict[key].append(input_[0].abs().mean().cpu().detach().numpy())\n",
    "    return forward_hook\n",
    "\n",
    "\n",
    "def get_backward_hook(history_dict, key):\n",
    "\n",
    "    def backward_hook(grad):  # for tensors\n",
    "        history_dict[key].append(grad.abs().mean().cpu().detach().numpy())\n",
    "    return backward_hook\n",
    "\n",
    "def register_model_hooks(model, max_ind=4):\n",
    "    cur_ind = 0\n",
    "    hooks_data_history = defaultdict(list)\n",
    "    for child in model.layers.children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            cur_ind += 1\n",
    "            forward_hook = get_forward_hook(hooks_data_history,\n",
    "                                            f\"activation_{cur_ind}\")\n",
    "            child.register_forward_hook(forward_hook)\n",
    "\n",
    "            backward_hook = get_backward_hook(hooks_data_history,\n",
    "                                              f\"gradient_{max_ind - cur_ind + 1}\")\n",
    "            child.weight.register_hook(backward_hook)\n",
    "    return hooks_data_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим обучение модели с 3 слоями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN(n_layers=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "\n",
    "history = train_model(model, optimizer, model_name=\"n_layers3_sigmoid2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hooks_data(hooks_data_history, smooth_val=0.85):\n",
    "    keys = hooks_data_history.keys()\n",
    "    n_layers = len(keys) // 2\n",
    "    fig, ax = plt.subplots(2, n_layers, figsize=(12, 12), sharey='row')\n",
    "    for layer_idx in range(n_layers):\n",
    "        \n",
    "        smoothed_values = exponential_smoothing(hooks_data_history[f'activation_{layer_idx + 1}'],\n",
    "                                                smooth_val) \n",
    "        ax[0, layer_idx].plot(smoothed_values)\n",
    "        ax[0, layer_idx].set_title(f'activation_{layer_idx + 1}')\n",
    "        ax[0, layer_idx].set_ylim([0, 1])\n",
    "\n",
    "        smoothed_values = exponential_smoothing(hooks_data_history[f'gradient_{layer_idx + 1}'],\n",
    "                                                smooth_val) \n",
    "        scale_transform = lambda x : np.array(x) * 1.e5 + 1\n",
    "        ax[1, layer_idx].plot(scale_transform(smoothed_values))\n",
    "        ax[1, layer_idx].set_title(f'gradient_{layer_idx + 1}')\n",
    "        ax[1, layer_idx].set_yscale('log')\n",
    "    ax[0,0].set_ylabel('value')\n",
    "    ax[1,0].set_ylabel(r'value $\\times$ $10^5 + 1$')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_data(hooks_data_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что градиент нашей модели стремительно затухает. Первые слои (до которых градиент доходит последним), получают значения градиента, мало отличимые от нуля.\n",
    "\n",
    "Причем, это будет верно с самых первых шагов обучения нашей модели\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это явление получило название **паралич сети**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Затухание градиента\n",
    "\n",
    "Откуда оно берется? \n",
    "\n",
    "Посмотрим на обычную сигмоиду\n",
    "\n",
    "$$\\sigma(z) = \\dfrac 1 {1 + e^{-z}}$$\n",
    "\n",
    "Ее производная, как вы уже выводили, равна\n",
    "\n",
    "$$\\dfrac {\\delta \\sigma(z)} {\\delta z} = \\sigma(z) (1 - \\sigma(z))$$\n",
    "\n",
    "Какое максимальное значение у такой функции?\n",
    "\n",
    "Учтем, что сигмоида находится в пределах от 0 до 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "x = np.arange(0, 1.001, 0.001)\n",
    "plt.plot(x, x - x**2)\n",
    "plt.title('Derivative of the sigmoidal function', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что максимальное значение производной по сигмоиде - 1/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь возьмем простую нейронную сеть "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/simple_nn_with_sigmoid.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем у нее градиент\n",
    "\n",
    "$$\\dfrac {\\delta L} {\\delta z_4} = \\dfrac {\\delta L} {\\delta y} \\dfrac {\\delta y} {\\delta z_4} = \\dfrac {\\delta L} {\\delta y} \\dfrac {\\delta \\sigma(w_5z)} {\\delta z} w_5 \\le \\dfrac 1 4 \\dfrac {\\delta L} {\\delta y}  w_5 $$\n",
    "\n",
    "Аналогично можно посчитать градиент для $z_3$\n",
    "\n",
    "$$\\dfrac {\\delta L} {\\delta z_3} = \\dfrac {\\delta L} {\\delta z_4} \\dfrac {\\delta z_4} {\\delta z_3} \\le \\dfrac {\\delta L} {\\delta y} \\dfrac {\\delta \\sigma(w_4z)} {\\delta z} w_5 \\le \\left({\\dfrac 1 4}\\right)^2 \\dfrac {\\delta L} {\\delta y}  w_5 w_4$$\n",
    "\n",
    "И так далее\n",
    "\n",
    "$$\\dfrac {\\delta L} {\\delta x}  \\le \\left({\\dfrac 1 4}\\right)^5 \\dfrac {\\delta L} {\\delta y}  w_5 w_4 w_3 w_2 w_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, градиент начинает экспоненциально затухать, если веса маленькие.\n",
    "\n",
    "Если веса большие - то градиент наоборот начнет экспоненциально возрастать - все взорвется\n",
    "\n",
    "Для некоторых функций активации картина будет не столь катастрофична, но тоже неприятна.\n",
    "\n",
    "При выполнении заданий вы посмотрите, например, как ведет себя функция ReLU в этом случае."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициализация весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из способов борьбы с затухающим градиентом является правильная инициализация весов. Как это сделать?\n",
    "\n",
    "**Идея 1:** инициализировать все веса константой. \n",
    "\n",
    "Проблема: градиент во всем весам будет одинаков, как и обновление весов. Все нейроны в слое будут учить одно и то же, или, в случае $const = 0$, [не будут учиться вообще](https://habr.com/ru/post/592711/).\n",
    "\n",
    "\n",
    "Вывод: в качестве начальных весов нужно выбирать различные значения.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Идея 2:** инициализировать веса нормальным (Гауссовским) шумом с матожиданием 0 и маленькой дисперсией. \n",
    "\n",
    "Маленькая дисперсия нужна, чтобы не получить огромные градиенты за большие изначальные ошибки в предсказании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal distribution: mu = 0, sigma = 1\n",
    "\n",
    "x = np.arange(-4, 4.1, 0.1)\n",
    "y = np.exp(-np.square(x)/2) / np.sqrt(2*np.pi)\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.title('Normal distribution: mu = 0, sigma = 1', size=15)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема: инициализация нормальным шумом не гарантирует отсутствие взрыва или затухания градиета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Идея 3:** формализуем условия при которых не будет происходить взрыв градиентов.\n",
    "\n",
    "Нам бы хотелось, чтобы \n",
    "дисперсии признаков, получаемых на каждом слое были бы одинаковы: \n",
    "\n",
    "$$Dz^i = Dz^j. \\tag{1}$$\n",
    "\n",
    "И чтобы  начальные дисперсии градиентов для разных слоев были бы одинаковы:\n",
    " \n",
    "$$D\\dfrac {\\delta L} {\\delta z^i} = D\\dfrac {\\delta L} {\\delta z^j}. \\tag{2}$$\n",
    "\n",
    "При выполнении этих условий градиент не затухает и не взрывается.\n",
    "\n",
    "Попытаемся выполнить эти условия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация Ксавьера (Xavier Glorot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод Xavier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим функцию активации гиперболический тангенс (tanh).\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/simple_nn_with_tanh.png\" width=\"600\">\n",
    "\n",
    "Это - [нечетная функция](https://ru.wikipedia.org/wiki/%D0%A7%D1%91%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%B8) с единичной производной в нуле. Функция и ее производная изображены ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10, 10.1, 0.1)\n",
    "y = np.tanh(x)\n",
    "dy = 1 / np.cosh(x)\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig, (im1, im2) = plt.subplots(2, 1, figsize=(7, 7))\n",
    "im1.set(title = \"tanh(x)\")\n",
    "im1.plot(x[0:51], y[0:51], 'r', x[50:96], y[50:96], 'b', \n",
    "         x[95:106], y[95:106], 'g', x[105:151], y[105:151], 'b', \n",
    "         x[150:201], y[150:201], 'r') \n",
    "im2.set(title = \"tanh'(x)\")\n",
    "im2.plot(x[0:51], dy[0:51], 'r', x[50:96], dy[50:96], 'b',\n",
    "         x[95:106], dy[95:106], 'g', x[105:151], dy[105:151], 'b',\n",
    "         x[150:201], dy[150:201], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При выборе весов нам важно не попасть в красные зоны с почти нулевой производной, т.к. в этих областях градиент затухает. Мы хотим инициализировать веса таким образом, чтобы признаки, поступающие на слой активации, находились в зеленой области в окрестности нуля. Матожидание признаков, поступающих на слой активации, будет равно нулю\n",
    "$$E(z^i_t w_{kt})=0 \\tag{3}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выход слоя активации на текущем слое будет зависеть от выхода слоя активации на предыдущем: $$z^{i+1} = f(z^iW^i). \\tag{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В окрестности нуля функцию гиперболический тангенс можно считать [линейной](https://ru.wikipedia.org/wiki/%D0%A0%D1%8F%D0%B4_%D0%A2%D0%B5%D0%B9%D0%BB%D0%BE%D1%80%D0%B0):\n",
    "$$z^{i+1} \\approx z^i W^i \\tag{5}.$$\n",
    "Матожидаение выхода функции активации также равно нулю:\n",
    "$$E(z^i_t)=0 \\tag{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения весов в слоях будут генерироваться генератором случайных чисел, поэтому веса в различных слоях можно считать независимыми случайными величинами. Для независимых случайных величин выполняются формулы: \n",
    "1. Дисперсии суммы двух независимых величин:\n",
    "\n",
    "$$D(\\eta + \\gamma) = D\\eta + D\\gamma \\tag{7}.$$\n",
    "\n",
    "2. Дисперсии произведения двух независимых величин:\n",
    "\n",
    "$$D\\eta\\gamma = E(\\eta\\gamma)^2 - (E\\eta\\gamma)^2 = E\\eta^2E\\gamma^2 - (E\\eta)^2(E\\gamma)^2 \\tag{8}.$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распишем условие $(1)$ с использованием $(5)$ и $(7)$:\n",
    "\n",
    "$$D(z^{i+1}_{k}) = D(\\sum_t z^i_t w_{kt}) = \\sum_t D(z^i_t w_{kt}) \\tag{9}$$\n",
    "\n",
    "Дисперсии признаков на входе функции активации берем одинаковые:\n",
    "\n",
    "$$D(z^{i+1}_{k}) = n D(z^i_0 w_{k0}),\\tag{10}$$\n",
    "\n",
    "где $n$ - размерность выхода слоя.\n",
    "\n",
    "Применяем нашу формулу $(8)$ и получаем:\n",
    "\n",
    "$$D(z^{i+1}_{k}) = n [E(z^i_0)^2E(w_{k0})^2 - (Ez^i_0)^2(Ew_{k0})^2]. \\tag{11}$$\n",
    "\n",
    "Используем $(6)$:\n",
    "\n",
    "$$D(z^{i+1}_{k}) =   n E(z^i_0)^2E(w_{k0})^2. \\tag{12}$$\n",
    "\n",
    "Матожидание выходов активаций и весов равны 0. Из этого: \n",
    "\n",
    "$$D(z^{i}_{0}) = E(z^{i}_{0})^2 - (Ez^{i}_{0})^2 = E(z^{i}_{0})^2, \\tag{13}$$\n",
    "\n",
    "$$D(w_{k0}) = E(w_{k0})^2 - (Ew_{k0})^2 = E(w_{k0})^2.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подставляем в $(12)$:\n",
    "\n",
    "$$D(z^{i+1}_{k}) = n D(z^i_0)D(w_{k0}). \\tag{14}$$\n",
    "\n",
    "Из $(14)$ следует формула для зависимости выхода активаций любого слоя от весов предыдущих слоев и дисперсии исходных данных:\n",
    "\n",
    "$$Dz^i = Dx \\prod_{p=0}^{i-1}n_pDW^p, \\tag{15}$$\n",
    "\n",
    "где $n_p$ - размерность выхода слоя p-го слоя.\n",
    "\n",
    "Аналогично можно вывести формулу для градиентов по активациям\n",
    "\n",
    "$$D(\\dfrac {\\delta L} {\\delta z^i}) = D(\\dfrac {\\delta L} {\\delta z^d} ) \\prod_{p=i}^{d}n_{p+1}DW^p. \\tag{16}$$\n",
    "\n",
    "Вспоминаем условия $(1)$, $(2)$:\n",
    "\n",
    "$$Dz^i = Dz^j \\tag{1},$$\n",
    "\n",
    "$$D\\dfrac {\\delta L} {\\delta z^i} = D\\dfrac {\\delta L} {\\delta z^j} \\tag{2}.$$\n",
    "\n",
    "С учетом $(15)$, $(16)$ они эквивалентны условиям:\n",
    "\n",
    "$$n_iDW^i = 1 \\tag{17}$$\n",
    "\n",
    "$$n_{i+1}DW^i = 1 \\tag{18}$$\n",
    "\n",
    "Условия могут быть невыполнимы одновременно:\n",
    "\n",
    " $$n_i \\ne n_{i+1}. $$\n",
    "\n",
    "Возьмем компромисс - среднее гармоническое решений первого и второго уравнения:\n",
    "\n",
    "$$DW^i = \\dfrac 2 {n_i + n_{i+1}} \\tag{19}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итого:** нам нужно инициализировать веса нейронов случайными величинами со следующим матожиданием и дисперсией:\n",
    "\n",
    "$$ EW^i = 0,$$\n",
    "\n",
    "$$DW^i = \\dfrac 2 {n_i + n_{i+1}}.$$\n",
    "\n",
    "При инициализации Xavier используется [равномерное распределение](https://ru.wikipedia.org/wiki/%D0%9D%D0%B5%D0%BF%D1%80%D0%B5%D1%80%D1%8B%D0%B2%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D0%B2%D0%BD%D0%BE%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5): \n",
    "\n",
    "$$W_i \\sim U[a, b ],$$\n",
    "\n",
    "где $a=-b$, так как матожидание равно 0. \n",
    "\n",
    "Дисперсия которого выражается формулой: \n",
    "$$D(U[a, b]) = \\dfrac 1 {12} (b -a)^2 = \\dfrac 4 {12} b^2 = \\dfrac 1 {3} b^2.$$\n",
    "\n",
    "Из $(19)$ получим:\n",
    "\n",
    "$$ b = \\sqrt{\\dfrac {6} {n_i + n_{i + 1}}}$$\n",
    "\n",
    "**Инициализация  Xavier** - это инициализация весов случайной величиной с распределением:\n",
    "\n",
    "$$W_i \\sim U[-\\sqrt{\\dfrac {6} {n_i + n_{i + 1}}}, \\sqrt{\\dfrac {6} {n_i + n_{i + 1}}}],$$ \n",
    "\n",
    "где $n_i$ - размерность выхода слоя n-го слоя.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы понять, что происходит с выходами слоя активации при использовании инициализации Xavier, рассмотрим картинку из оригинальной статьи [Xavier, Yoshua, \"Understanding the difficulty of training deep feedforward neural networks\", Aistats, 2010](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf):\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/xavier_procentile_and_deviation_with_and_without_init.png\" width=\"600\">\n",
    "\n",
    "На картинке изображена зависимость 98-[процентиля](https://en.wikipedia.org/wiki/Percentile) (отдельные маркеры) и стандартного отклонения (соединенные маркеры) значений на выходе слоя активации $tanh$ от эпохи обучения для различных слоев нейросети. \n",
    "\n",
    "Верхнее изображение - инициализация весов с помощью нормального распределения $W_i \\sim U[-\\dfrac {1} {\\sqrt{n_i}}, \\dfrac {1} {\\sqrt{n_i}} ]$, нижнее с использованием инициализации Xavier.\n",
    "\n",
    "На верхнем изображении видно, как значения 98-процентиля уходят в значения +1 и -1 (сначала на выходе первого слоя, потом на выходе второго и т.д.). Это значит, что для части нейронов происходит затухание градиентов (они переходят в область, отмеченную на графиках $tanh(x)$, $tanh’(x)$ красным). На нижней картинке такого не происходит. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Хи-инициализация (Kaiming He)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для функции активации  ReLU и ее модификаций (PReLU, Leaky ReLU и т.д.) аналогично инициализации Xavier можно расписать условия $(1)$, $(2)$. Так вводится He-инициализация. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод Kaiming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично выводу для Xavier получаем выражения:\n",
    "\n",
    "$$Dz^i = Dx \\prod_{p=0}^{i-1}\\dfrac 1 2 n_pDW^p $$\n",
    "\n",
    "$$D(\\dfrac {\\delta L} {\\delta z^i}) = D(\\dfrac {\\delta L} {\\delta z^d} ) \\prod_{p=i}^{d}\\dfrac 1 2 n_{p+1}DW^p $$\n",
    "\n",
    "где $n_p$ - размерность выхода слоя p-го слоя.\n",
    "\n",
    "Условия $(1)$, $(2)$ эквивалентны условиям: \n",
    "\n",
    "$$  \\dfrac {n_iDW^i} {2}  = 1, $$\n",
    "\n",
    "$$\\dfrac {n_{i+1}DW^i} {2} = 1.$$\n",
    "\n",
    "Можно опять взять среднее гармоническое. Но на практике берут либо $ \\frac 2 {n_i}$, либо $\\frac 2 {n_i + 1}$\n",
    "\n",
    "Итого получим:\n",
    "\n",
    "$$W^i \\sim N(0, sd=\\sqrt{\\frac 2 n_i})$$\n",
    "\n",
    "Более подробно с выводом Хи-инициализации можно ознакомиться в оригинальной [статье](https://arxiv.org/pdf/1502.01852v1.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Важность инициализации весов\n",
    "\n",
    "1. Нейросеть может сойтись значительно быстрее\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/weight_initialization_influence_convergence_neural_networks.png\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. В зависимости от выбранной активации сеть вообще может сойтись или не сойтись"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/activation_function_influence_convergence_neural_networks.png\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обобщение инициализаций Ксавьера и Хи-инициализации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще говоря, коэффициенты в инициализациях (числитель в формуле для дисперсии), зависят от конкретной выбранной функции активации.\n",
    "[В pytorch есть функции для вычисления этих коэффициентов](https://pytorch.org/docs/stable/nn.init.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ортогональная инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также иногда используется так называемая ортогональная инициализация весов. \n",
    "Для каждого слоя мы убеждаемся, что изначальная матрица весов является ортогональной. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем ортогональную матрицу весов \n",
    "$$W: WW^T = 1$$\n",
    "\n",
    "Тогда:\n",
    "1.  норма активации сохраняется (опять же, активации между слоями остаются в одном масштабе)\n",
    "$$||s_{i+1}|| = ||W_{i}s_i|| = ||s_i||$$\n",
    "\n",
    "2.  все нейроны делают «разные» преобразования\n",
    "$$ ⟨W_i, W_j⟩ = 0~i \\ne j$$\n",
    "$$ ⟨W_i, W_j⟩ = 1~i = j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда такая инициализация обеспечивает значительно лучшую сходимость, [тут можно почитать об этом подробнее](https://datascience.stackexchange.com/questions/64899/why-is-orthogonal-weights-initialization-so-important-for-ppo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация весов в Pytorch\n",
    "\n",
    "Для инициализации весов Pytorch используется модуль torch.nn.init\n",
    "\n",
    "В нем определены разные функции для инициализации весов.\n",
    "\n",
    "Нюанс состоит в том, что обычно для слоев разного типа может требоваться разная инициализация. Потому в функции, которая инициализирует слои вашей нейронной сети желательно прописывать разное поведение для разных слоев.\n",
    "\n",
    "Попробуем, например, добавить в нашу нейросеть инициализацию. Нам нужна регуляризация Xavier, так как у нас Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.init.calculate_gain` - Возвращает рекомендуемое значение коэффициента масштабирования для стандартного отклонения заданной функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMNIST_NN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 activation=nn.Sigmoid,\n",
    "                 init_form=\"normal\"):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.activation = activation()\n",
    "        layers = [nn.Linear(28 * 28, 100), self.activation]\n",
    "        for _ in range(0, n_layers - 1):\n",
    "            layers.append(nn.Linear(100, 100))\n",
    "            layers.append(self.activation)\n",
    "        layers.append(nn.Linear(100, 10))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.init_form = init_form\n",
    "        if self.init_form is not None:\n",
    "            self.init()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "    # xavier weight initialization\n",
    "    def init(self):\n",
    "        sigmoid_gain = torch.nn.init.calculate_gain(\"sigmoid\")\n",
    "        for child in self.layers.children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                if self.init_form == \"normal\":\n",
    "                    torch.nn.init.xavier_normal_(child.weight,\n",
    "                                                 gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                elif self.init_form == \"uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(child.weight,\n",
    "                                                  gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                else:\n",
    "                    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим обучение модели с инициализацией весов Xavier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN(n_layers=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# plotting weights values of first(input layer)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(list(model.layers.children())[0].weight.cpu().detach().numpy().reshape(-1), bins=100) \n",
    "plt.title('weights histogram')\n",
    "plt.xlabel('values')\n",
    "plt.ylabel('counts')\n",
    "plt.show()\n",
    "\n",
    "history = train_model(model, optimizer, model_name=\"n3_layers_sigmoid_havier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что нейросеть стала хоть как-то учиться"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй способ улучшения сходимости нейросетей и борьбы с переобучением - введение регуляризации. Ее можно вводить несколькими способами. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1, L2 регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ мы уже разбирали - давайте просто добавим в лосс штраф к весам. На сходимость нейросети, это, правда, повлияет слабо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Loss\\_reg = loss + \\lambda \\cdot reg$$\n",
    "\n",
    "$$ reg_{L1} = \\lambda \\sum |w_i| $$\n",
    "\n",
    "$$ reg_{L2} = \\lambda \\sum w_i^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L07/out/l1_l2_regularization_to_weight.gif\" alt=\"alttext\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Visualizing regularization and the L1 and L2 norms](https://towardsdatascience.com/visualizing-regularization-and-the-l1-and-l2-norms-d962aa769932)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда уже его хватает, чтобы решить все проблемы. Напомним, что L2 лосс приводит к большому числу маленьких ненулевых весов в сети. А L1 лосс - к маленькому числу ненулевых весов (разреженной нейросети)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из распространенных именно в нейросетях методом регуляризации является Dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/dropout.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Состоит этот метод в следующем:\n",
    "\n",
    "1. Во время обучения мы с вероятностью *p* зануляем выход нейронов слоя (например, *p* = 0.5)\n",
    "2. Зануленные нейроны не участвуют в данном forward, и градиент потому к ним при backward не идет. \n",
    "\n",
    "3. Сила регуляризации определяется вероятностью p, чем она больше - тем сильнее регуляризация. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мотивация Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Борьба с коадаптацией \n",
    "\n",
    "Одной из  проблем при работе с глубокими сетями является совместная адаптация нейронов. В такой сети, если все весовые коэффициенты изучаются вместе, обычно некоторые соединения будут иметь больше возможностей прогнозирования, чем другие.\n",
    "\n",
    "Часть нейронов делает основную работу - предсказывает, а остальные могут вообще не вносить никакого вклада в итоговое предсказание. Или же другая картина - один нейрон делает неверное предсказание, другие его исправляют и в итоге первый нейрон свои ошибки не исправляет. \n",
    "\n",
    "Это явление называется коадаптацией. Этого нельзя было предотвратить с помощью традиционной регуляризации, такой как L1 и L2. А вот Dropout с этим хорошо борется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отмена способности некоторых нейронов учиться во время тренировки на самом деле, оказывается, направлена на то, чтобы получить более обученные нейроны и сократить переобучение. И гарантирует, что выучиваемые индивидуальными нейронами функции хорошо работают со случайно выбранными подмножествами функций, выученных другими нейронами. \n",
    "Таким образом, Dropout приводит к появлению более требовательных нейронов, которые пытаются обойти сложные, индивидуальные особенности, которые склонны плохо обобщать, и сохраняют больше полезной информации самостоятельно. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На следующем рисунке (извлеченном из статьи [Dropout: A Simple Way to Prevent Neural Networks from\n",
    "Overfitting](https://jmlr.org/papers/v15/srivastava14a.html)) мы находим сравнение признаков, изученных в наборе данных MNIST с одним скрытым слоем в автоэнкодере, имеющим 256 признаков после ReLU без dropout (слева), и признаков, изученных той же структурой с использованием dropout в ее скрытом слое с p=0.5 (справа).\n",
    "\n",
    "В то время как первый показывает неструктурированные, беспорядочные паттерны, которые невозможно интерпретировать, второй явно демонстрирует целенаправленное распределение веса, которое обнаруживает штрихи, края и пятна самостоятельно, нарушая их взаимозависимость с другими нейронами для выполнения этой работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/compare_weights_with_dropout_and_without_dropout.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout как регуляризация \n",
    "\n",
    "Фактически, Dropout штрафует слишком сложные, неустойчивые решения. Добавляя в нейросеть Dropout, мы сообщаем ей о том, что решение, которое мы ожидаем, должно быть устойчиво к шуму"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout как ансамбль \n",
    "\n",
    "Можно рассматривать Dropout как ансамбль нейросетей со схожими параметрами, которые мы учим одновременно, вместо того, чтобы учить каждую в отдельности, а затем результат их предсказания усредняем, [замораживая Dropout](https://prvnk10.medium.com/ensemble-methods-and-the-dropout-technique-95f36e4ae9be)\n",
    "\n",
    "Фактически, возникает аналогия со случайным лесом - каждая из наших нейросетей легко выучивает выборку и переобучается - имеет низкий bias, но высокий variance. При этом за счет временного отключения активаций, каждая нейросеть видит не все объекты, а только часть. Усредняя все эти предсказания, мы уменьшаем variance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout помогает бороться с переобучением\n",
    "\n",
    "Dropout, в силу указанного выше, может хорошо помогать бороться с переобучением\n",
    "\n",
    "И в случае линейных слоев "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/dropout_solve_overfitting_problem_in_mlp_networks.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tutorial: Dropout as Regularization and Bayesian Approximation](https://xuwd11.github.io/Dropout_Tutorial_in_PyTorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И в случае свёрточных слоёв "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/dropout_solve_overfitting_problem_in_convolution_networks.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence interval от Dropout\n",
    "Можно используя нейросеть с дропаутом, получить доверительный интервал для нашего предсказания. (Как делали в лекции по ML) Просто не \"замораживаем\" dropout-слои во время предсказания, а делаем предсказания с активными dropout. \n",
    "\n",
    "И делаем forward через такую нейросеть для одного объекта 1000 раз. \n",
    "Сделав это 1000 раз, вы получаете распределение предсказаний, на основе которого можно делать confidence интервалы и как раз ловить те объекты, на которых нейросеть вообще не понимает, что ей делать и потому предсказывает метку или еще что-то с сильной дисперсией. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/confidence_interval_dropout.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простая реализация Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BadDropout(nn.Module):\n",
    "    def __init__(self, p: float=0.5):\n",
    "        super().__init__()\n",
    "        if p < 0 or p > 1:\n",
    "            raise ValueError(\n",
    "                f\"Dropout probability has to be between 0 and 1, but got {p}\")\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            keep = torch.rand(x.size()) > self.p\n",
    "            if x.is_cuda:\n",
    "                keep = keep.to(device)\n",
    "            return x * keep\n",
    "        # in test time, expectation is calculated\n",
    "        return x * (1 - self.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нежелательное свойство представленной выше схемы состоит в том, что мы должны масштабировать (сохранять среднее значение) активации во время прогнозирования. Поскольку производительность тестирования критически важна, лучше всего использовать инвертированный dropout, который выполняет масштабирование во время обучения. Кроме того, если мы захотим убрать dropout из кода, функция прогнозирования останется без изменений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p: float=0.5):\n",
    "        super().__init__()\n",
    "        if p < 0 or p > 1:\n",
    "            raise ValueError(\n",
    "                f\"Dropout probability has to be between 0 and 1, but got {p}\")\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            keep = torch.rand(x.size()) > self.p\n",
    "            if x.is_cuda:\n",
    "                keep = keep.to(device)\n",
    "            return x * keep / (1 - self.p)\n",
    "        return x  # in test time, expectation is calculated intrinsically - we just not divide weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем применить Dropout в нашей нейросети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMNIST_NN_Dropout(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 activation=nn.Sigmoid,\n",
    "                 init_form=\"normal\"):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.activation = activation()\n",
    "        layers = [nn.Linear(28 * 28, 100), self.activation]\n",
    "        for _ in range(0, n_layers - 1):\n",
    "            layers.append(nn.Linear(100, 100))\n",
    "            layers.append(Dropout())           # add Dropout \n",
    "            layers.append(self.activation)\n",
    "        layers.append(nn.Linear(100, 10))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.init_form = init_form\n",
    "        if self.init_form is not None:\n",
    "            self.init()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "    def init(self):\n",
    "        sigmoid_gain = torch.nn.init.calculate_gain(\"sigmoid\")\n",
    "        for child in self.layers.children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                if self.init_form == \"normal\":\n",
    "                    torch.nn.init.xavier_normal_(child.weight,\n",
    "                                                 gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                elif self.init_form == \"uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(child.weight,\n",
    "                                                  gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                else:\n",
    "                    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как наша модель из-за Dropout ведет себя по-разному во время обучения и во время тестирования, то мы должны прямо ей сообщать, обучается она сейчас или нет. Делается это при помощи функций model.train и model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model_sep(model, optimizer, model_name=None, n_epochs=5):\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history['model_name'] = model_name\n",
    "    train_history['loss_on_train'] = []\n",
    "    train_history['loss_on_test'] = []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        loss_on_train = train_epoch(model,\n",
    "                                    optimizer,\n",
    "                                    criterion,\n",
    "                                    train_loader)\n",
    "        model.eval()\n",
    "        _, loss_on_test = validate(model,\n",
    "                                   criterion,\n",
    "                                   test_loader)\n",
    "        train_history['loss_on_train'].extend(loss_on_train)\n",
    "        train_history['loss_on_test'].extend(loss_on_test)\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Dropout(n_layers=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "history = train_model_sep(model, optimizer, model_name=\"nn3_dropout\")\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае выигрыша мы не получили. Возможно, если учить нейросеть больше эпох, эффект бы заметили"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример борьбы с переобучением при помощи Dropout\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы увидеть эффект, и при этом не учить нейросеть 100+ эпох, сделаем искусственный пример.\n",
    "\n",
    "Просто добавим к линейной зависимости шум и попробуем выучить ее нейронной сетью.\n",
    "\n",
    "[Dropout in Neural Networks with Pytorch](https://towardsdatascience.com/batch-normalization-and-dropout-in-neural-networks-explained-with-pytorch-47d7a8459bcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50  # number of data points\n",
    "noise = 0.3\n",
    "\n",
    "# generate the train data\n",
    "x_train = torch.unsqueeze(torch.linspace(-1, 1, N), 1)\n",
    "y_train = x_train + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))\n",
    "\n",
    "# generate the test data\n",
    "x_test = torch.unsqueeze(torch.linspace(-1, 1, N), 1)\n",
    "y_test = x_test + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))\n",
    "\n",
    "print(f'x_train shape: {x_train.shape}\\nx_test shape: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train.data.numpy(), y_train.data.numpy(),\n",
    "            c='purple', alpha=0.5, label='train')\n",
    "plt.scatter(x_test.data.numpy(), y_test.data.numpy(),\n",
    "            c='yellow', alpha=0.5, label='test')\n",
    "\n",
    "x_real = np.arange(-1, 1, 0.01)\n",
    "y_real = x_real\n",
    "plt.plot(x_real, y_real, c=\"green\", label='true')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель без дропаут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_h = 100 # num of neurons\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, N_h),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, N_h),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, 1),\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель с дропаутом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_h = 100 # num of neurons\n",
    "\n",
    "model_dropout = nn.Sequential(\n",
    "    nn.Linear(1, N_h),\n",
    "    nn.Dropout(0.5),  # 50 % probability\n",
    "    nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, N_h),\n",
    "    nn.Dropout(0.2),  # 20% probability\n",
    "    nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, 1),\n",
    ")\n",
    "optimizer_dropout = torch.optim.Adam(model_dropout.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1500\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # train without dropout\n",
    "    y_pred = model(x_train)  # look at the entire data in a single shot\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # train with dropout\n",
    "    y_pred_dropout = model_dropout(x_train)\n",
    "    loss_dropout = criterion(y_pred_dropout, y_train)\n",
    "    optimizer_dropout.zero_grad()\n",
    "    loss_dropout.backward()\n",
    "    optimizer_dropout.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "\n",
    "        model.eval() # not train mode\n",
    "        model_dropout.eval() #  not train mode\n",
    "\n",
    "        # get predictions\n",
    "        y_test_pred = model(x_test)\n",
    "        test_loss = criterion(y_test_pred, y_test)\n",
    "\n",
    "        y_test_pred_dropout = model_dropout(x_test)\n",
    "        test_loss_dropout = criterion(y_test_pred_dropout, y_test)\n",
    "        # plotting data and predictions\n",
    "        plt.scatter(x_train.data.numpy(), y_train.data.numpy(),\n",
    "                    c='purple', alpha=0.5, label='train')\n",
    "        plt.scatter(x_test.data.numpy(), y_test.data.numpy(),\n",
    "                    c='yellow', alpha=0.5, label='test')\n",
    "        plt.plot(x_test.data.numpy(), y_test_pred.data.numpy(),\n",
    "                 'r-', lw=3, label='normal')\n",
    "        plt.plot(x_test.data.numpy(), y_test_pred_dropout.data.numpy(),\n",
    "                 'b--', lw=3,  label='dropout')\n",
    "\n",
    "        plt.title('Epoch %d, Loss = %0.4f, Loss with dropout = %0.4f' %\n",
    "                  (epoch, test_loss, test_loss_dropout))\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        model.train() # train mode\n",
    "        model_dropout.train() # train mode\n",
    " \n",
    "        plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что нейросеть без dropout сильно переобучилась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DropConnect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если занулять не нейроны (активации), а случайные веса, с вероятностью $p$ получится DropConnect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/dropconnect.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DropConnect похож на Dropout, поскольку он вводит динамическую разреженность в модель, но отличается тем, что разреженность зависит от весов *W*, а не от выходных векторов слоя. Другими словами, полностью связанный слой с DropConnect становится разреженно связанным слоем, в котором соединения выбираются случайным образом на этапе обучения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В принципе, вариантов зануления чего-то в нейросетке можно предложить великое множество, в разных ситуациях будут работать разные ([в этом списке](https://paperswithcode.com/methods/category/regularization)  много Drop...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DropBlock\n",
    "\n",
    "Например, можно убирать для каждого батча из нейросети случайные блоки из слоев. И это будет работать!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/dropblock.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Why Self-training with Noisy Students beats SOTA Image classification while using fewer resources](https://medium.datadriveninvestor.com/the-next-big-thing-in-image-classification-self-training-with-noisy-student-for-improving-22d52dc74dda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация входных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим себе, что данные, которые мы подаем в нейросеть, распределены следующим образом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/data_before_normalization.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фактически нейросети работают со скалярными произведениями. В этом плане два вектора, изображенных на рисунке, не сильно отличаются. Так же и точки нашего датасета слабо разделимы. Чтобы с этим работать, нейросеть сначала должна подобрать удобное преобразование, а затем только сравнивать наши объекты. Понятно, что это усложняют задачу. \n",
    "\n",
    "Для того, чтобы облегчить нейросети задачу, входные признаки часто нормируют:\n",
    "\n",
    "$$x1' = \\dfrac {x1 - \\mu_{x1}} {\\sigma_{x1}}$$\n",
    "$$x2' = \\dfrac {x2 - \\mu_{x2}} {\\sigma_{x2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/data_after_normalization.png\" width=\"450\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Такое преобразование действительно помогает нейросети "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/normalization_helps_find_minimum_of_function.png\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[deeplearning.ai](https://www.deeplearning.ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariate shift (Ковариантный сдвиг)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariate shift - явление, когда признаки тренировочной выборки и тестовой по-разному распределены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/covariate_shift.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В такой ситуации модель не в состоянии делать адекватные предсказания на тесте, так как сеть не видела области пространства, в которой расположены тестовые объекты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/covariate_shift_problem.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal covariate shift\n",
    "\n",
    "Похожее явление может иметь место уже внутри нейросети\n",
    "\n",
    "Пусть у нас $i$-й слой переводит выход $i$-1 слоя в новое пространство. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/internal_covariate_shift_example_1_step.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конце нейросеть делает предсказание, считается лосс, делается обратное распространение ошибки и обновляются веса. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/internal_covariate_shift_example_2_step.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого возникает нехорошая ситуация - распределение выходов $i$-1 слоя поменялось, а $i$-й слой изменял веса, думая, что распределение выходов не изменилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/internal_covariate_shift_example_3_step.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плохой вариант борьбы с этим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте на каждом слое просто нормировать каждый признак, используя среднее и дисперсию по батчу\n",
    "\n",
    "$$ \\hat{x}_{i} = \\frac{x_{i} - \\mu_{B}}{\\sigma_{B} + \\epsilon}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в том, что таким образом мы можем попасть в область линейной составляющей нашей функции. Например, в случае сигмоиды "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/domain_of_linear_of_sigmoid_function.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем набор линейных слоев фактически без функций активации -> все вырождается в однослойную сеть. Не то, что нам надо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам надо дать нейронной сети возможность перемещать распределение выходов слоя из области 0 и самой подбирать дисперсию. Для этой цели используется **батч-нормализация** (*batch normalization*), которая вводит в нейронную сеть дополнительную операцию между соседними скрытыми слоями. Она состоит из нормализации входящих (в слой батч-нормализации) значений, полученных от одного скрытого слоя, масштабирования и сдвига с применением двух новых параметров и передачи полученных значений на вход следующему скрытому слою.\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnormalization.png\" width=\"800\">\n",
    "\n",
    "Параметры, используемые в батч-нормализации $\\gamma$ &mdash; отвечающий за сжатие и $\\beta$ &mdash; отвечающий за сдвиг являются обучаемыми параметрами (наподобие весов и смещений скрытых слоев). \n",
    "\n",
    "Помимо обучаемых параметров $\\gamma$ и $\\beta$ в слое батч-нормализации существуют также необучаемые параметры: __скользящее среднее__ средних (_Mean Moving Average_) и скользящее среднее дисперсий (_Variance Moving Average_), служащие для сохранения состояния слоя батч-нормализации. \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnorm_layer_parameters.png\" >  \n",
    "\n",
    "Параметры $\\gamma$, $\\beta$, а также оба скользящих средних вычисляются для каждого слоя батч-нормализации отдельно и являются векторами с длиной, равной количеству входящих признаков.\n",
    "\n",
    "В процессе обучения, мы подаем в нейронную сеть по одному мини-батчу за раз. Процедуру обработки значений $x$ из одного мини-батча $ B = \\{x_{1},\\ldots, x_{m}\\} $ можно представить следующим образом:\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batch_normalization_compute_moving_average.png\" width=\"1000\">\n",
    "\n",
    "Шаг масштабирования и сдвига является главным новшеством батч-нормализации, поскольку в отличие от предыдущего рассмотренного примера, нормированные значения больше не обязаны иметь среднее равное 0 и единичную дисперсию. Батч-нормализации позволяет сдвигать среднее нормированных значений и масштабировать дисперсию. Фактически, теперь нейросеть даже может отменить нормализацию входных данных, если считает ее ненужной.\n",
    "\n",
    "Для наглядности проиллюстрируем размерности промежуточных переменных на следующем изображении:\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batch_normalization_compute_moving_average_scheme.png\" width=\"1000\">\n",
    "\n",
    "После прямого прохода, параметры $\\gamma$ и $\\beta$ обновляются через обратное распространение ошибки также как и веса скрытых слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скользящее среднее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше мы обсуждали то, что в процессе обучения слой  Батч-нормализация рассчитывает значение среднего и дисперсии каждого признака в соответствующем мини-батче. Однако во время предсказания, батч у нас уже отсутствует &mdash; откуда брать среднее и дисперсию? \n",
    "\n",
    "Во время предсказания используется скользящее среднее, которое было рассчитано и сохранено в процессе обучения. \n",
    "\n",
    "$$ \\mu_{mov_{B}} = (1-\\alpha)\\mu_{mov_{B-1}}+\\alpha\\mu_{B} $$\n",
    "\n",
    "$$ \\sigma_{mov_{B}} = (1-\\alpha)\\sigma_{mov_{B-1}}+\\alpha\\sigma_{B} $$\n",
    "\n",
    "Обычно используется параметр $\\alpha = 0.1$\n",
    "\n",
    "Почему используется именно скользящее среднее, а не, например, статистика всей обучающей выборки? Дело в том, что при таком подходе нам бы пришлось хранить средние всех признаков для всех батчей, пропущенных через нейросеть в ходе обучения. Это ужасно невыгодно по памяти. Вместо этого скользящее среднее выступает в качестве приближенной оценки среднего и дисперсии обучающего набора, в этом случае эффективность использования ресурсов увеличивается, поскольку вычисления производятся постепенно &mdash; нам нужно хранить в памяти только одно число &mdash; значение скользящего среднего, полученное на последнем шаге.\n",
    "\n",
    "Проиллюстрировать преимущество использования скользящего среднего можно на следующем примере:\n",
    "\n",
    "Предположим, что у нас есть некоторая генеральная совокупность объектов, обладающих некоторым признаком $x$, (соответствующая абстрактной обучающей выборке) и некоторый черный ящик, извлекающий по $k$ объектов из этой генеральной совокупности (соответствующий абстрактному даталоадеру). Наша задача &mdash; дать оценку ожидаемому среднему этих $k$ объектов. При этом ожидаемое среднее для $k$ объектов может отличаться от среднего генеральной совокупности, поскольку могут накладываться дополнительные условия на извлекаемую выборку. В данном примере для простоты будем извлекать $k$ объектов из некого распределения случайным образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = 500 # sample size\n",
    "n = 2\n",
    "p = 0.5\n",
    "\n",
    "sample = np.random.negative_binomial(n, p, k)\n",
    "sns.histplot(data=sample, discrete=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценить ожидаемое среднее теоретически, не зная как распределен признак $x$ наших объектов, трудно. Мы можем собрать большое количество средних и произвести оценку с их помощью, но для этого нам потребуется хранить в памяти все эти значения, что опять-таки приведет к неэффективному расходу ресурсов. Более эффективным решением будет воспользоваться скользящим средним. Давайте сравним эти два метода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema = 0\n",
    "alpha = 0.01\n",
    "means = np.array([])\n",
    "\n",
    "for i in range(10000):\n",
    "    sample = np.random.negative_binomial(n, p, 50)\n",
    "    ema = (1 - alpha) * ema + alpha * sample.mean()\n",
    "    means = np.append(means, sample.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем количество памяти, затрачиваемое на хранение списка средних значений признака $x$ по выборкам из $k$ объектов, и количество памяти, затрачиваемое на хранение скользящего среднего:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(f'{sys.getsizeof(ema)} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество памяти для хранения списка средних:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{sys.getsizeof(means)} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что на хранение массива средних значений расходуется на порядки больше памяти, чем на хранение одного скользящего среднего. Теперь давайте воспользуемся тем, что мы сэмплировали случайные выборки из известного распределения, и можем теоретически рассчитать их среднее. В нашем примере мы извлекали выборки из негативного биномиального распределения с параметрами $n=2$ и $p=0.5$, для которого среднее рассчитывается по формуле $mean=\\frac{np}{1-p}=2$. Мы знаем, что при достаточно большом количестве сэмплированных выборок, среднее распределения выборочных средних будет стремиться к среднему генеральной совокупности. Сравним результаты, полученные с использованием сохраненных выборочных средних и скользящего среднего с теоретическим расчетом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среднее признака x по k объектам, оцененное с помощью скользящего среднего:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ema:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среднее признака x по k объектам, оцененное по всем сэмплированным выборкам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{means.mean():.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что мы получили довольно точную оценку, использовав скользящее среднее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Защита от нулей в знаменателе\n",
    "\n",
    "Чтобы у нас не мог возникнуть 0 в знаменателе, добавляем маленькое число - $\\epsilon$. Например, равное 1e-5\n",
    "\n",
    "\n",
    "$$ \\hat{x}_{i} = \\frac{x_{i} - \\mu_{B}}{\\sigma_{B} + \\epsilon}$$\n",
    "\n",
    "$$ BN_{\\gamma, \\beta}(x_{i}) = \\gamma \\hat{x}_{i} + \\beta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейный слои и конволюции\n",
    "\n",
    "Слой конволюции можно свести к линейному слою с очень жесткими ограничениями на веса. Поэтому неудивительно, что BatchNorm можно применять и для линейных слоев и для конволюций. \n",
    "\n",
    "С конволюциями есть единственный нюанс - у нас \"одним признаком\" считается вся получаемая **feature map**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/feature_map.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И нормализация идет по всей такой feature map (по всему каналу) для всех объектов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/batchnorm_efficiency.png\" width=\"550\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот метод действительно работает. \n",
    "Видим, что нейросети с батч-нормализацией:\n",
    "\n",
    "1. Сходятся быстрее, чем нейросети без неё\n",
    "2. Могут работать с более высоким начальным learning rate, причем это позволяет достигать лучших результатов\n",
    "3. BatchNorm позволяет глубокой нейросетке работать даже с функцией активации в виде сигмоиды. Без батчнорма такая сеть не обучилась бы вовсе. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисление градиента batchnorm - интересное упражнение на понимание того, как работает backpropagation. В лекции мы это опускаем, можете ознакомиться самостоятельно\n",
    "\n",
    "[Deriving the Gradient for the Backward Pass of Batch Normalization](https://kevinzakka.github.io/2016/09/14/batch_normalization/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/batchnorm_gradient.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchnorm как регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему для нейросети с батчнормализацией можно использовать более высокие learning rate? \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оказывается, батчнормализация делает неявную регуляризацию на веса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы решили увеличить веса в $a$ раз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы шкалируем, то домножение весов $W$ на константу выходных значений слоя не меняет\n",
    "\n",
    "$$BN((aW)u) = BN(Wu)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиент слоя по входу не меняется\n",
    "\n",
    "$$\\dfrac {\\delta BN((aW)u)} {\\delta u} = \\dfrac {\\delta BN(Wu)} {\\delta u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А градиент по весам уменьшается в $a$ раз\n",
    "\n",
    "$$\\dfrac {\\delta BN((aW)u)} {\\delta aW} = \\dfrac 1 a \\dfrac {\\delta BN(Wu)} {\\delta W} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, нейросеть автоматически не дает большим весам расти"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal covariate shift?\n",
    "\n",
    "Согласно некоторым исследованиям ([например](https://arxiv.org/abs/1805.11604)), успех BatchNormalization заключается не в исправлении covariate shift. BatchNormalization работает как-то иначе, улучшая гладкость пространства решений и облегчает поиск в нем минимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnorm_helps_find_minimum_of_function.jpg\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Советы по использованию BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит помнить, что с батч-нормализацией:\n",
    "\n",
    "* **Крайне важно** перемешивать объекты (составлять новые батчи) между эпохами. Единицей обучения параметров $\\beta$ и $\\gamma$ являются батчи. Если их не перемешивать, то из 6400 объектов в тренировочном датасете получим лишь 100 объектов (при условии, что в батче 64 объекта) для обучения $\\beta$ и $\\gamma$\n",
    "\n",
    "* В слое, после которого поставили BatchNormalization, надо убрать bias (параметр $\\beta$ в BatchNormalization берет эту роль сам по себе)\n",
    "\n",
    "\n",
    "* Другое расписание learning rate: бОльшее значение в начале обучения и быстрое уменьшение в процессе обучения\n",
    "\n",
    "* Если используем BatchNormalization, то надо уменьшить силу Dropout и L2-регуляризации\n",
    "\n",
    "* Чем меньше размер батча в обучении, тем хуже будет работать BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/batchnorm_batch_size.png\" width=\"550\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем BatchNormalization в Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMNIST_NN_Init_Batchnorm(nn.Module):\n",
    "    def __init__(self, n_layers):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        layers = [nn.Linear(28 * 28, 100, bias=False),\n",
    "                  nn.BatchNorm1d(100),\n",
    "                  nn.Sigmoid()]\n",
    "        for _ in range(0, n_layers - 1):\n",
    "            layers.append(nn.Linear(100, 100, bias=False))\n",
    "            layers.append(nn.BatchNorm1d(100))\n",
    "            layers.append(nn.Sigmoid())\n",
    "        layers.append(nn.Linear(100, 10))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.init()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "    def init(self):\n",
    "        sigmoid_gain = torch.nn.init.calculate_gain(\"sigmoid\")\n",
    "        for child in self.layers.children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                torch.nn.init.xavier_normal_(child.weight,\n",
    "                                             gain=sigmoid_gain)\n",
    "                if child.bias is not None:\n",
    "                    torch.nn.init.zeros_(child.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "history = train_model_sep(model, optimizer, model_name=\"batchnorm2\")\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_data(hooks_data_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И попробуем, согласно советам, увеличить learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "history = train_model_sep(model, optimizer, model_name=\"batchnorm_increased_lr\")\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_data(hooks_data_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ставить BatchNormalization до или после активации?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### До"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnormalization_before_activation.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Рекомендуется авторами статьи, где предложили Batch Normalization\n",
    "* Для сигмоиды, BN, поставленная после активации, не решает проблем сигмоиды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### После"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnormalization_after_activation.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Аргументация авторов статьи не до конца обоснована\n",
    "* Обычно, сигмоиду не используют в современных нейронных сетях\n",
    "* Для популярной ReLU, BN, поставленная до активации может приводить к “умирающей ReLU”, когда большая часть ее входов меньше 0 и потому для них градиент не проходит\n",
    "* На многих задачах BN после функции активации работает лучше или не хуже поставленной до"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/batchnormalization_before_or_after_relu.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BN experiments](https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ставить BatchNormalization до или после Dropout?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### До"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnormalization_before_dropout.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Меньше влияние (covariate shift) Dropout на Batchnorm\n",
    "\n",
    "#### После"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnormalization_after_dropout.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Информация о зануленных активациях не просачивается через среднее и дисперсию батча"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ставить только что-то одно \n",
    "\n",
    "* Dropout может отрицательно влиять на качество нейросети с BatchNorm за счет разного поведения на train и test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Строго говоря\n",
    "\n",
    "* Оптимальный порядок следования слоев зависит от задачи и архитектуры сети\n",
    "* Возможно, стоит применять модифицированные версии BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другие Normalization\n",
    "\n",
    "Существует большое количество иных нормализаций, их неполный список можно найти [здесь](https://paperswithcode.com/methods/category/normalization). В данной секции мы рассмотрим самые популярные виды нормализации помимо BatchNorm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/normalization_methods.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чаще всего нормализации тестируют на изображениях, в том числе или только на изображениях. Потому их графически объясняют при помощи следующей схемы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/dimensions_channels_batch_samples.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*По оси абсцисс* расположены объекты из батча,  \n",
    "*по оси ординат* - feature map, преобразованный в вектор,  \n",
    "*по оси аппликат* - каналы (feature maps).\n",
    "\n",
    "В этом представлении BatchNorm выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/visualization_of_batch_normalization.png\" width=\"450\">\n",
    "\n",
    "[Batch Normalization](https://paperswithcode.com/method/batch-normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Norm\n",
    "\n",
    "Помимо свёрточных нейронных сетей, существует специальный тип нейронных сетей, используемых для обработки последовательностей. Называется он \"рекуррентные нейронные сети\", ему же будет посвящена наша следующая лекция. \n",
    "\n",
    "Когда оказалось, что BatchNorm положительно сказывается на обучении нейронных сетей, его попытались применить для различных архитектур. BatchNorm нельзя было использовать \"из коробки\" для рекуррентных нейронных сетей (работающих с последовательными данными), пришлось придумывать различные адаптации, среди которых наиболее удачной оказалась **Layer Normalization**.  \n",
    "По сути, теперь нормализация происходит внутри одного объекта из батча, а не поканально в рамках батча. С математической точки зрения, данная \"адаптация\" отличается от BatchNorm, однако экспериментально она превзошла своих конкурентов в задаче нормализации при обработке последовательных данных.\n",
    "\n",
    "Впоследствии, данный метод нормализации хорошо проявил себя в трансформерах - наследниках рекуррентных нейронных сетей в вопросах обработки последовательных данных (об этом типе нейросетей мы также поговорим на следующей лекции). После успешного применения трансформеров в задачах компьютерного зрения, LayerNorm стал использоваться и в компьютерном зрении (хотя и уступал BatchNorm при использовании в свёрточных нейронных сетях)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/visualization_of_layer_normalization.png\" width=\"450\">\n",
    "\n",
    "[Layer Normalization](https://paperswithcode.com/method/layer-normalization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Norm\n",
    "\n",
    "Следующий вид нормализации был предложен отечественными исследователями (из Сколтеха), занимавшимися разработкой быстрого и эффективного способа переноса стиля с одного изображения на другое. \n",
    "\n",
    "При использовании BatchNorm терялась информация о контрастах на конкретном изображении, поскольку нормализация производится по нескольким объектам. Для сохранения *контрастов* в экземпляре (*instance*) изображения была предложена специальная нормализация, рассматривающая конкретный канал одного конкретного объекта. Было предложено два названия нормализации: связанное с мотивацией (contrast normalization) и связанное с принципом работы (**instance normalization**). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/visualization_of_instance_normalization.png\" width=\"450\">\n",
    "\n",
    "[Instance Normalization](https://paperswithcode.com/method/instance-normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Norm\n",
    "\n",
    "В течение долгого времени, BatchNorm оставался однозначным фаворитом для использования в задачах компьютерного зрения, однако:\n",
    "1. В связи с необходимостью точно считать статистики внутри batch, при обучении приходилось использовать большой batch size.  \n",
    "\n",
    "2. Ограниченность размера видеопамяти вынуждает разработчиков идти на компромисс между сложностью модели и batch size.\n",
    "\n",
    "Итого, использование BatchNorm приводило к невозможности использовать сложные модели**\\***, поскольку им просто не хватало места на видеокарте. \n",
    "\n",
    "Необходимость использовать большой batch size могут решать различные нормализации, не использующие batch-размерность. К примеру, уже известные нам **Layer Norm** и **Instance Norm**. Эмпирически оказалось, что данные нормализации уступают BatchNorm по качеству работы: в то время как LayerNorm предполагает одинаковую важность и суть различных каналов (*рассматривая данные излишне глобально*), InstNorm упускает межканальные взаимодействия (*рассматривая данные слишком локально*). \n",
    "\n",
    "Успешным обобщением данных методов является **Group Normalization**: данный метод разбивает каналы на $G \\in [1; C]$ групп, присваивая каждой из них (примерно) равное количество каналов. Отметим, что при $G = 1$, GroupNorm идентичен LayerNorm, а при $G = C$, GroupNorm идентичен InstNorm. \n",
    "\n",
    "Эмпирически оказалось, что при замене BatchNorm на GroupNorm качество модели падает в разы менее значительно, чем при использовании LayerNorm либо GroupNorm. Более того, при изменении batch size качество работы LayerNorm не изменялось, что открыло перспективы для создания более сложных моделей компьютерного зрения. \n",
    "\n",
    "\n",
    "**\\*** - подразумевается, что уменьшение batch size позволило бы создать более сложные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/visualization_of_group_normalization.png\" width=\"450\">\n",
    "\n",
    "[Group Normalization](https://paperswithcode.com/method/group-normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Normalization\n",
    "\n",
    "Существует семейство методов, принципиально отличающихся от рассмотренных ранее нормализаций: в отличие от BatchNorm, LayerNorm и прочих известных вам нормализаций, ориентированных на **изменение представлений данных** внутри нейронной сети (и по сути представляемых как обычные слои), некоторые методы повышения качества обучения нейронных сетей ориентированы на **изменение параметров** самой нейронной сети.\n",
    "\n",
    "[Weight Normalization](https://paperswithcode.com/method/weight-normalization) - один из таких методов, во многом вдохновлённый BatchNorm. В отличие от ранее упомянутых нормализаций, он появился в результате анализа влияния BatchNorm на обучение с сугубо математической точки зрения (было рассмотрено влияние BatchNorm на [информационную матрицу Фишера](https://en.wikipedia.org/wiki/Fisher_information)).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном методе производится репараметризация слоя нейронной сети следующим образом:\n",
    "\n",
    "$$\\mathbb{w} = \\frac{g}{\\left\\Vert \\mathbb{v}\\right\\Vert}\\mathbb{v},$$\n",
    "\n",
    "где $\\mathbb{w}$ - вектор весов слоя, $g$ и $\\mathbb{v}$ - обучаемые параметры. Важный момент, который стоит сразу отметить: данный вид параметризации не зависит от данных, потому одинаково хорошо будет работать при любом batch size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight normalization** в некоторых случаях позволяет с лёгкостью выполнять ранее обсуждаемую \"умную инициализацию\" параметров нейронной сети. Выполняется она следующим образом: некоторым образом инициализируем $\\mathbb{v}$; выполним запуск сети на случайном batch, пусть на вход слою приходит $\\mathbb{x}$. Выполним следующую операцию:\n",
    "\n",
    "$$t = \\frac{\\mathbb{v}\\cdot\\mathbb{x}}{\\left\\Vert\\mathbb{x}\\right\\Vert}, \\qquad y = \\phi\\left(\\frac{t - \\mu[t]}{\\sigma[t]}\\right)$$\n",
    "\n",
    "Чтобы перед активацией получить значения с нулевым средним и единичным стандартным отклонением, стоит установить параметрам $g$ и $b$ следующие значения:\n",
    "\n",
    "$$g \\leftarrow \\frac{1}{\\sigma[t]}, \\qquad b \\leftarrow \\frac{-\\mu[t]}{\\sigma[t]}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой важной особенностью **weight normalization** является *разделение* вектора весов на \"направление вектора\" и \"норму вектора\". По сути, отделение нормы векторов весов позволяет реализовывать гибкую настройку скорости обучения - различные параметры начинают обновляться с различной скоростью ($\\sim\\lambda \\cdot g_i$), что позволяет модели более гибко обучаться. \n",
    "\n",
    "Weight normalization - далеко не единственный метод, позволяющий улучшать обучение модели, влияя на обновление её параметров: существует целое семейство \"оптимизаторов\" - методов, отвечающих за изменение параметров обучаемой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизация весов нейросетей\n",
    "\n",
    "Методов тоже много, расскажем о популярных ([неполный список](https://paperswithcode.com/methods/category/stochastic-optimization))\n",
    "\n",
    "Эти методы реализованы в модуле torch.optim\n",
    "При этом, что важно, подсчет градиентов лосс функции по весам никак не зависит от оптимизаторов из пакета. На прошлых занятиях мы с вами видели, что pytorch вычисляет градиенты автоматически, на основе оптимизаций.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обзор популярных оптимизаторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD\n",
    "Обычный стохастичный градиентный спуск. Обновляем веса в соответствии с текущим градиентом по ним, домножая антиградиент на постоянный коэффициент $\\eta$ (гиперпараметр обучения - learning rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/stochastic_gradient_descent.gif\" width=\"950\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD обладает важной особенностью - на каждом объекте или наборе объектов (мини-батче) ландшафт функции потерь выглядит по-разному. Некоторые минимумы функции потерь и седловые точки могут быть характерны лишь для части объектов.\n",
    "\n",
    "Использование SGD позволяет модели при обучении выбираться из **некоторых** локальных минимумов. В результате обучения модель с большой вероятностью остановится в относительно широком и глубоком минимуме, хотя нет гарантий, что он будет \"лучшим\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/sgd_loss_batch_landscape.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD до сих пор является достаточно популярным методом обучения нейросетей, потому что он простой, не требует подбора дополнительных гиперпараметров кроме $\\eta$ и сам по себе обычно дает неплохие результаты. \n",
    "\n",
    "Если же модель учится слишком долго и/или важна каждая сотая в качестве, то нужно либо использовать его вкупе с другими технологиями (о них - ниже), либо использовать другие способы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.SGD([parameters], lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минусы SGD:\n",
    "\n",
    " 1. Если функция ошибки быстро меняется в одном направлении и медленно - в другом, то это приводит к резким изменениям направления  градиентов и замедляет процесс обучения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/stohastic_gradient_descent_no_momentum.gif\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Machine Learning Optimization Methods “Mechanics, Pros and Cons”](https://salmenzouari.medium.com/machine-learning-optimization-methods-mechanics-pros-and-cons-81b720194292)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Может застревать в локальных минимумах или седловых точках (точках, где все производные равны 0, но не являющихся минимума/ максимумами). В них градиент равен 0, веса не обновляются - конец оптимизации. \n",
    "\n",
    "Пример таких точек:\n",
    "\n",
    "\n",
    "Точка 0 у функции $x^3$, не имеющей минимума или максимума вовсе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/getting_stuck_in_local_minimum_example.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или точка 0, 0 у функции z = $x^2 - y^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/saddle_point_example.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Седловая точка\n",
    "](https://ru.wikipedia.org/wiki/%D0%A1%D0%B5%D0%B4%D0%BB%D0%BE%D0%B2%D0%B0%D1%8F_%D1%82%D0%BE%D1%87%D0%BA%D0%B0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3. Так как мы оцениваем градиенты по малой части выборки, они могут плохо отображать градиент по всей выборке и являться шумными. В результате часть шагов градиентного спуска делаются впустую или во вред. \n",
    " \n",
    " 4. Мы применяем один и тот же learning rate ко всем параметрам, что не всегда разумно. Параметр, отвечающий редкому классу, будет обучаться медленнее остальных. \n",
    " \n",
    " 5. Просто медленнее сходится"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основой всех описанных ниже алгоритмов является SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum\n",
    "\n",
    "Чтобы избежать проблем 1-3, можно использовать momentum - фактически, мы добавляем нашему движению инерции. Если представить наши текущие веса как координаты шарика, и мы этот шарик пытаемся загнать в наиболее глубокое место, то у шарика теперь появился вес."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/stohastic_gradient_descent_with_momentum.gif\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Градиентный спуск, как учатся нейронные сети(Видео)](https://youtu.be/IHZwWFHWa-w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала пытаемся поменять направление движения шарика с прежнего направления с учетом текущего градиента\n",
    "$$v_{t+1} = \\rho v_t + \\nabla_wL(x, y, W)$$\n",
    "\n",
    "Вычисляем, куда он покатится\n",
    "$$w_{t+1} = w_t - \\eta v_{t+1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/advantages_wtih_momentum.png\" width=\"480\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.SGD([parameters], momentum=0.9, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы быстрее достигаем локального минимума и можем выкатываться из совсем неглубоких. Градиент стал менее подвержен шуму, меньше осциллирует"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/stohastic_gradient_descent_no_momentum.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/stohastic_gradient_descent_with_momentum.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У этого подхода есть одна опасность - мы можем выкатиться за пределы минимума, к которому стремимся, а потом какое-то время к нему возвращаться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/problem_of_big_momentum_value.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[optimizer-visualization](https://github.com/Jaewan-Yun/optimizer-visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы с этим бороться, предложен другой способ подсчета момента инерции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAG (Nesterov momentum)\n",
    "\n",
    "Будем сначала смещаться в сторону, куда привел бы нас наш накопленный градиент, там считать новый градиент и смещаться по нему. \n",
    "В результате перескоки через минимум будут менее значительными, и мы будем быстрее сходиться\n",
    "\n",
    "$$v_{t+1} = \\rho v_t +  \\nabla_w L(w + \\rho v_t )$$\n",
    "\n",
    "$$w_{t} = w_{t-1} - \\eta v_{t} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/nesterov_momentum.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике эту формулу все равно можно записать так, чтобы задача вычисления градиента ложилась не на сам оптимизатор\n",
    "(к примеру, [реализация в PyTorch](https://github.com/pytorch/pytorch/blob/master/torch/optim/_functional.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.SGD([parameters], momentum=0.9, nesterov=True, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Learning Rate\n",
    "\n",
    "Оба озвученных улучшения никак не борются с тем, что некоторые параметры нашей нейросети могут получать информацию для обновления реже, чем остальные. Например, фильтр, отличающий сиамских кошек от остальных, будет работать только тогда, когда в выборке попадутся конкретно сиамские кошки. А их может быть и не очень много, по батчам мы их не размажем (либо батчей получится очень много, если нарочно балансировать)\n",
    "\n",
    "Другая ситуация - учим нейросеть на словах из русского языка. Есть веса, отвечающие за редкие слова, например \"молвить\". Вы часто в языке встречаете слово молвить? Молвят устами, а они тоже встречаются не часто. В результате, если learning rate постоянен, то мы выучим параметры для слова молвить плохо. \n",
    "\n",
    "Единственный путь - завести для каждого параметра индивидуальный learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adagrad\n",
    "\n",
    "Будем хранить для каждого параметра сумму квадратов его градиентов. \n",
    "\n",
    "И будем добавлять наш градиент с коэффициентом, обратно пропорциональным корню из этой суммы (фактически - некая аппроксимация средней амплитуды градиента нашего параметра). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ w = w - \\eta \\frac{l}{\\sqrt{G} + e} \\odot (\\nabla_w L(x,y,W)) $$\n",
    "\n",
    "$$ G = \\sum_{t=1}^T \\nabla_w L(x,y,w_t)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате, если градиент у нашего веса часто большой - коэффициент будет уменьшаться. \n",
    "\n",
    "Единственная проблема - при такой формуле наш learning rate неминуемо в конце концов затухает (так как сумма квадратов не убывает)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.Adagrad([parameters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте устроим \"забывание\" предыдущих квадратов градиентов. Просто будем домножать их на некий коэффициент меньше 1\n",
    "\n",
    "\n",
    "$$v_t = \\alpha v_{t-1} + (1-\\alpha) (\\nabla_w L(x,y,w_t))^2$$\n",
    "\n",
    "$$w = w - \\frac{\\eta}{\\sqrt{v_t }+ e} \\odot \\nabla_w L(x,y,W)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.RMSprop([parameters], alpha=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam\n",
    "\n",
    "Одним из самых популярных адаптивных оптимизаторов является Adam. \n",
    "Получается он за счет объединения идеи с инерцией и идеи с суммой квадратов. \n",
    "\n",
    "$$ m_t = \\beta_1 m_{t-1} + (1-\\beta_1) (\\nabla_w L(x,y,w_t)) $$\n",
    "$$ v_t = \\beta_2 v_{t-1} + (1-\\beta_2) (\\nabla_w L(x,y,w_t)^2) $$\n",
    "$$ w = w - \\eta \\cdot \\frac{m_t}{\\sqrt{v_t} + e} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы в начале у нас получались очень большие шаги, будем дополнительно модицифировать инерцию и сумму квадратов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ m_t = \\frac{m_t}{1-\\beta_1^t} $$\n",
    "\n",
    "$$ v_t = \\frac{v_t}{1-\\beta_2^t} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.Adam([parameters], betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "\n",
    "\n",
    "history = train_model_sep(model, optimizer, model_name=\"adam\")\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_data(hooks_data_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2-loss\n",
    "\n",
    "Все оптимизаторы так же поддерживают возможность добавления к ним напрямую L2-loss, коэффициент перед этим лоссом -  $\\textrm{weight_decay}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.RMSprop([parameters], alpha=0.99, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нюанс в том, что в Adam L2-loss учитывается не совсем верно. Потому есть поправленная версия Adam - AdamW. Но не факт, что она всегда лучше работает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение оптимизаторов \n",
    "\n",
    "У каждого из предложенных оптимизаторов есть минусы и плюсы \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы с инерцией сходятся к решению более плавно, но могут \"перелетать\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/convergence_optimizers.gif\" width=\"250\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы с адаптивным learning rate быстрее сходятся, более стабильны и меньше случайно блуждают"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/methods_with_adaptive_learning_rate.gif\" width=\"250\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Алгоритмы без адаптивного learning rate сложнее выбираются из локальных минимумом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/methods_without_adaptive_learning_rate.gif\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы с инерцией осцилируют в седловых точках прежде чем найти верный путь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/methods_with_momentum_in_saddle_point.gif\" width=\"450\">\n",
    "\n",
    "<p><em>Иллюстрации <a href=\"https://imgur.com/a/Hqolp\">Alec Radford</a></p> </em>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Режимы обучения\n",
    "\n",
    "Нам не обязательно поддерживать один и тот же learning rate в течение всего обучения. Более того, для того же SGD есть гарантии, что если правильно подобрать схему уменьшения learning rate, он сойдется к глобальному оптимуму.\n",
    "\n",
    "\n",
    "Мы можем менять learning rate по некоторым правилам.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ранняя остановка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем использовать критерий ранней остановки - когда лосс на валидационной выборке не улучшается какое-то количество эпох(patience), умножаем learning rate на некое значение(factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/early_stopping.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                 'min',\n",
    "                                                 factor=0.1,\n",
    "                                                 patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим к нашей модели\n",
    "\n",
    "(выполнение занимает ~ 5 минут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_sep_scheduler(model, optimizer, scheduler, model_name=None, n_epochs=5):\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history['model_name'] = model_name\n",
    "    train_history['loss_on_train'] = []\n",
    "    train_history['loss_on_test'] = []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        loss_on_train = train_epoch(model,\n",
    "                                    optimizer,\n",
    "                                    criterion,\n",
    "                                    train_loader)\n",
    "        model.eval()\n",
    "        val_loss, loss_on_test = validate(model,\n",
    "                                   criterion,\n",
    "                                   test_loader)\n",
    "        train_history['loss_on_train'].extend(loss_on_train)\n",
    "        train_history['loss_on_test'].extend(loss_on_test)\n",
    "        scheduler.step(val_loss)\n",
    "    return train_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                 'min',\n",
    "                                                 factor=0.1,\n",
    "                                                 patience=1)\n",
    "\n",
    "\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "history = train_model_sep_scheduler(model,\n",
    "                                    optimizer,\n",
    "                                    scheduler,\n",
    "                                    model_name=\"reduce_lr_on_plateu\",\n",
    "                                    n_epochs=15)\n",
    "plot_history(history, n_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Понижение шага обучения на каждой эпохе \n",
    "\n",
    "Домножать learning rate на gamma каждую эпоху"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                            step_size=2,\n",
    "                                            gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclical learning schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем не все время понижать learning rate, а делать это циклически - то понижать, то повышать. Делать это можно по-разному:\n",
    "\n",
    "\n",
    "1. Постоянно оставлять одни и те же границы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/cyclical_learning_schedule_permanent_confines.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Уменьшать верхнюю границу во сколько-то раз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/cyclical_learning_schedule_reduce_confines.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/cyclical_learning_schedule_reduce_confines_smooth.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нюанс - здесь мы ОБЯЗАТЕЛЬНО должны хранить модель с лучшим качеством. Такая оптимизация не гарантирует, что в конце модель будет лучше, чем на каком-то промежуточном шаге"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбираем границы learning rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Просто берем и либо делаем для каждого learning rate минимизацию одну эпоху (чтобы всю выборку увидеть), нейросетку для каждого значения learning rate инициализируем заново\n",
    "\n",
    "Это долго\n",
    "\n",
    "Потому  делаем \"магию\":\n",
    "\n",
    "2. На каждое значение learning rate у нас будет лишь один батч, нейросетку для каждого learning rate не меняем. И это часто работает, так как нам нужна просто грубая прикидка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/optimal_learning_rate_range.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Transfer Learning In NLP](https://medium.com/modern-nlp/transfer-learning-in-nlp-f5035cc3f62f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные значения (оптимальные границы)  используем в качестве высокого и низкого порога на learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_lr = 1e-8\n",
    "end_lr = 10\n",
    "lr_find_epochs = 2\n",
    "steps = lr_find_epochs * len(train_loader)\n",
    "smoothing = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "lrs = []\n",
    "losses = []\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-8)\n",
    "lr_lambda = lambda x: math.exp(x * math.log(end_lr / start_lr) / (steps))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "for epoch in tqdm(range(lr_find_epochs)):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x_train, y_train = batch\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "        y_pred = model(x_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        loss = loss.detach().cpu().numpy()\n",
    "        if len(losses) > 1:\n",
    "            loss = smoothing * loss + (1 - smoothing) * losses[-1]\n",
    "        losses.append(loss)\n",
    "        lr_step = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
    "        lrs.append(lr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"LR range selection\", size=15)\n",
    "plt.plot(np.log10(lrs), losses)\n",
    "plt.xlabel(\"Learning rate (log10)\",size=15)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом графике нам нужен минимум. Это в районе 1e-1. Делим это число на 10. \n",
    "Нижняя граница, стало быть - 1e-2.\n",
    "\n",
    "Снижение лосса начинается с learning rate в районе 1e-4. Его делим на 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lr = 1e-4 / 6\n",
    "max_lr = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот scheduler надо применять после каждого батча. Потому перепишем train_epoch_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_sh(model,\n",
    "                   optimizer,\n",
    "                   scheduler,\n",
    "                   criterion,\n",
    "                   train_loader):\n",
    "    loss_history = []\n",
    "    for batch in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        x_train, y_train = batch # parse data\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "        y_pred = model(x_train) # get predictions\n",
    "        loss = criterion(y_pred, y_train) # compute loss\n",
    "        loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запускаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=min_lr)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CyclicLR(optimizer,\n",
    "                                        base_lr=min_lr,\n",
    "                                        max_lr=max_lr,\n",
    "                                        mode=\"triangular\")  # first case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По-хорошему, в коде ниже мы на каждой эпохе сохраняем лучшую модель. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def train_model_cycle_sh(model, optimizer, scheduler, model_name=None, n_epochs=5):\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history['model_name'] = model_name\n",
    "    train_history['loss_on_train'] = []\n",
    "    train_history['loss_on_test'] = []\n",
    "\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        loss_on_train = train_epoch_sh(model,\n",
    "                                       optimizer,\n",
    "                                       scheduler,\n",
    "                                       criterion,\n",
    "                                       train_loader)\n",
    "        model.eval()\n",
    "        val_loss, loss_on_test = validate(model,\n",
    "                                   criterion,\n",
    "                                   test_loader)\n",
    "        train_history['loss_on_train'].extend(loss_on_train)\n",
    "        train_history['loss_on_test'].extend(loss_on_test)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = deepcopy(model)\n",
    "    return best_model, train_history\n",
    "\n",
    "\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "best_model, history = train_model_cycle_sh(model,\n",
    "                                           optimizer,\n",
    "                                           scheduler,\n",
    "                                           model_name=\"sgd_cycle_lr\",\n",
    "                                           n_epochs=15)\n",
    "plot_history(history, n_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network WarmUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также, для достаточно больших нейронных сетей практикуют следующую схему (**gradual warmup**, [изначальная статья](https://arxiv.org/pdf/1706.02677.pdf)):\n",
    "\n",
    "Поставить изначальный learning rate значительно ниже того, с которого мы обычно начинаем обучение. За несколько эпох, например, 5, довести learning rate от этого значения до требуемого. За счет этого нейросеть лучше \"адаптируется\" к нашим данным. \n",
    "\n",
    "Также такой learning schedule позволяет адаптивным оптимизаторам лучше оценить значения learning rate для разных параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/neural_network_warmup.png\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kn на картинке - это размер одного батча"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взаимодействие learning schedule и адаптивного изменения learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И то, и другое меняет learning rate: learning scheduler - глобально, а адаптивные оптимизаторы - для каждого веса отдельно \n",
    "\n",
    "Часто их применяют вместе, особенно в случае критерия ранней остановки и WarmUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в случае циклического режима обучения так делают не всегда. Дело в том, что одна из его задач - как раз избежать использования адаптивных оптимизаторов, требующих бОльше памяти и дополнительных вычислений. \n",
    "\n",
    "Однако никаких препятствий к использованию того же Adam в компании вместе с циклическим режимом обучения нет. В [исходной статье](https://arxiv.org/pdf/2004.02401.pdf) так делают. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"6\"/> Ссылки:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A journey into Optimization algorithms for Deep Neural Networks](https://theaisummer.com/optimization/)\n",
    "\n",
    "[Optimizers Explained - Adam, Momentum and Stochastic Gradient Descent](https://mlfromscratch.com/optimizers-explained/#adam)\n",
    "\n",
    "[Батч-нормализация. In-layer normalization techniques for training very deep neural networks](https://theaisummer.com/normalization/)\n",
    "\n",
    "[Циклический learning rate](https://towardsdatascience.com/adaptive-and-cyclical-learning-rates-using-pytorch-2bf904d18dee)\n",
    "\n",
    "[Разные функции активации, затухающие и взрывающиеся градиенты и т.д](https://mlfromscratch.com/activation-functions-explained/#/)\n",
    "\n",
    "[Визуализация разных оптимизаторов в ipynb, но на tensorflow](https://nbviewer.jupyter.org/github/ilguyi/optimizers.numpy/blob/master/optimizer.tf.all.opt.plot.ipynb)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
