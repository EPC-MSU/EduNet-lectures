{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Улучшение сходимости нейросетей и борьба с переобучением</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сигмоида затухает и теоретически, и практически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные, создадим сеть, обучим ее и посмотрим на практике, как проходит обучение.\n",
    "\n",
    "Загрузим **датасет MNIST**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# transforms for data\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.13), (0.3))]\n",
    ")\n",
    "\n",
    "train_set = MNIST(root=\"./MNIST\", train=True, download=True, transform=transform)\n",
    "test_set = MNIST(root=\"./MNIST\", train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "clear_output()\n",
    "print(\"Already downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим сеть с **сигмоидой** в качестве функции активации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleMNIST_NN(nn.Module):\n",
    "    def __init__(self, n_layers, activation=nn.Sigmoid):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers  # Num of layers\n",
    "        self.activation = activation()\n",
    "        layers = [nn.Linear(28 * 28, 100), self.activation]  # input layer\n",
    "        for _ in range(n_layers - 1):  # append num of layers\n",
    "            layers.append(nn.Linear(100, 100))\n",
    "            layers.append(self.activation)\n",
    "        layers.append(nn.Linear(100, 10))  # 10 classes\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # reshape to [-1, 784]\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для визуализации результатов обучения моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(scalars, weight):\n",
    "    last = scalars[0]\n",
    "    smoothed = []\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point\n",
    "        smoothed.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class HistoryPlotter:\n",
    "    def __init__(self):\n",
    "        # dict for safe learning history\n",
    "        self._history_dict = {}\n",
    "\n",
    "    def add(self, history):\n",
    "        \"\"\"\n",
    "        Save learning history.\n",
    "        history: dict with keys: model_name, epoсhs, loss_on_train, loss_on_test\n",
    "        \"\"\"\n",
    "        self._history_dict[history[\"model_name\"]] = history\n",
    "        self.color_list = list(mcolors.TABLEAU_COLORS.keys())\n",
    "\n",
    "    def plot(self, models, show_smooth=True, smooth_val=0.90):\n",
    "        \"\"\"\n",
    "        Plot informatiom from self._history_dict.\n",
    "        models: list of model_name (len <= 5, or extend color_list)\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(3, 1, figsize=(10, 10))\n",
    "        for model_num, model_name in enumerate(models):\n",
    "            history = self._history_dict[model_name]\n",
    "            for idx, (key, title) in enumerate(\n",
    "                zip([\"loss_on_train\", \"loss_on_test\"], [\"train loss\", \"test loss\"])\n",
    "            ):\n",
    "                epoch_len = len(history[key]) // history[\"epoсhs\"]\n",
    "                loss_len = len(history[key])\n",
    "                ticks_positions = np.arange(history[\"epoсhs\"] + 1)\n",
    "\n",
    "                if show_smooth:\n",
    "                    x = np.arange(len(history[key])) / epoch_len\n",
    "                    # Plot train loss and test loss:\n",
    "                    # 1. plot smoothing vals\n",
    "                    ax[idx].plot(\n",
    "                        x,\n",
    "                        exponential_smoothing(history[key], smooth_val),\n",
    "                        label=model_name + \" smoothed\",\n",
    "                        color=self.color_list[2 * model_num + idx],\n",
    "                    )\n",
    "                    # 2. plot raw vals\n",
    "                    ax[idx].plot(\n",
    "                        x,\n",
    "                        history[key],\n",
    "                        label=model_name + \" raw\",\n",
    "                        alpha=0.2,\n",
    "                        color=self.color_list[2 * model_num + idx],\n",
    "                    )\n",
    "                    # 3. add descriptions if it is nesessary\n",
    "                    if not ax[idx].title.get_text():\n",
    "                        ax[idx].set_title(title)\n",
    "                        ax[idx].set_xlabel(\"epochs\")\n",
    "                        ax[idx].set_ylabel(\"loss\")\n",
    "                        ax[idx].set_xticks(ticks_positions)\n",
    "                        ax[idx].set_xticklabels(np.arange(history[\"epoсhs\"] + 1))\n",
    "                    ax[idx].legend()\n",
    "\n",
    "                # Plot mean train and test loss combined:\n",
    "                # 1. calculate mean and std\n",
    "                mean_loss_on_epoch = [\n",
    "                    np.mean(history[key][i : i + epoch_len])\n",
    "                    for i in range(0, loss_len, epoch_len)\n",
    "                ]\n",
    "                std_loss_on_epoch = [\n",
    "                    np.std(history[key][i : i + epoch_len])\n",
    "                    for i in range(0, loss_len, epoch_len)\n",
    "                ]\n",
    "                # 2. plot\n",
    "                ax[2].errorbar(\n",
    "                    np.arange(history[\"epoсhs\"]) + idx / 30.0,\n",
    "                    mean_loss_on_epoch,\n",
    "                    yerr=std_loss_on_epoch,\n",
    "                    capsize=5,\n",
    "                    fmt=\"X--\",\n",
    "                    label=model_name + \" \" + title,\n",
    "                )\n",
    "                # 3. add descriptions if it is necessary\n",
    "                if not ax[2].title.get_text():\n",
    "                    ax[2].set_title(\"\\nAverage loss per epoch\", {\"fontsize\": 12})\n",
    "                    ax[2].set_xticks(np.arange(history[\"epoсhs\"]))\n",
    "                    ax[2].set_xticklabels(np.arange(history[\"epoсhs\"]))\n",
    "                    ax[2].set_xlabel(\"epochs\")\n",
    "                    ax[2].set_ylabel(\"loss\")\n",
    "                ax[2].legend()\n",
    "        plt.subplots_adjust(hspace=0.4)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter = HistoryPlotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения сети на обучающей выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# compute on cpu or gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, criterion, train_loader):\n",
    "    loss_history = []\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x_train, y_train = batch  # parse data\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device)  # compute on gpu\n",
    "        y_pred = model(x_train)  # get predictions\n",
    "        loss = criterion(y_pred, y_train)  # compute loss\n",
    "        loss_history.append(loss.cpu().detach().item())  # write loss to log\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для валидации сети на валидационной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, val_loader):\n",
    "    cumloss = 0\n",
    "    loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_train, y_train = batch  # parse data\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device)  # compute on gpu\n",
    "            y_pred = model(x_train)  # get predictions\n",
    "            loss = criterion(y_pred, y_train)  # compute loss\n",
    "            loss_history.append(loss.cpu().detach().item())  # write loss to log\n",
    "            cumloss += loss\n",
    "    return cumloss / len(val_loader), loss_history  # mean loss and history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, model_name=None, num_epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history[\"model_name\"] = model_name\n",
    "    train_history[\"epoсhs\"] = num_epochs\n",
    "    train_history[\"loss_on_train\"] = []\n",
    "    train_history[\"loss_on_test\"] = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        loss_on_train = train_epoch(model, optimizer, criterion, train_loader)\n",
    "        _, loss_on_test = validate(model, criterion, test_loader)\n",
    "        train_history[\"loss_on_train\"].extend(loss_on_train)\n",
    "        train_history[\"loss_on_test\"].extend(loss_on_test)\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим и запустим обучение модели с **2-мя скрытыми слоями** и одним выходным слоем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"n_layers2_sigmoid\"\n",
    "model = SimpleMNIST_NN(n_layers=2).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "history = train_model(model, optimizer, model_name=model_name)\n",
    "history_plotter.add(history)\n",
    "history_plotter.plot([model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь посмотрим на модель **с 3-мя скрытыми слоями** и одним выходным слоем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"n_layers3_sigmoid\"\n",
    "model = SimpleMNIST_NN(n_layers=3).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "history = train_model(model, optimizer, model_name=model_name)\n",
    "history_plotter.add(history)\n",
    "history_plotter.plot([\"n_layers2_sigmoid\", model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:** На самом деле, если увеличить learning rate, размер батча или число нейронов, то нейросеть начнет учиться. Это — учебный пример, чтобы показать, что и такое бывает.\n",
    "\n",
    "Нейросеть с тремя слоями вообще **не учится**. Почему? Можем попробовать разобраться.\n",
    "\n",
    "Для этого напишем функции, которые будут следить за **распределением градиентов** и **активаций** на наших слоях.\n",
    "\n",
    "Воспользуемся методом `register_backward_hook` библиотеки PyTorch для того, чтобы выполнять эти функции при каждом пропускании градиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_forward_hook(history_dict, key):\n",
    "    def forward_hook(self, input_, output):\n",
    "        history_dict[key] = input_[0].cpu().detach().numpy().flatten()\n",
    "\n",
    "    return forward_hook\n",
    "\n",
    "\n",
    "def get_backward_hook(history_dict, key):\n",
    "    def backward_hook(grad):  # for tensors\n",
    "        history_dict[key] = grad.abs().cpu().detach().numpy().flatten()\n",
    "\n",
    "    return backward_hook\n",
    "\n",
    "\n",
    "def register_model_hooks(model):\n",
    "    cur_ind = 0\n",
    "    hooks_data_history = defaultdict(list)\n",
    "    for child in model.layers.children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            forward_hook = get_forward_hook(\n",
    "                hooks_data_history, f\"sigmoid_out_{cur_ind}\"\n",
    "            )\n",
    "            child.register_forward_hook(forward_hook)\n",
    "\n",
    "            cur_ind += 1\n",
    "            backward_hook = get_backward_hook(\n",
    "                hooks_data_history, f\"gradient_linear_{cur_ind}\"\n",
    "            )\n",
    "            child.weight.register_hook(backward_hook)\n",
    "    return hooks_data_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим обучение **модели с 3 слоями**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN(n_layers=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "\n",
    "model_name = \"n_layers3_sigmoid2\"\n",
    "history = train_model(model, optimizer, model_name=model_name)\n",
    "history_plotter.add(history)\n",
    "history_plotter.plot([\"n_layers2_sigmoid\", model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hooks_data(hooks_data_history):\n",
    "    keys = hooks_data_history.keys()\n",
    "    n_layers = len(keys) // 2\n",
    "\n",
    "    activation_names = [f\"sigmoid_out_{i}\" for i in range(1, n_layers)]\n",
    "    activations_on_layers = [\n",
    "        hooks_data_history[activation] for activation in activation_names\n",
    "    ]\n",
    "\n",
    "    gradient_names = [f\"gradient_linear_{i + 1}\" for i in range(n_layers)]\n",
    "    gradients_on_layers = [hooks_data_history[gradient] for gradient in gradient_names]\n",
    "\n",
    "    for plot_name, values, labels in zip(\n",
    "        [\"activations\", \"gradients\"],\n",
    "        [activations_on_layers, gradients_on_layers],\n",
    "        [activation_names, gradient_names],\n",
    "    ):\n",
    "        fig, ax = plt.subplots(1, len(labels), figsize=(14, 4), sharey=\"row\")\n",
    "        for label_idx, label in enumerate(labels):\n",
    "            ax[label_idx].boxplot(values[label_idx], labels=[label])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hooks_data(hooks_data_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что градиент нашей модели стремительно затухает. Первые слои (до которых градиент доходит последним), получают значения градиента, мало отличимые от нуля.\n",
    "\n",
    "Причем, это будет верно с самых первых шагов обучения нашей модели.\n",
    "\n",
    "Это явление получило название **паралич сети**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Затухание градиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откуда оно берется?\n",
    "\n",
    "Посмотрим на обычную сигмоиду\n",
    "\n",
    "$$\\sigma(z) = \\dfrac 1 {1 + e^{-z}}$$\n",
    "\n",
    "Ее производная, как мы уже выводили, равна\n",
    "\n",
    "$$\\dfrac {\\partial \\sigma(z)} {\\partial z} = \\sigma(z) (1 - \\sigma(z))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/activation_function_sigmoid.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое максимальное значение у такой функции?\n",
    "\n",
    "Сигмоида находится в пределах от 0 до 1. **Максимальное значение производной** по сигмоиде  $=\\dfrac 1 4$\n",
    "\n",
    "Теперь возьмем простую нейронную сеть:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/simple_nn_with_sigmoid.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем у нее градиент\n",
    "\n",
    "$$\\dfrac {\\partial L} {\\partial z_4} = \\dfrac {\\partial L} {\\partial y} \\dfrac {\\partial y} {\\partial z_4} = \\dfrac {\\partial L} {\\partial y} \\dfrac {\\partial \\sigma(w_5z)} {\\partial z} w_5 \\le \\dfrac 1 4 \\dfrac {\\partial L} {\\partial y}  w_5 $$\n",
    "\n",
    "Аналогично можно посчитать градиент для $z_3$\n",
    "\n",
    "$$\\dfrac {\\partial L} {\\partial z_3} = \\dfrac {\\partial L} {\\partial z_4} \\dfrac {\\partial z_4} {\\partial z_3} \\le \\dfrac {\\partial L} {\\partial y} \\dfrac {\\partial \\sigma(w_4z)} {\\partial z} w_5 \\le \\left({\\dfrac 1 4}\\right)^2 \\dfrac {\\partial L} {\\partial y}  w_5 w_4$$\n",
    "\n",
    "И так далее\n",
    "\n",
    "$$\\dfrac {\\partial L} {\\partial x}  \\le \\left({\\dfrac 1 4}\\right)^5 \\dfrac {\\partial L} {\\partial y}  w_5 w_4 w_3 w_2 w_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом:\n",
    "* градиент начинает **экспоненциально затухать**, если **веса маленькие**;\n",
    "\n",
    "* если **веса большие**, то градиент наоборот начнет **экспоненциально возрастать** (взрыв градиента).\n",
    "\n",
    "Для некоторых функций активации картина будет не столь катастрофична, но тоже неприятна.\n",
    "При выполнении заданий вы посмотрите, например, как ведет себя функция **ReLU** в этом случае."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте подумаем, что можно сделать с нейронной сетью, чтобы она начала учиться. В начале рассмотрим методы, **не изменяющие структуру сети** (без добавления дополнительных слоев), также зафиксируем количество нейронов и параметры оптимизатора.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация входов и выходов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с уже знакомого: **нормализация**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация входных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим себе, что данные, которые мы подаем в нейросеть, распределены следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/data_before_normalization.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фактически нейросети работают со скалярными произведениями. В этом плане два вектора, изображенные на рисунке, **не сильно отличаются**. Также и точки нашего датасета слабо разделимы. Чтобы с этим работать, нейросеть сначала должна подобрать **удобное преобразование**, а затем только сравнивать наши объекты. Понятно, что это усложняет задачу.\n",
    "\n",
    "Для того, чтобы облегчить нейросети задачу, входные признаки часто **нормируют**:\n",
    "\n",
    "$$x1' = \\dfrac {x1 - \\mu_{x1}} {\\sigma_{x1}}$$\n",
    "\n",
    "$$x2' = \\dfrac {x2 - \\mu_{x2}} {\\sigma_{x2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/data_after_normalization.png\" width=\"450\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Такое преобразование действительно помогает нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Large J(w,b) = \\frac1m \\sum L(\\hat{y^i}, y^i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/normalization_helps_find_minimum_of_function.png\" width = \"900\"></center>\n",
    "\n",
    "<center><em>Нормализация позволяет искать минимум целевой функции удобнее и быстрее</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация целевых значений в задаче регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ряде приложений также нужна **нормализация выходных значений**, например, в задаче **регрессии**. Существует несколько причин, почему это необходимо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взрыв градиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В большинстве случаев, мы **нормализуем входные данные**, чтобы среднее значение было 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = torch.randn((512, 100))  # Fake normalized data\n",
    "plt.hist(x.mean(dim=0), bins=20)\n",
    "plt.show()\n",
    "print(f\"X mean: {x.mean().item():.2f} X variance: {x.var().item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого мы определенным **случайным образом инициализируем веса**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(100, 50),  # weights randomly sampled from some random distribution\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(50, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса **нормально распределены вокруг нуля**:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = net[0].weight.data.numpy()\n",
    "plt.hist(weights.flatten(), bins=20)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Weights mean: {weights.mean():.2f},  Weights variance: {weights.var():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необученная сеть будет чаще всего предсказывать значения порядка $10^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(x)\n",
    "plt.hist(out.detach().numpy(), bins=20)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Out mean: {out.mean().item():.2f}, Out variance: {out.var().item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, мы предсказываем какую-то большую величину. Например, [стоимость дома в штате Калифорния в долларах](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) (в датасете в sklearn целевое значение отнормированно на 100 000\\$). Стоимость лежит в диапазоне от 15 000\\$ до 500 000\\$.\n",
    "\n",
    "Выберем случайные значения в этом диапазоне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake cost\n",
    "targets = torch.randint(15_000, 500_000, (512, 1), dtype=torch.float32)\n",
    "print(f\"Target example: {targets[:10].flatten()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы будем пытаться предсказывать эти значения, мы получим **очень большую ошибку**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, targets)\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Loss: {loss.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта ошибка приведет к **большим значениям градиента** (cмотрим на значения по x), **большим значениям весов** и **нестабильному обучению**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "layer_names = (\"Linear 1\", \"Sigmoid\", \"Linear 2\", \"Loss\")\n",
    "gradient_values = {}\n",
    "for layer_name, p in zip(layer_names, net.parameters()):\n",
    "    gradient_values[layer_name] = pd.Series(p.grad.detach().flatten().numpy())\n",
    "    # print(f\"{layer_name} grad: \\n {p.grad}\")\n",
    "\n",
    "gradient_values = pd.DataFrame(gradient_values)\n",
    "data_to_plot = gradient_values.melt(value_name=\"Gradient value\", var_name=\"Layer name\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(data=data_to_plot, x=\"Gradient value\", y=\"Layer name\")\n",
    "plt.grid()\n",
    "plt.title(f\"Large gradient values in the case of learning on a nonnormalized target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы **стандартизуем целевые значения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = targets.float().mean()\n",
    "std = targets.float().std()\n",
    "\n",
    "transformed_targets = (targets - mean) / std\n",
    "print(transformed_targets.flatten()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То получим ошибку на 10 порядков **меньше**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out = net(x)\n",
    "loss = criterion(out, transformed_targets)\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Loss: {loss.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И **небольшие градиенты** (cмотрим на значения по x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = (\"Linear 1\", \"Sigmoid\", \"Linear 2\", \"Loss\")\n",
    "gradient_values = {}\n",
    "for layer_name, p in zip(layer_names, net.parameters()):\n",
    "    gradient_values[layer_name] = pd.Series(p.grad.detach().flatten().numpy())\n",
    "    # print(f\"{layer_name} grad: \\n {p.grad}\")\n",
    "\n",
    "gradient_values = pd.DataFrame(gradient_values)\n",
    "data_to_plot = gradient_values.melt(value_name=\"Gradient value\", var_name=\"Layer name\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(data=data_to_plot, x=\"Gradient value\", y=\"Layer name\")\n",
    "plt.grid()\n",
    "plt.title(f\"Large gradient values in the case of learning on a nonnormalized target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Dimensional регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ряде задач, например, при [**использовании нейронных сетей для моделирования физических процессов**](https://arxiv.org/abs/2007.13875), в задаче регрессии необходимо вычислять **несколько целевых значений**. При этом необходимо помнить, что в качестве функционала ошибки в задачах регрессии часто выбирается **метрика расстояния**, а физические величины могут иметь **различный порядок** и **диапазон значений**. Не самая лучшая идея — считать расстояние, когда по одной оси отложены нанометры, а по другой — килограммы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В физических задачах полезно изучить, какие нормировки используют в **численных методах** для получения [безразмерных (**dimensionless**) величин](https://www.physics.umd.edu/perg/MathPhys/content/2/pstruc/dimsDE.htm). Это может подсказать хорошую, физически обоснованную нормировку.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также полезно посмотреть в сторону [**multi-task learning**](https://www.mdpi.com/2076-3417/9/22/4748) с добавлением весов в Loss функцию и выделением специальных слоев для различных физических величин:\n",
    "$$Loss = \\sum_{i=1}^nα_i\\cdot Loss_i$$\n",
    "\n",
    "где $Loss_i$ — значение Loss отдельных выходов, $\\alpha_i$ — коэффиценты, которые являются гиперпараметрами модели и подбираются из требований к точности.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/multi-task.webp\" width=\"550\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/pdf/2007.13875.pdf\">Multi-Task Learning for Multi-Dimensional Regression:\n",
    "Application to Luminescence Sensing</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициализация весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из способов борьбы с затухающим градиентом является правильная **инициализация весов**. Как это сделать?\n",
    "\n",
    "**Идея 1:** инициализировать все веса константой.\n",
    "\n",
    "Проблема: градиент по всем весам будет одинаков, как и обновление весов. Все нейроны в слое будут учить одно и то же, или, в случае $const = 0$ и активации ReLU, [не будут учиться вообще](https://habr.com/ru/post/592711/).\n",
    "\n",
    "Вывод: в качестве начальных весов нужно выбирать различные значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Идея 2:** инициализировать веса нормальным (Гауссовским) шумом с матожиданием 0 и маленькой дисперсией.\n",
    "\n",
    "Маленькая дисперсия нужна, чтобы не получить огромные градиенты за большие изначальные ошибки в предсказании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal distribution: mu = 0, sigma = 1\n",
    "\n",
    "x = np.arange(-4, 4.1, 0.1)\n",
    "y = np.exp(-np.square(x) / 2) / np.sqrt(2 * np.pi)\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.title(\"Normal distribution: mu = 0, sigma = 1\", size=15)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема: инициализация нормальным шумом не гарантирует отсутствие взрыва или затухания градиета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Идея 3:** формализуем условия, при которых не будет происходить взрыв или затухание градиентов.\n",
    "\n",
    "1. Нам бы хотелось, чтобы **дисперсии признаков**, получаемых на каждом слое, были одинаковы (т.е мы хотим задать начальные веса таким образом, чтобы входные признаки каждого линейного слоя были **одинаково нормализованы**).\n",
    "\n",
    "Это важно, т.к. значения признаков используются при расчете градиента. Например, для линейного слоя:\n",
    "$$y = wx+b$$\n",
    "$$\\dfrac{\\partial y} {\\partial w} = x$$\n",
    "\n",
    "Запишем это условие:\n",
    "\n",
    "$$Dz^i = Dz^j. \\tag{1}$$\n",
    "\n",
    "2. Нам бы хотелось, чтобы **дисперсии градиентов** для разных слоев были одинаковы:\n",
    "\n",
    "$$D\\dfrac {\\partial L} {\\partial z^i} = D\\dfrac {\\partial L} {\\partial z^j}. \\tag{2}$$\n",
    "\n",
    "\n",
    "При выполнении этих условий градиент **не затухает** и **не взрывается**.\n",
    "\n",
    "Инициализации Ксавье и Каймин Хе пытаются выполнить эти условия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация Ксавье (Xavier Glorot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим функцию активации **гиперболический тангенс** (Tanh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/simple_nn_with_tanh.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это — [нечетная функция](https://ru.wikipedia.org/wiki/%D0%A7%D1%91%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%B8) с единичной производной в нуле. Функция и ее производная изображены ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10, 10.1, 0.1)\n",
    "y = np.tanh(x)\n",
    "dy = 1 / np.cosh(x)\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "fig, (im1, im2) = plt.subplots(2, 1, figsize=(7, 7))\n",
    "im1.set(title=\"tanh(x)\")\n",
    "\n",
    "# fmt: off\n",
    "im1.plot(x[0:51], y[0:51], \"#F9B041\",\n",
    "         x[150:201], y[150:201], \"#F9B041\",\n",
    "         x[50:96], y[50:96], \"#2DA9E1\",\n",
    "         x[105:151], y[105:151], \"#2DA9E1\",\n",
    "         x[95:106], y[95:106], \"#4AAE4D\",)\n",
    "im1.grid(True)\n",
    "im2.set(title=\"tanh'(x)\")\n",
    "im2.plot(x[0:51], dy[0:51], \"#F9B041\",\n",
    "         x[150:201], dy[150:201], \"#F9B041\",\n",
    "         x[50:96], dy[50:96], \"#2DA9E1\",\n",
    "         x[105:151], dy[105:151], \"#2DA9E1\",\n",
    "         x[95:106], dy[95:106], \"#4AAE4D\",)\n",
    "# fmt: on\n",
    "\n",
    "im2.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третья интуиция, которая нам понадобится: нам важно не попасть в <font color='#F9B041'>**оранжевые**</font>  зоны с почти нулевой производной, т.к. в этих областях градиент затухает. Мы хотим инициализировать веса таким образом, чтобы признаки, поступающие на слой активации, находились в <font color='#4AAE4D'>**зеленой**</font> области в окрестности нуля. Матожидание признаков, поступающих на слой активации, будет равно нулю\n",
    "$$E(z^i_t w_{kt})=0.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно  [показать](https://github.com/Gan4x4/ml_snippets/blob/main/Training/Weights_initipynb.ipynb), что в <font color='#4AAE4D'>**зеленой**</font> области условия $(1)$ и $(2)$ можно переписать как:\n",
    "\n",
    "$$n_iDW^i = 1$$\n",
    "$$n_{i+1}DW^i = 1$$\n",
    "\n",
    "где где $n_i$ — размерность выхода слоя i-го слоя.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если размерность слоев отличается, то условия невыполнимы одновременно:\n",
    "\n",
    " $$n_i \\ne n_{i+1}. $$\n",
    "\n",
    "На практике хорошо работает компромисс — среднее гармоническое решений первого $\\dfrac 1 {n_i}$ и второго $\\dfrac 1 {n_{i+1}}$ уравнения:\n",
    "\n",
    "$$DW^i = \\dfrac 2 {n_i + n_{i+1}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итого:** нам нужно инициализировать веса нейронов случайными величинами со следующими матожиданием и дисперсией:\n",
    "\n",
    "$$ EW^i = 0,$$\n",
    "\n",
    "$$DW^i = \\dfrac 2 {n_i + n_{i+1}}.$$\n",
    "\n",
    "Мы можем взять [равномерное распределение](https://ru.wikipedia.org/wiki/%D0%9D%D0%B5%D0%BF%D1%80%D0%B5%D1%80%D1%8B%D0%B2%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D0%B2%D0%BD%D0%BE%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5). Именно такое распределение было предложено в [статье](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf):\n",
    "\n",
    "$$W_i \\sim U[a, b ],$$\n",
    "\n",
    "где $a=-b$, так как матожидание равно 0\n",
    "\n",
    "Дисперсия которого выражается формулой:\n",
    "$$D(U[a, b]) = \\dfrac 1 {12} (b -a)^2 = \\dfrac 4 {12} b^2 = \\dfrac 1 {3} b^2.$$\n",
    "\n",
    "Получим:\n",
    "\n",
    "$$ b = \\sqrt{\\dfrac {6} {n_i + n_{i + 1}}}$$\n",
    "\n",
    "**Итого:**\n",
    "\n",
    "$$W_i \\sim U[-\\sqrt{\\dfrac {6} {n_i + n_{i + 1}}}, \\sqrt{\\dfrac {6} {n_i + n_{i + 1}}}],$$\n",
    "\n",
    "где $n_i$ — размерность выхода слоя n-го слоя.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно использовать и другие распределения, например [нормальное](https://ru.wikipedia.org/wiki/%D0%9D%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5). Для него получится:\n",
    "$$W_i \\sim N (0,  std=\\sqrt{\\dfrac{2}{n_i + n_{i + 1}}})$$\n",
    "Результат получится аналогичный.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы понять, что происходит с выходами слоя активации при использовании инициализации Xavier, рассмотрим картинку из оригинальной статьи [Xavier, Yoshua, \"Understanding the difficulty of training deep feedforward neural networks\", Aistats, 2010](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/xavier_procentile_and_deviation_with_and_without_init.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\">Understanding the difficulty of training deep feedforward neural networks</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На картинке изображена зависимость 98-[процентиля](https://en.wikipedia.org/wiki/Percentile) (отдельные маркеры) и стандартного отклонения (соединенные маркеры) значений на выходе слоя активации $tanh$ от эпохи обучения для различных слоев нейросети.\n",
    "\n",
    "Верхнее изображение — инициализация весов с помощью нормального распределения $W_i \\sim U[-\\dfrac {1} {\\sqrt{n_i}}, \\dfrac {1} {\\sqrt{n_i}} ]$. Нижнее — с использованием инициализации Xavier.\n",
    "\n",
    "На верхнем изображении видно, как значения 98-процентиля уходят в значения +1 и -1 (сначала на выходе первого слоя, потом на выходе второго и т.д.). Это значит, что для части нейронов происходит затухание градиентов (они переходят в область, отмеченную на графиках $tanh(x)$, $tanh’(x)$ <font color='#F9B041'>**оранжевым**</font>  и перестают учиться). На нижней картинке такого не происходит.\n",
    "\n",
    "Xavier используется для симметричных функций активаций, таких как **tanh** и **sigmoid**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще говоря, коэффициенты в инициализациях (числитель в формуле для дисперсии), зависят от конкретной **выбранной функции активации**.\n",
    "В PyTorch есть [функции](https://pytorch.org/docs/stable/nn.init.html) для вычисления этих коэффициентов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация Каймин Хе (Kaiming He)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для функции активации **ReLU** и ее модификаций (**PReLU**, **Leaky ReLU** и т.д.) аналогично инициализации Xavier можно расписать условия $(1)$, $(2)$. Так вводится He-инициализация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условия $(1)$, $(2)$ эквивалентны условиям:\n",
    "\n",
    "$$  \\dfrac {n_iDW^i} {2}  = 1, $$\n",
    "\n",
    "$$\\dfrac {n_{i+1}DW^i} {2} = 1.$$\n",
    "\n",
    "Можно опять взять среднее гармоническое. Но на практике берут либо $\\displaystyle \\frac 2 {n_i}$, либо $\\displaystyle \\frac 2 {n_i + 1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого получим для нормального распределения:\n",
    "\n",
    "$$W^i \\sim N(0, std=\\sqrt{\\frac 2 {n_i}})$$\n",
    "\n",
    "Для равномерного распределения:\n",
    "$$W^i \\sim U(-\\sqrt{\\frac 3 {n_i}}, \\sqrt{\\frac 3 {n_i}})$$\n",
    "\n",
    "Более подробно с выводом инициализации Каймин Хе можно ознакомиться в оригинальной [статье](https://arxiv.org/pdf/1502.01852v1.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Важность инициализации весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Нейросеть может **сойтись значительно быстрее**. Графики для активации **ReLU**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/weight_initialization_influence_convergence_neural_networks.png\" width=\"550\">\n",
    "\n",
    "<em>Source: <a href=\"https://arxiv.org/pdf/1502.01852v1.pdf\">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. В зависимости от выбранной активации сеть вообще может **сойтись или не сойтись**. Графики для активации **ReLU**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/activation_function_influence_convergence_neural_networks.png\" width=\"550\">\n",
    "\n",
    "<em>Source: <a href=\"https://arxiv.org/pdf/1502.01852v1.pdf\">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ортогональная инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой идеей является **ортогональная инициализация**.\n",
    "[Преобразование](https://ru.wikipedia.org/wiki/%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%BE%D0%B5_%D0%BE%D1%82%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5), заданное [ортогональной матрицей](https://ru.wikipedia.org/wiki/%D0%9E%D1%80%D1%82%D0%BE%D0%B3%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0), **не изменяет расстояние между точками**. Можно представить **ортогональную матрицу** как [матрицу поворота](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0_%D0%BF%D0%BE%D0%B2%D0%BE%D1%80%D0%BE%D1%82%D0%B0) (это не совсем верно, т.к. матрицы перестановки тоже ортогональны), т.е. линейный слой будет **разворачивать** карту признаков, чтобы собирать их линейные коомбинации, **не изменяя масштаб признаков**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого слоя мы убеждаемся, что изначальная матрица весов является ортогональной.\n",
    "\n",
    "Выберем ортогональную матрицу весов\n",
    "$$W: WW^T = 1$$\n",
    "\n",
    "Тогда:\n",
    "1.  Норма активации сохраняется (опять же, активации между слоями остаются в одном масштабе):\n",
    "$$||s_{i+1}|| = ||W_{i}s_i|| = ||s_i||$$\n",
    "\n",
    "2.  Все нейроны делают «разные» преобразования:\n",
    "$$ ⟨W_i, W_j⟩ = 0~i \\ne j$$\n",
    "$$ ⟨W_i, W_j⟩ = 1~i = j$$\n",
    "\n",
    "\n",
    "Замечание: т.к. ортогональные матрицы бывают только квадратные, то этот метод подходит только для слоев с одинаковым количеством входных и выходных значений.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда такая инициализация обеспечивает значительно лучшую сходимость, [тут](https://arxiv.org/pdf/1312.6120.pdf) можно почитать об этом подробнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация весов в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для инициализации весов PyTorch используется модуль `torch.nn.init`\n",
    "\n",
    "В нем определены разные функции для инициализации весов.\n",
    "\n",
    "Нюанс состоит в том, что обычно для слоев разного типа может требоваться разная инициализация. Поэтому в функции, которая инициализирует слои вашей нейронной сети, желательно прописывать разное поведение для разных слоев.\n",
    "\n",
    "Попробуем, например, добавить в нашу нейросеть инициализацию. Нам нужна инициализация Xavier, так как у нас `nn.Sigmoid`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `torch.nn.init.calculate_gain` возвращает рекомендуемое значение коэффициента масштабирования для стандартного отклонения заданной функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMNIST_NN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layers, activation=nn.Sigmoid, init_form=\"normal\"):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.activation = activation()\n",
    "        layers = [nn.Linear(28 * 28, 100), self.activation]\n",
    "        for _ in range(0, n_layers - 1):\n",
    "            layers.append(nn.Linear(100, 100))\n",
    "            layers.append(self.activation)\n",
    "        layers.append(nn.Linear(100, 10))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.init_form = init_form\n",
    "        if self.init_form is not None:\n",
    "            self.init()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "    # xavier weight initialization\n",
    "    def init(self):\n",
    "        sigmoid_gain = torch.nn.init.calculate_gain(\"sigmoid\")\n",
    "        for child in self.layers.children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                if self.init_form == \"normal\":\n",
    "                    torch.nn.init.xavier_normal_(child.weight, gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                elif self.init_form == \"uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(child.weight, gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                else:\n",
    "                    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим обучение модели с инициализацией весов Xavier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN(n_layers=3, init_form=\"normal\").to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# plotting weights values of first(input layer)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.hist(\n",
    "    list(model.layers.children())[0].weight.cpu().detach().numpy().reshape(-1), bins=100\n",
    ")\n",
    "plt.title(\"weights histogram\")\n",
    "plt.xlabel(\"values\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.show()\n",
    "\n",
    "model_name = \"n3_layers_sigmoid_havier\"\n",
    "history = train_model(model, optimizer, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter.add(history)\n",
    "history_plotter.plot([\"n_layers3_sigmoid\", model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что нейросеть стала хоть как-то учиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Слои нормализации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariate shift (Ковариантный сдвиг)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Covariate shift** &mdash; явление, когда признаки тренировочной и тестовой выборок **распределены по-разному**. Ковариантный сдвиг может стать серьезной проблемой для практического применения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/covariate_shift.png\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель учится сопоставлять целевые значения признакам. В такой ситуации модель не в состоянии делать адекватные предсказания на тесте, так как во время обучения она не видела области пространства, в которой расположены тестовые объекты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/covariate_shift_problem.png\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделяют **два источника ошибок**, приводящих к **ковариантному сдвигу**:\n",
    "\n",
    "1. **Систематические ошибки**:\n",
    "*   *Ошибки при сборе данных* (предвзятый метод сбора данных, нерепрезентативная выборка).\n",
    "\n",
    "**Пример:** стандартные наборы данных для задачи **Face Recognition** не сбалансированы по полу, возрасту и этнической принадлежности, поэтому обученные на них модели могут плохо работать с редкими классами. Это привело к обвинениям таких корпораций, как Microsoft, IBM и Amazon, в [расизме](https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/face_recognition_racism.webp\" width=\"1000\"></center>\n",
    "<center><em>Source: <a href=\"https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/\">Racial Discrimination in Face Recognition Technology</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что делать?**\n",
    "Следить за репрезентативностью данных, использовать Importance Reweighting (при обучении давать больший вес редким объектам)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*  *Различие условий сбора данных для train и test выборки*\n",
    "\n",
    "**Пример:** Задачи компьютерного зрения. Данных для обучения может быть недостаточно, поэтому часто для обучения используют датасеты из Интернета. При этом условия съемки (качество, разрешение, освещенность) train и test выборок могут отличаться.\n",
    "\n",
    "**Что делать?** Аугментировать данные с учетом условий применения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Ошибки предобработки данных*\n",
    "\n",
    "**Пример:** В картах пациентов больницы А, использованных для train, рост пациента указан метрах, в картах пациентов больницы Б, использованных для test, рост пациента указан в футах. При составлении датасета данные не привели к одной **единице измерения**.\n",
    "\n",
    "\n",
    "**Что делать?** Искать ошибку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Нестационарная среда**\n",
    "\n",
    "При обучении мы используем ограниченный набор признаков и объектов. При этом есть факторы, которые мы можем не учесть: износ оборудования, изменение политических условий и т.д., что может приводить к постепенной или резкой деградации модели при применении ее в реальных условиях.\n",
    "\n",
    "**Что делать?**\n",
    "* Удалять из модели маловажные нестационарные признаки.\n",
    "* Дообучать модель на новых данных.\n",
    "* [Компенсировать сдвиг](https://www.researchgate.net/publication/339021786_Covariate_Shift_A_Review_and_Analysis_on_Classifiers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:** Просадка качества на test выборке может быть также связана с **проблемами обобщающей способности модели**. Причины могут быть разными, например переобучение под validate выборку или отсутствие связи между признаками и целевым значением (задача в данной постановке не решается).\n",
    "\n",
    "**Практический совет:** для быстрого обнаружения ковариантного сдвига можно **обучить модель**, которая будет предсказывать, относится ли объект к **train** или **test выборке**. Если модель легко делит данные, то имеет смысл визуализировать значения признаков, по которым она это делает.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal covariate shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В статье [“Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift”](https://arxiv.org/pdf/1502.03167.pdf) 2015 года авторы предположили, что похожее явление имеет место внутри нейросети, назвав его **internal covariate shift**.\n",
    "\n",
    "**Internal covariate shift** — это изменение распределения выхода слоя активации из-за изменения обучаемых параметров во время обучения.\n",
    "\n",
    "Пусть у нас $k$-ый нейрон $i$-го слоя переводит выход $i$-1 слоя с распределениями <font color='#F9B041'>$f^{(j)}_{i-1}(x)$</font> в новое пространство с распределением <font color='#5D5DA6'>$f^{(k)}_{i}(x)$</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/internal_covariate_shift_example.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении:\n",
    "- нейросеть делает предсказание,\n",
    "- считается значение функции потерь,\n",
    "- делается обратное распространение ошибки,\n",
    "- обновляются веса.\n",
    "\n",
    "\n",
    "После обновления весов $k$-ый нейрон $i$-го слоя будет переводить выходы $i$-1 слоя <font color='#F9B041'>$f^{(j)}_{i-1}(x)$</font> в пространство с другим распределением <font color='#5D5DA6'>$f^{*(k)}_{i}(x)$</font>.\n",
    "\n",
    "При этом $i$+1 слой учился работать со старым распределением  <font color='#5D5DA6'>$f^{(k)}_{i}(x)$</font>, и будет хуже обрабатывать <font color='#5D5DA6'>$f^{*(k)}_{i}(x)$</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плохой вариант борьбы с этим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте на каждом слое просто нормировать **каждый признак** (выход каждого нейрона), используя среднее и дисперсию по батчу\n",
    "\n",
    "$$ \\hat{x}_{i} = \\frac{x_{i} - \\mu_{B}}{\\sigma_{B} + \\epsilon}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в том, что таким образом мы можем попасть в область линейной составляющей нашей функции. Например, в случае сигмоиды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/domain_of_linear_of_sigmoid_function.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем набор линейных слоев фактически без функций активации, следовательно, все вырождается в однослойную сеть. Не то, что нам надо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам надо дать нейронной сети **возможность перемещать распределение выходов** слоя из области 0 и самой **подбирать дисперсию**. Для этой цели используется **батч-нормализация** (*batch normalization*), которая вводит в нейронную сеть дополнительную операцию между соседними скрытыми слоями. Она состоит из **нормализации** входящих (в слой батч-нормализации) значений, полученных от скрытого слоя, **масштабирования** и **сдвига** с применением двух новых параметров и передачи полученных значений на вход следующему скрытому слою."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnormalization.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры, используемые в батч-нормализации ($\\gamma$ — отвечающий за **сжатие** и $\\beta$ — отвечающий за **сдвиг**), являются **обучаемыми параметрами** (наподобие весов и смещений скрытых слоев).\n",
    "\n",
    "Помимо обучаемых параметров $\\gamma$ и $\\beta$ в слое батч-нормализации существуют также необучаемые параметры: **скользящее среднее матожидания** (_Mean Moving Average_) и **скользящее среднее дисперсий** (_Variance Moving Average_), служащие для сохранения состояния слоя батч-нормализации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnorm_layer_parameters.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры $\\gamma$, $\\beta$, а также оба скользящих средних вычисляются для каждого слоя батч-нормализации отдельно и являются векторами с **длиной, равной количеству входящих признаков.**\n",
    "\n",
    "В процессе обучения мы подаем в нейронную сеть **по одному мини-батчу за раз**. Процедуру обработки значений одного признака $x^{(k)}$ (фиолетовая колонка на изображении ниже), который для краткости мы будем обозначать $x$,  из одного мини-батча $ B = \\{x_{1},\\ldots, x_{m}\\} $ можно представить следующим образом:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batch_normalization_compute_moving_average.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаг **масштабирования** Gamma $γ$ и шаг **сдвига** Beta $β$ являются главным новшеством батч-нормализации, поскольку в отличие от предыдущего рассмотренного примера, нормированные значения больше не обязаны иметь среднее, равное 0, и единичную дисперсию. Батч-нормализация позволяет сдвигать среднее нормированных значений и масштабировать дисперсию. Фактически, теперь **нейросеть даже может отменить нормализацию входных данных, если считает ее ненужной.**\n",
    "\n",
    "Для наглядности проиллюстрируем размерности промежуточных переменных на следующем изображении:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batch_normalization_compute_moving_average_scheme.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После прямого прохода параметры $\\gamma$ и $\\beta$ **обновляются через обратное распространение ошибки** так же, как и веса скрытых слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скользящее среднее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше мы обсуждали то, что в процессе обучения слой **батч-нормализации** рассчитывает значение **среднего и дисперсии** каждого признака в соответствующем **мини-батче**. Предположим, нам нужно сделать предсказание на **одном объекте.** Во время предсказания батч у нас уже отсутствует — откуда брать среднее и дисперсию?\n",
    "\n",
    "Во время предсказания используется **скользящее среднее**, которое было **рассчитано и сохранено в процессе обучения**.\n",
    "\n",
    "$$ \\mu_{mov_{B}} = (1-\\alpha)\\mu_{mov_{B-1}}+\\alpha\\mu_{B} $$\n",
    "\n",
    "$$ \\sigma_{mov_{B}} = (1-\\alpha)\\sigma_{mov_{B-1}}+\\alpha\\sigma_{B} $$\n",
    "\n",
    "Обычно используется параметр $\\alpha = 0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для перевода модели из режима обучения в режим тестирования и обратно в PyTorch используются `model.train()` и `model.eval()`.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|c}\n",
    "\\large{\\text{model.train()}}&\\ \\large{\\text{model.eval()}}\\\\  \\hline\n",
    "\\large{\\text{Батч-нормализация использует статистику по батчу.}}&\\large{\\text{Батч-нормализация использует скользящие средние.}}\\\\\n",
    "\\large{\\text{Cкользящие средние копятся.}}\n",
    "\\end{array}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему используется именно **скользящее среднее**, а **не статистика всей обучающей выборки**?\n",
    "\n",
    "При таком подходе нам бы пришлось хранить **средние всех признаков** для **всех батчей**, пропущенных через нейросеть в ходе обучения. Это ужасно невыгодно по памяти. Вместо этого **скользящее среднее** выступает в качестве приближенной оценки **среднего и дисперсии** обучающего набора. В этом случае эффективность использования ресурсов увеличивается: нам нужно **хранить в памяти только одно число** — значение скользящего среднего, полученное на последнем шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проиллюстрировать преимущество использования скользящего среднего можно на следующем примере:\n",
    "\n",
    "Предположим, что у нас есть массив объектов, обладающих некоторым признаком $x$ (обучающая выборка), и некоторый черный ящик, извлекающий по $k$ объектов из этого массива (Dataloader). Наша задача — дать оценку ожидаемому среднему этих $k$ объектов. В данном примере для простоты будем извлекать $k$ объектов из некоего распределения случайным образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "k = 500  # sample size\n",
    "n = 2\n",
    "p = 0.5\n",
    "\n",
    "sample = np.random.negative_binomial(n, p, k)\n",
    "sns.histplot(data=sample, discrete=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценить ожидаемое среднее теоретически, не зная, как распределен признак $x$ наших объектов, трудно. Мы можем собрать **большое количество средних** и произвести оценку с их помощью, но для этого нам потребуется хранить в памяти все эти значения, что приведет к неэффективному расходу ресурсов. Более эффективным решением будет воспользоваться **скользящим средним**. Давайте сравним эти два метода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema = 0\n",
    "alpha = 0.01\n",
    "means = np.array([])\n",
    "\n",
    "for i in range(10000):\n",
    "    sample = np.random.negative_binomial(n, p, 50)\n",
    "    ema = (1 - alpha) * ema + alpha * sample.mean()\n",
    "    means = np.append(means, sample.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем количество памяти, затрачиваемое на хранение списка средних значений признака $x$ по выборкам из $k$ объектов, и **количество памяти**, затрачиваемое на хранение **скользящего среднего**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(f\"{sys.getsizeof(ema)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество памяти для хранения **списка средних**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sys.getsizeof(means)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что на хранение массива средних значений расходуется на порядки больше памяти, чем на хранение одного скользящего среднего. Теперь давайте воспользуемся тем, что мы сэмплировали случайные выборки из известного распределения, и можем теоретически рассчитать их среднее. В нашем примере мы извлекали выборки из негативного биномиального распределения с параметрами $n=2$ и $p=0.5$, для которого среднее рассчитывается по формуле $mean=\\frac{np}{1-p}=2$. Мы знаем, что при достаточно большом количестве сэмплированных выборок среднее распределения выборочных средних будет стремиться к среднему генеральной совокупности. Сравним результаты, полученные с использованием сохраненных выборочных средних и скользящего среднего с теоретическим расчетом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среднее признака $x$ по $k$ объектам, оцененное с помощью **скользящего среднего**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{ema:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среднее признака $x$ по $k$ объектам, **оцененное по всем сэмплированным выборкам**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{means.mean():.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что мы получили довольно точную оценку, использовав скользящее среднее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Защита от нулей в знаменателе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы у нас не мог возникнуть 0 в знаменателе, добавляем маленькое число — $\\epsilon$. Например, равное 1e-5\n",
    "\n",
    "\n",
    "$$ \\hat{x}_{i} = \\frac{x_{i} - \\mu_{B}}{\\sigma_{B} + \\epsilon}$$\n",
    "\n",
    "$$ BN_{\\gamma, \\beta}(x_{i}) = \\gamma \\hat{x}_{i} + \\beta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточные слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сверточный слой можно свести к линейному слою. BatchNorm можно применять и для линейных слоев, и для сверточных.\n",
    "\n",
    "Признаки внутри одного канала (одной карты признаков) получаются путем применения к исходному изображению одних и тех же преобразований. По сути **1 канал** - это **карта одного признака**. Поэтому логично, что нормализация будет происходить по каналам, а одним признаком считаться одна  **feature map**.\n",
    "Нормализация идет по всей такой feature map (по всему каналу) для всех объектов батча."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/feature_map.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PyTorch для полносвязных слоев используют [`nn.BatchNorm1d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html), а для сверточных [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Графически нормализации часто объясняют при помощи следующей схемы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/dimensions_channels_batch_samples.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*По оси абсцисс* расположены **объекты из батча**,  \n",
    "*по оси ординат* &mdash; **feature map**, преобразованный в вектор,  \n",
    "*по оси аппликат* &mdash; **каналы** (feature maps).\n",
    "\n",
    "В этом представлении **BatchNorm** для свертки выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/visualization_of_batch_normalization.png\" width=\"450\">\n",
    "\n",
    "[Batch Normalization](https://paperswithcode.com/method/batch-normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/batchnorm_efficiency.png\" width=\"550\">\n",
    "\n",
    "<em>Source: <a href=\"https://arxiv.org/pdf/1502.03167.pdf\">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shiftn</a></em>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот метод действительно работает.\n",
    "Видим, что нейросети с батч-нормализацией:\n",
    "\n",
    "1. **Сходятся быстрее**, чем нейросети без неё.\n",
    "2. Могут работать с **более высоким начальным значением learning rate**, причем это позволяет достигать лучших результатов.\n",
    "3. Работают даже с функцией активации в виде **сигмоиды**. Без **BatchNorm** такая сеть не обучилась бы вовсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисление **градиента BatchNorm** — интересное упражнение на понимание того, как работает **backpropagation**. В лекции мы это опускаем, можете ознакомиться самостоятельно:\n",
    "\n",
    "[Deriving the Gradient for the Backward Pass of Batch Normalization](https://kevinzakka.github.io/2016/09/14/batch_normalization/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization как регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему для нейросети с батчнормализацией можно использовать более высокие learning rate?\n",
    "\n",
    "Оказывается, **батч-нормализация** делает **неявную регуляризацию на веса**.\n",
    "\n",
    "Допустим, мы решили **увеличить веса** в $a$ раз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы шкалируем, то домножение весов $W$ на константу выходных значений слоя не меняет\n",
    "\n",
    "$$BN((aW)u) = BN(Wu)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиент слоя по входу не меняется\n",
    "\n",
    "$$\\dfrac {\\partial BN((aW)u)} {\\partial u} = \\dfrac {\\partial BN(Wu)} {\\partial u}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А **градиент по весам уменьшается** в $a$ раз\n",
    "\n",
    "$$\\dfrac {\\partial BN((aW)u)} {\\partial aW} = \\dfrac 1 a \\dfrac {\\partial BN(Wu)} {\\partial W} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, нейросеть автоматически не дает большим весам расти"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сглаживающий эффект Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Normalization** была разработана на идее необходимости коррекции **Internal covariate shift**. В 2019 году вышла статья [How Does Batch Normalization Help Optimization?](https://arxiv.org/pdf/1805.11604.pdf), которая показала, что влияние коррекции **Internal covariate shift** на качество обучения не так велико, как считали авторы **Batch Normalization**.\n",
    "\n",
    "Другим интересным эффектом Batch Normalization оказалось **сглаживание ландшафта** функции потерь. Batch Normalization улучшает гладкость пространства решений и облегчает поиск в нем минимума. Именно благодаря сглаживанию ландшафта Batch Normalization справляется с затуханием и взрывом градиента.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnorm_helps_find_minimum_of_function.jpg\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Советы по использованию Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит помнить, что с батч-нормализацией:\n",
    "\n",
    "* **Крайне важно** перемешивать объекты (составлять новые батчи) между эпохами. Единицей обучения параметров $\\beta$ и $\\gamma$ являются батчи. Если их не перемешивать, то из 6400 объектов в тренировочном датасете получим лишь 100 объектов (при условии, что в батче 64 объекта) для обучения $\\beta$ и $\\gamma$.\n",
    "\n",
    "* В слое, после которого поставили Batch Normalization, надо **убрать bias** (параметр $\\beta$ в BatchNormalization берет эту роль на себя).\n",
    "\n",
    "\n",
    "* Другое расписание **learning rate: большее значение** в начале обучения и быстрое уменьшение в процессе обучения.\n",
    "\n",
    "\n",
    "* Чем **меньше размер батча в обучении**, тем **хуже** будет работать BatchNormalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/batchnorm_batch_size.png\" width=\"550\">\n",
    "\n",
    "<em>Source: <a href=\"https://arxiv.org/pdf/1803.08494.pdf\">Group Normalization</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем Batch Normalization в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как наша модель из-за **Batch Normalization** ведет себя по-разному во время **обучения** и во время **тестирования**, то мы должны прямо ей сообщать, обучается она сейчас или нет. Делается это при помощи функций `model.train` и `model.eval`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_model_sep(model, optimizer, model_name=None, num_epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history[\"model_name\"] = model_name\n",
    "    train_history[\"epoсhs\"] = num_epochs\n",
    "    train_history[\"loss_on_train\"] = []\n",
    "    train_history[\"loss_on_test\"] = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        loss_on_train = train_epoch(model, optimizer, criterion, train_loader)\n",
    "        model.eval()\n",
    "        _, loss_on_test = validate(model, criterion, test_loader)\n",
    "        train_history[\"loss_on_train\"].extend(loss_on_train)\n",
    "        train_history[\"loss_on_test\"].extend(loss_on_test)\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMNIST_NN_Init_Batchnorm(nn.Module):\n",
    "    def __init__(self, n_layers):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        layers = [\n",
    "            nn.Linear(28 * 28, 100, bias=False),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Sigmoid(),\n",
    "        ]\n",
    "        for _ in range(0, n_layers - 1):\n",
    "            layers.append(nn.Linear(100, 100, bias=False))\n",
    "            layers.append(nn.BatchNorm1d(100))\n",
    "            layers.append(nn.Sigmoid())\n",
    "        layers.append(nn.Linear(100, 10))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.init()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "    def init(self):\n",
    "        sigmoid_gain = torch.nn.init.calculate_gain(\"sigmoid\")\n",
    "        for child in self.layers.children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                torch.nn.init.xavier_normal_(child.weight, gain=sigmoid_gain)\n",
    "                if child.bias is not None:\n",
    "                    torch.nn.init.zeros_(child.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "model_name = \"batchnorm2\"\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "history = train_model_sep(model, optimizer, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter.add(history)\n",
    "history_plotter.plot([\"n_layers3_sigmoid\", \"n3_layers_sigmoid_havier\", model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем, согласно советам, увеличить learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "model_name = \"batchnorm_increased_lr\"\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "history = train_model_sep(model, optimizer, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter.add(history)\n",
    "history_plotter.plot([\"n3_layers_sigmoid_havier\", \"batchnorm2\", model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ставить Batch Normalization до или после активации?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### До"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnormalization_before_activation.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Рекомендуется авторами статьи, где предложили Batch Normalization**.\n",
    "* Для **сигмоиды** BN, поставленная после активации, **не решает проблем** сигмоиды.\n",
    "* Во многих сверточных архитектурах, например [**ResNet**](https://arxiv.org/pdf/1512.03385.pdf) и [**MobileNetV2**](https://arxiv.org/pdf/1801.04381.pdf) (изучите на следующих лекциях), Batch Normalization ставится именно так."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### После"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnormalization_after_activation.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Аргументация авторов статьи не до конца обоснована**.\n",
    "* Обычно, **сигмоиду не используют** в современных нейронных сетях.\n",
    "* Для популярной **ReLU BN**, поставленная до активации, может приводить к “умирающей **ReLU**”, когда большая часть ее входов меньше 0, и поэтому через них градиент не проходит.\n",
    "* На многих задачах BN после функции активации **работает лучше** или не хуже поставленной до."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BN — before or after ReLU?**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/batchnormalization_before_or_after_relu.png\" width=\"500\">\n",
    "\n",
    "<em>Source: <a href=\"https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md\">BN experiments</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** можно экспериментировать с расположением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другие Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует большое количество иных нормализаций, их неполный список можно найти [здесь](https://paperswithcode.com/methods/category/normalization). В данной секции мы рассмотрим самые популярные виды нормализации помимо **BatchNorm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/normalization_methods.png\" width=\"900\">\n",
    "\n",
    "<center><em>Source: <a href=\"https://paperswithcode.com/method/layer-normalization\">Layer Normalization</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо свёрточных нейронных сетей, существует специальный тип нейронных сетей, используемых для обработки последовательностей. Называется он \"**рекуррентные нейронные сети**\", ему будет посвящена следующая лекция.\n",
    "\n",
    "Когда оказалось, что **BatchNorm** положительно сказывается на обучении нейронных сетей, его попытались применить для различных архитектур. BatchNorm нельзя было использовать \"из коробки\" для рекуррентных нейронных сетей (работающих с последовательными данными), пришлось придумывать различные адаптации, среди которых наиболее удачной оказалась **Layer Normalization**.\n",
    "\n",
    "По сути, теперь нормализация происходит внутри **одного объекта из батча**, а не поканально в рамках батча. С математической точки зрения, данная \"адаптация\" отличается от **BatchNorm**, однако экспериментально она превзошла своих конкурентов в задаче нормализации при обработке последовательных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Впоследствии данный метод нормализации хорошо проявил себя в **трансформерах** — наследниках рекуррентных нейронных сетей в вопросах обработки последовательных данных (об этом типе нейросетей мы также поговорим на следующей лекции). После успешного применения трансформеров в задачах компьютерного зрения, **LayerNorm** стал использоваться и в компьютерном зрении (хотя и уступал BatchNorm при использовании в свёрточных нейронных сетях)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/visualization_of_layer_normalization.png\" width=\"450\">\n",
    "\n",
    "[Layer Normalization](https://paperswithcode.com/method/layer-normalization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий вид нормализации был предложен отечественными исследователями (из Сколтеха), занимавшимися разработкой быстрого и эффективного способа **переноса стиля** с одного изображения на другое.\n",
    "\n",
    "При использовании BatchNorm теряется информация о контрастах на конкретном изображении, поскольку нормализация производится по нескольким объектам. Для сохранения *контрастов* в экземпляре (*instance*) изображения была предложена специальная нормализация, рассматривающая конкретный канал одного конкретного объекта. Было предложено два названия нормализации: связанное с мотивацией (contrast normalization) и связанное с принципом работы (**instance normalization**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/visualization_of_instance_normalization.png\" width=\"450\">\n",
    "\n",
    "[Instance Normalization](https://paperswithcode.com/method/instance-normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В течение долгого времени BatchNorm оставался однозначным фаворитом для использования в задачах компьютерного зрения, однако:\n",
    "1. В связи с необходимостью точно считать статистики внутри batch, при обучении приходилось использовать большой batch size.  \n",
    "\n",
    "2. Ограниченность размера памяти видеокарты вынуждает разработчиков идти на компромисс между сложностью модели и размером батча."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, использование BatchNorm приводило к невозможности использовать сложные модели**\\***, поскольку им просто не хватало места на видеокарте.\n",
    "\n",
    "Необходимость использовать большой batch size могут решать различные нормализации, не использующие batch-размерность. К примеру, уже известные нам **Layer Norm** и **Instance Norm**. Эмпирически оказалось, что данные нормализации уступают BatchNorm по качеству работы: в то время как LayerNorm предполагает одинаковую важность и суть различных каналов (*рассматривая данные излишне глобально*), InstNorm упускает межканальные взаимодействия (*рассматривая данные слишком локально*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Успешным обобщением данных методов является **Group Normalization**: данный метод разбивает каналы на $G \\in [1; C]$ групп, присваивая каждой из них (примерно) равное количество каналов. Отметим, что при $G = 1$ GroupNorm идентичен LayerNorm, а при $G = C$ GroupNorm идентичен InstanceNorm.\n",
    "\n",
    "Эмпирически оказалось, что при замене BatchNorm на GroupNorm качество модели падает в разы менее значительно, чем при использовании LayerNorm либо InstanceNorm. Более того, при изменении batch size качество работы GroupNorm не изменялось, что открыло перспективы для создания более сложных моделей компьютерного зрения.\n",
    "\n",
    "**\\*** — подразумевается, что уменьшение batch size позволило бы создать более сложные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/visualization_of_group_normalization.png\" width=\"450\">\n",
    "\n",
    "[Group Normalization](https://paperswithcode.com/method/group-normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй способ улучшения сходимости нейросетей и борьбы с переобучением — введение регуляризации. Ее можно вводить несколькими способами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1, L2 регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже разбирали самый простой способ — добавление штрафа к весам в функцию потерь. На сходимость нейросети это, правда, влияет слабо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Loss\\_reg = loss + \\lambda \\cdot reg$$\n",
    "\n",
    "$$ reg_{L1} = \\lambda \\sum |w_i| $$\n",
    "\n",
    "$$ reg_{L2} = \\lambda \\sum w_i^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/L07/out/l1_l2_regularization_to_weight.gif\" alt=\"alttext\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда уже его хватает, чтобы решить все проблемы. Напомним, что **L2** лосс приводит к большому числу маленьких ненулевых весов в сети. А **L1** лосс — к маленькому числу ненулевых весов (разреженной нейросети)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из распространенных именно в нейросетях методом регуляризации является **Dropout**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/dropout.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Состоит этот метод в следующем:\n",
    "\n",
    "1. Во время обучения мы с вероятностью $p$ **зануляем выход нейронов** слоя (например, $p = 0.5$)\n",
    "2. Зануленные нейроны не участвуют в данном `forward`, и поэтому градиент к ним при `backward` не идет.\n",
    "3. Сила регуляризации определяется вероятностью $p$: чем она больше, тем сильнее регуляризация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Сверточные слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично **Batch Normalization**, при применении к **сверточному слою**  **Dropout** должен **убирать каналы целиком**. Dropout для полносвязного слоя реализован в PyTorch в [nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html), для сверточного — в [nn.Dropout2d](https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/dropout_2d.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мотивация Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Борьба с коадаптацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной из  проблем при работе с глубокими сетями является **совместная адаптация нейронов**. Если все весовые коэффициенты обучаются вместе, некоторые соединения будут иметь больше возможностей прогнозирования, чем другие.\n",
    "\n",
    "**Часть нейронов** делает основную работу — **предсказывает**, а остальные могут вообще не вносить никакого вклада в итоговое предсказание. Или же другая картина: один нейрон делает **неверное предсказание**, другие его **исправляют**, и в итоге первый нейрон свои ошибки не исправляет.\n",
    "\n",
    "Это явление называется **коадаптацией**. Это нельзя было предотвратить с помощью традиционной регуляризации, такой как **L1** и **L2**. А вот **Dropout** с этим хорошо борется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отключая хорошо обученные нейроны, мы заставляем плохо обученные нейроны учиться. Отключая нейроны, которые исправляют ошибки других нейронов, мы заставляем ошибающиеся нейроны исправлять ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropout** гарантирует, что выучиваемые индивидуальными нейронами функции хорошо работают со **случайно выбранными подмножествами функций**, выученных другими нейронами, улучшая **обобщающую способность** нейронов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На следующем рисунке, извлеченном из [статьи](https://jmlr.org/papers/v15/srivastava14a.html), мы находим сравнение признаков, изученных в наборе данных **MNIST** нейросетью с **одним скрытым слоем** в автоэнкодере, имеющим 256 признаков после ReLU **без Dropout** (слева), и признаков, изученных той же структурой с использованием **Dropout** в ее скрытом слое с $p = 0.5$ (справа).\n",
    "\n",
    "Первый показывает неструктурированные, беспорядочные паттерны, которые невозможно интерпретировать. Второй явно демонстрирует целенаправленное распределение весов, которое обнаруживает штрихи, края и пятна самостоятельно, нарушая их взаимозависимость с другими нейронами для выполнения этой работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/compare_weights_with_dropout_and_without_dropout.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\">Dropout: A Simple Way to Prevent Neural Networks from\n",
    "Overfitting</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout как регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фактически, **Dropout** штрафует слишком сложные, неустойчивые решения. Добавляя в нейросеть **Dropout**, мы сообщаем ей о том, что решение, которое мы ожидаем, должно быть устойчиво к шуму."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout как ансамбль"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно рассматривать **Dropout** как **ансамбль нейросетей** со схожими параметрами, которые мы учим одновременно, вместо того, чтобы учить каждую в отдельности, а затем результат их предсказания усредняем, [выключая Dropout в режиме eval](https://habr.com/ru/companies/wunderfund/articles/330814/).\n",
    "\n",
    "Таким образом, возникает аналогия со случайным лесом: каждая из наших нейросетей легко выучивает выборку и переобучается — имеет низкий bias, но высокий variance. При этом, за счет временного отключения активаций, каждая нейросеть видит не все объекты, а только часть. Усредняя все эти предсказания, мы уменьшаем variance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout помогает бороться с переобучением"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout, в силу указанного выше, может хорошо помогать бороться с переобучением.\n",
    "\n",
    "И в случае линейных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/dropout_solve_overfitting_problem_in_mlp_networks.png\" width=\"500\">\n",
    "\n",
    "<em>Source: <a href=\"https://xuwd11.github.io/Dropout_Tutorial_in_PyTorch/\">Tutorial: Dropout as Regularization and Bayesian Approximation</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И в случае свёрточных слоёв"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/dropout_solve_overfitting_problem_in_convolution_networks.png\" width=\"500\">\n",
    "\n",
    "<em>Source: <a href=\"https://xuwd11.github.io/Dropout_Tutorial_in_PyTorch/\">Tutorial: Dropout as Regularization and Bayesian Approximation</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Простая реализация Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем \"наивную\" реализацию модуля Dropout.\n",
    "\n",
    "**Замечание:** Этот блок кода дан для объяснения работы Dropout, при построении нейронной сети используйте [`nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) или [`nn.Dropout2d`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BadDropout(nn.Module):\n",
    "    def __init__(self, p: float = 0.5):\n",
    "        super().__init__()\n",
    "        if p < 0 or p > 1:\n",
    "            raise ValueError(\n",
    "                f\"Dropout probability has to be between 0 and 1, but got {p}\"\n",
    "            )\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            keep = torch.rand(x.size()) > self.p\n",
    "            if x.is_cuda:\n",
    "                keep = keep.to(device)\n",
    "            return x * keep\n",
    "        # in test time, expectation is calculated\n",
    "        return x * (1 - self.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведенная реализация неоптимальна, так как в режиме инференса (когда ```training = False```) функция ```forward``` совершает дополнительное умножение. Одним из приоритетов при создании модели является скорость работы в режиме инференса. Поэтому по возможности все \"лишние\" операции выполняют только в режиме обучения. В данном случае можно целиком убрать коэффициент нормировки из режима инференса, перенеся его в режим обучения в знаменатель.\n",
    "\n",
    "Дополнительным плюсом такого подхода является то, что при удалении модуля из архитектуры сети функция прогнозирования не изменится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p: float = 0.2):\n",
    "        super().__init__()\n",
    "        if p < 0 or p > 1:\n",
    "            raise ValueError(\n",
    "                f\"Dropout probability has to be between 0 and 1, but got {p}\"\n",
    "            )\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            keep = torch.rand(x.size()) > self.p\n",
    "            if x.is_cuda:\n",
    "                keep = keep.to(device)\n",
    "            return x * keep / (1 - self.p)\n",
    "        return x  # in test time, expectation is calculated intrinsically - we just not divide weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем применить Dropout в нашей нейросети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMNIST_NN_Dropout(nn.Module):\n",
    "    def __init__(self, n_layers, activation=nn.Sigmoid, init_form=\"normal\"):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.activation = activation()\n",
    "        layers = [nn.Linear(28 * 28, 100), self.activation]\n",
    "        for _ in range(0, n_layers - 1):\n",
    "            layers.append(nn.Linear(100, 100))\n",
    "            layers.append(Dropout())  # add Dropout\n",
    "            layers.append(self.activation)\n",
    "        layers.append(nn.Linear(100, 10))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.init_form = init_form\n",
    "        if self.init_form is not None:\n",
    "            self.init()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "    def init(self):\n",
    "        sigmoid_gain = torch.nn.init.calculate_gain(\"sigmoid\")\n",
    "        for child in self.layers.children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                if self.init_form == \"normal\":\n",
    "                    torch.nn.init.xavier_normal_(child.weight, gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                elif self.init_form == \"uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(child.weight, gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                else:\n",
    "                    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как наша модель из-за Dropout ведет себя по-разному во время обучения и во время тестирования, мы должны прямо ей сообщать, обучается она сейчас или нет. Используем `train_model_sep`.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|c}\n",
    "\\large{\\text{model.train()}}&\\ \\large{\\text{model.eval()}}\\\\  \\hline\n",
    "\\large{\\text{Активируются Dropout слои.}}&\\large{\\text{Слои Dropout отключены.}}\\\\\n",
    "\\large{\\text{Выход части нейронов обнуляется, выходы нормируются.}}&\\large{\\text{Все нейроны работают.}}\n",
    "\\end{array}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с **Dropout**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Dropout(n_layers=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "model_name = \"nn3_dropout\"\n",
    "history = train_model_sep(model, optimizer, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter.add(history)\n",
    "history_plotter.plot([\"n_layers3_sigmoid\", \"n3_layers_sigmoid_havier\", model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае выигрыша мы не получили. Возможно, если учить нейросеть больше эпох, эффект бы заметили"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример борьбы с переобучением при помощи Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы увидеть эффект и при этом не учить нейросеть 100+ эпох, сделаем искусственный пример.\n",
    "\n",
    "Просто **добавим к линейной зависимости шум** и попробуем выучить ее нейронной сетью.\n",
    "\n",
    "[Dropout in Neural Networks with PyTorch (перевод)](https://machinelearningmastery.ru/batch-normalization-and-dropout-in-neural-networks-explained-with-pytorch-47d7a8459bcd/#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50  # number of data points\n",
    "noise = 0.3\n",
    "\n",
    "# generate the train data\n",
    "x_train = torch.unsqueeze(torch.linspace(-1, 1, N), 1)\n",
    "y_train = x_train + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))\n",
    "\n",
    "# generate the test data\n",
    "x_test = torch.unsqueeze(torch.linspace(-1, 1, N), 1)\n",
    "y_test = x_test + noise * torch.normal(torch.zeros(N, 1), torch.ones(N, 1))\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\\nx_test shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    x_train.data.numpy(), y_train.data.numpy(), c=\"purple\", alpha=0.5, label=\"train\"\n",
    ")\n",
    "plt.scatter(\n",
    "    x_test.data.numpy(), y_test.data.numpy(), c=\"yellow\", alpha=0.5, label=\"test\"\n",
    ")\n",
    "\n",
    "x_real = np.arange(-1, 1, 0.01)\n",
    "y_real = x_real\n",
    "plt.plot(x_real, y_real, c=\"green\", label=\"true\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель **без Dropout**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_h = 100  # num of neurons\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, N_h),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, N_h),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, 1),\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель **с Dropout**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_h = 100  # num of neurons\n",
    "\n",
    "model_dropout = nn.Sequential(\n",
    "    nn.Linear(1, N_h),\n",
    "    nn.Dropout(0.5),  # 50 % probability\n",
    "    nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, N_h),\n",
    "    nn.Dropout(0.2),  # 20% probability\n",
    "    nn.ReLU(),\n",
    "    torch.nn.Linear(N_h, 1),\n",
    ")\n",
    "optimizer_dropout = torch.optim.Adam(model_dropout.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1500\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train without dropout\n",
    "    y_pred = model(x_train)  # look at the entire data in a single shot\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # train with dropout\n",
    "    y_pred_dropout = model_dropout(x_train)\n",
    "    loss_dropout = criterion(y_pred_dropout, y_train)\n",
    "    optimizer_dropout.zero_grad()\n",
    "    loss_dropout.backward()\n",
    "    optimizer_dropout.step()\n",
    "\n",
    "    if epoch % 300 == 0:\n",
    "        model.eval()  # not train mode\n",
    "        model_dropout.eval()  #  not train mode\n",
    "\n",
    "        # get predictions\n",
    "        y_test_pred = model(x_test)\n",
    "        test_loss = criterion(y_test_pred, y_test)\n",
    "\n",
    "        y_test_pred_dropout = model_dropout(x_test)\n",
    "        test_loss_dropout = criterion(y_test_pred_dropout, y_test)\n",
    "        # plotting data and predictions\n",
    "        plt.scatter(\n",
    "            x_train.data.numpy(),\n",
    "            y_train.data.numpy(),\n",
    "            c=\"purple\",\n",
    "            alpha=0.5,\n",
    "            label=\"train\",\n",
    "        )\n",
    "        plt.scatter(\n",
    "            x_test.data.numpy(),\n",
    "            y_test.data.numpy(),\n",
    "            c=\"yellow\",\n",
    "            alpha=0.5,\n",
    "            label=\"test\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            x_test.data.numpy(), y_test_pred.data.numpy(), \"r-\", lw=3, label=\"normal\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            x_test.data.numpy(),\n",
    "            y_test_pred_dropout.data.numpy(),\n",
    "            \"b--\",\n",
    "            lw=3,\n",
    "            label=\"dropout\",\n",
    "        )\n",
    "\n",
    "        plt.title(\n",
    "            \"Epoch %d, Loss = %0.4f, Loss with dropout = %0.4f\"\n",
    "            % (epoch, test_loss, test_loss_dropout)\n",
    "        )\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        model.train()  # train mode\n",
    "        model_dropout.train()  # train mode\n",
    "\n",
    "        plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что **нейросеть без Dropout сильно переобучилась**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Доверительный интервал от Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно, используя нейросеть с Dropout, получить **доверительный интервал** для нашего предсказания (как делали в лекции по ML). Просто **не \"замораживаем\" dropout-слои** во время предсказания, а делаем предсказания с активными dropout.\n",
    "\n",
    "Делаем предсказание для каждого объекта 1000 раз. Сделав это 1000 раз, вы получаете распределение предсказаний, на основе которого можно делать **доверительные интервалы** и как раз ловить **аномалии** — те объекты, на которых нейросеть вообще не понимает, что ей делать, и потому предсказывает метку или еще что-то с сильной дисперсией.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/confidence_interval_dropout.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://atcold.github.io/pytorch-Deep-Learning/en/week14/14-3/\">Overfitting and regularization</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DropConnect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если занулять не нейроны (активации), а случайные веса с вероятностью $p$, получится DropConnect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/dropconnect.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DropConnect похож на Dropout, поскольку он вводит динамическую разреженность в модель, но отличается тем, что разреженность зависит от весов *W*, а не от выходных векторов слоя. Другими словами, полностью связанный слой с DropConnect становится разреженно связанным слоем, в котором соединения выбираются случайным образом на этапе обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В принципе, вариантов зануления чего-то в нейронной сети можно предложить великое множество, в разных ситуациях будут работать разные способы ([в этом списке](https://paperswithcode.com/methods/category/regularization)  много Drop...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DropBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, можно убирать для каждого батча из нейросети случайные блоки из слоев. И это будет работать!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/dropblock.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Deep Networks with Stochastic Depth (Huang et al., 2016)](https://arxiv.org/pdf/1603.09382.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization до или после Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### После"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnormalization_after_dropout.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Плохо**: В режиме обучения **Dropout** будет отключать (занулять) выходы слоя активации, из-за этого накопленные в режиме обучения **значения скользящего среднего матожидания и дисперсии** для вычисления **Batch Normalization** в режиме тестирования будут иметь **сдвиг**, который приведет к нестабильной работе нейросети.\n",
    "\n",
    "\n",
    "Подробно об этом можно почитать в [статье](https://arxiv.org/pdf/1801.05134.pdf) и [блокноте](https://github.com/adelizer/kaggle-sandbox/blob/master/drafts/dropout_bn.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### До"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/batchnormalization_before_dropout.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Лучше**: Меньше влияние сдвига от **Dropout** на **BatchNorm**. Но если на предыдущих слоях есть **Dropout**, то значения все равно могут быть смещены.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ставить только что-то одно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Dropout** может отрицательно влиять на качество нейросети с **BatchNorm** за счет разного поведения на train и test. Лучше не ставить **Dropout** раньше **BatchNorm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строго говоря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Оптимальный порядок следования слоев зависит от задачи и архитектуры сети.\n",
    "* Возможно, стоит применять другие виды нормализации.\n",
    "* Если используем **BatchNormalization**, то надо уменьшить силу **Dropout** и **L2**-регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизация параметров нейросетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе обучения мы пытаемся подобрать параметры модели, при которых она будет работать лучше всего. Это — **оптимизационная задача** (задача подбора оптимальных параметров). Мы уже ознакомились с одним алгоритмом оптимизации параметров — **градиентным спуском**.\n",
    "\n",
    "Существует множество **алгоритмов оптимизации**, которые можно применять для поиска минимума функционала ошибки ([неполный список](https://paperswithcode.com/methods/category/stochastic-optimization)). Эти алгоритмы реализованы в модуле [`torch.optim`](https://pytorch.org/docs/stable/optim.html).\n",
    "\n",
    "Важно отметить, что **выбор оптимизатора не влияет на расчет градиента**. Градиент в PyTorch вычисляется автоматически на основе графа вычислений.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обзор популярных оптимизаторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD (stochastic gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При градиентном спуске мы:\n",
    "- делаем **прямой проход**, вычисляем функционал ошибки $L(x, y, w_t)$;\n",
    "- делаем **обратный проход**, вычисляем градиент $\\nabla_wL(x, y, w_t)$;\n",
    "- делаем **шаг оптимизации**: изменяем параметры модели по формуле:\n",
    "\n",
    "$$w_{t+1} = w_t - lr \\cdot \\nabla_wL(x, y, w_t),$$\n",
    "\n",
    "домножая антиградиент на постоянный коэффициент $lr$ (гиперпараметр обучения — learning rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/stochastic_gradient_descent.gif\" width=\"950\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У данного алгоритма есть проблема: он может застревать в **локальных минимумах** или даже **седловых точках**.\n",
    "\n",
    "**Cедловые точки** — точки, в которых все производные равны 0, но они не являются экстремумами. В них градиент равен 0, веса не обновляются — оптимизация останавливается.\n",
    "\n",
    "Пример таких точек:\n",
    "\n",
    "- точка $(0, 0)$ у функции $y = x^3$, не имеющей минимума или максимума вовсе;\n",
    "- точка $(0, 0, 0)$ у функции $z = x^2 - y^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/getting_stuck_in_local_minimum_example.png\" width=\"350\"> <img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/saddle_point_example.png\" width=\"400\"></center>\n",
    "\n",
    "<center><em><a href=\"https://ru.wikipedia.org/wiki/%D0%A1%D0%B5%D0%B4%D0%BB%D0%BE%D0%B2%D0%B0%D1%8F_%D1%82%D0%BE%D1%87%D0%BA%D0%B0\">Седловая точка</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частично эту проблему решает **стохастический градиентный спуск** (stochastic gradient descent, **SGD**). В нем для градиентного спуска используется не все данные, а некоторая подвыборка (mini-batch) или даже один элемент.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SGD** обладает важной особенностью: на каждом объекте или подвыборке (mini-batch) ландшафт функции потерь выглядит по-разному. Некоторые минимумы функции потерь и седловые точки могут быть характерны лишь для части объектов.\n",
    "\n",
    "Ниже **упрощенно** показаны ландшафты функции потерь на полном датасете и на отдельных батчах. При оптимизации на полном датасете модель могла бы **остановиться в левом локальном минимуме**, но стохастическая природа спуска позволяет избежать этого за счет того, что **для некоторых батчей этот минимум отсутствует**.\n",
    "\n",
    "В результате модель сможет остановиться только в каком-то относительно широком и глубоком минимуме, характерном для большинства батчей обучающих данных. С большой вероятностью этот минимум будет присутствовать и на реальных данных, то есть модель сможет адекватно работать с ними."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/sgd_loss_batch_landscape.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SGD** до сих пор является достаточно популярным методом обучения нейросетей, потому что он простой, не требует подбора дополнительных гиперпараметров, кроме **скорости обучения** `lr`, и сам по себе обычно дает неплохие результаты.\n",
    "\n",
    "Если же модель учится слишком долго и/или важна каждая сотая в качестве, то нужно либо использовать его в совокупности с другими техниками (их рассмотрим далее), либо использовать другие способы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фрагмент кода для понимания работы SGD:\n",
    "```\n",
    "class SGD:  \n",
    "  def __init__(self, parameters, lr):\n",
    "    self.parameters = parameters\n",
    "    self.lr = lr\n",
    "  \n",
    "  def step(self):\n",
    "    d_parameters = self.parameters.grad\n",
    "    self.parameters -= self.lr*d_parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм SGD реализован в [`torch.optim.SGD`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Минусы SGD**:\n",
    "\n",
    " 1. Если функция ошибки быстро меняется в одном направлении, а в другом &mdash; медленно, то это приводит к резким изменениям направления градиентов и замедляет процесс обучения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/stohastic_gradient_descent_no_momentum.gif\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Может застревать в локальных минимумах или седловых точках.\n",
    "\n",
    " 3. Мы оцениваем градиент по малым частям выборки, которые могут плохо отображать градиент по всей выборке и являться шумными. В результате часть шагов градиентного спуска делается впустую или во вред.\n",
    "\n",
    " 4. Мы применяем один и тот же `learning rate` ко всем параметрам, что не всегда разумно. Параметр, отвечающий редкому классу, будет обучаться медленнее остальных.\n",
    "\n",
    " 5. Просто медленнее сходится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SGD** является основой всех описанных ниже алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы избежать проблем 1–3, можно добавить движению по ландшафту функции ошибок инерции (**momentum**). По аналогии с реальной жизнью: если мяч катится с горки, то он благодаря инерции может проскочить пологое место или даже небольшую яму.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корректируем направление движения шарика с учетом текущего градиента:\n",
    "\n",
    "$$v_{t} = m \\cdot v_{t-1} + \\nabla_wL(x, y, w_{t})$$\n",
    "\n",
    "где $m \\in [0, 1)$ — momentum (гиперпараметр).\n",
    "\n",
    "Вычисляем, куда он покатится:\n",
    "\n",
    "$$w_{t+1} = w_t - lr \\cdot v_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/advantages_wtih_momentum.png\" width=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Градиентный спуск, как учатся нейронные сети (видео)](https://youtu.be/IHZwWFHWa-w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы быстрее достигаем локального минимума и можем выкатываться из совсем неглубоких. Градиент стал менее подвержен шуму, меньше осциллирует"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/stohastic_gradient_descent_no_momentum.gif\" width=\"500\"> <img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/stohastic_gradient_descent_with_momentum.gif\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фрагмент кода для понимания работы Momentum:\n",
    "\n",
    "```\n",
    "class SGD_with_momentum:  \n",
    "  def __init__(self, parameters, momentum, lr):\n",
    "    self.parameters = parameters\n",
    "    self.momentum = momentum\n",
    "    self.lr = lr\n",
    "    self.velocity = torch.zeros_like(parameters)\n",
    "    \n",
    "  def step(self):\n",
    "    d_parameters = self.parameters.grad\n",
    "    self.velocity =  self.momentum*self.velocity + d_parameters\n",
    "    self.weights -= self.lr*self.velocity\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Momentum удваивает количество хранимых параметров.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм Momentum реализован в [`torch.optim.SGD`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.SGD(model.parameters(), momentum=0.9, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У этого подхода есть одна опасность — мы можем выкатиться за пределы минимума, к которому стремимся, а потом какое-то время к нему возвращаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/problem_of_big_momentum_value.gif\" width=\"700\">\n",
    "\n",
    "<em>Source: <a href=\"https://distill.pub/2017/momentum/\">Why Momentum Really Works</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[optimizer-visualization](https://github.com/Jaewan-Yun/optimizer-visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы с этим бороться, предложен другой способ подсчета инерции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAG (Nesterov momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем сначала смещаться в сторону, куда привел бы нас наш накопленный градиент, там считать новый градиент и смещаться по нему.\n",
    "В результате перескоки через минимум будут менее значительными, и алгоритм будет быстрее сходиться:\n",
    "\n",
    "$$v_{t} = m \\cdot v_{t-1} +  \\nabla_w L(w_t - lr \\cdot m \\cdot  v_{t-1} )$$\n",
    "\n",
    "$$w_{t+1} = w_{t} - lr \\cdot v_{t} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/nesterov_momentum.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, что для реализации такого алгоритма необходимо пересчитывать прямой и обратный проход с новыми параметрами, для вычисления градиента. На практике эту формулу можно [переписать](http://www.cs.toronto.edu/~hinton/absps/momentum.pdf) так, чтобы не пересчитывать градиент.\n",
    "\n",
    "С псевдокодом, описывающим последовательность действий NAG, можно познакомиться в [документации PyTorch](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Так же, как momentum, Nesterov momentum удваивает количество хранимых параметров.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм Nesterov momentum реализован в [`torch.optim.SGD`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.SGD(model.parameters(), momentum=0.9, nesterov=True, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описанные алгоритмы не борются с 4-ой проблемой SGD: \"мы применяем **один и тот же learning rate ко всем параметрам**, что не всегда разумно. Параметр, отвечающий редкому классу, будет обучаться медленнее остальных\".\n",
    "\n",
    "**Пример:** мы решаем задачу классификации картинок из Интернета, и у нас есть параметры, ответственные за признаки, которые характеризуют кошек породы сфинкс. Кошки породы сфинкс встречаются в нашем датасете редко, и эти параметры реже получают информацию для обновления. Поэтому наша модель может хуже классифицировать кошек этой породы.\n",
    "\n",
    "Для решения этой проблемы мы можем завести для каждого параметра **индивидуальный learning rate**, зависящий от того, как часто и как сильно изменяется этот параметр в процессе обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем хранить для каждого параметра **сумму квадратов его градиентов** (запоминаем, как часто и как сильно он изменялся).\n",
    "\n",
    "И будем вычитать из значений параметров градиент с коэффициентом, обратно пропорциональным корню из этой суммы $G_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ G_ t = \\sum_{i=1}^t \\nabla_w L(x,y,w_i)\\odot\\nabla_w L(x,y,w_i) $$\n",
    "\n",
    "$$ w_{t+1} = w_{t} -  \\frac{lr}{\\sqrt{G_t} + e} \\odot \\nabla_w L(x,y,w_{t}) $$\n",
    "\n",
    "$e$ — малая константа, чтобы не допускать деления на ноль, $\\odot$ — поэлементное умножение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате, если градиент у нашего веса часто большой, коэффициент будет уменьшаться.\n",
    "\n",
    "Проблема заключается в том, что при такой формуле наш `learning rate` неминуемо в конце концов затухает (так как сумма квадратов не убывает).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фрагмент кода для понимания работы Adagrad:\n",
    "```\n",
    "class AdaGrad:  \n",
    "  def __init__(self, parameters, lr=0.01):\n",
    "     self.parameters = parameters\n",
    "     self.lr = lr\n",
    "     self.grad_squared = torch.zeros_like(parameters)\n",
    "   \n",
    "  def step(self):\n",
    "    d_parameters = self.parameters.grad\n",
    "    self.grad_squared += d_parameters*d_parameters\n",
    "    self.parameters -= self.lr*d_parameters / (torch.sqrt(self.grad_squared) + 1e-7)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adagrad удваивает количество хранимых параметров**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм Adagrad реализован в [`torch.optim.Adagrad`](https://pytorch.org/docs/stable/generated/torch.optim.Adagrad.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим \"забывание\" предыдущих квадратов градиентов. Теперь мы считаем не сумму квадратов, а [экспоненциальное скользящее среднее](https://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D0%BE%D0%BB%D1%8C%D0%B7%D1%8F%D1%89%D0%B0%D1%8F_%D1%81%D1%80%D0%B5%D0%B4%D0%BD%D1%8F%D1%8F) с коэффициентом $\\alpha$.\n",
    "\n",
    "\n",
    "$$G_t = \\alpha \\cdot G_{t-1} + (1-\\alpha) \\cdot \\nabla_w L(x,y,w_t) \\odot \\nabla_w L(x,y,w_t)$$\n",
    "\n",
    "$$w_{t+1} = w_{t} - \\frac{lr}{\\sqrt{G_t }+ e} \\odot \\nabla_w L(x,y,w_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фрагмент кода для понимания работы RMSprop:\n",
    "\n",
    "```\n",
    "class RMSprop():  \n",
    "  def __init__(self, parameters, lr=0.01, alpha=0.99):\n",
    "    self.parameters = parameters\n",
    "    self.lr = lr\n",
    "    self.alpha = alpha\n",
    "    self.grad_squared = torch.zeros_like(parameters)\n",
    "  \n",
    "  def step(self):\n",
    "    d_parameters = self.parameters.grad\n",
    "    self.grad_squared = self.alpha*self.grad_squared + \\\n",
    "        (1 - self.alpha)*d_parameters*d_parameters\n",
    "\n",
    "    self.parameters -= self.lr*d_parameters / (torch.sqrt(self.grad_squared) + 1e-7)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Так же, как Adagrad, RMSprop удваивает количество хранимых параметров**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм RMSprop реализован в [`torch.optim.RMSprop`](https://pytorch.org/docs/stable/generated/torch.optim.RMSprop.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из самых популярных адаптивных оптимизаторов является Adam, объединяющий идеи momentum и adaptive learning rate:\n",
    "\n",
    "$$ v_t = \\beta_1 \\cdot v_{t-1} + (1-\\beta_1) \\cdot \\nabla_w L(x,y,w_t) $$\n",
    "\n",
    "$$ G_t = \\beta_2 \\cdot G_{t-1} + (1-\\beta_2) \\cdot \\nabla_w L(x,y,w_t) \\odot \\nabla_w L(x,y,w_t) $$\n",
    "\n",
    "$$ w_{t+1} = w_t - \\frac{lr}{\\sqrt{G_t} + e} \\odot v_t$$\n",
    "\n",
    "где $\\beta_1$ — аналог $m$ из Momentum, а $\\beta_2$ — аналог $\\alpha$ из RMSprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фрагмент кода для понимания работы Adam:\n",
    "\n",
    "```\n",
    "class Adam:  \n",
    "  def __init__(self, parameters, lr=0.01, betas=(0.9, 0.999)):\n",
    "    self.parameters = parameters\n",
    "    self.lr = lr\n",
    "    self.betas = betas\n",
    "    self.velocity = torch.zeros_like(parameters)\n",
    "    self.grad_squared = torch.zeros_like(parameters)   \n",
    "    self.beta_1 = betas[0] # momentum\n",
    "    self.beta_2 = betas[1] # alpha\n",
    "  \n",
    "  def step(self):\n",
    "    d_parameters = self.parameters.grad\n",
    "    # momentum\n",
    "    self.velocity = self.beta_1*self.velocity + (1 - self.beta_1)*d_parameters\n",
    "    # adaptive learning rate\n",
    "    self.grad_squared = self.beta_2*self.grad_squared + \\\n",
    "        (1 - self.beta_2)*d_parameters*d_parameters\n",
    "    self.parameters -= self.lr*self.velocity / (torch.sqrt(self.grad_squared) + 1e-7)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam утраивает количество хранимых параметров**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы в начале у нас получались очень большие шаги, будем дополнительно модицифировать инерцию и сумму квадратов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ v_t = \\frac{v_t}{1-\\beta_1^t} $$\n",
    "\n",
    "$$ G_t = \\frac{G_t}{1-\\beta_2^t} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм Adam реализован в [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.Adam([parameters], betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример применения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "\n",
    "model_name = \"adam\"\n",
    "history = train_model_sep(model, optimizer, model_name=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter.add(history)\n",
    "history_plotter.plot([\"batchnorm2\", \"batchnorm_increased_lr\", model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 vs Weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для использования L2 c оптимизатором необходимо указать значение `weight_decay`,  где `weight_decay` — коэффициент перед L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(10, requires_grad=True)\n",
    "optimizer = optim.RMSprop(model.parameters(), alpha=0.99, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще говоря, **Weight decay** и **L2** — это немного разные вещи.\n",
    "\n",
    "**L2** добавляет член регуляризации к Loss функции:\n",
    "\n",
    "$$Loss_{L2} = Loss + \\frac{λ}{2n}w^2$$\n",
    "\n",
    "**Weight decay** уменьшает веса:\n",
    "\n",
    "$$w_{wd} = w - \\frac{λ}{n}w$$\n",
    "\n",
    "где $λ$ — константа, а $n$ — количество элементов в батче.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для **SGD** оптимизатора **Weight decay** и **L2** **эквивалентны**, но не для всех оптимизаторов это так.\n",
    "\n",
    "Например, это не так для **Adam**. **L2** регуляризация прибавляется к Loss функции и изменяет **значение градиента**, квадраты которого будут храниться. **Weight decay** изменяет только веса (подробно об этом можно почитать [тут](https://arxiv.org/pdf/1711.05101.pdf)).\n",
    "\n",
    "**Обратите внимание**, что `weight_decay` в `torch.optim.Adam` — это **коэффициент перед L2**. **Weight decay** для **Adam** реализовано в\n",
    "`torch.optim.AdamW`.\n",
    "\n",
    "Считается, что **Weight decay** для **Adam** работает лучше, чем **L2**, но на практике это не всегда выполняется.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другие оптимизаторы (Lion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не Adam-ом единым живут нейронные сети. Есть альтернативные методы оптимизации, например, проект [Google Brain](https://research.google/teams/brain/) в 2023 году опубликовал [статью](https://arxiv.org/pdf/2302.06675.pdf), в которой описывает найденный в процессе [AutoML](https://arxiv.org/pdf/2101.08809.pdf) (автоматического подбора архитектур и алгоритмов) оптимизатор, названный **Lion**  (Evo**L**ved S**i**gn M**o**me**n**tum) 🦁."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что AutoML алгоритм пришел к интуитивно понятной эвристике: градиенты — вещь не очень надежная. Они могут взрываться и затухать. Может тогда мы зафиксируем размер шага, а градиенты будем использовать только для определения направления?\n",
    "\n",
    "Для определения направления используют функцию $sign$ (знак):\n",
    "\n",
    "\\begin{align}\n",
    "\\text{sign}(x) = \\left\\{\n",
    "\\begin{array}{cl}\n",
    "1 & x > 0 \\\\\n",
    "0 & x = 0\\\\\n",
    "-1 & x < 0.\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К этому добавляется уже изученный нами momentum, чтобы знак “прыгал” реже. Интересно, что AutoML подобрал алгоритм, в котором используются две константы для momentum. $\\beta_1$ — для определения текущего знака градиента, $\\beta_2$ — для хранения значения $v_t$. Значения по умолчанию $\\beta_1 = 0.9$, $\\beta_2 = 0.99$. Это значит, что текущее значение градиента сильнее влияет на значение для выбора направления текущего шага $с_{t}$, чем на хранимое значение момента $v_t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение для вычисления направления текущего шага:\n",
    "\n",
    "$$с_{t} = \\beta_1 \\cdot v_{t-1} + (1-\\beta_1) \\nabla_wL(x, y, w_{t})$$\n",
    "\n",
    "Шаг оптимизатора. $λ$ — константа weight decay:\n",
    "\n",
    "$$w_{t+1} = w_t - lr \\cdot (sign(c_t) +λ w_t)$$\n",
    "\n",
    "Обновление хранимого значения момента:\n",
    "\n",
    "$$v_t = \\beta_2 \\cdot v_{t-1} + (1-\\beta_2) \\nabla_wL(x, y, w_{t})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фрагмент кода для понимания работы **Lion**:\n",
    "\n",
    "```\n",
    "class Lion:  \n",
    "  def __init__(self, parameters, lr=0.0001, betas=(0.9, 0.99), weight_decay=0.01):\n",
    "    self.parameters = parameters\n",
    "    self.lr = lr\n",
    "    self.betas = betas\n",
    "    self.velocity = torch.zeros_like(parameters)\n",
    "    self.beta_1 = betas[0] # momentum 1\n",
    "    self.beta_2 = betas[1] # momentum 2\n",
    "    self.weight_decay = weight_decay\n",
    "  \n",
    "  def step(self):\n",
    "    d_parameters = self.parameters.grad\n",
    "    # current momentum\n",
    "    current = self.beta_1*self.velocity + (1 - self.beta_1)*d_parameters\n",
    "    # step\n",
    "    self.parameters -= self.lr*(torch.sign(carent)+self.weight_decay*self.parameters)\n",
    "    # history momentum\n",
    "    self.velocity = self.beta_2*self.velocity + (1 - self.beta_2)*d_parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lion удваивает количество хранимых параметров**\n",
    "\n",
    "Обратите внимание, что значение lr по умолчанию у **Lion** выбрано меньше, чем у **Adam**. Это связано с тем, что только lr и регуляризация определяют размер шага. Авторы статьи советуют брать для **Lion** в 10 раз меньший lr, чем для **Adam**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У **Lion** есть преимущества по сравнению с **Adam** и **AdamW**: в нем нет необходимости хранить квадраты градиентов. Он позволяет **снизить количество хранимых параметров** в 1.5–2 раза по сравнению с **AdamW**, а также сокращает количество операций, что позволяет [ускорить расчеты на 2-15%](https://arxiv.org/pdf/2302.06675.pdf) (в Colab это не заметно из-за специфики, связанной с виртуальными машинами).\n",
    "\n",
    "Кроме того, **Lion** [позволяет добиться лучших результатов](https://github.com/google/automl/tree/master/lion), чем AdamW, при обучении больших сложных моделей, таких как Visual Transformer-ы и диффузионные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но до сложных моделей мы пока не добрались, попробуем простую. Воспользуемся реализацией [lion-pytorch](https://github.com/lucidrains/lion-pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lion-pytorch\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lion_pytorch import Lion\n",
    "\n",
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "optimizer = Lion(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "\n",
    "model_name = \"lion\"\n",
    "history = train_model_sep(model, optimizer, model_name=\"lion\", num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter.add(history)\n",
    "history_plotter.plot([\"adam\", model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат получился почти как у **Adam**, число хранимых параметров меньше.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ландшафт функции потерь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует [исследование](https://proceedings.neurips.cc/paper/2018/file/be3087e74e9100d4bc4c6268cdbe8456-Paper.pdf), которое показывает, что ландшафт функции потерь представляет собой неизолированные локальные минимумы (рисунок слева), а связанные области с почти постоянным значением (рисунок справа). Поэтому умение “выбираться” из седловых точек важно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/loss_surfaces.png\" width=\"900\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://proceedings.neurips.cc/paper/2018/file/be3087e74e9100d4bc4c6268cdbe8456-Paper.pdf\">Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение оптимизаторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У каждого из предложенных оптимизаторов есть минусы и плюсы\n",
    "\n",
    "- Методы с инерцией сходятся к решению более плавно, но могут \"перелетать\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/convergence_optimizers.gif\" width=\"250\">\n",
    "\n",
    "<em>Source: <a href=\"https://imgur.com/a/Hqolp\">Visualizing Optimization Algos</a></em>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Методы с адаптивным learning rate быстрее сходятся, более стабильны и меньше случайно блуждают"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/methods_with_adaptive_learning_rate.gif\" width=\"250\">\n",
    "\n",
    "<em>Source: <a href=\"https://imgur.com/a/Hqolp\">Visualizing Optimization Algos</a></em>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Алгоритмы без адаптивного learning rate сложнее выбираются из локальных минимумов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/methods_without_adaptive_learning_rate.gif\" width=\"450\">\n",
    "\n",
    "<em>Source: <a href=\"https://imgur.com/a/Hqolp\">Visualizing Optimization Algos</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Алгоритмы с инерцией осцилируют в седловых точках прежде, чем находят верный путь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/methods_with_momentum_in_saddle_point.gif\" width=\"450\">\n",
    "\n",
    "<em>Source: <a href=\"https://imgur.com/a/Hqolp\">Visualizing Optimization Algos</a></em>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Режимы обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам не обязательно поддерживать один и тот же `learning rate` в течение всего обучения. Более того, для того же SGD есть гарантии, что если правильно подобрать схему уменьшения `learning rate`, он сойдется к глобальному оптимуму.\n",
    "\n",
    "Мы можем менять `learning rate` по некоторым правилам.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ранняя остановка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем использовать критерий ранней остановки: когда значение функции потерь на валидационной выборке не улучшается какое-то количество эпох(`patience`), умножаем `learning rate` на некое значение `factor`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/early_stopping.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \"min\", factor=0.1, patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим к нашей модели\n",
    "\n",
    "(выполнение занимает ~ 5 минут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_sep_scheduler(\n",
    "    model, optimizer, scheduler, model_name=None, num_epochs=5\n",
    "):\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history[\"model_name\"] = model_name\n",
    "    train_history[\"epoсhs\"] = num_epochs\n",
    "    train_history[\"loss_on_train\"] = []\n",
    "    train_history[\"loss_on_test\"] = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        loss_on_train = train_epoch(model, optimizer, criterion, train_loader)\n",
    "        model.eval()\n",
    "        val_loss, loss_on_test = validate(model, criterion, test_loader)\n",
    "        train_history[\"loss_on_train\"].extend(loss_on_train)\n",
    "        train_history[\"loss_on_test\"].extend(loss_on_test)\n",
    "        scheduler.step(val_loss)\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \"min\", factor=0.1, patience=1\n",
    ")\n",
    "\n",
    "model_name = \"reduce_lr_on_plateu\"\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "history = train_model_sep_scheduler(\n",
    "    model, optimizer, scheduler, model_name=model_name, num_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter.add(history)\n",
    "history_plotter.plot([model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Понижение шага обучения на каждой эпохе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домножать `learning rate` на `gamma` каждую эпоху"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network WarmUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для достаточно больших нейронных сетей практикуют следующую схему (**gradual warmup**, [изначальная статья](https://arxiv.org/pdf/1706.02677.pdf)):\n",
    "\n",
    "1. Поставить изначальный `learning rate` значительно ниже того, с которого мы обычно начинаем обучение.\n",
    "2. За несколько эпох, например, 5, довести `learning rate` от этого значения до требуемого. Так мы не совершаем больших шагов, когда сеть еще ничего не знает о данных. За счет этого нейросеть лучше \"адаптируется\" к нашим данным.\n",
    "\n",
    "Также такой `learning schedule` позволяет адаптивным оптимизаторам лучше оценить значения `learning rate` для разных параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/neural_network_warmup.png\" width=\"1000\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/pdf/1706.02677.pdf\">Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</a></em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$kn$ на картинке — это размер одного батча."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclical learning schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статья: [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/pdf/1506.01186.pdf)\n",
    "\n",
    "**Идея:**\n",
    "Функция потерь может иметь сложный ландшафт. Нам бы хотелось:\n",
    "* Изучить побольше локальных минимумов.\n",
    "* Оценить качество в каждом локальном минимуме.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/Cyclic_LR_Schedule.png\" width=\"750\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://openreview.net/pdf?id=BJYwwY9ll\">Snapshot Ensembles: train 1, get M for free</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого мы можем не все время понижать learning rate, а делать это **циклически**: то понижать, то повышать.\n",
    "\n",
    "При **увеличении** learning rate модель может **выбраться** из одного локального минимума. При **уменьшении** — **сойтись** к следующему.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть две основные мотивации использования **циклического learning rate**:\n",
    "\n",
    "* **Ускорение сходимости**: мы уже посмотрели на адаптивные оптимизаторы. Их недостатком является необходимость хранения в памяти квадратов градиентов. Для циклического learning rate это необязательно, его можно использовать с SGD, изменяя скорости в 3–4 раза. Аналогично с Adam — это позволит редким признакам быстрее обучаться (частые признаки будут немного “ломаться”, а затем восстанавливаться). Для таких целей важно подбирать learning rate вблизи оптимального. Идея этого представлена в [статье](https://arxiv.org/pdf/1506.01186.pdf).\n",
    "\n",
    "* **Создание ансамблей моделей:** разные локальные минимумы будут давать ошибки на разных объектах. Можно сохранять модели в локальных минимумах и не только искать лучшую, но и устраивать между моделями голосования. Для этого learning rate изменяют в сотни раз. Идея этого представлена в [статье](https://openreview.net/pdf?id=BJYwwY9ll). Обычно для создания ансамблей используют [циклический отжиг](https://arxiv.org/pdf/1608.03983.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Ускорение сходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Циклическое изменение  learning rate для ускорения сходимости реализовано в PyTorch в `optim.lr_scheduler.CyclicLR`.\n",
    "\n",
    "Делать это можно по-разному (`mode` — параметр, передаваемый `CyclicLR`):\n",
    "\n",
    "1. Постоянно оставлять одни и те же границы `mode='triangular'`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/cyclical_learning_schedule_permanent_confines.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Уменьшать верхнюю границу во сколько-то раз: `mode='triangular2'` — уменьшение в 2 раза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/cyclical_learning_schedule_reduce_confines.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Уменьшать границу экспоненциально ($amplitude_{iterations\n",
    " } = amplitude_0⋅\\gamma^{iterations}$, где $0<\\gamma\\leq1$), `mode='exp_range'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L07/out/cyclical_learning_schedule_reduce_confines_smooth.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. По собственной формуле с использованием `scale_fn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбираем границы learning rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем батч побольше, чтобы учить модель быстрее.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 * 16\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_count(pred, labels):\n",
    "    _, predicted = torch.max(pred.data, 1)\n",
    "    return (predicted.cpu() == labels.cpu()).sum().item()\n",
    "\n",
    "\n",
    "@torch.inference_mode()  # this annotation disable grad computation\n",
    "def get_accuracy(model, test_loader, device=\"cpu\"):\n",
    "    correct, total = 0, 0\n",
    "    for imgs, labels in test_loader:\n",
    "        pred = model(imgs.to(device))\n",
    "        total += labels.size(0)\n",
    "        correct += get_correct_count(pred, labels)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для определения оптимального learning rate будем обучать модель 2 эпохи (в статье 8 эпох, но MNIST — очень простой датасет) и смотреть на accuracy на тестовой выборке для различных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "lr_find_epochs = 2\n",
    "lrs = [0.0002 + 0.0005 * i for i in range(10)]\n",
    "losses = []\n",
    "test_accuracy = []\n",
    "\n",
    "for lr in tqdm(lrs):\n",
    "    model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for iter in range(lr_find_epochs):\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x_train, y_train = batch\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "            y_pred = model(x_train)\n",
    "            loss = criterion(y_pred, y_train)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "\n",
    "    losses.append(loss)\n",
    "    acc = get_accuracy(model, test_loader, device=device)\n",
    "    test_accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\n",
    "fig.suptitle(\"LR range selection\", size=15)\n",
    "\n",
    "ax1.plot(lrs, losses)\n",
    "ax1.set(xlabel=\"Learning rate\", ylabel=\"Loss\")\n",
    "ax1.axvline(x=0.001, color=\"r\")\n",
    "ax1.axvline(x=0.004, color=\"r\")\n",
    "\n",
    "ax2.plot(lrs, test_accuracy)\n",
    "ax2.set(xlabel=\"Learning rate\", ylabel=\"Accuracy\")\n",
    "ax2.axvline(x=0.001, color=\"r\")\n",
    "ax2.axvline(x=0.004, color=\"r\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нас интересует диапазон learning rate, при котором качество начинает сильно расти. Возьмем минимальное значение learning rate $1\\cdot10^{-3}$ и максимальное  learning rate $4\\cdot10^{-3}$. Максимальное больше минимального в 4 раза (в статье рекомендуют 3–4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = 1e-3\n",
    "max_lr = 4e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот `scheduler` надо применять после каждого батча. Поэтому перепишем `train_epoch_sh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_sh(model, optimizer, scheduler, criterion, train_loader):\n",
    "    loss_history = []\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x_train, y_train = batch  # parse data\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device)  # compute on gpu\n",
    "        y_pred = model(x_train)  # get predictions\n",
    "        loss = criterion(y_pred, y_train)  # compute loss\n",
    "        loss_history.append(loss.cpu().detach().numpy())  # write loss to log\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запускаем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернем размер батча для корректного сравнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер шага learning rate рекомендуют выбирать каждые 2-8 эпох. Мы возьмем 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_up = 4 * len(train_loader)\n",
    "print(step_size_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMNIST_NN_Init_Batchnorm(n_layers=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=base_lr)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CyclicLR(\n",
    "    optimizer,\n",
    "    base_lr=base_lr,\n",
    "    max_lr=max_lr,\n",
    "    mode=\"triangular\",\n",
    "    step_size_up=step_size_up,\n",
    ")  # first case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде ниже мы на каждой эпохе сохраняем лучшую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def train_model_cycle_sh(model, optimizer, scheduler, model_name=None, num_epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history[\"model_name\"] = model_name\n",
    "    train_history[\"epoсhs\"] = num_epochs\n",
    "\n",
    "    train_history[\"loss_on_train\"] = []\n",
    "    train_history[\"loss_on_test\"] = []\n",
    "\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        loss_on_train = train_epoch_sh(\n",
    "            model, optimizer, scheduler, criterion, train_loader\n",
    "        )\n",
    "        model.eval()\n",
    "        val_loss, loss_on_test = validate(model, criterion, test_loader)\n",
    "        train_history[\"loss_on_train\"].extend(loss_on_train)\n",
    "        train_history[\"loss_on_test\"].extend(loss_on_test)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = deepcopy(model)\n",
    "\n",
    "    return best_model, train_history\n",
    "\n",
    "\n",
    "model_name = \"sgd_cycle_lr\"\n",
    "hooks_data_history = register_model_hooks(model)\n",
    "best_model, history = train_model_cycle_sh(\n",
    "    model, optimizer, scheduler, model_name=model_name, num_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_plotter.add(history)\n",
    "history_plotter.plot([model_name, \"batchnorm2\", \"adam\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось хуже, чем Adam, но лучше, чем SGD, и мы сэкономили память."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание ансамблей моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/Cyclic_LR_Schedule.png\" width=\"750\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://openreview.net/pdf?id=BJYwwY9ll\">Snapshot Ensembles: train 1, get M for free</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания ансамблей моделей learning rate циклически изменяют в сотни раз (а можно и до 0, как ниже), поэтому подбор оптимального значения learning rate не критичен. В качестве правила изменения используют циклический отжиг (cosine annealing cycles):\n",
    "\n",
    "$$lr(t) = \\frac {lr_0}{2}(\\cos(\\frac{\\pi\\cdot mod(t-1, [T/M])}{[T/M]})+1)$$\n",
    "\n",
    "где $lr_0$ — начальная скорость обучения, $T$ — общее количество итераций, $M$ — общее количество моделей, $t$ — текущая итерация.\n",
    "\n",
    "В формулу можно добавить минимальное значение, но мы это делать не будем, т.к. это не обязательный параметр.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# number of models (M in formula)\n",
    "n_models = 6\n",
    "# epoch per model\n",
    "epoch = 50\n",
    "# number of bats in dataset\n",
    "len_dataset = 8\n",
    "\n",
    "# total iteration number (T in formula)\n",
    "total_iter = n_models * epoch * len_dataset\n",
    "\n",
    "learning_rate_0 = 0.1\n",
    "\n",
    "t = np.array(range(total_iter))\n",
    "lr_t = (learning_rate_0 / 2) * (\n",
    "    np.cos(np.pi * np.mod(t, total_iter / n_models) / (total_iter / n_models)) + 1\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "fig.suptitle(\"Cosine annealing cycles\", size=15)\n",
    "ax.plot(t / len_dataset, lr_t)\n",
    "ax.set(xlabel=\"Epoch\", ylabel=\"Learning rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PyTorch циклический отжиг реализован в модуле `torch.optim.lr_scheduler.CosineAnnealingWarmRestarts`.\n",
    "\n",
    "Общее правило подбора скорости обучения $lr_0$ — она должна быть достаточно большой, чтобы “ломать” обученную модель, при этом количество эпох для обучения каждой модели должно быть достаточным для получения приличного качества. В [статье](https://openreview.net/pdf?id=BJYwwY9ll), например, используют 50 эпох, но это значение будет зависеть от модели.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=total_iter // n_models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss при обучении будет выглядеть примерно так (красная линия):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/cosine_annealing_cycles.png\" width=\"350\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://openreview.net/pdf?id=BJYwwY9ll\">Snapshot Ensembles: train 1, get M for free</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели в конце цикла отжига сохраняются. Можно выбрать лучшую или построить ансамбль.\n",
    "\n",
    "Интересующимся построением ансамблей нейросетевых моделей советуем ознакомиться с идеей [супа моделей](https://arxiv.org/pdf/2203.05482.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Взаимодействие learning schedule и адаптивного изменения learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И то, и другое меняет `learning rate`:\n",
    "\n",
    "* `learning scheduler` — глобально,\n",
    "\n",
    "* адаптивные оптимизаторы — для каждого веса отдельно.\n",
    "\n",
    "Часто их применяют вместе, особенно в случае критерия ранней остановки и WarmUp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в случае циклического режима обучения так делают не всегда. Дело в том, что одна из его задач — как раз избежать использования адаптивных оптимизаторов, требующих больше памяти и дополнительных вычислений.\n",
    "\n",
    "При этом никаких препятствий к использованию того же Adam в компании вместе с циклическим режимом обучения нет. Так делают, например, в [статье](https://arxiv.org/pdf/2004.02401.pdf).\n",
    "\n",
    "Кроме того, есть сложные оптимизаторы, составленные из нескольких простых оптимизаторов и шедулеров. Например, есть проект [Ranger21](https://github.com/lessw2020/Ranger21), не получивший оформления в виде библиотеки на [PyPi](https://pypi.org/), авторы которого пытаются “померить” разные идеи из статей. Подробнее о нем можно почитать в [статье](https://arxiv.org/pdf/2106.13731.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L07/ranger21.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Loss и accuracy при использовании Adam и Ranger21 при обучении ResNet50 на наборе данных ImageNet</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/pdf/2106.13731.pdf\">Ranger21: A Synergistic Deep Learning Optimizer</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты выглядят неплохо. Недостатком этого оптимизатора является большое количество хранимых параметров и гиперпараметров, а также тестирование на ограниченном числе моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"6\">Ссылки:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A journey into Optimization algorithms for Deep Neural Networks](https://theaisummer.com/optimization/)\n",
    "\n",
    "[Батч-нормализация. In-layer normalization techniques for training very deep neural networks](https://theaisummer.com/normalization/)\n",
    "\n",
    "[Разные функции активации, затухающие и взрывающиеся градиенты и т.д.](https://www.kdnuggets.com/2022/06/activation-functions-work-deep-learning.html)\n",
    "\n",
    "[Визуализация разных оптимизаторов в ipynb, но на tensorflow](https://nbviewer.jupyter.org/github/ilguyi/optimizers.numpy/blob/master/optimizer.tf.all.opt.plot.ipynb)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
