{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=\"6\">–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ\" –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞—á–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —ç—Ç–æ–º –∫—É—Ä—Å–µ –º—ã –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ä–∞–±–æ—Ç–∞–ª–∏ —Å **—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–º–∏** –¥–∞–Ω–Ω—ã–º–∏. –ú—ã –Ω–∞—É—á–∏–ª–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, —Ä–µ–≥—Ä–µ—Å—Å–∏–∏, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ —Ç.–¥. –ù–∞ –≤—Ö–æ–¥–µ –º–æ–¥–µ–ª–∏ —É –Ω–∞—Å –±—ã–ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–æ—Ç–æ—Ä—ã–º –º—ã —É—á–∏–ª–∏—Å—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ —á–∏—Å–ª–∞, –º–∞—Å–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ —Ç.–¥):\n",
    "\n",
    "$$\\large \\text{–í–æ—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ} \\xrightarrow[\\text{}]{\\text{–ú–æ–¥–µ–ª—å}} \\text{–¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è}$$\n",
    "\n",
    "–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —ç—Ç–æ –º–æ–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å, –∫–∞–∫\n",
    "\n",
    "$$\\large X \\xrightarrow[\\text{}]{f_{Œ∏}(x)} Y$$\n",
    "–≥–¥–µ $X$ - –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, $Y$ - –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ü–µ–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, $f_{Œ∏}(x)$ - –º–æ–¥–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ $Œ∏$. –ü–æ —Å—É—Ç–∏ –Ω–∞—à–∞ –º–æ–¥–µ–ª—å - —ç—Ç–æ —Å–ª–æ–∂–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å—Ç–∞–≤–∏—Ç –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É $x$ –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö $X$ —Ü–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ $y$ –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö $Y$:\n",
    "$$y = f_{Œ∏}(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–° –∑–∞–¥–∞—á–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–µ–ª–∞ –æ–±—Å—Ç–æ—è—Ç —Å–ª–æ–∂–Ω–µ–µ, –≤–µ–¥—å –≤ –∑–∞–¥–∞—á–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º—ã —Ö–æ—Ç–∏–º –Ω–∞—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –±—ã–ª–æ –≤ –∏—Å—Ö–æ–¥–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ.\n",
    "\n",
    "**–ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**\n",
    "\n",
    "**–î–∞–Ω–æ**: –¥–∞–Ω–Ω—ã–µ, —á–∞—Å—Ç–æ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ.\n",
    "\n",
    "**–í—Ö–æ–¥ –º–æ–¥–µ–ª–∏**: ?????\n",
    "\n",
    "**–†–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**: –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—Ç—å —Å–ª–µ–¥—É—é—â–∏–º —É—Å–ª–æ–≤–∏—è–º:\n",
    "* –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ **–ø–æ—Ö–æ–∂–∏** –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–µ.\n",
    "* –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ **–Ω–µ –ø–æ–≤—Ç–æ—Ä—è—é—Ç** –∏—Å—Ö–æ–¥–Ω—ã–µ (–∏–ª–∏ –ø–æ–≤—Ç–æ—Ä—è—é—Ç, –æ—á–µ–Ω—å —Ä–µ–¥–∫–æ, –ø—Ä–∏ —Å–ª—É—á–∞–π–Ω–æ–º —Å—Ç–µ—á–µ–Ω–∏–∏ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤).\n",
    "\n",
    "**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ:**\n",
    "* –í–∞–∂–µ–Ω **—ç–ª–µ–º–µ–Ω—Ç —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏**: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –∑–∞–ø—É—Å–∫–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Ç–æ–≥–æ –Ω–µ –æ—á–µ–Ω—å –ø–æ–Ω—è—Ç–Ω–æ, **—á—Ç–æ –¥–æ–ª–∂–Ω–æ –ø–æ–¥–∞–≤–∞—Ç—å—Å—è –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏** –∏ –∫–∞–∫ –æ–±–µ—Å–ø–µ—á–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏. –í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç **–≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π –∏–ª–∏ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π —à—É–º.**\n",
    "\n",
    "$$\\large \\text{–®—É–º} \\xrightarrow[\\text{}]{\\text{–ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏}} \\text{C–≥–µ–Ω–µ—Ä–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/generator_model_pipeline.png\" width=\"350\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —ç—Ç–æ –º–æ–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å, –∫–∞–∫\n",
    "\n",
    "$$\\large Z \\xrightarrow[\\text{}]{g_{Œ∏}(z)} X$$\n",
    "–≥–¥–µ $Z$ - —Ö–æ—Ä–æ—à–æ –∏–∑—É—á–µ–Ω–Ω–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–æ—Ä–º–∞–ª—å–Ω–µ –≥–∞—É—Å—Å–æ–≤–æ —Ä–∞—Å–ø—Ä–µ–ª–µ–Ω–∏–µ) –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã —É–º–µ–µ–º —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã, $X$ - –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∏–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã –Ω–µ —É–º–µ–µ–º —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å.\n",
    "\n",
    "–ü–æ —Å—É—Ç–∏ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ - —ç—Ç–æ —Å–ª–æ–∂–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å—Ç–∞–≤–∏—Ç –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤—ã–±–æ—Ä–∫–µ –∏–∑ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø–µ–¥–µ–ª–µ–Ω–∏—è $z$ –æ–±—ä–µ–∫—Ç –∏–∑ —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è $x$:\n",
    "$$x = g_{Œ∏}(z)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/generative_models.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –ø—Ä–∏–º–µ—Ä: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å –ø—Ä–∏–º–µ—Ä–æ–≤ - —É—Å—Ç–∞–Ω–æ–≤–∏–º —Å–∏–¥—ã:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —É –Ω–∞—Å –ø–æ–¥ —Ä—É–∫–æ–π –µ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–º –ª–µ–≥–∫–æ –ø–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ —á–∏—Å–ª–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ $[0,1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "u1 = np.random.uniform(size=1000)\n",
    "u2 = np.random.uniform(size=1000)\n",
    "\n",
    "data = pd.DataFrame.from_dict(dict(zip([\"U1\", \"U2\"], [u1, u2])))\n",
    "\n",
    "sns.jointplot(data=data, x=\"U1\", y=\"U2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—É—Å—Ç—å $U_i$ ‚Äî —Ç–æ—á–∫–∞, –∫–æ—Ç–æ—Ä—É—é –¥–∞—ë—Ç –Ω–∞–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª. –ï—Å–ª–∏ –º—ã –≤–æ–∑—å–º—ë–º –ø–∞—Ä—É —Ç–∞–∫–∏—Ö —Ç–∞–∫–∏—Ö —Ç–æ—á–µ–∫ $U_1$, $U_2$ –∏ –ø—Ä–æ–∏–∑–≤–µ–¥—ë–º —Å –Ω–∏–º–∏ —Ç–∞–∫ –Ω–∞–∑—ã–≤–∞–µ–º–æ–µ [–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ú—é–ª–ª–µ—Ä–∞ üìö[wiki]](https://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform), —Ç–æ –ø–æ–ª—É—á–∏–º –ø–∞—Ä—É –Ω–æ–≤—ã—Ö —Ç–æ—á–µ–∫ $X$ –∏ $Y$ –Ω–∞ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø—Ä—è–º–æ–π:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{l}\n",
    "X=\\sqrt{-2 \\log U_{1}} \\cos \\left(2 \\pi U_{2}\\right) \\\\\n",
    "Y=\\sqrt{-2 \\log U_{1}} \\sin \\left(2 \\pi U_{2}\\right)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–≤—Ç–æ—Ä–∏–≤ —Ç–∞–∫—É—é –ø—Ä–æ—Ü–µ–¥—É—Ä—É –¥–ª—è –±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞ —Ç–æ—á–µ–∫ $U_i$, –º–æ–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ $X$ –∏ $Y$ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø–æ—Ö–æ–∂–∏–º –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.sqrt(-2 * np.log(u1))\n",
    "theta = 2 * np.pi * u2\n",
    "\n",
    "x = r * np.cos(theta)\n",
    "y = r * np.sin(theta)\n",
    "\n",
    "data[\"X\"] = x\n",
    "data[\"Y\"] = y\n",
    "\n",
    "sns.jointplot(data=data, x=\"X\", y=\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –º—ã –º–æ–∂–µ–º –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ú—é–ª–ª–µ—Ä–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–ª–æ –∏—Å—Ö–æ–¥–Ω–æ–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ. –° –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º –º–æ–∂–Ω–æ –æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è [—Ç—É—Ç](https://mathworld.wolfram.com/Box-MullerTransformation.html).\n",
    "\n",
    "–ú–æ–∂–Ω–æ —Ä–∞—Å–∫—Ä–∞—Å–∏—Ç—å —Ç–æ—á–∫–∏ –≤—ã–±–æ—Ä–∫–∏ –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫ –∏–º–µ–Ω–Ω–æ –æ–Ω–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.sqrt(u1*u1 + u2*u2) # for visualization\n",
    "color = color / color.max()\n",
    "data[\"color\"] = color\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "cmap = sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "sns.scatterplot(\n",
    "    data=data, x=\"U1\", y=\"U2\", hue=\"color\", palette=cmap, ax=ax[0],\n",
    "    legend=False,\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=data, x=\"X\", y=\"Y\", hue=\"color\", palette=cmap, ax=ax[1], legend=False\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ –Ω–∞–º —Ö–æ—á–µ—Ç—Å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –Ω–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏, –∞ –≤ –∫–∞–∫–æ–º-—Ç–æ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–º? –í –æ–±—â–µ–º —Å–ª—É—á–∞–µ –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—É—é —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –∏–∑ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ \"–ø—Ä–æ—Å—Ç–æ–≥–æ\" —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤ \"—Ü–µ–ª–µ–≤–æ–µ\". –û—Å—É—â–µ—Å—Ç–≤–ª—è—é—â–∏–µ —Ç–∞–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥–µ–º –Ω–∞–∑—ã–≤–∞—Ç—å **–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ —Ü–µ–ª–µ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ $\\mathcal{F}[\\vec {x}]$ –∏–∑–≤–µ—Å—Ç–Ω–æ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏, —Ç–æ –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ —Ç–∞–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –º–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ [Markov Chain Monte Carlo üìö[wiki]](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –≥–ª—É–±–æ–∫–æ–º –æ–±—É—á–µ–Ω–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/deep_generative_models.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –í–≤–µ–¥–µ–Ω–∏–µ  –≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[–ú–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤](https://thisxdoesnotexist.com)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ù–∞–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –≤ —Ä–µ—à–µ–Ω–∏–∏ –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–±–µ—Ä–µ–º—Å—è —Å **—ç–ª–µ–º–µ–Ω—Ç–æ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏**. –í –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö –º—ã –ø—Ä–∏–≤—ã–∫–ª–∏ –∫ **–≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏** —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: –≤ —Ä–µ–∂–∏–º–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º—ã –º–æ–∂–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–¥–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –æ–±—ä–µ–∫—Ç –∏ –ø–æ–ª—É—á–∏—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.  –í–æ–∑–Ω–∏–∫–∞–µ—Ç –¥–≤–∞ –≤–æ–ø—Ä–æ—Å–∞:\n",
    "- —á—Ç–æ –ø–æ–¥–∞–≤–∞—Ç—å –Ω–∞ **–≤—Ö–æ–¥** —Å–µ—Ç–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏?\n",
    "- –∫–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å **—Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å**?\n",
    "\n",
    "–û—Ç–≤–µ—Ç –Ω–∞ –æ–±–∞ –≤–æ–ø—Ä–æ—Å–∞: –ø–æ–¥–∞–≤–∞—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ **–≤—Ö–æ–¥–∞** –≤–µ–∫—Ç–æ—Ä **—Å–ª—É—á–∞–π–Ω–æ–≥–æ —à—É–º–∞**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ **–≤–µ–∫—Ç–æ—Ä**? –ü–æ—á–µ–º—É –Ω–µ –æ–¥–Ω–æ **—Å–ª—É—á–∞–π–Ω–æ–µ —á–∏—Å–ª–æ**?\n",
    "\n",
    "**–û—Ç–≤–µ—Ç**: –≤—Ö–æ–¥–Ω–æ–π –≤–µ–∫—Ç–æ—Ä –º–æ–∂–Ω–æ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∫–∞–∫ **–ø—Ä–∏–∑–Ω–∞–∫–∏** –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞. –ö–∞–∂–¥—ã–π —Ç–∞–∫–æ–π –ø—Ä–∏–∑–Ω–∞–∫ ‚Äî **–Ω–µ–∑–∞–≤–∏—Å–∏–º–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞**. –ï—Å–ª–∏ –º—ã –±—É–¥–µ–º –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–ª—É—á–∞–π–Ω–æ–µ —á–∏—Å–ª–æ, —Ç–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±—É–¥–µ—Ç –æ–¥–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–π. –ß–µ–º –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Å—Ç–µ–ø–µ–Ω–µ–π —Å–≤–æ–±–æ–¥—ã) —É –≤—Ö–æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞, —Ç–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–µ–µ –±—É–¥–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–æ –µ—Å—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º **–±–æ–ª—å—à–µ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** –¥–∞—ë—Ç –Ω–∞–º **–±–æ–ª—å—à–µ –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏**  –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –≠—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è **input latent space** ‚Äî –≤—Ö–æ–¥–Ω–æ–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ.\n",
    "\n",
    "**Note:** *–∏–∑-–∑–∞ –Ω–µ—É—Å—Ç–æ—è–≤—à–µ–π—Å—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏ —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –≤—Ö–æ–¥–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –ª–∞—Ç–µ–Ω—Ç–Ω—ã–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ–º —Ç–∞–∫ –∂–µ, –∫–∞–∫ –∏ —Å–∫—Ä—ã—Ç–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞—Ö. –ü–æ—ç—Ç–æ–º—É –≤ —ç—Ç–æ–π –ª–µ–∫—Ü–∏–∏ –±—É–¥–µ–º –Ω–∞–∑—ã–≤–∞—Ç—å –µ–≥–æ **–≤—Ö–æ–¥–Ω—ã–º** –ª–∞—Ç–µ–Ω—Ç–Ω—ã–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ–º. –¢–∞–∫–∂–µ –≤ —Å—Ç–∞—Ç—å—è—Ö –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤–∞—Ä–∏–∞–Ω—Ç: predefined latent space.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∂–¥—É—é –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—É –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –º–æ–∂–Ω–æ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é —à–∫–∞–ª—É, –≤–¥–æ–ª—å –∫–æ—Ç–æ—Ä–æ–π –∏–∑–º–µ–Ω—è—é—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä, –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å —á–µ—Ç—ã—Ä–µ –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–∞ –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã –ø–ª–∞–≤–Ω–æ –∏–∑–º–µ–Ω—è—é—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –æ—Ç –æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –∫ –¥—Ä—É–≥–æ–º—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/input_latent_space_lin_interpol.png\" width=\"600\">\n",
    "\n",
    "<center><em>–õ–∏–Ω–µ–π–Ω—ã–µ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É —á–µ—Ç—ã—Ä—å–º—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –≤ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/abs/1803.09093\">Comparing Generative Adversarial Network Techniques for Image Creation and Modification(M. Pieters, M. Wiering, 2018)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω–æ–≥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –≤—ã–±–æ—Ä–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—Ö–æ–¥–Ω–æ–≥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –≤–∞–∂–Ω–æ —Å–æ–±–ª—é—Å—Ç–∏  –±–∞–ª–∞–Ω—Å.\n",
    "- –ø—Ä–∏ **–Ω–∏–∑–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç –ø—Ä–æ–±–ª–µ–º–∞ **–Ω–∏–∑–∫–æ–π –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏**.\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ª–∏—Ü —Å –≤—Ö–æ–¥–Ω—ã–º –≤–µ–∫—Ç–æ—Ä–æ–º –¥–ª–∏–Ω—ã 1. –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —Ä–∞–±–æ—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –±—É–¥–µ—Ç –≤—Å–µ–≥–æ –æ–¥–Ω–∞ —à–∫–∞–ª–∞, –≤–¥–æ–ª—å –∫–æ—Ç–æ—Ä–æ–π –±—É–¥—É—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –°–µ—Ç—å —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ **–Ω–µ —Å–º–æ–∂–µ—Ç –≤—ã–¥–∞–≤–∞—Ç—å –≤—Å–µ –º–Ω–æ–≥–æ–æ–±—Ä–∞–∑–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤**, –æ–Ω–∞ –≤—ã—É—á–∏—Ç –Ω–µ–±–æ–ª—å—à—É—é —á–∞—Å—Ç—å: –Ω–∞–ø—Ä–∏–º–µ—Ä –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∑–Ω–∞—á–µ–Ω–∏–π –±—É–¥–µ—Ç –≤—ã–¥–∞–≤–∞—Ç—å –æ—Ç –º–æ–ª–æ–¥–æ–π –∂–µ–Ω—â–∏–Ω—ã –±–ª–æ–Ω–¥–∏–Ω–∫–∏ –¥–æ –ø–æ–∂–∏–ª–æ–≥–æ –º—É–∂—á–∏–Ω—ã –±—Ä—é–Ω–µ—Ç–∞. –£ —Ç–∞–∫–æ–π —Å–µ—Ç–∏ –±—É–¥–µ—Ç **–Ω–∏–∑–∫–∞—è –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å** ‚Äî –æ–Ω–∞ –Ω–µ —Å–º–æ–∂–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä—ã–∂–µ–≥–æ —Ä–µ–±–µ–Ω–∫–∞ –≤ –æ—á–∫–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –ø—Ä–∏ **–±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º **—Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–º**.\n",
    "\n",
    "–ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –≤ —ç—Ç–æ–º –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –±—É–¥–µ—Ç –Ω–∞—Å—Ç–æ–ª—å–∫–æ –º–∞–ª–æ, —á—Ç–æ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –±—É–¥–µ—Ç —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑ –ø—É—Å—Ç–æ—Ç. –¢–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∫—Ä–∞–π–Ω–µ –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –≤ —Ç–æ—á–∫–∞—Ö –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞, –¥–∞–ª–µ–∫–∏—Ö –æ—Ç —Ç–æ—á–µ–∫ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ—É—á—à–∏–π —Å–ø–æ—Å–æ–± **–≤—ã–±—Ä–∞—Ç—å –¥–ª–∏–Ω—É** –≤–µ–∫—Ç–æ—Ä–∞ ‚Äî —ç—Ç–æ **–Ω–∞–π—Ç–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏—é —Å –ø–æ—Ö–æ–∂–µ–π –∑–∞–¥–∞—á–µ–π** –∏ –≤–∑—è—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –Ω–µ–µ. –ï—Å–ª–∏ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç, —Ç–æ –ø—Ä–∏–¥–µ—Ç—Å—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å. –õ—É—á—à–µ **–Ω–∞—á–∏–Ω–∞—Ç—å** —Å **–Ω–∏–∑–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞**, —á—Ç–æ–±—ã **–Ω–∞–ª–∞–¥–∏—Ç—å —Ä–∞–±–æ—Ç—É –≤—Å–µ–π —Å–µ—Ç–∏**, –ø—É—Å—Ç—å –∏ —Å –Ω–∏–∑–∫–∏–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ–º, –∞ –∑–∞—Ç–µ–º –ø—Ä–æ–≤–æ–¥–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ **–ø–æ–∏—Å–∫—É –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏**.\n",
    "\n",
    "–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –≤ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏: —Å–ø—Ä–æ—Å–∏—Ç–µ —Å–µ–±—è, **—Å–∫–æ–ª—å–∫–∏–º–∏ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏ –º–æ–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä–µ–∫—Ç–µ**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –º—ã –∑–Ω–∞–µ–º –∏–∑ –ª–µ–∫—Ü–∏–∏ –ø—Ä–æ –æ–±—É—á–µ–Ω–∏–µ —Å–µ—Ç–∏, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤–Ω–æ—Å—è—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Ä–∞–±–æ—Ç—É –º–æ–¥–µ–ª–∏. –ü–æ—ç—Ç–æ–º—É –ø—Ä–∏–Ω—è—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **–º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ** –¥–ª—è input latent space. –û–Ω–æ –ª—É—á—à–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç —Å –≤–µ—Å–∞–º–∏ –º–æ–¥–µ–ª–∏ –∏ —É–ª—É—á—à–∞–µ—Ç —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/binomial_distribution.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://matplotlib.org/3.1.0/gallery/lines_bars_and_markers/scatter_hist.html\">–î–≤—É–º–µ—Ä–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —ç—Ç–æ–π –ª–µ–∫—Ü–∏–∏ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `lightning` –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ `tbparse` –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–æ–≥–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install lightning tbparse\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ø—Ä–æ–±—É–µ–º —Å–æ–±—Ä–∞—Ç—å **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–æ—á–µ–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏**. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **–ø–∞—Ä–∞–±–æ–ª—É**. –î–ª—è –Ω–∞—á–∞–ª–∞ –Ω–∞–ø–∏—à–µ–º –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å **–∏—Å—Ç–∏–Ω–Ω—ã–µ —Ç–æ—á–∫–∏**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_pair(num=100):\n",
    "    x = np.random.uniform(low=-1, high=1, size=(num,))\n",
    "    y = x * x\n",
    "    return np.hstack(\n",
    "        (x.reshape(-1, 1), y.reshape(-1, 1))\n",
    "    )  # Create num of correct dots(x,y) on parabola\n",
    "\n",
    "\n",
    "set_random_seed(42)\n",
    "pairs = create_pair(100)\n",
    "plt.scatter(pairs[:, 0], pairs[:, 1])\n",
    "plt.title(\"Random dots on parabola,\\nwhich will use like a dataset.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –≤—ã–¥–∞–≤–∞—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º–æ–≤–æ–π –≤–µ–∫—Ç–æ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é  `ls = 1` (–º—ã –≤—ã–±—Ä–∞–ª–∏ —Ç–∞–∫—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ç.–∫. –∑–Ω–∞–µ–º, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è x –∏ y —Å–≤—è–∑–∞–Ω—ã –Ω–µ–∫–æ—Ç–æ—Ä–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π) –∏ –∏—Å—Ç–∏–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã.\n",
    "–ú—ã –∑–∞—Ä–∞–Ω–µ–µ —Å–æ–∑–¥–∞–µ–º –≤ —Ñ—É–Ω–∫—Ü–∏–∏  `__init__` —Ç–æ—á–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å –∏—Å—Ç–∏–Ω–Ω—ã–º–∏.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define input parameters\n",
    "n_batches = 30\n",
    "batch_size = 128\n",
    "ls = 1  # latent space\n",
    "\n",
    "class ParabolaDS(Dataset):\n",
    "    def __init__(self, n_batches, batch_size, ls):\n",
    "        # create ground true item\n",
    "        self.xy_pair = torch.tensor(\n",
    "            create_pair(num=(n_batches * batch_size)), dtype=torch.float\n",
    "        )\n",
    "        self.ls = ls\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.xy_pair.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get ground true item\n",
    "        item = self.xy_pair[idx]\n",
    "        # generate random noise\n",
    "        noise = torch.randn(self.ls, dtype=torch.float)\n",
    "        return item, noise\n",
    "\n",
    "trainset = ParabolaDS(n_batches, batch_size, ls)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –æ–∂–∏–¥–∞—Ç—å —à—É–º –Ω–∞ –≤—Ö–æ–¥ –∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–æ—á–∫–∏ –Ω–∞ –≤—ã—Ö–æ–¥–µ. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Å–ª–æ–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø–æ—Å–∫–æ–ª—å–∫—É –º—ã –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –Ω–∞—à –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤ –∫–∞–∫–æ–º-—Ç–æ –¥–∏–∞–ø–∞–∑–æ–Ω–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_space, hidden_dim=50):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_space, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "        )  # x,y\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ—Ü–µ–Ω–∫–∏ loss.\n",
    "\n",
    "–¢–∞–∫ –∫–∞–∫ –º—ã –Ω–µ –∑–Ω–∞–µ–º, –≤ –∫–∞–∫–æ–º –º–µ—Å—Ç–µ –ø–∞—Ä–∞–±–æ–ª—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–æ–∑–¥–∞—Å—Ç –Ω–æ–≤—É—é —Ç–æ—á–∫—É, —Ç–æ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ, —Å –∫–∞–∫–∏–º —ç–ª–µ–º–µ–Ω—Ç–æ–º –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –µ–µ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í–∞—Ä–∏–∞–Ω—Ç ‚Ññ1 (–∑–∞–¥–∞—á–∞ —É–∂–µ —Ä–µ—à–µ–Ω–∞)**\n",
    "\n",
    "–î–ª—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ $x$ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª—è—Ç—å $y_{target}=x*x$ –∏ —Å—á–∏—Ç–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É $y$, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –º–æ–¥–µ–ª—å—é, –∏ $y_{target}$, –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–º –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(pair, label):\n",
    "    # All inputs are batches\n",
    "    x_fake = pair[:, 0]\n",
    "    y_fake = pair[:, 1]\n",
    "    return torch.abs(x_fake * x_fake - y_fake).mean()  # average by batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å.\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ –µ—Å–ª–∏ –º—ã **–∑–Ω–∞–µ–º —Å–ø–æ—Å–æ–± —Ç–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤—ã—Ö–æ–¥ –ø–æ –≤—Ö–æ–¥—É**, —Ç–æ **–∑–∞–¥–∞—á–∞ —É–∂–µ —Ä–µ—à–µ–Ω–∞** –∏ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –Ω–µ –Ω—É–∂–Ω–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í–∞—Ä–∏–∞–Ω—Ç ‚Ññ2 (–∫–∞–∫ –Ω–µ –Ω–∞–¥–æ –¥–µ–ª–∞—Ç—å)**\n",
    "\n",
    "–ù–∞–π—Ç–∏ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ —Ç–æ—á–∫—É  $ \\text{target} = (x_{\\text{target}},y_{\\text{target}})$, –Ω–∞–∏–±–æ–ª–µ–µ –±–ª–∏–∑–∫—É—é –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–º $ \\text{generated} = (x,y)$, –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —ç—Ç–∏–º–∏ —Ç–æ—á–∫–∞–º–∏ –≤ –∫–∞—á–µ—Å—Ç–≤–µ loss.\n",
    "\n",
    "$$\\large \\text{Loss} = \\min(\\text{dist}(\\text{target}_{i},\\text{generated}))$$\n",
    "\n",
    "\n",
    "**–í –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –≤—ã—Å–æ–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** —Ç–∞–∫–æ–π –ø–æ–∏—Å–∫ –±—É–¥–µ—Ç –≤–µ—Å—å–º–∞ **—Ä–µ—Å—É—Ä—Å–æ–∑–∞—Ç—Ä–∞—Ç–Ω—ã–º**, –Ω–æ –≤ –Ω–∞—à–µ–º —É—á–µ–±–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ —Ä–∞–±–æ—Ç–∞—Ç—å –±—É–¥–µ—Ç.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, targets):\n",
    "        super().__init__()\n",
    "        self.targets = targets  # Remember all real samples, impossible in real world\n",
    "\n",
    "    def forward(self, input, dummy_target=None):\n",
    "        dist = torch.cdist(input, self.targets)  # claculate pairwise distances (euc.)\n",
    "        min_dist, index = torch.min(dist, dim=1)  # take the best\n",
    "        return min_dist.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ –æ–±—É—á–µ–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "# DON'T USE IT! IT'S NAIVE DECISION!\n",
    "class NaiveGAN(L.LightningModule):\n",
    "    def __init__(self, model, criration):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criration = criration\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.criration.targets = self.criration.targets.to(self.device) # for fix device diff\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        real_items, noises = batch\n",
    "        gen_items = self.model(noises)\n",
    "        loss = self.criration(gen_items, real_items)\n",
    "        self.log(\"loss/train\", loss, on_epoch=True, on_step=False)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¶–µ–ª–µ–≤—ã–µ —Ç–æ—á–∫–∏ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–ø–æ–º–∏–Ω–∞—é—Ç—Å—è –≤ loss, –∑–∞—Ç–µ–º –∏–¥–µ—Ç –æ–±—ã—á–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "criterion = Loss(trainset.xy_pair) # save target\n",
    "model = Generator(latent_space=ls)\n",
    "\n",
    "pl_model = NaiveGAN(model, criterion)\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=\"./log_naive/\"),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=pl_model,\n",
    "    train_dataloaders=train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –∫—É–¥–∞ –±—ã–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ª–æ–≥–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = pl_model.logger.log_dir\n",
    "log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—Ä–∏–≤—É—é –æ–±—É—á–µ–Ω–∏—è, —á—Ç–æ–±—ã —É–¥–æ—Å—Ç–æ–≤–µ—Ä–∏—Ç—å—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbparse import SummaryReader\n",
    "\n",
    "def visualization(log_dir):\n",
    "    # visualization without TensorBoard for TensorBoard logs\n",
    "    clear_output()\n",
    "    reader = SummaryReader(log_dir)\n",
    "    df = reader.scalars.drop_duplicates()\n",
    "\n",
    "    uniq = set(df.tag.unique())\n",
    "    uniq.remove(\"epoch\")\n",
    "    uniq = list(uniq)\n",
    "    uniq.sort()\n",
    "\n",
    "    i = 0\n",
    "    ax_dict = {}\n",
    "    for item in uniq:\n",
    "        metric = item.split(\"/\")[0] # log shoud have tag\n",
    "        if metric not in ax_dict:\n",
    "            ax_dict[metric] = i\n",
    "            i += 1\n",
    "\n",
    "    fig, axs = plt.subplots(len(ax_dict), 1, figsize=(12, 3.5 * len(ax_dict)))\n",
    "    for item in uniq:\n",
    "        metric = item.split(\"/\")[0]\n",
    "        if len(ax_dict)>1:\n",
    "            ax = axs[ax_dict[metric]]\n",
    "        else:\n",
    "            ax = axs\n",
    "        sub_df = df[df[\"tag\"] == item]\n",
    "        ax.plot(sub_df.step, sub_df.value, label=item)\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"iter\")\n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "visualization(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ —à—É–º–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image(pair_gen, pairs, figsize=None):\n",
    "    if figsize:\n",
    "        plt.figure(figsize=figsize)\n",
    "    plt.scatter(pairs[:, 0], pairs[:, 1], label=\"real\")\n",
    "    plt.scatter(pair_gen[:, 0], pair_gen[:, 1], label=\"generated\")\n",
    "    plt.axis([-1, 1, 0, 1])\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model.eval().to(\"cpu\")\n",
    "noise = torch.tensor(np.random.normal(size=(1000, ls)), dtype=torch.float)\n",
    "with torch.no_grad():\n",
    "    pair_gen = model(noise).detach().numpy()\n",
    "\n",
    "test_image(pair_gen, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–¥–Ω–æ, —á—Ç–æ –º–æ–¥–µ–ª—å **–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ—á–∫–∏**, –ª–µ–∂–∞—â–∏–µ –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –æ–Ω–∏ –ª–µ–∂–∞—Ç **–≤ –Ω–µ–±–æ–ª—å—à–æ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ –æ–∫–æ–ª–æ $0$**. –≠—Ç–æ –º–æ–∂–Ω–æ –æ–±—ä—è—Å–Ω–∏—Ç—å, —Ç–µ–º, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è –æ—à–∏–±–æ–∫ –æ–∫–æ–ª–æ –Ω—É–ª—è –≤ —Å—Ä–µ–¥–Ω–µ–º –º–µ–Ω—å—à–µ, –≤–µ–¥—å $y$ –æ–∫–æ–ª–æ $0$ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–µ–±–æ–ª—å—à–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π.\n",
    "\n",
    "–í loss –º—ã –ø—Ä–æ–ø–∏—Å–∞–ª–∏, —á—Ç–æ **—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –¥–æ–ª–∂–Ω–∞ –ª–µ–∂–∞—Ç—å –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ**, –∏ –º–æ–¥–µ–ª—å –æ–±—É—á–∏–ª–∞—Å—å. –ù–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –≤ –∫–∞–∫–∏—Ö —á–∞—Å—Ç—è—Ö –∫—Ä–∏–≤–æ–π –¥–æ–ª–∂–Ω—ã –æ–∫–∞–∑–∞—Ç—å—Å—è —Ç–æ—á–∫–∏, –º—ã –≤ loss –Ω–∏–∫–∞–∫ –Ω–µ –∫–æ–¥–∏—Ä–æ–≤–∞–ª–∏. –ë–æ–ª–µ–µ —Ç–æ–≥–æ, –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –Ω–∞—É—á–∏—Ç—å—Å—è —Ö–æ—Ä–æ—à–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–¥–Ω—É –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é —Ç–æ—á–∫—É, –∏ –ø—Ä–∏ —ç—Ç–æ–º loss –º–æ–∂–µ—Ç —Å—Ç–∞—Ç—å –Ω—É–ª–µ–≤—ã–º.\n",
    "\n",
    "–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –≤ loss —Å–µ–π—á–∞—Å **—Ö—Ä–∞–Ω—è—Ç—Å—è –≤—Å–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–æ—á–∫–∏**. –ï—Å–ª–∏ –±—ã –º—ã –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∏ –Ω–µ —Ç–æ—á–∫–∏, –∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ —Å–ø–µ–∫—Ç—Ä—ã - –º—ã –±—ã –ø–æ–ª—É—á–∏–ª–∏ **–ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏**.\n",
    "\n",
    "\n",
    "–ò—Ç–∞–∫, –Ω–∞–¥–æ —Ä–µ—à–∏—Ç—å **–¥–≤–µ –ø—Ä–æ–±–ª–µ–º—ã**:\n",
    "\n",
    "1.   –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –≤ loss —É—Å–ª–æ–≤–∏–µ –æ —Ç–æ–º, —á—Ç–æ **—Ç–æ—á–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏**.\n",
    "2.   –ü—Ä–∏–¥—É–º–∞—Ç—å —Å–ø–æ—Å–æ–± –ø—Ä–æ–≤–µ—Ä–∫–∏, **–Ω–µ —Ç—Ä–µ–±—É—é—â–∏–π —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –ø–µ—Ä–µ–±–æ—Ä–∞ –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë—É–¥–µ–º –Ω–∞–∫–∞–∑—ã–≤–∞—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –Ω–µ —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞ –æ—à–∏–±–æ–∫ , –∞ –≤—Ç–æ—Ä–æ–π\n",
    "**—Å–µ—Ç—å—é**, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å, –ª–µ–∂–∏—Ç –ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ.\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º —Å–µ—Ç—å-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ—á–µ–∫, –∫–æ—Ç–æ—Ä—É—é –Ω–∞–∑–æ–≤—ë–º **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),  # real/fake\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –æ–±—â–µ–º —Å–ª—É—á–∞–µ –∑–∞–¥–∞—á–∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ ‚Äî –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å, **–ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ª–∏ –æ–±—ä–µ–∫—Ç –∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏**. –ï—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –≤—ã—Ä–æ–¥—è—Ç—Å—è –≤ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ - –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –ª–µ–≥–∫–æ –∑–∞–ø–æ–º–Ω–∏—Ç, —á—Ç–æ —ç—Ç–∏ —Ç–æ—á–∫–∏ - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ò—Ç–æ–≥–æ** –º—ã –∏–º–µ–µ–º:\n",
    "- **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä**, –≤—ã–¥–∞—é—â–∏–π —Ç–æ—á–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç—å –ø–∞—Ä–∞–±–æ–ª–µ, –∞ –º–æ–≥—É—Ç –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç—å –µ–π;\n",
    "- **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä**, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Ö —Ä–∞–∑–ª–∏—á–∞—Ç—å.\n",
    "\n",
    "–ú—ã –±—É–¥–µ–º –ø–æ–¥–∞–≤–∞—Ç—å –≤ **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä** **–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏**, –ø–æ–º–µ—á–∞—è –∏—Ö —Ä–µ–∞–ª—å–Ω—ã–º–∏,  –∏ **—Ç–æ—á–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–¥–∞—ë—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä**, —Å—á–∏—Ç–∞—è –∏—Ö –ø–æ–¥–¥–µ–ª–∫–æ–π. **–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä** –±—É–¥–µ—Ç —É—á–∏—Ç—å—Å—è **–ø–æ–¥—Ä–∞–∂–∞—Ç—å** —Ä–µ–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º, –∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –±—É–¥–µ—Ç —É—á–∏—Ç—å—Å—è **–æ—Ç–ª–∏—á–∞—Ç—å** —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏, –æ—Ç –ø–æ–¥–¥–µ–ª–æ–∫.\n",
    "\n",
    "–ú—ã –ø—Ä–∏—à–ª–∏ –∫ –∏–¥–µ–µ **–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö** –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π (Generative Adversarial Network).\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/generative_adversarial_network_scheme.png\" width=\"700\"></center>\n",
    "<center><em>–°—Ö–µ–º–∞—Ç–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã GAN </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generative adversarial network (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[arxiv] üéì Generative Adversarial Networks (Goodfellow et al., 2014)](https://arxiv.org/abs/1406.2661) (**Cited by 62647 (–¥–µ–∫–∞–±—Ä—å 2023)!!!**)\n",
    "\n",
    "[[video] üì∫ –†–∞–∑–±–æ—Ä –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–∏ GAN](https://www.youtube.com/watch?v=eyxmSmjmNS0)\n",
    "\n",
    "[[video] üì∫ –õ–µ–∫—Ü–∏—è –ò–∞–Ω–∞ –ì—É–¥—Ñ–µ–ª–ª–æ—É](https://www.youtube.com/watch?v=HGYYEUSm-0Q)\n",
    "\n",
    "**–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω—É—é** —Å–µ—Ç—å –æ–ø–∏—Å–∞–ª –ò–∞–Ω –ì—É–¥—Ñ–µ–ª–ª–æ—É –∏–∑ –∫–æ–º–ø–∞–Ω–∏–∏ Google (–Ω–∞ —Ç–æ—Ç –º–æ–º–µ–Ω—Ç) –≤ 2014 –≥–æ–¥—É. –ü—Ä–∏–Ω—Ü–∏–ø —Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Å–µ—Ç–∏ GAN —á–∞—Å—Ç–æ –æ–±—ä—è—Å–Ω—è—é—Ç –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –∏–∑ —Ç–µ–æ—Ä–∏–∏ –∏–≥—Ä."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN –≤ —Ç–µ–æ—Ä–∏–∏ –∏–≥—Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –º–æ–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å –∏–¥–µ—é GAN, –∫–∞–∫ **[–∏–≥—Ä—É](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B8%D0%B3%D1%80) –¥–≤—É—Ö –∏–≥—Ä–æ–∫–æ–≤**:\n",
    "\n",
    " - –ü–µ—Ä–≤—ã–π –∏–≥—Ä–æ–∫ - —ç—Ç–æ **—Ñ–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫** –∏–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä (generator).\n",
    " - –í—Ç–æ—Ä–æ–π - —ç—Ç–æ **–±–∞–Ω–∫–∏—Ä** —Å –º–∞—à–∏–Ω–∫–æ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–Ω–µ–≥ –∏–ª–∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä (discriminator).\n",
    "\n",
    "\n",
    " –ó–∞–¥–∞—á–∞ —Ñ–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫–∞ - –æ–±–º–∞–Ω—É—Ç—å –±–∞–Ω–∫–∏—Ä–∞. –ó–∞–¥–∞—á–∞ –±–∞–Ω–∫–∏—Ä–∞ - –æ—Ç–ª–∏—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –¥–µ–Ω—å–≥–∏ –æ—Ç —Ñ–∞–ª—å—à–∏–≤—ã—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/gan_idea.png\" width=\"600\"></center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫—É –Ω–µ–æ–±—Ö–æ–¥–∏–º —ç–ª–µ–º–µ–Ω—Ç —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ $z$. –ú–æ–∂–Ω–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–æ–≥–∏—é: –µ—Å–ª–∏ –≤—Å–µ —Ñ–∞–ª—å—à–∏–≤—ã–µ –∫—É–ø—é—Ä—ã –±—É–¥—É—Ç –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä - –±–∞–Ω–∫–∏—Ä—É –±—É–¥–µ—Ç –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–¥–¥–µ–ª–∫—É. –§–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫ –±–µ—Ä–µ—Ç –Ω–∞ –≤—Ö–æ–¥ —à—É–º $z$ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∞–ª—å—à–∏–≤—É—é –ø–∞—á–∫—É –¥–µ–Ω–µ–≥ $G(z)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–∞–Ω–∫–∏—Ä $D$ –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –ø–∞—á–∫—É –∫—É–ø—é—Ä $x$, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Ö –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç—å –∏ —Å–æ–æ–±—â–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä $D(x)$, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ —á–∏—Å–µ–ª –æ—Ç –Ω—É–ª—è –¥–æ –µ–¥–∏–Ω–∏—Ü—ã ‚Äî —Å–≤–æ—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å) –ø–æ –∫–∞–∂–¥–æ–π –∫—É–ø—é—Ä–µ –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–∞ –Ω–∞—Å—Ç–æ—è—â–∞—è.\n",
    "\n",
    "**–¶–µ–ª—å –±–∞–Ω–∫–∏—Ä–∞ (–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞):** –æ—Ç–ª–∏—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –¥–µ–Ω—å–≥–∏ –æ—Ç —Ñ–∞–ª—å—à–∏–≤—ã—Ö\n",
    "\n",
    "\n",
    "$$D(x_i) = 1,  x_i  \\text{ - real},$$\n",
    "\n",
    "$$D(G(z_i)) = 0, G(z_i) \\text{ - fake},$$\n",
    "\n",
    "\n",
    "—Ç–æ –µ—Å—Ç—å –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å $log(D(x))+log(1-D(G(z)))$.\n",
    "\n",
    "**–¶–µ–ª—å —Ñ–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫–∞ (–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞):** —É–±–µ–¥–∏—Ç—å –±–∞–Ω–∫–∏—Ä–∞ –≤ —Ç–æ–º, —á—Ç–æ –ø–æ–¥–¥–µ–ª–∫–∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ\n",
    "\n",
    "\n",
    "$$D(G(z_i)) = 1, G(z_i) \\text{ - fake}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —ç—Ç–æ –º–æ–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å, –∫–∞–∫:\n",
    "\n",
    "$$\\large \\min\\limits_{\\theta_g}  \\max\\limits_{\\theta_d} [\\mathbb{E}_{x _\\sim p(x)} log(D_{\\theta_d}(x)]+\\mathbb{E}_{z _\\sim p(z)}\n",
    "[log(1-D_{\\theta_d}(G_{\\theta_g}(z))]$$\n",
    "\n",
    "–≥–¥–µ $\\theta_g$ - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞, –≤ $\\theta_d$ - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä (–±–∞–Ω–∫–∏—Ä):**\n",
    "- –æ–±—É—á–∞–µ—Ç—Å—è –ø—Ä–∏ **—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ** ${G}_{\\theta_{g}}$,\n",
    "- **–º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç** —Ñ—É–Ω–∫—Ü–∏—é –≤—ã—à–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ $\\theta_d$ (**–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –ø–æ–¥—ä–µ–º**),\n",
    "- —Ä–µ—à–∞–µ—Ç –∑–∞–¥–∞—á—É **–±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**: —Å—Ç–∞—Ä–∞–µ—Ç—Å—è –ø—Ä–∏—Å–≤–æ–∏—Ç—å $1$ —Ç–æ—á–∫–∞–º –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞ $E_{x‚àºp_{data}}$ –∏ 0 —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—ã–±–æ—Ä–∫–∞–º $E_{z‚àºp(z)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä (—Ñ–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫):**\n",
    "- –æ–±—É—á–∞–µ—Ç—Å—è –ø—Ä–∏ **—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–µ** $D_{Œ∏_d}$,\n",
    "- –ø–æ–ª—É—á–∞–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤–µ—Å–æ–≤ –∑–∞ —Å—á–µ—Ç backpropagation —á–µ—Ä–µ–∑ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä,\n",
    "- **–º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç** —Ñ—É–Ω–∫—Ü–∏—é –≤—ã—à–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ $\\theta_d$ (**–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –ø—Ä–æ—Ü–µ—Å—Å–µ —Å–æ–≤–º–µ—Å—Ç–Ω–æ–≥–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –µ—Å–ª–∏ —Å–∏—Å—Ç–µ–º–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∞, –¥–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è **–º–∏–Ω–∏–º–∞–∫—Å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–∞–≤–Ω–æ–≤–µ—Å–∏—è**, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–±–µ —Å–µ—Ç–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —É—á–∞—Ç—Å—è.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º –Ω–∞—à–∏ **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä** –∏ **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_space, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_space, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "        )  # x,y\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),  # real/fake\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º **–≤—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã**. –î–ª—è –æ–±—É—á–µ–Ω–∏—è –≥–∞–Ω–∞ –Ω—É–∂–Ω–æ –º–Ω–æ–≥–æ —Ä–µ–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ—Ç–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 10  # latent space\n",
    "num_epochs = 1\n",
    "n_batches = 10000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —É –Ω–∞—Å —Ç–∞–∫ –∂–µ, –∫–∞–∫ –∏ –≤ –ø–µ—Ä–≤–æ–º –ø—Ä–∏–º–µ—Ä–µ, –µ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è **latent space**. –≠—Ç–æ —Ç–æ—Ç —à—É–º, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã –±—É–¥–µ–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à–∏ —Ç–æ—á–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä** —Ä–µ—à–∞–µ—Ç –∑–∞–¥–∞—á—É **–±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**. –î–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç [`BCELoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html) (**Binary Cross Entropy**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è GAN**\n",
    "\n",
    "–û–±—É—á–µ–Ω–∏–µ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞:\n",
    "1. –†–∞—Å—á–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ (real —Ç–æ—á–∫–∏):\n",
    "    * –æ–±–Ω—É–ª–∏–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞**\n",
    "    * –≤–æ–∑—å–º–µ–º –Ω–∞–±–æ—Ä **real —Ç–æ—á–µ–∫**, –∫–æ—Ç–æ—Ä—ã–µ –ª–µ–∂–∞—Ç –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ,\n",
    "    * –ø—Ä–∏–º–µ–Ω–∏–º –∫ –Ω–∏–º **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä**,\n",
    "    * –ø–æ—Å—á–∏—Ç–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –Ω–∞ **real —Ç–æ—á–∫–∞—Ö** –∏ **real –º–µ—Ç–∫–∞—Ö** `loss_disc_real`,\n",
    "    * –ø–æ—Å—á–∏—Ç–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/gan_training_algorithm_1.png\" width=\"1000\">\n",
    "\n",
    "–ü—Ä–æ–¥–æ–ª–∂–∞—è –∞–Ω–∞–ª–æ–≥–∏—é —Å –∏–≥—Ä–æ–π: –≤ —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç –±–∞–Ω–∫–∏—Ä –∏–∑—É—á–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –∫—É–ø—é—Ä—ã, —á—Ç–æ–±—ã —É—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞—Ç—å –º–∞—à–∏–Ω–∫—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–Ω–µ–≥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. –†–∞—Å—á–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ (fake —Ç–æ—á–∫–∏):\n",
    "    * –≤–æ–∑–±–º–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º\n",
    "$z$,\n",
    "    * –≤–æ–∑—å–º–µ–º –Ω–∞—à **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä** (–µ–≥–æ –ø–æ–∫–∞ –Ω–µ –æ–±—É—á–∞–µ–º) –∏ —Å–æ–∑–¥–∞–¥–∏–º —Å –µ–≥–æ –ø–æ–º–æ—â—å—é **fake —Ç–æ—á–∫–∏** –∏–∑ $z$,\n",
    "    * –ø–æ—Å—á–∏—Ç–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –Ω–∞ **fake —Ç–æ—á–∫–∞—Ö** –∏ **fake –º–µ—Ç–∫–∞—Ö** `loss_disc_fake`,\n",
    "    * –ø–æ—Å—á–∏—Ç–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞** (–æ–Ω–∏ —Å–ª–æ–∂–∞—Ç—Å—è —Å —É–∂–µ –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—ã–º–∏ —Ä–∞–Ω–µ–µ).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/gan_training_algorithm_2.png\" width=\"1000\">\n",
    "\n",
    "\n",
    "–ü–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –∏–≥—Ä–æ–π: –≤ —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç –±–∞–Ω–∫–∏—Ä –∏–∑—É—á–∞–µ—Ç —Ñ–∞–ª—å—à–∏–≤—ã–µ –∫—É–ø—é—Ä—ã, —á—Ç–æ–±—ã —É—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞—Ç—å –º–∞—à–∏–Ω–∫—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–Ω–µ–≥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞\n",
    "   * —Å–¥–µ–ª–∞–µ–º —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞** (–æ–±–Ω–æ–≤–∏–º –µ–≥–æ –≤–µ—Å–∞),\n",
    "   * **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä** –Ω–µ –æ–±—É—á–∞–µ—Ç—Å—è.\n",
    "\n",
    "–ü–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –∏–≥—Ä–æ–π: –≤ —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç –±–∞–Ω–∫–∏—Ä –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –º–∞—à–∏–Ω–∫—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞:\n",
    "\n",
    "   * –æ–±–Ω—É–ª–∏–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞**,\n",
    "   * —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º $z$,\n",
    "   * —Å–æ–∑–¥–∞–¥–∏–º —Å –ø–æ–º–æ—â—å—é **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞** –Ω–∞–±–æ—Ä **fake —Ç–æ—á–µ–∫** –∏–∑ $z$,\n",
    "   * –ø–æ—Å—á–∏—Ç–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –Ω–∞ **fake —Ç–æ—á–∫–∞—Ö** –∏ **real –º–µ—Ç–∫–∞—Ö** `loss_gen` (–ø–æ–¥–º–µ–Ω–∞ –º–µ—Ç–æ–∫),\n",
    "   * –ø–æ—Å—á–∏—Ç–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞**,\n",
    "   * —Å–¥–µ–ª–∞–µ–º —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞** (–æ–±–Ω–æ–≤–∏–º –µ–≥–æ –≤–µ—Å–∞),\n",
    "   * **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä** –Ω–µ –æ–±—É—á–∞–µ—Ç—Å—è.\n",
    "\n",
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –≤–º–µ—Å—Ç–æ —Ä–µ—à–µ–Ω–∏—è minmax –∑–∞–¥–∞—á–∏ - –º—ã –ø–æ–¥–º–µ–Ω—è–µ–º –º–µ—Ç–∫–∏. –≠—Ç–æ - [—á–∞—Å—Ç–æ –ø—Ä–∏–º–µ–Ω—è–µ–º—ã–π —Ç—Ä—é–∫](https://github.com/soumith/ganhacks/#2-a-modified-loss-function) –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/gan_training_algorithm_3.png\" width=\"1000\">\n",
    "\n",
    "–ü–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –∏–≥—Ä–æ–π: —Ñ–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫ –Ω–µ –ø—Ä–æ—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥–¥–µ–ª–∫–∏ –Ω–∞—É–¥–∞—á—É. –û–Ω –¥–æ–±—ã–≤–∞–µ—Ç –ø—Ä–∏–±–æ—Ä –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–æ–¥–¥–µ–ª–æ–∫, —Ä–∞–∑–±–∏—Ä–∞–µ—Ç –µ–≥–æ, —Å–º–æ—Ç—Ä–∏—Ç, –∫–∞–∫ —Ç–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏ –∑–∞—Ç–µ–º —Å–æ–∑–¥–∞–µ—Ç –ø–æ–¥–¥–µ–ª–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–º–æ–≥—É—Ç –æ–±–º–∞–Ω—É—Ç—å —ç—Ç–æ—Ç –ø—Ä–∏–±–æ—Ä."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —ç—Ç–æ —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è –≤ –∫–æ–¥–µ –æ–±—É—á–µ–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(L.LightningModule):\n",
    "    def __init__(self, generator, discriminator, lr=3e-4, betas=(0.9, 0.999),\n",
    "                 noise_in_place=False, latent_dim=10):\n",
    "        super().__init__()\n",
    "        self.automatic_optimization = False # for hand made settings\n",
    "\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.real_lable = 1.\n",
    "        self.fake_lable = 0.\n",
    "        self.lr = lr\n",
    "        self.betas = betas\n",
    "        self.noise_in_place = noise_in_place\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_gen = torch.optim.Adam(\n",
    "            self.generator.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=self.betas,\n",
    "        )\n",
    "        opt_disc = torch.optim.Adam(\n",
    "            self.discriminator.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=self.betas,\n",
    "        )\n",
    "        return [opt_gen, opt_disc], []\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        if self.noise_in_place: # for standart dataset\n",
    "            self.real_items, _ = batch\n",
    "            noises = torch.randn(\n",
    "                (self.real_items.shape[0], self.latent_dim),\n",
    "                dtype=torch.float32,\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.real_items, noises = batch # for heandmade dataset\n",
    "        opt_gen, opt_disc = self.optimizers()\n",
    "\n",
    "        # ---------------------\n",
    "        # Train discriminator\n",
    "        # ---------------------\n",
    "        self.discriminator.zero_grad()\n",
    "        # 1. discriminator on real items\n",
    "        real_lable = torch.full(\n",
    "            size=(self.real_items.shape[0], 1),\n",
    "            fill_value=self.real_lable,\n",
    "            dtype=torch.float,\n",
    "        ).to(self.device)\n",
    "        disc_lable = self.discriminator(self.real_items)\n",
    "        loss_disc_real = self.criterion(disc_lable, real_lable)\n",
    "        loss_disc_real.backward()\n",
    "\n",
    "        # 2. discriminator on fake items\n",
    "        fake_lable = torch.full(\n",
    "            size=(self.real_items.shape[0], 1),\n",
    "            fill_value=self.fake_lable,\n",
    "            dtype=torch.float,\n",
    "        ).to(self.device)\n",
    "        self.fake_items = self.generator(noises)\n",
    "        disc_lable = self.discriminator(self.fake_items)\n",
    "        loss_disc_fake = self.criterion(disc_lable, fake_lable)\n",
    "        loss_disc_fake.backward()\n",
    "\n",
    "        # 3. discriminator optimizer step (on real and fake items)\n",
    "        opt_disc.step()\n",
    "        loss_disc = 0.5*loss_disc_real + 0.5*loss_disc_fake\n",
    "        self.log(\"loss/disc\", loss_disc, on_epoch=False, on_step=True)\n",
    "\n",
    "        # ---------------------\n",
    "        # Train generator\n",
    "        # ---------------------\n",
    "        self.generator.zero_grad()\n",
    "        self.fake_items = self.generator(noises)\n",
    "        disc_lable = self.discriminator(self.fake_items)\n",
    "        loss_gen = self.criterion(disc_lable, real_lable)\n",
    "        loss_gen.backward()\n",
    "\n",
    "        opt_gen.step()\n",
    "        self.log(\"loss/gen\", loss_gen, on_epoch=False, on_step=True)\n",
    "\n",
    "        if (batch_idx+1)%100==0:\n",
    "            visualization(self.logger.log_dir)\n",
    "            test_image(\n",
    "                self.fake_items.detach().cpu().numpy(),\n",
    "                self.real_items.detach().cpu().numpy(),\n",
    "                figsize=(12, 3.5),\n",
    "            )\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        visualization(self.logger.log_dir)\n",
    "        test_image(\n",
    "            self.fake_items.detach().cpu().numpy(),\n",
    "            self.real_items.detach().cpu().numpy(),\n",
    "            figsize=(12, 3.5),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –º–æ–¥–µ–ª–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)\n",
    "trainset = ParabolaDS(n_batches, batch_size, latent_dim)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "generator = Generator(latent_space=latent_dim, hidden_dim=50)\n",
    "discriminator = Discriminator(hidden_dim=50)\n",
    "\n",
    "pl_model = GAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–∏–º –Ω–∞—à GAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model = GAN(generator, discriminator)\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=\"./log_gan/\"),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=pl_model,\n",
    "    train_dataloaders=train_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£ –Ω–∞—Å –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–æ—á–∫–∏ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –ø–æ –ø–∞—Ä–∞–±–æ–ª–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN ‚Äî –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–° –ø–æ–º–æ—â—å—é **GAN** –º–æ–∂–Ω–æ, –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–æ—á–∫–∏ –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ, –Ω–æ –∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ù–æ –ø–æ—è–≤–ª—è—é—Ç—Å—è –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–∞–∫ –∏–∑ —à—É–º–∞ –Ω–∞ –≤—Ö–æ–¥–µ —Å–µ—Ç–∏ –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∞–º—ã–º –ø—Ä–æ—Å—Ç—ã–º –æ—Ç–≤–µ—Ç–æ–º –±—É–¥–µ—Ç: –≤–∑—è—Ç—å —à—É–º, –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –µ–≥–æ —á–µ—Ä–µ–∑ **–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏** –∏ —Å–¥–µ–ª–∞—Ç—å **reshape** –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è. –í —Ü–µ–ª–æ–º, —ç—Ç–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å.\n",
    "\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ **DCGAN (Deep Convolutional GAN)** –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **—Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ** –∏ **—Å–≤–µ—Ä—Ç–æ—á–Ω–æ-—Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ** (*convolutional* –∏ *convolutional-transpose*) —Å–ª–æ–∏ –≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ. –í–ø–µ—Ä–≤—ã–µ –º–µ—Ç–æ–¥ **DCGAN** –±—ã–ª –æ–ø–∏—Å–∞–Ω –≤ —Å—Ç–∞—Ç—å–µ [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (Radford et al., 2015)](https://arxiv.org/abs/1511.06434)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/deep_convolutional_gan_scheme.png\" width=\"700\"></center>\n",
    "<center><em>–°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã DCGAN (Radford et al., 2015).</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∏–∂–µ –≤–∏–¥–Ω–∞ —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ **–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö —Å–ª–æ—ë–≤** –∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ **–æ–±—Ä–∞—Ç–Ω—ã—Ö —Å–≤—ë—Ä—Ç–æ–∫**. –í–∏–¥–Ω–æ, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç **DCGAN** –ª—É—á—à–µ, —á–µ–º **GAN**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/gan_dcgan_mnist_examples.png\" width=\"600\"></center>\n",
    "<center><em>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ MNIST (Radford et al., 2015)</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/pdf/1511.06434.pdf\">\tUnsupervised representation learning with deep convolutional generative adversarial networks</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ –≤—Ö–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –ø–æ–¥–∞—é—Ç —à—É–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤. –≠—Ç–æ—Ç —à—É–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –≤–µ–∫—Ç–æ—Ä –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ. –û–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä ‚Äî –æ–¥–∏–Ω —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç. –ó–∞–¥–∞—á–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n",
    "\n",
    "–¢–∞–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–∏ –ø–æ–º–æ—â–∏ —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö (convolution-transpose, –∏–Ω–æ–≥–¥–∞ –Ω–∞–∑—ã–≤–∞—é—Ç fractionally strided convolution) —Å–ª–æ–µ–≤ –∏–ª–∏ upsample —Å–ª–æ–µ–≤ —Å –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Å–≤–µ—Ä—Ç–∫–æ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/dcgan_architecture.png\" width=\"900\"></center>\n",
    "<center><em>–ó–µ—Ä–∫–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ DCGAN </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–Ω–æ–≥–æ DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ø—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–Ω–æ–≥–æ **DCGAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True if torch.cuda.is_available() else False\n",
    "model = torch.hub.load(\n",
    "    \"facebookresearch/pytorch_GAN_zoo:hub\", \"DCGAN\", pretrained=True, useGPU=use_gpu\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å–ø–µ—á–∞—Ç–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.getNetG())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å–ø–µ—á–∞—Ç–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.getNetD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "\n",
    "num_images = 16\n",
    "noise, _ = model.buildNoiseData(num_images)\n",
    "with torch.no_grad():\n",
    "    generated_images = model.test(noise)\n",
    "    generated_images = (\n",
    "        generated_images.clamp(-1, 1) + 1\n",
    "    ) / 2.0  # normalization to 0..1 range\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16 * 3, 2 * 3))\n",
    "ax.imshow(\n",
    "    torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy(),\n",
    "    interpolation=\"nearest\",\n",
    "    aspect=\"equal\",\n",
    ")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–∞–º–∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–π **DCGAN** –∏ –æ–±—É—á–∏—Ç—å –µ–≥–æ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ **FashionMNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3  # Num of epochs\n",
    "batch_size = 64  # batch size\n",
    "lr = 2e-4  # Learning rate\n",
    "b1 = 0.5  # Adam: decay of first order momentum of gradient\n",
    "b2 = 0.999  # Adam: decay of first order momentum of gradient\n",
    "latent_dim = 100  # latent space\n",
    "img_size = 32  # images size\n",
    "channels = 1  # Num of channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—ã—á–Ω–æ –º—ã **–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å–∞** —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º, –Ω–æ –Ω–∏—á—Ç–æ –Ω–µ –º–µ—à–∞–µ—Ç –Ω–∞–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏—Ö —Ç–∞–∫, –∫–∞–∫ –º—ã —Ö–æ—Ç–∏–º. –í [–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–µ](https://arxiv.org/pdf/1511.06434.pdf) –ø—Ä–æ **DCGAN** –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Å —Ü–µ–Ω—Ç—Ä–æ–º –≤ –Ω—É–ª–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º 0,02:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, –∫–∞–∫ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è **—à—É–º** –≤ **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ**:\n",
    "* –°–Ω–∞—á–∞–ª–∞ —Å –ø–æ–º–æ—â—å—é **–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è** –æ–Ω –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ **–ø–µ—Ä–≤–∏—á–Ω—ã–µ —Ñ–∏—á–∏**\n",
    "* –ü–æ—Ç–æ–º —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `view` **—Ä–µ—Å—ç–º–ø–ª–∏—Ç—Å—è** –≤ –∫–∞—Ä—Ç–∏–Ω–∫—É –Ω–∏–∑–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è\n",
    "* –ü–æ—Ç–æ–º –ø—Ä–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ **conv_blocks** –∫ –Ω–µ–º—É –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è `ConvTranspose2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channel, out_channel, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_size, channels):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = img_size // 2**2\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size**2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            GeneratorBlock(in_channel=128, out_channel=128),\n",
    "            GeneratorBlock(in_channel=128, out_channel=64),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, bn=True):\n",
    "        super().__init__()\n",
    "        block = [\n",
    "            nn.Conv2d(\n",
    "                in_channel, out_channel, kernel_size=3, stride=2, padding=1\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "        ]\n",
    "        if bn:\n",
    "            block.append(nn.BatchNorm2d(out_channel, 0.8))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            DiscriminatorBlock(channels, 16, bn=False),\n",
    "            DiscriminatorBlock(16, 32),\n",
    "            DiscriminatorBlock(32, 64),\n",
    "            DiscriminatorBlock(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2**4\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(128 * ds_size**2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(42)\n",
    "L.seed_everything(42)\n",
    "\n",
    "# Initialize Generator and Discriminator\n",
    "generator = Generator(\n",
    "    latent_dim=latent_dim, img_size=img_size, channels=channels\n",
    ")\n",
    "discriminator = Discriminator(channels=channels)\n",
    "\n",
    "# Initialize weight\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "pl_model = GAN(generator, discriminator, noise_in_place=True, latent_dim=100,\n",
    "               lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "def test_image(fake_items, real_items, figsize=(5, 5)):\n",
    "    grid_fake = make_grid(\n",
    "        torch.tensor(fake_items[:10]),\n",
    "        nrow=10,\n",
    "        normalize=True\n",
    "    ).permute(1, 2, 0).numpy()\n",
    "\n",
    "    grid_real = make_grid(\n",
    "        torch.tensor(real_items[:10]),\n",
    "        nrow=10,\n",
    "        normalize=True\n",
    "    ).permute(1, 2, 0).numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=figsize)\n",
    "    ax[0].imshow(grid_fake)\n",
    "    ax[0].set_axis_off()\n",
    "    ax[1].imshow(grid_real)\n",
    "    ax[1].set_axis_off()\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–¥–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ –∏ –∑–∞–≥—Ä—É–∑–∏–º –∏ –∏—Ö –≤ Data Loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        \"../../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(img_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5], [0.5]),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=\"./log_cgan/\"),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=pl_model,\n",
    "    train_dataloaders=data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –ø—Ä–æ—É—á–∏–ª–∏ –º–æ–¥–µ–ª—å 3 —ç–ø–æ—Ö–∏. –í–∏–¥–Ω–æ, —á—Ç–æ Loss –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–µ —Å–æ—à–ª–∏—Å—å, –Ω–æ –Ω–∞—á–∞–ª–∏ —Ä–∞—Å—Ö–æ–¥–∏—Ç—å—Å—è. –ü—Ä–∏ —ç—Ç–æ–º –Ω–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–∞—è —Ä—è–±—å. –ï—Å–ª–∏ —É–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö - –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —É–ª—É—á—à–∏—Ç—å—Å—è, —ç—Ñ—Ñ–µ–∫—Ç —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è Loss —Ç–æ–ª—å–∫–æ —É—Å–∏–ª–∏—Ç—å—Å—è.\n",
    "\n",
    "\n",
    "–¢–∞–∫–∞—è —Å–∏—Ç—É–∞—Ü–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —á–∞—â–µ, —á–µ–º –Ω–∞–º –±—ã —Ö–æ—Ç–µ–ª–æ—Å—å.  –ù–∏–∂–µ –ø–æ–∫–∞–∑–∞–Ω—ã –∫—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ GAN –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ MNIST, –≤–∑—è—Ç—ã–µ –∏–∑ [—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è](https://github.com/znxlwm/pytorch-generative-model-collections/tree/master)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://raw.githubusercontent.com/znxlwm/pytorch-generative-model-collections/master/assets/mnist_results/GAN_loss.png\" width=\"600\"></center>\n",
    "<center><em>–ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ GAN –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ MNIST</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://github.com/znxlwm/pytorch-generative-model-collections\"> Pytorch implementation of various GANs.</a></em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –¢–æ–Ω–∫–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è GAN–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[–°—Ç–∞—Ç—å—è ‚Äî –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä —Ç–æ–Ω–∫–æ—Å—Ç–µ–π –∏ —Å–æ–≤–µ—Ç–æ–≤](https://beckham.nz/2021/06/28/training-gans.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–æ–±–ª–µ–º–∞ –±–æ–ª—å—à–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–Ω–æ–π –∏–∑ –ø—Ä–∏—á–∏–Ω –ø—Ä–æ–±–ª–µ–º —Å–æ —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å—é GAN —è–≤–ª—è—é—Ç—Å—è –±–æ–ª—å—à–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ —Å–±–æ—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞.\n",
    "\n",
    "–í —Å—Ç–∞—Ç—å–µ [Wasserstein GAN](https://arxiv.org/pdf/1701.07875.pdf) –ø–æ–∫–∞–∑–∞–Ω–æ, —á—Ç–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –ø–ª–∞–≤–Ω–æ—Å—Ç–∏ ([k-–õ–∏–ø—à–∏—Ü–µ–≤–æ—Å—Ç–∏](https://en.wikipedia.org/wiki/Lipschitz_continuity)) –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ —É–ª—É—á—à–∞–µ—Ç —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å GAN. –ï—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—é —Ç–∞–∫–æ–π –ø–ª–∞–≤–Ω–æ—Å—Ç–∏. –í–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–∑ –Ω–∏—Ö:\n",
    "- –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è:\n",
    "    - **weight clipping** - –∫–ª–∏–ø–ø–∏–Ω–≥ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è) –≤–µ—Å–æ–≤. –ú–æ–∂–µ—Ç [–¥–∞–≤–∞—Ç—å —á—Ä–µ–∑–º–µ—Ä–Ω–æ —Å–∏–ª—å–Ω—É—é —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é](https://beckham.nz/2021/06/28/training-gans.html);\n",
    "    - **gradient penalty** - —à—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π –≥—Ä–∞–¥–∏–µ–Ω—Ç (–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –≤—ã–±—Ä–∞–Ω –≥—Ä–∞–¥–∏–µ–Ω—Ç —Å –Ω–æ—Ä–º–æ–π 1). C—Ç–∞—Ç—å—è [—Ç—É—Ç](https://arxiv.org/pdf/1704.00028.pdf). –ö–æ–¥ [—Ç—É—Ç](https://github.com/EmilienDupont/wgan-gp). –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ —Å–ª–æ–∂–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è.\n",
    "    - —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è. [–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ –¥–µ—à–µ–≤—ã–π –∞–Ω–∞–ª–æ–≥ gradient penalty](https://beckham.nz/2021/06/28/training-gans.html). –°—Ç–∞—Ç—å—è [—Ç—É—Ç](https://arxiv.org/pdf/1802.05957.pdf). –ö–æ–¥ - –Ω–∏–∂–µ.\n",
    "- –ò–∑–º–µ–Ω–µ–Ω–∏–µ Loss:\n",
    "    - —Ñ—É–Ω–∫—Ü–∏–∏ c Cross-Entropy –Ω–∞ **[—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –í–∞—Å—Å–µ—Ä—à—Ç–µ–π–Ω–∞](https://en.wikipedia.org/wiki/Wasserstein_metric)** -  —É—Ö–æ–¥ –æ—Ç –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ –±–æ–ª—å—à–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –ø—Ä–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞, —á—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç - —Ñ–µ–π–∫. –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ —Å **weight clipping** –∏–ª–∏ **gradient penalty**. –°—Ç–∞—Ç—å—è [—Ç—É—Ç](https://arxiv.org/pdf/1701.07875.pdf). –†–µ–∞–ª–∏–∑–∞—Ü—è [—Ç—É—Ç](https://github.com/znxlwm/pytorch-generative-model-collections/blob/master/WGAN.py).\n",
    "    - –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∫–∞—Ä—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.  C—Ç–∞—Ç—å—è [—Ç—É—Ç](https://proceedings.neurips.cc/paper_files/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf). –†–µ–∞–ª–∏–∑–∞—Ü—è [—Ç—É—Ç](https://github.com/openai/improved-gan).\n",
    "\n",
    "- **Top-k Training:** –æ—Ç–∫–∞–∑ –æ—Ç –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –ø–ª–æ—Ö–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö. –ì—Ä–∞–¥–∏–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ top-k –Ω–∞–∏–ª—É—á—à–∏–º —Å–ø–æ—Å–æ–±–æ–º —Å–≥–µ–Ω–µ—Ä–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤. –û–±—ä–µ–∫—Ç—ã —Å –±–æ–ª—å—à–∏–º–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ –æ—Ç–±—Ä–∞—Å—ã–≤–∞—é—Ç—Å—è. –°—Ç–∞—Ç—å—è [—Ç—É—Ç](https://arxiv.org/abs/2002.06224).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –ø–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∫ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "def add_spectral_norm(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, torch.nn.Conv2d):\n",
    "        m = spectral_norm(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "set_random_seed(42)\n",
    "L.seed_everything(42)\n",
    "\n",
    "# Initialize Generator and Discriminator\n",
    "generator = Generator(\n",
    "    latent_dim=latent_dim, img_size=img_size, channels=channels\n",
    ")\n",
    "\n",
    "discriminator = Discriminator(channels=channels)\n",
    "\n",
    "# Initialize weight\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "discriminator.apply(add_spectral_norm)\n",
    "\n",
    "pl_model = GAN(generator, discriminator, noise_in_place=True, latent_dim=100,\n",
    "               lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=\"./log_cgan/\"),\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=pl_model,\n",
    "    train_dataloaders=data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss –º–µ–Ω—è–µ—Ç—Å—è –±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤–æ. –ù–µ—Ç —Ä—è–±–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö. –ü—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö - –∫–∞—á–µ—Å—Ç–≤–æ –µ—â–µ –ª—É—á—à–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î—Ä—É–≥–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ —Å–ø–∏—Å–∫–æ–º —Å–æ–≤–µ—Ç–æ–≤ –ø–æ –æ–±—É—á–µ–Ω–∏—é GAN](https://github.com/soumith/ganhacks/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ—Å—Ç—ã–µ –æ—à–∏–±–∫–∏**:\n",
    "- –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Ç–æ–º –∂–µ —á–∏—Å–ª–æ–≤–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ –∏ –∏–º–µ—Ç—å —Ç–æ—Ç –∂–µ —Ä–∞–∑–º–µ—Ä, —á—Ç–æ –∏ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.\n",
    "- –ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ `BatchNorm` —Å–ª–µ–¥–∏—Ç–µ, —á—Ç–æ–±—ã  real –∏ fake –±–∞—Ç—á–∏ [–ø–æ—Å—Ç—É–ø–∞–ª–∏ –Ω–∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –æ—Ç–¥–µ–ª—å–Ω–æ](https://github.com/soumith/ganhacks/?tab=readme-ov-file#4-batchnorm). –ü—Ä–∏ –Ω–µ–±–æ–ª—å—à–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –±–∞—Ç—á–µ –∏–ª–∏ —Å—Ç—Ä–∞–Ω–Ω–æ–º –ø–æ–≤–µ–¥–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ - –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `InstanceNorm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ù—É–∂–Ω–æ –ª–∏ –¥–∞–≤–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä—É?**\n",
    "\n",
    "–û–¥–∏–Ω –∏–∑ —Å–∞–º—ã—Ö —Å—Ç–∞—Ä—ã—Ö –∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–æ–≤–µ—Ç–æ–≤ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ GAN - –¥–∞–≤–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä—É. –í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤ —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å —Ä–µ—à–∏—Ç—å –æ–≥—Ä–∞–Ω–∏–µ—á–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä:**\n",
    "\n",
    "–í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å—Ç–∞—Ç—å—è—Ö **GAN** –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **ADAM**. –í [—Å—Ç–∞—Ç—å–µ](https://arxiv.org/pdf/1802.05957.pdf) –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ –ø–æ–∏—Å–∫—É –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞: –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä $\\beta_1 = 0.5, \\beta_2 = 0.999, lr = 2\\cdot 10^{-4}$ - —Ö–æ—Ä–æ—à–∞—è –æ—Ç–ø—Ä–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–∞—Ä–∞–º–µ—Ç—Ä `epsilon` **ADAM** –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ PyTorch —Ä–∞–≤–µ–Ω `1e-8`, —á—Ç–æ –º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã –ø–æ—Å–ª–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ –æ–±—É—á–µ–Ω–∏—è, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–Ω–∞—á–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –≤–∑—Ä—ã–≤–∞—é—Ç—Å—è –∏–ª–∏ —É–≤–µ–ª–∏—á–∏–≤–∞—é—Ç—Å—è.  –î–ª—è –±–æ—Ä—å–±—ã —Å —ç—Ç–∏–º, –ø–∞—Ä–∞–º–µ—Ç—Ä `epsilon` –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä –¥–æ `1e-3`. –ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ–± —ç—Ç–æ–º –Ω–∞ [StackOverflow](https://stackoverflow.com/questions/42327543/adam-optimizer-goes-haywire-after-200k-batches-training-loss-grows) –∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ [Reddit](https://www.reddit.com/r/reinforcementlearning/comments/j9rflf/intuitive_explanation_for_adams_epsilon_parameter/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cGAN ‚Äî GAN —Å —É—Å–ª–æ–≤–∏–µ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cGAN** —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ **Conditional Generative Adversarial Net** ‚Äî —ç—Ç–æ **GAN** —Å —É—Å–ª–æ–≤–∏–µ–º. –£—Å–ª–æ–≤–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±—ã–º, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ü–∏—Ñ—Ä—ã. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –Ω–∞–º –Ω—É–∂–µ–Ω —É–∂–µ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –æ–±—É—á–∏—Ç—å Conditional GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/conditional_gan_scheme.png\" width=\"800\"></center>\n",
    "<center><em>–°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã cGAN. Label Y –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ —Å–ª—É—á–∞–π–Ω–æ–º—É —à—É–º—É, —Ç–µ–º —Å–∞–º—ã–º –º—ã –≥–æ–≤–æ—Ä–∏–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—É –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–ª—É—á–∞–π–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω—É–∂–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞. –¢–∞–∫–∂–µ –æ–Ω –ø–æ–¥–∞—ë—Ç—Å—è –≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–∞, —á—Ç–æ–±—ã –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –∑–Ω–∞–ª, –∫–∞–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Ä–µ–∞–ª—å–Ω–æ–µ, –∞ –∫–∞–∫–æ–µ ‚Äî –∫–∞–∫ –≤—ã–º—ã—à–ª–µ–Ω–Ω–æ–µ.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –±—É–¥–µ—Ç –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º –æ–±—É—á–µ–Ω–∏—é **GAN**: –º—ã –±—É–¥–µ–º –æ–±—É—á–∞—Ç—å —Å–µ—Ç–∏, —á–µ—Ä–µ–¥—É—è —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, –¥–æ–±–∞–≤–∏–≤ `label`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/cGANS_results_20_and_50_epochs_mnist.png\" width=\"600\"></center>\n",
    "<center><em>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ cGAN –∏ cDCGAN.</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/pdf/1511.06434.pdf\">Unsupervised Representation Learning with Deep Convolutional Generative Adversial Networks</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–∞–∫ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç–∫–∏?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–∫–æ–ª—å–∫—É –ø–æ–¥–∞–≤–∞—Ç—å –≤ —Å–µ—Ç—å —á–∏—Å–ª–∞ –æ—Ç 0 –¥–æ 9 (–≤ —Å–ª—É—á–∞–µ **MNSIT**) –Ω–µ—Ç —Å–º—ã—Å–ª–∞, —Ç–æ –Ω—É–∂–Ω–æ –ø—Ä–∏–¥—É–º–∞—Ç—å, –∫–∞–∫ –ø–æ–¥–∞–≤–∞—Ç—å –∏—Ö –≤ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å. –ù–∞ –ø–æ–º–æ—â—å –ø—Ä–∏—Ö–æ–¥—è—Ç **Embeddings**. –ú—ã –º–æ–∂–µ–º –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∂–¥—É—é –º–µ—Ç–∫—É –≤ –≤–∏–¥–µ –≤–µ–∫—Ç–æ—Ä–∞ —Å –¥–µ—Å—è—Ç—å—é —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏.\n",
    "\n",
    "[–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = next(iter(data_loader))\n",
    "\n",
    "label_emb = nn.Embedding(10, 10)\n",
    "\n",
    "e = label_emb(labels)\n",
    "\n",
    "print(f\"Label: {labels[0]}\")\n",
    "print(f\"Embedding for this label: {e[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ **—ç–º–±–µ–¥–¥–∏–Ω–≥–∏** –º–µ—Ç–æ–∫ –æ–±—ã—á–Ω–æ —Å–∫–ª–µ–∏–≤–∞—é—Ç—Å—è —Å –≤—Ö–æ–¥–∞–º–∏ —Å–µ—Ç–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü–æ—á–µ–º—É –Ω–µ–ª—å–∑—è –ø–æ–¥–∞—Ç—å –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ –º—ã –±—É–¥–µ–º –ø–æ–¥–∞–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä 0.1 –¥–ª—è –µ–¥–∏–Ω–∏—Ü—ã, –∏ 0.5 –¥–ª—è –ø—è—Ç–∏, —Ç–æ –≤—Ö–æ–¥ —É –Ω–∞—Å –±—É–¥–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º, —á—Ç–æ –¥–æ–≤–æ–ª—å–Ω–æ –Ω–µ–ª–æ–≥–∏—á–Ω–æ: —Ç–æ–≥–¥–∞ –ø—Ä–∏ –Ω–µ–±–æ–ª—å—à–æ–º –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≤—Ö–æ–¥–∞ –º—ã –±—É–¥–µ–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é —Ü–∏—Ñ—Ä—É. –ê —Ç–∞–∫–∂–µ —Å–µ—Ç–∏ –±—É–¥–µ—Ç —Å–ª–æ–∂–Ω–µ–µ –≤—ã—É—á–∏—Ç—å –Ω–µ–±–æ–ª—å—à–∏–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –≤ —ç—Ç–æ–º –Ω–µ–±–æ–ª—å—à–æ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ. –í —Å–ª—É—á–∞–µ —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –º—ã –∏–∑–±–µ–≥–∞–µ–º —ç—Ç–∏—Ö –ø—Ä–æ–±–ª–µ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°—É—â–µ—Å—Ç–≤—É–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Å–ø–æ—Å–æ–±–æ–≤ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ GAN, –Ω–∞–ø—Ä–∏–º–µ—Ä –º–æ–∂–Ω–æ –ø–æ–¥–º–µ—à–∏–≤–∞—Ç—å –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ —Ç–æ–ª—å–∫–æ –≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä, –∫–∞–∫ —Å–¥–µ–ª–∞–Ω–æ –≤ [**Semi-Supervised GAN**](https://arxiv.org/pdf/1606.01583.pdf). –í –Ω–µ–º –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –¥–µ–ª–∞–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –Ω–µ –Ω–∞ 2 –∫–ª–∞—Å—Å–∞ **[real, fake]**, –∞ –Ω–∞ n+1 –∫–ª–∞—Å—Å **[real 1, real 2, ‚Ä¶, real n, fake]**, –≥–¥–µ n - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î—Ä—É–≥–∏–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä –∫–æ–¥–∞ —Å –Ω–∏–º–∏ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤ [—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ 1](https://github.com/znxlwm/pytorch-generative-model-collections) –∏–ª–∏ [—Ä–µ–ø–æ–∑–∏–æ—Ç—Ä–∏–∏ 2](https://github.com/eriklindernoren/PyTorch-GAN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∂–µ —Å—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–π –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ - **Style GAN**. –ò–º–µ–Ω–Ω–æ –æ–Ω–∏ –ø–æ–∑–≤–æ–ª–∏–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å  –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤. –ü—Ä–∏–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å  [—Ç—É—Ç](https://nvlabs.github.io/stylegan3/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[arxiv] üéì A Style-Based Generator Architecture for Generative Adversarial Networks (StyleGAN) (Karras et al., 2018)](https://arxiv.org/abs/1812.04948)\n",
    "\n",
    "[[arxiv] üéì Analyzing and Improving the Image Quality of StyleGAN (StyleGAN2) (Karras et al., 2019)](https://arxiv.org/abs/1912.04958)\n",
    "\n",
    "[[arxiv] üéì Alias-Free Generative Adversarial Networks (Alias-Free GAN) (Karras et al., 2021)](https://arxiv.org/abs/2106.12423)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(TODO - –†–ï–®–ò–¢–¨ –ù–£–ñ–ù–û –õ–ò –≠–¢–û?)\n",
    "\n",
    "**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ GAN**\n",
    "* **–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ**\n",
    "* –û—á–µ–Ω—å **–¥–æ–ª–≥–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å**\n",
    "* **Mode-collapsing** (–º–æ–¥–µ–ª—å –≤—ã–¥–∞–µ—Ç –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –∫–ª–∞—Å—Å –∏ —Ç.–¥., –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫–∏–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ–π –ø–æ–¥–∞—é—Ç—Å—è)\n",
    "* **–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞**: –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –Ω–∞—Å—Ç–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –Ω–∞—É—á–∏–ª—Å—è –æ—Ç–ª–∏—á–∞—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã –æ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö, —á—Ç–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç –≤–µ—Å–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ä–∞–≤–Ω—ã–º 0: –≤ –∫–∞–∫—É—é —Å—Ç–æ—Ä–æ–Ω—É –±—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –Ω–µ –∏–∑–º–µ–Ω–∏–ª —Å–≤–æ–∏ –≤–µ—Å–∞, –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –≤—Å–µ —Ä–∞–≤–Ω–æ –∏–¥–µ–∞–ª—å–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ñ–∞–ª—å—à–∏–≤–∫–∏\n",
    "* –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ‚Äî **pure luck**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–∞–∑–æ–≤–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ: [Denoising Diffusion Probabilistic Models (Ho et al., 2020) üéì[arxiv]](https://arxiv.org/abs/2006.11239)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä—è–º–æ–π –¥–∏—Ñ—Ñ—É–∑–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—É—Å—Ç—å –º—ã –∏–º–µ–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–π –æ–±—ä–µ–∫—Ç $\\mathbf{x}_0$ –∏–∑ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –∏–º–µ—é—â–∏–º—Å—è –¥–∞—Ç–∞—Å–µ—Ç–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è $\\mathbf{x}_0 \\sim q(\\mathbf{x})$. –û–ø—Ä–µ–¥–µ–ª–∏–º —Ç–∞–∫ –Ω–∞–∑—ã–≤–∞–µ–º—ã–π –ø—Ä—è–º–æ–π –¥–∏—Ñ—Ñ—É–∑–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, –≤ —Ö–æ–¥–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã –±—É–¥–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–µ–±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ì–∞—É—Å—Å–æ–≤–æ–≥–æ —à—É–º–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ $T$ —Ä–∞–∑, —Å–æ–∑–¥–∞–≤–∞—è –∏–∑ –Ω–∞—à–µ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å $\\mathbf{x}_1, \\dots, \\mathbf{x}_T$ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –≤—Å—ë –±–æ–ª–µ–µ –∑–∞—à—É–º–ª–µ–Ω–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –Ω–∞—à–µ–≥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–±–∞–≤–ª—è–µ–º–æ–≥–æ —à—É–º–∞ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –Ω–æ–º–µ—Ä–∞ —à–∞–≥–∞ –∑–∞—à—É–º–ª–µ–Ω–∏—è –∏ –∏—Ö –Ω–∞–±–æ—Ä $\\{\\beta_t \\in (0, 1)\\}_{t=1}^T$ –∑–∞–¥–∞–Ω –∑–∞—Ä–∞–Ω–µ–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/diffusion_process.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å—Ö–æ–¥–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –±—É–¥–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –≤ –ì–∞—É—Å—Å–æ–≤ —à—É–º:\n",
    "\n",
    "$$\\large q(\\mathbf{x}_t \\vert \\mathbf{x}_{t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}, \\beta_t\\mathbf{I}) \\quad\n",
    "q(\\mathbf{x}_{1:T} \\vert \\mathbf{x}_0) = \\prod^T_{t=1} q(\\mathbf{x}_t \\vert \\mathbf{x}_{t-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∞–∂–Ω—ã–º —Å–≤–æ–π—Å—Ç–≤–æ–º –æ–ø–∏—Å–∞–Ω–Ω–æ–≥–æ –≤—ã—à–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ —è–≤–ª—è–µ—Ç—Å—è —Ç–æ, —á—Ç–æ –æ–Ω –¥–æ–ø—É—Å–∫–∞–µ—Ç –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —à—É–º–∞ –Ω–∞ –ª—é–±–æ–º –∏–∑ —à–∞–≥–æ–≤ –ø—Ä–æ—Ü–µ—Å—Å–∞ –≤ —è–≤–Ω–æ–º –≤–∏–¥–µ. –≠—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º, —á—Ç–æ —Å—É–º–º–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö –≤–µ–ª–∏—á–∏–Ω —Ç–∞–∫–∂–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ–π –≤–µ–ª–∏—á–∏–Ω–æ–π —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º. –í–≤–µ–¥—ë–º –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–∏ $\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i$ –∏ $\\alpha_t = 1 - \\beta_t$. –¢–æ–≥–¥–∞:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large\n",
    "\\begin{aligned}\n",
    "\\mathbf{x}_t\n",
    "&= \\sqrt{\\alpha_t}\\mathbf{x}_{t-1} + \\sqrt{1 - \\alpha_t}\\boldsymbol{\\epsilon}_{t-1} \\\\\n",
    "&= \\sqrt{\\alpha_t \\alpha_{t-1}} \\mathbf{x}_{t-2} + \\sqrt{1 - \\alpha_t \\alpha_{t-1}} \\bar{\\boldsymbol{\\epsilon}}_{t-2} \\\\\n",
    "&= \\dots \\\\\n",
    "&= \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon} \\\\\n",
    "\\end{aligned} $$\n",
    "\n",
    "$$ \\large\n",
    "\\begin{aligned}\n",
    "q(\\mathbf{x}_t \\vert \\mathbf{x}_0) &= \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1 - \\bar{\\alpha}_t)\\mathbf{I})\n",
    "\\end{aligned}; $$\n",
    "\n",
    "$\\large \\text{–≥–¥–µ } \\boldsymbol{\\epsilon}_{t-1}, \\boldsymbol{\\epsilon}_{t-2}, \\dots \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}),$\n",
    "\n",
    "$\\large \\qquad \\bar{\\boldsymbol{\\epsilon}}_{t-2} \\text{ ‚Äì –Ω–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞ (*)}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(*)  –ù–∞–ø–æ–º–Ω–∏–º, —á—Ç–æ –∫–æ–≥–¥–∞ –º—ã —Å–∫–ª–∞–¥—ã–≤–∞–µ–º –¥–≤–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≤–µ–ª–∏—á–∏–Ω—ã —Å —Ä–∞–∑–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π –∏ –Ω—É–ª–µ–≤—ã–º —Å—Ä–µ–¥–Ω–∏–º $\\mathcal{N}(\\mathbf{0}, \\sigma_1^2\\mathbf{I})$ –∏ $\\mathcal{N}(\\mathbf{0}, \\sigma_2^2\\mathbf{I})$,—Ç–æ –ø–æ–ª—É—á–∞–µ–º –Ω–æ–≤—É—é –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é —Å–ª—É—á–∞–π–Ω—É—é –≤–µ–ª–∏—á–∏–Ω—É $\\mathcal{N}(\\mathbf{0}, (\\sigma_1^2 + \\sigma_2^2)\\mathbf{I})$, —á—Ç–æ –≤ –Ω–∞—à–µ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏–∏ –æ–∑–Ω–∞—á–∞–µ—Ç $\\sqrt{(1 - \\alpha_t) + \\alpha_t (1-\\alpha_{t-1})} = \\sqrt{1 - \\alpha_t\\alpha_{t-1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—Ä–∞—Ç–Ω—ã–π –¥–∏—Ñ—Ñ—É–∑–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large p_\\theta(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod^T_{t=1} p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) \\quad\n",
    "p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t), \\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/diffusion_example.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models\">Lilian Weng: What are Diffusion Models?</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ë–∞–∑–æ–≤—ã–π –±–ª–æ–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/resnet_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, mid_features=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_features:\n",
    "            mid_features = out_features\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_features, mid_features, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, mid_features),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_features, out_features, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            return F.gelu(x + self.conv_stack(x))\n",
    "        else:\n",
    "            return self.conv_stack(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/down_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/upblock.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class ResizeBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, emb_dim):\n",
    "        super().__init__()\n",
    "        # defines non-linear map from time embedding features to conv features\n",
    "        self.emb_projection = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(emb_dim, out_features),\n",
    "        )\n",
    "\n",
    "    def add_emb(self, x, t_vector):\n",
    "        # [batch_size, time_embedding_dim] -> [batch_size, out_features]\n",
    "        emb = self.emb_projection(t_vector)\n",
    "        # [batch_size, out_features] - > [batch_size, out_features, H, W]\n",
    "        emb = emb[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Down(ResizeBlock):\n",
    "    def __init__(self, in_features, out_features, emb_dim=256):\n",
    "        super().__init__(in_features, out_features, emb_dim)\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            ResNetBlock(in_features, in_features, residual=True),\n",
    "            ResNetBlock(in_features, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.maxpool_conv(x)\n",
    "        x = self.add_emb(x, t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Up(ResizeBlock):\n",
    "    def __init__(self, in_features, out_features, emb_dim=256):\n",
    "        super().__init__(in_features, out_features, emb_dim)\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.conv = nn.Sequential(\n",
    "            ResNetBlock(in_features, in_features, residual=True),\n",
    "            ResNetBlock(in_features, out_features, in_features // 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip_x, t):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([skip_x, x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.add_emb(x, t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/se_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, channels, size):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.size = size\n",
    "        self.mha = nn.MultiheadAttention(channels, num_heads=4, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [batch_size, C, H, W] -> [batch_size, H*W, C]\n",
    "        x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)\n",
    "        x_ln = self.ln(x)\n",
    "        # K, Q, V in Self attention are equal\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        # skip connection\n",
    "        attention_value = attention_value + x\n",
    "        # simple multilayer perceptron and second skip connection\n",
    "        attention_value = self.mlp(attention_value) + attention_value\n",
    "        # back to [batch_size, C, H, W]\n",
    "        return attention_value.swapaxes(2, 1).view(\n",
    "            -1, self.channels, self.size, self.size\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://dl.skoltech.ru/lectures/lecture-15/ddpm-architecture.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    r\"\"\"\n",
    "    Denoising U-Net model implementation based on arXiv:2006.11239 [cs.LG]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_channels=3, img_size=64, time_enbed_dim=256):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.time_dim = time_enbed_dim\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # Downsample and enlarge feature dim\n",
    "        self.inc = ResNetBlock(num_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.sa1 = SelfAttention(128, img_size // 2)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.sa2 = SelfAttention(256, img_size // 4)\n",
    "        self.down3 = Down(256, 256)\n",
    "        self.sa3 = SelfAttention(256, img_size // 8)\n",
    "\n",
    "        # Keep spatial dim constant\n",
    "        self.conv_bottleneck = nn.Sequential(\n",
    "            ResNetBlock(256, 512),\n",
    "            SelfAttention(512, img_size // 8),\n",
    "            ResNetBlock(512, 256),\n",
    "        )\n",
    "\n",
    "        # Upsample and reduce feature dim\n",
    "        # 512=256+256 from conv_bottleneck and sa3\n",
    "        self.up1 = Up(512, 128)\n",
    "        self.sa4 = SelfAttention(128, img_size // 4)\n",
    "        # 256=128+128 from sa4 and sa2\n",
    "        self.up2 = Up(256, 64)\n",
    "        self.sa5 = SelfAttention(64, img_size // 2)\n",
    "        # 128=64+64 from sa5 and sa1\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.sa6 = SelfAttention(64, img_size)\n",
    "        self.outc = nn.Conv2d(64, num_channels, kernel_size=1)\n",
    "\n",
    "    def pos_encoding(self, t):\n",
    "        r\"\"\"\n",
    "        Returns embedding vector for given integer time index.\n",
    "\n",
    "        We adopt 1d Positional Encoding form arXiv:1706.03762 [cs.CL]\n",
    "        see 3.5 for more details.\n",
    "\n",
    "        PE(x,2i) = sin(x/10000^(2i/D))\n",
    "        PE(x,2i+1) = cos(x/10000^(2i/D))\n",
    "\n",
    "        Where:\n",
    "        x is a point in 1d space\n",
    "        i is an integer in [0, D/2), where D is the size of the feature dimension\n",
    "\n",
    "        Args:\n",
    "            t: Tensor, shape ``[batch_size, 1]``\n",
    "        Returns:\n",
    "            pe: Tensor, shape ``[batch_size, time_embedding_dim]``\n",
    "        \"\"\"\n",
    "        # placeholder for diffusion time encoding vector\n",
    "        pe = torch.zeros(t.shape[0], self.time_dim).to(t.device)\n",
    "\n",
    "        # factor 1/10000^(2i/D)\n",
    "        div_factors = torch.exp(\n",
    "            torch.arange(0, self.time_dim, 2)\n",
    "            * (-torch.log(torch.as_tensor(10000.0)) / self.time_dim)\n",
    "        ).to(t.device)\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(t * div_factors)\n",
    "        pe[:, 1::2] = torch.cos(t * div_factors)\n",
    "\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = t.unsqueeze(-1).type(torch.float).to(x)\n",
    "        t = self.pos_encoding(t)\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1, t)\n",
    "        x2 = self.sa1(x2)\n",
    "        x3 = self.down2(x2, t)\n",
    "        x3 = self.sa2(x3)\n",
    "        x4 = self.down3(x3, t)\n",
    "        x4 = self.sa3(x4)\n",
    "\n",
    "        x4 = self.conv_bottleneck(x4)\n",
    "\n",
    "        x = self.up1(x4, x3, t)\n",
    "        x = self.sa4(x)\n",
    "        x = self.up2(x, x2, t)\n",
    "        x = self.sa5(x)\n",
    "        x = self.up3(x, x1, t)\n",
    "        x = self.sa6(x)\n",
    "        output = self.outc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_noise_steps = 1000\n",
    "time_enbed_dim = 256\n",
    "\n",
    "model = UNet()\n",
    "\n",
    "t = torch.arange(start=1, end=1001, step=1).unsqueeze(1)\n",
    "positional_embeding = model.pos_encoding(t)\n",
    "embeding_img = positional_embeding.numpy()\n",
    "\n",
    "cax = plt.matshow(embeding_img[0:100])\n",
    "plt.gcf().colorbar(cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä—è–º–æ–≥–æ –∏ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –¥–∏—Ñ—Ñ—É–∑–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install lightning\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch.optim import AdamW\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "L.seed_everything(42)\n",
    "\n",
    "class DiffusionGenerativeModel(L.LightningModule):\n",
    "    def __init__(\n",
    "        self, model, path,\n",
    "        num_noise_steps=1000,\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.02,\n",
    "        img_size=64,\n",
    "        lr=0.001,\n",
    "        save_images=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.path = path\n",
    "        self.num_noise_steps = num_noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size\n",
    "        self.lr = lr\n",
    "        self.save_images = save_images\n",
    "\n",
    "        # diffusion process linear noise schedule\n",
    "        self.beta = self._get_noise_schedule()\n",
    "        self.alpha = 1.0 - self.beta\n",
    "        # \\hat{\\alpha}_{i-1} = \\prod_{j=0}^{i-1} \\alpha_j\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "        # init optimizer and loss for training\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def _get_noise_schedule(self):\n",
    "        return torch.linspace(\n",
    "            self.beta_start, self.beta_end, self.num_noise_steps\n",
    "        )\n",
    "\n",
    "    def _noise_images_batch(self, x, t):\n",
    "        # \\mu_i = \\sqrt{\\hat{\\alpha}_i}\n",
    "        mu = torch.sqrt(self.alpha_hat[t])[:, None, None, None].to(self.device)\n",
    "        # \\sigma_i = \\sqrt{1 - \\hat{\\alpha}_i}\n",
    "        sigma = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None].to(self.device)\n",
    "\n",
    "        standard_normal_noise = torch.randn_like(x).to(self.device)\n",
    "        noised_image_batch = mu * x + sigma * standard_normal_noise\n",
    "        return noised_image_batch, standard_normal_noise\n",
    "\n",
    "    def _get_timestams_batch(self):\n",
    "        return torch.randint(\n",
    "            low=1, high=self.num_noise_steps, size=(self.batch_size,)\n",
    "        )\n",
    "\n",
    "    def generate_images_batch(self):\n",
    "        # start from pure noise batch\n",
    "        x = torch.randn((self.batch_size, 3, self.img_size, self.img_size)).to(self.device)\n",
    "        # and apply self.num_noise_steps denoising steps with model\n",
    "        for t_i in tqdm(reversed(range(1, self.num_noise_steps)), position=0):\n",
    "            # Build tensor with timestamp index. Same for each element in batch\n",
    "            t = torch.full((self.batch_size,), t_i).long().to(self.device)\n",
    "\n",
    "            # predict noise on current timestamp\n",
    "            with torch.inference_mode():\n",
    "                pred_noise = self.model(x, t).detach()\n",
    "\n",
    "            # restore noise parametrs on current timestamp\n",
    "            alpha = self.alpha[t.to('cpu')][:, None, None, None].to(self.device)\n",
    "            alpha_hat = self.alpha_hat[t.to('cpu')][:, None, None, None].to(self.device)\n",
    "            beta = self.beta[t.to('cpu')][:, None, None, None].to(self.device)\n",
    "\n",
    "            # partialy denoise batch of images\n",
    "            x = x - (1.0 - alpha) / (1 - alpha_hat).sqrt() * pred_noise\n",
    "            x = (1 / alpha.sqrt()) * x\n",
    "\n",
    "            # add appropriate amount of noise for next step if any\n",
    "            if t_i > 0:\n",
    "                z = torch.randn_like(x).to(self.device)\n",
    "                x = x + beta.sqrt() * z\n",
    "        # clip x to valid 0..255 image range\n",
    "        x = x.clamp(0, 1)\n",
    "        x = (x * 255).type(torch.uint8)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # unpack data\n",
    "        images, labels = batch\n",
    "        self.batch_size = images.shape[0]\n",
    "        t = self._get_timestams_batch()\n",
    "\n",
    "        # prep batch of noised images\n",
    "        noised_images, target_noise = self._noise_images_batch(images, t)\n",
    "\n",
    "        # estimate noise with U-Net\n",
    "        predicted_noise = self.model(noised_images, t)\n",
    "\n",
    "        # optimize model to fit target noise\n",
    "        loss = self.criterion(predicted_noise, target_noise)\n",
    "        self.log(\"loss\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.save_images:\n",
    "            generated_images = self.generate_images_batch()\n",
    "            image_grid = make_grid(generated_images)\n",
    "            # convert to numpy\n",
    "            ndarr = image_grid.permute(1, 2, 0).to(\"cpu\").numpy()\n",
    "            # and save\n",
    "            im = Image.fromarray(ndarr)\n",
    "            im.save(f\"{self.path}model_{self.current_epoch}.jpg\")\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        images, labels = batch\n",
    "        self.batch_size = images.shape[0]\n",
    "        return self.generate_images_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ –¥–∏—Ñ—Ñ—É–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q astronn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–ø–µ—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –≤—ã—à–µ –¥–∏—Ñ—Ñ—É–∑–Ω–æ–π –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ Galaxy10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/galaxy10sdss_example.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ü—Ä–∏–º–µ—Ä—ã –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ Galaxy10</a></em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://github.com/henrysky/Galaxy10\">Galaxy10 DECals Dataset</a></em></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroNN.datasets import load_galaxy10\n",
    "\n",
    "images, labels = load_galaxy10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform):\n",
    "        super().__init__()\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, indx):\n",
    "        image = self.images[indx]\n",
    "        label = self.labels[indx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(64, antialias=True),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomVerticalFlip(0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = GalaxyDataset(images, labels, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ —Å–µ—Ç–∏ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º. –ü—Ä–æ–ø—É—Å—Ç–∏–º —ç—Ç–æ—Ç —ç—Ç–∞–ø, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–Ω–∏–º–∞–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "path = \"/diffusion/\"\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=8, shuffle=True, drop_last=True, num_workers=2\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=path,\n",
    "    save_last=True,\n",
    "    every_n_epochs=1,\n",
    "    save_top_k=1,\n",
    "    monitor=\"loss\",\n",
    "    filename=\"best\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "model = UNet()\n",
    "\n",
    "ddpm = DiffusionGenerativeModel(model, path)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=200,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    log_every_n_steps=100,\n",
    "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=path),\n",
    ")\n",
    "\n",
    "#trainer.fit(model=ddpm, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GalaxyDataset(images[:16], labels[:16], transform)\n",
    "\n",
    "gen_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=16, shuffle=False, num_workers=2\n",
    ") # just for image num\n",
    "\n",
    "generated_images = trainer.predict(ddpm, gen_loader)[0]\n",
    "\n",
    "image_grid = make_grid(generated_images)\n",
    "# convert to numpy\n",
    "ndarr = image_grid.permute(1, 2, 0).to(\"cpu\").numpy()\n",
    "# and show\n",
    "Image.fromarray(ndarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–¥–∏–º, —á—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π —à—É–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –≤–µ—Å–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -q https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/weights/unconditioned_baseline.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "model.load_state_dict(\n",
    "    torch.load(\"/content/unconditioned_baseline.pt\", map_location=\"cpu\")\n",
    ")\n",
    "ddpm = DiffusionGenerativeModel(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = trainer.predict(ddpm, gen_loader)[0]\n",
    "image_grid = make_grid(generated_images)\n",
    "# convert to numpy\n",
    "ndarr = image_grid.permute(1, 2, 0).to(\"cpu\").numpy()\n",
    "# and show\n",
    "Image.fromarray(ndarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞</font>\n",
    "\n",
    "<font size=\"5\">GAN</font>\n",
    "\n",
    "[[book] üìö ¬´–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ. –¢–≤–æ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π¬ª](https://habr.com/ru/company/piter/blog/504956/)\n",
    "\n",
    "[[arxiv] üéì Generative Adversarial Networks (Goodfellow et al., 2014)](https://arxiv.org/abs/1406.2661)\n",
    "\n",
    "[[video] üì∫ –†–∞–∑–±–æ—Ä –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–∏ GAN](https://www.youtube.com/watch?v=eyxmSmjmNS0)\n",
    "\n",
    "[[video] üì∫ –õ–µ–∫—Ü–∏—è –ò–∞–Ω–∞ –ì—É–¥—Ñ–µ–ª–ª–æ—É](https://www.youtube.com/watch?v=HGYYEUSm-0Q)\n",
    "\n",
    "[Generative adversarial networks](https://deepgenerativemodels.github.io/notes/gan/)\n",
    "\n",
    "[–°–∞–º—ã–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏](https://paperswithcode.com/methods/category/generative-models)\n",
    "\n",
    "[exactly how the NVIDIA GauGAN neural network works](https://sudonull.com/post/29972-Pictures-from-rough-sketches-how-exactly-the-NVIDIA-GauGAN-neural-network-works-ITSumma-Blog)\n",
    "\n",
    "<font size=\"5\">DCGAN</font>\n",
    "\n",
    "[[arxiv] üéì Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (Radford et al., 2015)](https://arxiv.org/abs/1511.06434).\n",
    "\n",
    "[DCGAN TUTORIAL](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)\n",
    "\n",
    "<font size=\"5\">Wasserstein GAN</font>\n",
    "\n",
    "[[arxiv] üéì Wasserstein GAN (Arjovsky et. al., 2017)](https://arxiv.org/abs/1701.07875)\n",
    "\n",
    "[–ë–ª–æ–≥ –ø–æ—Å—Ç –æ Wasserstein GAN](https://vincentherrmann.github.io/blog/wasserstein/)\n",
    "\n",
    "[[arxiv] üéì Improved Training of Wasserstein GANs (Gulrajani et al., 2017)](https://arxiv.org/abs/1704.00028)\n",
    "\n",
    "[[arxiv] üéì Spectral Normalization for Generative Adversarial Networks (Miyato et al., 2018)](https://arxiv.org/abs/1802.05957).\n",
    "\n",
    "<font size=\"5\">ProGAN -> StyleGAN -> StyleGAN2 -> Alias-Free GAN</font>\n",
    "\n",
    "[[arxiv] üéì Progressive Growing of GANs for Improved Quality, Stability, and Variation (ProGAN) (Karras et al., 2017)](https://arxiv.org/abs/1710.10196)\n",
    "\n",
    "[[arxiv] üéì A Style-Based Generator Architecture for Generative Adversarial Networks (StyleGAN) (Karras et al., 2018)](https://arxiv.org/abs/1812.04948)\n",
    "\n",
    "[[arxiv] üéì Analyzing and Improving the Image Quality of StyleGAN (StyleGAN2) (Karras et al., 2019)](https://arxiv.org/abs/1912.04958)\n",
    "\n",
    "[[arxiv] üéì Alias-Free Generative Adversarial Networks (Alias-Free GAN) (Karras et al., 2021)](https://arxiv.org/abs/2106.12423)\n",
    "\n",
    "<font size=\"5\">–¢–æ–Ω–∫–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è GAN</font>\n",
    "\n",
    "[[blog] ‚úèÔ∏è –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä —Ç–æ–Ω–∫–æ—Å—Ç–µ–π –∏ —Å–æ–≤–µ—Ç–æ–≤](https://beckham.nz/2021/06/28/training-gans.html)\n",
    "\n",
    "[[arxiv] üéì Top-k Training of GANs: Improving GAN Performance by Throwing Away Bad Samples (Sinha et al., 2020)](https://arxiv.org/abs/2002.06224)\n",
    "\n",
    "<font size=\"5\">GAN Zoo:</font>\n",
    "\n",
    "<font size=\"5\">BigGAN</font>\n",
    "\n",
    "[[arxiv] üéì Large Scale GAN Training for High Fidelity Natural Image Synthesis (Brock et al., 2018)](https://arxiv.org/abs/1809.11096)\n",
    "\n",
    "<font size=\"5\">StackGAN</font>\n",
    "\n",
    "[StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks (Zhang et al., 2016)](https://arxiv.org/abs/1612.03242)\n",
    "\n",
    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: [—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∫ —Å—Ç–∞—Ç—å–µ —Å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤](https://github.com/hanzhanggit/StackGAN).\n",
    "\n",
    "[[arxiv] üéì StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks (Zhang et al., 2017)](https://arxiv.org/abs/1710.10916)\n",
    "\n",
    "[[arxiv] üéì Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (Ledig et al., 2016)](https://arxiv.org/abs/1609.04802)\n",
    "\n",
    "[Deep Learning Generative Models for Image Synthesis and Image Translation](https://www.rulit.me/data/programs/resources/pdf/Generative-Adversarial-Networks-with-Python_RuLit_Me_610886.pdf)\n",
    "\n",
    "[[video] üì∫ StackGAN++ Realistic Image Synthesis with Stacked Generative Adversarial Networks | AISC](https://www.youtube.com/watch?v=PXWIaLE7_NU)\n",
    "\n",
    "[[video] üì∫ Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks](https://www.youtube.com/watch?v=crI5K4RCZws)\n",
    "\n",
    "<font size=\"5\">ControlGAN</font>\n",
    "\n",
    "[[arxiv] üéì Controllable Generative Adversarial Network](https://arxiv.org/pdf/1708.00598.pdf)\n",
    "\n",
    "[[arxiv] üéì Controllable Text-to-Image Generation](https://arxiv.org/pdf/1909.07083.pdf)\n",
    "\n",
    "[[arxiv] üéì Image Generation and Recognition (Emotions)](https://arxiv.org/pdf/1910.05774.pdf)\n",
    "\n",
    "[Natural Language & Text-to-Image 2019](https://meta-guide.com/data/data-processing/text-to-image-systems/natural-language-text-to-image-2019)\n",
    "\n",
    "<font size=\"5\">AC-GAN</font>\n",
    "\n",
    "[How to Develop an Auxiliary Classifier GAN (AC-GAN) From Scratch with Keras](https://machinelearningmastery.com/how-to-develop-an-auxiliary-classifier-gan-ac-gan-from-scratch-with-keras/)\n",
    "\n",
    "Conditional Image Synthesis with Auxiliary Classifier GANs: [—Å—Ç–∞—Ç—å—è](https://arxiv.org/pdf/1610.09585.pdf), [—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π](https://github.com/clvrai/ACGAN-PyTorch)\n",
    "\n",
    "[[arxiv] üéì An Auxiliary Classifier Generative Adversarial Framework for Relation Extraction (Zhao, 2019)](https://arxiv.org/pdf/1909.05370.pdf)\n",
    "\n",
    "[A Multi-Class Hinge Loss for Conditional GANs](https://openaccess.thecvf.com/content/WACV2021/papers/Kavalerov_A_Multi-Class_Hinge_Loss_for_Conditional_GANs_WACV_2021_paper.pdf)\n",
    "\n",
    "<font size=\"5\">Domain Transfer Network</font>\n",
    "\n",
    "[[arxiv] üéì Unsupervised Cross-Domain Image Generation (Taigma et al., 2016)](https://arxiv.org/abs/1611.02200)\n",
    "\n",
    "<font size=\"5\">Pix2Pix</font>\n",
    "\n",
    "[[arxiv] üéì Image-to-Image Translation with Conditional Adversarial Networks (Isola et al., 2016)](https://arxiv.org/abs/1611.07004)\n",
    "\n",
    "<font size=\"5\">–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è</font>\n",
    "\n",
    "[[arxiv] üéì Learning to Generate Chairs, Tables and Cars\n",
    "with Convolutional Networks (Dosovitskiy et al., 2017)](https://arxiv.org/abs/1411.5928)\n",
    "\n",
    "<font size=\"5\">Text to image</font>\n",
    "\n",
    "[[arxiv] üéì Text-to-Image Generation with Attention Based Recurrent Neural Networks (Zia et al., 2020)](https://arxiv.org/abs/2001.06658)\n",
    "\n",
    "<font size=\"5\">Image-to-Image</font>\n",
    "\n",
    "[[arxiv] üéì GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (Chong et al., 2021)](https://arxiv.org/abs/2106.06561)\n",
    "\n",
    "[[arxiv] üéì Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (Zhu et al., 2017)](https://arxiv.org/abs/1703.10593)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">–°—Å—ã–ª–∫–∏</font>\n",
    "\n",
    "[[git] üêæ MNIST CelebA cGAN cDCGAN](https://github.com/znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN)\n",
    "\n",
    "[[git] üêæ Text-to-Photo realistic Image Synthesis with Stacked Generative Adversarial Networks](https://github.com/zeusm9/Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks)\n",
    "\n",
    "[[git] üêæ ControlGAN](https://github.com/mrlibw/ControlGAN)\n",
    "\n",
    "[[git] üêæ ControlGAN-Tensorflow](https://github.com/taki0112/ControlGAN-Tensorflow)\n",
    "\n",
    "[[git] üêæ Keras-ACGan](https://github.com/lukedeo/keras-acgan)\n",
    "\n",
    "[–ú–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤](https://thisxdoesnotexist.com)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
