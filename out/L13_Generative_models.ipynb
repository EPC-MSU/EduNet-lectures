{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=\"6\">–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ\" –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞—á–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —ç—Ç–æ–º –∫—É—Ä—Å–µ –º—ã –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ä–∞–±–æ—Ç–∞–ª–∏ —Å **—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–º–∏** –¥–∞–Ω–Ω—ã–º–∏. –ú—ã –Ω–∞—É—á–∏–ª–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ —Ç.–¥.\n",
    "\n",
    "–í —ç—Ç–æ–π –ª–µ–∫—Ü–∏–∏ –º—ã —Ä–∞–∑–±–µ—Ä–µ–º—Å—è, –∫–∞–∫ –Ω–∞—É—á–∏—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Å–æ–∑–¥–∞–≤–∞—Ç—å —á—Ç–æ-—Ç–æ –Ω–æ–≤–æ–µ.\n",
    "\n",
    "\n",
    "–ö–∞–∫ –ø–æ–¥–æ–π—Ç–∏ –∫ —Ç–∞–∫–æ–π –∑–∞–¥–∞—á–µ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**\n",
    "\n",
    "**–î–∞–Ω–æ**: –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "\n",
    "**–í—ã—Ö–æ–¥**: –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—Ç—å —Å–ª–µ–¥—É—é—â–∏–º —É—Å–ª–æ–≤–∏—è–º:\n",
    "* –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å **–ø–æ—Ö–æ–∂–∏** –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–µ.\n",
    "* –ù–æ **–Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å** –∏—Ö –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ (–∏–ª–∏ –ø–æ–≤—Ç–æ—Ä—è—Ç—å, –ø—Ä–∏ —Å–ª—É—á–∞–π–Ω–æ–º —Å—Ç–µ—á–µ–Ω–∏–∏ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤).\n",
    "* –ß—Ç–æ–±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±—ã–ª —Ä–∞–∑–ª–∏—á–Ω—ã–º –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –∑–∞–ø—É—Å–∫–∞—Ö, –Ω–∞–º –Ω—É–∂–µ–Ω **—ç–ª–µ–º–µ–Ω—Ç —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –ø—Ä–∏–º–µ—Ä: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —É –Ω–∞—Å –ø–æ–¥ —Ä—É–∫–æ–π –µ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–º –ª–µ–≥–∫–æ –ø–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ —á–∏—Å–ª–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ $[0,1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "uniform_noise = np.random.uniform(size=1000)\n",
    "plt.hist(uniform_noise)\n",
    "plt.title(\"uniform distribution U\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.xlabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—É—Å—Ç—å $U_i$ ‚Äî —Ç–æ—á–∫–∞, –∫–æ—Ç–æ—Ä—É—é –¥–∞—ë—Ç –Ω–∞–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª. –ï—Å–ª–∏ –º—ã –≤–æ–∑—å–º—ë–º –ø–∞—Ä—É —Ç–∞–∫–∏—Ö —Ç–∞–∫–∏—Ö —Ç–æ—á–µ–∫ $U_1$, $U_2$ –∏ –ø—Ä–æ–∏–∑–≤–µ–¥—ë–º —Å –Ω–∏–º–∏ —Ç–∞–∫ –Ω–∞–∑—ã–≤–∞–µ–º–æ–µ [–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ú—é–ª–ª–µ—Ä–∞ üìö[wiki]](https://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform), —Ç–æ –ø–æ–ª—É—á–∏–º –ø–∞—Ä—É –Ω–æ–≤—ã—Ö —Ç–æ—á–µ–∫ $X$ –∏ $Y$ –Ω–∞ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø—Ä—è–º–æ–π:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{l}\n",
    "X=\\sqrt{-2 \\log U_{1}} \\cos \\left(2 \\pi U_{2}\\right) \\\\\n",
    "Y=\\sqrt{-2 \\log U_{1}} \\sin \\left(2 \\pi U_{2}\\right)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–≤—Ç–æ—Ä–∏–≤ —Ç–∞–∫—É—é –ø—Ä–æ—Ü–µ–¥—É—Ä—É –¥–ª—è –±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞ —Ç–æ—á–µ–∫ $U_i$, –º–æ–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ $X$ –∏ $Y$ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø–æ—Ö–æ–∂–∏–º –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U1 = np.random.uniform(size=1000)\n",
    "U2 = np.random.uniform(size=1000)\n",
    "R = np.sqrt(-2 * np.log(U1))\n",
    "Theta = 2 * np.pi * U2\n",
    "X = R * np.cos(Theta)\n",
    "Y = R * np.sin(Theta)\n",
    "\n",
    "plt.hist(X)\n",
    "plt.title(\"Box‚ÄìMuller transform of U\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.xlabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_noise = np.random.normal(size=1000)\n",
    "plt.hist(gaussian_noise)\n",
    "plt.title(\"Gaussian distribution N\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.xlabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –º—ã –º–æ–∂–µ–º –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ú—é–ª–ª–µ—Ä–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–ª–æ –∏—Å—Ö–æ–¥–Ω–æ–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{l}\n",
    "X=\\sqrt{-2 \\log U_{1}} \\cos \\left(2 \\pi U_{2}\\right) \\\\\n",
    "Y=\\sqrt{-2 \\log U_{1}} \\sin \\left(2 \\pi U_{2}\\right)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–µ—à–∏–º —É—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö $U_i$:\n",
    "$$ \\large\n",
    "\\begin{array}{l}\n",
    "U_{1}=e^{-\\left(X^{2}+Y^{2}\\right) / 2} \\\\\n",
    "U_{2}=\\frac{1}{2 \\pi} \\arctan \\left(\\frac{X}{Y}\\right)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–∞—Ç—Ä–∏—Ü–∞ –Ø–∫–æ–±–∏ –¥–ª—è —Ç–∞–∫–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large\n",
    "J(X,Y) = \\begin{bmatrix}\n",
    "\\frac{\\partial U_1}{\\partial X} & \\frac{\\partial U_1}{\\partial Y}\\\\\n",
    "\\frac{\\partial U_2}{\\partial X} & \\frac{\\partial U_2}{\\partial Y}\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "-X e^{\\frac{-(X^2+Y^2)}{2}}  & -Y e^{\\frac{-(X^2+Y^2)}{2}}\\\\\n",
    "\\frac{1}{2\\pi} \\frac{Y}{X^2 + Y^2} & \\frac{1}{2\\pi} \\frac{-X}{X^2 + Y^2}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ç—Å—é–¥–∞ –∏–º–µ–µ–º:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large\n",
    "\\begin{aligned}\n",
    "f_{X,Y}(x,y)&=f_{U_1,U_2}(e^{-\\left(X^{2}+Y^{2}\\right) / 2}, \\frac{1}{2 \\pi} \\arctan \\left(\\frac{X}{Y}\\right)) |\\det(J)|\\\\\n",
    "&= |\\det(J)|\\\\\n",
    "&= \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{X^2}{2}} \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{Y^2}{2}}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–æ –µ—Å—Ç—å –º—ã –ø–æ–ª—É—á–∏–ª–∏ –ø–∞—Ä—É –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª $X$ –∏ $Y$, –∫–∞–∂–¥–æ–µ –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –ª–µ–∂–∏—Ç –≤ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏:\n",
    "$$\n",
    "X\\perp Y, \\quad X \\sim \\mathcal{N}(0,1),\\quad Y\\sim \\mathcal{N}(0,1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ –Ω–∞–º —Ö–æ—á–µ—Ç—Å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –Ω–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏, –∞ –≤ –∫–∞–∫–æ–º-—Ç–æ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–º? –í –æ–±—â–µ–º —Å–ª—É—á–∞–µ –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—É—é —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –∏–∑ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ \"–ø—Ä–æ—Å—Ç–æ–≥–æ\" —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤ \"—Ü–µ–ª–µ–≤–æ–µ\". –û—Å—É—â–µ—Å—Ç–≤–ª—è—é—â–∏–µ —Ç–∞–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥–µ–º –Ω–∞–∑—ã–≤–∞—Ç—å **–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ —Ü–µ–ª–µ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ $\\mathcal{F}[\\vec {x}]$ –∏–∑–≤–µ—Å—Ç–Ω–æ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏, —Ç–æ –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ —Ç–∞–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –º–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ [Markov Chain Monte Carlo üìö[wiki]](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/generative_models.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –≥–ª—É–±–æ–∫–æ–º –æ–±—É—á–µ–Ω–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/deep_generative_models.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –í–≤–µ–¥–µ–Ω–∏–µ  –≤ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–≠–≤–æ–ª—é—Ü–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ª–∏—Ü:**\n",
    "\n",
    "[–ú–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤](https://thisxdoesnotexist.com)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/faces_generation_quality_progress.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–±–µ—Ä–µ–º—Å—è —Å **—ç–ª–µ–º–µ–Ω—Ç–æ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏**. –í –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö –º—ã –ø—Ä–∏–≤—ã–∫–ª–∏ –∫ **–≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏** —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: –≤ —Ä–µ–∂–∏–º–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º—ã –º–æ–∂–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–¥–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –æ–±—ä–µ–∫—Ç –∏ –ø–æ–ª—É—á–∏—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.  –í–æ–∑–Ω–∏–∫–∞–µ—Ç –¥–≤–∞ –≤–æ–ø—Ä–æ—Å–∞:\n",
    "- —á—Ç–æ –ø–æ–¥–∞–≤–∞—Ç—å –Ω–∞ **–≤—Ö–æ–¥** —Å–µ—Ç–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏?\n",
    "- –∫–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å **—Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å**?\n",
    "\n",
    "–û—Ç–≤–µ—Ç –Ω–∞ –æ–±–∞ –≤–æ–ø—Ä–æ—Å–∞: –ø–æ–¥–∞–≤–∞—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ **–≤—Ö–æ–¥–∞** –≤–µ–∫—Ç–æ—Ä **—Å–ª—É—á–∞–π–Ω–æ–≥–æ —à—É–º–∞**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/generator_model_pipeline.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ **–≤–µ–∫—Ç–æ—Ä**? –ü–æ—á–µ–º—É –Ω–µ –æ–¥–Ω–æ **—Å–ª—É—á–∞–π–Ω–æ–µ —á–∏—Å–ª–æ**?\n",
    "\n",
    "**–û—Ç–≤–µ—Ç**: –≤—Ö–æ–¥–Ω–æ–π –≤–µ–∫—Ç–æ—Ä –º–æ–∂–Ω–æ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∫–∞–∫ **–ø—Ä–∏–∑–Ω–∞–∫–∏** –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞. –ö–∞–∂–¥—ã–π —Ç–∞–∫–æ–π –ø—Ä–∏–∑–Ω–∞–∫ ‚Äî **–Ω–µ–∑–∞–≤–∏—Å–∏–º–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞**. –ï—Å–ª–∏ –º—ã –±—É–¥–µ–º –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–ª—É—á–∞–π–Ω–æ–µ —á–∏—Å–ª–æ, —Ç–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±—É–¥–µ—Ç –æ–¥–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–π. –ß–µ–º –±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Å—Ç–µ–ø–µ–Ω–µ–π —Å–≤–æ–±–æ–¥—ã) —É –≤—Ö–æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞, —Ç–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–µ–µ –±—É–¥–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–æ –µ—Å—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º **–±–æ–ª—å—à–µ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** –¥–∞—ë—Ç –Ω–∞–º **–±–æ–ª—å—à–µ –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏**  –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –≠—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è **input latent space** ‚Äî –≤—Ö–æ–¥–Ω–æ–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ.\n",
    "\n",
    "**Note:** *–∏–∑-–∑–∞ –Ω–µ—É—Å—Ç–æ—è–≤—à–µ–π—Å—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏ —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –≤—Ö–æ–¥–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –ª–∞—Ç–µ–Ω—Ç–Ω—ã–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ–º —Ç–∞–∫ –∂–µ, –∫–∞–∫ –∏ —Å–∫—Ä—ã—Ç–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞—Ö. –ü–æ—ç—Ç–æ–º—É –≤ —ç—Ç–æ–π –ª–µ–∫—Ü–∏–∏ –±—É–¥–µ–º –Ω–∞–∑—ã–≤–∞—Ç—å –µ–≥–æ **–≤—Ö–æ–¥–Ω—ã–º** –ª–∞—Ç–µ–Ω—Ç–Ω—ã–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ–º. –¢–∞–∫–∂–µ –≤ —Å—Ç–∞—Ç—å—è—Ö –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤–∞—Ä–∏–∞–Ω—Ç: predefined latent space.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∂–¥—É—é –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—É –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –º–æ–∂–Ω–æ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é —à–∫–∞–ª—É, –≤–¥–æ–ª—å –∫–æ—Ç–æ—Ä–æ–π –∏–∑–º–µ–Ω—è—é—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä, –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å —á–µ—Ç—ã—Ä–µ –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–∞ –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã –ø–ª–∞–≤–Ω–æ –∏–∑–º–µ–Ω—è—é—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –æ—Ç –æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –∫ –¥—Ä—É–≥–æ–º—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/input_latent_space_lin_interpol.png\" width=\"600\">\n",
    "\n",
    "<center><em>–õ–∏–Ω–µ–π–Ω—ã–µ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É —á–µ—Ç—ã—Ä—å–º—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –≤ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/abs/1803.09093\">Comparing Generative Adversarial Network Techniques for Image Creation and Modification(M. Pieters, M. Wiering, 2018)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω–æ–≥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –≤—ã–±–æ—Ä–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—Ö–æ–¥–Ω–æ–≥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –≤–∞–∂–Ω–æ —Å–æ–±–ª—é—Å—Ç–∏  –±–∞–ª–∞–Ω—Å.\n",
    "- –ø—Ä–∏ **–Ω–∏–∑–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç –ø—Ä–æ–±–ª–µ–º–∞ **–Ω–∏–∑–∫–æ–π –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏**.\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ª–∏—Ü —Å –≤—Ö–æ–¥–Ω—ã–º –≤–µ–∫—Ç–æ—Ä–æ–º –¥–ª–∏–Ω—ã 1. –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —Ä–∞–±–æ—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –±—É–¥–µ—Ç –≤—Å–µ–≥–æ –æ–¥–Ω–∞ —à–∫–∞–ª–∞, –≤–¥–æ–ª—å –∫–æ—Ç–æ—Ä–æ–π –±—É–¥—É—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤—ã—É—á–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—É—é –∏ \"–æ—á–µ–≤–∏–¥–Ω—É—é\" —à–∫–∞–ª—É: –æ—Ç –º–æ–ª–æ–¥–æ–π –∂–µ–Ω—â–∏–Ω—ã –±–ª–æ–Ω–¥–∏–Ω–∫–∏ –∫ –ø–æ–∂–∏–ª–æ–º—É –º—É–∂—á–∏–Ω–µ –±—Ä—é–Ω–µ—Ç—É. –£ —Ç–∞–∫–æ–π —Å–µ—Ç–∏ –±—É–¥–µ—Ç –Ω–∏–∑–∫–∞—è –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å ‚Äî –æ–Ω–∞ –Ω–µ —Å–º–æ–∂–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä—ã–∂–µ–≥–æ —Ä–µ–±–µ–Ω–∫–∞ –≤ –æ—á–∫–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –ø—Ä–∏ **–±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º **—Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–º**.\n",
    "\n",
    "–ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –≤ —ç—Ç–æ–º –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –±—É–¥–µ—Ç –Ω–∞—Å—Ç–æ–ª—å–∫–æ –º–∞–ª–æ, —á—Ç–æ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –±—É–¥–µ—Ç —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑ –ø—É—Å—Ç–æ—Ç. –¢–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∫—Ä–∞–π–Ω–µ –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –≤ —Ç–æ—á–∫–∞—Ö –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞, –¥–∞–ª–µ–∫–∏—Ö –æ—Ç —Ç–æ—á–µ–∫ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ—É—á—à–∏–π —Å–ø–æ—Å–æ–± –≤—ã–±—Ä–∞—Ç—å –¥–ª–∏–Ω—É –≤–µ–∫—Ç–æ—Ä–∞ ‚Äî —ç—Ç–æ –Ω–∞–π—Ç–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏—é —Å –ø–æ—Ö–æ–∂–µ–π –∑–∞–¥–∞—á–µ–π –∏ –≤–∑—è—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –Ω–µ–µ.\n",
    "\n",
    "–ï—Å–ª–∏ —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç, —Ç–æ –ø—Ä–∏–¥–µ—Ç—Å—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å. –õ—É—á—à–µ –Ω–∞—á–∏–Ω–∞—Ç—å —Å –Ω–∏–∑–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞, —á—Ç–æ–±—ã –Ω–∞–ª–∞–¥–∏—Ç—å —Ä–∞–±–æ—Ç—É –≤—Å–µ–π —Å–µ—Ç–∏, –ø—É—Å—Ç—å –∏ —Å –Ω–∏–∑–∫–∏–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ–º, –∞ –∑–∞—Ç–µ–º –ø—Ä–æ–≤–æ–¥–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –ø–æ –ø–æ–∏—Å–∫—É –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –≤ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏: —Å–ø—Ä–æ—Å–∏—Ç–µ —Å–µ–±—è, —Å–∫–æ–ª—å–∫–∏–º–∏ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏ –º–æ–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä–µ–∫—Ç–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –º—ã –∑–Ω–∞–µ–º –∏–∑ –ª–µ–∫—Ü–∏–∏ –ø—Ä–æ –æ–±—É—á–µ–Ω–∏–µ —Å–µ—Ç–∏, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤–Ω–æ—Å—è—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Ä–∞–±–æ—Ç—É –º–æ–¥–µ–ª–∏. –ü–æ—ç—Ç–æ–º—É –ø—Ä–∏–Ω—è—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **–º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ** –¥–ª—è input latent space. –û–Ω–æ –ª—É—á—à–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç —Å –≤–µ—Å–∞–º–∏ –º–æ–¥–µ–ª–∏ –∏ —É–ª—É—á—à–∞–µ—Ç —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/binomial_distribution.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://matplotlib.org/3.1.0/gallery/lines_bars_and_markers/scatter_hist.html\">–î–≤—É–º–µ—Ä–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ù–∞–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –≤ —Ä–µ—à–µ–Ω–∏–∏ –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "(–∫–∞–∫ –¥–µ–ª–∞—Ç—å –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –ù–ï –Ω—É–∂–Ω–æ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–æ—á–µ–∫ –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ (c–∞–º—ã–º —Ç—Ä–∏–≤–∏–∞–ª—å–Ω—ã–º —Ä–µ—à–µ–Ω–∏–µ–º –∫–∞–∂–µ—Ç—Å—è –ø–æ–¥–∞—á–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —à—É–º–∞ –Ω–∞ –≤—Ö–æ–¥ —Å–µ—Ç–∏) –∏ –±—É–¥–µ–º –æ–∂–∏–¥–∞—Ç—å –Ω–∞ –≤—ã—Ö–æ–¥–µ —Ç–æ—á–∫–∏ –ø–∞—Ä–∞–±–æ–ª—ã. –ü—Ä–æ–≤–µ—Ä–∏–º, –∫–∞–∫ —ç—Ç–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def gen_pair(num=100):\n",
    "    x = np.random.uniform(low=-1, high=1, size=(num,))\n",
    "    y = x * x\n",
    "    return np.hstack(\n",
    "        (x.reshape(-1, 1), y.reshape(-1, 1))\n",
    "    )  # Create num of correct dots(x,y) on parabola\n",
    "\n",
    "\n",
    "pairs = gen_pair(100)\n",
    "plt.scatter(pairs[:, 0], pairs[:, 1])\n",
    "plt.title(\"Random dots on parabola,\\nwhich will use like a dataset.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ–∑—å–º—ë–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω–æ–≥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ $ls = 1$ –∏ –æ–±—ä–µ–¥–∏–Ω–∏–º —à—É–º —Å —Ç–æ—á–∫–∞–º–∏ –≤ –¥–∞—Ç–∞—Å–µ—Ç—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define input parameters\n",
    "n_batches = 10\n",
    "batch_size = 128\n",
    "ls = 1  # latent space\n",
    "\n",
    "# Generate random noise\n",
    "noise = torch.randn(size=(n_batches * batch_size, ls), dtype=torch.float)\n",
    "print(f\"NN Input: noise.shape: {noise.shape}\")\n",
    "\n",
    "# Generates dots on parabola\n",
    "xy_pair = gen_pair(num=(n_batches * batch_size))\n",
    "xy_pair = torch.tensor(xy_pair, dtype=torch.float)\n",
    "print(f\"NN Output: xy_pair.shape: {xy_pair.shape}\")\n",
    "\n",
    "dataset = TensorDataset(noise, xy_pair)  # model inputs, model outputs\n",
    "trainset, testset = train_test_split(\n",
    "    dataset, train_size=0.8\n",
    ")  # split dataset for train and test\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –æ–∂–∏–¥–∞—Ç—å —à—É–º –Ω–∞ –≤—Ö–æ–¥ –∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–æ—á–∫–∏ –Ω–∞ –≤—ã—Ö–æ–¥–µ. (–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Å–ª–æ–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø–æ—Å–∫–æ–ª—å–∫—É –º—ã –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –Ω–∞—à –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤ –∫–∞–∫–æ–º-—Ç–æ –¥–∏–∞–ø–∞–∑–æ–Ω–µ.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class GenModel(nn.Module):\n",
    "    def __init__(self, latent_space):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_space, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 2),\n",
    "        )  # x,y\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ—Ü–µ–Ω–∫–∏ loss.\n",
    "\n",
    "–¢–∞–∫ –∫–∞–∫ –º—ã –Ω–µ –∑–Ω–∞–µ–º, –≤ –∫–∞–∫–æ–º –º–µ—Å—Ç–µ –ø–∞—Ä–∞–±–æ–ª—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–æ–∑–¥–∞—Å—Ç –Ω–æ–≤—É—é —Ç–æ—á–∫—É, —Ç–æ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ, —Å –∫–∞–∫–∏–º —ç–ª–µ–º–µ–Ω—Ç–æ–º –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –µ–µ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í–∞—Ä–∏–∞–Ω—Ç ‚Ññ1**\n",
    "\n",
    "–î–ª—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ $x$ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª—è—Ç—å $y_{target}=x*x$ –∏ —Å—á–∏—Ç–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É $y$, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –º–æ–¥–µ–ª—å—é, –∏ $y_{target}$, –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–º –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(pair, label):\n",
    "    # All inputs are batches\n",
    "    x_fake = pair[:, 0]\n",
    "    y_fake = pair[:, 1]\n",
    "    return torch.abs(x_fake * x_fake - y_fake).mean()  # average by batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å.\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ –µ—Å–ª–∏ –º—ã –∑–Ω–∞–µ–º —Å–ø–æ—Å–æ–± —Ç–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤—ã—Ö–æ–¥ –ø–æ –≤—Ö–æ–¥—É, —Ç–æ –∑–∞–¥–∞—á–∞ —É–∂–µ —Ä–µ—à–µ–Ω–∞ –∏ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –Ω–µ –Ω—É–∂–Ω–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í–∞—Ä–∏–∞–Ω—Ç ‚Ññ2**\n",
    "\n",
    "–ù–∞–π—Ç–∏ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ —Ç–æ—á–∫—É  $ target = (x_{target},y_{target})$, –Ω–∞–∏–±–æ–ª–µ–µ –±–ª–∏–∑–∫—É—é –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–º $ generated = (x,y)$, –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —ç—Ç–∏–º–∏ —Ç–æ—á–∫–∞–º–∏ –≤ –∫–∞—á–µ—Å—Ç–≤–µ loss.\n",
    "\n",
    "$$\\large Loss = min(dist(target_{i},generated))$$\n",
    "\n",
    "–í –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –≤—ã—Å–æ–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —Ç–∞–∫–æ–π –ø–æ–∏—Å–∫ –±—É–¥–µ—Ç –≤–µ—Å—å–º–∞ —Ä–µ—Å—É—Ä—Å–æ–∑–∞—Ç—Ä–∞—Ç–Ω—ã–º, –Ω–æ –≤ –Ω–∞—à–µ–º —É—á–µ–±–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ —Ä–∞–±–æ—Ç–∞—Ç—å –±—É–¥–µ—Ç.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, targets):\n",
    "        super().__init__()\n",
    "        self.targets = targets  # Remember all real samples, impossible in real world\n",
    "\n",
    "    def forward(self, input, dummy_target=None):\n",
    "        dist = torch.cdist(input, self.targets)  # claculate pairwise distances (euc.)\n",
    "        min_dist, index = torch.min(dist, dim=1)  # take the best\n",
    "        return min_dist.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–¥ –¥–ª—è –≤—ã–≤–æ–¥–∞ loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def get_test_loss(model, loader):\n",
    "    test_data = next(iter(loader))\n",
    "    test_loss = Loss(test_data[1])\n",
    "    outputs = model(samples.to(device))\n",
    "    return test_loss(outputs.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "–¶–µ–ª–µ–≤—ã–µ —Ç–æ—á–∫–∏ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–ø–æ–º–∏–Ω–∞—é—Ç—Å—è –≤ loss, –∑–∞—Ç–µ–º –∏–¥–µ—Ç –æ–±—ã—á–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_epochs = 600\n",
    "model = GenModel(latent_space=ls)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "all_train_targets = next(iter(train_loader))[1]\n",
    "criterion = Loss(all_train_targets.to(device))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_epoch = 0\n",
    "    for samples, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(samples.to(device))\n",
    "        loss = criterion(outputs.to(device), labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    loss_test = get_test_loss(model, test_loader)\n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            f\"Epoch={epoch} train_loss={loss_epoch/len(train_loader):.4} test_loss={loss_test:.4}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ —à—É–º–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image(model, pairs, ls=1):\n",
    "    model.eval().to(\"cpu\")\n",
    "    noise = torch.tensor(np.random.normal(size=(1000, ls)), dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "        xy_pair_gen = model(noise)\n",
    "\n",
    "    xy_pair_gen = xy_pair_gen.detach().numpy()\n",
    "    plt.scatter(pairs[:, 0], pairs[:, 1], color=\"red\", label=\"real\")\n",
    "    plt.scatter(xy_pair_gen[:, 0], xy_pair_gen[:, 1], color=\"blue\", label=\"generated\")\n",
    "    plt.axis([-1, 1, 0, 1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "test_image(model, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–¥–Ω–æ, —á—Ç–æ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ—á–∫–∏, –ª–µ–∂–∞—â–∏–µ –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ, –ø—Ä–∏ —ç—Ç–æ–º –≤—Å–µ –æ–Ω–∏ –ª–µ–∂–∞—Ç –≤ –¥–æ–≤–æ–ª—å–Ω–æ —É–∑–∫–æ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ –ø–æ –æ—Å–∏ —Ö.\n",
    "\n",
    "\n",
    "–≠—Ç–æ –Ω–µ—É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ: –≤ loss function –º—ã –ø—Ä–æ–ø–∏—Å–∞–ª–∏, —á—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –¥–æ–ª–∂–Ω–∞ –ª–µ–∂–∞—Ç—å –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ, –∏ –º–æ–¥–µ–ª—å –æ–±—É—á–∏–ª–∞—Å—å. –ê –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –≤ –∫–∞–∫–∏—Ö —á–∞—Å—Ç—è—Ö –∫—Ä–∏–≤–æ–π –¥–æ–ª–∂–Ω—ã –æ–∫–∞–∑–∞—Ç—å—Å—è —Ç–æ—á–∫–∏, –º—ã –≤ loss –Ω–∏–∫–∞–∫ –Ω–µ –∫–æ–¥–∏—Ä–æ–≤–∞–ª–∏.\n",
    "\n",
    "–ë–æ–ª–µ–µ —Ç–æ–≥–æ, –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –Ω–∞—É—á–∏—Ç—å—Å—è —Ö–æ—Ä–æ—à–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–¥–Ω—É –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é —Ç–æ—á–∫—É, –∏ –ø—Ä–∏ —ç—Ç–æ–º loss –º–æ–∂–µ—Ç —Å—Ç–∞—Ç—å –Ω—É–ª–µ–≤—ã–º.\n",
    "\n",
    "\n",
    "–ò—Ç–∞–∫, –Ω–∞–¥–æ —Ä–µ—à–∏—Ç—å –¥–≤–µ –ø—Ä–æ–±–ª–µ–º—ã:\n",
    "\n",
    "\n",
    "1.   –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –≤ loss —É—Å–ª–æ–≤–∏–µ –æ —Ç–æ–º, —á—Ç–æ —Ç–æ—á–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏.\n",
    "2.   –ü—Ä–∏–¥—É–º–∞—Ç—å —Å–ø–æ—Å–æ–± –ø—Ä–æ–≤–µ—Ä–∫–∏, –Ω–µ —Ç—Ä–µ–±—É—é—â–∏–π –ø–µ—Ä–µ–±–æ—Ä–∞ –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë—É–¥–µ–º –Ω–∞–∫–∞–∑—ã–≤–∞—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –Ω–µ –Ω–∞–ø—Ä—è–º—É—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π loss function, –∞ –≤—Ç–æ—Ä–æ–π **—Å–µ—Ç—å—é**, –∫–æ—Ç–æ—Ä–∞—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –ª–µ–∂–∏—Ç –ª–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ.\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º —Å–µ—Ç—å-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ—á–µ–∫ (–ª–µ–∂–∏—Ç/–Ω–µ –ª–µ–∂–∏—Ç –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ), –∫–æ—Ç–æ—Ä—É—é –Ω–∞–∑–æ–≤—ë–º **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä** –∏–ª–∏ –∫—Ä–∏—Ç–∏–∫."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisModel(nn.Module):\n",
    "    def __init__(self, n_points):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 15),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15, 1),  # real/fake\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2 * n_points)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –æ–±—â–µ–º —Å–ª—É—á–∞–µ –∑–∞–¥–∞—á–∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ ‚Äî –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ª–∏ –æ–±—ä–µ–∫—Ç –∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ò—Ç–æ–≥–æ** –º—ã –∏–º–µ–µ–º:\n",
    "- **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä**, –≤—ã–¥–∞—é—â–∏–π —Ç–æ—á–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç—å –ø–∞—Ä–∞–±–æ–ª–µ, –∞ –º–æ–≥—É—Ç –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç—å –µ–π;\n",
    "- **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä**, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Ö —Ä–∞–∑–ª–∏—á–∞—Ç—å.\n",
    "\n",
    "–ú—ã –±—É–¥–µ–º –ø–æ–¥–∞–≤–∞—Ç—å –≤ **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä** **–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏** (—á—Ç–æ–±—ã –æ–Ω –∑–Ω–∞–ª, –∫–∞–∫ —ç—Ç–æ –¥–æ–ª–∂–Ω–æ –≤—ã–≥–ª—è–¥–µ—Ç—å) –∏ **—Ç–æ—á–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–¥–∞—ë—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä**, —Å—á–∏—Ç–∞—è –∏—Ö –ø–æ–¥–¥–µ–ª–∫–æ–π.\n",
    "\n",
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä** –±—É–¥–µ—Ç —É—á–∏—Ç—å—Å—è **–ø–æ–¥—Ä–∞–∂–∞—Ç—å** —Ä–µ–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º, –∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –±—É–¥–µ—Ç —É—á–∏—Ç—å—Å—è **–æ—Ç–ª–∏—á–∞—Ç—å** —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏, –æ—Ç –ø–æ–¥–¥–µ–ª–æ–∫.\n",
    "\n",
    "–ú—ã –ø—Ä–∏—à–ª–∏ –∫ –∏–¥–µ–µ **–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö** –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generative adversarial network (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[arxiv] üéì Generative Adversarial Networks (Goodfellow et al., 2014)](https://arxiv.org/abs/1406.2661) (**Cited by 33430!!!**)\n",
    "\n",
    "[[video] üì∫ –†–∞–∑–±–æ—Ä –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–∏ GAN](https://www.youtube.com/watch?v=eyxmSmjmNS0)\n",
    "\n",
    "[[video] üì∫ –õ–µ–∫—Ü–∏—è –ò–∞–Ω–∞ –ì—É–¥—Ñ–µ–ª–ª–æ—É](https://www.youtube.com/watch?v=HGYYEUSm-0Q)\n",
    "\n",
    "**–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω—É—é** —Å–µ—Ç—å –æ–ø–∏—Å–∞–ª –ò–∞–Ω –ì—É–¥—Ñ–µ–ª–ª–æ—É –∏–∑ –∫–æ–º–ø–∞–Ω–∏–∏ Google (–Ω–∞ —Ç–æ—Ç –º–æ–º–µ–Ω—Ç) –≤ 2014 –≥–æ–¥—É. –°–µ–π—á–∞—Å –æ–Ω –≤–æ–∑–≥–ª–∞–≤–ª—è–µ—Ç –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ Apple. –ü—Ä–∏–Ω—Ü–∏–ø —Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Å–µ—Ç–∏ **GAN** –Ω–µ—Ä–µ–¥–∫–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –º–µ—Ç–∞—Ñ–æ—Ä—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/generative_adversarial_network_scheme.png\" width=\"700\"></center>\n",
    "<center><em>–°—Ö–µ–º–∞—Ç–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã GAN </em></center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä ‚Äî —Ñ–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—â–µ —Å–æ –≤—Ä–µ–º–µ–Ω **AlexNet** –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ –µ—Å–ª–∏ –º—ã —á—Ç–æ-—Ç–æ –∏ —É–º–µ–µ–º –¥–µ–ª–∞—Ç—å —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏, —Ç–æ —ç—Ç–æ **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã**. –í –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º GAN **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä** –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ—Å—Ç–µ–π—à—É—é –∏–∑ –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ‚Äî **–±–∏–Ω–∞—Ä–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é** (–ª–∏–±–æ *real*, –ª–∏–±–æ *fake*). –ê –≤–æ—Ç –∑–∞–¥–∞—á–∞ **–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏** –∫–∞–∫–∏–º-—Ç–æ –ø—Ä—è–º—ã–º –æ–±—Ä–∞–∑–æ–º –Ω–∞ —Ç–æ—Ç –º–æ–º–µ–Ω—Ç —Ä–µ—à–µ–Ω–∞ –Ω–µ –±—ã–ª–∞.\n",
    "\n",
    "–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—é –º–æ—â—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–¥—Å—Ç–∞–≤–∏–º, —á—Ç–æ –µ—Å—Ç—å —Ñ–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫ $G$ (generator) –∏ –±–∞–Ω–∫–∏—Ä —Å –ø—Ä–∏–±–æ—Ä–æ–º –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç–∏ –∫—É–ø—é—Ä $D$ (discriminator).\n",
    "\n",
    "–§–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫ —á–µ—Ä–ø–∞–µ—Ç –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ –∏–∑ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª –≤ –≤–∏–¥–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —à—É–º–∞ $z$ –∏ —Å–æ–∑–¥–∞–µ—Ç –ø–æ–¥–¥–µ–ª–∫–∏ $G(z)$.\n",
    "\n",
    "–ë–∞–Ω–∫–∏—Ä $D$ –ø–æ–ª—É—á–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –ø–∞—á–∫—É –∫—É–ø—é—Ä $x$, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Ö –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç—å –∏ —Å–æ–æ–±—â–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä $D(x)$, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ —á–∏—Å–µ–ª –æ—Ç –Ω—É–ª—è –¥–æ –µ–¥–∏–Ω–∏—Ü—ã ‚Äî —Å–≤–æ—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å) –ø–æ –∫–∞–∂–¥–æ–π –∫—É–ø—é—Ä–µ –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–∞ –Ω–∞—Å—Ç–æ—è—â–∞—è. –ï–≥–æ —Ü–µ–ª—å ‚Äî –≤—ã–¥–∞–≤–∞—Ç—å –Ω—É–ª–∏ –¥–ª—è –ø–æ–¥–¥–µ–ª–æ–∫ $D(G(z))$ –∏ –µ–¥–∏–Ω–∏—Ü—ã –¥–ª—è –Ω–∞—Å—Ç–æ—è—â–∏—Ö –¥–µ–Ω–µ–≥ $D(x)$. –ó–∞–¥–∞—á—É –º–æ–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å –∫–∞–∫ –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—é –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è $D(x)(1-D(G(z)))$, –∞ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ, –≤ —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å, –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ —Å—É–º–º—É —á–µ—Ä–µ–∑ –ª–æ–≥–∞—Ä–∏—Ñ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –∑–∞–¥–∞—á–∞ –±–∞–Ω–∫–∏—Ä–∞ ‚Äî –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å $log(D(x))+log(1-D(G(z)))$.\n",
    "\n",
    "–¶–µ–ª—å —Ñ–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫–∞ –ø—Ä—è–º–æ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–∞ ‚Äî –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å $D(G(z))$, —Ç–æ –µ—Å—Ç—å —É–±–µ–¥–∏—Ç—å –±–∞–Ω–∫–∏—Ä–∞ –≤ —Ç–æ–º, —á—Ç–æ –ø–æ–¥–¥–µ–ª–∫–∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ.\n",
    "\n",
    "–ü—Ä–æ–¥–æ–ª–∂–∞—è –∞–Ω–∞–ª–æ–≥–∏—é, –æ–±—É—á–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å —Ç–∞–∫: —Ñ–∞–ª—å—à–∏–≤–æ–º–æ–Ω–µ—Ç—á–∏–∫ –Ω–µ –ø—Ä–æ—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥–¥–µ–ª–∫–∏ –Ω–∞—É–¥–∞—á—É. –û–Ω –¥–æ–±—ã–≤–∞–µ—Ç –ø—Ä–∏–±–æ—Ä –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–æ–¥–¥–µ–ª–æ–∫, —Ä–∞–∑–±–∏—Ä–∞–µ—Ç –µ–≥–æ, —Å–º–æ—Ç—Ä–∏—Ç, –∫–∞–∫ —Ç–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏ –∑–∞—Ç–µ–º —Å–æ–∑–¥–∞–µ—Ç –ø–æ–¥–¥–µ–ª–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–º–æ–≥—É—Ç –æ–±–º–∞–Ω—É—Ç—å —ç—Ç–æ—Ç –ø—Ä–∏–±–æ—Ä."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —ç—Ç–æ **[–∏–≥—Ä–∞](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B8%D0%B3%D1%80) –¥–≤—É—Ö –∏–≥—Ä–æ–∫–æ–≤**:\n",
    "\n",
    "$$\\large \\min\\limits_{\\theta_g}  \\max\\limits_{\\theta_d} [\\mathbb{E}_{x _\\sim p(data)} log(D_{\\theta_d}(x)]+\\mathbb{E}_{z _\\sim p(z)}\n",
    "[log(1-D_{\\theta_d}(G_{\\theta_g}(z))]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä**\n",
    "- –æ–±—É—á–∞–µ—Ç—Å—è –ø—Ä–∏ **—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ** ${G}_{\\theta_{g}}$,\n",
    "- **–º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç** —Ñ—É–Ω–∫—Ü–∏—é –≤—ã—à–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ $\\theta_d$ (**–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –ø–æ–¥—ä–µ–º**),\n",
    "- —Ä–µ—à–∞–µ—Ç –∑–∞–¥–∞—á—É **–±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**: —Å—Ç–∞—Ä–∞–µ—Ç—Å—è –ø—Ä–∏—Å–≤–æ–∏—Ç—å $1$ —Ç–æ—á–∫–∞–º –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞ $E_{x‚àºp_{data}}$ –∏ 0 —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—ã–±–æ—Ä–∫–∞–º $E_{z‚àºp(z)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä**\n",
    "- –æ–±—É—á–∞–µ—Ç—Å—è –ø—Ä–∏ **—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–µ** $D_{Œ∏_d}$,\n",
    "- –ø–æ–ª—É—á–∞–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤–µ—Å–æ–≤ –∑–∞ —Å—á–µ—Ç backpropagation —á–µ—Ä–µ–∑ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä,\n",
    "- **–º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç** —Ñ—É–Ω–∫—Ü–∏—é –≤—ã—à–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ $\\theta_d$ (**–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å—Ä–µ–¥—Å—Ç–≤–æ–º **—á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏—è** –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ **–ø–æ–¥—ä–µ–º–∞** –∏ **—Å–ø—É—Å–∫–∞** —Å–µ—Ç—å –º–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π **–ø–æ–¥—ä–µ–º** –Ω–∞ **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–µ**:\n",
    "\n",
    "\n",
    "$$\\large \\max\\limits_{\\theta_d} [\\mathbb{E}_{x _\\tilde{}p(data)} log(D_{\\theta_d}(x)+\\mathbb{E}_{z _\\tilde{}p(z)} log(1-D_{\\theta_d}(G_{\\theta_g}(z)))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π **—Å–ø—É—Å–∫** –Ω–∞ **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ**:\n",
    "\n",
    "\n",
    "$$\\large \\min\\limits_{\\theta_g} \\mathbb{E}_{z _\\tilde{}p(z)} log(1-D_{\\theta_d}(G_{\\theta_d}(z)))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π **—Å–ø—É—Å–∫** –Ω–∞ **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ** —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–µ–Ω –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–º—É **–ø–æ–¥—ä–µ–º—É**\n",
    "\n",
    "$$\\large \\max\\limits_{\\theta_g} \\mathbb{E}_{z _\\tilde{}p(z)} log(D_{\\theta_d}(G_{\\theta_d}(z)))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –ø—Ä–æ—Ü–µ—Å—Å–µ —Å–æ–≤–º–µ—Å—Ç–Ω–æ–≥–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –µ—Å–ª–∏ —Å–∏—Å—Ç–µ–º–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∞, –¥–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è **–º–∏–Ω–∏–º–∞–∫—Å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–∞–≤–Ω–æ–≤–µ—Å–∏—è**, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–±–µ —Å–µ—Ç–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —É—á–∞—Ç—Å—è.\n",
    "\n",
    "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É–¥–∞—á–Ω–æ –æ–±—É—á–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–æ—Ç–ª–∏—á–∏–º—ã –æ—Ç –Ω–∞—Å—Ç–æ—è—â–∏—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ —Ö–æ—Ä–æ—à–µ–Ω—å–∫–æ –ø–æ–¥—É–º–∞—Ç—å, —Ç–æ –º–æ–∂–Ω–æ –ø—Ä–∏–π—Ç–∏ –∫ –≤—ã–≤–æ–¥—É, —á—Ç–æ **loss function** –≤ **GAN** ‚Äî —ç—Ç–æ –Ω–µ –∫–∞–∫–∞—è-—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è, –∑–∞–¥–∞–Ω–Ω–∞—è –ª—é–¥—å–º–∏, –∞ –µ—â–µ –æ–¥–Ω–∞ **–Ω–µ–π—Ä–æ—Å–µ—Ç—å**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ GAN**\n",
    "* –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ **–≥–∞—Ä–∞–Ω—Ç–∏–∏ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏**\n",
    "* –ú–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å –æ–±—ã—á–Ω—ã–º **SGD/Adam**\n",
    "* –†–µ—à–∞–µ—Ç –≤ —è–≤–Ω–æ–º –≤–∏–¥–µ –∑–∞–¥–∞—á—É **generative modeling**, –Ω–æ –Ω–µ—è–≤–Ω—ã–º –æ–±—Ä–∞–∑–æ–º (**–Ω–µ–π—Ä–æ—Å–µ—Ç–∏**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ GAN**\n",
    "* **–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ**\n",
    "* –û—á–µ–Ω—å **–¥–æ–ª–≥–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å**\n",
    "* **Mode-collapsing** (–º–æ–¥–µ–ª—å –≤—ã–¥–∞–µ—Ç –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –∫–ª–∞—Å—Å –∏ —Ç.–¥., –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫–∏–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ–π –ø–æ–¥–∞—é—Ç—Å—è)\n",
    "* **–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞**: –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –Ω–∞—Å—Ç–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –Ω–∞—É—á–∏–ª—Å—è –æ—Ç–ª–∏—á–∞—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã –æ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö, —á—Ç–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç –≤–µ—Å–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ä–∞–≤–Ω—ã–º 0: –≤ –∫–∞–∫—É—é —Å—Ç–æ—Ä–æ–Ω—É –±—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –Ω–µ –∏–∑–º–µ–Ω–∏–ª —Å–≤–æ–∏ –≤–µ—Å–∞, –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –≤—Å–µ —Ä–∞–≤–Ω–æ –∏–¥–µ–∞–ª—å–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ñ–∞–ª—å—à–∏–≤–∫–∏\n",
    "* –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ‚Äî **pure luck**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º –Ω–∞—à–∏ **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä** –∏ **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_space, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_space, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2),\n",
    "        )  # x,y\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),  # real/fake\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º **–≤—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 10  # latent space\n",
    "num_epochs = 10000\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —É –Ω–∞—Å —Ç–∞–∫ –∂–µ, –∫–∞–∫ –∏ –≤ –ø–µ—Ä–≤–æ–º –ø—Ä–∏–º–µ—Ä–µ, –µ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è **latent space**. –≠—Ç–æ —Ç–æ—Ç —à—É–º, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã –±—É–¥–µ–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à–∏ —Ç–æ—á–∫–∏. –ó–∞–∫–æ–Ω —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–∞—Å—Å –≤ –¥–µ–π—Å—Ç–≤–∏–∏ ‚Äî –Ω–µ–ª—å–∑—è —Å–æ–∑–¥–∞—Ç—å —á—Ç–æ-—Ç–æ –∏–∑ –Ω–∏—á–µ–≥–æ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "criterion = nn.BCELoss()  # Loss\n",
    "gen = Generator(latent_space=latent_dim, hidden_dim=50).to(device)\n",
    "disc = Discriminator(hidden_dim=50).to(device)\n",
    "\n",
    "# 2 optimizers for Discriminator and Generator\n",
    "optimizerD = torch.optim.Adam(disc.parameters(), lr=3e-4)\n",
    "optimizerG = torch.optim.Adam(gen.parameters(), lr=3e-4)\n",
    "\n",
    "# Fix noise to compare\n",
    "fixed_noise = torch.randn(128, latent_dim, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º `BCELoss` (**Binary Cross Entropy**). –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è –ø–æ—á–µ–º—É:\n",
    "\n",
    "- **–î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä** —Ä–µ—à–∞–µ—Ç –∑–∞–¥–∞—á—É **–±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**. –î–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç **BCE**.\n",
    "- –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—É –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–æ –∫–∞–∫ \"–æ–±—ä–µ–∫—Ç–∞–º, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–º**, **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–æ–º** –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—Ä–∏—Å–≤–æ–µ–Ω–∞ **–≤—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å**\". –î–ª—è **\"–∏–¥–µ–∞–ª—å–Ω–æ–≥–æ\" –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞**, –∫–æ—Ç–æ—Ä—ã–π –≤—Å–µ–≥–¥–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –∑–Ω–∞—á–µ–Ω–∏—è **$D(G(z))$** –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å **–±–ª–∏–∑–∫–∏ –∫ 1**. –î–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç **BCE**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞–µ—Ç —Ç–æ—á–∫–∏ –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pair(num=100):\n",
    "    x = np.random.uniform(low=-1, high=1, size=(num,))\n",
    "    y = x * x\n",
    "    return torch.tensor(\n",
    "        np.hstack((x.reshape(-1, 1), y.reshape(-1, 1))), dtype=torch.float\n",
    "    )  # Create num of correct dots(x,y) on parabola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ —Å–µ–π—á–∞—Å –±—É–¥–µ—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å? $$$$\n",
    "\n",
    "* –û–±—É—á–µ–Ω–∏–µ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞\n",
    "    * –æ–±–Ω—É–ª–∏–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞**\n",
    "    * real —Ç–æ—á–∫–∏\n",
    "        * —Å–æ–∑–¥–∞–¥–∏–º –Ω–∞–±–æ—Ä **real —Ç–æ—á–µ–∫**, –∫–æ—Ç–æ—Ä—ã–µ –ª–µ–∂–∞—Ç –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ\n",
    "        * –ø–æ—Å—á–∏—Ç–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –Ω–∞ **real —Ç–æ—á–∫–∞—Ö** –∏ **real –º–µ—Ç–∫–∞—Ö** $\\text{loss D}_\\text{real}$\n",
    "        * –ø–æ—Å—á–∏—Ç–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/gan_training_algorithm_1.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* –û–±—É—á–µ–Ω–∏–µ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ)\n",
    " * fake —Ç–æ—á–∫–∏\n",
    "   * —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º $z$\n",
    "   * –≤–æ–∑—å–º–µ–º –Ω–∞—à –Ω–µ –æ–±—É—á–µ–Ω–Ω—ã–π **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä** –∏ —Å–æ–∑–¥–∞–¥–∏–º —Å –µ–≥–æ –ø–æ–º–æ—â—å—é **fake —Ç–æ—á–∫–∏** –∏–∑ $z$\n",
    "   * –ø–æ—Å—á–∏—Ç–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –Ω–∞ **fake —Ç–æ—á–∫–∞—Ö** –∏ **fake –º–µ—Ç–∫–∞—Ö** $\\text{loss D}_\\text{fake}$\n",
    "   * –ø–æ—Å—á–∏—Ç–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞** (–æ–Ω–∏ —Å–ª–æ–∂–∞—Ç—Å—è —Å —É–∂–µ –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—ã–º–∏ —Ä–∞–Ω–µ–µ)\n",
    " * –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤\n",
    "   * —Å–¥–µ–ª–∞–µ–º —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞** (–æ–±–Ω–æ–≤–∏–º –µ–≥–æ –≤–µ—Å–∞)\n",
    "   * **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä** –Ω–µ –æ–±—É—á–∞–µ—Ç—Å—è\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/gan_training_algorithm_2.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* –û–±—É—á–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞\n",
    " * –æ–±–Ω—É–ª–∏–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞**\n",
    " * —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º $z$\n",
    " * —Å–æ–∑–¥–∞–¥–∏–º —Å –ø–æ–º–æ—â—å—é **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞** –Ω–∞–±–æ—Ä **fake —Ç–æ—á–µ–∫** –∏–∑ $z$\n",
    " * –ø–æ—Å—á–∏—Ç–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –Ω–∞ **fake —Ç–æ—á–∫–∞—Ö** –∏ **real –º–µ—Ç–∫–∞—Ö** $\\text{loss G}$ (–ø–æ–¥–º–µ–Ω–∞ –º–µ—Ç–æ–∫)\n",
    " * –ø–æ—Å—á–∏—Ç–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–ª—è **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞**\n",
    " * —Å–¥–µ–ª–∞–µ–º —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞** (–æ–±–Ω–æ–≤–∏–º –µ–≥–æ –≤–µ—Å–∞)\n",
    " * **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä** –Ω–µ –æ–±—É—á–∞–µ—Ç—Å—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/gan_training_algorithm_3.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Main Training Loop\n",
    "print(\"Training...\")\n",
    "print(device)\n",
    "\n",
    "x = []\n",
    "y_D = []\n",
    "y_G = []\n",
    "for epoch in range(num_epochs):\n",
    "    # max log(D(x)) + log(1 - D(G(z)))\n",
    "    # train on real points\n",
    "    disc.zero_grad()\n",
    "\n",
    "    # Define real points\n",
    "    real_points = gen_pair(num=batch_size).to(device)\n",
    "    label = torch.full(\n",
    "        (batch_size,), real_label, dtype=torch.float, device=device\n",
    "    ).view(-1)\n",
    "\n",
    "    # Train disc on real_points\n",
    "    output = disc(real_points).view(-1)\n",
    "    errD_real = criterion(output, label)\n",
    "    errD_real.backward()\n",
    "\n",
    "    # Define fake points\n",
    "    # This dots generated by generator transform from latent space\n",
    "    noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "    fake_points = gen(noise)\n",
    "    label.fill_(fake_label)\n",
    "\n",
    "    # Train disc on fake_points\n",
    "    output = disc(fake_points.detach()).view(-1)\n",
    "    errD_fake = criterion(output, label)\n",
    "    errD_fake.backward()\n",
    "\n",
    "    # Discriminator loss(real+fake)\n",
    "    errD = errD_real + errD_fake\n",
    "\n",
    "    optimizerD.step()\n",
    "\n",
    "    # max log(D(G(z)))\n",
    "    # Now, train generator\n",
    "    gen.zero_grad()\n",
    "\n",
    "    # Let's tell the discriminator that our generator creates real points\n",
    "    label.fill_(real_label)\n",
    "\n",
    "    output = disc(fake_points).view(-1)\n",
    "\n",
    "    errG = criterion(output, label)\n",
    "\n",
    "    errG.backward()\n",
    "\n",
    "    optimizerG.step()\n",
    "\n",
    "    # Plotting every N epoch\n",
    "    x.append(epoch)\n",
    "    y_D.append(errD.item() / 2)\n",
    "    y_G.append(errG.item())\n",
    "\n",
    "    if epoch % 250 == 0:\n",
    "        fig, ax = plt.subplots(nrows=2, figsize=(9, 6))\n",
    "        ax[0].plot(x, y_D, color=\"red\", lw=1, label=\"D\")\n",
    "        ax[0].plot(x, y_G, color=\"green\", lw=1, label=\"G\")\n",
    "\n",
    "        # Generates dots from fixed_noise\n",
    "        fake_points = gen(fixed_noise)\n",
    "        ax[1].scatter(\n",
    "            fake_points.detach().to(\"cpu\")[:, 0],\n",
    "            fake_points.detach().to(\"cpu\")[:, 1],\n",
    "            color=\"green\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        ax[1].scatter(\n",
    "            real_points.detach().to(\"cpu\")[:, 0],\n",
    "            real_points.detach().to(\"cpu\")[:, 1],\n",
    "            color=\"red\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        ax[1].set_xlim(-1, 1)\n",
    "        ax[1].set_ylim(0, 1)\n",
    "        clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–ª–∞—Å—Å!** –£ –Ω–∞—Å –ø–æ–ª—É—á–∏–ª–æ—Å—å (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –Ω–µ —Å–æ—à–ª–æ—Å—å –∑–∞ 10000 —ç–ø–æ—Ö, –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –∑–∞–Ω–æ–≤–æ, –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é, **—Ñ–∏–∫—Å–∞—Ü–∏—è seed –µ—â–µ –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å GAN**). –û—Å–æ–±–µ–Ω–Ω–æ –∫—Ä—É—Ç–æ —Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫ –∫—Ä–∞—Å–∏–≤–æ loss **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞** –∏ **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞** —Å—Ö–æ–¥—è—Ç—Å—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN ‚Äî –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–° –ø–æ–º–æ—â—å—é **GAN** –º–æ–∂–Ω–æ, —Ä–∞–∑—É–º–µ–µ—Ç—Å—è, –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–æ—á–∫–∏ –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ. –ú–æ–∂–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ù–æ –ø–æ—è–≤–ª—è—é—Ç—Å—è –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–∞–∫ –∏–∑ —à—É–º–∞ –Ω–∞ –≤—Ö–æ–¥–µ —Å–µ—Ç–∏ –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∞–º—ã–º –ø—Ä–æ—Å—Ç—ã–º –æ—Ç–≤–µ—Ç–æ–º –±—É–¥–µ—Ç: –≤–∑—è—Ç—å —à—É–º, –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –µ–≥–æ —á–µ—Ä–µ–∑ **–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏** –∏ —Å–¥–µ–ª–∞—Ç—å **reshape** –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è. –í —Ü–µ–ª–æ–º, —ç—Ç–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å.\n",
    "\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ **DCGAN (Deep Convolutional GAN)** –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **—Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ** –∏ **—Å–≤–µ—Ä—Ç–æ—á–Ω–æ-—Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ** (*convolutional* –∏ *convolutional-transpose*) —Å–ª–æ–∏ –≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ. –í–ø–µ—Ä–≤—ã–µ –º–µ—Ç–æ–¥ **DCGAN** –±—ã–ª –æ–ø–∏—Å–∞–Ω –≤ —Å—Ç–∞—Ç—å–µ [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (Radford et al., 2015)](https://arxiv.org/abs/1511.06434)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/deep_convolutional_gan_scheme.png\" width=\"700\"></center>\n",
    "<center><em>–°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã DCGAN (Radford et al., 2015).</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∏–∂–µ –≤–∏–¥–Ω–∞ —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ **–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö —Å–ª–æ—ë–≤** –∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ **–æ–±—Ä–∞—Ç–Ω—ã—Ö —Å–≤—ë—Ä—Ç–æ–∫**. –û—á–µ–≤–∏–¥–Ω–æ, —Ä–µ–∑—É–ª—å—Ç–∞—Ç **DCGAN** –ª—É—á—à–µ, —á–µ–º **GAN**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/gan_dcgan_mnist_examples.png\" width=\"600\"></center>\n",
    "<center><em>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ MNIST (Radford et al., 2015)</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/pdf/1511.06434.pdf\">\tUnsupervised representation learning with deep convolutional generative adversarial networks</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ –≤—Ö–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –ø–æ–¥–∞—é—Ç —à—É–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤. –≠—Ç–æ—Ç —à—É–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –≤–µ–∫—Ç–æ—Ä –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ. –û–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä ‚Äî –æ–¥–∏–Ω —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç. –ó–∞–¥–∞—á–∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n",
    "\n",
    "–¢–∞–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–∏ –ø–æ–º–æ—â–∏ —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö (convolution-transpose, –∏–Ω–æ–≥–¥–∞ –Ω–∞–∑—ã–≤–∞—é—Ç fractionally strided convolution) —Å–ª–æ–µ–≤. –ö–∞–∫ –∏ –æ–±—ã—á–Ω—ã–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–ª–æ–∏, —ç—Ç–∏ —Å–ª–æ–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —è–¥—Ä–∞, –Ω–æ –ø–µ—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º —Å–≤–µ—Ä—Ç–æ–∫ –æ–Ω–∏ —É–≤–µ–ª–∏—á–∏–≤–∞—é—Ç —Ä–∞–∑–º–µ—Ä –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, \"—Ä–∞–∑–¥–≤–∏–≥–∞—è\" –ø–∏–∫—Å–µ–ª–∏ –∏ –∑–∞–ø–æ–ª–Ω—è—è –æ–±—Ä–∞–∑—É—é—â–∏–µ—Å—è –ø—Ä–æ–º–µ–∂—É—Ç–∫–∏ –º–µ–∂–¥—É –ø–∏–∫—Å–µ–ª—è–º–∏ –Ω—É–ª—è–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/dcgan_architecture.png\" width=\"700\"></center>\n",
    "<center><em>–ó–µ—Ä–∫–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ DCGAN </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposed Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –∫—Ä–∞—Ç–∫–æ –≤—Å–ø–æ–º–Ω–∏–º, —á—Ç–æ –¥–µ–ª–∞—é—Ç TC —Å–ª–æ–∏.\n",
    "\n",
    "Transposed convolution –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –≤—Å–µ–º –ø–∏–∫—Å–µ–ª—è–º –≤—Ö–æ–¥–∞ –∏ —É–º–Ω–æ–∂–∞–µ—Ç –∏—Ö –Ω–∞ –æ–±—É—á–∞–µ–º–æ–µ —è–¥—Ä–æ —Å–≤–µ—Ä—Ç–∫–∏. –ü—Ä–∏ —ç—Ç–æ–º –∫–∞–∂–¥—ã–π –æ–¥–∏–Ω–æ—á–Ω—ã–π –ø–∏–∫—Å–µ–ª—å –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ —Ñ—Ä–∞–≥–º–µ–Ω—Ç. –¢–∞–º, –≥–¥–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–∞–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–∞, –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ø–∏–∫—Å–µ–ª—å–Ω–æ —Å—É–º–º–∏—Ä—É—é—Ç—Å—è.\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É—è Transposed convolution —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º `stride = 2`, –º–æ–∂–Ω–æ –ø–æ–≤—ã—à–∞—Ç—å —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –≤ –¥–≤–∞ —Ä–∞–∑–∞, –¥–æ–±–∞–≤–ª—è—è –Ω–∞ –Ω–µ–µ –º–µ–ª–∫–∏–µ –¥–µ—Ç–∞–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/transposed_convolution_explained.png\" width=\"1024\"></center>\n",
    "<center><em>Transposed convolution</em></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1, 3, 10, 10)) * 255  # one 3-channel image with 10x10 size\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convT = nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=3)\n",
    "y = convT(x)\n",
    "print(y.shape)  # One 3-chanells image with 12x12 size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ª—É—á–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –ø–æ—Ö–æ–∂–µ –Ω–∞ –≤—Ö–æ–¥–Ω–æ–µ, –ø–æ—Ç–æ–º—É —á—Ç–æ –±—ã–ª–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–µ —è–¥—Ä–∞ —Å–æ —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "ax[0].imshow(x[0].permute(1, 2, 0).detach().numpy().astype(np.uint8))\n",
    "ax[1].imshow(y[0].permute(1, 2, 0).detach().numpy().astype(np.uint8))\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].set_title(\"After ConvTranspose\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î—Ä—É–≥–∏–µ —Å–ø–æ—Å–æ–±—ã –ø–æ–≤—ã—à–µ–Ω–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è ‚Äî Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–º–∏–º–æ **–æ–±—Ä–∞—Ç–Ω—ã—Ö —Å–≤—ë—Ä—Ç–æ–∫** —Å—É—â–µ—Å—Ç–≤—É—é—Ç –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã –ø–æ–≤—ã—à–µ–Ω–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∏–∑ –Ω–∏–∑–∫–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± ‚Äî –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–≤—ã—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é **–∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏**. –î–∞–≤–∞–π—Ç–µ –≤—Å–ø–æ–º–Ω–∏–º, —á—Ç–æ –≤ PyTorch —ç—Ç–æ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–µ–º [Upsample](https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1, 3, 10, 10))  # one 3-channal image with 10x10 size\n",
    "print(\"Input shape:\", x.shape)\n",
    "\n",
    "upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "y = upsample(x)\n",
    "\n",
    "print(\"Output shape\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "ax[0].imshow((x[0].permute(1, 2, 0) * 256).detach().numpy().astype(np.uint8))\n",
    "ax[1].imshow((y[0].permute(1, 2, 0).detach().numpy() * 256).astype(np.uint8))\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].set_title(\"After Upsample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–Ω–æ–≥–æ DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ø—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–Ω–æ–≥–æ **DCGAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True if torch.cuda.is_available() else False\n",
    "model = torch.hub.load(\n",
    "    \"facebookresearch/pytorch_GAN_zoo:hub\", \"DCGAN\", pretrained=True, useGPU=use_gpu\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "\n",
    "num_images = 16\n",
    "noise, _ = model.buildNoiseData(num_images)\n",
    "with torch.no_grad():\n",
    "    generated_images = model.test(noise)\n",
    "    generated_images = (\n",
    "        generated_images.clamp(-1, 1) + 1\n",
    "    ) / 2.0  # normalization to 0..1 range\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16 * 3, 2 * 3))\n",
    "ax.imshow(\n",
    "    torchvision.utils.make_grid(generated_images).permute(1, 2, 0).cpu().numpy(),\n",
    "    interpolation=\"nearest\",\n",
    "    aspect=\"equal\",\n",
    ")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–∞–º–∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–π **DCGAN** –∏ –æ–±—É—á–∏—Ç—å –µ–≥–æ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ **FashionMNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2  # Num of epochs\n",
    "batch_size = 64  # batch size\n",
    "lr = 2e-4  # Learning rate\n",
    "b1 = 0.5  # Adam: decay of first order momentum of gradient\n",
    "b2 = 0.999  # Adam: decay of first order momentum of gradient\n",
    "num_cpu = 8  # Num of cpu threads to generate batch\n",
    "latent_dim = 100  # latent space\n",
    "img_size = 32  # images size\n",
    "channels = 1  # Num of channels\n",
    "sample_interval = 450  # interval between image sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—ã—á–Ω–æ –º—ã **–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å–∞** —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º, –Ω–æ –Ω–∏—á—Ç–æ –Ω–µ –º–µ—à–∞–µ—Ç –Ω–∞–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏—Ö —Ç–∞–∫, –∫–∞–∫ –º—ã —Ö–æ—Ç–∏–º. –í [–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–µ](https://arxiv.org/pdf/1511.06434.pdf) –ø—Ä–æ **DCGAN** –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Å —Ü–µ–Ω—Ç—Ä–æ–º –≤ –Ω—É–ª–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º 0,02:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, –∫–∞–∫ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è **—à—É–º** –≤ **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ**:\n",
    "* –°–Ω–∞—á–∞–ª–∞ —Å –ø–æ–º–æ—â—å—é **–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è** –æ–Ω –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ **–ø–µ—Ä–≤–∏—á–Ω—ã–µ —Ñ–∏—á–∏**\n",
    "* –ü–æ—Ç–æ–º —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ **view** **—Ä–µ—Å—ç–º–ø–ª–∏—Ç—Å—è** –≤ –∫–∞—Ä—Ç–∏–Ω–∫—É –Ω–∏–∑–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è\n",
    "* –ü–æ—Ç–æ–º –ø—Ä–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ **conv_blocks** –∫ –Ω–µ–º—É –ø–æ–æ—á–µ—Ä—ë–¥–Ω–æ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è **Upsample** –∏ **–û–ë–´–ß–ù–´–ï** —Å–≤—ë—Ä—Ç–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size**2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [\n",
    "                nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "            ]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2**4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size**2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Initialize Generator and Discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Initialize weight\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "def show_gen_img(model, latent_dim=100):\n",
    "    z = Tensor(np.random.normal(0, 1, (9, latent_dim)))  # define latent dim\n",
    "\n",
    "    # Generate noise from latent dim\n",
    "    sample_images = generator(z)\n",
    "    sample_images = sample_images.cpu().detach()\n",
    "\n",
    "    # Plotting images\n",
    "    grid = (\n",
    "        make_grid(sample_images, nrow=3, ncols=3, normalize=True)\n",
    "        .permute(1, 2, 0)\n",
    "        .numpy()\n",
    "    )\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.imshow(grid)\n",
    "    plt.axis(\"off\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–¥–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ –∏ –∑–∞–≥—Ä—É–∑–∏–º –∏ –∏—Ö –≤ Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        \"../../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(img_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5], [0.5]),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(data_loader):\n",
    "        # Adversarial ground truths\n",
    "        valid = Tensor(imgs.shape[0], 1).fill_(1.0)\n",
    "        fake = Tensor(imgs.shape[0], 1).fill_(0.0)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs.type(Tensor)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim)))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = criterion(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = criterion(discriminator(real_imgs), valid)\n",
    "        fake_loss = criterion(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        batches_done = epoch * len(data_loader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, num_epochs, i, len(data_loader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "            fig = show_gen_img(generator)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –∫–∞—Ä—Ç–∏–Ω–∫–∏ –æ–±—Ä–µ–ª–∏ –ø—Ä–∏–ª–∏—á–Ω—ã–π –≤–∏–¥, —Ö–≤–∞—Ç–∞–µ—Ç 2 —ç–ø–æ—Ö. –ß—Ç–æ–±—ã —Å—Ç–∞–ª–∏ –≤—ã–≥–ª—è–¥–µ—Ç—å —Ö–æ—Ä–æ—à–æ ‚Äî 5 —ç–ø–æ—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cGAN ‚Äî GAN —Å —É—Å–ª–æ–≤–∏–µ–º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cGAN** —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ **Conditional Generative Adversarial Net** ‚Äî —ç—Ç–æ **GAN** —Å —É—Å–ª–æ–≤–∏–µ–º. –£—Å–ª–æ–≤–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±—ã–º, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ü–∏—Ñ—Ä—ã. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –Ω–∞–º –Ω—É–∂–µ–Ω —É–∂–µ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –æ–±—É—á–∏—Ç—å –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/conditional_gan_scheme.png\" width=\"800\"></center>\n",
    "<center><em>–°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã cGAN. Label Y –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ —Å–ª—É—á–∞–π–Ω–æ–º—É —à—É–º—É, —Ç–µ–º —Å–∞–º—ã–º –º—ã –≥–æ–≤–æ—Ä–∏–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—É –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–ª—É—á–∞–π–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω—É–∂–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞. –¢–∞–∫–∂–µ –æ–Ω –ø–æ–¥–∞—ë—Ç—Å—è –≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–∞, —á—Ç–æ–±—ã –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –∑–Ω–∞–ª, –∫–∞–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Ä–µ–∞–ª—å–Ω–æ–µ, –∞ –∫–∞–∫–æ–µ ‚Äî –∫–∞–∫ –≤—ã–º—ã—à–ª–µ–Ω–Ω–æ–µ.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –±—É–¥–µ—Ç –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º –æ–±—É—á–µ–Ω–∏—é **GAN**: –º—ã –±—É–¥–µ–º –æ–±—É—á–∞—Ç—å —Å–µ—Ç–∏, —á–µ—Ä–µ–¥—É—è —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, –¥–æ–±–∞–≤–∏–≤ `label`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/cGANS_results_20_and_50_epochs_mnist.png\" width=\"600\"></center>\n",
    "<center><em>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ cGAN –∏ cDCGAN.</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/pdf/1511.06434.pdf\">Unsupervised Representation Learning with Deep Convolutional Generative Adversial Networks</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–∞–∫ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç–∫–∏?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–∫–æ–ª—å–∫—É –ø–æ–¥–∞–≤–∞—Ç—å –≤ —Å–µ—Ç—å —á–∏—Å–ª–∞ –æ—Ç 0 –¥–æ 9 (–≤ —Å–ª—É—á–∞–µ **MNSIT**) –Ω–µ—Ç —Å–º—ã—Å–ª–∞, —Ç–æ –Ω—É–∂–Ω–æ –ø—Ä–∏–¥—É–º–∞—Ç—å, –∫–∞–∫ –ø–æ–¥–∞–≤–∞—Ç—å –∏—Ö –≤ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å. –ù–∞ –ø–æ–º–æ—â—å –ø—Ä–∏—Ö–æ–¥—è—Ç **Embeddings**. –ú—ã –º–æ–∂–µ–º –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∂–¥—É—é –º–µ—Ç–∫—É –≤ –≤–∏–¥–µ –≤–µ–∫—Ç–æ—Ä–∞ —Å –¥–µ—Å—è—Ç—å—é —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏.\n",
    "\n",
    "[–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = next(iter(data_loader))\n",
    "\n",
    "label_emb = nn.Embedding(10, 10)\n",
    "\n",
    "e = label_emb(labels)\n",
    "\n",
    "print(f\"Label: {labels[0]}\")\n",
    "print(f\"Embedding for this label: {e[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ **—ç–º–±–µ–¥–¥–∏–Ω–≥–∏** –º–µ—Ç–æ–∫ –æ–±—ã—á–Ω–æ —Å–∫–ª–µ–∏–≤–∞—é—Ç—Å—è —Å –≤—Ö–æ–¥–∞–º–∏ —Å–µ—Ç–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ü–æ—á–µ–º—É –Ω–µ–ª—å–∑—è –ø–æ–¥–∞—Ç—å –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ –º—ã –±—É–¥–µ–º –ø–æ–¥–∞–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä 0.1 –¥–ª—è –µ–¥–∏–Ω–∏—Ü—ã, –∏ 0.5 –¥–ª—è –ø—è—Ç–∏, —Ç–æ –≤—Ö–æ–¥ —É –Ω–∞—Å –±—É–¥–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º, —á—Ç–æ –¥–æ–≤–æ–ª—å–Ω–æ –Ω–µ–ª–æ–≥–∏—á–Ω–æ: —Ç–æ–≥–¥–∞ –ø—Ä–∏ –Ω–µ–±–æ–ª—å—à–æ–º –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –≤—Ö–æ–¥–∞ –º—ã –±—É–¥–µ–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é —Ü–∏—Ñ—Ä—É. –ê —Ç–∞–∫–∂–µ —Å–µ—Ç–∏ –±—É–¥–µ—Ç —Å–ª–æ–∂–Ω–µ–µ –≤—ã—É—á–∏—Ç—å –Ω–µ–±–æ–ª—å—à–∏–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –≤ —ç—Ç–æ–º –Ω–µ–±–æ–ª—å—à–æ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ. –í —Å–ª—É—á–∞–µ —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –º—ã –∏–∑–±–µ–≥–∞–µ–º —ç—Ç–∏—Ö –ø—Ä–æ–±–ª–µ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ cGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ –º–æ–∂–Ω–æ –ø–æ–¥–∞–≤–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ —Å–ø–æ—Å–æ–±–æ–º, –æ–ø–∏—Å–∞–Ω–Ω—ã–º –≤—ã—à–µ. –ú–æ–∂–Ω–æ –≤–º–µ—Å—Ç–æ –ø–æ–¥–∞—á–∏ –∏—Ö –≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä —Å–¥–µ–ª–∞—Ç—å —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω –∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–ª ‚Äî **Semi-Supervised GAN**.\n",
    "\n",
    "–ò–ª–∏ –∂–µ –Ω–µ –ø–æ–¥–∞–≤–∞—Ç—å label –≤ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä, –Ω–æ –∂–¥–∞—Ç—å –æ—Ç –Ω–µ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –∫–ª–∞—Å—Å–æ–º, –∫–æ—Ç–æ—Ä—ã–π –º—ã —Ö–æ—Ç–∏–º –ø–æ–ª—É—á–∏—Ç—å –æ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ ‚Äî —ç—Ç–æ **InfoGAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—â—ë –æ–¥–Ω–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è cGAN ‚Äî —ç—Ç–æ **AC-GAN** (auxiliary classifier), –≤ –∫–æ—Ç–æ—Ä–æ–π –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞–∑–ª–∏—á–∏–µ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –¥–æ–ª–∂–µ–Ω –ø–æ–º–∏–º–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∏ —Ñ–µ–π–∫–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –µ—â—ë –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∏—Ö. –û–Ω –∏–º–µ–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∏–∑—É—á–∞—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤ —Å–∫—Ä—ã—Ç–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ, –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/gans_zoo_schemes.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –¢–æ–Ω–∫–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è GAN–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[–°—Ç–∞—Ç—å—è ‚Äî –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä —Ç–æ–Ω–∫–æ—Å—Ç–µ–π –∏ —Å–æ–≤–µ—Ç–æ–≤](https://beckham.nz/2021/06/28/training-gans.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ß–∞—Å—Ç—ã–µ/–ø—Ä–æ—Å—Ç—ã–µ –æ—à–∏–±–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã–µ —Å—ç–º–ø–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ —Ç–æ–º –∂–µ –¥–∏–∞–ø–∞–∑–æ–Ω–µ, —á—Ç–æ –∏ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.** –ù–∞–ø—Ä–∏–º–µ—Ä, —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ $[-1, \\dots, 1]$, –ø—Ä–∏ —ç—Ç–æ–º –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ $[0, \\dots, 1]$. –≠—Ç–æ –Ω–µ—Ö–æ—Ä–æ—à–æ, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –ø–æ–¥—Å–∫–∞–∑–∫–∞ –¥–ª—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞.\n",
    "* **–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—ç–º–ø–ª—ã —Ç–æ–≥–æ –∂–µ —Ä–∞–∑–º–µ—Ä–∞, —á—Ç–æ –∏ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.** –ù–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ MNIST $(28,28)$, –∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤—ã–¥–∞–µ—Ç $(32,32)$. –í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –Ω—É–∂–Ω–æ –ª–∏–±–æ –∏–∑–º–µ–Ω–∏—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∞—Ç—å –Ω–∞ –≤—ã—Ö–æ–¥–µ —Ä–∞–∑–º–µ—Ä $(28,28)$, –ª–∏–±–æ —Å–¥–µ–ª–∞—Ç—å —Ä–µ—Å–∞–π–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–æ $(32,32)$.\n",
    "* **–°—Ç–∞—Ä–∞–π—Ç–µ—Å—å –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `BatchNorm`**. –ü—Ä–æ–±–ª–µ–º–∞ `BN` –≤ —Ç–æ–º, —á—Ç–æ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –µ–≥–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø–æ –º–∏–Ω–∏–±–∞—Ç—á—É, –∞ –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –æ–Ω–∞ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∫–∞–∫ *moving average*, —á—Ç–æ –≤ —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å –º–æ–∂–µ—Ç –ø–æ–≤–ª–µ—á—å –Ω–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –ï—Å–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ GAN –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é, —Ç–æ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **`InstanceNorm`**.\n",
    "* **–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–≤–æ–∏ –ª–æ—Å—Å—ã –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è**. –î–ª—è —ç—Ç–æ–≥–æ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, TensorBoard). –°–ª–µ–¥–∏—Ç—å –∑–∞ –±–µ–≥—É—â–∏–º–∏ –ø–æ —ç–∫—Ä–∞–Ω—É —Ü–∏—Ñ—Ä–∞–º–∏ –æ—Ç –¥–≤—É—Ö —Å–æ—Ä–µ–≤–Ω—É—é—â–∏—Ö—Å—è –º–µ–∂–¥—É —Å–æ–±–æ–π –ª–æ—Å—Å–æ–≤ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω–æ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞—á–µ–º –¥–∞–≤–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä—É"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ –≤–∞—à–∞ –≤–µ—Ä—Å–∏—è **GAN** —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ —Ç–∞–∫ —Ö–æ—Ä–æ—à–æ, –∫–∞–∫ –≤–∞–º —Ö–æ—Ç–µ–ª–æ—Å—å –±—ã, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –¥–∞—Ç—å —Å–≤–æ–µ–º—É **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä—É** –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ, –æ–±—É—á–∏–≤ –µ–≥–æ –Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–µ–µ —á–∏—Å–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–π, —á–µ–º **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä**. –î—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, —á–µ–º –ª—É—á—à–µ **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä** —Ä–∞–∑–ª–∏—á–∞–µ—Ç –Ω–∞—Å—Ç–æ—è—â–∏–µ –∏ —Ñ–∞–ª—å—à–∏–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, —Ç–µ–º –ª—É—á—à–µ —Å–∏–≥–Ω–∞–ª, –∫–æ—Ç–æ—Ä—ã–π **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä** –º–æ–∂–µ—Ç –∏–∑–≤–ª–µ—á—å –∏–∑ –Ω–µ–≥–æ. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —ç—Ç–∞ –ª–æ–≥–∏–∫–∞ –Ω–µ –∏–º–µ–ª–∞ —Å–º—ã—Å–ª–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–∞ \"–¥–æ WGAN\", –ø–æ—Å–∫–æ–ª—å–∫—É —Å–ª–∏—à–∫–æ–º —Ö–æ—Ä–æ—à–∞—è —Ä–∞–±–æ—Ç–∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –≤—Ä–µ–¥–∏–ª–∞ –æ–±—É—á–µ–Ω–∏—é.\n",
    "\n",
    "–ù–∞–ø—Ä–∏–º–µ—Ä:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def train_on_batch(x, iter_, n_gen=5):\n",
    "     Generator:\n",
    "    ...\n",
    "    ...\n",
    "    if iter_ % n_gen == 0:\n",
    "        g_loss.backward()\n",
    "        opt_g.step()\n",
    "\n",
    "     Discriminator:\n",
    "    ...\n",
    "    ...\n",
    "    d_loss.backward()\n",
    "    d_loss.step()\n",
    "```\n",
    "\n",
    "–ì–¥–µ `iter_` ‚Äî —Ç–µ–∫—É—â–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è —à–∞–≥–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞, –∞ `n_gen` –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞. –í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω —Ä–∞–≤–µ–Ω 5, –º—ã –º–æ–∂–µ–º —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –≤ 5 —Ä–∞–∑ —á–∞—â–µ, —á–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä.\n",
    "\n",
    "–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ –≤—Å–µ–≥–¥–∞ –∏ –Ω–µ –≤–µ–∑–¥–µ. –ù–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å—Ç–æ–∏—Ç\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–∂–Ω–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –ø–æ—á—Ç–∏ –≤–æ –≤—Å–µ—Ö —Å—Ç–∞—Ç—å—è—Ö –ø–æ **GAN** –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **ADAM**. –°–ª–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å, –ø–æ—á–µ–º—É —Ç–∞–∫ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –Ω–æ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ. –ï—Å–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ –≤–∞—à–µ–≥–æ **GAN** –æ—Å—Ç–∞–≤–ª—è–µ—Ç –∂–µ–ª–∞—Ç—å –ª—É—á—à–µ–≥–æ, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Ç—É—Ç –Ω–µ –ø—Ä–∏ —á–µ–º. –ò—â–∏—Ç–µ –æ—à–∏–±–∫—É –≥–¥–µ-—Ç–æ –µ—â–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–∞—Ä–∞–º–µ—Ç—Ä `epsilon` **ADAM** –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ PyTorch —Ä–∞–≤–µ–Ω `1e-8`, —á—Ç–æ –º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã –ø–æ—Å–ª–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ –æ–±—É—á–µ–Ω–∏—è, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–Ω–∞—á–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –≤–∑—Ä—ã–≤–∞—é—Ç—Å—è –∏–ª–∏ —É–≤–µ–ª–∏—á–∏–≤–∞—é—Ç—Å—è. –ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ–± —ç—Ç–æ–º –Ω–∞ [StackOverflow](https://stackoverflow.com/questions/42327543/adam-optimizer-goes-haywire-after-200k-batches-training-loss-grows) –∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ [Reddit](https://www.reddit.com/r/reinforcementlearning/comments/j9rflf/intuitive_explanation_for_adams_epsilon_parameter/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–∞–∑–æ–≤–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è –ø–æ —Ç–µ–º–µ: [Denoising Diffusion Probabilistic Models (Ho et al., 2020) üéì[arxiv]](https://arxiv.org/abs/2006.11239)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä—è–º–æ–π –¥–∏—Ñ—Ñ—É–∑–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—É—Å—Ç—å –º—ã –∏–º–µ–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–π –æ–±—ä–µ–∫—Ç $\\mathbf{x}_0$ –∏–∑ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –∏–º–µ—é—â–∏–º—Å—è –¥–∞—Ç–∞—Å–µ—Ç–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è $\\mathbf{x}_0 \\sim q(\\mathbf{x})$. –û–ø—Ä–µ–¥–µ–ª–∏–º —Ç–∞–∫ –Ω–∞–∑—ã–≤–∞–µ–º—ã–π –ø—Ä—è–º–æ–π –¥–∏—Ñ—Ñ—É–∑–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, –≤ —Ö–æ–¥–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã –±—É–¥–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–µ–±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ì–∞—É—Å—Å–æ–≤–æ–≥–æ —à—É–º–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ $T$ —Ä–∞–∑, —Å–æ–∑–¥–∞–≤–∞—è –∏–∑ –Ω–∞—à–µ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å $\\mathbf{x}_1, \\dots, \\mathbf{x}_T$ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –≤—Å—ë –±–æ–ª–µ–µ –∑–∞—à—É–º–ª–µ–Ω–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –Ω–∞—à–µ–≥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–±–∞–≤–ª—è–µ–º–æ–≥–æ —à—É–º–∞ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –Ω–æ–º–µ—Ä–∞ —à–∞–≥–∞ –∑–∞—à—É–º–ª–µ–Ω–∏—è –∏ –∏—Ö –Ω–∞–±–æ—Ä $\\{\\beta_t \\in (0, 1)\\}_{t=1}^T$ –∑–∞–¥–∞–Ω –∑–∞—Ä–∞–Ω–µ–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/diffusion_process.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å—Ö–æ–¥–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –±—É–¥–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ –≤ –ì–∞—É—Å—Å–æ–≤ —à—É–º:\n",
    "\n",
    "$$\\large q(\\mathbf{x}_t \\vert \\mathbf{x}_{t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}, \\beta_t\\mathbf{I}) \\quad\n",
    "q(\\mathbf{x}_{1:T} \\vert \\mathbf{x}_0) = \\prod^T_{t=1} q(\\mathbf{x}_t \\vert \\mathbf{x}_{t-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∞–∂–Ω—ã–º —Å–≤–æ–π—Å—Ç–≤–æ–º –æ–ø–∏—Å–∞–Ω–Ω–æ–≥–æ –≤—ã—à–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ —è–≤–ª—è–µ—Ç—Å—è —Ç–æ, —á—Ç–æ –æ–Ω –¥–æ–ø—É—Å–∫–∞–µ—Ç –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —à—É–º–∞ –Ω–∞ –ª—é–±–æ–º –∏–∑ —à–∞–≥–æ–≤ –ø—Ä–æ—Ü–µ—Å—Å–∞ –≤ —è–≤–Ω–æ–º –≤–∏–¥–µ. –≠—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º, —á—Ç–æ —Å—É–º–º–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö –≤–µ–ª–∏—á–∏–Ω —Ç–∞–∫–∂–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ–π –≤–µ–ª–∏—á–∏–Ω–æ–π —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º. –í–≤–µ–¥—ë–º –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–∏ $\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i$ –∏ $\\alpha_t = 1 - \\beta_t$. –¢–æ–≥–¥–∞:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large\n",
    "\\begin{aligned}\n",
    "\\mathbf{x}_t\n",
    "&= \\sqrt{\\alpha_t}\\mathbf{x}_{t-1} + \\sqrt{1 - \\alpha_t}\\boldsymbol{\\epsilon}_{t-1} \\\\\n",
    "&= \\sqrt{\\alpha_t \\alpha_{t-1}} \\mathbf{x}_{t-2} + \\sqrt{1 - \\alpha_t \\alpha_{t-1}} \\bar{\\boldsymbol{\\epsilon}}_{t-2} \\\\\n",
    "&= \\dots \\\\\n",
    "&= \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon} \\\\\n",
    "\\end{aligned} $$\n",
    "\n",
    "$$ \\large\n",
    "\\begin{aligned}\n",
    "q(\\mathbf{x}_t \\vert \\mathbf{x}_0) &= \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1 - \\bar{\\alpha}_t)\\mathbf{I})\n",
    "\\end{aligned}; $$\n",
    "\n",
    "$\\large \\text{–≥–¥–µ } \\boldsymbol{\\epsilon}_{t-1}, \\boldsymbol{\\epsilon}_{t-2}, \\dots \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}),$\n",
    "\n",
    "$\\large \\qquad \\bar{\\boldsymbol{\\epsilon}}_{t-2} \\text{ ‚Äì –Ω–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞ (*)}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(*)  –ù–∞–ø–æ–º–Ω–∏–º, —á—Ç–æ –∫–æ–≥–¥–∞ –º—ã —Å–∫–ª–∞–¥—ã–≤–∞–µ–º –¥–≤–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≤–µ–ª–∏—á–∏–Ω—ã —Å —Ä–∞–∑–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π –∏ –Ω—É–ª–µ–≤—ã–º —Å—Ä–µ–¥–Ω–∏–º $\\mathcal{N}(\\mathbf{0}, \\sigma_1^2\\mathbf{I})$ –∏ $\\mathcal{N}(\\mathbf{0}, \\sigma_2^2\\mathbf{I})$,—Ç–æ –ø–æ–ª—É—á–∞–µ–º –Ω–æ–≤—É—é –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é —Å–ª—É—á–∞–π–Ω—É—é –≤–µ–ª–∏—á–∏–Ω—É $\\mathcal{N}(\\mathbf{0}, (\\sigma_1^2 + \\sigma_2^2)\\mathbf{I})$, —á—Ç–æ –≤ –Ω–∞—à–µ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏–∏ –æ–∑–Ω–∞—á–∞–µ—Ç $\\sqrt{(1 - \\alpha_t) + \\alpha_t (1-\\alpha_{t-1})} = \\sqrt{1 - \\alpha_t\\alpha_{t-1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—Ä–∞—Ç–Ω—ã–π –¥–∏—Ñ—Ñ—É–∑–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large p_\\theta(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod^T_{t=1} p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) \\quad\n",
    "p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t), \\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/diffusion_example.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models\">Lilian Weng: What are Diffusion Models?</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/resnet_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, mid_features=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_features:\n",
    "            mid_features = out_features\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_features, mid_features, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, mid_features),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_features, out_features, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            return F.gelu(x + self.conv_stack(x))\n",
    "        else:\n",
    "            return self.conv_stack(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/down_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/upblock.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class ResizeBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, emb_dim):\n",
    "        super().__init__()\n",
    "        # defines non-linear map from time embedding features to conv features\n",
    "        self.emb_projection = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(emb_dim, out_features),\n",
    "        )\n",
    "\n",
    "    def add_emb(self, x, t_vector):\n",
    "        # [batch_size, time_embedding_dim] -> [batch_size, out_features]\n",
    "        emb = self.emb_projection(t_vector)\n",
    "        # [batch_size, out_features] - > [batch_size, out_features, H, W]\n",
    "        emb = emb[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Down(ResizeBlock):\n",
    "    def __init__(self, in_features, out_features, emb_dim=256):\n",
    "        super().__init__(in_features, out_features, emb_dim)\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            ResNetBlock(in_features, in_features, residual=True),\n",
    "            ResNetBlock(in_features, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.maxpool_conv(x)\n",
    "        x = self.add_emb(x, t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Up(ResizeBlock):\n",
    "    def __init__(self, in_features, out_features, emb_dim=256):\n",
    "        super().__init__(in_features, out_features, emb_dim)\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.conv = nn.Sequential(\n",
    "            ResNetBlock(in_features, in_features, residual=True),\n",
    "            ResNetBlock(in_features, out_features, in_features // 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip_x, t):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([skip_x, x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.add_emb(x, t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/out/se_block.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, channels, size):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.size = size\n",
    "        self.mha = nn.MultiheadAttention(channels, num_heads=4, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [batch_size, C, H, W] -> [batch_size, H*W, C]\n",
    "        x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)\n",
    "        x_ln = self.ln(x)\n",
    "        # K, Q, V in Self attention are equal\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        # skip connection\n",
    "        attention_value = attention_value + x\n",
    "        # simple multilayer perceptron and second skip connection\n",
    "        attention_value = self.mlp(attention_value) + attention_value\n",
    "        # back to [batch_size, C, H, W]\n",
    "        return attention_value.swapaxes(2, 1).view(\n",
    "            -1, self.channels, self.size, self.size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    r\"\"\"\n",
    "    Denoising U-Net model implementation based on arXiv:2006.11239 [cs.LG]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_channels=3, img_size=64, time_enbed_dim=256):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.time_dim = time_enbed_dim\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # Downsample and enlarge feature dim\n",
    "        self.inc = ResNetBlock(num_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.sa1 = SelfAttention(128, img_size // 2)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.sa2 = SelfAttention(256, img_size // 4)\n",
    "        self.down3 = Down(256, 256)\n",
    "        self.sa3 = SelfAttention(256, img_size // 8)\n",
    "\n",
    "        # Keep spatial dim constant\n",
    "        self.conv_bottleneck = nn.Sequential(\n",
    "            ResNetBlock(256, 512),\n",
    "            SelfAttention(512, img_size // 8),\n",
    "            ResNetBlock(512, 256),\n",
    "        )\n",
    "\n",
    "        # Upsample and reduce feature dim\n",
    "        # 512=256+256 from conv_bottleneck and sa3\n",
    "        self.up1 = Up(512, 128)\n",
    "        self.sa4 = SelfAttention(128, img_size // 4)\n",
    "        # 256=128+128 from sa4 and sa2\n",
    "        self.up2 = Up(256, 64)\n",
    "        self.sa5 = SelfAttention(64, img_size // 2)\n",
    "        # 128=64+64 from sa5 and sa1\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.sa6 = SelfAttention(64, img_size)\n",
    "        self.outc = nn.Conv2d(64, num_channels, kernel_size=1)\n",
    "\n",
    "    def pos_encoding(self, t):\n",
    "        r\"\"\"\n",
    "        Returns embedding vector for given integer time index.\n",
    "\n",
    "        We adopt 1d Positional Encoding form arXiv:1706.03762 [cs.CL]\n",
    "        see 3.5 for more details.\n",
    "\n",
    "        PE(x,2i) = sin(x/10000^(2i/D))\n",
    "        PE(x,2i+1) = cos(x/10000^(2i/D))\n",
    "\n",
    "        Where:\n",
    "        x is a point in 1d space\n",
    "        i is an integer in [0, D/2), where D is the size of the feature dimension\n",
    "\n",
    "        Args:\n",
    "            t: Tensor, shape ``[batch_size, 1]``\n",
    "        Returns:\n",
    "            pe: Tensor, shape ``[batch_size, time_embedding_dim]``\n",
    "        \"\"\"\n",
    "\n",
    "        # placeholder for diffusion time encoding vector\n",
    "        pe = torch.zeros(t.shape[0], self.time_dim).to(t)\n",
    "\n",
    "        # factor 1/10000^(2i/D)\n",
    "        div_factors = torch.exp(\n",
    "            torch.arange(0, self.time_dim, 2)\n",
    "            * (-torch.log(torch.as_tensor(10000.0)) / self.time_dim)\n",
    "        ).to(t)\n",
    "\n",
    "        # repeat t index for each feature\n",
    "        x = t.repeat(1, self.time_dim // 2)\n",
    "\n",
    "        # sin(x/10000^(2i/D)) for even features\n",
    "        pe[:, 0::2] = torch.sin(x * div_factors)\n",
    "        # cos(x/10000^(2i/D)) for odd features\n",
    "        pe[:, 1::2] = torch.cos(x * div_factors)\n",
    "\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = t.unsqueeze(-1).type(torch.float).to(x)\n",
    "        t = self.pos_encoding(t)\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1, t)\n",
    "        x2 = self.sa1(x2)\n",
    "        x3 = self.down2(x2, t)\n",
    "        x3 = self.sa2(x3)\n",
    "        x4 = self.down3(x3, t)\n",
    "        x4 = self.sa3(x4)\n",
    "\n",
    "        x4 = self.conv_bottleneck(x4)\n",
    "\n",
    "        x = self.up1(x4, x3, t)\n",
    "        x = self.sa4(x)\n",
    "        x = self.up2(x, x2, t)\n",
    "        x = self.sa5(x)\n",
    "        x = self.up3(x, x1, t)\n",
    "        x = self.sa6(x)\n",
    "        output = self.outc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä—è–º–æ–≥–æ –∏ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –¥–∏—Ñ—Ñ—É–∑–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class DiffusionGenerativeModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        model_name=\"unconditioned_baseline\",\n",
    "        num_noise_steps=1000,\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.02,\n",
    "        img_size=64,\n",
    "        denoising_model_class=UNet,\n",
    "        batch_size=2,\n",
    "        lr=0.001,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        self.num_noise_steps = num_noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "\n",
    "        # diffusion process linear noise schedule\n",
    "        self.beta = self._get_noise_schedule().to(self.device)\n",
    "        self.alpha = 1.0 - self.beta\n",
    "        # \\hat{\\alpha}_{i-1} = \\prod_{j=0}^{i-1} \\alpha_j\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "        # init denoising model\n",
    "        self.denoising_model = denoising_model_class(img_size=img_size).to(self.device)\n",
    "\n",
    "        # init dataset and dataloader\n",
    "        self.dataset = dataset\n",
    "        self.dl = torch.utils.data.DataLoader(\n",
    "            self.dataset, batch_size=self.batch_size, shuffle=True, drop_last=True\n",
    "        )\n",
    "\n",
    "        # init optimizer and loss for training\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = AdamW(self.denoising_model.parameters(), lr=self.lr)\n",
    "\n",
    "    def _load_pretrained_model(self, path=None):\n",
    "        if path is not None:\n",
    "            self.denoising_model.load_state_dict(\n",
    "                torch.load(path, map_location=self.device)\n",
    "            )\n",
    "        else:\n",
    "            self.denoising_model.load_state_dict(\n",
    "                torch.load(f\"{self.model_name}.pt\", map_location=self.device)\n",
    "            )\n",
    "\n",
    "    def _get_noise_schedule(self):\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.num_noise_steps)\n",
    "\n",
    "    def _noise_images_batch(self, x, t):\n",
    "        # \\mu_i = \\sqrt{\\hat{\\alpha}_i}\n",
    "        mu = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        # \\sigma_i = \\sqrt{1 - \\hat{\\alpha}_i}\n",
    "        sigma = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "\n",
    "        standard_normal_noise = torch.randn_like(x)\n",
    "        noised_image_batch = mu * x + sigma * standard_normal_noise\n",
    "        return noised_image_batch, standard_normal_noise\n",
    "\n",
    "    def _get_timestams_batch(self):\n",
    "        return torch.randint(low=1, high=self.num_noise_steps, size=(self.batch_size,))\n",
    "\n",
    "    def generate_images_batch(self, use_best_model=False):\n",
    "        if use_best_model:\n",
    "            self.denoising_model.load_state_dict(\n",
    "                torch.load(f\"{self.model_name}.pt\", map_location=self.device)\n",
    "            )\n",
    "\n",
    "        # stop tracking normalisation stats\n",
    "        self.denoising_model.eval()\n",
    "\n",
    "        # avoid training on generated samples\n",
    "        with torch.no_grad():\n",
    "            # start from pure noise batch\n",
    "            x = torch.randn((self.batch_size, 3, self.img_size, self.img_size)).to(\n",
    "                self.device\n",
    "            )\n",
    "            # and apply self.num_noise_steps denoising steps with model\n",
    "            for t_i in tqdm(reversed(range(1, self.num_noise_steps)), position=0):\n",
    "                # Build tensor with timestamp index. Same for each element in batch\n",
    "                t = torch.full((self.batch_size,), t_i).long().to(self.device)\n",
    "\n",
    "                # predict noise on current timestamp\n",
    "                pred_noise = self.denoising_model(x, t)\n",
    "\n",
    "                # restore noise parametrs on current timestamp\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "\n",
    "                # partialy denoise batch of images\n",
    "                x = x - (1.0 - alpha) / (1 - alpha_hat).sqrt() * pred_noise\n",
    "                x = (1 / alpha.sqrt()) * x\n",
    "\n",
    "                # add appropriate amount of noise for next step if any\n",
    "                if t_i > 0:\n",
    "                    z = torch.randn_like(x).to(self.device)\n",
    "                    x = x + beta.sqrt() * z\n",
    "\n",
    "        # clip x to valid 0..255 image range\n",
    "        x = (x.clamp(-1, 1) + 1) / 2\n",
    "        x = (x * 255).type(torch.uint8)\n",
    "\n",
    "        # reenable tracking normalisation stats\n",
    "        self.denoising_model.train()\n",
    "        return x\n",
    "\n",
    "    def _train_step(self, batch):\n",
    "        # unpack data\n",
    "        images, labels = batch\n",
    "        t = self._get_timestams_batch()\n",
    "\n",
    "        # send tensors to device\n",
    "        images = images.to(self.device)\n",
    "        t = t.to(self.device)\n",
    "\n",
    "        # prep batch of noised images\n",
    "        noised_images, target_noise = self._noise_images_batch(images, t)\n",
    "\n",
    "        # estimate noise with U-Net\n",
    "        predicted_noise = self.denoising_model(noised_images, t)\n",
    "\n",
    "        # optimize model to fit target noise\n",
    "        loss = self.criterion(predicted_noise, target_noise)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def fit(self, n_epochs=20, save_images=True):\n",
    "        best_loss = float(\"inf\")\n",
    "        for epoch in tqdm(range(n_epochs), position=1):\n",
    "            ep_loss = 0.0\n",
    "            with tqdm(total=len(self.dl), position=2) as progress_bar:\n",
    "                for batch in self.dl:\n",
    "                    loss_step = self._train_step(batch)\n",
    "                    # loss per single object\n",
    "                    loss_step = loss_step / len(self.dl) * self.batch_size\n",
    "                    ep_loss += loss_step\n",
    "\n",
    "                    progress_bar.update(1)\n",
    "            log_string = f\"Loss at epoch {epoch + 1}: {ep_loss:.3f}\"\n",
    "\n",
    "            if best_loss > ep_loss:\n",
    "                best_loss = ep_loss\n",
    "                torch.save(self.denoising_model.state_dict(), f\"{self.model_name}.pt\")\n",
    "                log_string += \" || Best model updated\"\n",
    "\n",
    "                # Save images generated at this epoch\n",
    "                if save_images:\n",
    "                    generated_images = self.generate_images_batch()\n",
    "                    image_grid = make_grid(generated_images)\n",
    "                    # convert to numpy\n",
    "                    ndarr = image_grid.permute(1, 2, 0).to(\"cpu\").numpy()\n",
    "                    # and save\n",
    "                    im = Image.fromarray(ndarr)\n",
    "                    im.save(f\"{self.model_name}_{epoch}.jpg\")\n",
    "\n",
    "            print(log_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ –¥–∏—Ñ—Ñ—É–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q astronn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–ø–µ—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –≤—ã—à–µ –¥–∏—Ñ—Ñ—É–∑–Ω–æ–π –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ Galaxy10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L13/galaxy10sdss_example.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ü—Ä–∏–º–µ—Ä—ã –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ Galaxy10</a></em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://github.com/henrysky/Galaxy10\">Galaxy10 DECals Dataset</a></em></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroNN.datasets import load_galaxy10\n",
    "\n",
    "images, labels = load_galaxy10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform):\n",
    "        super().__init__()\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, indx):\n",
    "        image = self.images[indx]\n",
    "        label = self.labels[indx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(64, antialias=True),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomVerticalFlip(0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = GalaxyDataset(images, labels, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm = DiffusionGenerativeModel(dataset, device=\"cuda\", batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ —Å–µ—Ç–∏ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º. –ü—Ä–æ–ø—É—Å—Ç–∏–º —ç—Ç–æ—Ç —ç—Ç–∞–ø, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–Ω–∏–º–∞–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddpm.fit(n_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = ddpm.generate_images_batch()\n",
    "image_grid = make_grid(generated_images)\n",
    "# convert to numpy\n",
    "ndarr = image_grid.permute(1, 2, 0).to(\"cpu\").numpy()\n",
    "# and show\n",
    "Image.fromarray(ndarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–¥–∏–º, —á—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π —à—É–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –≤–µ—Å–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -q https://edunet.kea.su/repo/EduNet-content/dev-2.0/L13/weights/unconditioned_baseline.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm._load_pretrained_model(\"unconditioned_baseline.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = ddpm.generate_images_batch()\n",
    "image_grid = make_grid(generated_images)\n",
    "# convert to numpy\n",
    "ndarr = image_grid.permute(1, 2, 0).to(\"cpu\").numpy()\n",
    "# and show\n",
    "Image.fromarray(ndarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞</font>\n",
    "\n",
    "<font size=\"5\">GAN</font>\n",
    "\n",
    "[[book] üìö ¬´–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ. –¢–≤–æ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π¬ª](https://habr.com/ru/company/piter/blog/504956/)\n",
    "\n",
    "[[arxiv] üéì Generative Adversarial Networks (Goodfellow et al., 2014)](https://arxiv.org/abs/1406.2661)\n",
    "\n",
    "[[video] üì∫ –†–∞–∑–±–æ—Ä –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–∏ GAN](https://www.youtube.com/watch?v=eyxmSmjmNS0)\n",
    "\n",
    "[[video] üì∫ –õ–µ–∫—Ü–∏—è –ò–∞–Ω–∞ –ì—É–¥—Ñ–µ–ª–ª–æ—É](https://www.youtube.com/watch?v=HGYYEUSm-0Q)\n",
    "\n",
    "[Generative adversarial networks](https://deepgenerativemodels.github.io/notes/gan/)\n",
    "\n",
    "[–°–∞–º—ã–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏](https://paperswithcode.com/methods/category/generative-models)\n",
    "\n",
    "[exactly how the NVIDIA GauGAN neural network works](https://sudonull.com/post/29972-Pictures-from-rough-sketches-how-exactly-the-NVIDIA-GauGAN-neural-network-works-ITSumma-Blog)\n",
    "\n",
    "<font size=\"5\">DCGAN</font>\n",
    "\n",
    "[[arxiv] üéì Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (Radford et al., 2015)](https://arxiv.org/abs/1511.06434).\n",
    "\n",
    "[DCGAN TUTORIAL](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)\n",
    "\n",
    "<font size=\"5\">Wasserstein GAN</font>\n",
    "\n",
    "[[arxiv] üéì Wasserstein GAN (Arjovsky et. al., 2017)](https://arxiv.org/abs/1701.07875)\n",
    "\n",
    "[–ë–ª–æ–≥ –ø–æ—Å—Ç –æ Wasserstein GAN](https://vincentherrmann.github.io/blog/wasserstein/)\n",
    "\n",
    "[[arxiv] üéì Improved Training of Wasserstein GANs (Gulrajani et al., 2017)](https://arxiv.org/abs/1704.00028)\n",
    "\n",
    "[[arxiv] üéì Spectral Normalization for Generative Adversarial Networks (Miyato et al., 2018)](https://arxiv.org/abs/1802.05957).\n",
    "\n",
    "<font size=\"5\">ProGAN -> StyleGAN -> StyleGAN2 -> Alias-Free GAN</font>\n",
    "\n",
    "[[arxiv] üéì Progressive Growing of GANs for Improved Quality, Stability, and Variation (ProGAN) (Karras et al., 2017)](https://arxiv.org/abs/1710.10196)\n",
    "\n",
    "[[arxiv] üéì A Style-Based Generator Architecture for Generative Adversarial Networks (StyleGAN) (Karras et al., 2018)](https://arxiv.org/abs/1812.04948)\n",
    "\n",
    "[[arxiv] üéì Analyzing and Improving the Image Quality of StyleGAN (StyleGAN2) (Karras et al., 2019)](https://arxiv.org/abs/1912.04958)\n",
    "\n",
    "[[arxiv] üéì Alias-Free Generative Adversarial Networks (Alias-Free GAN) (Karras et al., 2021)](https://arxiv.org/abs/2106.12423)\n",
    "\n",
    "<font size=\"5\">–¢–æ–Ω–∫–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è GAN</font>\n",
    "\n",
    "[[blog] ‚úèÔ∏è –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä —Ç–æ–Ω–∫–æ—Å—Ç–µ–π –∏ —Å–æ–≤–µ—Ç–æ–≤](https://beckham.nz/2021/06/28/training-gans.html)\n",
    "\n",
    "[[arxiv] üéì Top-k Training of GANs: Improving GAN Performance by Throwing Away Bad Samples (Sinha et al., 2020)](https://arxiv.org/abs/2002.06224)\n",
    "\n",
    "<font size=\"5\">GAN Zoo:</font>\n",
    "\n",
    "<font size=\"5\">BigGAN</font>\n",
    "\n",
    "[[arxiv] üéì Large Scale GAN Training for High Fidelity Natural Image Synthesis (Brock et al., 2018)](https://arxiv.org/abs/1809.11096)\n",
    "\n",
    "<font size=\"5\">StackGAN</font>\n",
    "\n",
    "[StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks (Zhang et al., 2016)](https://arxiv.org/abs/1612.03242)\n",
    "\n",
    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: [—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∫ —Å—Ç–∞—Ç—å–µ —Å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤](https://github.com/hanzhanggit/StackGAN).\n",
    "\n",
    "[[arxiv] üéì StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks (Zhang et al., 2017)](https://arxiv.org/abs/1710.10916)\n",
    "\n",
    "[[arxiv] üéì Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (Ledig et al., 2016)](https://arxiv.org/abs/1609.04802)\n",
    "\n",
    "[Deep Learning Generative Models for Image Synthesis and Image Translation](https://www.rulit.me/data/programs/resources/pdf/Generative-Adversarial-Networks-with-Python_RuLit_Me_610886.pdf)\n",
    "\n",
    "[[video] üì∫ StackGAN++ Realistic Image Synthesis with Stacked Generative Adversarial Networks | AISC](https://www.youtube.com/watch?v=PXWIaLE7_NU)\n",
    "\n",
    "[[video] üì∫ Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks](https://www.youtube.com/watch?v=crI5K4RCZws)\n",
    "\n",
    "<font size=\"5\">ControlGAN</font>\n",
    "\n",
    "[[arxiv] üéì Controllable Generative Adversarial Network](https://arxiv.org/pdf/1708.00598.pdf)\n",
    "\n",
    "[[arxiv] üéì Controllable Text-to-Image Generation](https://arxiv.org/pdf/1909.07083.pdf)\n",
    "\n",
    "[[arxiv] üéì Image Generation and Recognition (Emotions)](https://arxiv.org/pdf/1910.05774.pdf)\n",
    "\n",
    "[Natural Language & Text-to-Image 2019](https://meta-guide.com/data/data-processing/text-to-image-systems/natural-language-text-to-image-2019)\n",
    "\n",
    "<font size=\"5\">AC-GAN</font>\n",
    "\n",
    "[How to Develop an Auxiliary Classifier GAN (AC-GAN) From Scratch with Keras](https://machinelearningmastery.com/how-to-develop-an-auxiliary-classifier-gan-ac-gan-from-scratch-with-keras/)\n",
    "\n",
    "Conditional Image Synthesis with Auxiliary Classifier GANs: [—Å—Ç–∞—Ç—å—è](https://arxiv.org/pdf/1610.09585.pdf), [—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π](https://github.com/clvrai/ACGAN-PyTorch)\n",
    "\n",
    "[[arxiv] üéì An Auxiliary Classifier Generative Adversarial Framework for Relation Extraction (Zhao, 2019)](https://arxiv.org/pdf/1909.05370.pdf)\n",
    "\n",
    "[A Multi-Class Hinge Loss for Conditional GANs](https://openaccess.thecvf.com/content/WACV2021/papers/Kavalerov_A_Multi-Class_Hinge_Loss_for_Conditional_GANs_WACV_2021_paper.pdf)\n",
    "\n",
    "<font size=\"5\">Domain Transfer Network</font>\n",
    "\n",
    "[[arxiv] üéì Unsupervised Cross-Domain Image Generation (Taigma et al., 2016)](https://arxiv.org/abs/1611.02200)\n",
    "\n",
    "<font size=\"5\">Pix2Pix</font>\n",
    "\n",
    "[[arxiv] üéì Image-to-Image Translation with Conditional Adversarial Networks (Isola et al., 2016)](https://arxiv.org/abs/1611.07004)\n",
    "\n",
    "<font size=\"5\">–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è</font>\n",
    "\n",
    "[[arxiv] üéì Learning to Generate Chairs, Tables and Cars\n",
    "with Convolutional Networks (Dosovitskiy et al., 2017)](https://arxiv.org/abs/1411.5928)\n",
    "\n",
    "<font size=\"5\">Text to image</font>\n",
    "\n",
    "[[arxiv] üéì Text-to-Image Generation with Attention Based Recurrent Neural Networks (Zia et al., 2020)](https://arxiv.org/abs/2001.06658)\n",
    "\n",
    "<font size=\"5\">Image-to-Image</font>\n",
    "\n",
    "[[arxiv] üéì GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (Chong et al., 2021)](https://arxiv.org/abs/2106.06561)\n",
    "\n",
    "[[arxiv] üéì Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (Zhu et al., 2017)](https://arxiv.org/abs/1703.10593)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">–°—Å—ã–ª–∫–∏</font>\n",
    "\n",
    "[[git] üêæ MNIST CelebA cGAN cDCGAN](https://github.com/znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN)\n",
    "\n",
    "[[git] üêæ Text-to-Photo realistic Image Synthesis with Stacked Generative Adversarial Networks](https://github.com/zeusm9/Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks)\n",
    "\n",
    "[[git] üêæ ControlGAN](https://github.com/mrlibw/ControlGAN)\n",
    "\n",
    "[[git] üêæ ControlGAN-Tensorflow](https://github.com/taki0112/ControlGAN-Tensorflow)\n",
    "\n",
    "[[git] üêæ Keras-ACGan](https://github.com/lukedeo/keras-acgan)\n",
    "\n",
    "[–ú–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤](https://thisxdoesnotexist.com)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
