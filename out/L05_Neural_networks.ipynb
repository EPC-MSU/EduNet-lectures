{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=\"6\">Нейронные сети</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ограничения линейных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним материал лекции №2, на которой мы разбирали линейные модели. Напомним, что выход линейной модели является линейной комбинацией входных признаков, к которой также добавляется смещение:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large\n",
    "\\begin{eqnarray*}\n",
    "y & = & w_1 x_1+ w_2 x_2 + ... + w_n x_n + b\\\\\n",
    "& = & \\sum_{i=1}^n x_i w_i + b \\\\\n",
    "& = & (\\vec{x}, \\vec{w}) + b\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данную формулу можно графически представить следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/one_neuron_linear_model.png\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если линейная модель имеет множество выходов, то каждый выход $\\large y_j$ имеет свой собственный вектор весов $\\large \\vec{w_j}$ и свое смещение $\\large b_j$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large y_j = (\\vec{x}, \\vec{w_j}) + b_j \\ \\ \\ \\ \\ \\ \\ j= 1 ... C,$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "где $\\large \\vec{w_j}=[w_{1j}, w_{2j}, ... w_{nj}]^\\top$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда выход всей модели можно записать в векторно-матричном виде:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\underset{[1 \\times C]}{\\vec{y}} = \\underset{[1 \\times n]}{x} \\underset{[n \\times C]}{W} + \\underset{[1 \\times C]}{\\vec{b}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь матрица весовых коэффициентов $\\large W$ образуется путем объединения векторов весовых коэффициентов для каждого выхода, а вектор смещений $\\large \\vec{b}$ — соответственно путем объединения смещений всех выходов:\n",
    "\n",
    "$$ \\large\n",
    "\\begin{eqnarray*}\n",
    "W & = & [\\vec{w_1}, \\vec{w_2}, ... \\vec{w_C}]\\\\\n",
    "\\vec{b} & = & [b_1, b_2, ... b_c]\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Графически это можно представить следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/linear_classifier.png\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим линейный классификатор, обученный на датасетах MNIST и CIFAR-10:\n",
    "\n",
    "- Функция потерь: Cross-Entropy Loss\n",
    "- Метод обучения: стохастический градиентный спуск\n",
    "- Оценка точности линейного классификатора на MNIST: $\\approx 0.85$, на CIFAR-10: $\\approx 0.38$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В линейном классификаторе каждый выход модели отвечает за свой класс. Мы можем надеяться, что в процессе обучения линейного классификатора весовые вектора разных выходов выучат некий обобщенный \"шаблон\" образцов данного класса. Тогда при подаче на вход нового образца один из шаблонов будет \"подходить\" больше других, и соответствующий выход будет получать **наибольшее значение взвешенной суммы**. Номер выхода, который имеет наибольшее значение взвешенной суммы, будет восприниматься как предсказанный класс.\n",
    "\n",
    "Визуализируем шаблоны (векторы весовых коэффициентов), получающиеся в результате обучения линейного классификатора на датасете MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/linear_classifier_mnist.png\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый пример рукописной цифры в MNIST представляет собой изображение размером $28×28$ пикселей в оттенках серого. Входные примеры представляются в виде векторов из $n=784$ компонент. Соответственно, каждый вектор весовых коэффициентов имеет такое же число компонент, и каждый такой вектор мы можем обратно перевести в матрицу $[28×28]$ и отобразить как изображение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qN https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L05/lc_mnist_weights.txt\n",
    "!wget -qN https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L05/lc_cifar10_weights.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display templates\n",
    "plt.rcParams[\"figure.figsize\"] = (25, 10)\n",
    "\n",
    "W = np.loadtxt(\"lc_mnist_weights.txt\")  # load weigths, shape (785, 10)\n",
    "print(f\"Shape with bias: {W.shape}\")\n",
    "\n",
    "# Remove bias\n",
    "W = W[:-1, :]\n",
    "print(f\"Shape without bias: {W.shape}\")\n",
    "\n",
    "# Normalize\n",
    "w_min, w_max = np.min(W), np.max(W)\n",
    "templates = 255 * (W - w_min) / (w_max - w_min)\n",
    "\n",
    "# Display templates\n",
    "labels_names = [str(i) for i in range(10)]\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    img = templates[:, i].reshape(28, 28).astype(int)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(labels_names[i], size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуально заметно, что шаблоны цифр в какой-то мере несут в себе образы соответствующих цифр.\n",
    "\n",
    "Таким же образом мы можем отобразить шаблоны линейного классификатора для датасета CIFAR-10 с надеждой, что мы так же сможем увидеть в шаблонах обобщенную \"лошадь\" или \"кота\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/linear_classifier_cifar.png\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display templates\n",
    "plt.rcParams[\"figure.figsize\"] = (25, 10)\n",
    "\n",
    "W = np.loadtxt(\"lc_cifar10_weights.txt\")  # load weigths, shape (3073, 10)\n",
    "print(f\"Shape with bias: {W.shape}\")\n",
    "\n",
    "# Remove bias\n",
    "W = W[:-1, :]\n",
    "print(f\"Shape without bias: {W.shape}\")\n",
    "\n",
    "# Normalize\n",
    "w_min, w_max = np.min(W), np.max(W)\n",
    "templates = 255 * (W - w_min) / (w_max - w_min)\n",
    "\n",
    "# Display templates\n",
    "labels_names = [\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    img = templates[:, i].reshape(3, 32, 32).transpose(1, 2, 0).astype(int)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(labels_names[i], size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для датасета CIFAR-10 уже гораздо сложнее визуально проследить схожесть выученных шаблонов с входными изображениями.\n",
    "\n",
    "Качественное отличие датасетов MNIST и CIFAR-10 заключается в том, что в CIFAR-10 выше **внутриклассовая вариативность**. Это значит, что изображения внутри каждого класса могут достаточно сильно различаться. Лошадь может стоять головой направо или налево, на фоне леса или на фоне поля, и т. д. В датасете MNIST внутриклассовая вариативность гораздо ниже: все цифры отцентрированы, и изображения одной и той же цифры в среднем гораздо больше похожи друг на друга.\n",
    "\n",
    "Ограничение линейного классификатора состоит в том, что для каждого класса существует только один шаблон. Шаблон каждого класса будет пытаться вобрать в себя информацию обо всех объектах класса сразу (например, на получившихся шаблонах для CIFAR-10 у лошади две головы, машина красная и т. д.). Сильная внутриклассовая вариативность будет мешать линейному классификатору запоминать разные варианты объектов одного класса, и это ограничивает точность модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проблемы классификации более сложных объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Человек узнает на изображении кошку или любой другой объект, руководствуясь целостным представлением о данном объекте на изображении. Такое целостное интуитивное представление об объектах для компьютера напрямую недоступно. С точки зрения компьютера, изображение представляет собой не более чем таблицу из чисел, кодирующих цвета всех его пикселей. Небольшое цветное изображение (с тремя  цветовыми каналами: красным, зеленым и синим) в разрешении $32 \\times 32$ для компьютера представлено просто упорядоченным набором из $32 \\times 32 \\times 3 = 3072 $ целых чисел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Легко себе представить ситуацию, в которой изображения одного и того же объекта будут значительно отличаться. Так, например, один и тот же кот может быть представлен на фотографии в различных позах, фотографии могут отличаться условиями освещения, яркостью или контрастностью. Кроме того, на одной из фотографий может быть изображен только фрагмент объекта — скажем, только хвост. Все эти факторы не являются преградой для распознавания человеком, и мы хотим потребовать того же и для реализованных на компьютере алгоритмов классификации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот лишь малая часть параметров, которые будут влиять на точность распознавания классификатора:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/problem_classification_difficult_object.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все описанные выше сложности обобщенно можно назвать **внутриклассовой вариативностью**: мы можем приписывать к одному классу объекты, которые допускают широкий спектр определения. Так, например, мы обобщаем классом \"кошка\" кошек различных пород, размеров и возрастов. \"Хороший\" алгоритм классификации должен быть устойчив к внутриклассовой вариативности и верно распознавать все возможные варианты объектов.\n",
    "\n",
    "Кроме описанных сложностей, линейные модели классификации способны качественно работать в условиях линейной разделимости классов, что бывает далеко не всегда. Классическим примером задачи, в которой данные линейно неразделимы, является задача моделирования логической функции XOR (\"исключающее ИЛИ\"). Линейный классификатор может построить только одну разделяющую прямую в пространстве признаков и не может справиться с этой, казалось бы, простой задачей.\n",
    "\n",
    "Подробнее о проблеме XOR: [[blog] ✏️ Demystifying the XOR problem](https://dev.to/jbahire/demystifying-the-xor-problem-1blk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/xor_problem.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Многослойные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из идей для решения проблемы внутриклассовой вариативности — модифицировать модель таким образом, чтобы у нее внутри было не по одному шаблону на каждый класс, а по несколько (скажем, 100 шаблонов вместо 10 при десяти классах). Тогда бы модель имела возможность запоминать разные объекты одного класса и далее использовать эти промежуточные шаблоны для разбиения объектов на классы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/modified_model.png\"  width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем эту модель на основе линейного классификатора из лекции №2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем к выходам классификатора еще один классификатор. Будет ли данная модель работать лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "x = np.random.rand(3072)  # random image\n",
    "W1 = np.random.randn(3072, 100) * 0.0001  # without bias\n",
    "W2 = np.random.randn(100, 10) * 0.0001  # without bias\n",
    "\n",
    "scores1 = np.matmul(x, W1)  # matrix multiplication, equivalent x @ W1\n",
    "scores2 = np.matmul(scores1, W2)  # matrix multiplication, of the next classifier\n",
    "\n",
    "print(f\"First classifier shape: {scores1.shape}\")\n",
    "print(f\"Second classifier shape: {scores2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нетрудно заметить, что последовательное применение двух классификаторов к входным данным эквивалентно применению одного классификатора с матрицей весов, равной произведению двух матриц весов классификаторов, примененных последовательно.\n",
    "\n",
    "$$\\large \\text{scores}_1 = x \\cdot W_1 $$\n",
    "\n",
    "$$\\large \\text{scores}_2 = \\text{scores}_1 \\cdot W_2 = x  \\cdot W_1 \\cdot W_2 $$\n",
    "\n",
    "$$\\large W = W_1 \\cdot W_2 $$\n",
    "\n",
    "$$\\large \\text{scores}_2 = x \\cdot W $$\n",
    "\n",
    "Для того, чтобы последовательно примененные классификаторы не вырождались в один, необходимо применить нелинейность к их выходам. Например, пропустить результат применения первой матрицы весов через сигмоиду:\n",
    "\n",
    "$$\\large \\sigma(s)=\\frac{1}{1+e^{-s}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/sigmoid_function.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    return 1 / (1 + np.exp(-s))\n",
    "\n",
    "\n",
    "# define vectorized sigmoid to implement with ndarray element-wise\n",
    "sigmoid_np = np.vectorize(sigmoid)\n",
    "\n",
    "scores1 = np.matmul(x, W1)\n",
    "activations = sigmoid_np(scores1)  # values after non-linear function\n",
    "scores2 = np.matmul(activations, W2)\n",
    "\n",
    "print(f\"First classifier shape: {scores1.shape}\")\n",
    "print(f\"Activations shape: {scores1.shape}\")\n",
    "print(f\"Second classifier shape: {scores2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вычисления выглядят так:\n",
    "\n",
    "$$\\large \\text{scores}_1 = x \\cdot W_1 $$\n",
    "\n",
    "$$\\large \\text{activations} = σ(\\text{scores}_1) $$\n",
    "\n",
    "$$\\large \\text{scores}_2 = \\text{activations} \\cdot W_2 =σ(x \\cdot W_1) \\cdot W_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая нелинейная функция, примененная к результату линейного преобразования, называется **функцией активации**. И мы уже пользовались подобной, когда разбирали Cross-Entropy Loss (Softmax).\n",
    "\n",
    "Приведем код в порядок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self):\n",
    "        self.W1 = np.random.randn(3072, 100) * 0.0001\n",
    "        self.W2 = np.random.randn(100, 10) * 0.0001\n",
    "\n",
    "    def predict(self, x):\n",
    "        scores1 = np.matmul(x, W1)  # Linear\n",
    "        activations = sigmoid_np(scores1)  # activation Sigmoid\n",
    "        scores2 = np.matmul(activations, W2)  # Linear\n",
    "\n",
    "        return scores2\n",
    "\n",
    "\n",
    "x = np.random.rand(3072)  # image\n",
    "model = NeuralNet()\n",
    "scores = model.predict(x)\n",
    "print(f\"Model output shape: {scores.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ядром вычислений по-прежнему является скалярное произведение входов с весовыми коэффициентами.\n",
    "\n",
    "Таким образом вводится модель искусственного нейрона — базового элемента искусственной нейронной сети. Выходом нейрона является результат применения функции активации к взвешенной сумме входных сигналов (в общем случае с учетом смещения — \"bias\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/neurons_output.png\" width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейроны в нейронных сетях объединяют в слои и соединяют между слоями по принципу \"каждый с каждым\". Так получаются **многослойные полносвязные нейронные сети** (fully-connected networks). Синонимичным названием является **многослойный персептрон**.\n",
    "\n",
    "Пример многослойного персептрона с двумя скрытыми слоями:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/nn_fully_connected.png\"  width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как добавление в модель скрытых слоев с нелинейностями позволяет решать линейно неразделимые задачи (вроде XOR или более сложные) можно пронаблюдать [в интерактивном тренажере от TensorFlow 🎮[demo]](http://playground.tensorflow.org/#activation=linear&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.1&regularizationRate=0&noise=0&networkShape=&seed=0.62952&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Веса и смещения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса и смещения являются настраиваемыми параметрами в нейронной сети. Они настраиваются в процессе обучения, поэтому их также называют **обучаемыми параметрами**. Рассмотрим, как различные значения обучаемых параметров влияют на работу одного нейрона. Это поможет нам получить интуицию, как добавление в модель скрытых слоев с нелинейностями наделяет её большей выразительной способностью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/why_add_bias_example.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим простой пример. На вход нейрона подаётся входное значение $x$, умноженное на вес $w$. После применения сигмоидальной функции активации, в зависимости от веса, при всевозможных значениях входа мы можем получить следующие графики при $w$, равном $0.5$, $1$ и $2$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/sigmoid_with_different_weights.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что значение веса меняет **крутизну** итоговой сигмоидальной функции.\n",
    "\n",
    "Но что, если требуется, чтобы при $x=5$ нейрон выдавал $0$? Изменением крутизны сигмоиды этого не добиться. Требуется дополнительный параметр — смещение.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Смещение** (англ. bias) — это дополнительный коэффициент, прибавляющийся к взвешенной сумме входов. Наличие смещения позволяет сдвинуть функцию активации влево или вправо.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/add_bias_example.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда при смещениях, равных $5$, $0$ и $-5$, мы можем получить сдвинутые функции активации, что способствует лучшему обучению нейронной сети:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/sigmoid_with_different_biases.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейронная сеть как универсальный аппроксиматор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известным теоретическим результатом в области нейронных сетей является **теорема об универсальной аппроксимации**, или [теорема Цыбенко 📚[wiki]](https://ru.wikipedia.org/wiki/Теорема_Цыбенко). Она гласит следующее:\n",
    "\n",
    "\n",
    "> Искусственная нейронная сеть прямого распространения с одним скрытым слоем и сигмоидальными функциями активации может поточечно аппроксимировать любую непрерывную функцию многих переменных с любой наперед заданной точностью.\n",
    "\n",
    "Условиями универсальной аппроксимации являются достаточное количество нейронов скрытого слоя и правильный подбор параметров (весовых коэффициентов и смещений) нейросети.\n",
    "\n",
    "Данный результат неконструктивен, поскольку он не говорит, *сколько необходимо скрытых нейронов* для аппроксимации той или иной функции, а также *как следует подбирать веса и смещения*. Однако он дает основания полагать, что для аппроксимации любой функции с помощью нейросети **достаточно** одного скрытого слоя с нелинейностями в виде сигмоиды.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы увидеть, как из суммы сигмоидальных функций можно построить произвольную функцию, рассмотрим следующую иллюстрацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "!wget -qN https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/universal_approximation.mp4\n",
    "\n",
    "mp4 = open(\"universal_approximation.mp4\", \"rb\").read()\n",
    "data_url = f\"data:video/mp4;base64,{b64encode(mp4).decode()}\"\n",
    "HTML(f\"<video width=1000  controls><source src={data_url} type='video/mp4'></video>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть мы имеем набор точек $(x, y)$ и предполагаем, что существует некоторая закономерность, связывающая $x$ и $y$:\n",
    "\n",
    "$$y=f(x)$$\n",
    "\n",
    "Мы можем подобрать и применить к $x$ такой весовой коэффициент $w_{1}$ и такое смещение $b_1$, что взятая от них сигмоида пройдет через часть наших точек или достаточно близко к ним:\n",
    "\n",
    "$$\\sigma_1=\\sigma(w_{1}x+b_1)$$\n",
    "\n",
    "После этого мы можем подобрать и применить к $x$ такие $w_{2}$ и $b_2$, что взятая от них сигмоида в сумме с $\\sigma_1$ пройдет еще через часть точек или достаточно близко к ним:\n",
    "\n",
    "$$\\sigma_2=\\sigma(w_{2}x+b_2)$$\n",
    "\n",
    "Мы можем продолжать добавлять сигмоиды и подбирать их параметы до тех пор, пока их сумма не станет достаточно точно приближать закономерность $f(x)$, выраженную в данных.\n",
    "\n",
    "$$\\sigma_1+\\sigma_2+...+\\sigma_n \\approx f(x)$$\n",
    "\n",
    "В случае нашего примера $n=4$.\n",
    "\n",
    "Этот пример не говорит, *как подбирать веса и смещения*, но показывает, что принципиально нам достаточно лишь одного скрытого слоя и нелинейностей в виде сигмоиды, чтобы в сумме они приближали произвольную закономерность, выраженную в данных. Это и утверждает теорема об универсальной аппроксимации.\n",
    "\n",
    "Для получения дополнительной интуиции об универсальной аппроксимации рекомендуем обратиться к [A visual proof that neural nets can compute any function 📚[book]](http://neuralnetworksanddeeplearning.com/chap4.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике обучение нейронных сетей (подбор значений весов) производится при помощи **метода градиентного спуска**.\n",
    "\n",
    "Обучение заключается в **минимизации функции потерь по обучаемым параметрам нейронной сети** — весам и смещениям.\n",
    "\n",
    "Для минимизации функции потерь методом градиентного спуска **необходимо уметь вычислять градиент функции потерь по всем обучаемым параметрам модели**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Прямое и обратное распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процесс расчета градиента функции потерь по обучаемым параметрам состоит из двух этапов: **прямого и обратного распространения**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/forward_pass.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время **прямого распространения** (forward pass) производится расчет значений на выходе модели $y_{pred}$, которые передаются в функцию потерь $\\text{Loss}$ для сравнения с целевыми значениями $y_{true}$.\n",
    "\n",
    "$$\\large y_{pred}=\\text{model}(x, 𝐖)$$\n",
    "\n",
    "$$\\large L=\\text{Loss}(y_{true}, y_{pred})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение функции потерь зависит от целевых значений $y_{true}$, входных данных $x$ и параметров модели $𝐖$.\n",
    "\n",
    "$$\\large L=\\text{Loss}(y_{true}, \\text{model}(x, 𝐖)) = f(y_{true}, x, 𝐖)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А значит, если модель и функция потерь дифференцируемы, мы можем посчитать $\\nabla_𝐖L$ — градиент функции потерь по обучаемым параметрам. Для этого нужен этап **обратного распространения** (backward pass)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/backward_pass.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Метод обратного распространения ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для эффективного численного расчета градиента функции потерь по обучаемым параметрам модели применяется **метод обратного распространения ошибки (backpropagation)**. Благодаря данному методу становится практически возможным использование метода градиентного спуска для проведения процедуры обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод обратного распространения ошибки использует структуру многослойной нейронной сети как сложной функции, применяя правило дифференцирования сложной функции для вычисления градиента от функции потерь по весам сети. Градиент от функции потерь вычисляется при движении по нейронной сети от её выходов в направлении входов. Именно такой порядок обхода вычислительного графа и обуславливает название метода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для более детального рассмотрения принципов работы и обучения нейронных сетей рекомендуем:\n",
    "\n",
    "[[video] 📺 Плей-лист от 3Blue1Brown](https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&si=O3gq6RoIxoNS6iJf) [[озвучка на русском](https://youtube.com/playlist?list=PLZjXXN70PH5itkSPe6LTS-yPyl5soOovc&si=ElKVi98Ui4m2nJKq)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычислительный граф"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По существу, нейронная сеть является сложной функцией, работу которой можно представить как последовательное выполнение математических операций. Такое представление функций называется [вычислительным графом ✏️[blog]](https://qudata.com/ml/ru/ML_Comp_Graph.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/nn_fully_connected.png\"  width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм обратного распространения ошибки позволяет находить градиенты для любого графа вычислений, если описываемая им функция дифференцируема.\n",
    "\n",
    "В его основе лежит правило взятия производной сложной функции (chain rule):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна переменная:\n",
    "\n",
    "$$\\large y(x) = f(u(g(x))) $$\n",
    "\n",
    "$$\\large \\frac{dy}{dx} = \\frac{df}{du} \\frac{du}{dg} \\frac{dg}{dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько переменных:\n",
    "\n",
    "$$\\large y(x) = f(u_1(x),u_2(x),...u_n(x))$$\n",
    "\n",
    "$$\\large \\frac{dy}{dx} = \\sum_{i=1}^{n} \\frac{\\partial f(u_1, u_2, ... u_n)}{\\partial u_i} \\frac{du_i}{dx}$$\n",
    "\n",
    "$$\\large \\underbrace{\\frac{d}{dx} f(\\vec{\\mathbf{u}}(x))}_{\\text{Derivative of composition function}} = \\overbrace{\\nabla_{\\vec{u}} f \\cdot \\vec{\\mathbf{u}}'(x)}^{\\text{Dot product of vectors}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Пошаговый разбор метода обратного распространения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть в каком-то узле графа производится вычисление\n",
    "\n",
    "$$\\large z = f(x, y),$$\n",
    "\n",
    "и далее результат вычисления $\\large z$ используется для вычисления функции $\\large L(z)=L(f(x, y))$.\n",
    "\n",
    "Тогда правило вычисления производных $\\dfrac{\\partial L}{\\partial x}$ и $\\dfrac{\\partial L}{\\partial y}$ можно представить следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/rule_for_taking_gradients.png\"  width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим следующую функцию:\n",
    "\n",
    "$$\\Large f(w,x)=\\frac{1}{1+e^{-(w_0x_0+w_1x_1+w_2)}}$$\n",
    "\n",
    "Представим ее в виде вычислительного графа, состоящего из элементарных операций, от которых просто берутся производные:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/graph_of_calculation_gradient.png\"  width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На примере данной функции рассмотрим алгоритм обратного распространения ошибки и найдём величину её градиента по параметрам $\\large w$.\n",
    "Нам потребуется вычислить частные производные $\\dfrac{\\partial f}{\\partial w_0}, \\dfrac{\\partial f}{\\partial w_1}, \\dfrac{\\partial f}{dw_2}, \\dfrac{\\partial f}{\\partial x_0}$ и $\\dfrac{\\partial f}{\\partial x_1}$.\n",
    "\n",
    "Пусть \"веса\" $w$ инициализированы значениями $w_0=2,\\;w_1=-3,\\;w_2=-3$, а \"входные признаки\" $x$ принимают значения $x_0=-1,\\;x_1=-2$.\n",
    "\n",
    "Делая прямой проход через граф вычислений для данной функции, получаем её значение для заданных $w$ и $x$ равным $f=0.73$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/forward_pass_example.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, в соответствии с алгоритмом обратного распространения ошибки, рассчитаем частные производные, пройдясь последовательно по графу вычислений, постепенно накапливая искомое значение для градиента функции.\n",
    "\n",
    "Для начала зададим $\\dfrac{df}{df}=1$.\n",
    "\n",
    "Начинаем обратный проход по графу вычислений — первая вершина содержит функцию $f(x)=\\dfrac{1}{x}$, производная которой равна $\\dfrac{df}{dx}=-\\dfrac{1}{x^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/compute_gradient_1_step.png\" width=\"800\"></center>\n",
    "\n",
    "$$\\large f(x)=\\frac1x \\quad \\longrightarrow \\quad \\frac{df}{dx} = -\\frac{1}{x^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующем узле находится функция $f(x)=1+x$. Производная от выражения в данном узле равняется $\\dfrac{df}{dx}=1$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/compute_gradient_2_step.png\" width=\"800\"></center>\n",
    "\n",
    "$$\\large f(x)=c+x \\quad \\longrightarrow \\quad \\frac{df}{dx} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Третья вершина содержит экспоненту $f(x)=e^x$. Её производная также является экспонентой $\\dfrac{df}{dx}=e^x$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/compute_gradient_3_step.png\" width=\"800\"></center>\n",
    "\n",
    "$$\\large f(x)=e^x \\quad \\longrightarrow \\quad \\frac{df}{dx} = e^x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая вершина, четвертая, содержит умножение на константу $f(x)=ax$. Производная равна $\\dfrac{df}{dx}=a$ (в данном случае $a=-1$):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/compute_gradient_4_step.png\" width=\"800\"></center>\n",
    "\n",
    "$$\\large f(x)=ax \\quad \\longrightarrow \\quad \\frac{df}{dx} = a$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Двигаясь по графу вычислений, мы дошли до узла суммирования, который имеет два входа. Относительно каждого из входов локальный градиент в вершине суммирования будет равен $1$:\n",
    "$$\\large f(x,y)=x+y \\quad \\Rightarrow \\quad \\frac{\\partial f}{\\partial x}=1  \\quad \\quad \\frac{\\partial f}{\\partial y}=1$$\n",
    "Так как умножение на единицу не изменит значения входного градиента, всем входам узла суммирования мы можем приписать точно такое же значение входного градиента ($0.2$), что мы имели и для самого узла суммирования. Будем действовать аналогично и со всеми остальными узлами суммирования, которые встретятся нам в вычислительном графе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/compute_gradient_5_step.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Двигаясь далее к началу графа вычислений, мы подходим к вершинам умножения. Для такой вершины локальный градиент по отношению к какому-либо из входов будет равен значению оставшегося входа. Остается умножить локальный градиент на входящий.\n",
    "\n",
    "$$\\large f(w,x)=wx \\quad \\Rightarrow \\quad \\frac{\\partial f}{\\partial w}=x  \\quad \\quad \\frac{\\partial f}{\\partial x}=w$$\n",
    "\n",
    "Точно так же мы можем поступить и с оставшейся второй вершиной умножения, которая привязана к $w_1$ и $x_1$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/compute_gradient_6_step.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так, двигаясь по графу вычислений в обратном направлении от выхода функции к входным аргументам, мы последовательно для каждого узла умножаем локальный градиент на входящий градиент, используя цепное правило дифференцирования сложной функции. В описанном примере мы полностью разбили граф вычислений на отдельные элементарные узлы. Разбиение вычислительного графа на элементарные узлы вовсе не обязательно — мы можем сгруппировать несколько вершин вместе, если они образуют дифференцируемую функцию, от которой \"удобно\" брать производную, и рассматривать их совместно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем примере мы можем заметить, что вычислительный граф можно свести к двум операциям: получению выражения $w_0x_0+w_1x_1+w_2$ и последующему вычислению от него сигмоидальной функции.\n",
    "\n",
    "Функция сигмоиды:\n",
    "\n",
    "$$\\large \\displaystyle \\sigma(x) = \\frac{1}{1+e^{-x}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно отметить, что сигмоида обладает важным свойством: её производная может быть выражена через саму сигмоидальную функцию:\n",
    "\n",
    "$$\\large \\frac{d}{dx}\\sigma(x) = \\frac{d}{dx}(1+e^{-x})^{-1} = \\frac{e^{-x}}{(1+e^{-x})^{2}} = \\frac{1}{1+e^{-x}} \\cdot \\frac{1+e^{-x}-1}{1+e^{-x}} = \\sigma(x)\\cdot(1-\\sigma(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/compute_gradient_join_vertices_sigmoid_example.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде без использования библиотек подсчёт градиентов можно записать как:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/calculating_gradients_in_code.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практически вся наша работа c нейронными сетями будет осуществляться с помощью [PyTorch 🛠️[doc]](https://pytorch.org/), поэтому необходимо познакомиться с основными концептами, принципами и функциями этой библиотеки.\n",
    "\n",
    "Лучший друг в этом, конечно же, [документация 🛠️[doc]](https://pytorch.org/docs/stable/index.html), здесь же мы разберем только основные сущности и методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Основная сущность — torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс `torch.Tensor` [🛠️[doc]](https://pytorch.org/docs/stable/tensors.html#torch.Tensor) предоставляет функциональность работы с многомерными массивами.\n",
    "\n",
    "Создание \"пустого\" тензора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.Tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция создания тензора из списка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1.1, 2.2, 3.2])\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явное указание типа данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1.1, 2.2, 3.2], dtype=torch.float64)\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание двумерного тензора, заполненного единицами (для нулей `zeros`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(size=(3, 2))\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание двумерного тензора, заполненного указанным значением\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.full(size=(3, 2), fill_value=3.74)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Транспонирование (изменение порядка осей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.T\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке реализовано большое количество математических функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.exp(a)\n",
    "print(\"Exponents tensor:\\n\", c)\n",
    "\n",
    "c += 1\n",
    "print(\"\\nAdd 1 to tensor:\\n\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти всё, что есть в NumPy, есть в PyTorch. Например, суммирование значений тензора с помощью `.sum()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перестановка, удаление и добавление пространственных измерений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros((2, 5, 1, 8))\n",
    "print(\"Original tensor size:\\n\", a.size())\n",
    "\n",
    "a = a.permute(dims=(2, 0, 3, 1))  # permute dimensions\n",
    "print(\"After permute tensor size:\\n\", a.size())\n",
    "\n",
    "a = a.squeeze()  # delete dimension\n",
    "print(\"After squzee tensor size:\\n\", a.size())\n",
    "\n",
    "a = a.unsqueeze(dim=0)  # add dimension\n",
    "print(\"After unsquzee tensor size:\\n\", a.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование `torch.Tensor` в `np.ndarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch позволяет тензору быть представлением (view) существующего тензора. Тензор представления использует те же данные, что и его базовый тензор. Поддержка `view` позволяет избежать явного копирования данных, что позволяет экономить память."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2, 8)\n",
    "print(\"Original tensor:\\n\", a)\n",
    "\n",
    "b = a.view(4, 4)\n",
    "print(\"\\nTensor after view:\\n\", b)\n",
    "\n",
    "print(\"\\nTensor b uses the same memory space as tensor a:\")\n",
    "id(a[0, 0]) == id(b[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размещение тензора на GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()} \\n\")\n",
    "\n",
    "a = a.to(device)  # moving tensor to gpu\n",
    "b = torch.full_like(a, 2).to(device)\n",
    "c = a * b  # compute on gpu (more fast with parallel computing)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Автоматическое вычисление градиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch умеет запоминать последовательность операций с тензорами и вычислять градиент.\n",
    "\n",
    "Вспомним функцию из примера выше\n",
    "\n",
    "$$\\Large f(w,x)=\\sigma(w_0x_0+w_1x_1+w_2)$$\n",
    "\n",
    "И построим ее вычислительный граф при $x_0=-1, x_1=-2, w_0=2,\\;w_1=-3,\\;w_2=-3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x from above example\n",
    "x0 = torch.tensor(-1.0, requires_grad=True)\n",
    "x1 = torch.tensor(-2.0, requires_grad=True)\n",
    "\n",
    "# w from above example\n",
    "w0 = torch.tensor(2.0, requires_grad=True)\n",
    "w1 = torch.tensor(-3.0, requires_grad=True)\n",
    "w2 = torch.tensor(-3.0, requires_grad=True)\n",
    "\n",
    "# forward pass to compute f\n",
    "s = x0 * w0 + x1 * w1 + w2\n",
    "f = torch.sigmoid(s)\n",
    "\n",
    "print(f\"f(x, W) = {f:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При создании тензоров мы указали параметр `requires_grad=True`. Установка этого параметра указывает PyTorch на то, что необходимо отслеживать операции, в которых участвует данный тезор, для построения вычислительного графа и последующего вычисления градиента.\n",
    "\n",
    "Можно визуализировать получившийся вычислительный граф с помощью библиотеки torchviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install -qU torchviz\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(f, params={'x0': x0, 'x1': x1, 'w0': w0, 'w1': w1, 'w2': w2, 'f': f})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы рассчитать градиент функции по всем параметрам, надо вызвать метод `backward`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"gradient is None before backward\")\n",
    "print(f\"w0.grad = {w0.grad}\")\n",
    "print(f\"w1.grad = {w1.grad}\")\n",
    "print(f\"w2.grad = {w2.grad}\")\n",
    "\n",
    "# backward pass to compute gradient df/dW\n",
    "f.backward()\n",
    "\n",
    "print(\"\\ngradient computed after backward\")\n",
    "print(f\"w0.grad = {w0.grad}\")\n",
    "print(f\"w1.grad = {w1.grad}\")\n",
    "print(f\"w2.grad = {w2.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили такие же значения частных производных $\\dfrac{\\partial f}{\\partial w_i}$, как и при вычислении вручную (на иллюстрации градиент расчитан с точностью до двух знаков после запятой, в коде выше получены более точные значения)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/autograd_example.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все те же вычисления, что и несколькими ячейками выше, можно записать короче и произвести за счет скалярного произведения тензора признаков $x$ и тензора весов $w$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-1.0, -2.0])  # x from above example\n",
    "\n",
    "x = torch.cat([x, torch.tensor([1.0])])  # concatenate x with 1. for bias trick\n",
    "\n",
    "W = torch.tensor([2.0, -3.0, -3.0], requires_grad=True)  # w from above example\n",
    "\n",
    "print(f\"W.grad = {W.grad} (before forward and backward pass grad is 'None')\")\n",
    "\n",
    "# forward pass to compute f\n",
    "s = x.matmul(W)\n",
    "f = torch.sigmoid(s)\n",
    "print(f\"f(x, W) = {f:.2f}\")\n",
    "\n",
    "# backward pass to compute gradient df/dW\n",
    "f.backward()\n",
    "print(f\"W.grad = {W.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы не требовали возможности расчета градиента по аргументу `x` (не указали `requires_grad=True`), поэтому после вызова `f.backward()` градиент по нему не рассчитается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсоединение тензора от графа вычислений производится с помощью `.detach()` (используется, если нужно производить какие-либо дальнейшие операции с тензором, но чтобы они не становились частью вычислительного графа):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_detached = f.detach()\n",
    "\n",
    "print(f\"f_detached = {f_detached:.2f}\")\n",
    "print(f\"f_detached type: {type(f_detached)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также от тензора, содержащего скаляр, можно получить его величину с помощью `.item()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = f_detached.item()\n",
    "\n",
    "print(f\"value = {value:.2f}\")\n",
    "print(f\"value type: {type(value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Обратное распространение в PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим алгоритм обратного распространения на примере вычисления квадрата ошибки для линейной регрессии (для простоты не будем рассматривать смещение):\n",
    "\n",
    "$$\\large y=w\\cdot x, \\quad при \\;x=[1,2,3,4],\\;y=[2,4,6,8],\\;w=1$$\n",
    "\n",
    "В данном примере видно, что предсказанный моделью $\\hat{y}=[1,2,3,4]$ не совпадает с истинными значениями $y$, и, соответственно, квадратичная ошибка для такого примера будет:\n",
    "\n",
    "$$\\large \\text{MSE}=\\frac{1}{4}\\sum_{i=1}^4E_i^2=\\frac{1}{4}\\sum_{i=1}^4(\\hat{y}_i-y_i)^2=\\frac{1+4+9+16}{4}=7.5$$\n",
    "\n",
    "Градиент функции потерь по весу $w$ вычисляется следующим образом, в соответствии с цепным правилом:\n",
    "\n",
    "$$\\large \\frac{\\partial \\text{MSE}}{\\partial w} = \\frac{\\partial \\text{MSE}}{\\partial E}\\cdot \\frac{\\partial E}{\\partial \\hat{y}}\\cdot \\frac{\\partial \\hat{y}}{\\partial w}$$\n",
    "\n",
    "Рассчитаем его с использованием PyTorch:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y_train = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "# This is the parameter we want to optimize -> requires_grad=True\n",
    "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
    "print(f\"W.grad = {W.grad} (before forward pass must be 'None')\\n\")\n",
    "\n",
    "# forward pass to compute MSE\n",
    "y_pred = W * x_train\n",
    "E = y_pred - y_train\n",
    "SE = E**2\n",
    "MSE = SE.mean()\n",
    "print(f\"MSE = {MSE}\")\n",
    "\n",
    "# backward pass to compute gradient dMSE/dw\n",
    "MSE.backward()\n",
    "print(f\"W.grad = {W.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном примере мы произвели следующие расчеты:\n",
    "\n",
    "$\\displaystyle\\frac{\\partial \\text{MSE}}{\\partial E}=\\frac{1}{4}\\frac{\\partial E^2}{\\partial E}=\\frac{1}{4}\\cdot2\\cdot E=\\frac{1}{2}*[-1, -2, -3, -4]=[-0.5, -1, -1.5, -2]\\quad $ $*$ — поэлементное умножение\n",
    "\n",
    "$\\displaystyle \\frac{\\partial E}{\\partial \\hat{y}}=\\frac{\\partial (\\hat{y}-y)}{\\partial \\hat{y}}=1$\n",
    "\n",
    "$\\displaystyle \\frac{\\partial \\hat{y}}{\\partial w}=\\frac{\\partial wx}{\\partial w}=x=[1, 2, 3, 4]$\n",
    "\n",
    "$\\displaystyle \\frac{\\partial \\text{MSE}}{\\partial w} = \\frac{\\partial \\text{MSE}}{\\partial E}\\cdot \\frac{\\partial E}{\\partial \\hat{y}}\\cdot \\frac{\\partial \\hat{y}}{\\partial w}=\\sum[-0.5, -1, -1.5, -2]*[1, 2, 3, 4]=-0.5-2-4.5-8=-15$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MSE.backward()` автоматически вычисляет градиент $\\dfrac{\\partial \\text{MSE}}{\\partial w}$ при указании `requires_grad=True`.\n",
    "Результаты вычислений будут храниться в `W.grad`. Для всех промежуточных переменных градиенты не сохраняются, поэтому попытка обратиться, например, к `E.grad` выдаст ошибку.\n",
    "\n",
    "Также после однократного обратного прохода в целях экономии памяти граф, используемый для вычисления градиента, будет удаляться, и следующий запуск `MSE.backward()` будет выдавать ошибку:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```\n",
    "MSE.backward() # Error on second backward call\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сохранить вычислительный граф, нужно взывать `backward()` с параметром `retain_graph=True`. В таком случае значения градиентов, полученные на следующих итерациях обратного распространения ошибки, будут складываться с текущими значениями градиентов.\n",
    "\n",
    "Градиенты переменных, для которых был указан `requires_grad=True`, сохраняются автоматически. Чтобы избежать их накопления при многократном итерировании алгоритма обратного распространения, нужно обнулять градиент на каждом шаге с помощью метода `Тensor.grad.zero_()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y_train = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "# This is the parameter we want to optimize -> requires_grad=True\n",
    "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# forward pass to compute MSE\n",
    "y_pred = W * x_train\n",
    "MSE = ((y_pred - y_train) ** 2).mean()\n",
    "\n",
    "print(\"Backward 1:\")\n",
    "MSE.backward(retain_graph=True)\n",
    "print(f\"dMSE/dW = {W.grad} \\n\")\n",
    "\n",
    "print(\"Without forward, backward 2. Gradient is accumulating:\")\n",
    "MSE.backward(retain_graph=True)\n",
    "# Gradients are accumulated\n",
    "print(f\"dMSE/dW = {W.grad}\\n\")\n",
    "\n",
    "print(\"Backward 3, but firstly nullify gradients:\")\n",
    "W.grad.zero_()  # Nullify gradients for W for the next iteration\n",
    "MSE.backward(retain_graph=True)\n",
    "print(f\"dMSE/dW = {W.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы умеем вычислять градиент $\\displaystyle \\frac{\\partial \\text{MSE}}{\\partial w}$ для нашего примера. Теперь давайте с его помощью оптимизируем веса, используя алгоритм обратного распространения ошибки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y_train = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "# Define model output\n",
    "def forward(x_train):\n",
    "    return W * x_train\n",
    "\n",
    "\n",
    "# Compute MSE loss\n",
    "def criterion(y_pred, y_train):\n",
    "    return ((y_pred - y_train) ** 2).mean()\n",
    "\n",
    "\n",
    "print(f\"Prediction before training: f(x) = {forward(x_train)}\")\n",
    "print(f\"True values: y = {y_train}\\n\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.005\n",
    "num_epochs = 102\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Propagate forward\n",
    "    y_pred = forward(x_train)\n",
    "\n",
    "    # Compute MSE loss\n",
    "    MSE = criterion(y_pred, y_train)\n",
    "\n",
    "    # Propagate backward, compute gradients\n",
    "    MSE.backward()\n",
    "\n",
    "    # Update weights\n",
    "    with torch.no_grad():  #  We don't want this step to be the part of the computational graph\n",
    "        W -= learning_rate * W.grad\n",
    "\n",
    "    # Nullify gradients after updating to avoid their accumulation\n",
    "    W.grad.zero_()\n",
    "\n",
    "    if epoch % 10 == 1:\n",
    "        print(f\"epoch {epoch}: w = {W.item():.3f}, loss = {MSE.item():.8f}\")\n",
    "\n",
    "print(f\"\\nPrediction after training: f(x) = {forward(x_train)}\")\n",
    "print(f\"True values: y = {y_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что наш подход позволяет оптимизировать вес $w$ регрессии из примера и таким образом добиться почти идеального предсказания нашей модели, однако в данном подходе дополнительно можно автоматизировать вычисление функции потерь и обновление параметров с учетом градиента, используя готовые функции потерь из `torch.nn` и оптимизаторы из `torch.optim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y_train = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "# Define model output\n",
    "def forward(x_train):\n",
    "    return W * x_train\n",
    "\n",
    "\n",
    "print(f\"Prediction before training: f(x) = {forward(x_train)}\")\n",
    "print(f\"True values: y = {y_train}\\n\")\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.005\n",
    "num_epochs = 102\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([W], lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Propagate forward\n",
    "    y_pred = forward(x_train)\n",
    "\n",
    "    # Compute MSE loss\n",
    "    MSE = criterion(y_pred, y_train)\n",
    "\n",
    "    # Propagate backward, compute gradients\n",
    "    MSE.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Nullify gradients after updating to avoid their accumulation\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 1:\n",
    "        print(f\"epoch {epoch}: w = {W.item():.3f}, loss = {MSE.item():.8f}\")\n",
    "\n",
    "print(f\"\\nPrediction after training: f(x) = {forward(x_train)}\")\n",
    "print(f\"True values: y = {y_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Функции потерь (loss functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь измеряет точность нейронной сети, оценивая расхождение между предсказанными результатами и истинными значениями. Она принимает два аргумента:\n",
    "\n",
    "- Вектор истинных значений.\n",
    "- Вектор предсказанных значений.\n",
    "\n",
    "Для успешного обучения с использованием градиентного спуска функция потерь должна быть дифференцируемой и ограниченной снизу.\n",
    "Рассмотрим наиболее часто применяемые функции потерь и то, как устроены их реализации в PyTorch и как ими пользоваться.\n",
    "\n",
    "[[doc] 🛠️ Функции потерь в PyTorch](https://pytorch.org/docs/stable/nn.html#loss-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средняя квадратическая ошибка (MSE) — популярная функция потерь для задач регрессии, где модель предсказывает вещественные числа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для $i$-го объекта выборки, если выходной вектор состоит из $C$ компонент, средняя квадратическая ошибка между выходом модели $\\hat{y}$ и целевым вектором $y$ будет равна\n",
    "\n",
    "$$\\large \\text{MSE}_i(\\hat{y},y)=\\frac{1}{C} \\sum_{k=1}^{C}{(\\hat{y}_{ik}-y_{ik})^2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание, относящееся ко всем функциям потерь в PyTorch, которые будут рассмотрены ниже.**\n",
    "\n",
    "При вычислении по всему набору данных (или по мини-батчу) из $N$ объектов ошибка на отдельных объектах может усредняться или суммироваться. За это отвечает параметр `reduction`, который принимает значения `'mean'` или `'sum'`, а также может принимать значение `'none'`, при котором агрегация производиться не будет, и тогда функция будет возвращать тензор значений размером $N$.\n",
    "\n",
    "**По умолчанию в большинстве функций потерь в PyTorch `reduction='mean'`.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] 🛠️ MSE Loss в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss):\n",
    "```python\n",
    "torch.nn.MSELoss()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "# batch of 1 element and 3 components in output vector\n",
    "model_output = torch.Tensor([0.5, -0.25, 0.75])\n",
    "print(f\"model_output: {model_output}\")\n",
    "\n",
    "target = torch.Tensor([1, 0.25, 0.25])\n",
    "print(f\"target: {target}\")\n",
    "\n",
    "loss_mse = criterion(model_output, target)\n",
    "print(f\"loss_mse: {loss_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Преимущество:** MSE штрафует за большие ошибки в предсказаниях, так как ошибки возводятся в квадрат.\n",
    "\n",
    "- **Недостаток:** MSE сильно акцентируется на выбросах, что может быть нежелательно для задач, где важнее высокая точность на большинстве примеров, а не устранение одиночных выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средняя абсолютная ошибка (MAE) также применяется для задач регрессии. В отличие от MSE, которая акцентируется на крупных выбросах (ошибка $L_2$), MAE, будучи $L_1$ ошибкой, имеет другие свойства и может быть более устойчивой к выбросам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для $i$-го объекта выборки, если выходной вектор состоит из $C$ компонент, средняя абсолютная ошибка между выходом модели $\\hat{y}$ и целевым вектором $y$ будет равна:\n",
    "\n",
    "$$\\large \\text{MAE}_i(\\hat{y},y)=\\frac{1}{C} \\sum_{k=1}^{C}{\\left| \\hat{y}_{ik}-y_{ik}\\right|}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] 🛠️ MAE Loss в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss):\n",
    "```python\n",
    "torch.nn.L1Loss()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "\n",
    "# batch of 1 element and 3 components in output vector\n",
    "model_output = torch.Tensor([0.5, -0.25, 0.75])\n",
    "print(f\"model_output: {model_output}\")\n",
    "\n",
    "target = torch.Tensor([1, 0.25, 0.25])\n",
    "print(f\"target: {target}\")\n",
    "\n",
    "loss_mae = criterion(model_output, target)\n",
    "print(f\"loss_mae: {loss_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Преимущество:** MAE учитывает все ошибки равнозначно и менее чувствительна к выбросам по сравнению с MSE.\n",
    "\n",
    "- **Недостаток:** Использование MAE может привести к большим ошибкам на отдельных примерах, поскольку модель фокусируется на общей точности, а не на устранении выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huber Loss комбинирует среднюю квадратическую ошибку (MSE) и среднюю абсолютную ошибку (MAE). Она применима к задачам регрессии и используется для улучшения устойчивости модели к выбросам. Huber Loss ведёт себя как MSE для небольших ошибок и как MAE для больших ошибок, что позволяет сбалансировать точность и устойчивость. Выбор порога, при котором происходит переключение между MSE и MAE, задаётся гиперпараметром $\\delta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.2/L05/out/mse_mae_huber_losses.png\" width=\"750\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для $i$-го объекта выборки, если выходной вектор состоит из $C$ компонент, Huber Loss между выходом модели $\\hat{y}$ и целевым вектором $y$ будет равна:\n",
    "\n",
    "$$\\large \\text{Huber Loss}_i(\\hat{y},y)=\\frac{1}{C} \\sum_{k=1}^{C}{l_{ik}}$$\n",
    "\n",
    "где\n",
    "\n",
    "$$\\large\n",
    "l_{ik} =\n",
    "\\begin{cases}\n",
    "0.5 (\\hat{y}_{ik}-y_{ik})^2, & \\text{if} |\\hat{y}_{ik}-y_{ik}| < \\delta \\\\\n",
    "\\delta \\cdot (|\\hat{y}_{ik}-y_{ik}| - 0.5 \\cdot \\delta), & \\text{else}\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] 🛠️ Huber Loss в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html):\n",
    "```python\n",
    "torch.nn.HuberLoss()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.HuberLoss()\n",
    "\n",
    "# batch of 1 element and 3 components in output vector\n",
    "model_output = torch.Tensor([0.5, -0.25, 0.75])\n",
    "print(f\"model_output: {model_output}\")\n",
    "\n",
    "target = torch.Tensor([1, 0.25, 0.25])\n",
    "print(f\"target: {target}\")\n",
    "\n",
    "huber_loss = criterion(model_output, target)\n",
    "print(f\"huber_loss: {huber_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huber Loss комбинирует преимущества MSE и MAE и позволяет сбалансировать точность и устойчивость модели к выбросам, но требует выбора значения гиперпараметра $\\delta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cross-Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс-энтропия — это функция потерь, используемая для измерения несовпадения между двумя вероятностными распределениями, и она широко применяется в задачах классификации. Кросс-энтропия как функция потерь оценивает различие между истинными метками классов и предсказаниями модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для $i$-го объекта выборки, если выходной вектор состоит из $C$ компонент (**логитов** для $C$ классов), кросс-энтропия между выходом модели $\\hat{y}$ и целевым вектором $y$ будет равна\n",
    "\n",
    "$$\\large \\text{CE}_i(\\hat{y},y)= - \\sum_{k=1}^{C}{y_{ik}\\cdot\\log\\left(\\frac{\\exp(\\hat{y}_{ik})}{\\sum_{j=1}^{C}\\exp(\\hat{y}_{ij})}\\right)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] 🛠️ Cross-Entropy Loss в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss):\n",
    "```python\n",
    "torch.nn.CrossEntropyLoss()\n",
    "```\n",
    "\n",
    "Обратите внимание, что Cross-Entropy Loss в PyTorch уже включает в себя Softmax и принимает в качестве выхода модели логиты. Поэтому при использовании данной фукции потерь ставить на последнем слое нейронной сети Softmax **не нужно**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# fmt: off\n",
    "model_output = torch.tensor([[2.4, 1.9, 7.3],\n",
    "                             [9.5, 2.7, 4.0],\n",
    "                             [5.7, 4.1, 0.2]])  # logits\n",
    "# fmt: on\n",
    "\n",
    "print(f\"model_output:\\n {model_output}\")\n",
    "\n",
    "target = torch.tensor([2, 0, 1], dtype=torch.long)  # class labels\n",
    "print(f\"target: {target}\")\n",
    "\n",
    "loss_ce = criterion(model_output, target)\n",
    "print(f\"loss_ce: {loss_ce}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{CE}_1 = - \\log\\left(\\frac{\\exp{(7.3)}}{\\exp{(2.4)}+\\exp{(1.9)}+\\exp{(7.3)}}\\right)$$\n",
    "\n",
    "$$\\text{CE}_2 = - \\log\\left(\\frac{\\exp{(9.5)}}{\\exp{(9.5)}+\\exp{(2.7)}+\\exp{(4.0)}}\\right)$$\n",
    "\n",
    "$$\\text{CE}_3 = - \\log\\left(\\frac{\\exp{(4.1)}}{\\exp{(5.7)}+\\exp{(4.1)}+\\exp{(0.2)}}\\right)$$\n",
    "\n",
    "$$\\text{CE} = \\frac{1}{3}(\\text{CE}_1 + \\text{CE}_2 + \\text{CE}_3)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ce_1 = -np.log(np.exp(7.3) / (np.exp(2.4) + np.exp(1.9) + np.exp(7.3)))\n",
    "ce_2 = -np.log(np.exp(9.5) / (np.exp(9.5) + np.exp(2.7) + np.exp(4.0)))\n",
    "ce_3 = -np.log(np.exp(4.1) / (np.exp(5.7) + np.exp(4.1) + np.exp(0.2)))\n",
    "\n",
    "ce = (1 / 3) * (ce_1 + ce_2 + ce_3)\n",
    "print(f\"hand-calculated loss_ce: {ce}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Преимущество:** Кросс-энтропия может учитывать веса классов, что делает её полезной для работы с несбалансированными датасетами.\n",
    "\n",
    "- **Недостаток:** Кросс-энтропия может быть чувствительна к шуму в данных, что может привести к переобучению, особенно если модель делает сильные, но ошибочные предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Веса классов\n",
    "\n",
    "При работе с несбалансированными данными модель может сосредоточиться на доминирующем классе, игнорируя признаки объектов. Например, в датасете с 95% объектов класса 1 и 5% — класса 0, модель может просто присваивать всем объектам класс 1, достигая 95% точности.\n",
    "\n",
    "Чтобы учесть дисбаланс, можно модифицировать функцию потерь, увеличивая штраф за ошибки в минорных классах. В PyTorch параметр `weight` в `CrossEntropyLoss` [🛠️[doc]](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) позволяет задать веса для каждого класса, корректируя функцию потерь с учетом дисбаланса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как это работает. Допустим, мы получили от нейросети неверные предсказания: второй объект должен относиться к классу $1$, а не $0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "# Scores for batch of two samples\n",
    "model_output = torch.tensor([[30.0, 2.0],\n",
    "                             [30.0, 2.0]])\n",
    "\n",
    "target = torch.tensor([0, 1])  # Second sample belongs to class 1\n",
    "# but logit for class 0 is greater: 30 > 2. So it was misclassified\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем Cross-Entropy Loss без весов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{CE} = \\frac{1}{2} \\biggr[- \\log\\frac{e^{30}}{e^{30}+e^{2}} - \\log\\frac{e^{2}}{e^{30}+e^{2}}\\biggr]\\approx 14.0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(model_output, target)\n",
    "print(f\"Loss = {loss.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас есть два класса с соотношением $4:1$, можно задать веса `weight = [0.2, 0.8]`. И, так как сеть ошиблась на классе с большим весом, ошибка вырастет:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{CE}_{\\text{weighted}} =  \\biggr[\\mathbf{-0.2} \\log\\frac{e^{30}}{e^{30}+e^{2}} -\\mathbf{0.8} \\log\\frac{e^{2}}{e^{30}+e^{2}}\\biggr]\\approx 22.4 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([0.2, 0.8])\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "loss = criterion(model_output, target)\n",
    "print(f\"Loss = {loss.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сумма весов не обязана быть равной единице, важно только соотношение между весами. Часто соотношение весов делают обратно пропорциональным количеству объектов в классах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0, 4.0]))\n",
    "loss = criterion(model_output, target)\n",
    "print(f\"Loss = {loss.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Иногда качество модели можно улучшить, взяв квадратные корни от полученных таким образом весов (немного снижает штрафы за ошибки на редких классах).\n",
    "\n",
    "- Несмотря на интуитивно понятную логику работы способа, он не всегда дает значительный эффект. Тем не менее, на практике стоит пробовать экспериментировать с этим способом наряду с прочими техниками борьбы с дисбалансом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Focal Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss — это функция потерь, используемая в нейронных сетях для решения проблемы классификации *сложных* объектов (hard examples).\n",
    "\n",
    "[[colab] 🥨 Подробное рассмотрение Focal Loss с примерами](https://colab.research.google.com/drive/1rM7zRySu8WulXbFiXzxBGVzILxvQ6K4A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/hard_examples_fruits.png\" width=\"800\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss немного модифицирует кросс-энтропию для придания большей значимости ошибкам на сложных объектах.\n",
    "\n",
    "Она была предложена в статье [Focal Loss for Dense Object Detection (Lin et al., 2017) 🎓[arxiv]](https://arxiv.org/abs/1708.02002) изначально для задачи детектирования объектов на изображениях. Определяется так:\n",
    "\n",
    "$$\\large\\text{FL}(p_t) = -(1 - p_t)^\\gamma\\log(p_t),$$\n",
    "\n",
    "где $p_t$ — предсказанная вероятность истинного класса, а $\\gamma\\geq0$ — настраиваемый гиперпараметр.\n",
    "\n",
    "Focal Loss уменьшает потери на уверенно классифицируемых примерах (где $p_t>0.5$) и больше фокусируется на сложных примерах, которые классифицированы неправильно. Параметр $\\gamma$ управляет относительной важностью неправильно классифицируемых примеров. Более высокое значение $\\gamma$ увеличивает важность неправильно классифицированных примеров. В экспериментах авторы показали, что параметр $\\gamma=2$ показывал себя наилучшим образом в их задаче."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При $\\gamma=0$ Focal Loss становится равной Cross-Entropy Loss, которая может быть выражена как обратный логарифм вероятности истинного класса:\n",
    "\n",
    "$$\\large\\text{CE}(p_t)=-\\log(p_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss может применяться также и в задачах с дисбалансом классов. В этом смысле объекты преобладающего класса могут считаться простыми, а объекты минорного класса — сложными.\n",
    "\n",
    "Однако для работы с дисбалансом в Focal Loss могут быть добавлены веса для классов. Тогда формула будет выглядеть так:\n",
    "\n",
    "$$\\large\\text{FL}(p_t) = -\\alpha_t(1 - p_t)^\\gamma\\log(p_t),$$\n",
    "\n",
    "где $\\alpha_t$ — вес для истинного класса, имеющий такой же смысл, как параметр `weight` в Cross-Entropy Loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss не реализована в PyTorch нативно, но существуют сторонние совместимые реализации. Посмотрим, как воспользоваться [одной из них 🐾[git]](https://github.com/AdeelH/pytorch-multi-class-focal-loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -qN https://raw.githubusercontent.com/AdeelH/pytorch-multi-class-focal-loss/master/focal_loss.py\n",
    "!wget -qN https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L05/focal_loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focal_loss import FocalLoss\n",
    "\n",
    "\n",
    "criterion = FocalLoss(alpha=None, gamma=2.0)\n",
    "\n",
    "# fmt: off\n",
    "model_output = torch.tensor([[2.4, 1.9, 7.3],\n",
    "                             [9.5, 2.7, 4.0],\n",
    "                             [5.7, 4.1, 0.2]])  # model output is logits, as in CrossEntropyLoss\n",
    "# fmt: on\n",
    "print(f\"model_output:\\n {model_output}\")\n",
    "\n",
    "target = torch.tensor([2, 0, 1], dtype=torch.long)  # class labels\n",
    "print(f\"target: {target}\")\n",
    "\n",
    "loss_fl = criterion(model_output, target)\n",
    "print(f\"loss_fl: {loss_fl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что **Focal Loss следует применять с осторожностью**: если мы имеем **ошибки в разметке**, то при большом $\\gamma$ можно начать очень сильно наказывать модель за ошибки на неверно размеченных примерах, что может привести к переобучению под ошибки в разметке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Log Likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLL Loss, используемая для классификации, отличается от Cross-Entropy Loss тем, что ожидает логарифмы вероятностей классов на выходе модели, а не логиты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для $i$-го объекта выборки, если выходной вектор состоит из $C$ компонент (**логарифмов вероятностей** для $C$ классов), NLL Loss между выходом модели $\\hat{y}$ и целевым вектором $y$ будет равна:\n",
    "\n",
    "$$\\large \\text{NLL}_i(\\hat{y},y)= - \\sum_{k=1}^{C}{y_{ik}\\cdot\\hat{y}_{ik}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для применения NLL Loss в классификации логиты модели нужно сначала преобразовать через Softmax и взять их натуральный логарифм. В PyTorch это выполняется с помощью модуля `LogSoftmax` [🛠️[doc]](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html). Связь между NLL Loss и Cross-Entropy Loss можно выразить так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/ce_loss_vs_nll_loss.png\" width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исторически NLL Loss использовалась с LogSoftmax, тогда как Cross-Entropy Loss объединяет LogSoftmax и NLL Loss, упрощая модель. Cross-Entropy Loss стала популярнее за счёт упрощения.\n",
    "\n",
    "После обучения модели:\n",
    "\n",
    "- **LogSoftmax + NLL Loss:** На выходе логарифмы вероятностей. Для получения вероятностей нужно взять экспоненту.\n",
    "  \n",
    "- **Cross-Entropy Loss:** На выходе логиты. Для получения вероятностей примените Softmax.\n",
    "\n",
    "[[blog] ✏️ Объяснение Negative Log Likelihood Loss](https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/)\n",
    "\n",
    "[[blog] ✏️ О соотношении Cross-Entropy Loss и Negative Log Likelihood Loss](https://jamesmccaffrey.wordpress.com/2020/06/11/pytorch-crossentropyloss-vs-nllloss-cross-entropy-loss-vs-negative-log-likelihood-loss/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Binary Cross-Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В частном случае, когда количество классов равно двум (**задача бинарной классификации**), их можно закодировать одним числом: $0$ — для первого класса, и $1$ — для второго. Тогда сумму $\\displaystyle \\sum_{k=1}^{C}$ в формуле Cross-Entropy Loss можно расписать в явном виде."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для $i$-го объекта выборки, когда выход модели является скаляром (**вероятностью** отнесения объекта к классу $1$), бинарная кросс-энтропия между выходом модели $\\hat{y}$  и целевым значением $y$ будет равна\n",
    "\n",
    "$$\\large \\text{BCE}_i(\\hat{y},y)= - [{y_i\\cdot\\log(\\hat{y_i})+(1-y_i)\\cdot\\log(1-\\hat{y_i})}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] 🛠️ Binary Cross-Entropy Loss в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss):\n",
    "\n",
    "```python\n",
    "torch.nn.BCELoss()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важной особенностью BCE Loss является то, что здесь используется не one-hot кодирование целевых значений для двух классов, а **одно число: 0 — первый класс, 1 — второй класс.** При этом значения целевой переменной должны быть представлены как вещественные (float) числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "model_output = torch.rand(1)\n",
    "print(f\"model_output: {model_output}\")\n",
    "\n",
    "target = torch.empty(1).random_(2)\n",
    "print(f\"target: {target}\")\n",
    "\n",
    "loss_bce = criterion(model_output, target)\n",
    "print(f\"loss_bce: {loss_bce}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если классы \"абсолютно полностью\" не совпали, то возникает ситуация взятия логарифма от $0$, а он не определён и стремится к бесконечности, поэтому берётся \"обрезанная бесконечность\", равная $100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "model_output = torch.ones(5)\n",
    "print(f\"model_output: {model_output}\")\n",
    "\n",
    "target = torch.zeros(5)\n",
    "print(f\"target: {target}\")\n",
    "\n",
    "loss_bce = criterion(model_output, target)\n",
    "print(f\"loss_bce: {loss_bce}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Cross-Entropy With Logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для бинарной классификации выход модели должен быть вероятностью принадлежности к классу 1, которую можно получить с помощью логистической функции (sigmoid) и передать в BCE Loss.\n",
    "\n",
    "BCE With Logits Loss объединяет две операции:\n",
    "\n",
    "- Применение функции sigmoid.\n",
    "- Расчёт BCE Loss.\n",
    "\n",
    "BCE With Logits Loss ожидает логиты на входе, и её использование упрощает модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/bce_loss_vs_bce_with_logits_loss.png\" width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции потерь BCE Loss и BCE With Logits Loss можно применять не только в случае бинарной классификации, но и **в случае Multi-label классификации**.\n",
    "\n",
    "В таком случае в векторе целевых значений вероятностей для каждого объекта может быть больше, чем одна единица. А логиты на последнем слое сети независимо пропускаются через сигмоиду (а не через Softmax, как в случае с многоклассовой классификацией)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "В PyTorch доступны другие функции потерь, и можно создавать собственные.\n",
    "\n",
    "[[blog] ✏️ Обзор функций потерь в PyTorch с примером написания своей собственной функции (custom loss function)](https://neptune.ai/blog/pytorch-loss-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Функции активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея применения функций активации в структуре искусственных нейронных сетей обусловлена биологической аналогией. Известно, что в биологических нейронных сетях имеется аналог нелинейной функции активации: существует пороговый потенциал, только после достижения которого происходит возбуждение (активация) нейрона и, как следствие, распространение сигнала далее по нейронной сети.\n",
    "\n",
    "Именно таким простейшим образом ведёт себя пороговая функция активации, которая использовалась при построении первых искусственных нейронных сетей — перцептронов:\n",
    "\n",
    "$$\\large f(x) =\n",
    "\\begin{cases}\n",
    "0, &\\text{$x<b$} \\\\\n",
    "1, &\\text{$x\\geq b$}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/threshold_function_plot.png\" width=\"300\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построенная с пороговой функцией активации нейронная сеть обладает ключевым недостатком, не позволяющим фактически использовать данную функцию активации на практике. В силу того, что производная функции активации тривиальна почти всюду на числовой прямой:\n",
    "\n",
    "$$\\large f'(x) =\n",
    "\\begin{cases}\n",
    "0, &\\text{$x\\neq b$} \\\\\n",
    "?, &\\text{$x= b$}\n",
    "\\end{cases},\n",
    "$$\n",
    "\n",
    "не представляется возможным использовать метод градиентного спуска для оптимизации параметров нейронной сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Свойства функций активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции активации должны обладать следующими свойствами:\n",
    "\n",
    "* **Нелинейность:** функция активации необходима для введения нелинейности в нейронные сети. Если функция активации не применяется, выходной сигнал становится простой линейной функцией. Нейронная сеть $\\text{NN}$ без нелинейностей будет действовать как линейная модель с ограниченной способностью к обучению:\n",
    "$$\\large \\hat{y}=\\text{NN}(X,W_1,...,W_n)=X\\cdot W_1\\cdot ...\\cdot W_n=X\\cdot W$$\n",
    "Только нелинейные функции активации позволяют нейронным сетям решать задачи аппроксимации нелинейных функций:\n",
    "$$\\large \\hat{y}=\\text{NN}(X,W_1,...,W_n)=\\sigma(...\\sigma(X\\cdot W_1)...\\cdot W_n)\\neq X\\cdot W$$\n",
    "\n",
    "* **Дифференцируемость:** функции активации должны быть способными пропускать градиент, чтобы было возможно оптимизировать параметры сети градиентными методами, в частности использовать алгоритм обратного распространения ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Различные функции активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим наиболее популярные функции активации и обсудим их преимущества и недостатки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L05/popular_activation_functions.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://arxiv.org/pdf/1911.05187.pdf\">AI in Pursuit of Happiness, Finding Only Sadness: Multi-Modal Facial Emotion Recognition Challenge</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Логистическая функция**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая (сигмоидальная) функция — используется в задачах бинарной классификации, в основном после выхода последнего нейрона. Позволяет определить вероятность принадлежности к одному из двух классов (0 или 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\sigma(x)=\\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/activation_function_sigmoid.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечательным свойством логистической функции является то, что ее производная выражается через саму функцию. Это значит, что, зная значение функции в точке, вычислить значение производной в этой точке очень легко:\n",
    "\n",
    "$$\\large \\frac{d}{dx}\\sigma(x) = \\frac{d}{dx}(1+e^{-x})^{-1} = \\frac{e^{-x}}{(1+e^{-x})^{2}} = \\frac{1}{1+e^{-x}} \\cdot \\frac{1+e^{-x}-1}{1+e^{-x}} = \\sigma(x)\\cdot(1-\\sigma(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от пороговой функции активации, где у нейрона было всего два состояния: \"активирован\" или \"не активирован\", с логистической функцией для нейрона возможны значения \"активирован на $50\\%$\", \"активирован на $20\\%$\" и так далее. Если активированы несколько нейронов, можно найти нейрон с наибольшим значением активации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] 🛠️ Сигмоидальная функция активации в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html):\n",
    "```python\n",
    "torch.nn.Sigmoid()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.Sigmoid()\n",
    "input_values = torch.randn(5) * 5\n",
    "activation_sig = activation(input_values)\n",
    "print(f\"input_values: {input_values}\\nactivation_sig: {activation_sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Свойства логистической функции активации:\n",
    "\n",
    "1. **Диапазон значений**. Значения лежат в интервале от 0 до 1, что делает ее полезной для моделирования вероятностных величин. Значения сигмоиды можно интерпретировать как вероятности, что делает ее полезной в задачах бинарной, а также многозначной (multilabel) классификации.\n",
    "\n",
    "2. **Гладкость**. Функция является гладкой и дифференцируемой во всей области определения, что упрощает обучение с использованием градиентных методов.\n",
    "\n",
    "3. **Насыщение**. При очень больших или очень маленьких входных значениях сигмоида насыщается, а ее производная стремится к нулю, что может привести к проблеме затухания градиента. Проблема затухания градиента возникает в процессе обучения нейронных сетей, когда градиенты, передаваемые через множество слоев, становятся слишком маленькими. Это приводит к тому, что параметры модели не обновляются должным образом, и обучение замедляется или даже останавливается.\n",
    "\n",
    "Логистическую функцию активации применяют в нейронных сетях в основном для задач бинарной классификации, когда необходимо получить вероятности принадлежности к классу. Также ее могут использовать в скрытых слоях, хотя она стала менее популярной в этом контексте из-за проблемы затухания градиента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Гиперболический тангенс**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперболический тангенс схож с логистической функцией. Он определяется следующей формулой:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\tanh(x)=\\frac{e^x - e^{-x}}{e^x+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также гиперболический тангенс может быть выражен через логистическую функцию:\n",
    "\n",
    "$$\\large \\tanh(x) = 2\\cdot\\sigma(2x)-1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/activation_function_tanh.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная гиперболического тангенса также [выражается через саму функцию ✏️[blog]](https://socratic.org/questions/what-is-the-derivative-of-tanh-x):\n",
    "\n",
    "$$\\large \\frac{d}{dx}\\tanh(x)=1-\\tanh^2(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперболический тангенс обладает следующими свойствами:\n",
    "\n",
    "1. **Диапазон значений**. Значения лежат в интервале от $-1$ до $1$, что обеспечивает симметричность относительно нуля.\n",
    "\n",
    "2. **Гладкость**. Функция является гладкой и дифференцируемой на всей области определения, что облегчает обучение с использованием методов оптимизации градиентного спуска.\n",
    "\n",
    "3. **Более высокая чувствительность**. По сравнению с сигмоидной функцией, $\\text{tanh}$ более чувствительна к изменениям входных данных, что может способствовать более быстрой сходимости в некоторых случаях.\n",
    "\n",
    "4. **Центрирование вокруг нуля**. Это свойство может ускорить обучение, поскольку оно способствует более быстрой стабилизации весов в сети.\n",
    "\n",
    "5. **Насыщение**. Как и у сигмоиды, у $\\text{tanh}$ есть проблема насыщения на краях своего диапазона, что может приводить к затуханию градиента.\n",
    "\n",
    "Гиперболический тангенс применяют в нейронных сетях в основном для задач, требующих внутренних представлений, симметрично распределенных вокруг нуля. Также его часто используют в скрытых слоях нейронных сетей для моделирования нелинейных зависимостей в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] 🛠️ Гиперболический тангенс в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html):\n",
    "```python\n",
    "torch.nn.Tanh()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.Tanh()\n",
    "input_values = torch.tensor([11.1529, 4.3029, 0.5081, -3.8456, -1.9058])\n",
    "activation_tanh = activation(input_values)\n",
    "print(f\"input_values: {input_values}\\nactivation_tanh: {activation_tanh}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **ReLU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто на практике применяется функция активации ReLU. Значение данной функции равно нулю для всех отрицательных входных значений и равно входному значению, если оно неотрицательно. Название ReLU (Rectified Linear Unit), \"выпрямитель\", связано с электротехнической аналогией — график вольт-амперной характеристики идеального выпрямительного диода похож на график функции ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{ReLU}(x)=\\max(0,x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/activation_function_relu.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная ReLU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{d}{dx}\\text{ReLU}(x) =\n",
    "\\begin{cases}\n",
    "\\displaystyle \\frac{d}{dx}0, &\\text{$x<0$} \\\\\n",
    "\\displaystyle \\frac{d}{dx}x, &\\text{$x\\geq0$}\n",
    "\\end{cases}=\n",
    "\\begin{cases}\n",
    "0, &\\text{$x<0$} \\\\\n",
    "1, &\\text{$x\\geq0$}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] 🛠️ ReLU в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html):\n",
    "```python\n",
    "torch.nn.ReLU()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.ReLU()\n",
    "input_values = torch.randn(5)\n",
    "activation_relu = activation(input_values)\n",
    "print(f\"input_values: {input_values}\\nactivation_relu: {activation_relu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция активации ReLU имеет следующие свойства:\n",
    "\n",
    "1. **Диапазон значений**. Значения лежат в $[0, + \\infty)$. Все отрицательные значения обнуляются, а положительные значения остаются без изменений.\n",
    "\n",
    "2. **Отсутствие насыщения в области положительных значений**. В отличие от сигмоиды и гиперболического тангенса, ReLU не насыщается в диапазоне положительных входных значений, а производная остается неизменной. Это может способствовать более эффективному обучению глубоких нейронных сетей.\n",
    "\n",
    "3. **Простота**. ReLU проста в вычислении и программной реализации.\n",
    "\n",
    "4. **Проблема \"умерших\" нейронов**. Нейроны с отрицательными входами имеют нулевой градиент и могут остановить обновление своих весов.\n",
    "\n",
    "Функцию активации ReLU применяют в нейронных сетях в основном в скрытых слоях. Она широко используется во многих архитектурах, доказавших свою эффективность на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Leaky ReLU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaky ReLU (ReLU с «утечкой», название также обусловлено электротехнической аналогией) является простейшей модификацией описанной выше ReLU, призванной исправить проблему \"умирания\" отдельных нейронов. В отличие от ReLU, данная функция не равна константе $0$ при всех отрицательных входных значениях, а реализует в этой области линейную зависимость с небольшим угловым коэффициентом (например, с угловым коэффициентом $10^{-2}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{LeakyReLU}(x, \\alpha)=\\max(\\alpha x,x), \\ \\ \\ \\alpha<1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/activation_function_leaky_relu.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная Leaky ReLU:\n",
    "\n",
    "$$\\large \\frac{d}{dx}\\text{LeakyReLU}(x)=\\frac{d}{dx}\\max(\\alpha x,x)=\\begin{cases}\n",
    "\\displaystyle \\frac{d}{dx}\\alpha x, &\\text{$x<0$} \\\\\n",
    "\\displaystyle \\frac{d}{dx}x, &\\text{$x\\geq0$}\n",
    "\\end{cases}=\n",
    "\\begin{cases}\n",
    "\\alpha, &\\text{$x<0$} \\\\\n",
    "1, &\\text{$x\\geq0$}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] 🛠️ Leaky ReLU в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html):\n",
    "```python\n",
    "torch.nn.LeakyReLU()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.LeakyReLU(0.01)\n",
    "input_values = torch.randn(5)\n",
    "activation_lrelu = activation(input_values)\n",
    "print(f\"input_values: {input_values}\\nactivation_lrelu: {activation_lrelu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeakyReLU имеет следующие свойства:\n",
    "\n",
    "1. **Диапазон значений**. Значения лежат в $(-\\infty, +\\infty)$.\n",
    "\n",
    "2. **Отсутствие насыщения**. Как и ReLU, LeakyReLU не насыщается, что помогает избежать проблемы затухания градиента.\n",
    "\n",
    "3. **Простота**. LeakyReLU проста в вычислении и обратном распространении градиента.\n",
    "\n",
    "4. **Преодоление проблемы \"умерших\" нейронов**. Использование ненулевого наклона для отрицательных значений помогает избежать проблемы \"умерших нейронов\", которая возникает при использовании обычной ReLU.\n",
    "\n",
    "5. **Дополнительный гиперпараметр**. Необходимо выбрать значение для наклона отрицательной части, что может потребовать дополнительного подбора и настройки.\n",
    "\n",
    "Функцию активации LeakyReLU применяют в нейронных сетях в основном в скрытых слоях для предотвращения проблемы \"умерших\" нейронов, особенно в глубоких архитектурах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **GELU (Gaussian Error Linear Unit)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция активации, используемая в трансформерах: Google BERT и OpenAI GPT-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{GELU}(x)=xP(X\\leq x)=x\\Phi(x)=x\\cdot \\frac{1}{2}[1+erf(\\frac{x}{\\sqrt{2}})]$$\n",
    "\n",
    "$$\\large erf(x)=\\frac{2}{\\sqrt{\\pi}}\\int_0^xe^{-t^2}dt$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике GELU может быть приблизительно вычислена так:\n",
    "$$\\large \\text{GELU}(x)\\approx 0.5x(1+\\tanh[\\sqrt{2/\\pi}(x+0.044715x^3)])$$\n",
    "\n",
    "или\n",
    "\n",
    "$$\\large \\text{GELU}(x) \\approx x\\cdot \\sigma(1.702x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/activation_function_gelu.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[doc] 🛠️ GELU в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.GELU.html):\n",
    "```python\n",
    "torch.nn.GELU()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.GELU()\n",
    "input_values = torch.randn(5) * 5\n",
    "activation_gelu = activation(input_values)\n",
    "print(f\"input_values: {input_values}\\nactivation_gelu: {activation_gelu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация функций активации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/animated_activation_functions.png\" width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[blog] ✏️ How Activation Functions Work in Deep Learning](https://www.kdnuggets.com/2022/06/activation-functions-work-deep-learning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Углубление в PyTorch. Пример нейронной сети на MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источник:\n",
    "\n",
    "[[doc] 🛠️ Learn the basics tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset и DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/dataset_dataloader.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительная обработка данных часто сильно зависит от домена, предметной области, самих данных. В идеале мы бы хотели, чтобы код, относящийся к набору данных, был отделен от кода для обучения модели для его лучшей читаемости, понимаемости и модульности.\n",
    "\n",
    "PyTorch предоставляет два базовых класса для работы с данными: `torch.utils.data.DataLoader` и `torch.utils.data.Dataset`, которые позволяют работать как со встроенными наборами данных, так и с вашими собственными данными.\n",
    "\n",
    "`Dataset` хранит в себе объекты (samples, сэмплы) — например, изображения и соответствующие им метки (labels, targets).\n",
    "\n",
    "`DataLoader` представляет из себя итерируемый объект — обертку над `Dataset`-ом, и позволяет получить простой доступ к объектам и меткам из набора данных в виде мини-батчей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотеки из семейства PyTorch предоставляют ряд предзагруженных наборов данных (например, таких как MNIST), которые релизованы как дочерние классы от `torch.utils.data.Dataset` и несут в себе функции, специфичные для конкретных данных. Эти наборы данных могут быть использованы как бенчмарк для отладки и оценки вашей модели или в учебных целях. Вы можете найти их здесь:\n",
    "* [[doc] 🛠️ Image Datasets](https://pytorch.org/vision/stable/datasets.html),\n",
    "* [[doc] 🛠️ Text Datasets](https://pytorch.org/text/stable/datasets.html),\n",
    "* [[doc] 🛠️ Audio Datasets](https://pytorch.org/audio/stable/datasets.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим пример того, как загрузить набор данных MNIST, который содержится в `torchvision.datasets` [🛠️[doc]](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим MNIST, указав следующие параметры:\n",
    "* `root` — путь до директории с данными,\n",
    "* `train` определяет, использовать обучающую или тестовую часть набора данных,\n",
    "* `download=True` позволяет скачать данные из интернета, если их нет в пути `root`,\n",
    "*  `transform` определяет преобразования, которые нужно сделать с данными. Здесь мы сразу указываем `transform=ToTensor()`, чтобы перевести входные данные (изображения) в формат `torch.Tensor`. Подробнее о трансформациях поговорим далее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from IPython.display import clear_output\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"./MNIST\", train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"./MNIST\", train=False, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "clear_output()\n",
    "\n",
    "print(\"Train data info:\\n\", train_data)\n",
    "print(\"\\nTest data info:\\n\", test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы дальнейший код воспроизводился, зафиксируем случайные состояния:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение выборки на обучающую и валидационную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим из обучающей выборки часть данных для **валидации** при помощи функции `random_split` [🛠️[doc]](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split) из модуля `torch.utils.data`.\n",
    "\n",
    "Сумма значений в параметре `lengths` функции `random_split` должна в точности равняться количеству элементов в датасете, который она разделяет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_data, val_data = random_split(train_data, lengths=[50000, 10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `random_split` возвращает объекты класса `Subset`. Эти объекты имеют два основных атрибута:\n",
    "\n",
    "* `dataset` — объект, из которого данный Subset был выделен, он будет один и тот же для всех продуктов функции `random_split`,\n",
    "* `indices` — список индексов, которые попали в данный Subset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Type of train_data: {type(train_data)}\")\n",
    "print(f\"Type of val_data:   {type(val_data)}\\n\")\n",
    "\n",
    "print(f\"Type of train_data.dataset: {type(train_data.dataset)}\")\n",
    "print(f\"Type of val_data.dataset:   {type(val_data.dataset)}\\n\")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"train_data.dataset and val_data.dataset are same: {train_data.dataset is val_data.dataset}\\n\"\n",
    ")\n",
    "\n",
    "print(f\"First 10 indices of train_data: {train_data.indices[:10]}\")\n",
    "print(f\"First 10 indices of val_data:   {val_data.indices[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итерирование по `Dataset` и визуализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно обращаться к элементам `Dataset`-а вручную, как в списках или массивах: `dataset[i]`. При таком обращении мы получим кортеж `(sample, label)`. Воспользуемся библиотекой matplotlib, чтобы отобразить первые 10 изображений из тестового множества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_imgs_to_visualize = 10\n",
    "\n",
    "figure = plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(num_imgs_to_visualize):\n",
    "    # here we indexing the Dataset-object \"as is\" and gettig a tuple (img, label)\n",
    "    img, label = test_data[i]\n",
    "\n",
    "    figure.add_subplot(1, num_imgs_to_visualize, i + 1)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"true: {label}\", fontsize=20)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных для обучения с помощью DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset` возвращает по одной паре \"объект — метка\" за раз. При обучении моделей мы обычно хотим получать обекты в виде мини-батчей, перемешивая данные на каждой эпохе для уменьшения переобучения.\n",
    "\n",
    "`DataLoader` — это объект, который позволяет нам получать такие мини-батчи. При инициализации он принимает в себя объект `Dataset` (или `Subset`), а также параметры `batch_size` (размер мини-батча) и `shuffle` (перемешивать ли данные в батчах каждую эпоху).\n",
    "\n",
    "Другие параметры, а также значения по умолчанию можно посмотреть в документации PyTorch для класса `DataLoader` [🛠️[doc]](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=8, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы разделили данные на обучающие, валидационные и тестовые (`train_data`, `val_data` и `test_data`), то мы создаем также три независимых `DataLoader`-а. Один из них позволит нам получать батчи из обучающей выборки, второй — из валидационной, третий — из тестовой.\n",
    "\n",
    "Обратите внимание на параметр `shuffle`! По умолчанию он имеет значение `False`. **Для обучения нейронной сети критически важно, чтобы во время обучения батчи обучающих данных перемешивались**. Именно таким образом мы вносим **стохастичность** в процесс градиентного спуска. Поэтому для `DataLoader`-a, который будет выдавать батчи для обучения, необходимо использовать `shuffle=True`.\n",
    "\n",
    "В противоположность этому — `DataLoader`-ы для валидационных и тестовых данных. Эти данные данные служат для оценки качества работы модели, на них не происходит обучение и градиентный спуск. Поэтому установка здесь `shuffle=True` не имеет большого смысла."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итерирование по `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы загрузили набор данных в `DataLoader`, и теперь можем проходиться по нему по мере необходимости. Каждая итерация в коде ниже будет возвращать мини-батч в виде кортежа тензоров `(samples, labels)`, содержащих `batch_size=8` объектов и меток соответственно.\n",
    "Так как мы установили для `train_dataloader` параметр `shuffle=True`, когда мы пройдемся по всем батчам, данные перемешаются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one next batch\n",
    "imgs, labels = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Images batch shape: {imgs.size()} : [batch_size, num_channels, H, W]\")\n",
    "print(f\"Labels batch shape: {labels.size()}\")\n",
    "\n",
    "print(\"\\nThe first sample in the batch:\")\n",
    "img = imgs[0].squeeze()\n",
    "label = labels[0].item()\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(label)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Взвешенное формирование батчей для работы с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще одним атрибутом `DataLoader` является `sampler` [🛠️[doc]](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler) — он отвечает за то, как объекты набираются в батчи. **По умолчанию** все объекты могут попадать в батчи **равновероятно**.\n",
    "\n",
    "При работе с несбалансированными классами можно формировать батчи так, чтобы в каждом батче примерно был баланс классов.\n",
    "\n",
    "Это может улучшать сходимость даже в случае небольшого дисбаланса или его отсутствия, т. к. мы будем избегать шаги обучения нейросети, в которых она просто не увидела какого-то класса в силу случайных причин.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/batch_balancing.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При таком подходе требуется, чтобы объекты попадали в батчи **не равновероятно, а с определенными весами**. В PyTorch эту функциональность можно получить, используя класс `WeightedRandomSampler` [🛠️[doc]](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler). Для его инициализации требуется рассчитать вес каждого класса.\n",
    "\n",
    "Сумма весов не обязана быть равна единице, важно только соотношение между весами. Часто соотношение весов делают обратно пропорциональным количеству объектов в классах.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "_, classes_counts = torch.unique(y, return_counts=True)  # y — tensor of labels in train set\n",
    "weights_for_classes = classes_counts.max() / classes_counts\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конструктор `WeightedRandomSampler` требуется подать два аргумента:\n",
    "\n",
    "- список весов для **каждого** элемента в датасете;\n",
    "- количество элементов (можно использовать не весь датасет).\n",
    "\n",
    "Затем созданный `sampler` передается в конструктор `DataLoader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "weight_for_every_sample = []  # Every sample must have a weight\n",
    "for label in y:\n",
    "    weight_for_every_sample.append(weights_for_classes[label].item())\n",
    "\n",
    "sampler = WeightedRandomSampler(torch.tensor(weight_for_every_sample), len(dataset))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда у `DataLoader` указывается `sampler`, последний принимает на себя функцию перемешивания, поэтому параметр `shuffle` **должен** быть не указан.\n",
    "\n",
    "Также отметим, что подобную процедуру взвешенного формирования батчей следует производить только с обучающими данными, но не с валидационными и тестовыми. Мы хотим, чтобы модель при обучении поровну видела объекты всех классов, но оценивать качество нужно на данных с реальным распределением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что нужно быть осторожным со взвешиванием объектов в батчах и **контролировать состав батчей**. Дело в том, что при существенном дисбалансе веса при объектах минорного класса могут оказываться на несколько порядков больше, чем при объектах мажорного класса. Данные веса преобразуются в вероятности для сэмплирования, и может случиться так, что вероятности при объектах мажорного класса станут численно неотличимы от нуля. Тем самым можно получить обратный эффект: батчи будут состоять исключительно из объектов минорного класса. В таком случае нужно намеренно ограничивать веса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Трансформации (Transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные не всегда поступают в том формате, который требуется для работы моделей машинного обучения. Для того, чтобы производить некоторые преобразования с данными, чтобы они становились пригодны для обучения, в PyTorch реализован механизм трансформаций (transforms).\n",
    "\n",
    "Все наборы данных в Torchvision имеют два параметра: `transform` — для применения трансформаций к входным данным, и `target_transform` — соответственно для преобразования меток.\n",
    "Эти параметры принимают в себя вызываемые (callable) объекты, содержащие логику преобразований. Модуль `torchvision.transforms` [🛠️[doc]](https://pytorch.org/vision/stable/transforms.html) предоставляет ряд часто используемых трансформаций \"из коробки\".\n",
    "\n",
    "Важно понимать, что трансформации, указанные в `transform` и `target_transform`, **применяются к данным налету**, то есть в момент обращения к этим данным через `Dataset` или `DataLoader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения в MNIST (и в большинстве других встроенных датасетов) изначально хранятся в формате PIL Image (Python Image Library), а метки представлены как целые числа. Если с метками, представленными таким образом, ничего делать не нужно, то входные данные для обучения необходимо перевести в тензоры. Чтобы произвести эту трансформацию, выше при загрузке данных MNIST мы использовали `torchvision.transforms.ToTensor` [🛠️[doc]](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor).\n",
    "\n",
    "`ToTensor` преобразует PIL Image или NumPy `ndarray` в `FloatTensor` **и масштабирует значения интенсивности пикселей к диапазону $[0., 1.]$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что помимо перевода данных в подходящий формат мы бы хотели произвести какие-то преобразования с самими величинами. Скажем, произвести нормализацию: вычесть математическое ожидание и разделить на стандартное отклонение по выборке. Для проведения такой операции в `torchvision.transforms` предусмотрена трансформация `Normalize` [🛠️[doc]](https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Два обязательных параметра в этой трансформации — это `mean` и `std`:\n",
    "* `mean` — последовательность математических ожиданий по каждому каналу выборки изображений,\n",
    "* `std` — последовательность стандартных отклонений по каждому каналу выборки изображений.\n",
    "\n",
    "`Normalize` не применяется к PIL Image, поэтому ее необходимо применять после `ToTensor`.\n",
    "\n",
    "Давайте вычислим среднее и стандартное отклонение по обучающим данным. Для этого обратимся к `train_data.dataset.data` по индексам, которые попали в Subset `train_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "raw_train_data = train_data.dataset.data[train_data.indices]\n",
    "\n",
    "print(\"Train part of data:\")\n",
    "print(\"Type: \", type(raw_train_data))\n",
    "print(\"Size: \", raw_train_data.size())\n",
    "print(\"Dtype:\", raw_train_data.dtype)\n",
    "print(\"Max:  \", torch.max(raw_train_data).item())\n",
    "print(\"Min:  \", torch.min(raw_train_data).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `train_data.dataset.data` для MNIST данные хранятся как тензор целых чисел (`uint8`) c минимальным значением $0$ и максимальным значением $255$. Функции `torch.mean()` и `torch.std()` выдадут ошибку, если передать им тензор целых чисел. Поэтому изменим тип на вещественный, применив метод `.double()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.mean(raw_train_data.double()).item()\n",
    "std = torch.std(raw_train_data.double()).item()\n",
    "print(f\"mean = {mean:.2f}, std = {std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним, что `Normalize` должна применяться после `ToTensor`, которая масштабирует величины в диапазон $[0., 1.]$. Значит, матожидание и стандартное отклонение мы также должны разделить на максимальное значение до масштабирования — на $255$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean /= 255\n",
    "std /= 255\n",
    "print(f\"Scaled mean = {mean:.2f}, std = {std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы вычислили среднее и стандартное отклонение по обучающей выборке MNIST для применения транcформации `Normalize`. Но мы также помним, что она должна применяться только после `ToTensor`. Как же объединить несколько трансформаций в одну, чтобы они применились последовательно?\n",
    "\n",
    "Для этого предусмотрен класс `torchvision.transforms.Compose` [🛠️[doc]](https://pytorch.org/vision/main/generated/torchvision.transforms.Compose.html). Его единственный параметр — список принимаемых трансформаций. `Compose` — это контейнер для трансформаций, при помещении в который они будут применяться одна за одной. В общем случае их может быть сколько угодно. Давайте напишем трансформацию, которая примет в себя две: `ToTensor` и `Normalize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform_with_normalize = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(mean, std)]\n",
    ")\n",
    "\n",
    "print(transform_with_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остается только подменить у обучающего и тестового датасетов ту трансформацию, которую мы указали при загрузке данных, на нашу новую — с нормализацией. Для этого посмотрим на атрибут `.transform` и изменим его.\n",
    "\n",
    "**Внимание! Неочевидная особенность!**\n",
    "\n",
    "Функция `random_split` возвращает объекты класса `Subset`, которые не имеют своих трансформаций, а используют трансформации, определенные в родительском объекте класса `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Old train and val transform:\", train_data.dataset.transform)\n",
    "print(\"Old test transform:\", test_data.transform)\n",
    "\n",
    "train_data.dataset.transform = transform_with_normalize\n",
    "test_data.transform = transform_with_normalize\n",
    "\n",
    "print(\"\\nNew train and val transform:\", train_data.dataset.transform)\n",
    "print(\"New test transform:\", test_data.transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следует еще раз заметить, что при нормализации мы **вычисляем** оценки математического ожидания и стандартного отклонения `mean` и `std` **на обучающих данных**, а **применяем** вычисленные оценки **и на обучающих, и на валидационных, и на тестовых данных**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь при обращении к данным через `DataLoader` будет происходить следующее:\n",
    "\n",
    "1. Объект `DataLoader` обращается к объекту `Dataset` за данными, чтобы сформировать батч.\n",
    "2. `Dataset` считывает данные, которые хранятся на диске, в формате PIL Image, применяет к ним трансформации, указанные в его атрибуте `.transform` (в данном случае это последовательность `ToTensor` и `Normalize`) и возвращает `DataLoader`-у преобразованные данные.\n",
    "3. `DataLoader` формирует из полученных данных батч и возвращает его."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что на диске по-прежнему лежат просто изображения в своем специальном формате, и их довольно много. Но при этом в каждый момент времени мы не храним на диске все изображения как тензоры в сыром виде или в нормализованном. Нужные операции применяются к данным налету, только когда они нужны — при формировании батчей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейронные сети состоят из слоев, которые производят преобразования над данными. В PyTorch принято называть слои ***модулями*** (modules), и далее мы тоже будем использовать это название.\n",
    "\n",
    "Пространство имен `torch.nn` [🛠️[doc]](https://pytorch.org/docs/stable/nn.html) предоставляет \"строительные блоки\", которые нужны для создания своей собственной нейронной сети. Каждый *модуль* в PyTorch является дочерним классом от `nn.Module` [🛠️[doc]](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). Таким образом, нейронная сеть сама по себе будет являться *модулем*, состоящим из других *модулей* (слоев). Такая вложенная структура позволяет легко создавать сложные архитектуры и управлять ими.\n",
    "\n",
    "Ниже мы рассмотрим пример создания нейронной сети для классификации изображений из набора данных MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор устройства (device) для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы бы хотели иметь возможность обучать модель на аппаратном ускорителе, таком как GPU, если он доступен. Проверим, доступен ли нам ускоритель `torch.cuda` [🛠️[doc]](https://pytorch.org/docs/stable/notes/cuda.html), иначе продолжим вычисления на CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание класса модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы определяем нейронную сеть, наследуясь от класса `nn.Module`, и инициализируем ее слои в методе `__init__`. Каждый класс-наследник `nn.Module` производит операции над входными данными в методе `forward`.\n",
    "\n",
    "Напишем собственную нейронную сеть как класс `NeuralNetwork`. Ниже подробно рассмотрим все составляющие ее части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.layers_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим экземпляр класса `NeuralNetwork`, переместим его на `device` с помощью метода `to` и выведем информацию о структуре модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы использовать модель, мы передаем ей входные данные. Это приводит в действие метод `forward`, а также определенные фоновые операции. Не следует вызывать `model.forward` напрямую!\n",
    "\n",
    "Вызов модели с входными данными возвращает тензор с двумя размерностями: нулевая размерность `dim=0` соответствует  количеству переданных примеров, а первая `dim=1` — десяти выходным \"сырым\" предсказаниям (логитам) для каждого класса.\n",
    "\n",
    "Мы можем получить предсказание модели в виде вероятностей, пропустив логиты через экземпляр модуля `nn.Softmax`, вызвав его вычисление вдоль первой размерности `dim=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random input of 3 images\n",
    "sample_batch = torch.rand(\n",
    "    3, 1, 28, 28, device=device\n",
    ")  # [batch_size, num_channels, H, W]\n",
    "\n",
    "# model output\n",
    "logits = model(sample_batch)\n",
    "\n",
    "# predicted probabilities\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "\n",
    "# predicted classes\n",
    "y_pred = pred_probab.argmax(dim=1)\n",
    "\n",
    "print(f\"Input size:       {sample_batch.size()} : [batch_size, num_channels, H, W]\")\n",
    "print(f\"Output size:      {logits.size()}        : [batch_size, num_classes]\")\n",
    "print(\n",
    "    f\"Predicted class:  {y_pred}          : [class for sample 1, class for sample 2, class for sample 3]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слои модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте заглянем \"под капот\" нашей модели `NeuralNetwork`. Для иллюстрации возьмем мини-батч из трех одноканальных изображений $28×28$ и посмотрим, что с ним происходит, когда мы пропускаем его через сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = torch.rand(3, 1, 28, 28)\n",
    "print(f\"Input size: {sample_batch.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Слой `nn.Flatten`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы используем слой `nn.Flatten` [🛠️[doc]](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) для преобразования каждого изображения $1×28×28$ пикселей в непрерывный массив из $784$ значений (размер батча (на позиции `dim=0`) сохраняется)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(sample_batch)\n",
    "print(f\"Size after Flatten: {flat_image.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Слой `nn.Linear`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейный слой `nn.Linear` [🛠️[doc]](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) — это модуль, который производит линейное преобразование входных данных с помощью хранящихся в нем весов и смещений.\n",
    "\n",
    "Обязательными параметрами при объявлении этого слоя являются `in_features` — количество входных признаков, и `out_features` — количество выходных признаков.\n",
    "\n",
    "Фактически этот модуль добавляет в модель один полносвязный слой нейронов *без активаций*. Слой состоит из `out_features` нейронов, каждый из которых имеет `in_features` входов.\n",
    "\n",
    "В примере ниже мы объявляем слой из $512$ нейронов, каждый из которых получает \"вытянутое\" изображение из $784$ пикселей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.Linear(in_features=784, out_features=512)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(f\"Size after Linear:  {hidden1.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейный слой, в отличие от слоя `nn.Flatten`, имеет обучаемые параметры — веса и смещения. Они хранятся как объекты специального класса `torch.nn.parameter.Parameter` и содержат в себе тензоры собственно с величинами параметров. Получить доступ к ним можно, обратившись к атрибутам слоя `.weight` и `.bias` соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Size of linear layer weights: {layer1.weight.size()}\")\n",
    "print(f\"Type of linear layer weights: {type(layer1.weight)}\")\n",
    "\n",
    "print(f\"\\nSize of linear layer biases: {layer1.bias.size()}\")\n",
    "print(f\"Type of linear layer biases: {type(layer1.bias)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Слой `nn.ReLU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нелинейные активации — это то, что позволяет модели учить сложные взаимосвязи между входом и выходом. Они применяются после линейных преобразований, чтобы ввести *нелинейность*, помогая нейронным сетям изучать самые разные закономерности.\n",
    "\n",
    "В данной модели мы используем `nn.Relu` [🛠️[doc]](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) между линейными слоями, но существуют и реализации [других функций активации 🛠️[doc]](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations1 = nn.ReLU()(hidden1)\n",
    "\n",
    "print(f\"Before ReLU:  {hidden1}\")\n",
    "print(f\"After ReLU:  {activations1}\")\n",
    "print(f\"\\n Size after ReLU:  {activations1.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Объединение модулей в `nn.Sequential`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential` [🛠️[doc]](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) — это упорядоченный контейнер для модулей. Данные проходят через все модули в том же порядке, в котором они определены в `nn.Sequential`. Можно использовать такой контейнер для того, чтобы быстро собрать простую нейронную сеть, как `seq_modules` в примере ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(flatten, layer1, nn.ReLU(), nn.Linear(512, 10))\n",
    "\n",
    "sample_batch = torch.rand(3, 1, 28, 28)\n",
    "logits = seq_modules(sample_batch)\n",
    "\n",
    "print(f\"Output size: {logits.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Слой `nn.Softmax`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последний линейный слой нейронной сети возвращает *логиты* — \"сырые\" значения из диапазона $[-∞; +∞]$, которые могут быть пропущены через модуль `nn.Softmax` [🛠️[doc]](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html). Пропущенные через $\\text{Softmax}$ величины могут восприниматься как вероятности, с которыми модель относит данный объект к тому или иному классу. Параметр `dim` определяет размерность, вдоль которой величины должны суммироваться к $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "pred_probab = softmax(logits)\n",
    "\n",
    "print(f\"Size after Softmax: {pred_probab.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Множество слоев в нейронных сетях имеют *обучаемые параметры*, т. е. имеют ассоциированные с ними веса и смещения, которые оптимизируются во время обучения.\n",
    "\n",
    "Наследование от `nn.Module` автоматически отслеживает все слои, определенные внутри вашего класса модели, и делает все их параметры доступными с помощью методов `model.parameters()` или `model.named_parameters()`.\n",
    "\n",
    "В примере ниже мы проходимся по всем параметрам модели и для каждого тензора параметров выводим его размер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model structure: {model}\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(\n",
    "        f\"Layer: {name:23}  Requires grad: {param.requires_grad}  Size: {param.size()}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы подготовили данные и создали модель, мы можем приступить к обучению.\n",
    "\n",
    "Обучение модели — итеративный процесс оптимизации параметров модели на обучающих данных. На каждой итерции модель получает входные данные, дает предсказание на выходе, вычисляет значение функции потерь (loss), вычисляет производные функции потерь по параметрам и подстраивает параметры, используя градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гиперпараметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметры — это задаваемые разработчиком параметры, которые позволяют управлять процессом обучения. Различные значения гиперпараметров могут влиять на обучение модели и скорость сходимости ([подробнее про подбор гиперпараметров 🛠️[doc]](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)).\n",
    "\n",
    "Мы определим следующие гиперпараметры процедуры обучения:\n",
    "* **количество эпох** (`num_epochs`) — количество итераций обучения по всему набору данных;\n",
    "* **размер батча** (`batch_size`) — количество образцов, передаваемых в сеть для обновления параметров;\n",
    "* **скорость обучения** (`learning_rate`) — коэффициент, определяющий, насколько сильно нужно обновлять параметры модели на каждом батче. Малые значения приводят к долгому обучению, в то время как большие значения могут приводить к непредсказуемому поведению во время обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше для демонстрации мы указывали размер батча в `DataLoader`-ах равным восьми. Для установки нового значения придется переопределить `DataLoader`-ы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация параметров (обучение сети)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задав гиперпараметры, мы можем приступить к обучению модели. Каждая итерация цикла оптимизации называется **эпохой**.\n",
    "\n",
    "Каждая эпоха состоит из двух частей:\n",
    "* **цикл обучения (Train Loop)** — проход по обучающему набору данных и оптимизация параметров;\n",
    "* **цикл валидации (Validation Loop)** — проход по валидационному набору данных и контроль того, что качество работы сети улучшается.\n",
    "\n",
    "Кратко ознакомимся с некоторыми понятиями, используемыми в цикле оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция потерь (Loss function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы решаем задачу классификации со сбалансированным датасетом, выберем `nn.CrossEntropyLoss` [🛠️[doc]](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) в качестве функции потерь.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимизатор (Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизация — это процесс подстройки параметров модели для уменьшения ошибки на каждом шаге обучения. От **алгоритма оптимизации** зависит то, как этот процесс будет выполняться. Здесь мы будем использовать стохастический градиентный спуск (Stochastic Gradient Descent, SGD). Однако в PyTorch реализовано еще [множество других алгоритмов оптимизации 🛠️[doc]](https://pytorch.org/docs/stable/optim.html#algorithms), таких как Adam и RMSProp, и они могут работать лучше или хуже для разных видов моделей и данных.\n",
    "\n",
    "Вся логика оптимизации заключена в объекте `optimizer`. Мы инициализируем оптимизатор, передавая ему параметры модели, которые требуется обучать (`model.parameters()`), а также гиперпараметр скорости обучения (`learning_rate`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри цикла обучения оптимизация производится за три шага:\n",
    "1. Вызов `optimizer.zero_grad()`, чтобы сбросить градиенты параметров модели. По умолчанию градиенты суммируются, и во избежание повторного вычисления их необходимо явно обнулять на каждой итерации;\n",
    "2. Обратное распространение ошибки предсказания с помощью вызова `loss.backward()`. PyTorch вычислит градиенты функции потерь относительно каждого обучаемого параметра;\n",
    "3. Когда у нас есть градиенты, мы вызываем `optimizer.step()`, чтобы подстроить обучаемые параметры с учетом градиентов, посчитанных при обратном распространении, согласно алгоритму оптимизации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы определим две функции:\n",
    "* `train_loop`, которая производит цикл обучения,\n",
    "* `val_loop`, которая оценивает качество модели на валидационных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, criterion, optimizer):\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for imgs, labels in dataloader:\n",
    "        # Compute prediction and loss\n",
    "        pred = model(imgs.to(device))\n",
    "        loss = criterion(pred, labels.to(device))\n",
    "\n",
    "        # Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.detach().item()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    print(f\"Train loss: {train_loss:>8f}\")\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def val_loop(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    val_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dataloader:\n",
    "            # Compute prediction and loss\n",
    "            pred = model(imgs.to(device))\n",
    "            loss = criterion(pred, labels.to(device))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            correct += (pred.argmax(dim=1) == labels.to(device)).sum().item()\n",
    "\n",
    "    val_loss /= num_batches\n",
    "    accuracy = correct / size\n",
    "    print(f\"Val loss: {val_loss:>8f}, val accuracy: {(100*accuracy):>0.1f}% \\n\")\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше мы объявили гиперпараметры и инициализировали функцию потерь `criterion` и оптимизатор `optimizer`. Теперь мы запускаем цикл оптимизации на $10$ эпох, и в каждой итерации мы вызываем функцию для выполнения цикла обучения `train_loop`, а затем функцию для промежуточной оценки качества `val_loop`. Также на каждой эпохе будем сохранять текущее значение функции потерь на обучающих и валидационных данных для построения графика обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "loss_history = {\"train\": [], \"val\": []}\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    print(f\"Epoch {i+1}\")\n",
    "    train_loss = train_loop(train_dataloader, model, criterion, optimizer)\n",
    "    val_loss = val_loop(val_dataloader, model, criterion)\n",
    "\n",
    "    loss_history[\"train\"].append(train_loss)\n",
    "    loss_history[\"val\"].append(val_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график функции потерь на обучающих и на валидационных данных по эпохам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), loss_history[\"train\"], label=\"train\")\n",
    "plt.plot(range(1, num_epochs + 1), loss_history[\"val\"], label=\"val\")\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.ylabel(\"Loss\", fontsize=15)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение и загрузка весов модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно обучение модели является достаточно затратным процессом с точки зрения вычислительных ресурсов. Поэтому однажды обученную сеть разумно будет сохранить для последующего использования. Рассмотрим варианты, как это можно сделать в PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели PyTorch хранят обучаемые параметры во внутреннем словаре состояния, который называется `state_dict`. Их можно сохранить с помощью метода `torch.save`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы загрузить веса модели, сперва необходимо создать экземпляр такой модели, а затем загрузить параметры с помощью метода `load_state_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный способ сохранения модели подходит только для случая, когда в дальнейшем не предполагается продолжать обучать модель. Для продолжения обучения также необходимо как минимум сохранять состояние оптимизатора.\n",
    "\n",
    "[[doc] 🛠️ О более общем сохранении состояний модели, оптимизатора и других объектов](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение в общем случае может выглядеть так:\n",
    "\n",
    "```\n",
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss_history': loss_history,\n",
    "            ...\n",
    "            }, PATH)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Предсказания обученной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтапно пропустим тестовые изображения через модель и визуализируем результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get batch\n",
    "imgs, labels = next(iter(test_dataloader))\n",
    "print(\"imgs shape: \", imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get output\n",
    "pred = model(imgs.to(device))\n",
    "print(\"pred shape: \", pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred = pred[:10].detach()\n",
    "print(\"Prediction(1 sample):\\n\", pred[0])\n",
    "\n",
    "digits = np.argmax(pred.cpu().numpy(), axis=1)\n",
    "print(\"Predicted class: \", digits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove axis\n",
    "imgs = torch.squeeze(imgs)\n",
    "print(\"imgs shape (after squeeze): \", imgs.shape)\n",
    "\n",
    "# take 10 first images\n",
    "imgs = imgs[:10]\n",
    "print(\"imgs shape: \", imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем изображения, подпишем предсказанное и истинное значение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25.0, 25.0))\n",
    "for i in range(10):\n",
    "    img = imgs[i]\n",
    "\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.title(\n",
    "        f\"true: {labels[i].numpy()}\\npred: {digits[i]}\", fontsize=20\n",
    "    )  # predicted and real values\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>Литература</font>\n",
    "\n",
    "<font size=5>Многослойные нейронные сети:</font>\n",
    "\n",
    "* [[demo] 🎮 Интерактивный тренажер от TensorFlow ](http://playground.tensorflow.org/#activation=linear&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.1&regularizationRate=0&noise=0&networkShape=&seed=0.62952&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
    "* [[wiki] 📚 Теорема Цыбенко](https://ru.wikipedia.org/wiki/Теорема_Цыбенко)\n",
    "* [[book] 📚 Neural Networks and Deep Learning: визуальное доказательство теоремы об универсальной аппроксимации](http://neuralnetworksanddeeplearning.com/chap4.html)\n",
    "\n",
    "<font size=5>Обучение нейронной сети:</font>\n",
    "\n",
    "* [[blog] ✏️ ML: Вычислительный граф](https://qudata.com/ml/ru/ML_Comp_Graph.html)\n",
    "* [[blog] ✏️ Обзор функций потерь в PyTorch с примером написания своей собственной функции (custom loss function)](https://neptune.ai/blog/pytorch-loss-functions)\n",
    "* [[colab] 🥨 Подробное рассмотрение Focal Loss с примерами](https://colab.research.google.com/drive/1rM7zRySu8WulXbFiXzxBGVzILxvQ6K4A)\n",
    "* [[arxiv] 🎓 Focal Loss for Dense Object Detection (Lin et al., 2017)](https://arxiv.org/abs/1708.02002)\n",
    "* [[blog] ✏️ Объяснение Negative Log Likelihood Loss](https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/)\n",
    "* [[blog] ✏️ О соотношении Cross-Entropy Loss и Negative Log Likelihood Loss](https://jamesmccaffrey.wordpress.com/2020/06/11/pytorch-crossentropyloss-vs-nllloss-cross-entropy-loss-vs-negative-log-likelihood-loss/)\n",
    "* [[blog] ✏️ How Activation Functions Work in Deep Learning](https://www.kdnuggets.com/2022/06/activation-functions-work-deep-learning.html)\n",
    "\n",
    "<font size=5>Углубление в PyTorch. Пример нейронной сети на MNIST:</font>\n",
    "* [[doc] 🛠️ PyTorch: Learn the basics tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
    "* [[video] 📺 Плей-лист с объяснением базовых принципов нейронных сетей от 3Blue1Brown](https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&si=O3gq6RoIxoNS6iJf) [[озвучка на русском](https://youtube.com/playlist?list=PLZjXXN70PH5itkSPe6LTS-yPyl5soOovc&si=ElKVi98Ui4m2nJKq)]\n",
    "* [[doc] 🛠️ PyTorch: Сохранение состояний модели, оптимизатора и других объектов](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training)\n",
    "\n",
    "<font size=5>Дополнительно:</font>\n",
    "* [[wiki] 📚 Теорема об универсальной аппроксимации](https://en.wikipedia.org/wiki/Universal_approximation_theorem)\n",
    "* [[book] 📚 Deep Learning](https://www.deeplearningbook.org/)\n",
    " * [[book] 📚 Part 2, Chapter 6: Deep Feedforward Networks](https://www.deeplearningbook.org/contents/mlp.html)\n",
    "* [[demo] 🎮 Интерактивное и визуальное объяснение работы многослойных нейронных сетей](https://mlu-explain.github.io/neural-networks/)\n",
    "* [[demo] 🎮 Интерактивная визуализация ландшафтов функций потерь в нейронных сетях](https://losslandscape.com/explorer)\n",
    "* [[blog] ✏️ The 7 Most Common Machine Learning Loss Functions](https://builtin.com/machine-learning/common-loss-functions)\n",
    "* [[blog] ✏️ Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss and all those confusing names](https://gombru.github.io/2018/05/23/cross_entropy_loss/)\n",
    "* Курс А. Г. Дьяконова \"Глубокое обучение\". Лекции по PyTorch:\n",
    " * [[video] 📺 часть 1](https://www.youtube.com/watch?v=tDJnwc8Hioc)\n",
    " * [[video] 📺 часть 2](https://www.youtube.com/watch?v=c3y--ydWku0)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
