{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение на малом объеме данных. 7 (перенесла сюда), 10, 11 лекция\n",
    "\n",
    "Transfer learning, Augmentation. One-shot learning. Кластеризация (embedding, one-shot learning - ПРИМЕР С ЛИЦАМИ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм распознавания образов обучающийся с одного раза (One-Shot learning)\n",
    "\n",
    "https://habr.com/ru/post/414425/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как решить проблему меньшего количества данных?\n",
    "\n",
    "источник: https://towardsdatascience.com/breaking-the-curse-of-small-datasets-in-machine-learning-part-1-36f28b0c044d\n",
    "перевод - яндекс, могу окультурить "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_33.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На приведенном выше рисунке предпринята попытка охватить основные проблемы, с которыми приходится сталкиваться при работе с небольшими наборами данных, а также возможные подходы и методы их решения. В этой части мы сосредоточимся только на методах, используемых в традиционном машинном обучении, а остальное будет обсуждаться в части 2 блога."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а) Изменение функции потерь: Для задач классификации мы часто используем кросс-энтропийные потери и редко используем среднюю абсолютную ошибку или среднеквадратичную ошибку для обучения и оптимизации нашей модели. В случае несбалансированных данных модель становится более смещенной в сторону класса большинства, поскольку она оказывает большее влияние на конечное значение потерь, и наша модель становится менее полезной. В таких сценариях мы можем добавить веса к потерям, соответствующим различным классам, чтобы выровнять это смещение данных. Например, если у нас есть два класса с данными в соотношении 4:1, мы можем применить веса в соотношении 1:4 к вычислению функции потерь, чтобы сделать данные сбалансированными. Этот метод помогает нам легко смягчить проблему несбалансированных данных и улучшает обобщение моделей в различных классах. Мы можем легко найти библиотеки как в R, так и в Python, которые могут помочь в присвоении весов классам при расчете потерь и оптимизации. Scikit-learn имеет удобную функцию полезности для вычисления весов на основе частот классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train),y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем избежать приведенного выше вычисления, используя class_weight=`balanced`, который выполняет те же вычисления, чтобы найти class_weights. Мы также можем подавать явные веса классов в соответствии с нашими требованиями. Для получения более подробной информации обратитесь к документации Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create decision tree classifer object\n",
    "clf = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "\n",
    "# Train model\n",
    "model = clf.fit(X_std, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "б) Обнаружение аномалий/изменений: В случаях сильно несбалансированных наборов данных, таких как мошенничество или отказ машины, стоит задуматься, можно ли рассматривать такие примеры как Аномалии или нет. Если данная задача удовлетворяет критерию аномальности, то мы можем использовать такие модели, как SVM Одного класса, методы кластеризации или методы обнаружения гауссовых аномалий. Эти методы требуют сдвига в мышлении, когда мы рассматриваем младший класс как класс выбросов, который может помочь нам найти новые способы разделения и классификации. Обнаружение изменений аналогично обнаружению аномалий, за исключением того, что мы ищем изменение или различие вместо аномалии. Это могут быть изменения в поведении пользователя, наблюдаемые с помощью шаблонов использования или банковских транзакций. Пожалуйста, обратитесь к следующей документации, чтобы узнать, как реализовать обнаружение аномалий с помощью Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_34.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в) Восходящая выборка или нисходящая выборка: Поскольку несбалансированные данные по своей сути наказывают класс большинства с разным весом по сравнению с классом меньшинства, одно из решений проблемы состоит в том, чтобы сделать данные сбалансированными. Это может быть сделано либо путем увеличения частоты класса меньшинства, либо путем уменьшения частоты класса большинства с помощью методов случайной или кластерной выборки. Выбор передискретизации против недискретизации и случайной против кластеризации определяется бизнес-контекстом и размером данных. Как правило, повышающая дискретизация предпочтительна, когда общий размер данных невелик, в то время как понижающая дискретизация полезна, когда у нас есть большой объем данных. Аналогично, случайная или кластеризованная выборка определяется тем, насколько хорошо распределены данные. Для более подробного понимания, пожалуйста, обратитесь к следующему блогу. Повторная выборка может быть легко выполнена с помощью пакета imdb learn, как показано ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "г) Генерировать синтетические данные: Хотя повышающая или понижающая дискретизация помогает сделать данные сбалансированными, дублирование данных увеличивает вероятность переоснащения. Другой подход к решению этой проблемы заключается в создании синтетических данных с помощью данных о меньшинствах. Метод синтетической передискретизации меньшинства (SMOTE) и Модифицированный SMOTE - это два таких метода, которые генерируют синтетические данные. Проще говоря, SMOTE берет точки данных миноритарного класса и создает новые точки данных, которые лежат между любыми двумя ближайшими точками данных, соединенными прямой линией. Для этого алгоритм вычисляет расстояние между двумя точками данных в пространстве признаков, умножает расстояние на случайное число от 0 до 1 и помещает новую точку данных на это новое расстояние от одной из точек данных, используемых для вычисления расстояния. Обратите внимание, что число ближайших соседей, рассматриваемых для генерации данных, также является гиперпараметром и может быть изменено в зависимости от требований."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_35.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M-SMOTE представляет собой модифицированную версию SMOTE который берет лежащее в основе распределение меньшинством во внимание. Этот алгоритм классифицирует выборки классов меньшинств на 3 различные группы — образцы безопасности/Безопасности, Пограничные выборки и скрытые шумовые выборки. Это делается путем вычисления расстояний между выборками класса меньшинства и выборками обучающих данных. В отличие от SMOTE, алгоритм случайным образом выбирает точку данных из k ближайших соседей для выборки безопасности, выбирает ближайшего соседа из граничных выборок и ничего не делает для скрытого шума. Для более подробного понимания обратитесь к блогу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "д) Методы ансамблирования: Идея объединения нескольких слабых учащихся/различных моделей показала отличные результаты при работе с несбалансированными наборами данных. Как методы упаковки в мешки, так и методы повышения эффективности показали отличные результаты в различных задачах и должны быть изучены вместе с методами, рассмотренными выше, чтобы получить лучшие результаты. В попытке ограничить длину этого блога я не буду обсуждать эти методы, но для детального понимания различных методов ансамблирования и того, как использовать их для несбалансированных данных, пожалуйста, обратитесь к следующему блогу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "В этой части мы увидели, что размер данных может проявлять проблемы, связанные с обобщением, дисбалансом данных и трудностями в достижении глобального оптимума. Мы рассмотрели несколько наиболее часто используемых методов решения таких проблем для традиционных алгоритмов машинного обучения. Один или несколько из вышеперечисленных методов могут быть хорошей отправной точкой в зависимости от конкретной бизнес-задачи. Чтобы сохранить блог коротким, я не очень подробно описал многие из этих техник, но есть много замечательных ресурсов в Интернете, которые очень подробно описывают вышеперечисленные техники. В части 2 мы обсудим, как малый набор данных препятствует процессу обучения в моделях глубокого обучения и различные способы его преодоления."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## По Ганичеву (7 лекция)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Подготовка данных (Data Preprocessing)\n",
    "2. Инициализация весов (Weight Initialization)\n",
    "3. Обучение (Optimization)*\n",
    "4. Пакетная нормализация (Batch Normalization)\n",
    "5. Переобучение (Overfitting)*:\n",
    "Регуляризация, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_4.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_4.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_5.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_6.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_7.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_7.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_8.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_9.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_10.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_11.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_12.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_14.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_15.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_16.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_17.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_18.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_19.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_20.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_21.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_22.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_23.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_24.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_25.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_26.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_27.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_28.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_29.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_30.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_31.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_32.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_33.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДОПИНФОРМАЦИЯЯЯЯЯЯЯЯЯЯЯЯЯЯЯЯЯЯЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning: как быстро обучить нейросеть на своих данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "источник: https://habr.com/ru/company/binarydistrict/blog/428255/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если перед нами встает задача распознавания изображений, можно воспользоваться готовым сервисом. Однако, если нужно обучить модель на собственном наборе данных, то придется делать это самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для таких типовых задач, как классификация изображений, можно воспользоваться готовой архитектурой (AlexNet, VGG, Inception, ResNet и т.д.) и обучить нейросеть на своих данных. Реализации таких сетей с помощью различных фреймворков уже существуют, так что на данном этапе можно использовать одну из них как черный ящик, не вникая глубоко в принцип её работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, глубокие нейронные сети требовательны к большим объемам данных для сходимости обучения. И зачастую в нашей частной задаче недостаточно данных для того, чтобы хорошо натренировать все слои нейросети. Transfer Learning решает эту проблему."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning для классификации изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейронные сети, которые используются для классификации, как правило, содержат N выходных нейронов в последнем слое, где N — это количество классов. Такой выходной вектор трактуется как набор вероятностей принадлежности к классу. В нашей задаче распознавания изображений еды количество классов может отличаться от того, которое было в исходном датасете. В таком случае нам придётся полностью выкинуть этот последний слой и поставить новый, с нужным количеством выходных нейронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_0.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зачастую в конце классификационных сетей используется полносвязный слой. Так как мы заменили этот слой, использовать предобученные веса для него уже не получится. Придется тренировать его с нуля, инициализировав его веса случайными значениями. Веса для всех остальных слоев мы загружаем из предобученного снэпшота."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют различные стратегии дообучения модели. Мы воспользуемся следующей: будем тренировать всю сеть из конца в конец (end-to-end), а предобученные веса не будем фиксировать, чтобы дать им немного скорректироваться и подстроиться под наши данные. Такой процесс называется тонкой настройкой (fine-tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Структурные компоненты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи нам понадобятся следующие компоненты:\n",
    "\n",
    "1. Описание модели нейросети\n",
    "2. Пайплайн обучения\n",
    "3. Инференс пайплайн\n",
    "4. Предобученные веса для этой модели\n",
    "5. Данные для обучения и валидации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем примере компоненты (1), (2) и (3) я буду брать из собственного репозитория, который содержит максимально легковесный код — при желании с ним можно легко разобраться. Наш пример будет реализован на популярном фреймворке TensorFlow. Предобученные веса (4), подходящие под выбранный фреймворк, можно найти, если они соответствуют одной из классических архитектур. В качестве датасета (5) для демонстрации я возьму Food-101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве модели воспользуемся классической нейросетью VGG (точнее, VGG19). Несмотря на некоторые недостатки, эта модель демонстрирует довольно высокое качество. Кроме того, она легко поддается анализу. На TensorFlow Slim описание модели выглядит достаточно компактно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "def vgg_19(inputs,\n",
    "           num_classes,\n",
    "           is_training,\n",
    "           scope='vgg_19',\n",
    "           weight_decay=0.0005):\n",
    "    with slim.arg_scope([slim.conv2d],\n",
    "                activation_fn=tf.nn.relu,\n",
    "                weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "                biases_initializer=tf.zeros_initializer(),\n",
    "                padding='SAME'):\n",
    "        with tf.variable_scope(scope, 'vgg_19', [inputs]):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            # Use conv2d instead of fully_connected layers\n",
    "            net = slim.conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')\n",
    "            net = slim.dropout(net, 0.5, is_training=is_training, scope='drop6')\n",
    "            net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "            net = slim.dropout(net, 0.5, is_training=is_training, scope='drop7')\n",
    "            net = slim.conv2d(net, num_classes, [1, 1], scope='fc8',\n",
    "                activation_fn=None)\n",
    "            net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код обучения модели состоит из следующих шагов:\n",
    "\n",
    "1. Построение train/validation пайплайнов данных\n",
    "2. Построение train/validation графов (сетей)\n",
    "3. Надстраивание классификационной функция потерь (cross entropy loss) поверх train графа\n",
    "4. Код, необходимый для вычисления точности предсказания на валидационной выборке во время обучения\n",
    "5. Логика загрузки предобученных весов из снэпшота\n",
    "6. Создание различных структур для обучения\n",
    "7. Непосредственно сам цикл обучения (итерационная оптимизация)\n",
    "\n",
    "Последний слой графа конструируется с нужным нам количеством нейронов и исключается из списка параметров, загружаемых из предобученного снэпшота.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "import model\n",
    "import data\n",
    "\n",
    "###########################################################\n",
    "###  Settings\n",
    "###########################################################\n",
    "\n",
    "INPUT_SIZE = 224\n",
    "RANDOM_CROP_MARGIN = 10\n",
    "TRAIN_EPOCHS = 20\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "VAL_BATCH_SIZE = 128\n",
    "LR_START = 0.001\n",
    "LR_END = LR_START / 1e4\n",
    "MOMENTUM = 0.9\n",
    "VGG_PRETRAINED_CKPT = 'data/vgg_19.ckpt'\n",
    "CHECKPOINT_DIR = 'checkpoints/vgg19_food'\n",
    "LOG_LOSS_EVERY = 10\n",
    "CALC_ACC_EVERY = 500\n",
    "\n",
    "###########################################################\n",
    "###  Build training and validation data pipelines\n",
    "###########################################################\n",
    "\n",
    "train_ds, train_iters = data.train_dataset(train_data,\n",
    "    TRAIN_BATCH_SIZE, TRAIN_EPOCHS, INPUT_SIZE, RANDOM_CROP_MARGIN)\n",
    "train_ds_iterator = train_ds.make_one_shot_iterator()\n",
    "train_x, train_y = train_ds_iterator.get_next()\n",
    "\n",
    "val_ds, val_iters = data.val_dataset(val_data,\n",
    "    VAL_BATCH_SIZE, INPUT_SIZE)\n",
    "val_ds_iterator = val_ds.make_initializable_iterator()\n",
    "val_x, val_y = val_ds_iterator.get_next()\n",
    "\n",
    "###########################################################\n",
    "###  Construct training and validation graphs\n",
    "###########################################################\n",
    "\n",
    "with tf.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "    train_logits = model.vgg_19(train_x, num_classes, is_training=True)\n",
    "    val_logits = model.vgg_19(val_x, num_classes, is_training=False)\n",
    "\n",
    "###########################################################\n",
    "###  Construct training loss\n",
    "###########################################################\n",
    "\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "    labels=train_y, logits=train_logits)\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "###########################################################\n",
    "###  Construct validation accuracy\n",
    "###  and related functions\n",
    "###########################################################\n",
    "\n",
    "def calc_accuracy(sess, val_logits, val_y, val_iters):\n",
    "    acc_total = 0.0\n",
    "    acc_denom = 0\n",
    "    for i in range(val_iters):\n",
    "        logits, y = sess.run((val_logits, val_y))\n",
    "        y_pred = np.argmax(logits, axis=1)\n",
    "        correct = np.count_nonzero(y == y_pred)\n",
    "        acc_denom += y_pred.shape[0]\n",
    "        acc_total += float(correct)\n",
    "        tf.logging.info('Validating batch [{} / {}] correct = {}'.format(\n",
    "            i, val_iters, correct))\n",
    "    acc_total /= acc_denom\n",
    "    return acc_total\n",
    "\n",
    "def accuracy_summary(sess, acc_value, iteration):\n",
    "    acc_summary = tf.Summary()\n",
    "    acc_summary.value.add(tag=\"accuracy\", simple_value=acc_value)\n",
    "    sess._hooks[1]._summary_writer.add_summary(acc_summary, iteration)\n",
    "\n",
    "###########################################################\n",
    "###  Define set of VGG variables to restore\n",
    "###  Create the Restorer\n",
    "###  Define init callback (used by monitored session)\n",
    "###########################################################\n",
    "\n",
    "vars_to_restore = tf.contrib.framework.get_variables_to_restore(\n",
    "    exclude=['vgg_19/fc8'])\n",
    "vgg_restorer = tf.train.Saver(vars_to_restore)\n",
    "\n",
    "def init_fn(scaffold, sess):\n",
    "    vgg_restorer.restore(sess, VGG_PRETRAINED_CKPT)\n",
    "\n",
    "###########################################################\n",
    "###  Create various training structures\n",
    "###########################################################\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "lr = tf.train.polynomial_decay(LR_START, global_step, train_iters, LR_END)\n",
    "tf.summary.scalar('learning_rate', lr)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=MOMENTUM)\n",
    "training_op = slim.learning.create_train_op(\n",
    "    loss, optimizer, global_step=global_step)\n",
    "scaffold = tf.train.Scaffold(init_fn=init_fn)\n",
    "\n",
    "###########################################################\n",
    "###  Create monitored session\n",
    "###  Run training loop\n",
    "###########################################################\n",
    "\n",
    "with tf.train.MonitoredTrainingSession(checkpoint_dir=CHECKPOINT_DIR,\n",
    "                                       save_checkpoint_secs=600,\n",
    "                                       save_summaries_steps=30,\n",
    "                                       scaffold=scaffold) as sess:\n",
    "    start_iter = sess.run(global_step)\n",
    "    for iteration in range(start_iter, train_iters):\n",
    "\n",
    "        # Gradient Descent\n",
    "        loss_value = sess.run(training_op)\n",
    "\n",
    "        # Loss logging\n",
    "        if iteration % LOG_LOSS_EVERY == 0:\n",
    "            tf.logging.info('[{} / {}] Loss = {}'.format(\n",
    "                iteration, train_iters, loss_value))\n",
    "\n",
    "        # Accuracy logging\n",
    "        if iteration % CALC_ACC_EVERY == 0:\n",
    "            sess.run(val_ds_iterator.initializer)\n",
    "            acc_value = calc_accuracy(sess, val_logits, val_y, val_iters)\n",
    "            accuracy_summary(sess, acc_value, iteration)\n",
    "            tf.logging.info('[{} / {}] Validation accuracy = {}'.format(\n",
    "                iteration, train_iters, acc_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После запуска обучения можно посмотреть на его ход с помощью утилиты TensorBoard, которая поставляется в комплекте с TensorFlow и служит для визуализации различных метрик и других параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конце обучения в TensorBoard мы наблюдаем практически идеальную картину: снижение Train loss и рост Validation Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате мы получаем сохранённый снэпшот в checkpoints/vgg19_food, который будем использовать во время тестирования нашей модели (inference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЕСЛИ ЭТО АКТУАЛЬНО, МОЖНО ДОБАВИТЬ ЕЩЕ ИЗ ТОЙ ЖЕ СТАТЬИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_0.png\" width=\"700\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
