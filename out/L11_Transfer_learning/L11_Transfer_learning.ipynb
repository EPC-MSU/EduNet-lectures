{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGxG39mYIlfM"
   },
   "source": [
    "## ResNet + CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWLDU1Fd6jdj"
   },
   "source": [
    "Как получить 90%+ точности для Resnet\n",
    "...\n",
    "\n",
    "\n",
    "Augmentation  + manual decrease LR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omOba3tRJlYP"
   },
   "source": [
    "#Работа с реальными данными\n",
    "\n",
    "Проблемы:\n",
    "\n",
    "- нехватка данных\n",
    "- недостаток размеченных данных\n",
    "- не качественная разметка\n",
    "- не сбалансированность датасета\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHbsUCAoMOu-"
   },
   "source": [
    "### ImageFolder\n",
    "\n",
    "Создадим датасет из своих данных для этого достаточно разложить изображения по папкам и использовать класс ImgeFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BowKHdTdOu1j"
   },
   "outputs": [],
   "source": [
    "!wget  http://fmb.images.gan4x4.ru/hse/bt_dataset3.zip\n",
    "!unzip -q bt_dataset3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IWj1Jh1aO-a"
   },
   "outputs": [],
   "source": [
    "!ls bike/bike_type/train\n",
    "!ls bike/bike_type/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mys34WshO6WO"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_dataset = ImageFolder(\"/content/bike/bike_type/train\")\n",
    "val_dataset = ImageFolder(\"/content/bike/bike_type/val\")\n",
    "\n",
    "fig=plt.figure(figsize=(24, 6))\n",
    "for i in range(1, 2*7 +1):\n",
    "    img = val_dataset[i][0]\n",
    "    fig.add_subplot(2, 7, i)\n",
    "    plt.imshow(np.asarray(img))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rG99u7mUSAU"
   },
   "source": [
    "Обратите внимание: на многих кадрах один и тот же велосипед. Хорошо ли это? Что будет если часть кадров попадет в обучающую, а часть в теренировочную выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhKflMW1ONDd"
   },
   "source": [
    "##Дисбаланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsqLYU2RZLxh"
   },
   "outputs": [],
   "source": [
    "print(\"Classes: \",val_dataset.classes)\n",
    "print(\"Sizes train:\",len(train_dataset), 'val', len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQPtyPT1aAaj"
   },
   "source": [
    "У imageFolder есть свойство classes которое запослняется в соответствии с названиями папок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0DqyPvSZ_az"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def class_hist(dataset):\n",
    "  plt.figure() \n",
    "  unique, counts = np.unique(dataset.targets, return_counts=True)\n",
    "  ax = plt.bar(unique, counts)\n",
    "  plt.title('Train objects')\n",
    "  plt.xticks(unique, dataset.classes)\n",
    "  plt.show()\n",
    "  return counts\n",
    "\n",
    "class_hist(train_dataset)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfhikz0Wcs-7"
   },
   "source": [
    "Что делать?\n",
    "\n",
    "1. Использовать адекватные метрики:\n",
    "- F1_score\n",
    "- PR_Curve\n",
    "- Confusion matrix\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# targets and preds must be calculated during training\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(targets, preds))\n",
    "\n",
    "conf_matrix.columns = dataset_val.classes\n",
    "conf_matrix.index = dataset_val.classes\n",
    "\n",
    "conf_matrix = conf_matrix.rename_axis('Real')\n",
    "conf_matrix = conf_matrix.rename_axis('Predicted', axis='columns')\n",
    "\n",
    "conf_matrix\n",
    "```\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/gan/conf_matrix.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ8WCMRYe_Gw"
   },
   "source": [
    "### Использовать веса в Loss - функции\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html?highlight=crossentropy#torch.nn.CrossEntropyLoss\n",
    "\n",
    "Как следует из описания к CrossEntropyLoss можно добавить веса классов. Сравним loss для с весам и без для оних и тех же данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ap11JzLufjFL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# Without weights\n",
    "scores = torch.tensor([[2.,30.],[2.,30.]]) # Scores for two samples batch\n",
    "target = torch.tensor([0,1]) # First sample belongs to class 0 second to 1 and firse was misclassified\n",
    "weights = torch.tensor([1,1],dtype = torch.float32)\n",
    "criterion = torch.nn.CrossEntropyLoss( weight = weights,reduction = 'mean')  #'mean'\n",
    "criterion(scores,target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLfxNumPhtPX"
   },
   "source": [
    "Добавим к первому классу вес 10. Это условно соответствует ситуации с BMX велосипедами в нашем датасете: их примерно в 10 раз больше чем MTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8r3WiFghZ3e"
   },
   "outputs": [],
   "source": [
    "weights = torch.tensor([10,1],dtype = torch.float32)\n",
    "criterion = torch.nn.CrossEntropyLoss( weight = weights,reduction = 'mean')  #'mean'\n",
    "criterion(scores,target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pfj8fhAeiDr1"
   },
   "source": [
    "Лосс вырос так как класс на котором возникла ошибка оказался редким."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv8qFZiwibqL"
   },
   "source": [
    "Рассчет весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "to5vboMHiddC"
   },
   "outputs": [],
   "source": [
    "#numpy\n",
    "import numpy as np\n",
    "_, counts = np.unique(train_dataset.targets, return_counts=True)\n",
    "weights= np.max(counts) / counts\n",
    "weights = torch.FloatTensor(weights)\n",
    "print('Веса классов: ', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdu1W-xwi0jc"
   },
   "outputs": [],
   "source": [
    "#torch\n",
    "# https://pytorch.org/docs/stable/generated/torch.unique.html\n",
    "_, counts = torch.unique(torch.tensor(train_dataset.targets),return_counts = True)\n",
    "print(counts.max())\n",
    "weights = counts.max() / counts\n",
    "print('Классы: ',train_dataset.classes)\n",
    "print('Веса классов: ', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Yk9OFyTkVK7"
   },
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html\n",
    "from sklearn.utils import class_weight\n",
    "weights = class_weight.compute_class_weight('balanced',np.unique(train_dataset.targets),train_dataset.targets)\n",
    "print(weights)\n",
    "weights / min(weights) # The same as before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7bvuwq_qb9G"
   },
   "source": [
    "#### Выборка с повышением или с понижением (Up-sample or Down-sample): одно из решений проблемы - сбалансировать данные.\n",
    "\n",
    "  \n",
    "\n",
    "```\n",
    "  Это может быть сделано либо за счет увеличения частоты класса меньшинства, либо за счет уменьшения частоты класса большинства с помощью методов случайной или кластерной выборки.\n",
    "\n",
    "    Выбор между избыточной или недостаточной выборкой и случайным или кластеризованным определяется бизнес-контекстом и размером данных.\n",
    "\n",
    "    Обычно `upsampling` предпочтителен, когда общий размер данных небольшой, а понижающая дискретизация полезна, когда у нас есть большой объем данных. Точно так же случайная или кластерная выборка определяется тем, насколько хорошо распределены данные.\n",
    "```\n",
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_34.png\" width=\"600\">\n",
    "\n",
    "Фактически мы либо удаляем часть объектов одного из классов либо копируем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAtwOmchIxWm"
   },
   "source": [
    "## Недостаток данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jImgxrC_bH8U"
   },
   "outputs": [],
   "source": [
    "class_hist(val_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXj75eeecay8"
   },
   "source": [
    "На 3-х изображениях мы не сможем оценить точность. Давайте на них посмотрим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSzqZLdhrMvq"
   },
   "source": [
    "Очевидно что выкидывать тут уже нечего, и 100 копий одного велосипеда не решат проблемму. В данном случае можно переместить несколько велосипедов из тренировочной выборки в валидационную но поблему дефицита BMX-ов в целом это не решит. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2lk1xbUrm5m"
   },
   "source": [
    "#### Генерация синтетических данных:\n",
    "\n",
    " хотя `upsampling` или `downsampling` помогает сбалансировать данные, дублирование данных увеличивает вероятность переобучения.\n",
    "\n",
    "Другой подход к решению этой проблемы - создание синтетических данных с помощью данных о классе меньшинств.\n",
    "\n",
    "Для табличных данных можно использовать методы \n",
    "\n",
    "[Synthetic Minority Over-sampling Technique (SMOTE)](https://rikunert.com/SMOTE_explained) или Modified- SMOTE - два таких метода, которые генерируют синтетические данные.\n",
    "\n",
    "Проще говоря, SMOTE берет точки данных класса меньшинства и создает новые точки данных, которые лежат между любыми двумя ближайшими точками данных, соединенными прямой линией.\n",
    "\n",
    "Для этого алгоритм вычисляет расстояние между двумя точками данных в пространстве признаков, умножает расстояние на случайное число от 0 до 1 и помещает новую точку данных на этом новом расстоянии от одной из точек данных, используемых для определения расстояния.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_35.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaTJM2vgI-o2"
   },
   "source": [
    "## Аугментации\n",
    "\n",
    "Применяются для изображений с той же целью: получить дополнительные данные. \n",
    "\n",
    "Сам термин пришел из музыки:\n",
    "\n",
    "Аугмента́ция (позднелат. augmentatio — увеличение, расширение) — техника ритмической композиции в старинной музыке.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_12.png\" width=\"700\">\n",
    "\n",
    "Собственно механизм трансформаций torcvision который мы использовали с первого занятия, в основном предназначен для аугментации данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPmrnebytZi-"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyx8C7y_uw4k"
   },
   "source": [
    "#### Создание собственных аугментаций\n",
    "\n",
    "В том числе могут применяться в том числе  и к меткам!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShF2cngdwy92"
   },
   "source": [
    "#### Целесообразность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKIS463qt5XG"
   },
   "source": [
    "#### Применение большого количества аугментаций может испортить изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZBccNOkt45Z"
   },
   "outputs": [],
   "source": [
    "RandomChoice и/или RandomOrder из torchvision.transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79DlFEH_uUmf"
   },
   "source": [
    "#### Аугментация как регуляризация\n",
    "- помогает бороться с переобучением\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-M5GN22MoBf"
   },
   "source": [
    "#### Albumentation\n",
    "\n",
    "https://github.com/albumentations-team/albumentations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyVxVVd1M0OZ"
   },
   "source": [
    "### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gh8SM1YxJDwX"
   },
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsHOgoMgZza4"
   },
   "source": [
    "Для таких типовых задач, как классификация изображений, можно воспользоваться готовой архитектурой (AlexNet, VGG, Inception, ResNet и т.д.) и обучить нейросеть на своих данных. Реализации таких сетей с помощью различных фреймворков уже существуют, так что на данном этапе можно использовать одну из них как черный ящик, не вникая глубоко в принцип её работы.\n",
    "\n",
    "Однако, глубокие нейронные сети требовательны к большим объемам данных для сходимости обучения. И зачастую, в нашей частной задаче недостаточно данных для того, чтобы хорошо натренировать все слои нейросети. `Transfer Learning` решает эту проблему. Зачем обучать сеть заново, если можно использовать уже обученную на миллионе изображений и дообучить на свой датасет?\n",
    "\n",
    "В PyTorch есть много предобученных сетей: [TORCHVISION.MODELS](https://pytorch.org/vision/stable/models.html)\n",
    "\n",
    "- AlexNet\n",
    "- VGG\n",
    "- ResNet\n",
    "- SqueezeNet\n",
    "- DenseNet\n",
    "- Inception v3\n",
    "- GoogLeNet\n",
    "- ShuffleNet v2\n",
    "- MobileNetV2\n",
    "- MobileNetV3\n",
    "- ResNeXt\n",
    "- Wide ResNet\n",
    "- MNASNet\n",
    "\n",
    "Для этого,  нужно отключить какие-то промежуточные слои. Тогда можно использовать то, что называется `Fine turning` - не нужно обучать всю модель, а достаточно только ее новую часть.\n",
    "\n",
    "Зачастую в конце классификационных сетей используется полносвязный слой. Так как мы заменили этот слой, использовать предобученные веса для него уже не получится. Придется тренировать его с нуля, инициализировав его веса случайными значениями. Веса для всех остальных слоев мы загружаем из предобученной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkLUelSDxwcC"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9EiMku2xiDs"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_21.png\" width=\"700\">\n",
    "\n",
    "Мы уже делали это когда сравнивали Resnet собственного изготовления библиотечной реализацией. Нам требовалось изменить колчество классов и мы просто заменяли у можели последний слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXrgbsIYyEry"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "model = resnet18()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGDPfVybzWRt"
   },
   "source": [
    "Смотрим на вывод, линейный слой, и заменяем его другим с тем же количеством входов и нужным нам количеством выходов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-ezgscpzEeQ"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "imagenet_input = torch.randn([1,3,224,224])\n",
    "\n",
    "out = model(imagenet_input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBaZ7q1-0m2C"
   },
   "source": [
    "## Заморозка весов\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KigOQyed1C-g"
   },
   "outputs": [],
   "source": [
    "for tag, param in model.named_parameters():\n",
    "  if not 'layer4.' in tag and not 'fc' in tag:\n",
    "  #if not any(map(tag.__contains__, ['layer4.','fc'])): another way\n",
    "    param.requires_grad = False\n",
    "  print(tag,type(param),param.shape,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Q4SuaFL4F3F"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# or \n",
    "\n",
    "params_to_update = list(model.fc.parameters()) + list(model.layer4.parameters())\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq2ewTDH0UE1"
   },
   "source": [
    "#### Замена и удаление произвольных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-sDnP8T49bb"
   },
   "source": [
    "При отправке тензора с высотой и шириной 32x32 возникает ошибка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlcjVBRV0Jw-"
   },
   "outputs": [],
   "source": [
    "cifar10_input = torch.randn([1,3,32,32])\n",
    "out = model(cifar10_input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEuVi36c5IG7"
   },
   "source": [
    "Заменим 'stem' слои в начале сети, отвечающие за аггресивное сжатие изображения.\n",
    "\n",
    "P.S. Это потребуется при выполнении практической работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDM4fIg_0hUY"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "model.conv1 = nn.Conv2d(3,64,kernel_size=(5, 5),stride = 1, padding =2, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "out = model(cifar10_input)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iJKr--JJrds"
   },
   "source": [
    "## Рекомендации по обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qy3sQeuNQomZ"
   },
   "outputs": [],
   "source": [
    "Форматы изображений (OpenCv, Pillow ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gE4OOBqlY15y"
   },
   "source": [
    "### Сохранение весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8WO8LoYJfhW"
   },
   "source": [
    "#Few shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buNXsngyJ8xX"
   },
   "source": [
    "## Распознавание лиц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyuQkNbLJ1C7"
   },
   "source": [
    "## Сиамские сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xadqmUI2Lqpo"
   },
   "source": [
    "### Косинусное расстояние"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gf8ovS53LuP5"
   },
   "source": [
    "### Contrastive Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HrFhukxKCvj"
   },
   "source": [
    "## Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04u9HIl4KKsQ"
   },
   "source": [
    "## Triplet Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7oaDaeGKWOa"
   },
   "source": [
    "## Предоброботка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2cVStKiKbQx"
   },
   "source": [
    "### Ключевые точки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMGbbCyoKfIc"
   },
   "source": [
    "### Выравнивание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YJAFCBJKlya"
   },
   "source": [
    "### MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CX-3U4rMCsI"
   },
   "source": [
    "### Кластеризация / Поиск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCu6nDuNKt9j"
   },
   "source": [
    "### Демонстрация"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "L11_Augmentation_Transfer_OneShot.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
