{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Введение в машинное обучение</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Два пути"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть наручный браслет, который способен фиксировать перемещения по трем осям.\n",
    "\n",
    "Если задача состоит в том, чтобы подсчитать количество шагов, то к её решению можно подойти двумя способами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/accelerometer_task.jpg\" width=\"700\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вариант №1, Классический**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Напишем программу.**\n",
    "Если по одной из осей появилось ускорение, которое больше определенного порога, то мы создаем то условие, которое срабатывает. Позже мы выясним, что подобные сигнатурные сигналы с датчика могут поступить и при других определенных движениях, не связанных с шагами, например, во время плавания.\n",
    "Добавляется дополнительное условие, которое фильтрует подобные ситуации.\n",
    "\n",
    "Находятся всё новые и новые исключения из общего правила, программа и ее алгоритмическая сложность будут расти.\n",
    "\n",
    "Программу будет сложнее поддерживать из-за большого объема кода в ней.\n",
    "Изменение в одной из частей потребует внесение правок в другой код и т.п."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/accelerometr_solution_standart.png\" width=\"700\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вариант №2, Машинное обучение**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С появлением **машинного обучения** мы можем применить принципиально другой подход.\n",
    "Не задумываясь о том, что значат показания каждого из акселерометров, мы можем просто собрать некоторый архив данных за определенное время (возможно, разбив на более короткие промежутки времени). Всё, что нам потребуется помимо этих данных, — это информация о том, сколько было сделано реальных шагов. После этого данные загружаются в модель, и она на этих данных учится. При достаточном количестве данных и адекватно подобранной модели (чем мы и будем заниматься) мы сможем научить ее решать конкретные задачи (в данном случае — считать шаги)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/accelerometer_solution_nn.png\"  width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути, модели всё равно, что считать: шаги, сердечный ритм, количество калорий, ударов по клавиатуре и пр. Нет необходимости писать под каждый пример отдельную программу: достаточно собрать данные, и мы сможем решить множество абсолютно разных задач.\n",
    "\n",
    "Важно лишь понимать, какую модель предпочтительнее выбрать. С этим мы будем разбираться в ходе курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача курса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  AI, ML, DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Место глубокого обучения и нейронных сетей в ИИ**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/ai_ml_dl.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Искусственный интеллект (AI/ИИ)**  — область IT/Computer science, связанная с моделированием интеллектуальных или творческих видов человеческой деятельности.\n",
    "\n",
    "**Машинное обучение (ML)** — подраздел ИИ, связанный с разработкой алгоритмов и статистических моделей, которые компьютерные системы используют для выполнения задач без явных инструкций.\n",
    "\n",
    "**Глубокое обучение (Deep Learning, DL)** — совокупность методов машинного обучения, основанных на искуcственных нейронных сетях и обучении представлениям (**feature/representation learning**). Данный класс методов автоматически выделяет из необработанных данных необходимые признаки (представления), в отличие от методов ML, в которых признаки создают люди вручную (**feature engineering**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует множество определений сильного и слабого ИИ, рассуждений о появлении искусственного сознания и восстании машин.\n",
    "\n",
    "Всё намного **приземлённее**. Есть набор **объектов $X$** и набор **ответов $Y$**. Пары \"объект-ответ\" составляют **обучающую выборку**.\n",
    "\n",
    "Мы будем заниматься **восстановлением решающей функции $F$**, которая переводит признаки $X$, описывающие объекты, в ответы $Y$.\n",
    "\n",
    "$$ F: X \\xrightarrow\\ Y $$\n",
    "\n",
    "По ходу курса мы будем уточнять постановку задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Области применения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/ai_ml_dl_cv_nlp_sr.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последнее время именно такого рода модели показывают высокую эффективность в тех областях, с которыми ранее могли справиться только люди. В частности:\n",
    "* **компьютерное зрение** (Computer Vision, CV);\n",
    "* **распознавание и анализ речи** (NLP, извлечение смысла, Speech recognition, машинный перевод).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Связь с наукой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/science_cat.png\" width=\"200\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Научные исследования таковы, что их результаты в известной степени непредсказуемы. Одна из задач нашего курса — **научиться применять нейросети к решению новых задач**, в том числе в областях, где ранее такие технологии активно не использовались.\n",
    "\n",
    "В первую очередь для нас важны задачи слушателей курса, а успешным прохождением мы считаем **решённую научную задачу** и написанную по этому поводу **статью**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обзор курса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 1 Введение в машинное обучение</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Разобраться, как в целом подходить к задачам машинного обучения\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Базовая схема решения\n",
    "* Оценка и валидация результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/meme.png\" width=\"600\" ></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 2 Линейные модели</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Сделать базовое решение, применимое для небольшого количества данных\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Линейная модель — основа для будущих нейронных сетей\n",
    "* Градиентный спуск — учимся учить\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/svm_hard_margin.png\" width=\"900\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 3 Классическое машинное обучение</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Лучшее решение задачи для табличных данных\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Случайный лес и градиентный бустинг — лучшие алгоритмы для табличных данных\n",
    "* Идея ансамблей: как объединять алгоритмы и почему это хорошо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/random_forest.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 4 Генерация и отбор признаков</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Представление данных для модели — это основа хорошего решения задачи\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Сложности при работе с реальными данными\n",
    "* Основные этапы работы с данными как признаками: кодирование, генерация и отбор\n",
    "* Методы визуализации многомерных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/boruta_diagram.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 5 Нейронные сети</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Наконец познакомиться с нейронными сетями — классом моделей машинного обучения, которые позволяют решать огромное количество разнообразных задач, начать их создавать и обучать\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Интуиция, почему нейросети — очень выразительный класс моделей машинного обучения\n",
    "* Основные \"строительные блоки\" нейросетей\n",
    "* Основной метод обучения нейросетей — метод обратного распространения ошибки\n",
    "* Знакомство с **PyTorch** — основной программной библиотекой глубокого обучения, которой будем пользоваться на курсе\n",
    "* Процесс создания и обучения нейронной сети для задачи распознавания рукописных цифр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/nn_fully_connected.png\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 6 Свёрточные  сети</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться решать задачи компьютерного зрения\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Всевозможные виды свёрток\n",
    "* Выбор параметров моделей\n",
    "* Хитрости работы с картинками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/cv.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 7 Оптимизация нейронных сетей</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться учить сети, если они не учатся\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Поиск проблем и их решений\n",
    "* Улучшение сходимости\n",
    "* Советы и практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 8 Архитектуры нейронных сетей</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Познакомиться с историей развития архитектур сверточных сетей, чтобы понимать, чем они отличаются и какие нужно использовать\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Разбор основных идей развития сверточных сетей\n",
    "* Выбор архитектуры под свою задачу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/my_architecture.png\" width=\"500\" ></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 9 Рекуррентные нейронные сети</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться обрабатывать последовательности\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Обработка временных рядов\n",
    "* NLP классический\n",
    "* NLP нейросетевой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L01/nlp_processing.png\"  width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.mdpi.com/2076-3417/12/18/9060\">Deep Learning Model for Selecting Suitable Requirements Elicitation Techniques</a></em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 10 Трансформеры</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться решать задачи NLP и компьютерного зрения ещё круче\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Готовые трансформеры\n",
    "* Дообучение под задачу\n",
    "* Проблемы и пути решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/transformer.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 11 Сегментация и детектирование</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться решать продвинутые задачи компьютерного зрения\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Продвинутая работа с изображениями\n",
    "* Крутые решения \"из коробки\"\n",
    "* Написание своих архитектур"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/object_detection.jpg\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 12 Representation learning</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Взглянуть на задачи обучения нейронных сетей с новой точки зрения: когда нейросеть обучается переводить данные в компактные информативные векторные представления, которые можно использовать для решения нестандартных задач\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Познакомимся с постановкой задачи **Metric Learning** — узнаем, как быть, когда классов много, а представителей в них мало\n",
    "* Рассмотим **автоэнкодеры** — особый класс нейросетевых архитектур для обучения представлений без разметки\n",
    "* Поговорим про полезные применения автоэнкодеров — от понижения размерности до генерации новых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/nn_encoder_nn_decoder.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 13 Генеративные сети</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научить нейронную сеть генерировать объекты, которые она никогда не видела\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Генеративно-состязательные нейронные сети\n",
    "* Диффузионные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/diffusion_idea.png\" width=\"800\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 14 Explainability</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться **объяснять**, почему модели машинного обучения (часто предстающие перед нами как \"черные ящики\") выдают те или иные предсказания\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Разберем понятия **объяснимости** и **интерпретируемости** моделей машинного обучения\n",
    "* Рассмотрим методы построения объясняющих моделей: **SHAP** и **LIME**, а также методы, специфичные для моделей компьютерного зрения\n",
    "* Рассмотрим множество примеров для разных типов данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/explainability_vs_interpretability.png\" width=\"1000\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 15 Обучение с подкреплением</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться ̶з̶а̶х̶в̶а̶т̶ы̶в̶а̶т̶ь̶ ̶м̶и̶р̶  управлять роботами\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Ключевые подходы к задаче\n",
    "* Готовые модули для вашего решения\n",
    "* Применение для более классических задач"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L01/gangnam.gif\" width=\"900\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://bair.berkeley.edu/blog/2018/10/09/sfv/\"> Learning Acrobatics by Watching YouTube. Xue Bin (Jason) Peng and Angjoo Kanazawa</a></em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Типы задач в ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовые задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/classification.png\" width=\"650\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация — **отнесение образца к одному из нескольких попарно не пересекающихся множеств**.\n",
    "\n",
    "В качестве образцов могут выступать различные по своей природе объекты, например:\n",
    "* символы текста,\n",
    "* изображения,\n",
    "* звуки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/regression.png\" width=\"650\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае регрессионных задач у нас, как правило, нет жесткого ограничения на пространство ответов. И мы предсказываем некоторое число, в общем случае вещественное."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/clustering.png\" width=\"650\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация — **разбиение множества входных данных на группы**. Ни количество, ни специфические признаки заранее не известны.\n",
    "\n",
    "\n",
    "Относится к задачам **обучения без учителя**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Комбинированные задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют работы, которые **комбинируют в себе несколько задач**. Типичным примером является задача **Object Detection**:\n",
    "\n",
    "$$\\large Детектирование = Классификация + Регрессия$$\n",
    "\n",
    "Мы отмечаем координаты рамок (регрессия) и классифицируем объект в рамке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L01/cat.png\" width=\"400\"></center>\n",
    "\n",
    "\n",
    "\n",
    "<center><em>Source: <a href=\"https://neerc.ifmo.ru/wiki/index.php?title=%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BD%D0%B0%D1%85%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2_%D0%BD%D0%B0_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B8\">ИТМО\n",
    "</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комбинирование знаний и навыков**\n",
    "\n",
    "Вашим преимуществом станет **комбинирование узкоспециализированных знаний** в вашей предметной области **и машинного обучения**.\n",
    "\n",
    "Одним из самых известных примеров является **AlphaFold**.\n",
    "Коллектив обладал компетенциями в области биологии, физики, математики, алгоритмов глубокого обучения и оптимизации — то есть в области вычислительной биологии.\n",
    "\n",
    "Работа была посвящена проблеме получения структуры белка, который бы отвечал заранее заданным свойства. Была обучена нейросеть, которая предсказывает расстояния и углы между атомами аминокислот в конечном белке, а также  структуру белка в 3D-виде.\n",
    "\n",
    "[[article] 🎓 Jumper, John, et al. \"Highly accurate protein structure prediction with AlphaFold.\" Nature 596.7873 (2021): 583-589](https://www.nature.com/articles/s41586-021-03819-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L01/alpha.gif\" width=\"800\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://deepmind.google/discover/blog/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology/\">AlphaFold: a solution to a 50-year-old grand challenge in biology</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, вы решили заняться разработкой приложения для определения породы кошек. Как будет выглядеть план исследования?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/pipeline.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где можно добыть данные?\n",
    "\n",
    "* Эксперименты в вашей лаборатории\n",
    "* [[doc] 🛠️ Соревнования Kaggle](https://www.kaggle.com/datasets)\n",
    "* [[doc] 🛠️ Google Datasets](https://datasetsearch.research.google.com/)\n",
    "* [[article] 🎓 Сайт Papers with Code](https://paperswithcode.com/)\n",
    "\n",
    "Пройдитесь по соседним лабораториям. Напишите письма авторам статей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы используете данные, скачанные из сети, проверьте, откуда они. Описаны ли они в статье? Если да, посмотрите на документ, убедитесь, что он был опубликован в авторитетном месте, и проверьте, упоминают ли авторы какие-либо ограничения на использованные датасеты.\n",
    "\n",
    "Если данные использовались в ряде работ, это еще не гарантирует высокое качество датасета. **Иногда данные используются только потому, что их легко достать**.\n",
    "\n",
    "Даже широко распространённые датасеты могут иметь ошибки или какую-то странную специфику. Например, при исследовании **ImageNet** были обнаружены миллионы изображений темнокожих людей, которые были помечены как \"преступник\". В итоге большая часть набора данных ImageNet была удалена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/imagenet_bugs.png\" width=\"500\" ></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://labelerrors.com/\">Label Errors in ML Test Sets</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют [исследования 🎓[arxiv]](https://arxiv.org/abs/2211.01866), которые связывают странное поведение современных нейронных сетей и ошибки в разметке.\n",
    "\n",
    "Если вы обучаете свою модель на плохих данных, то, скорее всего, у вас получится плохое решение задачи. Существует соответствующий термин: **garbage in, garbage out**. Всегда начинайте с проверки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение и применение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как будут выглядеть данные во время **инференса** модели?\n",
    "\n",
    "Не окажется ли, что при обучении все кошки были мохнатые, а на инференсе попался сфинкс?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L01/cats.jpg\" width=\"300\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://dzen.ru/a/XfNtCpylEgCtH1c7\">Дзен</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что делать?**\n",
    "\n",
    "* Добавить целевые данные\n",
    "* Попробовать оценить смещение признаков данных и добавить это смещение к данным при обучении\n",
    "* Костыли и велосипеды\n",
    "\n",
    "Подробнее с этим вы познакомитесь в ходе курса.\n",
    "\n",
    "[[blog] ✏️ Обсуждение проблемы](https://stats.stackexchange.com/questions/362906/co-variate-shift-between-train-and-test-data-set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разведочный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory data analysis**, EDA — анализ основных свойств данных, нахождение в них общих закономерностей, распределений и аномалий, построение начальных моделей с использованием инструментов визуализации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/eda.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее с этим вы познакомитесь в следующих лекциях.\n",
    "\n",
    "Примеры:\n",
    "\n",
    "* [[git] 🐾 Три блокнота с подробным анализом реального датасета](https://github.com/AleksandrIvchenko/machine-learning-project-walkthrough)\n",
    "* [[blog] ✏️ Как избежать «подводных камней» машинного обучения: руководство для академических исследователей](https://habr.com/ru/post/664102/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постройте вашу первую систему быстро**, а затем итерационно улучшайте.\n",
    "\n",
    "Возьмите что-то простое, готовое. Ваша сложная модель должна работать не хуже.\n",
    "\n",
    "Возможно, даже простая модель сможет решить вашу задачу **с достаточным качеством**.\n",
    "\n",
    "**Учтите нижнюю границу качества.** За baseline можно считать известное значение. Например, результат работы классических методов или качество решения задачи человеком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**А как измерить это качество?**\n",
    "\n",
    "По ходу курса мы познакомимся с великим множеством **метрик** для различных задач. Важно, что любая из них **должна быть выбрана заранее**, до получения результатов.\n",
    "\n",
    "Фактически вы оцениваете, какой показатель нужно улучшить и как этот показатель измерить.\n",
    "\n",
    "Метрика должна отвечать **целевой задаче**.\n",
    "\n",
    "Так, отличной метрикой при разработке генератора упражнений для изучения программирования может быть улучшение оценок слушателей на внешних экзаменах.\n",
    "\n",
    "Общий совет: используйте **однопараметрические метрики**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так, если у нас есть 2 классификатора, вводя две метрики, тяжело оценить, какой из них лучше — А или Б."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/metric1.png\" width=\"350\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но если эти метрики объединить в одну, провести сравнение будет гораздо проще."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/metric2.png\" width=\"600\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также не стоит забывать об оптимизационных метриках. **Мы можем улучшать не только точность**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/metric3.png\" width=\"400\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметьте, что метрика получается не однопараметрическая. Вместо введения формулы типа $$\\large F_1 + 0,5* \\text{Скорость}$$ можно **сделать отсечку допустимого** времени рассчётов и использовать точность в качестве целевой метрики среди оставшихся моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели, эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По ходу курса мы будем не только писать модели с нуля, но и знакомиться с базами готовых моделей, в том числе предобученных. Поэтому стоит сразу начать логировать результаты экспериментов. Подумайте, как вам это будет делать удобнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрите на примеры из валидационной выборки, на которых есть ошибки. Так, разумным будет выделить 2 группы объектов:\n",
    "\n",
    "* на которых ошибка максимальна,\n",
    "* на которых возникают пограничные ошибки.\n",
    "\n",
    "Возьмите разумное количество объектов, которое можно проверить вручную (скажем, 100). Возможно, вы найдёте в этот момент ошибки в разметке или собак, которые очень похожи на котиков.\n",
    "\n",
    "Результат анализа позволит понять, какой ожидаемый эффект будет от дальнейших действий. Если у вас окажется проблема с разметкой, улучшение алгоритма даст малый вклад.\n",
    "\n",
    "Во время улучшения решения у вас будут появляться гипотезы, как можно улучшать решение. Имеет смысл при анализе ошибок завести подобную таблицу, в которой отмечать, на какие объекты в анализируемой подвыборке ожидается эффект."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/metric4.png\" width=\"1000\" ></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом можно оценить первоочередные улучшения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ работы модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как модель будет готова, необходимо вскрыть \"чёрный ящик\". Об этом будет отдельная лекция."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L01/grad_cam.webp\" width=\"700\" ></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.mdpi.com/2079-9292/10/13/1541\">Object Identification and Localization Using Grad-CAM++</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы сможете удостовериться, что модель выучила действительно значимые признаки, а не, например, фон.\n",
    "\n",
    "Заметки от Эндрю Ына:\n",
    "\n",
    "[[blog] ✏️ Страсть к машинному обучению](https://habr.com/ru/articles/419757/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инструменты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим примеры решения задач классификации на различных типах данных.\n",
    "\n",
    "Будем использовать библиотеки:\n",
    "\n",
    "* [[doc] 🛠️ NumPy](https://numpy.org/) — поддержка больших многомерных массивов и быстрых математических функций для операций с этими массивами.\n",
    "* [[doc] 🛠️ Scikit-learn](https://scikit-learn.org/stable/) — ML алгоритмы, \"toy\"-датасеты.\n",
    "* [[doc] 🛠️ Pandas](https://pandas.pydata.org/) — удобная работа с табличными данными.\n",
    "* [[doc] 🛠️ **PyTorch**](https://pytorch.org/) — основной фреймворк машинного обучения, который будет использоваться на протяжении всего курса.\n",
    "* [[doc] 🛠️ Matplotlib](https://matplotlib.org/) — основная библиотека для визуализации. Вывод различных графиков.\n",
    "* [[doc] 🛠️ Seaborn](https://seaborn.pydata.org/) — удобная библиотека для визуализации статистик. Прямо из коробки вызываются и гистограммы, и тепловые карты, и визуализация статистик по датасету, и многое другое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L01/sns.png\" width=\"850\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.acte.in/what-is-seaborn-in-python-article/\">What is Seaborn in Python? A Complete Guide For Beginners & REAL-TIME Examples</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Связность данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/various_data.png\" width=\"800\"></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют различные типы данных с различными типами связности:\n",
    "\n",
    "* последовательности (важны порядок данных, время),\n",
    "* пространственно-структурированная информация (изображения, видео),\n",
    "* табличные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большинство процессов и объектов, с которыми научились работать ML/DL-модели, можно отнести к одному из перечисленных типов. Хотя есть и более сложные примеры, которые схематично изображены выше (молекулярные графы, спектры, скорости галактик, где в белой части карты скоростей исследуемый объект не имеет нулевую скорость, а в принципе отсутствует).\n",
    "\n",
    "Наша задача будет состоять в том, чтобы определить, как данные из вашей предметной области свести к одному из этих типов и представить в виде набора чисел.\n",
    "\n",
    "Обычно выбор модели под тип данных выглядит следующим образом:\n",
    "\n",
    "* **Табличный**  — классические ML-модели либо полносвязные NN;\n",
    "* **Остальные типы данных** — глубокие нейронные сети.\n",
    "\n",
    "В разных типах данных количество связей между элементами разное и зависит только от типа этих данных. **Важно НЕ количество элементов, а СВЯЗИ между ними.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/connectivity_of_data_types.png\" width=\"700\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Связность** — степень взаимного влияния между соседними элементами.\n",
    "\n",
    "Например, в таблице, в которой есть определенные параметры (рост, вес), данные между собой связаны, но порядок столбцов значения не имеет. Если мы поменяем столбцы местами, то не потеряем никакой важной информации. Такие данные можно представить в виде вектора, но порядок элементов в нем не важен.\n",
    "\n",
    "При работе с изображениями нам становится важно, как связаны между собой пиксели и по горизонтали, и по вертикали. При добавлении цвета появляются 3 RGB-канала, и значения в каждом канале также связаны между собой. Эту связь нельзя терять, если мы хотим корректно извлечь максимум информации из данных. Соответственно, если дано цветное изображение, то у нас есть уже три измерения, в которых мы должны эти связи учитывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и визуализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример работы с табличными данными.\n",
    "Нам даётся описание вин из учебного датасета [Wine 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html), в котором представлены результаты химического анализа вин, выращенных в одном регионе Италии, но полученных из трех разных сортов винограда."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/wine_dataset.png\" width=\"700\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет, используя модуль `sklearn.datasets` [🛠️[doc]](https://scikit-learn.org/stable/api/sklearn.datasets.html) библиотеки Sklearn.\n",
    "\n",
    "Библиотека Sklearn обеспечивает API по работе с датасетами, а также хранит ряд учебных. Посмотрим, как это выглядит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Визуализация данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Чтобы отобразить данные в виде таблицы, загрузим их в формате `pandas.DataFrame`.\n",
    "В более крупных датасетах у вас могут появиться такие параметры, как доля загрузки датасета и фиксирование сида генератора случайных числе (для повторяемости загрузки).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "x, y = load_wine(return_X_y=True, as_frame=True)\n",
    "\n",
    "x.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так мы можем посмотреть, какие **уникальные классы** есть в нашей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно интерпретировать каждый объект как координаты точки в 13-мерном пространстве. Именно с таким представлением работает большинство алгоритмов машинного обучения.\n",
    "\n",
    "Визуализируем распределение данных по классам и отметим, что присутствует дисбаланс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(4, 3))\n",
    "y.hist()\n",
    "plt.suptitle(\"Label balance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с данными и моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся одной из самых простых моделей машинного обучения для классификации сортов винограда, из которых сделано вино."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание модели k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Метод k-ближайших соседей 📚[wiki]](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) (англ. k-nearest neighbors algorithm, k-NN) — метрический алгоритм для классификации или регрессии. В случае классификации алгоритм сводится к следующему:\n",
    "\n",
    "1. Рассматриваются объекты из обучающей выборки, для которых известно, к какому классу они принадлежат.\n",
    "2. Между подлежащими классификации объектами и объектами тренировочной выборки вычисляется матрица попарных расстояний согласно выбранной метрике.\n",
    "3. На основе полученной матрицы расстояний для каждого из подлежащих классификации объектов определяются $k$ ближайших объектов тренировочной выборки — $k$ ближайших соседей.\n",
    "4. Подлежащим классификации объектам приписывается тот класс, который чаще всего встречается у их $k$ ближайших соседей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/knn_idea.png\" width=\"700\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Близость данных согласно метрике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пара бутылок вина будет определяться идентично, если значения характеристик будут похожи по величине. Другими словами, практически идентичным объектам будут соответствовать **близкие** точки многомерного пространства. Для численной характеристики **близости** можно определить функцию подсчета расстояния между парой точек — метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известны различные способы задания [функции расстояния между парой точек 📚[wiki]](https://en.wikipedia.org/wiki/Metric_(mathematics)). Простейшим примером является широко известная **Евклидова** ($L_2$) метрика:\n",
    "$$L_2 (X, Y) = \\sqrt { \\sum_i (X_i - Y_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но, кроме неё, величина расстояния между парой точек может быть выражена рядом других функций.\n",
    "\n",
    "$L_1$-расстояние (манхэттенская метрика):\n",
    "$$L_1 (X, Y) = \\sum_i |X_i - Y_i|$$\n",
    "\n",
    "Угловое расстояние:\n",
    "$$\\text{ang}(X, Y) = \\frac{1}{\\pi} \\arccos \\frac{\\sum_i X_i Y_i}{\\sqrt{\\sum_i X_i^2} \\sqrt{\\sum_i Y_i^2}}$$\n",
    "\n",
    "И многие другие. От выбора конкретной функции расстояния между точками будет явно зависеть представление о **близости** точек: объекты, близкие по одной из метрик, вовсе не обязаны оказаться близкими согласно другой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем вычислить $L_1$-расстояние между несколькими первыми объектами из набора данных с использованием реализованного в пакете Sklearn класса `sklearn.metrics.DistanceMetric`[🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html#sklearn.metrics.DistanceMetric.get_metric)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем три объекта из выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "x, y = load_wine(return_X_y=True, as_frame=True)\n",
    "\n",
    "obj_0 = x.iloc[0]\n",
    "obj_1 = x.iloc[1]\n",
    "obj_2 = x.iloc[170]\n",
    "\n",
    "x.iloc[[0, 1, 170]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Два объекта класса 0 и один объект класса 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"obj_0: {y[0]} \\nobj_1: {y[1]} \\nobj_2: {y[170]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И посчитаем расстояния между ними:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "pairwise_dist = pairwise_distances([obj_0, obj_1, obj_2], metric=\"manhattan\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "im = ax.imshow(pairwise_dist)\n",
    "\n",
    "labels = [f\"obj{i}\" for i in range(1, 4)]\n",
    "ax.set_xticks(np.arange(len(pairwise_dist)))\n",
    "ax.set_yticks(np.arange(len(pairwise_dist)))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(len(pairwise_dist)):\n",
    "    for j in range(len(pairwise_dist)):\n",
    "        text = ax.text(\n",
    "            j,\n",
    "            i,\n",
    "            \"{:0.2f}\".format(pairwise_dist[i, j]),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"white\" if pairwise_dist[i, j] < np.mean(pairwise_dist) else \"black\",\n",
    "        )\n",
    "\n",
    "ax.set_title(\"Pairwise L-1 distance for 3 objects\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассматривая аналогичные примеры, можно выявить, что расстояние между объектами одного и того же класса может оказаться меньше, чем расстояние между объектами разных классов. Действительно, давайте рассчитаем средние расстояния между объектами разных классов для UCI ML Wine DataSet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "data = pd.concat([x, y], axis=1)\n",
    "classwise_distance = np.zeros((len(y.unique()), len(y.unique())))\n",
    "\n",
    "for i in range(len(y.unique())):\n",
    "    for j in range(len(y.unique())):\n",
    "        class_i_data = data[data[\"target\"] == i]\n",
    "        class_j_data = data[data[\"target\"] == j]\n",
    "        classwise_distance[i, j] = (\n",
    "            np.mean(manhattan_distances(class_i_data, class_j_data)) / 2.0\n",
    "        )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "im = ax.imshow(classwise_distance)\n",
    "\n",
    "ax.set_xticks(np.arange(len(y.unique())))\n",
    "ax.set_yticks(np.arange(len(y.unique())))\n",
    "ax.set_xticklabels(y.unique())\n",
    "ax.set_yticklabels(y.unique())\n",
    "plt.setp(ax.get_xticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(len(y.unique())):\n",
    "    for j in range(len(y.unique())):\n",
    "        text = ax.text(\n",
    "            j,\n",
    "            i,\n",
    "            \"{:0.2f}\".format(classwise_distance[i, j]),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=(\n",
    "                \"white\"\n",
    "                if classwise_distance[i, j] < np.mean(classwise_distance)\n",
    "                else \"black\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "ax.set_title(\"Mean class-wise Manhattan distance\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, для объектов классов в целом выполняется условие обособленности, т.е. отношение близости по манхэтенновскому расстоянию.\n",
    "\n",
    "Идея о том, что близость объектов по некоторой метрике и их принадлежность к одному определённому классу связаны, является основой известного алгоритма классификации и регрессии — **k-Nearest Neighbors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простейшая метрика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Довольно естественно оценивать долю правильных ответов алгоритма как отношение верно предсказанных классов к общему количеству объектов:\n",
    "\n",
    "$$ \\large \\text{Accuracy} = \\frac{P}{N}, $$\n",
    "\n",
    "\n",
    "\n",
    "$P$ — количество верно предсказанных классов,\n",
    "\n",
    "\n",
    "$N$ — общее количество тестовых примеров.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим алгоритм k-NN ([реализации алгоритма в scikit-learn 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors_graph)), используя параметры `n_neighbors=6` и `metric=\"chebyshev\"`. Метод `fit` служит для обучения модели, принимает матрицу объектов и вектор меток классов. После чего оценим качество, посчитав `accuracy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6, metric=\"chebyshev\")\n",
    "knn.fit(x, y)\n",
    "accuracy = accuracy_score(y_pred=knn.predict(x), y_true=y)  # accuracy\n",
    "\n",
    "print(\"Accuracy:\", f\"{accuracy*100 :0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `fit` настраивает модель. В простейшей реализации метода k-NN во время обучения просто запоминаются вектора признаков и их метки. Такая Brute-Force реализация самая медленная, существуют [более оптимальные реализации алгоритма ✏️[blog]](https://habr.com/ru/articles/801885/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры и гиперпараметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, у нас есть **два параметра** модели, которые мы **можем настраивать**:\n",
    "* метрика расстояния,\n",
    "* количество ближайших соседей $k$.\n",
    "\n",
    "Настраиваемые параметры, с помощью которых мы можем управлять процессом обучения, называются **гиперпараметрами**. В дальнейшем мы столкнемся с другими гиперпараметрами. Например, мы можем попробовать использовать другую модель, и выбор модели тоже станет гиперпараметром решаемой задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, мы выбрали не самые лучшие параметры. Посчитаем `accuracy` для разных параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for distance_type in [\"euclidean\", \"manhattan\", \"chebyshev\"]:\n",
    "    for k in [1, 3, 5, 7]:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric=distance_type)\n",
    "        knn.fit(x, y)\n",
    "        y_pred = knn.predict(x)\n",
    "        accuracy = str(round(accuracy_score(y, y_pred) * 100)) + \"%\"\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"n_neighbors\": \"k=\" + str(k),\n",
    "                \"distance_type\": distance_type,\n",
    "                \"accuracy\": accuracy,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.pivot(index=\"distance_type\", columns=\"n_neighbors\", values=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, при разных параметрах качество изменяется. **Как тогда подбирать парамеры?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение train-validation-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самым простым способом научиться чему-либо является \"запомнить всё\".\n",
    "\n",
    "Вспомним таблицу умножения. Если мы хотим проверить умение умножать, то проверки примерами из таблицы умножения будет недостаточно, ведь она может быть полностью запомнена. Нужно давать новые примеры, которых не было в таблице умножения (обучающей выборке)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если модель \"запомнит всё\", то она будет идеально работать на данных, которые мы ей показали, но может вообще не работать на любых других данных.\n",
    "\n",
    "С практической точки зрения важно, как модель будет вести себя именно на незнакомых ей данных, то есть насколько хорошо она научилась обобщать закономерности, которые в данных присутствовали (если они вообще существуют)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки этой способности набор данных разделяют на три части:\n",
    "\n",
    "* **Обучающая выборка** (Training set) — выборка данных, которая используется для обучения алгоритма.\n",
    "* **Валидационная выборка** (Validation set) — выборка данных, которая используется для подбора параметров, выбора признаков и принятия других решений, касающихся обучения алгоритма.\n",
    "* **Тестовая выборка** (Test set) — выборка, которая используется для оценки качества работы алгоритма, при этом никак не используется для обучения алгоритма или подбора используемых при этом обучении параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/split_dataset_for_train_val_test.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `sklearn.model_selection` есть функция для разделения массива данных на тренировочную и тестовую часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data to train/val/test\n",
    "x_train, x_tmp, y_train, y_tmp = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_tmp, y_tmp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Train:\", np.array(x_train).shape, np.array(y_train).shape)\n",
    "print(\"Val:\", np.array(x_val).shape, np.array(y_val).shape)\n",
    "print(\"Test:\", np.array(x_test).shape, np.array(y_test).shape)\n",
    "print(\"Total:\", np.array(x).shape, np.array(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1, metric=\"chebyshev\")\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_pred=knn.predict(x_train), y_true=y_train)\n",
    "accuracy_val = accuracy_score(y_pred=knn.predict(x_val), y_true=y_val)\n",
    "accuracy_test = accuracy_score(y_pred=knn.predict(x_test), y_true=y_test)\n",
    "\n",
    "print(\"Accuracy train:\", f\"{accuracy_train*100:.02f}%\")\n",
    "print(\"Accuracy val :\", f\"{accuracy_val*100:.02f}%\")\n",
    "print(\"Accuracy test :\", f\"{accuracy_test*100:.02f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вполне ожидаемо, оценка по одному соседу оказалась ошибочной. Такие случаи мы называем *переобучением*. Если теперь мы попробуем взять какой-то новый объект и классифицировать его, у нас, скорее всего, ничего не получится. В таких случаях мы говорим, что наша модель не умеет обобщать (*generalization*).\n",
    "\n",
    "Отметим, что качество на тесте получилось заметно выше, чем на валидации. Так произошло потому, что выборки оказались нерепрезентативными, ведь мы делили данные \"вслепую\", случайным образом. Для того, чтобы выборки были репрезентативными, применяется стратификация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стратификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки классов в датасете могут быть распределены неравномерно. Для того, чтобы сохранить соотношение классов при разделении на train и val, необходимо указать параметр `stratify` при разбиении.\n",
    "\n",
    "Еще одним параметром, используемым при разбиении, является `shuffle` (значение по умолчанию `True`). При `shuffle = True` датасет перед разбиением перемешивается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/stratified_sampling.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.reneshbedre.com/blog/stratified-sampling.html\">What is Stratified sampling and why should you use it</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы убедиться в необходимости стратификации, посмотрим на разбиение датасета [Iris 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html). Здесь нам важно, что датасет сбалансирован, а метки отсортированы в порядке возрастания.\n",
    "\n",
    "Будем делить датасет пополам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(labels):\n",
    "    label_count = {}\n",
    "    for item in labels:\n",
    "        if item not in label_count:\n",
    "            label_count[item] = 0\n",
    "        label_count[item] += 1\n",
    "    return label_count\n",
    "\n",
    "\n",
    "def print_split_stat(x_train, x_val, y_train, y_val):\n",
    "    print(\"Train statistics: \", count_labels(y_train))\n",
    "    print(\"Val statistics:  \", count_labels(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядит исходный датасет. Отметим, что **объекты отсортированы**. Ситуация вовсе не исключительная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data, labels = load_iris(return_X_y=True)\n",
    "print(\"DataSet labels:\\n\", labels)\n",
    "print(\"DataSet statistics: \", count_labels(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы **выключим перемешивание** (`shuffle=False`), то в обучение **не попадёт ни один объект класса 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    data, labels, train_size=0.5, shuffle=False, random_state=42\n",
    ")\n",
    "\n",
    "print_split_stat(x_train, x_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию `shuffle=True`, однако этого **не достаточно**. **Доли** объектов **не равны** в подвыборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    data, labels, train_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print_split_stat(x_train, x_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Только при использовании стратификации мы добиваемся желаемого результата.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    data, labels, train_size=0.5, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print_split_stat(x_train, x_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В случае временных рядов**, текстов и прочих данных, имеющих связь во времени, **данные нельзя перемешивать**. В таких задачах train должен предшествовать val и test по времени. Более подробно об этом будет рассказано в лекции про рекуррентные нейронные сети.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Алгоритм кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте все-таки разберемся, как подобрать гиперпараметры.\n",
    "\n",
    "Результат работы модели будет зависеть от разбиения. Поэкспериментируем с k-NN и датасетом [Iris 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) и посмотрим, как результат работы модели зависит от `random_state` для `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = sklearn.datasets.load_iris()  # load data\n",
    "x = dataset.data  # features\n",
    "y = dataset.target  # labels(classes)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def split_and_train(x, y, random_state):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x, y, train_size=0.8, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    max_neighbors = 30\n",
    "    num_neighbors = np.arange(1, max_neighbors + 1)  # array of the number of neighbors\n",
    "\n",
    "    train_accuracy = np.zeros(max_neighbors)\n",
    "    val_accuracy = np.zeros(max_neighbors)\n",
    "\n",
    "    for k in num_neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(x_train, y_train)\n",
    "\n",
    "        train_accuracy[k - 1] = accuracy_score(\n",
    "            y_pred=knn.predict(x_train), y_true=y_train\n",
    "        )\n",
    "        val_accuracy[k - 1] = accuracy_score(y_pred=knn.predict(x_val), y_true=y_val)\n",
    "\n",
    "    # Accuracy plot on train and test data\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(f\"k-NN on train vs val, seed = {random_state}\", size=20)\n",
    "    plt.plot(num_neighbors, train_accuracy, label=\"train\")\n",
    "    plt.plot(num_neighbors, val_accuracy, label=\"val\")\n",
    "    plt.legend()\n",
    "    plt.xticks(num_neighbors, size=12)\n",
    "    plt.xlabel(\"Neighbors\", size=14)\n",
    "    plt.ylabel(\"Accuracy\", size=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_train(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_train(x, y, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат зависит от того, как нам повезло или не повезло с разбиением данных на обучение и тест. Для одного разбиения хорошо выбрать $k=3$, а для другого — $k=13$. Кроме того, фактически мы сами выступаем в роли модели, которая учит гиперпараметры (а не параметры) под видимую ей выборку.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Получается, что если подбирать гиперпараметры модели на *train set*, то:\n",
    "1. Можно переобучитьcя, просто на более \"высоком\" уровне. Особенно если гиперпараметров у модели много и все они разнообразны.\n",
    "2. Нельзя быть уверенным, что выбор параметров не зависит от разбиения на обучение и валидацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения этой проблемы можно произвести **несколько разбиений** датасета на **обучающий и валидационный** по какой-то схеме, чтобы получить уверенность оценок качества для моделей с разными гиперпараметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/cross_validation_on_train_data.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой подход называется [K-Fold кросс-валидацией 🛠️[doc]](https://scikit-learn.org/stable/modules/cross_validation.html).\n",
    "\n",
    "Берется тренировочная часть датасета и разбивается на части — блоки. Дальше мы будем использовать для проверки первую часть (Fold 1), а на остальных частях будем обучать модель. И так последовательно для всех частей. В результате у нас будет информация о точности для разных фрагментов данных, и уже на основании этого мы сможем понять, насколько значение параметра, который мы проверяем, зависит или не зависит от данных. То есть, если у нас от разбиения точность при одном и том же $k$ меняться не будет, значит, мы подобрали правильный $k$. Если она будет сильно меняться в зависимости от того, на каком куске данных мы проводим тестирование, значит, надо попробовать другой $k$, и если ни при каком не получилось, то проблема заключается в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как работает K-Fold. Обратите внимание, что по умолчанию `shuffle = False`. Для упорядоченных данных это проблема."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "print(\"index without shuffle\")\n",
    "kf = KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "print(\"index with shuffle\")\n",
    "kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения стратифицированного разбиения (когда соотношение классов в частях разбиения сохраняется) нужно использовать `StratifiedKFold` [🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Временные ряды**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L01/timeseries.png\" width=\"850\"></center>\n",
    "<center><em>Типичный пример временного ряда</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/company/ods/blog/327242/\">Анализ временных рядов с помощью Python</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно нужно упомянуть о **временных рядах**. Особенностью таких данных является связность, наличие \"настоящего\", \"прошедшего\" и \"будущего\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/ts_split.png\" width=\"700\"/></center>\n",
    "<center><em>Разбиение данных временных рядов на подвыборки</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Оценка результата кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Посмотрим на результат кросс-валидации для k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "dataset = sklearn.datasets.load_iris()  # load data\n",
    "x = dataset.data  # features\n",
    "y = dataset.target  # labels(classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size=0.8, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "accuracy3 = cross_val_score(knn, x_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "accuracy5 = cross_val_score(knn, x_train, y_train, cv=cv, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv = np.vstack(\n",
    "    (\n",
    "        np.hstack((accuracy3, accuracy3.mean(), accuracy3.std())),\n",
    "        np.hstack((accuracy5, accuracy5.mean(), accuracy5.std())),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = pd.DataFrame(\n",
    "    knn_cv, columns=[\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\", \"Mean\", \"Std\"]\n",
    ")\n",
    "table.insert(loc=0, column=\"k\", value=[3, 5])\n",
    "table = table.set_axis([\"Accuracy\"] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В идеальном случае выбираются гиперпараметры, для которых математическое ожидание метрик качества выше, а дисперсия — меньше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Типичные ошибки при кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Можно ли делать только кросс-валидацию (без теста)?**\n",
    "\n",
    "Нет, нельзя. Кросс-валидация не до конца спасает от подгона параметров модели под выборку, на которой она проводится. Оценка конечного качества модели должно производиться на отложенной тестовой выборке. Если у вас очень мало данных, можно рассмотреть [вложенную кросс-валидацию 🛠️[doc]](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html). Речь об этом пойдет в следующих лекциях. Но даже в этом случае придется анализировать поведение модели, чтобы показать, что она учит что-то разумное. Кстати, вложенную кросс-валидацию можно использовать, чтобы просто получить более устойчивую оценку поведения модели на тесте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подбора параметров модели используется **GridSearchCV**.\n",
    "\n",
    "GridSearchCV – это инструмент для автоматического подбора параметров моделей машинного обучения. GridSearchCV находит наилучшие параметры путем обычного перебора: он создает модель для каждой возможной комбинации параметров из заданной сетки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет Iris маловат для подбора параметров, поэтому создадим свой датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "x, y = make_moons(n_samples=1000, noise=0.3, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отложим test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size=0.8, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подобрать параметры модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\"\"\"\n",
    "Parameters for GridSearchCV:\n",
    "estimator — model\n",
    "cv — num of fold to cross-validation splitting\n",
    "param_grid — parameters names\n",
    "scoring — metrics\n",
    "n_jobs — number of jobs to run in parallel, -1 means using all processors.\n",
    "\"\"\"\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    cv=KFold(5, shuffle=True, random_state=42),\n",
    "    param_grid={\n",
    "        \"n_neighbors\": np.arange(1, 31),\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "    },\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем лучшие гиперпараметры для модели, которые подобрали:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metric:\", model.best_params_[\"metric\"])\n",
    "print(\"Num neighbors:\", model.best_params_[\"n_neighbors\"])\n",
    "print(\"Weigths:\", model.best_params_[\"weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объект `GridSearchCV` можно использовать как обычную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(\n",
    "    f\"Percent correct predictions {np.round(accuracy_score(y_pred=y_pred, y_true=y_test)*100,2)} %\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем извлечь дополнительные данные о кросс-валидации и по ключу обратиться к результатам всех моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем для примера `mean_test_score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(model.cv_results_[\"mean_test_score\"])\n",
    "plt.title(\"Mean test score\", size=20)\n",
    "plt.xlabel(\"Num of experiment\", size=15)\n",
    "plt.ylabel(\"Accuracy\", size=15)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(model.cv_results_[\"param_metric\"])\n",
    "plt.title(\"Param Metric\", size=20)\n",
    "plt.xlabel(\"Num of experiment\", size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим, например, при фиксированных остальных параметрах (равных лучшим параметрам), качество модели на валидации в зависимости от числа соседей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_means = []\n",
    "selected_std = []\n",
    "num_neighbors = []\n",
    "for ind, params in enumerate(model.cv_results_[\"params\"]):\n",
    "    if (\n",
    "        params[\"metric\"] == model.best_params_[\"metric\"]\n",
    "        and params[\"weights\"] == model.best_params_[\"weights\"]\n",
    "    ):\n",
    "        num_neighbors.append(params[\"n_neighbors\"])\n",
    "        selected_means.append(model.cv_results_[\"mean_test_score\"][ind])\n",
    "        selected_std.append(model.cv_results_[\"std_test_score\"][ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим error bar для сравнения разброса ошибки при разном количестве соседей Neighbors.\n",
    "\n",
    "Видим, что на самом деле большой разницы в числе соседей, начиная с 11, и нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.title(f\"k-NN CV, {params['metric']}, {params['weights']}\", size=18)\n",
    "plt.errorbar(num_neighbors, selected_means, yerr=selected_std, fmt=\"-o\")\n",
    "plt.xticks(num_neighbors, size=13)\n",
    "plt.ylabel(\"Mean_test_score\", size=15)\n",
    "plt.xlabel(\"Neighbors\", size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативой GridSearch является [RandomizedSearch 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). Если в GridSearch поиск параметров происходит по фиксированному списку значений, то RandomizedSearch умеет работать с непрерывными значениями, случайно выбирая тестируемые значения, что может привести к более точной настройке гиперпараметров.\n",
    "\n",
    "Вы в явном виде указываете, сколько точек вы будете семплировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\"\"\"\n",
    "Parameters for RandomizedSearchCV:\n",
    "estimator — model\n",
    "cv — num of fold to cross-validation splitting\n",
    "param_distributions — parameters names\n",
    "n_iter — number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.\n",
    "scoring — metrics\n",
    "n_jobs — number of jobs to run in parallel, -1 means using all processors.\n",
    "\"\"\"\n",
    "\n",
    "model = RandomizedSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    n_iter=100,\n",
    "    cv=KFold(5, shuffle=True, random_state=42),\n",
    "    param_distributions={\n",
    "        \"n_neighbors\": np.arange(1, 31),\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "    },\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем лучшие гиперпараметры для модели, которые подобрали:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metric:\", model.best_params_[\"metric\"])\n",
    "print(\"Num neighbors:\", model.best_params_[\"n_neighbors\"])\n",
    "print(\"Weigths:\", model.best_params_[\"weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, параметры близки к выбранным полным перебором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объект `RandomizedSearchCV` также можно использовать как обычную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(\n",
    "    f\"Percent correct predictions {np.round(accuracy_score(y_pred=y_pred, y_true=y_test)*100,2)} %\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность уменьшилась на 0.5%. Возможно, такое понижение вам не критично."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы создать эффективное решение, важно сначала определить, что мы понимаем под «качеством». Для сравнения различных подходов и выбора лучшего из них необходимо понимать, как правильно измерять их эффективность, и для этого нам нужны соответствующие метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интуитивно понятной, очевидной и почти неиспользуемой метрикой является уже знакомая нам accuracy — доля правильных ответов алгоритма.\n",
    "\n",
    "$$ \\large \\text{Accuracy} = \\frac{P}{N}, $$\n",
    "\n",
    "где $P$ — количество верно предсказанных классов,\n",
    "\n",
    "$\\quad\\  N$ — общее количество тестовых примеров.\n",
    "\n",
    "**Недостатки метрики accuracy:**\n",
    "\n",
    "* **Несбалансированные классы.** Accuracy нельзя использовать, если данные не сбалансированы, то есть в одном из классов больше представителей, чем в другом.\n",
    "На рисунке ниже мы видим, что при явном количественном преобладании объектов класса airplane модель может классифицировать все объекты как airplane и при этом получить такую же точность, как модель, которая качественно разделяет все 3 класса, так как количество ошибок будет равно числу объектов классов, в которых меньше представителей (в данном случае в классах automobile и bird по 10 представителей, соответственно, 20 ошибок)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/problem_of_simple_way_to_compute_accuracy.png\" width=\"500\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Не различает типы ошибок.** Accuracy не учитывает, насколько критичны разные виды ошибок. Ошибки классификации бывают двух видов: **ошибка I-го рода** и **ошибка II-го рода**. Рассмотрим пример теста на беременность. Если женщина действительно беременна, то она принадлежит к классу с меткой 1, иначе — имеет метку 0. Пусть тест на беременность выполняет роль классификатора: показывает беременность (т.е. метку 1) или отсутствие беременности (метку 0).\n",
    "\n",
    "    Таким образом, решающее значение имеет то, какую ошибку выдает классификатор, потому что результат предсказания имеет разные последствия. Например, \"не беременна, но тест положительный\" соответствует ошибке I-го рода, а \"беременна, но тест отрицательный\" – ошибке II-го рода.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/1_2_errors.png\" width=\"400\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем решить эту проблему. Для этого сначала введём важную концепцию в терминах ошибок классификации — **confusion matrix** (матрицу ошибок). Допустим, у нас есть два класса и алгоритм, предсказывающий принадлежность каждого объекта к одному из классов. Тогда матрица ошибок классификации будет выглядеть следующим образом:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/conf_matrix.png\" width = \"600\"></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица ошибок имеет следующие обозначения:\n",
    "\n",
    "* **True Positive (TP):** количество правильных предсказаний для положительного класса.\n",
    "\n",
    "* **True Negative (TN):** количество правильных предсказаний для отрицательного класса.\n",
    "\n",
    "* **False Positive (FP):** количество неправильных предсказаний, когда отрицательный класс предсказан как положительный.\n",
    "\n",
    "* **False Negative (FN):** количество неправильных предсказаний, когда положительный класс предсказан как отрицательный.\n",
    "\n",
    "*Как легко запомнить: True/False — это верное предсказание или нет. Positive/Negative — это какой класс предсказал классификатор. Например, True Positive — предсказание верное (True), классификатор предсказал положительный класс (Positive).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя матрицу ошибок, можно рассчитать различные метрики качества классификации, такие как **accuracy**:\n",
    "\n",
    "\n",
    "$$\\large\\text{Accuracy} = \\dfrac{TP + TN}{TP + TN + FP + FN}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае дисбаланса классов можно посчитать метрику **balanced accuracy**. Она, в отличие от **accuracy**, учитывает дисбаланс классов:\n",
    "\n",
    "$$\\large\\text{Balanced Accuracy} = \\dfrac{1}{2} (\\dfrac{TP}{TP + FN} + \\dfrac{TN}{TN + FP})$$\n",
    "\n",
    "Посмотрим на примере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "fig.tight_layout(pad=3.0)\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "ax[0].set_title(\"Balanced data\")\n",
    "ax[1].set_title(\"Unbalanced data\")\n",
    "\n",
    "labels = [\"Airplane\", \"Auto\", \"Bird\"]\n",
    "\n",
    "# Balanced data\n",
    "air, auto, bird = 150, 150, 150\n",
    "actual_b = np.array([0] * air + [1] * auto + [2] * bird)\n",
    "predicted_b = np.array([0] * (air - 10) + [1] * (auto + 20) + [2] * (bird - 10))\n",
    "\n",
    "# Unbalanced data\n",
    "air, auto, bird = 430, 10, 10\n",
    "actual_ub = np.array([0] * air + [1] * auto + [2] * bird)\n",
    "predicted_ub = np.array([0] * (air + 20) + [1] * (auto - 10) + [2] * (bird - 10))\n",
    "\n",
    "metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix=metrics.confusion_matrix(actual_b, predicted_b),\n",
    "    display_labels=labels,\n",
    ").plot(ax=ax[0])\n",
    "\n",
    "metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix=metrics.confusion_matrix(actual_ub, predicted_ub),\n",
    "    display_labels=labels,\n",
    ").plot(ax=ax[1])\n",
    "\n",
    "label_font = {\"size\": \"15\"}  # Adjust to fit\n",
    "ax[0].set_xlabel(\"Predicted labels\", fontdict=label_font)\n",
    "ax[0].set_ylabel(\"True labels\", fontdict=label_font)\n",
    "ax[1].set_xlabel(\"Predicted labels\", fontdict=label_font)\n",
    "ax[1].set_ylabel(\"True labels\", fontdict=label_font)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f\"Accuracy for Balanced data   : {metrics.accuracy_score(actual_b, predicted_b):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Accuracy for Unbalanced data : {metrics.accuracy_score(actual_ub, predicted_ub):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Balanced accuracy for Balanced data   : {metrics.balanced_accuracy_score(actual_b, predicted_b):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Balanced accuracy for Unbalanced data : {metrics.balanced_accuracy_score(actual_ub, predicted_ub):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Для того, чтобы описать, как качественно алгоритм определяет метку объекта на каждом из классов и как много объектов из имеющихся находит, вводятся метрики **precision (точность)** и **recall (полнота)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/precision-recall.png\" width=\"650\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Precision} = \\dfrac{TP}{TP + FP}, \\quad \\text{Recall} = \\dfrac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Именно** введение **precision** не позволяет нам записывать все объекты в один класс, так как в этом случае мы получаем рост уровня False Positive. **Recall демонстрирует способность алгоритма обнаруживать данный класс вообще, а precision — способность отличать этот класс от других классов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_true = [0, 1, 0, 0, 1, 1]\n",
    "y_pred = [0, 1, 1, 1, 0, 1]\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-мера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто в реальной практике стоит задача найти **оптимальный** **баланс** между **Presicion и Recall**.\n",
    "\n",
    "Для этого вводится **$F_\\beta$-мера**:\n",
    "\n",
    "$$\\large F_\\beta = (1 + \\beta^2) \\cdot \\dfrac{\\text{precision} \\cdot \\text{recall}}{(\\beta^2 \\cdot \\text{precision}) + \\text{recall}}$$\n",
    "\n",
    "$\\beta$ в данном случае определяет относительное влияние precision и recall в метрике.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При $\\beta = 1$ $F_\\beta$-мера — это среднее гармоническое между Presicion и Recall.\n",
    "\n",
    "$$\\large F_1 = \\dfrac{2\\cdot\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$$\n",
    "\n",
    "F-мера достигает максимума, когда полнота и точность равны единице, и близка к нулю, если один из аргументов близок к нулю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более наглядно: низкие значения точности не позволяют метрике $F_1$ вырасти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/f1_lines.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Зависимость F1-меры от полноты при фиксированной точности. При точности 10% F1-мера не может быть больше 20%.</em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Sklearn есть удобная функция `sklearn.metrics.classification_report`, возвращающая recall, precision и F1-меру для каждого из классов, а также количество экземпляров каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "target_names = [\"class 0\", \"class 1\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть решается задача **бинарной классификации**, и необходимо оценить качество классификатора.\n",
    "\n",
    "В общем случае **классификатор выдаёт предсказания** не в виде \"0\" и \"1\", а **в виде вероятности принадлежности к классу \"1\" в промежутке между 0 и 1**.\n",
    "\n",
    "Для того, чтобы рассчитать все метрики, которые мы рассмотрели выше, требуется бинаризовать предсказания модели по некоторому порогу и построить confusion matrix.\n",
    "\n",
    "Стандартный порог = 0.5. Если вероятность больше порогового значения, объект считается принадлежащим к классу 1, если меньше&nbsp;— к классу 0.\n",
    "Однако порог можно выставить и другой. Для того, чтобы оценить качество модели, не выбирая конкретный порог, можно построить **ROC-кривую**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[wiki] 📚 ROC-кривая (Receiver Operating Characteristic curve)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) — это график изменения True Positive Rate (TPR) против изменения False Positive Rate (FPR) при переборе всех значений порога классификации.\n",
    "\n",
    "$\\text{TPR}$ и $\\text{FPR}$ вычисляются по по следующим формулам:\n",
    "\n",
    "$$\\large \\text{TPR} = \\dfrac{TP}{TP + FN}, \\quad \\text{FPR} = \\dfrac{FP}{FP + TN}$$\n",
    "\n",
    "**Площадь под ROC-кривой** (AUC-ROC, Area Under the ROC Curve) является численной характеристикой качества классификатора.\n",
    "\n",
    "**AUC-ROC является одной из немногих метрик, позволяющих оценить качество классификатора без необходимости подбора конкретного порога.**\n",
    "\n",
    "[[demo] 🎮 Интерактивная визуализация](http://navan.name/roc/) влияния порога на разделение двух классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим на примере. У нас есть таблица с предсказаниями модели (оценка уверенности в классе 1) и истинной разметкой классов. Отсортируем значения по убыванию оценки от модели.\n",
    "Если классификатор хорошо справляется с задачей, то вверху будет много единиц, а внизу — много нулей. Если классификатор неудачный — случайное распределение меток $0$ и $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/roc_auc_data_example.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приступим непосредственно к изображению графика ROC-кривой. Начнём с квадрата единичной площади и изобразим на нём прямоугольную координатную сетку, равномерно нанеся $m$ горизонтальных линий и $n$ вертикальных. Число горизонтальных линий $m$ соответствует количеству объектов класса $1$ из рассматриваемой выборки, а число $n$ — количеству объектов класса $0$. В нашем примере $m=3$ и $n=4$. Таким образом, квадрат единичной площади разбился на 12 ($m \\times n$) прямоугольных блоков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начиная из точки $(0, 0)$, построим ломаную линию в точку $(1, 1)$ по узлам получившейся решетки по следующему алгоритму, пройдя по строкам таблицы 2 сверху вниз:\n",
    "- **оценка** алгоритма для объекта из текущей строки не равна оценке для объекта из следующей:\n",
    " - если класс $1$, рисуем линию до следующего узла вертикально вверх\n",
    " - если класс $0$, рисуем линию до следующего узла горизонтально направо\n",
    "- оценки для объектов в нескольких последующих строках совпадают:\n",
    " - нарисовать линию из текущего узла в узел, располагающийся на $k$ углов вертикально выше и на $l$ узлов левее. $k$ и $l$ соответственно равны количеству объектов класса $1$ и $0$ среди группы повторяющихся оценок классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/make_roc_curve.png\" width=\"500\"/></center>\n",
    "\n",
    "<center><em>Рис.1. Построение ROC-кривой</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Линия справа** на рис. 1 и есть **ROC-кривая**. Вычислим площадь под получившийся кривой — **AUC-ROC**. AUC-ROC $= 9.5 / 12 \\sim 0.79$.\n",
    "\n",
    "\n",
    "Так как мы начали свое построение с квадрата единичной площади, то AUC-ROC может принимать значения в $[0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ROC-кривая абсолютно точного бинарного классификатора имеет вид единичного квадрата, его AUC-ROC = 1.\n",
    "\n",
    "2. Если классификатор для всех объектов предскажет одно и то же значение, то его AUC-ROC = 0.5\n",
    "\n",
    "3. ROC-кривая для всегда ошибающегося бинарного классификатора, в этом случае AUC-ROC = 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/various_roc_curves.png\" width=\"500\"/></center>\n",
    "\n",
    "<center><em>Рис. 2. ROC-кривые для наилучшего (AUC=1), константного (AUC=0.5) и наихудшего (AUC=0) алгоритма</em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем датасет для демонстрации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "y_true = np.random.randint(0, 2, size=n_samples)  # true labels (0 or 1)\n",
    "\n",
    "# Generate proba\n",
    "y_score = 0.3 * y_true + 0.7 * np.random.rand(n_samples)\n",
    "\n",
    "data = pd.DataFrame({\"y_true\": y_true, \"y_scores\": y_score})\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим ROC-кривую в коде и отобразим ее, а также посчитаем AUC-ROC.\n",
    "\n",
    "Построить ROC-кривую можно с помощью функции `sklearn.metrics.roc_curve` [🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html). Она принимает на вход:\n",
    "* массив истинных меток классов `y_true`,\n",
    "* массив оценок вероятностей `y_score`.\n",
    "\n",
    "И возвращает:\n",
    "\n",
    "* массив значений FPR,\n",
    "* массив значений TPR,\n",
    "* массив перебранных порогов.\n",
    "\n",
    "Посчитать AUC-ROC можно с помощью функции `sklearn.metrics.roc_auc_score` [🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html). Она принимает на вход массивы `y_true` и `y_score` и возвращает значение AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_score)\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random classifier\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на значения нагляднее, где $\\text{TPR}, \\text{FPR}$ для каждого порога:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.DataFrame({\"FPR\": fpr[1:], \"TPR\": tpr[1:], \"thresholds\": thresholds[1:]})\n",
    "\n",
    "df_tmp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PR-кривая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PR-кривая (Precision-Recall Curve) – графическое представление взаимосвязи между precision и recall модели при различных порогах классификации.\n",
    "\n",
    "PR-кривую можно построить с помощью функции `sklearn.metrics.precision_recall_curve` [🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html).\n",
    "\n",
    "Она принимает на вход массивы `y_true` и  `y_score` и возвращает массивы значений Precision, Recall и перебранных порогов.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Compute Precision-Recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f\"PR AUC: {pr_auc:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f\"PR curve (area = {pr_auc:.2f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике PR-кривой видно, что при фиксированном значении recall существуют значения порога, которые обеспечивают наилучшее значение precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае многоклассовой классификации термины $\\text{TP, FP, TN, FN}$ считаются для каждого класса:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L01/out/confmatrix.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "y_pred = np.random.randint(4, size=(200,))\n",
    "y_true = np.random.randint(4, size=(200,))\n",
    "\n",
    "label_names = [\"label A\", \"label B\", \"label C\", \"label D\"]\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае многоклассовой классификации есть различные способы усреднения результатов, рассмотрим их подробнее на примере расчета метрики $\\text{Precision}$:\n",
    "1. **Micro-усреднение**\n",
    "\n",
    "Сначала объединяем все истинные положительные $\\text{(TP)}$, ложные положительные $\\text{(FP)}$ значения по всем классам, а затем считаем метрику на этой общей сумме.\n",
    "\n",
    "Предположим, у нас есть три класса:\n",
    "\n",
    "$$\\text{Класс A: TP = 10, FP = 3}$$\n",
    "\n",
    "$$\\text{Класс B: TP = 15, FP = 8}$$\n",
    "\n",
    "$$\\text{Класс C: TP = 12, FP = 2}$$\n",
    "\n",
    "Общая точность по micro будет считаться как сумма всех $\\text{TP и FP}$:\n",
    "\n",
    "$$\\text{TP = 10 + 15 + 12 = 37}$$\n",
    "\n",
    "\n",
    "$$\\text{FP = 3 + 8 + 2 = 13}$$\n",
    "\n",
    "$$\\text{Micro-Precision = }{\\frac{37}{37+13}\\approx 0.74}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Macro-усреднение**\n",
    "\n",
    "Сначала рассчитываются метрики отдельно для каждого класса, затем берётся среднее арифметическое.\n",
    "\n",
    "Те же данные, теперь считаем точность для каждого класса отдельно:\n",
    "\n",
    "$$\\text{Precision}_{A} = \\frac{10}{10+3}\\approx 0.769$$\n",
    "\n",
    "$$\\text{Precision}_{B} = \\frac{15}{15+8}\\approx 0.652$$\n",
    "\n",
    "$$\\text{Precision}_{C} = \\frac{12}{12+2}\\approx 0.857$$\n",
    "\n",
    "$$\\text{Macro-Precision} = \\frac{0.769 + 0.652 + 0.857}{3}\\approx 0.759$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Weighted-усреднение**\n",
    "\n",
    "Классы взвешиваются в зависимости от их размера (количества объектов).\n",
    "\n",
    "Если класс $\\text{A}$ имеет $\\text{100}$ объектов, $\\text{B – 200, C – 50:}$\n",
    "\n",
    "$$\\text{Precision}_{A} = 0.769 × 100 = 76.9$$\n",
    "\n",
    "$$\\text{Precision}_{B} = 0.652 × 200 = 130.4$$\n",
    "\n",
    "$$\\text{Precision}_{C} = 0.857 × 50 = 42.85$$\n",
    "\n",
    "$$\\text{Weighted-Precision} = \\frac{76.9 + 130.4 + 42.85}{100 + 200 + 50} \\approx 0.715$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно!** Обращайте внимание, какое усреднение используется при расчете метрик для многоклассовой классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L01/three_types_of_classification_tasks.jpg\" width=\"650\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://thinkpalm.com/blogs/top-machine-learning-algorithms-for-business-applications-in-2023/\">Top Machine Learning Algorithms For Business Applications In 2023</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cлучай, когда объект может принадлежать одновременно нескольким классам, называется *multilabel* (многозначная) классификация. Такую задачу не стоит сводить к задаче бинарной классификации по каждому классу, так как метки могут быть не независимыми.\n",
    "\n",
    "Допустим, у нас есть 3 объекта, и модель предсказала нам 3 набора меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "y_true = [[0,1,1,1],\n",
    "         [0,0,1,0],\n",
    "         [1,1,0,0]]\n",
    "\n",
    "y_pred = [[0,1,0,1],\n",
    "          [0,1,1,1],\n",
    "          [1,0,1,1]]\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Confusion Matrix**\n",
    "\n",
    "Специальная функция, которая создаст 4 матрицы, по одной на каждый класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "multilabel_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также есть еще один способ усреднения:\n",
    "\n",
    "4. **Samples-усреднение**\n",
    "\n",
    "Допустим, у нас есть три образца, и для каждого образца предсказания делаются по нескольким классам. Например:\n",
    "\n",
    "- **Объект 1**: Истинные метки $\\text{[1, 0, 1]}$, предсказанные метки $\\text{[1, 0, 1]}$\n",
    "- **Объект 2**: Истинные метки $\\text{[0, 1, 0]}$, предсказанные метки $\\text{[0, 0, 0]}$\n",
    "- **Объект 3**: Истинные метки $\\text{[1, 1, 1]}$, предсказанные метки $\\text{[1, 1, 0]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем $\\text{Precision}$ для каждого образца:\n",
    "\n",
    "* **Образец 1**:\n",
    "    - Истинные метки: $\\text{[1, 0, 1]}$\n",
    "    - Предсказанные метки: $\\text{[1, 0, 1]}$\n",
    "    - Здесь $\\(\\text{TP} = 2\\)$ и $\\(\\text{FP} = 0\\)$\n",
    "    - $\\text{Precision} = \\dfrac{2}{2 + 0} = 1.0\\$\n",
    "\n",
    "* **Образец 2**:\n",
    "    - Истинные метки: $\\text{[0, 1, 0]}$\n",
    "    - Предсказанные метки: $\\text{[0, 0, 0]}$\n",
    "    - Здесь $\\(\\text{TP} = 0\\)$ и $\\(\\text{FP} = 0\\)$\n",
    "    - $\\text{Precision} = 0$ (не определён, но считается как 0, если нет предсказаний)\n",
    "\n",
    "* **Образец 3**:\n",
    "    - Истинные метки: $\\text{[1, 1, 1]}$\n",
    "    - Предсказанные метки: $\\text{[1, 1, 0]}$\n",
    "    - Здесь $\\(\\text{TP} = 2\\)$ и $\\(\\text{FP} = 0\\)$\n",
    "    - $\\text{Precision} = \\dfrac{2}{2 + 0} = 1.0\\$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы усредняем $\\text{Precision}$ для всех трёх образцов:\n",
    "\n",
    "$$\\text{Samples-Precision} = \\frac{1.0 + 0.0 + 1.0}{3} \\approx 0.67$$\n",
    "\n",
    "В отличие от других методов усреднения (например, Micro или Macro), здесь мы фактически оцениваем предсказания для каждого образца, а затем усредняем результаты, что даёт более точное представление о модели в задаче многозначной классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[colab] 🥨 Блокнот на Kaggle с примерами расчётов Multilabel](https://www.kaggle.com/code/kmkarakaya/multi-label-model-evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задаче **регрессии** мы используем входные **признаки**, чтобы предсказать **целевые значения**, являющиеся вещественными числами. Например, можно предсказывать цену жилья по его характеристикам (площадь, этаж, год постройки дома, высота потолков, район, ...).\n",
    "\n",
    "В нашем примере будем использовать уже знакомый алгоритм k-NN, но для регресии. Работает он следующим образом:\n",
    "1. Запоминаем объекты обучающей выборки.\n",
    "2. Для нового объекта ищем $k$ ближайших соседей.\n",
    "3. Предсказание для нового объекта — **это среднее значение целевой переменной $k$ ближайших соседей**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем данные для демонстрации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(100, 1)\n",
    "y = 2 + 3 * x + (np.random.rand(100, 1) - 0.5)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y, s=30)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем разделение на выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data to train and val\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print(\"Train:\", np.array(x_train).shape, np.array(y_train).shape)\n",
    "print(\"Val:\", np.array(x_val).shape, np.array(y_val).shape)\n",
    "print(\"Total:\", np.array(x).shape, np.array(y).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим `KNeighborsRegressor` [🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) и сделаем предсказание на отложенной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=3)\n",
    "knn_regressor.fit(x_train, y_train)\n",
    "y_pred = knn_regressor.predict(x_val)\n",
    "print(f\"predicted: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot true vs predicted values\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x_val, y_val, color=\"blue\", label=\"True values\", s=30)\n",
    "plt.scatter(x_val, y_pred, color=\"orange\", label=\"Predicted values\", s=30)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE (mean absolute error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценить качество модели, посчитаем среднюю абсолютную ошибку $\\text{MAE}$:\n",
    "\n",
    "$$\\large \\text{MAE} = \\frac{1}{N} \\sum |y_i - f(x_i)|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(np.abs(y_val - y_pred))\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразим, как выглядит ошибка графически:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x_val, y_val, color=\"blue\", label=\"True values\", s=30)\n",
    "plt.scatter(x_val, y_pred, color=\"orange\", label=\"Predicted values\", s=30)\n",
    "for i in range(len(x_val)):\n",
    "    plt.plot([x_val[i], x_val[i]], [y_val[i], y_pred[i]], \"r--\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{MAE}$ показывает, на сколько в среднем наши предсказания отличаются от реальных значений по модулю.\n",
    "\n",
    "**Когда применять:** $\\text{MAE}$ полезна, когда нам важны простота и интерпретируемость. Она одинаково наказывает все ошибки, без сильного акцента на большие ошибки.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `sklearn.metrics` есть много удобных инструментов для работы с метриками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(f\"Mean absolute error: {mean_absolute_error(y_val, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE (mean squared error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая метрика — $\\text{MSE}$. Она измеряет среднее значение квадратов ошибок. Из-за возведения ошибок в квадрат большие ошибки наказываются сильнее.\n",
    "\n",
    "$$\\large \\text{MSE}  = \\frac{1}{N} \\sum \\left(y_i - f(x_i)\\right)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(f\"mean_squared_error: {mean_squared_error(y_val, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Когда применять:** $\\text{MSE}$ полезна, когда нам важно минимизировать крупные ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE (root mean squared error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить оценку ошибки в размерности целевой переменной, можно взять корень (root) от $\\text{MSE}$. Это метрика $\\text{RMSE}$:\n",
    "\n",
    "$$\\large \\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum \\left(y_i - f(x_i)\\right)^2}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "print(f\"root_mean_squared_error: {root_mean_squared_error(y_val, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Когда применять:** $\\text{RMSE}$ часто используют в тех же случаях, что и $\\text{MSE}$, но она более интерпретируема, так как результат находится в тех же единицах измерения, что и данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют и более специфичные метрики, например, $R^2$, которая принимает значения из $(-\\infty, 1]$, где $1$  —  наилучший вариант. $R^2$ называется [коэффициентом детерминации 📚[wiki]](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%8D%D1%84%D1%84%D0%B8%D1%86%D0%B8%D0%B5%D0%BD%D1%82_%D0%B4%D0%B5%D1%82%D0%B5%D1%80%D0%BC%D0%B8%D0%BD%D0%B0%D1%86%D0%B8%D0%B8) и характеризует долю дисперсии целевого значения, которую объясняет модель.\n",
    "\n",
    "$$\\large R^2 = 1 - \\frac{\\text{MSE}}{\\sigma_y^2}=1 - \\frac{\\sum {\\left(y_i-f(x_i)\\right)^2}}{\\sum{\\left(y_i-\\bar{y}\\right)^2}},$$\n",
    "\n",
    "$$\\large \\bar{y} = \\frac{1}{N}\\sum {y_i},$$\n",
    "\n",
    "где $\\sigma_y^2$ — дисперсия целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(f\"R2 score: {r2_score(y_val, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Интуиция:** $R^2$ показывает качество модели в сравнении со случайным предсказателем.\n",
    "\n",
    "**Когда применять:** $R^2$  полезен для оценки общей способности модели объяснять вариацию в данных. Также удобен для сравнения разных моделей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSLE (mean squared logarithmic error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В некоторых задачах регрессии ошибки могут иметь разные последствия в зависимости от того, перепредсказали мы или недопредсказали значение. В таких случаях лучше использовать несимметричные метрики, которые учитывают, что одни ошибки хуже других.\n",
    "\n",
    "Например, мы предсказываем количество лекарств на скаладе больницы. Если мы перепредскажем их количество, то останутся излишки, которые могут испортиться. Если мы недопредскажем, то пострадают пациенты. В такой ситуации недопредсказание более критично."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{MSLE}  = \\frac{1}{N} \\sum \\left(\\ln \\left(1+y_i\\right) - \\ln \\left(1+f(x_i)\\right)\\right)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "y_true = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "y_pred1 = np.array([15, 25, 35, 45, 55])  # overprediction\n",
    "y_pred2 = np.array([5, 15, 25, 35, 45])  # underprediction\n",
    "\n",
    "print(\n",
    "    f\"mean_squared_log_error overprediction: {mean_squared_log_error(y_true, y_pred1):.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"mean_squared_log_error underprediction: {mean_squared_log_error(y_true, y_pred2):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее про метрики можно почитать [тут 📚[book]](https://academy.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii). Там же вы можете найти информацию об относительных ошибках, выражаемых в процентах. Выбор метрики в реальной задаче зависит от традиции, сложившейся в области, поэтому для выбора метрик важно провести литературный обзор.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Литература</font>\n",
    "\n",
    "<font size=\"5\">Полезное:</font>\n",
    "\n",
    "* [[article] 🎓 Работы выпускников](https://msu.ai/articles)\n",
    "* [[book] 📚 Как писать научные статьи?](https://stepik.org/course/10524/promo)\n",
    "\n",
    "<font size=\"5\">Данные:</font>\n",
    "* [[doc] 🛠️ Соревнования Kaggle](https://www.kaggle.com/datasets)\n",
    "* [[doc] 🛠️ Google Datasets](https://datasetsearch.research.google.com/)\n",
    "* [[article] 🎓 Сайт Papers with Code](https://paperswithcode.com/)\n",
    "* [[arxiv] 🎓 Поведение нейросетей и ошибки в разметке](https://arxiv.org/abs/2211.01866)\n",
    "* [[blog] ✏️ Обсуждение проблемы различия данных при обучении и на инференсе](https://stats.stackexchange.com/questions/362906/co-variate-shift-between-train-and-test-data-set)\n",
    "* [[doc] 🛠️ Датасет c трафиком из DARPA](https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)\n",
    "* [[doc] 🛠️ CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "<font size=\"5\">Руководства:</font>\n",
    "\n",
    "* [[blog] ✏️ Эндрю Ын. Страсть к Машинному обучению](https://habr.com/ru/articles/419757/)\n",
    "* [[git] 🐾 Три блокнота с подробным анализом реального датасета](https://github.com/AleksandrIvchenko/machine-learning-project-walkthrough)\n",
    "* [[blog] ✏️ Как избежать «подводных камней» машинного обучения: руководство для академических исследователей](https://habr.com/ru/post/664102/) — гайд по типичным ошибкам\n",
    "\n",
    "<font size=\"5\">Инструменты:</font>\n",
    "\n",
    "* [[doc] 🛠️ NumPy](https://numpy.org/) — массивы и математические функции\n",
    "* [[doc] 🛠️ Scikit-learn](https://scikit-learn.org/stable/) — ML алгоритмы, \"toy\"-датасеты\n",
    "* [[doc] 🛠️ Pandas](https://pandas.pydata.org/) — табличные данные\n",
    "* [[doc] 🛠️ **PyTorch**](https://pytorch.org/) — нейросети\n",
    "* [[doc] 🛠️ Matplotlib](https://matplotlib.org/) — визуализация\n",
    "* [[doc] 🛠️ Seaborn](https://seaborn.pydata.org/) — визуализация статистик\n",
    "\n",
    "<font size=\"5\">Методы и алгоритмы:</font>\n",
    "\n",
    "* [[wiki] 📚 Метод k-ближайших соседей](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "* [[wiki] 📚 Функции расстояния между парой точек](https://en.wikipedia.org/wiki/Metric_space)\n",
    "* [[git] 🐾 Быстрый k-NN Facebook AI Research Similarity Search](https://github.com/facebookresearch/faiss)\n",
    "* [[arxiv] 🎓 Hierarchical Navigable Small World](https://arxiv.org/abs/1603.09320) — алгоритм поиска ближайших соседей\n",
    "\n",
    "<font size=\"5\">Другое:</font>\n",
    "\n",
    "* [[blog] ✏️ Цветовые пространства](https://habr.com/ru/articles/181580/)\n",
    "* [[blog] ✏️ Стратификация](https://www.reneshbedre.com/blog/stratified-sampling.html)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
