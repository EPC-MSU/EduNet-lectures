{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Введение в машинное обучение</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Два пути"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть наручный шагомер, который фиксирует перемещения в пространстве. В него встроен акселерометр, который способен фиксировать перемещения по трем осям. На выходе мы получаем сигнал с трёх датчиков.\n",
    "\n",
    "Если задача состоит в том, чтобы подсчитать количество шагов, то к её решению можно подойти двумя способами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/accelerometer_task.jpg\" width=\"700\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вариант №1, Классический**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Напишем программу.**\n",
    "Если появилось ускорение по одной из осей, которое больше определенного порога, то мы создаем то условие, которое срабатывает. Позже мы выясним, что подобные сигнатурные сигналы с датчика могут поступить и при других определенных движениях, не связанных с шагами, например, во время плавания.\n",
    "Добавляется дополнительное условие, которое фильтрует подобные ситуации.\n",
    "\n",
    "Находятся всё новые и новые исключения из общего правила, программа и ее алгоритмическая сложность будут расти.\n",
    "\n",
    "Программу будет сложнее поддерживать из-за большого объема кода в ней.\n",
    "Изменение в одной из частей потребует внесение правок в другой код и т.п."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/accelerometr_solution_standart.png\" width=\"700\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вариант №2, Машинное обучение**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С появлением **машинного обучения** мы можем применить принципиально другой подход.\n",
    "Не задумываясь о том, что значат показания каждого из акселерометров, мы можем просто собрать некоторый архив данных за определенное время (возможно, разбив на более короткие промежутки времени). Всё, что нам потребуется помимо этих данных — это информация о том, сколько было сделано реальных шагов. После этого данные загружаются в модель, и она на этих данных учится. При достаточном количестве данных и адекватно подобранной модели (чем мы и будем заниматься) мы сможем научить ее решать конкретные задачи (в данном случае — считать шаги)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/accelerometr_solution_nn.png\" width=\"700\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фактически, мы приближаем реальную функцию $F_{real}$ некоторой функцией $F$: $$\\large {F = \\sum_i w_{i} x_{i} + b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути, модели всё равно, что считать: шаги, сердечный ритм, количество калорий, ударов по клавиатуре и пр. Нет необходимости писать под каждый пример отдельную программу: достаточно собрать данные, и мы сможем решить множество абсолютно разных задач.\n",
    "\n",
    "Важно лишь понимать, какую модель предпочтительнее выбрать. С этим мы будем разбираться в ходе курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача курса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  AI, ML, DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Место глубокого обучения и нейронных сетей в ИИ**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/ai_ml_dl.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Искусственный интеллект (AI/ИИ)**  — область IT/Computer science, связанная с моделированием интеллектуальных или творческих видов человеческой деятельности.\n",
    "\n",
    "**Машинное обучение (ML)** — подраздел ИИ, связанный с разработкой алгоритмов и статистических моделей, которые компьютерные системы используют для выполнения задач без явных инструкций.\n",
    "\n",
    "**Глубокое обучение (Deep Learning, DL)** — совокупность методов машинного обучения, основанных на искуcственных нейронных сетях и обучении представлениям (**feature/representation learning**). Данный класс методов автоматически выделяет из необработанных данных необходимые признаки (представления), в отличие от методов ML, в которых признаки создают люди вручную (**feature engineering**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует множество определений сильного и слабого ИИ, рассуждений о появлении искусственного сознания и восстании машин.\n",
    "\n",
    "Всё намного **приземлённее**. Есть набор **объектов $X$**, набор **ответов $Y$**. Пары \"объект-ответ\" составляют **обучающую выборку**.\n",
    "\n",
    "Мы будем заниматься **восстановлением решающей функции $F$**, которая переводит признаки $X$, описывающие объекты, в ответы $Y$.\n",
    "\n",
    "$$ F: X \\xrightarrow\\ Y $$\n",
    "\n",
    "Позже мы уточним постановку задачи и увидим, что **функцию восстанавливаем с погрешностью**, в каких-то задачах **нет ответов $Y$**, а где-то мы **создаём новые объекты ${\\hat X}$** на основе исходных объектов $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Области применения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/ai_ml_dl_cv_nlp_sr.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последнее время именно такого рода модели показывают высокую эффективность в тех областях, с которыми ранее могли справиться только люди. В частности:\n",
    "* **компьютерное зрение** (Computer Vision, CV);\n",
    "* **распознавание и анализ речи** (NLP, извлечение смысла, Speech recognition, машинный перевод).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Связь с наукой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/ai_ml_dl_cv_nlp_sr_science.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Научные исследования таковы, что результаты у них в известной степени непредсказуемы. Одна из задач нашего курса — **научиться применять нейросети к решению новых задач**, в том числе в областях, где ранее такие технологии активно не использовались.\n",
    "\n",
    "В первую очередь для нас важны задачи слушателей курса, а успешным прохождением мы считаем **решённую научную задачу** и написанную по этому поводу **статью**.\n",
    "\n",
    "В течение 15-ти лекций мы будем рассказывать теорию и практиковаться, далее плотно займёмся научной работой. Хотя, в целом, её можно начинать уже прямо сейчас.\n",
    "\n",
    "Преподаватели будут выступать в качестве менторов и помогать вам с выбором подходящих моделей, проверкой гипотез, поиском ошибок. По ходу курса будет несколько воркшопов, где мы всем коллективом будем давать советы по вашим задачам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обзор курса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 1 Введение в Машинное Обучение</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Показать шаблон решения задач\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* База\n",
    "* Инструменты\n",
    "* Работа с данными\n",
    "* Оценка и валидация результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 2 Линейные модели</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Сделать простое базовое решение\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Базовые алгоритмы\n",
    "* Основы обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/l02_example.png\" width=\"900\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 3 Классическое машинное обучение</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться полностью проходить пайплайн решения задачи с помощью МЛ\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Разведочный анализ\n",
    "* Деревья\n",
    "* Бустинги\n",
    "* Ансамбли моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/random_forest.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 4 Генерация и отбор признаков</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться выбирать оптимальный набор признаков\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Анализ важности\n",
    "* Генерация признаков\n",
    "* Методы понижения размерности\n",
    "* Визуализация многомерных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/pca_tsne_umap_on_mnist.png\" width=\"1000\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 5 Нейронные сети</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться писать и учить простые нейросети\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Основные блоки нейросетей\n",
    "* Способы обучения\n",
    "* Выбор параметров моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/nn_fully_connected.png\" width=\"450\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 6 Свёрточные  сети</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться решать задачи компьютерного зрения\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Всевозможные виды свёрток\n",
    "* Выбор параметров моделей\n",
    "* Хитрости работы с картинками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/cv.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 7 Оптимизация нейронных сетей</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться учить сети, если они не учатся\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Поиск проблем и их решений\n",
    "* Улучшение сходимости\n",
    "* Советы и практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 8 Архитектуры нейронных сетей</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться выбирать оптимальную архитектуру\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Подходы к построению архитектур\n",
    "* Лучшие сети и их особенности\n",
    "* Библиотеки моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/my_architecture.png\" width=\"500\" ></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 9 Рекуррентные нейронные сети</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться обрабатывать последовательности\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Обработка временных рядов\n",
    "* NLP классический\n",
    "* NLP нейросетевой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/nlp_processing.png\"  width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://machinelearningmastery.ru/deep-learning-structured-data-8d6a278f3088/\">MachineLearningMastery\n",
    "</a></em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 10 Трансформеры</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться решать задачи NLP и компьютерного зрения ещё круче\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Готовые трансформеры\n",
    "* Дообучение под задачу\n",
    "* Проблемы и пути решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/transformers.png\" width=\"500\" ></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.toplyne.io/blog/hugging-face-monetization-and-growth\">Transformers: The rise and rise of Hugging Face\n",
    "</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 11 Сегментация и детектирование</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться решать продвинутые задачи компьютерного зрения\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Продвинутая работа с изображениями\n",
    "* Крутые решения \"из коробки\"\n",
    "* Написание своих архитектур"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/object_detection.jpg\" width=\"500\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 12 Representation learning</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться решать задачи, когда данных мало, или когда постоянно появляются новые сущности\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Векторные представления данных\n",
    "* Новые архитектурные подходы\n",
    "* Векторная арифметика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/vector_arithmetic_example.png\" width=\"500\" ></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/#:~:text=First%2C%20let%E2%80%99s%20get,the%20autoencoded%20version\">Generating Large Images from Latent Vectors</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 13 Генеративные сети</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться создавать новые данные\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Новые архитектуры и подходы\n",
    "* Приложения на практике\n",
    "* Работа не с картинками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/style_transfer_gan.jpg\" width=\"800\" ></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 14 Explainability</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться вскрывать и анализировать \"черные ящики\"\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Методы для разных типов данных\n",
    "* Готовые решения\n",
    "* Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/input_blackbox_output.png\" width=\"500\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>Лекция 15 Обучение с подкреплением</big>\n",
    "\n",
    "**Зачем:**\n",
    "\n",
    "* Научиться ̶з̶а̶х̶в̶а̶т̶ы̶в̶а̶т̶ь̶ ̶м̶и̶р̶ управлять роботами\n",
    "\n",
    "**Что будет:**\n",
    "\n",
    "* Ключевые подходы к задаче\n",
    "* Готовые модули для вашего решения\n",
    "* Применение для более классических задач"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/gangnam.gif\" width=\"900\" ></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://bair.berkeley.edu/blog/2018/10/09/sfv/\"> Learning Acrobatics by Watching YouTube. Xue Bin (Jason) Peng and Angjoo Kanazawa</a></em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовые"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем случае **задача классификации выглядит следующим образом**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/classification_task.png\" width=\"700\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация — **отнесение образца к одному из нескольких попарно не пересекающихся множеств**.\n",
    "\n",
    "В качестве образцов могут выступать различные по своей природе объекты, например:\n",
    "* символы текста,\n",
    "* изображения,\n",
    "* звуки.\n",
    "\n",
    "При обучении сети предлагаются **пары образец-класс**. Образец, как правило, представляется как **вектор значений признаков**. При этом совокупность всех признаков должна однозначно определять класс, к которому относится образец. В случае, если признаков недостаточно, сеть может соотнести один и тот же образец с несколькими классами, что неверно. По окончании обучения сети ей можно предъявлять неизвестные ранее образцы и получать ответ об их принадлежности к определённому классу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/regression_task.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Способности нейронной сети к прогнозированию напрямую следуют из её **способности к обобщению** и **выделению скрытых зависимостей** между входными и выходными данными. После обучения сеть способна **предсказать будущее значение** некой последовательности на основе нескольких предыдущих значений и (или) каких-то существующих в настоящий момент факторов.\n",
    "\n",
    "Прогнозирование возможно только тогда, когда предыдущие изменения действительно в какой-то степени предопределяют будущие. Например, прогнозирование котировок акций на основе котировок за прошлую неделю может оказаться успешным (а может и не оказаться), тогда как прогнозирование результатов завтрашней лотереи на основе данных за последние 50 лет почти наверняка не даст никаких результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/clustering_task.png\" width=\"700\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация — **разбиение множества входных сигналов на классы при том, что ни количество, ни признаки классов заранее не известны**. После обучения модель способна определять, к какому классу относится входной сигнал. Модель также может сигнализировать о том, что входной сигнал не относится ни к одному из выделенных классов — это является признаком новых, отсутствующих в обучающей выборке данных. Таким образом, подобная модель может выявлять новые, неизвестные ранее классы сигналов. Соответствие между классами, выделенными сетью, и классами, существующими в предметной области, устанавливается человеком.\n",
    "\n",
    "Относится к задачам **обучения без учителя**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Комбинированные задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют работы, которые **комбинируют в себе несколько задач разом**. Типичным примером является задача **Object Detection**.\n",
    "\n",
    "**Детектирование = Классификация + Регрессия**.\n",
    "\n",
    "Мы отмечаем координаты рамок (регрессия) и классифицируем объект в рамке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/object_detection.png\" width=\"700\" ></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://neerc.ifmo.ru/wiki/index.php?title=%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BD%D0%B0%D1%85%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2_%D0%BD%D0%B0_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B8\">ИТМО\n",
    "</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комбинирование знаний и навыков**\n",
    "\n",
    "Вашим преимуществом станет **комбинирование узкоспециализированных знаний** в вашей предметной области **и машинного обучения**.\n",
    "\n",
    "Одним из самых известных примеров является **AlphaFold**.\n",
    "Коллектив обладал компетенциями в области биологии, физики, математики, алгоритмов глубокого обучения и оптимизации — то есть в области вычислительной биологии.\n",
    "\n",
    "Работа была посвящена проблеме получения структуры белка, который бы отвечал заранее заданным свойства. Была обучена нейросеть, которая предсказывает расстояния и углы между атомами аминокислот в конечном белке, а также  структуру белка в 3D-виде."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/alpha.gif\" width=\"1000\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.nature.com/articles/s41586-021-03819-2\">Jumper, John, et al. \"Highly accurate protein structure prediction with AlphaFold.\" Nature 596.7873 (2021): 583-589.</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, вы решили заняться разработкой приложения для определения породы кошек. Как будет выглядеть план исследования?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/pipeline.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где можно добыть данные?\n",
    "\n",
    "* Эксперименты в вашей лаборатории\n",
    "* [Соревнования Kaggle](https://www.kaggle.com/)\n",
    "* [Google Datasets](https://datasetsearch.research.google.com/)\n",
    "* [Сайт Papers with Code](https://paperswithcode.com/)\n",
    "\n",
    "Пройдитесь по соседним лабораториям. Напишите письма авторам статей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы используете данные, скачанные из сети, проверьте, откуда они. Описаны ли они в статье? Если да, посмотрите на документ; убедитесь, что он был опубликован в авторитетном месте, и проверьте, упоминают ли авторы какие-либо ограничения на использованные датасеты.\n",
    "\n",
    "Если данные использовались в ряде работ, это еще не гарантирует высокое качество датасета. **Иногда данные используются только потому, что их легко достать**.\n",
    "\n",
    "Даже широко распространённые датасеты могут иметь ошибки или какую-то странную специфику. Например, при исследовании **ImageNet** были обнаружены миллионы изображений темнокожих, которые были помечены как \"преступник\". В итоге большая часть набора данных ImageNet была удалена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/imagenet_bugs.png\" width=\"500\" ></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://labelerrors.com/\">Label Errors in ML Test Sets</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют [исследования 🎓[arxiv]](https://arxiv.org/abs/2211.01866), которые связывают странное поведение современных нейронных сетей и ошибки в разметке.\n",
    "\n",
    "Если вы обучаете свою модель на плохих данных, то, скорее всего, у вас получится плохое решение задачи. Существует соответствующий термин: **garbage in, garbage out**. Всегда начинайте с проверки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение vs применение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как будут выглядеть данные во время **инференса** модели?\n",
    "\n",
    "Не окажется ли, что при обучении все кошки были мохнатые, а на инференсе попался сфинкс?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/cats.jpg\" width=\"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://dzen.ru/a/XfNtCpylEgCtH1c7\">Дзен</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что делать?**\n",
    "\n",
    "* Добавить целевые данные\n",
    "* Попробовать оценить смещение признаков данных и добавить это смещение к данным при обучении\n",
    "* Костыли и велосипеды\n",
    "\n",
    "Подробнее с этим вы познакомитесь в ходе курса.\n",
    "\n",
    "[[stackexchange] 🎓 Обсуждение проблемы](https://stats.stackexchange.com/questions/362906/co-variate-shift-between-train-and-test-data-set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разведочный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory data analysis**, EDA — анализ основных свойств данных, нахождение в них общих закономерностей, распределений и аномалий, построение начальных моделей с использованием инструментов визуализации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/eda.png\" width=\"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://chernobrovov.ru/articles/kak-naglyadno-pokazat-data-science-vizualizaciya-bolshih-dannyh.html\">Как наглядно показать Data Science</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее с этим вы познакомитесь в следующих лекциях.\n",
    "\n",
    "Примеры:\n",
    "\n",
    "* [[git] 🐾 Три блокнота с подробным анализом реального датасета](https://github.com/AleksandrIvchenko/machine-learning-project-walkthrough).\n",
    "\n",
    "* [[blog] ✏️ Как избежать «подводных камней» машинного обучения: руководство для академических исследователей](https://habr.com/ru/post/664102/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постройте вашу первую систему быстро**, а затем итерационно улучшайте.\n",
    "\n",
    "Возьмите что-то простое, готовое. Ваша сложная модель должна работать не хуже.\n",
    "\n",
    "Возможно, даже простая модель сможет решить вашу задачу **с достаточным качеством**.\n",
    "\n",
    "**Учтите нижнюю границу качества.** За baseline можно считать известное значение. Например, результат работы классических методов или качество решения задачи человеком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**А как измерить это качество?**\n",
    "\n",
    "По ходу курса мы познакомимся с великим множеством **метрик** для различных задач. Важно, что любая из них **должна быть выбрана заранее**, до получения результатов.\n",
    "\n",
    "Фактически вы оцениваете, какой показатель нужно улучшить и как этот показатель измерить.\n",
    "\n",
    "Метрика должна отвечать **целевой задаче**.\n",
    "\n",
    "Так, отличной метрикой при разработке генератора упражнений для изучения программирования может быть улучшение оценок слушателей на внешних экзаменах.\n",
    "\n",
    "Обищй совет: используйте **однопараметрические метрики**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так, если у нас есть 2 классификатора, вводя две метрики, тяжело оценить, какой из них лучше — А или В."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/metric1.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но если эти метрики объединить в одну, провести сравнение будет гораздо проще."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/metric2.png\" width=\"750\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также не стоит забывать об оптимизационных метриках. **Мы можем улучшать не только точность**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/metric3.png\" width=\"500\" ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметьте, что метрика получается не однопараметрическая. Вместо введения формулы типа $$\\large F_1 + 0,5*Скорость$$ можно **сделать отсечку допустимого** времени рассчётов и использовать точность в качестве целевой метрики среди оставшихся моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели, эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По ходу курса мы будем не только писать модели с нуля, но и знакомиться с базами готовых моделей, в том числе предобученных. Таким образом, сразу логируйте результаты экспериментов. Подумайте, как вам это будет делать удобнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрите на примеры из валидационной выборки, на которых есть ошибки. Так, разумным будет выделить 2 группы объектов:\n",
    "\n",
    "* на которых ошибка максимальна,\n",
    "* на которых возникают пограничные ошибки.\n",
    "\n",
    "Возьмите разумное количество объектов, которые можно проверить вручную (скажем, 100). Возможно, вы найдёте в этот момент ошибки в разметке или собак, которые очень похожи на котиков.\n",
    "\n",
    "Результат анализа позволит понять, какой ожидаемый эффект будет от дальнейших действий. Если у вас окажется проблема с разметкой, улучшение алгоритма даст малый вклад.\n",
    "\n",
    "Во время улучшения решения у вас будут появляться гипотезы, как можно улучшать решение. Имеет смысл при анализе ошибок завести подобную таблицу, в которой отмечать, на какие объекты в анализируемой подвыборке ожидается эффект."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/metric4.png\" width=\"800\" ></center>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом можно оценить первоочередные улучшения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ работы модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как модель готова, необходимо вскрыть \"чёрный ящик\". Об этом будет отдельная лекция."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/grad_cam.webp\" width=\"700\" ></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.mdpi.com/2079-9292/10/13/1541\">Object Identification and Localization Using Grad-CAM++</a></em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы сможете удостовериться, что модель выучила действительно значимые признаки, а не, например, фон.\n",
    "\n",
    "Заметки от Эндрю Ына:\n",
    "\n",
    "[[blog] ✏️ Страсть к машинному обучению](https://habr.com/ru/articles/419757/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инструменты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим примеры решения задач классификации на различных типах данных.\n",
    "\n",
    "Будем использовать библиотеки:\n",
    "\n",
    "* [[doc] 🛠️ NumPy](https://numpy.org/) — поддержка больших многомерных массивов и быстрых математических функций для операций с этими массивами.\n",
    "* [[doc] 🛠️ Scikit-learn](https://scikit-learn.org/stable/) — ML алгоритмы, \"toy\"-датасеты.\n",
    "* [[doc] 🛠️ Pandas](https://pandas.pydata.org/) — Удобная работа с табличными данными.\n",
    "\n",
    "* [[doc] 🛠️ **PyTorch**](https://pytorch.org/) — Основной фреймворк машинного обучения, который будет использоваться на протяжении всего курса.\n",
    "\n",
    "* [[doc] 🛠️ Matplotlib](https://matplotlib.org/) — Основная библиотека для визуализации. Вывод различных графиков.\n",
    "\n",
    "* [[doc] 🛠️ Seaborn](https://seaborn.pydata.org/) — Удобная библиотека для визуализации статистик. Прямо из коробки вызываются и гистограммы, и тепловые карты, и визуализация статистик по датасету, и многое другое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/sns.png\" width=\"1000\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.acte.in/what-is-seaborn-in-python-article/\">What is Seaborn in Python? A Complete Guide For Beginners & REAL-TIME Examples</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Связность данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют различные типы данных:\n",
    "\n",
    "1. Последовательности (важен порядок данных, время):\n",
    "   - **временные ряды** (речь, мозговая активность, котировки);\n",
    "   - **текст**.\n",
    "\n",
    "2. Пространственно-структурированная информация (преобразуется к векторам чисел):\n",
    "   - **изображения** (пиксели);\n",
    "   - **видео** (пиксели + время);\n",
    "   - **3D** (воксели).\n",
    "\n",
    "3. Статистика:\n",
    "   - **табличные данные** (признаки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большинство процессов и объектов, с которыми научились работать ML/DL модели, можно отнести к одному из перечисленных типов. Наша задача будет состоять в том, чтобы определить, как данные из вашей предметной области свести к одному из них и представить в виде набора чисел.\n",
    "\n",
    "Для работы с различными типами данных используют разные типы моделей:\n",
    "\n",
    "**Табличный**  — классические ML модели либо полносвязные NN;\n",
    "\n",
    " **Последовательности** — рекуррентные сети + свёртка;\n",
    "\n",
    " **Изображения/видео** — 2,3 .. ND свёрточные сети.\n",
    "\n",
    "В разных типах данных количество связей между элементами разное и зависит только от типа этих данных. Важно НЕ количество элементов, а СВЯЗИ между ними.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/connectivity_of_data_types.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные мы можем условно делить по степени связанности. Это степень взаимного влияния между соседними элементами.\n",
    "Например, в таблице, в которой есть определенные параметры (например: рост, вес), данные между собой связаны, но порядок столбцов значения не имеет.\n",
    "Если мы поменяем столбцы местами, то не потеряем никакой важной информации.\n",
    "\n",
    "Такие данные можно представить в виде вектора, но порядок элементов в нем не важен.\n",
    "\n",
    "При работе с изображениями нам становится важно, как связаны между собой пиксели и по горизонтали, и по вертикали.\n",
    "При добавлении цвета появляются 3 RGB-канала, и значения в каждом канале также связаны между собой. Эту связь нельзя терять, если мы хотим корректно извлечь максимум информации из данных. Соответственно, если дано цветное изображение, то у нас есть уже три измерения, в которых мы должны эти связи учитывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и визуализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример работы с табличными данными.\n",
    "Нам даётся описание вин из [учебного датасета Wine 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека sklearn обеспечивает API по работе с датасетами, а также хранит ряд учебных. Посмотрим, как это выглядит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/wine_dataset.png\"   width=\"500\" ></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://machinelearningmastery.ru/the-7-steps-of-machine-learning-2877d7e5548e/\">7 ступеней машнного обучения</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот датасет можно загрузить, используя модуль `sklearn.datasets` библиотеки [sklearn 🛠️[doc]](https://scikit-learn.org/stable/), чем мы и воспользуемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "dataset = load_wine(return_X_y=True)\n",
    "\n",
    "# array 178x13 (178 wine examples each with 41 features)\n",
    "features = dataset[0]\n",
    "# array of 178 elements, each element is a number the class: 0,1 2\n",
    "class_labels = dataset[1]\n",
    "print(\"features shape:\", features.shape)\n",
    "print(\"class_labels shape:\", class_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем первый элемент массива. Это наш **$X_1$** из множества наблюдений **$X$**. Обратите внимание на размер каждого элемента — это **вектора из 13 признаков**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот так выглядят первые 10 меток $Y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Визуализация данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Чтобы отобразить данные в виде таблицы, загрузим их в формате `pandas.DataFrame`.\n",
    "В более крупных датасетах у вас могут появиться такие параметры, как доля загрузки датасета и фиксирование сида генератора случайных числе (для повторяемости загрузки).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library to work with tabular data: https://pandas.pydata.org/\n",
    "import pandas as pd\n",
    "\n",
    "x, y = load_wine(return_X_y=True, as_frame=True)\n",
    "\n",
    "x.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот так мы можем посмотреть, какие **уникальные классы** в нашей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно интерпретировать каждый объект как координаты точки в 13-мерном пространстве. Именно с таким представлением работает большинство алгоритмов машинного обучения.\n",
    "\n",
    "Визуализируем распределение данных по классам и отметим, что присутствует дисбаланс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(figsize=(4,3))\n",
    "y.hist()\n",
    "plt.suptitle(\"Label balance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с данными и моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что мы работаем с тренировочным датасетом [CIFAR-10 🛠️[doc]](https://www.cs.toronto.edu/~kriz/cifar.html) и хотим решить хрестоматийную задачу классификации: определить те картинки из тестового набора данных, которые относятся к классу `cat`. Эта задача является частным примером общей задачи классификации данных CIFAR-10, разные подходы к решению которой мы ещё неоднократно рассмотрим в ходе курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет CIFAR-10 содержит, как следует из названия, 10 различных классов изображений:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/knn_on_cifar10.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все изображения представляют собой матрицы чисел, которые кодируют цвета отдельных пикселей. Для изображений высоты $H$, ширины $W$ с $C$ цветовыми каналами получаем упорядоченный набор  $H \\times W \\times C$ чисел. В данном разделе пока не будем учитывать, что значения соседних пикселей изображения могут быть значительно связаны, и будем решать задачу классификации для наивного представления изображения в виде точки в  $H \\times W \\times C$-мерном вещественном пространстве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/img_to_array.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет CIFAR-10 содержит цветные (трехцветные) изображения размером $32 \\times 32$ пикселя. Таким образом, каждое изображение из датасета является точкой в $3072$-мерном ($32 \\times 32 \\times 3 = 3072$) вещественном пространстве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим, что помимо RGB встречаются и [другие цветовые пространства ✏️[blog]](https://habr.com/ru/articles/181580/), которые однозначно (или приблизительно) переходят друг в друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Близость данных согласно метрике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пара изображений будет выглядеть практически идентично, если значения цветов соответствующих пикселей будут похожи по величине. Другими словами, практически идентичным изображениям будут соответствовать **близкие** точки нашего многомерного вещественного пространства. Для численной характеристики **близости** можно определить функцию подсчета расстояния между парой точек — метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известны различные способы задания [функции расстояния между парой точек 📚[wiki]](https://en.wikipedia.org/wiki/Metric_(mathematics)). Простейшим примером является широко известная **Евклидова** ($L_2$) метрика:\n",
    "$$L_2 (X, Y) = \\sqrt { \\sum_i (X_i - Y_i)^2},$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но, кроме неё, величина расстояния между парой точек может быть выражена рядом других функций.\n",
    "\n",
    "$L_1$-расстояние (манхэттенская метрика):\n",
    "$$L_1 (X, Y) = \\sum_i |X_i - Y_i|,$$\n",
    "\n",
    "угловое расстояние:\n",
    "$$ang (X, Y) = \\frac{1}{\\pi} \\arccos \\frac{\\sum_i X_i Y_i}{\\sqrt{\\sum_i X_i^2} \\sqrt{\\sum_i Y_i^2}} ,$$\n",
    "\n",
    "и многие другие. От выбора конкретной функции расстояния между точками будет явно зависеть представление о **близости** точек — объекты, близкие по одной из метрик, вовсе не обязаны оказаться близкими согласно другой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем вычислить $L_1$-расстояние между несколькими первыми изображениями из тестового набора данных CIFAR-10 с использованием реализованного в пакете [sklearn 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html#sklearn.metrics.DistanceMetric.get_metric) класса `sklearn.metrics.DistanceMetric`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large L1\\;distance:\\; d_1(I_1, I_2) = \\sum_p|I^p_1 - I^p_2|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/metric_to_compare_train_and_test_imgs.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from torchvision.datasets\n",
    "from torchvision import datasets\n",
    "\n",
    "train_set = datasets.CIFAR10(\"content\", train=True, download=True)\n",
    "val_set = datasets.CIFAR10(\"content\", train=False, download=True)\n",
    "labels_names = train_set.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем три изображения из тестового набора данных и одно из валидационного:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_1 = train_set.data[0]\n",
    "img_2 = train_set.data[1]\n",
    "img_3 = train_set.data[2]\n",
    "\n",
    "fix, ax = plt.subplots(1, 3, figsize=(10, 3))\n",
    "ax[0].set_title(\"First image in train data\")\n",
    "ax[0].imshow(img_1)\n",
    "ax[1].set_title(\"Second image in train data\")\n",
    "ax[1].imshow(img_2)\n",
    "ax[2].set_title(\"Third image in train data\")\n",
    "ax[2].imshow(img_3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import DistanceMetric\n",
    "\n",
    "dist = DistanceMetric.get_metric(\"manhattan\")\n",
    "pairwise_dist = dist.pairwise([img_1.flatten(), img_2.flatten(), img_3.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "im = ax.imshow(pairwise_dist)\n",
    "\n",
    "# Show all ticks and label them with the respective list entries\n",
    "ax.set_xticks(np.arange(len(pairwise_dist)))\n",
    "ax.set_yticks(np.arange(len(pairwise_dist)))\n",
    "ax.set_xticklabels([f\"img{i}\" for i in range(1, 4)])\n",
    "ax.set_yticklabels([f\"img{i}\" for i in range(1, 4)])\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(pairwise_dist)):\n",
    "    for j in range(len(pairwise_dist)):\n",
    "        text = ax.text(\n",
    "            j,\n",
    "            i,\n",
    "            \"{:0.2f}\".format(pairwise_dist[i, j]),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"w\",\n",
    "        )\n",
    "\n",
    "ax.set_title(\"Pairwise L_1 distance for first 3 images in CIFAR 10 \")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассматривая аналогичные примеры, можно выявить, что расстояние между изображениями одного и того же класса может оказаться меньше, чем расстояние между объектами разных классов. Действительно, давайте рассчитаем среднее расстояние между объектами разных классов для CIFAR-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "# in order to limit computational time\n",
    "index_limiter = 1000\n",
    "# convert all (32,32,4) images into (32*32*4) vectors\n",
    "flattened_images = val_set.data.reshape(val_set.data.shape[0], -1)[:index_limiter]\n",
    "\n",
    "classwise_distance = np.zeros((len(val_set.classes), len(val_set.classes)))\n",
    "\n",
    "# iterate over all pair of classes and slice their members\n",
    "for class_id_i, class_name_i in enumerate(val_set.classes):\n",
    "    class_i_mask = np.asarray(val_set.targets[:index_limiter]) == class_id_i\n",
    "\n",
    "    for class_id_j, class_name_j in enumerate(val_set.classes):\n",
    "        class_j_mask = np.asarray(val_set.targets[:index_limiter]) == class_id_j\n",
    "\n",
    "        # manhattan_distances returns pairwise distance matrix for samples\n",
    "        # so in order to get mean distance for classes one should calc mean\n",
    "        # value over its higher triangle part or simply calc mean over whole matrix\n",
    "        # and divide by 2.0\n",
    "        classwise_distance[class_id_i, class_id_j] = (\n",
    "            np.mean(\n",
    "                manhattan_distances(\n",
    "                    flattened_images[class_i_mask], flattened_images[class_j_mask]\n",
    "                )\n",
    "            )\n",
    "            / 2.0\n",
    "        )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(classwise_distance)\n",
    "\n",
    "# Show all ticks and label them with the respective list entries\n",
    "ax.set_xticks(np.arange(len(val_set.classes)))\n",
    "ax.set_yticks(np.arange(len(val_set.classes)))\n",
    "ax.set_xticklabels(val_set.classes)\n",
    "ax.set_yticklabels(val_set.classes)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "ax.set_title(\"Mean class-wise Мanhattan distance for CIFAR 10\")\n",
    "fig.tight_layout()\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, среди первых 1000 картинок тестовой части датасета CIFAR-10 есть значительное число обособленных классов, для которых выполняется описанное выше отношение близости. Например, это справедливо для классов \"Корабль\", \"Олень\" и \"Лягушка\". Идея о том, что близость объектов по некоторой метрике и их принадлежность к одному определённому классу связаны, является основой известного алгоритма классификации и регрессии — **k-Nearest Neighbors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание модели k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Метод k-ближайших соседей 📚[wiki]](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) (англ. k-nearest neighbors algorithm, k-NN) — метрический алгоритм для классификации или регрессии. В случае классификации алгоритм сводится к следующему:\n",
    "\n",
    "1. Рассматриваются объекты из обучающей выборки, для которых известно, к какому классу они принадлежат.\n",
    "1. Между подлежащими классификации объектами и объектами тренировочной выборки вычисляется матрица попарных расстояний согласно выбранной метрике.\n",
    "1. На основе полученной матрицы расстояний для каждого из подлежащих классификации объектов определяются k ближайших объектов тренировочной выборки — k ближайших соседей.\n",
    "1. Подлежащим классификации объектам приписывается тот класс, который чаще всего встречается у их k ближайших соседей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/knn_idea.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера работы с алгоритмом k-NN классифицируем изображение корабля из тестовой выборки CIFAR-10 с использованием [реализации алгоритма в scikit-learn 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors_graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "sample_ship_img = val_set.data[18]\n",
    "ax.set_title(\"Image in validation data\")\n",
    "plt.imshow(sample_ship_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем близость с валидационным изображением согласно трём распространённым расстояниям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# in order to limit computational time\n",
    "index_limiter = 5000\n",
    "x = train_set.data.reshape(train_set.data.shape[0], -1)[:index_limiter]\n",
    "y = train_set.targets[:index_limiter]\n",
    "\n",
    "res = np.empty(shape=(3, 5), dtype=object)\n",
    "i = 0\n",
    "\n",
    "for distance_type in [\"euclidean\", \"manhattan\", \"chebyshev\"]:\n",
    "    for k in range(3, 7, 1):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric=distance_type)\n",
    "        knn.fit(x, y)\n",
    "        result_class_id = knn.predict([sample_ship_img.flatten()])[0]\n",
    "        result_class = train_set.classes[result_class_id]\n",
    "        res[i][0] = distance_type\n",
    "        res[i][k - 2] = result_class\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pandas_res = pd.DataFrame(res, columns=[\"distance\", \"k=3\", \"k=4\", \"k=5\", \"k=6\"])\n",
    "pandas_res.set_index(\"distance\", inplace=True)\n",
    "pandas_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, при `k=6` ответы совпадают при всех метриках. **Но как выбрать `k`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простейшая метрика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Довольно естественно оценивать долю правильных ответов алгоритма:\n",
    "\n",
    "$$ \\large Accuracy = \\frac{P}{N}, $$\n",
    "\n",
    "где $P$ — количество верно предсказанных классов,\n",
    "\n",
    "$\\quad\\  N$ — общее количество тестовых примеров.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте наш алгоритм будет предсказывать **как можно больше правильных классов**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6, metric=\"chebyshev\")\n",
    "knn.fit(x, y)\n",
    "accuracy = accuracy_score(y_pred=knn.predict(x), y_true=y)  # accuracy\n",
    "\n",
    "print(\"Accuracy:\", f\"{accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение train-validation-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самым простым способом научиться чему-либо является \"запомнить всё\".\n",
    "\n",
    "Вспомним \"Таблицу умножения\". Если мы хотим проверить умение умножать, то проверки примерами из таблицы умножения будет недостаточно, ведь она может быть полностью запомнена. Нужно давать новые примеры, которых не было в таблице умножения (обучающей выборке)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если модель \"запомнит всё\", то она будет идеально работать на данных, которые мы ей показали, но может вообще не работать на любых других данных.\n",
    "\n",
    "С практической точки зрения важно, как модель будет вести себя именно на незнакомых ей данных, то есть, насколько хорошо она научилась обобщать закономерности, которые в данных присутствовали (если они вообще существуют)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки этой способности набор данных разделяют на три части:\n",
    "\n",
    "* **Обучающая выборка** (Training set) — выборка из данных, которая используется для обучения алгоритма.\n",
    "* **Валидационная выборка** (Validation set) — выборка данных, которая используется для подбора параметров, выбора признаков и принятия других решений, касающихся обучения алгоритма.\n",
    "* **Тестовая выборка** (Test set) — выборка, которая используется для оценки качества работы алгоритма, при этом никак не используется для обучения алгоритма или подбора используемых при этом обучении параметрам.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/split_dataset_for_train_val_test.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `sklearn.model_selection` есть модель для разделения массива данных на тренировочную и тестовую часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data to train/test\n",
    "x_train, x_tmp, y_train, y_tmp = train_test_split(x, y, test_size=0.2)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_tmp, y_tmp, test_size=0.2)\n",
    "\n",
    "print(\"Train:\", np.array(x_train).shape, np.array(y_train).shape)\n",
    "print(\"Val:\", np.array(x_val).shape, np.array(y_val).shape)\n",
    "print(\"Test:\", np.array(x_test).shape, np.array(y_test).shape)\n",
    "print(\"Total:\", np.array(x).shape, np.array(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6, metric=\"chebyshev\")\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "accuracy_train = accuracy_score(y_pred=knn.predict(x_train), y_true=y_train)\n",
    "accuracy_val = accuracy_score(y_pred=knn.predict(x_val), y_true=y_val)\n",
    "accuracy_test = accuracy_score(y_pred=knn.predict(x_test), y_true=y_test)\n",
    "\n",
    "print(\"Accuracy train:\", f\"{accuracy_train*100}%\")\n",
    "print(\"Accuracy val :\", f\"{accuracy_val*100}%\")\n",
    "print(\"Accuracy test :\", f\"{accuracy_test*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры и гиперпараметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/l1_manhattan_and_l2_euclidian_distance.png\" width=\"600\">\n",
    "\n",
    "$\\displaystyle L1 = d_1(I_1, I_2) = \\sum_p|I^p_1-I^p_2| \\qquad \\qquad \\quad L2 = d_2(I_1, I_2) = \\sqrt{\\sum_p(I^p_1-I^p_2)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, у нас есть **два параметра** модели, которые мы **можем настраивать**:\n",
    "* метрика расстояния,\n",
    "* количество ближайших соседей k.\n",
    "\n",
    "Настраиваемые параметры, с помощью которых мы можем управлять процессом обучения, называются **гиперпараметрами**. В дальнейшем мы столкнемся с другими гиперпараметрами. Например, мы можем попробовать использовать другую модель, и выбор модели тоже станет гиперпараметром решаемой задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим k-NN для общей выборки данных при разном значении количества соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbors = np.arange(1, 31)  # array of the numbers of neighbors from 1 to 30\n",
    "\n",
    "quality = np.zeros(num_neighbors.shape[0])\n",
    "\n",
    "for i in range(num_neighbors.shape[0]):  # for all elements\n",
    "    # create knn for all number of neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=num_neighbors[i])\n",
    "    knn.fit(x_train, y_train)\n",
    "    q = accuracy_score(y_pred=knn.predict(x_test), y_true=y_test)  # accuracy\n",
    "    quality[i] = q  # fill quality\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title(\"k-NN on train\", size=18)\n",
    "plt.xlabel(\"Neighbors\", size=12)\n",
    "plt.ylabel(\"Accuracy\", size=12)\n",
    "plt.plot(num_neighbors, quality)\n",
    "plt.xticks(num_neighbors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что качество на 1 соседе самое лучшее. Но это и понятно — ближайшим соседом элемента из обучающей выборки будет сам объект. Мы просто **запомнили** все объекты.\n",
    "\n",
    "Если теперь мы попробуем взять какой-то новый объект и классифицировать его, у нас скорее всего ничего не получится. В таких случаях мы говорим, что наша модель не умеет обобщать (*generalization*).\n",
    "\n",
    "Для того, чтобы знать заранее, обобщает ли наша модель или нет, мы можем разбить все имеющиеся у нас данныe на 2 части. На одной части мы будем обучать классификатор (*train set*), а на другой — тестировать, насколько хорошо он работает (*test set*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbors = np.arange(\n",
    "    1, 31\n",
    ")  # array of the numbers of nearest neigbors from 1 to 30\n",
    "train_quality = np.zeros(num_neighbors.shape[0])  # quality on train data\n",
    "test_quality = np.zeros(num_neighbors.shape[0])  # quality on test data\n",
    "\n",
    "for i in range(num_neighbors.shape[0]):\n",
    "    knn = KNeighborsClassifier(n_neighbors=num_neighbors[i])\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "    # accuracy on train data\n",
    "    train_quality[i] = accuracy_score(y_pred=knn.predict(x_train), y_true=y_train)\n",
    "\n",
    "    # accuracy on test data\n",
    "    test_quality[i] = accuracy_score(y_pred=knn.predict(x_test), y_true=y_test)\n",
    "\n",
    "# accuracy plot  on train and test data\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title(\"k-NN on train vs test\", size=18)\n",
    "plt.plot(num_neighbors, train_quality, label=\"train\")\n",
    "plt.plot(num_neighbors, test_quality, label=\"test\")\n",
    "plt.legend()\n",
    "plt.xticks(num_neighbors)\n",
    "plt.xlabel(\"Neighbors\", size=12)\n",
    "plt.ylabel(\"Accuracy\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот, теперь мы видим, что 1 сосед был \"ложной тревогой\". Такие случаи мы называем *переобучением*. Чтобы действительно предсказывать что-то полезное, нам надо выбирать число соседей, начиная минимум с 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стратификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки классов в датасете могут быть распределены неравномерно. Для того, чтобы сохранить соотношение классов при разделении на train и test, необходимо указать параметр `stratify` при разбиении.\n",
    "\n",
    "Еще одним параметром, используемым при разбиении, является `shuffle` (значение по умолчанию `True`). При `shuffle = True` датасет перед разбиением перемешивается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/stratified_sampling.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.reneshbedre.com/blog/stratified-sampling.html\">What is Stratified sampling and why should you use it</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на разбиение датасета [Iris 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html). Для наглядности будем делить датасет\n",
    "пополам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lables(lables):\n",
    "    lable_count = {}\n",
    "    for item in lables:\n",
    "        if item not in lable_count:\n",
    "            lable_count[item] = 0\n",
    "        lable_count[item] += 1\n",
    "    return lable_count\n",
    "\n",
    "\n",
    "def print_split_stat(x_train, x_test, y_train, y_test):\n",
    "    # print(\"Train labels: \", y_train)\n",
    "    # print(\"Test labels:  \", y_test)\n",
    "    print(\"Train statistics: \", count_lables(y_train))\n",
    "    print(\"Test statistics:  \", count_lables(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядит исходный датасет. Отметим, что **объекты отсортированы**. Ситуация вовсе не исключительная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data, labels = load_iris(return_X_y=True)\n",
    "print(\"DataSet labels:\\n\", labels)\n",
    "print(\"DataSet statistics: \", count_lables(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы **выключим перемешивание** (`shuffle=False`), то в обучение **не попадёт ни один объект класса 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, labels, train_size=0.5, shuffle=False, random_state=42\n",
    ")\n",
    "\n",
    "print_split_stat(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию `shuffle=True`, однако этого **не достаточно**. **Доли** объектов **не равны** в подвыборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, labels, train_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print_split_stat(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Только при использовании стратификации мы добиваемся желаемого результата.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, labels, train_size=0.5, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print_split_stat(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В случае временных рядов**, текстов и прочих данных, имеющих связь во времени, **данные нельзя перемешивать**. В таких задачах train должен предшествовать test по времени. Более подробно об этом будет рассказано в лекции про рекуррентные нейронные сети.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно иметь сколько угодно хороший алгоритм для классификации, но до тех пор, пока данные на входе — мусор, на выходе из классификатора мы тоже будем получать мусор **(*garbage in, garbage out*)**. Давайте разберемся, что конкретно надо сделать, чтобы k-NN реально заработал.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы адекватно сравнить данные между собой, нам следует использовать нормализацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нормализацией** называется процедура приведения входных данных к единому масштабу (диапазону) значений.\n",
    "\n",
    "Преобразование данных к единому числовому диапазону (иногда говорят *домену*) позволяет считать их равноправными признаками и единообразно передавать их на вход модели. В некоторых источниках данная процедура явно называется *масштабирование*.\n",
    "\n",
    "Существует базовый вариант — `StandardScaler`.\n",
    "\n",
    "Подробно рассмотрим различные виды нормализации в следующей лекции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как применять нормировку**\n",
    "\n",
    "1. Делим данные на **3 части**: train, val, test.\n",
    "2. Вычисляем статистики **на train**.\n",
    "3. Применяем к train, val, test.\n",
    "\n",
    "**Нельзя вычислять статистики на всём наборе данных**, нормировать, а потом делить на подвыборки. Это ведёт к утечке данных и некорректным результатам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)  # setting the initialization parameter for random values\n",
    "\n",
    "x_train_feature = x_train[:, 0].reshape(-1, 1)\n",
    "\n",
    "plt.figure(1, figsize=(8, 3))\n",
    "plt.subplot(121)  # set location\n",
    "plt.scatter(x_train_feature, range(len(x_train_feature)), c=y_train)\n",
    "plt.ylabel(\"Num examples\", fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.title(\"Non scaled data\", fontsize=18)\n",
    "\n",
    "# scale data  with StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_feature)\n",
    "x_train_feature_scaled = scaler.transform(x_train_feature)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(x_train_feature_scaled, range(len(x_train_feature)), c=y_train)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.title(\"StandardScaler\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея **`StandardScaler`** заключается в том, что он преобразует данные таким образом, что распределение будет иметь среднее значение $0$ и стандартное отклонение $1$. Большинство значений будет находиться в диапазоне от $-1$ до $1$. Это стандартная трансформация, и она применима во многих ситуациях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large z_i=\\frac{X_i-u}{s},$$\n",
    "\n",
    "$u$ — среднее значение (или 0 при `with_mean=False`),\n",
    "\n",
    "$s$ — стандартное отклонение (или 0 при `with_std=False`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на данных без нормировки и с нормировкой для 10-ти соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, labels, random_state=42, test_size=0.5\n",
    ")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "print(\"Without normalization\")\n",
    "accuracy_train = accuracy_score(y_pred=knn.predict(x_train), y_true=y_train)\n",
    "print(\"accuracy_train\", round(accuracy_train, 3))\n",
    "accuracy_test = accuracy_score(y_pred=knn.predict(x_test), y_true=y_test)\n",
    "print(\"accuracy_test\", round(accuracy_test, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_norm = scaler.transform(x_train)  # scaling data\n",
    "x_test_norm = scaler.transform(x_test)  # scaling data\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(x_train_norm, y_train)\n",
    "\n",
    "print(\"With normalization\")\n",
    "accuracy_train = accuracy_score(y_pred=knn.predict(x_train_norm), y_true=y_train)\n",
    "print(\"accuracy_train\", round(accuracy_train, 3))\n",
    "accuracy_test = accuracy_score(y_pred=knn.predict(x_test_norm), y_true=y_test)\n",
    "print(\"accuracy_test\", round(accuracy_test, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN в прикладных задачах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике метод ближайших соседей для классификации используется редко.\n",
    "Проблема заключается в следующем.\n",
    "\n",
    "Предположим, что точность классификации нас устраивает. Теперь давайте применим k-NN на больших данных (e.g. миллион картинок). Для определения класса каждой из картинок нам нужно сравнить ее со всеми другими картинками в базе данных, а такие расчеты, даже в существенно оптимизированном виде, занимают много времени. Мы же хотим, чтобы обученная модель работала быстро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тем не менее, метод ближайших соседей используется в других задачах, где без него обойтись сложно. Например, **в задаче распознавания лиц**. Представим, что у нас есть большая база данных с фотографиями лиц (например, по 5 разных фотографий всех сотрудников, которые работают в офисном здании) и есть камера, установленная на входе в это здание. Мы хотим узнать, кто и во сколько пришел на работу. Для того, чтобы понять, кто прошел перед камерой, нам нужно зафиксировать лицо этого человека и сравнить его со всеми фотографиями лиц в базе. В такой формулировке мы не пытаемся определить конкретный класс фотографии, а всего лишь определяем **“похож-не похож”**. Мы смотрим на k ближайших соседей, и если из k соседей, 5 — это фотографии, например, Джеки Чана, то, скорее всего, под камерой прошел именно он."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры эффективной реализации метода на основе k-NN:\n",
    "* [[git] 🐾 Facebook AI Research Similarity Search](https://github.com/facebookresearch/faiss) – разработка команды Facebook AI Research для быстрого поиска ближайших соседей и кластеризации в векторном пространстве. Высокая скорость поиска позволяет работать с очень большими данными – до нескольких миллиардов векторов.\n",
    "* [[arxiv] 🎓 Hierarchical Navigable Small World](https://arxiv.org/abs/1603.09320) — алгоритм поиска ближайших соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Алгоритм кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте все-таки разберемся, как подобрать гиперпараметры.\n",
    "\n",
    "Результат работы модели будет зависеть от разбиения. Поэкспериментируем с k-NN и датасетом [Iris 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) и посмотрим, как результат работы модели зависит от `random_state` для `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = sklearn.datasets.load_iris()  # load data\n",
    "x = dataset.data  # features\n",
    "y = dataset.target  # labels(classes)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def split_and_train(x, y, random_state):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x, y, train_size=0.8, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    max_neighbors = 30\n",
    "    num_neighbors = np.arange(1, max_neighbors + 1)  # array of the number of neighbors\n",
    "\n",
    "    train_accuracy = np.zeros(max_neighbors)\n",
    "    val_accuracy = np.zeros(max_neighbors)\n",
    "\n",
    "    for k in num_neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(x_train, y_train)\n",
    "\n",
    "        train_accuracy[k - 1] = accuracy_score(\n",
    "            y_pred=knn.predict(x_train), y_true=y_train\n",
    "        )\n",
    "        val_accuracy[k - 1] = accuracy_score(y_pred=knn.predict(x_val), y_true=y_val)\n",
    "\n",
    "    # accuracy plot on train and test data\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(f\"KNN on train vs val, seed = {random_state}\", size=20)\n",
    "    plt.plot(num_neighbors, train_accuracy, label=\"train\")\n",
    "    plt.plot(num_neighbors, val_accuracy, label=\"val\")\n",
    "    plt.legend()\n",
    "    plt.xticks(num_neighbors, size=12)\n",
    "    plt.xlabel(\"Neighbors\", size=14)\n",
    "    plt.ylabel(\"Accuracy\", size=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_train(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_train(x, y, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат зависит от того, как нам повезло или не повезло с разбиением данных на обучение и тест. Для одного разбиения хорошо выбрать $k=3$, а для другого — $k=13$. Кроме того, фактически мы сами выступаем в роли модели, которая учит гиперпараметры (а не параметры) под видимую ей выборку.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Получается, что если подбирать гиперпараметры модели на *train set*, то:\n",
    "1. Можно переобучитьcя, просто на более \"высоком\" уровне. Особенно если гиперпараметров у модели много и все они разнообразны.\n",
    "2. Нельзя быть уверенным, что выбор параметров не зависит от разбиения на обучение и тест."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения этой проблемы можно произвести **несколько разбиений** датасета на **обучающий и валидационный** по какой-то схеме, чтобы получить уверенность оценок качества для моделей с разными гиперпараметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/cross_validation_on_train_data.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой подход называется [K-Fold кросс-валидацией 🛠️[doc]](https://scikit-learn.org/stable/modules/cross_validation.html).\n",
    "\n",
    "Берется тренировочная часть датасета, разбивается на части — блоки. Дальше мы будем использовать для проверки первую часть (Fold 1), а на остальных частях будем обучать модель. И так последовательно для всех частей. В результате у нас будет информация о точности для разных фрагментов данных, и уже на основании этого мы сможем понять, насколько значение параметра, который мы проверяем, зависит или не зависит от данных. То есть, если у нас от разбиения точность при одном и том же К меняться не будет, значит, мы подобрали правильный К. Если она будет сильно меняться в зависимости от того, на каком куске данных мы проводим тестирование, значит, надо попробовать другой К, и если ни при каком не получилось, то проблема заключается в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как работает k-Fold. Обратите внимание, что по умолчанию `shuffle = False`. Для упорядоченных данных это проблема."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "print(\"index without shuffle\")\n",
    "kf = KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "print(\"index with shuffle\")\n",
    "kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения стратифицированного разбиения (когда соотношение классов в частях разбиения сохраняется) нужно использовать `StratifiedKFold` [🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Временные ряды**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/timeseries.png\" width=\"850\"></center>\n",
    "<center><em>Типичный пример временного ряда</em></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://habr.com/ru/company/ods/blog/327242/\">Статья на хабре об анализе временных рядов на Python</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно нужно **упомянуть** о временных рядах. Особенностью таких данных является связность, наличие \"настоящего\", \"прошедшего\" и \"будущего\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/ts_split.png\" width=\"850\"/></center>\n",
    "<center><em>Разбиение данных временных рядов на подвыборки</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Оценка результата кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Посмотрим на результат кросс-валидации для k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "dataset = sklearn.datasets.load_iris()  # load data\n",
    "x = dataset.data  # features\n",
    "y = dataset.target  # labels(classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size=0.8, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "accuracy3 = cross_val_score(knn, x_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "accuracy5 = cross_val_score(knn, x_train, y_train, cv=cv, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv = np.vstack(\n",
    "    (\n",
    "        np.hstack((accuracy3, accuracy3.mean(), accuracy3.std())),\n",
    "        np.hstack((accuracy5, accuracy5.mean(), accuracy5.std())),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = pd.DataFrame(\n",
    "    knn_cv, columns=[\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\", \"Mean\", \"Std\"]\n",
    ")\n",
    "table = table.set_axis([\"Accuracy\"] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В идеальном случае выбираются гиперпараметры, для которых математическое ожидание метрик качества выше, а дисперсия меньше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Типичные ошибки при кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Можно ли делать только кросс-валидацию (без теста)?**\n",
    "\n",
    "Нет, нельзя. Кросс-валидация не до конца спасает от подгона параметров модели под выборку, на которой она проводится. Оценка конечного качества модели должно производиться на отложенной тестовой выборке. Если у вас очень мало данных, можно рассмотреть [вложенную кросс-валидацию 🛠️[doc]](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html). Речь об этом пойдет в следующих лекциях. Но даже в этом случае придется анализировать поведение модели, чтобы показать, что она учит что-то разумное. Кстати, вложенную кросс-валидацию можно использовать, чтобы просто получить более устойчивую оценку поведения модели на тесте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подбора параметров модели используется **GridSearchCV**.\n",
    "\n",
    "GridSearchCV – это инструмент для автоматического подбора параметров моделей машинного обучения. GridSearchCV находит наилучшие параметры путем обычного перебора: он создает модель для каждой возможной комбинации параметров из заданной сетки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет Iris маловат для подбора параметров, поэтому создадим свой датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "x, y = make_moons(n_samples=1000, noise=0.3, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отложим test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size=0.8, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подобрать параметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\"\"\"\n",
    "Parameters for GridSearchCV:\n",
    "estimator — model\n",
    "cv — num of fold to cross-validation splitting\n",
    "param_grid — parameters names\n",
    "scoring — metrics\n",
    "n_jobs — number of jobs to run in parallel, -1 means using all processors.\n",
    "\"\"\"\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    cv=KFold(5, shuffle=True, random_state=42),\n",
    "    param_grid={\n",
    "        \"n_neighbors\": np.arange(1, 31),\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "    },\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем лучшие гиперпараметры для модели, которые подобрали:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metric:\", model.best_params_[\"metric\"])\n",
    "print(\"Num neighbors:\", model.best_params_[\"n_neighbors\"])\n",
    "print(\"Weigths:\", model.best_params_[\"weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объект GridSearchCV можно использовать как обычную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(\n",
    "    f\"Percent correct predictions {np.round(accuracy_score(y_pred=y_pred, y_true=y_test)*100,2)} %\"\n",
    ")\n",
    "print(\n",
    "    f\"Percent correct predictions(balanced classes) {np.round(balanced_accuracy_score(y_pred=y_pred, y_true=y_test)*100,2)} %\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем извлечь дополнительные данные о кросс-валидации и по ключу обратиться к результатам всех моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем для примера mean_test_score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(model.cv_results_[\"mean_test_score\"])\n",
    "plt.title(\"Mean test score\", size=20)\n",
    "plt.xlabel(\"Num of experiment\", size=15)\n",
    "plt.ylabel(\"Accuracy\", size=15)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(model.cv_results_[\"param_metric\"])\n",
    "plt.title(\"Param Metric\", size=20)\n",
    "plt.xlabel(\"Num of experiment\", size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим, например, при фиксированных остальных параметрах (равных лучшим параметрам), качество модели на валидации в зависимости от числа соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_means = []\n",
    "selected_std = []\n",
    "num_neighbors = []\n",
    "for ind, params in enumerate(model.cv_results_[\"params\"]):\n",
    "    if (\n",
    "        params[\"metric\"] == model.best_params_[\"metric\"]\n",
    "        and params[\"weights\"] == model.best_params_[\"weights\"]\n",
    "    ):\n",
    "        num_neighbors.append(params[\"n_neighbors\"])\n",
    "        selected_means.append(model.cv_results_[\"mean_test_score\"][ind])\n",
    "        selected_std.append(model.cv_results_[\"std_test_score\"][ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим error bar для сравнения разброса ошибки при разном количестве соседей Neighbors.\n",
    "\n",
    "Видим, что на самом деле большой разницы в числе соседей, начиная с 11, и нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.title(f\"KNN CV, {params['metric']}, {params['weights']}\", size=18)\n",
    "plt.errorbar(num_neighbors, selected_means, yerr=selected_std, fmt=\"-o\")\n",
    "plt.xticks(num_neighbors, size=13)\n",
    "plt.ylabel(\"Mean_test_score\", size=15)\n",
    "plt.xlabel(\"Neighbors\", size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативой GridSearch является [RandomizedSearch 🛠️[doc]](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). Если в GridSearch поиск параметров происходит по фиксированному списку значений, то RandomizedSearch умеет работать с непрерывными значениями, случайно выбирая тестируемые значения, что может привести к более точной настройке гиперпараметров.\n",
    "\n",
    "Вы в явном виде указываете, сколько точек вы будете семплировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\"\"\"\n",
    "Parameters for RandomizedSearchCV:\n",
    "estimator — model\n",
    "cv — num of fold to cross-validation splitting\n",
    "param_distributions — parameters names\n",
    "n_iter — number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.\n",
    "scoring — metrics\n",
    "n_jobs — number of jobs to run in parallel, -1 means using all processors.\n",
    "\"\"\"\n",
    "\n",
    "model = RandomizedSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    n_iter=100,\n",
    "    cv=KFold(5, shuffle=True, random_state=42),\n",
    "    param_distributions={\n",
    "        \"n_neighbors\": np.arange(1, 31),\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "    },\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем лучшие гиперпараметры для модели, которые подобрали:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metric:\", model.best_params_[\"metric\"])\n",
    "print(\"Num neighbors:\", model.best_params_[\"n_neighbors\"])\n",
    "print(\"Weigths:\", model.best_params_[\"weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, параметры близки к выбранным полным перебором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Объект RandomizedSearchCV также можно использовать как обычную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(\n",
    "    f\"Percent correct predictions {np.round(accuracy_score(y_pred=y_pred, y_true=y_test)*100,2)} %\"\n",
    ")\n",
    "print(\n",
    "    f\"Percent correct predictions(balanced classes) {np.round(balanced_accuracy_score(y_pred=y_pred, y_true=y_test)*100,2)} %\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность уменьшилась на 0.5%. Возможно, такое понижение вам не критично."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>Насколько точна ваша модель?</font><img style: align=\"center\" width=\"200\" src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/how_compute_model_accuracy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Невозможно создать хорошее решение, не определив меру \"хорошести\". Нужно определиться с тем, как оценивать результат.\n",
    "Очень часто приходится слышать от заказчика вопрос со слайда.\n",
    "Чаще всего ответ “99%” их более чем устраивает.\n",
    "\n",
    "Однако в большинстве случаев такой ответ приводит к проблемам. Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/accuracy_problem_example.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/important_accuracy_factors.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Скорость перемещения  машины зависит от дороги: на дорогах бывают пробки, ограничивающие знаки, наконец, дороги бывают очень разного качества.\n",
    "\n",
    "Всё это влияет на скорость перемещения, порой — радикально.\n",
    "\n",
    "Также и точность наших моделей в первую очередь зависит от данных, на которых мы будем их оценивать. Модель, которая отлично работает на одном датасете, может намного хуже работать на другом или не работать вовсе.\n",
    "\n",
    "2. Машина может быть подвергнута тюнингу. Например, внедорожный тюнинг поможет преодолеть участок бездорожья, на котором неподготовленный автомобиль застрянет. Но при этом скорость на дорогах общего пользования может снизиться. Также и модель, как правило, имеет ряд параметров (гиперпараметров), от которых зависит её работа. Они могут подбираться в зависимости от задачи (ошибки первого и второго рода) и качества данных.\n",
    "\n",
    "3. Само понятие скорости допускает вариации: речь идет о средней или максимальной скорости? Аналогично и для оценки моделей существует несколько метрик, применение которых, опять же, зависит от целей заказчика и особенностей данных.\n",
    "\n",
    "**«На датасете X модель Y по метрике Z показала 99%».**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интуитивно понятной, очевидной и почти неиспользуемой метрикой является уже знакомая нам accuracy — доля правильных ответов алгоритма.\n",
    "\n",
    "$$ \\large Accuracy = \\frac{P}{N}, $$\n",
    "\n",
    "где $P$ — количество верно предсказанных классов,\n",
    "\n",
    "$\\quad\\  N$ — общее количество тестовых примеров.\n",
    "\n",
    "**Какие есть недостатки у такого способа?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/problem_of_simple_way_to_compute_accuracy.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy нельзя использовать, если **данные не сбалансированы**, то есть в одном из классов больше представителей, чем в другом.\n",
    "\n",
    "На рисунке выше мы видим, что при явном количественном преобладании объектов класса airplane модель может классифицировать все объекты как airplane и при этом получить такую же точность, как модель, которая учит все 3 класса, так как количество ошибок будет равно числу объектов классов, в которых меньше представителей (в данном случае в классах automobile и bird по 10 представителей, соответсвенно, 20 ошибок).\n",
    "\n",
    "Также она не подойдет для задач сегментации и детектирования: если требуется не только определить наличие объекта на изображении, но и найти место, где он находится, то весьма желательно учитывать разницу в координатах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения этой проблемы вводятся метрики \"точность\" и \"полнота\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/precision-recall.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для численного описания этих метрик необходимо ввести важную концепцию в терминах ошибок классификации — **confusion matrix** (матрица ошибок).\n",
    "Допустим, у нас есть два класса и алгоритм, предсказывающий принадлежность каждого объекта к одному из классов. Тогда матрица ошибок классификации будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|      |$\\large y=1$  |$\\large y=0$   |\n",
    "| ---  |---  |---   |\n",
    "| $\\large \\widehat{y}=1$    |$\\large True Positive \\ (TP) $   | $\\large False Positive \\ (FP)   $  |\n",
    "| $\\large \\widehat{y}=0$    |$\\large False Negative \\ (FN)$   | $\\large True Negative \\ (TN)     $ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision, recall**\n",
    "\n",
    "Для оценки качества работы алгоритма на каждом из классов по отдельности введем метрики **precision (точность)** и **recall (полнота)**.\n",
    "\n",
    "$\\large precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "$\\large recall = \\frac{TP}{TP + FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Именно** введение **precision** не позволяет нам записывать все объекты в один класс, так как в этом случае мы получаем рост уровня False Positive. **Recall демонстрирует способность алгоритма обнаруживать данный класс вообще, а precision — способность отличать этот класс от других классов.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**\n",
    "\n",
    "Accuracy также можно посчитать через матрицу ошибок.\n",
    "\n",
    "$\\displaystyle accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced accuracy**\n",
    "\n",
    "В случае дисбаланса классов есть специальный аналог точности – сбалансированная точность.\n",
    "\n",
    "$\\displaystyle BA = \\frac{R_1 + R_0}{2} = \\frac{1}{2} (\\frac{TP}{TP + FN} + \\frac{TN}{TN + FP})$\n",
    "\n",
    "Для сбалансированного и несбалансированного случаев она будет равна $0. 96$ и $0.33$ соответственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты запоминания – это среднее полноты всех классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-мера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибки классификации бывают двух видов: **False Positive** и **False Negative**. Первый вид ошибок называют **ошибкой I-го рода**, второй — **ошибкой II-го рода**. Пусть студент приходит на экзамен. Если он учил и знает, то принадлежит классу с меткой 1, иначе — имеет метку 0 (знающего студента называем «положительным»). Пусть экзаменатор выполняет роль классификатора: ставит зачёт (т.е. метку 1) или отправляет на пересдачу (метку 0). Самое желаемое для студента «не учил, но сдал» соответствует ошибке 1 рода, вторая возможная ошибка «учил, но не сдал» – 2 рода.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/1_2_errors.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто в реальной практике стоит задача найти **оптимальный** **баланс** между **Presicion и Recall**. Классическим примером является задача определения оттока клиентов.\n",
    "\n",
    "**F-мера** (в общем случае $\\ F_\\beta$) — среднее гармоническое precision и recall :\n",
    "\n",
    "$\\large \\ F_\\beta = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{(\\beta^2 \\cdot precision) + recall}$\n",
    "\n",
    "\n",
    "$\\beta$ в данном случае определяет вес точности в метрике, и при $\\beta = 1$ это среднее гармоническое (с множителем 2, чтобы в случае precision = 1 и recall = 1 иметь $\\ F_1 = 1$).\n",
    "\n",
    "F-мера достигает максимума при полноте и точности, равными единице, и близка к нулю, если один из аргументов близок к нулю.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сбалансированная F-мера, $β=1$:\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/f1_balanced.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При перекосе в точность ($β=1/4$):\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/f1_unbalanced.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более наглядно: низкие значения точности не позволяют метрике F вырасти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/f1_lines.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>Зависимость F1-меры от полноты при фиксированной точности. При точности 10% F1-мера не может быть больше 20%.</em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn есть удобная функция **sklearn.metrics.classification_report**, возвращающая recall, precision и F-меру для каждого из классов, а также количество экземпляров каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "target_names = [\"class 0\", \"class 1\", \"class 2\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Многоклассовый случай**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "fig.tight_layout(pad=3.0)\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "# font = {'size':'21'}\n",
    "ax[0].set_title(\"Balanced data\")\n",
    "ax[1].set_title(\"Unbalanced data\")\n",
    "\n",
    "labels = [\"Airplane\", \"Auto\", \"Bird\"]\n",
    "\n",
    "# Balanced data\n",
    "air, auto, bird = 150, 150, 150\n",
    "actual_b = np.array([0] * air + [1] * auto + [2] * bird)\n",
    "predicted_b = np.array([0] * (air - 10) + [1] * (auto + 20) + [2] * (bird - 10))\n",
    "\n",
    "# Unbalanced data\n",
    "air, auto, bird = 430, 10, 10\n",
    "actual_ub = np.array([0] * air + [1] * auto + [2] * bird)\n",
    "predicted_ub = np.array([0] * (air + 20) + [1] * (auto - 10) + [2] * (bird - 10))\n",
    "\n",
    "metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix=metrics.confusion_matrix(actual_b, predicted_b),\n",
    "    display_labels=labels,\n",
    ").plot(ax=ax[0])\n",
    "\n",
    "metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix=metrics.confusion_matrix(actual_ub, predicted_ub),\n",
    "    display_labels=labels,\n",
    ").plot(ax=ax[1])\n",
    "\n",
    "label_font = {\"size\": \"15\"}  # Adjust to fit\n",
    "ax[0].set_xlabel(\"Predicted labels\", fontdict=label_font)\n",
    "ax[0].set_ylabel(\"True labels\", fontdict=label_font)\n",
    "ax[1].set_xlabel(\"Predicted labels\", fontdict=label_font)\n",
    "ax[1].set_ylabel(\"True labels\", fontdict=label_font)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"Accuracy Balanced   Data:\", round(metrics.accuracy_score(actual_b, predicted_b), 2)\n",
    ")\n",
    "print(\n",
    "    \"Accuracy Unbalanced Data:\",\n",
    "    round(metrics.accuracy_score(actual_ub, predicted_ub), 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Balanced accuracy for Balanced data  :\",\n",
    "    round(metrics.balanced_accuracy_score(actual_b, predicted_b), 2),\n",
    ")\n",
    "print(\n",
    "    \"Balanced accuracy for Unbalanced data :\",\n",
    "    round(metrics.balanced_accuracy_score(actual_ub, predicted_ub), 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiclass Accuracy**\n",
    "\n",
    "\n",
    "В случае многоклассовой классификации термины TP, FP, TN, FN считаются для каждого класса:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/confmatrix.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large Multiclass Accuracy = \\frac{1}{n}\\sum_{i=1}^{n} [actual_{i}==predicted_{i}]  =   \\frac{\\sum_{k=1}^{N} TP_{Ck} }{\\sum_{k=1}^{N} (TP_{Ck} + TN_{Ck} + FP_{Ck} + FN_{Ck})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть решается задача бинарной классификации, и необходимо оценить важность признака $j$ для решения именно этой задачи. В этом случае можно попробовать построить классификатор, который использует лишь этот один признак $j$, и оценить его качество. Например, можно рассмотреть очень простой классификатор, который берёт значение признака $j$ на объекте, сравнивает его с порогом $t$, и если значение больше этого порога, то он относит объект к первому классу, если же меньше порога, то к другому, нулевому или минус первому, в зависимости от того, как мы его обозначили. Далее, поскольку этот классификатор зависит от порога $t$, то его качество можно измерить с помощью таких метрик, как площадь под ROC-кривой или Precision-Recall кривой, а затем по данной площади отсортировать все признаки и выбрать лучшие.\n",
    "\n",
    "Но вначале разберёмся, что такое **AUC-ROC**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC-кривой (ROC, receiver operating characteristic, кривой ошибок) традиционно называют график кривой, которая характеризует качество предсказаний бинарного классификатора на некоторой фиксированной выборке при всех значениях порога классификации. Площадь под графиком ROC-кривой AUC (area under the curve) является численной характеристикой качества классификатора. Определим, как именно строится ROC-кривая, через рассмотрение примера.\n",
    "\n",
    "Вывод некоторого бинарного классификатора представлен в табл. 1. Упорядочим строки данной таблицы по убыванию значения вывода нашего бинарного классификатора и запишем результат в табл. 2. Если наш алгоритм справился с задачей классификации, то мы увидим в последней колонке также упорядоченные по убыванию значения (или случайное распределение меток $0$ и $1$ в противном случае)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/roc_auc_data_example.png\" alt=\"alttext\" width=600/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приступим непосредственно к изображению графика ROC-кривой. Начнём с квадрата единичной площади и изобразим на нём прямоугольную координатную сетку, равномерно нанеся $m$ горизонтальных линий и $n$ вертикальных. Число горизонтальных линий $m$ соответствует количеству объектов класса $1$ из рассматриваемой выборки, а число $n$ — количеству объектов класса $0$. В нашем примере $m=3$ и $n=4$. Таким образом, квадрат единичной площади разбился на $m \\times n$ прямоугольных блоков (на $12$ штук согласно нашему примеру)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начиная из точки $(0, 0)$, построим ломаную линию в точку $(1, 1)$ по узлам получившейся решетки по следующему алгоритму:\n",
    "- рассмотрим последовательно все строки табл. 2\n",
    "- оценка алгоритма для объекта из текущей строки не равна оценке для объекта из следующей:\n",
    "- - если в строке содержится объект с меткой класса $1$, рисуем линию до следующего узла вертикально вверх\n",
    "- - если в строке содержится объект с меткой класса $0$, рисуем линию до следующего узла горизонтально направо\n",
    "- оценки для объектов в нескольких последующих строках совпадают:\n",
    "- - нарисовать линию из текущего узла в узел, располагающийся на $k$ углов вертикально выше и на $l$ узлов левее. $k$ и $l$ соответственно равны количеству объектов класса $1$ и $0$ среди группы повторяющихся значений оценок классификатора\n",
    "\n",
    "(всего потребуется не более $n + m$ шагов — столько же, сколько строк в нашей таблице)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/make_roc_curve.png\" alt=\"alttext\" width=500/></center>\n",
    "\n",
    "<center><em>Рис.1. Построение ROC-кривой.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Справа на рис. 1 показана полученная для нашего примера кривая – эта изображенная на единичном квадрате ломаная линия и называется ROC-кривой.\n",
    "\n",
    "Вычислим площадь под получившийся кривой — **AUC-ROC**. В нашем примере AUC-ROC $= 9.5 / 12 ~ 0.79$, и именно это значение является искомой метрикой качества работы нашего бинарного классификатора.\n",
    "(Так как мы начали свое построение с квадрата единичной площади, то AUC-ROC может принимать значения в $[0,1]$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ROC-кривая абсолютно точного бинарного классификатора имеет вид $(0,0) \\rightarrow (1,0) \\rightarrow (1,1)$. ROC-AUC для такого идеального классификатора равен площади всего единичного квадрата.\n",
    "2. ROC-кривая для всегда ошибающегося бинарного классификатора имеет вид $(0,0) \\rightarrow (0,1) \\rightarrow (1,1)$. ROC-AUC в этом случае равен нулю.\n",
    "3. Если наш бинарный классификатор для всех объектов предскажет одно и то же значение, то его ROC-кривая будет иметь вид $(0,0) \\rightarrow (1,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/various_roc_curves.png\" alt=\"alttext\" width=500/></center>\n",
    "\n",
    "<center><em>Рис. 2. ROC-кривые для наилучшего (AUC=1), константного (AUC=0.5) и наихудшего (AUC=0) алгоритма.</em></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смысл метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить на рис. 3, координатная сетка, описанная в нашем алгоритме построения ROC кривой, разбила единичный квадрат на столько прямоугольников, сколько существовало пар объектов класс-$0$ — класс-$1$ в исследуемой выборке данных. Если теперь посчитать количество оказавшихся под ROC-кривой прямоугольников, то можно заметить, что оно в точности равно числу верно классифицированных алгоритмом пар объектов, то есть таких пар объектов противоположных классов, для которых алгоритм поставил большую по величине оценку для объекта класса $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L01/out/roc_auc_pairs_descripton.png\" alt=\"alttext\" width=200/></center>\n",
    "\n",
    "<center><em>Рис. 3. Каждый блок соответствует паре объектов.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, **ROC-AUC равен части верно упорядоченных оценкой классификатора пар объектов противоположных классов (в которой объект класса $0$ получил оценку исследуемым классификатором ниже, чем объект класса $1$)**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L01/three_types_of_classification_tasks.jpg\" width=\"650\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://thinkpalm.com/blogs/top-machine-learning-algorithms-for-business-applications-in-2023/\">Top Machine Learning Algorithms For Business Applications In 2023</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ещё один случай — когда объект может принадлежать одновременно нескольким классам — называется multilabel (многометочная) классификация. Такую задачу не стоит сводить к задаче бинарной классификации по каждому классу, ибо метки могут быть не независимыми.\n",
    "\n",
    "Допустим, у нас есть 3 объекта, и модель предсказала нам 3 набора меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0,1,1,1],\n",
    "         [0,0,1,0],\n",
    "         [1,1,0,0]]\n",
    "\n",
    "y_pred = [[0,1,0,1],\n",
    "          [0,1,1,1],\n",
    "          [1,0,1,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**\n",
    "\n",
    "Оценивает точное совпадение вектов классов. Вариант — считать точность по каждому классу независимо.\n",
    "\n",
    "**Confusin Matrix**\n",
    "\n",
    "Специальная функция, которая создаст 4 матрицы, по одной на каждый класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision, Recall, F1**\n",
    "\n",
    "Могут применяться независимо к каждой метке, также эти результаты можно объединить различными усреднениями:\n",
    "\n",
    "* micro — расчёт идёт без разделения меток по классам;\n",
    "* macro — вычисление метрик производится для каждой метки, затем идёт вычисление среднего значения, дисбаланс не берётся в расчёт;\n",
    "* weighted — также, только берётся в расчёт дисбаланс объектов;\n",
    "* samples — усредение ведётся по каждому объекту.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification report**\n",
    "\n",
    "Может быть использован вами ровно также, как и раньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['label A', 'label B', 'label C', 'label D']\n",
    "\n",
    "print(classification_report(y_true, y_pred,target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[colab] 🥨 Блокнот на Kaggle с примерами рассчётов Multilabel](https://www.kaggle.com/code/kmkarakaya/multi-label-model-evaluation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Литература:</font>\n",
    "\n",
    "<font size=\"5\">Полезное</font>\n",
    "\n",
    "* [Работы выпускников](https://msu.ai/library)\n",
    "* [Как писать научные статьи?](https://stepik.org/course/10524/promo)\n",
    "\n",
    "<font size=\"5\">Данные</font>\n",
    "* [Соревнования Kaggle](https://www.kaggle.com/)\n",
    "* [Google Datasets](https://datasetsearch.research.google.com/)\n",
    "* [Сайт Papers with Code](https://paperswithcode.com/)\n",
    "* [[arxiv] 🎓 Поведение нейросетей и ошибки в разметке](https://arxiv.org/abs/2211.01866)\n",
    "* [[stackexchange] 🎓 Обсуждение проблемы различия данных при обучении и на инференсе](https://stats.stackexchange.com/questions/362906/co-variate-shift-between-train-and-test-data-set)\n",
    "* [[doc] 🛠️ Датасет c трафиком из DARPA](https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)\n",
    "* [[doc] 🛠️ CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "<font size=\"5\">Руководства</font>\n",
    "\n",
    "* [[blog] ✏️ Эндрю Ын. Страсть к Машинному обучению](https://habr.com/ru/articles/419757/)\n",
    "\n",
    "* [[git] 🐾 Три блокнота с подробным анализом реального датасета](https://github.com/AleksandrIvchenko/machine-learning-project-walkthrough)\n",
    "\n",
    "* [[blog] ✏️ Как избежать «подводных камней» машинного обучения: руководство для академических исследователей](https://habr.com/ru/post/664102/) — гайд по типичным ошибкам\n",
    "\n",
    "<font size=\"5\">Инструменты</font>\n",
    "\n",
    "* [[doc] 🛠️ NumPy](https://numpy.org/) — массивы и математические функции\n",
    "* [[doc] 🛠️ Scikit-learn](https://scikit-learn.org/stable/) — ML алгоритмы, \"toy\" — датасеты;\n",
    "* [[doc] 🛠️ Pandas](https://pandas.pydata.org/) — табличные данные.\n",
    "\n",
    "* [[doc] 🛠️ **PyTorch**](https://pytorch.org/) — нейросети.\n",
    "\n",
    "* [[doc] 🛠️ Matplotlib](https://matplotlib.org/) — визуализация.\n",
    "\n",
    "* [[doc] 🛠️ Seaborn](https://seaborn.pydata.org/) — визуализация статистик\n",
    "\n",
    "<font size=\"5\">Методы и алгоритмы</font>\n",
    "\n",
    "* [[wiki] 📚 Метод k-ближайших соседей](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "* [[wiki] 📚 Функции расстояния между парой точек](https://en.wikipedia.org/wiki/Metric_(mathematics))\n",
    "* [[git] 🐾 Быстрый k-NN Facebook AI Research Similarity Search](https://github.com/facebookresearch/faiss)\n",
    "* [[arxiv] 🎓 Hierarchical Navigable Small World](https://arxiv.org/abs/1603.09320) — алгоритм поиска ближайших соседей\n",
    "\n",
    "<font size=\"5\">Другое</font>\n",
    "\n",
    "* [[blog] ✏️ Цветовые пространства](https://habr.com/ru/articles/181580/)\n",
    "* [[blog] ✏️ Стратификация](https://www.reneshbedre.com/blog/stratified-sampling.html)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
