{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Введение в машинное обучение</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ML и DL и AI в Computer Science "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Место глубокого обучения и нейронных сетей в ИИ**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/ai_ml_dl.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует множество разных определений, однако большая часть из них завязана на человеко-машинном взаимодействии, то есть это алгоритмы или методы, которые либо имитируют поведение людей, либо позволяют машине вести себя аналогично людям (то есть проявлять некоторое интеллектуальное-разумное поведение). Область ИИ не ограничивается исключительно машинным обучением, которое состоит из обучения на примерах. В ИИ входит целый ряд алгоритмов, например многоагентные системы (расшифровка) или базы знаний, в которых люди создают связи между разными понятиями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Искусственный интеллект (AI/ИИ)**  ≈ область ИТ/Computer science, связанная с моделированием интеллектуальных или творческих видов человеческой деятельности.\n",
    "\n",
    "**Машинное обучение(ML)** — подраздел ИИ, связанный с обучением на данных, он не единственный. Например, базы знаний или многоагентные системы также относят к разделам ИИ. \n",
    "\n",
    "**Глубокое обучение (Deep Learning, DL)** ≈ Многослойная нейросеть (MLP = multi layer perceptron).\n",
    "\n",
    "Однако сейчас мы рассмотрим более узкую область, связанную с DL. Модели, которые имеют несколько слоёв, называются глубокими или нейросетевыми. Хотя, если мы возьмем один слой такой модели (например линейный классификатор, он же перцептрон), он перестанет быть глубокой моделью, хотя по факту он и является простейшей нейросетью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Области применения DL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/ai_ml_dl_cv_nlp_sr.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последнее время именно такого рода модели показывают высокую эффективность в тех областях, в которых влияние человека казалось превалирующим. В частности, это человеко-компьютерное зрение (Computer Vision, CV), распознавание естественного языка (NLP, извлечение смысла, машинный перевод) и речи. В рамках курса мы рассмотрим, как эта область может применяться на практических задачах и моделях, их решающих. Также мы познакомимся с результатами самых современных исследований по теме. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Связь DL с наукой "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/ai_ml_dl_cv_nlp_sr_science.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо прикладных задач существуют еще и научные исследования, результаты которых до известной степени непредсказуемы. Нельзя исключать то, что они окажутся применимы к решению новых задач, в том числе в областях, где применяются технологии DL, где до сих пор активно не использовались. Поддержка такого рода исследований и есть основная задача нашего курса. \n",
    "\n",
    "В первую очередь для нас важны задачи аспирантов, на которых и будет построены дальнейшие исследования. И именно на основе ваших задач будут сделаны выводы о моделях, рекомендованных под конкретно ваш случай."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## История развития DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретические основы искусственных нейронных сетей были заложены более 50 лет назад."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/history_of_dl.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему же для решения практических задач их начали активно стали применять только в последние 10 лет?\n",
    "\n",
    "Давайте разберемся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/perceptron_xor.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перцептро́н, или персептрон (англ. perceptron от лат. perceptio — восприятие; нем. Perzeptron) — математическая или компьютерная модель восприятия информации мозгом (кибернетическая модель мозга), предложенная Фрэнком Розенблаттом в 1957 году и впервые реализованная в виде электронной машины «Марк-1» в 1960 году. Перцептрон стал одной из первых моделей нейросетей, а «Марк-1» — первым в мире нейрокомпьютером. \n",
    "\n",
    "Классический метод обучения перцептрона — это метод коррекции ошибки. Он представляет собой такой вид обучения с учителем, при котором вес связи не изменяется до тех пор, пока текущая реакция перцептрона остаётся правильной. При появлении неправильной реакции вес изменяется на единицу, а знак (+/-) определяется противоположным от знака ошибки. \n",
    "\n",
    "На фоне роста популярности нейронных сетей в 1969 году вышла книга Марвина Минского и Сеймура Паперта, которая показала принципиальные ограничения перцептронов. Это привело к смещению интереса исследователей искусственного интеллекта в противоположную от нейросетей область символьных вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/hubel_and_wiesel_experiment.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной из важнейших работ, связанных с глубоким обучением, является эксперимент американских биологов из Гарварда. В 1959 были изучены реакции определенных участков кошачьего мозга на определенные простые визуальные стимулы. Как и большая часть открытий, это выяснилось абсолютно случайно. \n",
    "\n",
    "В мозг кошке был вживлен электрод для того, чтобы определить, на какой рисунок будет реакция. Однако стоит вспомнить, что в то время слайды переключались последовательным движением и именно на это движение случилась реакция. Как только менялся слайд и по экрану проходила граница затвора, по сути, простая прямая линия, реакция передавалась и записывалась.\n",
    "\n",
    "После ряда экспериментов выяснилось, что существуют клетки, реагирующие на простые формы (линии и углы), на движение и движение в определенном направлении или определенной формы. Слои этих клеток образуют определенного рода иерархию и именно эта идея лежит в основе концепции нейросетевых методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/cognitron_fukushima.png\" width=\"400\" >\n",
    "\n",
    "\n",
    "<center><em>1975 - Cognitron: A self-organizing multilayered neural network K.Fukushima</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Кунихикой Фукусима:**\n",
    "\n",
    "**Когнитро́н** — искусственная нейронная сеть на основе принципа самоорганизации. Своей архитектурой когнитрон похож на строение зрительной коры, имеет иерархическую многослойную организацию, в которой нейроны между слоями связаны только локально.\n",
    "\n",
    "**Неокогнитрон** (англ. Neocognitron) — иерархическая многослойная искусственная нейронная сеть свёрточного типа, производная от когнитрона. Прообраз сети был позаимствован из модели, предложенной Хьюбелом и Визелем (1959 г.), согласно которой существует два вида клеток в первичной зрительной коре: простая и сложная клетка, расположенные каскадно.\n",
    "\n",
    "Архитектура этих моделей имеет много общего с современными искусственными нейронными сетями. Но на момент описания не было ни компьютерных ресурсов для  обучения такой модели, ни эффективного алгоритма обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/backpropagation_galushkin.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод обратного распространения ошибки** (англ. backpropagation) — метод вычисления градиента, который используется при обновлении весов многослойного перцептрона. Впервые метод был описан в 1974 г. А. И. Галушкиным, а также независимо и одновременно Полом Дж. Вербосом. Далее существенно развит в 1986 г. Дэвидом И. Румельхартом, Дж. Е. Хинтоном и Рональдом Дж. Вильямсом.\n",
    "\n",
    "Основная идея этого метода состоит в распространении сигналов ошибки от выходов сети к её входам, в направлении, обратном прямому распространению сигналов в обычном режиме работы.\n",
    "\n",
    "Для возможности применения метода обратного распространения ошибки передаточная функция нейронов должна быть дифференцируема."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Полный](https://scholar.google.ru/citations?user=3F4eOJMAAAAJ&hl=ru) перечень работ А.И. Галушкина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/lenet_lecun.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появление алгоритма обратного распространения ошибки, вкупе с возрастающими компьютерными мощностиями, позволило обучить многослойную нейронную сеть, которую можно было применять для решения практических задач.\n",
    "\n",
    "Архитектура такой сети была разработана в 1989 г. Яном Ле Куном. \n",
    "Сеть имела **5** слоёв, из них **2** свёрточных.\n",
    "\n",
    "Применялась в США для распознавания рукописных букв на почтовых конвертах до начала 2000г."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Победа нейросети AlexNet на соревновании ImageNet в 2012**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/imagenet_2012.png\" width=\"900\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 2012 году свёрточная нейронная сеть **[AlexNet](https://neurohive.io/ru/vidy-nejrosetej/alexnet-svjortochnaja-nejronnaja-set-dlja-raspoznavanija-izobrazhenij/)** (Alex Krizhevsky in collaboration with Ilya Sutskever and Geoffrey Hinton) победила на ImageNet c большим отрывом от конкурентов.\n",
    "Это событие породило новую волну интереса к алгоритмам глубокого обучения и, в частности, к свёрточным нейронным сетям.\n",
    "\n",
    "**AlexNet** — свёрточная нейронная сеть, которая оказала большое влияние на развитие машинного обучения, в особенности — на алгоритмы компьютерного зрения. Сеть с большим отрывом выиграла конкурс по распознаванию изображений ImageNet LSVRC-2012 в 2012 году (с количеством ошибок 15,3% против 26,2% у второго места). Архитектура AlexNet схожа с созданной Yann LeCum сетью LeNet. Однако у AlexNet больше фильтров на слое и вложенных свёрточных слоев.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ImageNet: Large Scale Visual Recognition Challenge (ILSVRC)**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/imagenet_ilsvrc.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fei-Fei Li](https://en.wikipedia.org/wiki/Fei-Fei_Li)\n",
    "\n",
    "[Christiane Fellbaum](https://en.wikipedia.org/wiki/Christiane_Fellbaum)\n",
    "\n",
    "С 2010 года в рамках проекта ILSVRC проводятся соревнования между исследовательскими группами по классификации объектов. ILSVCR возникла по аналогии с небольшой кампанией 2005 года PASCAL VOC, которая располагала набором из 20 тысяч изображений и 20 классов объектов. Существенный прогресс в распознавании образов был достигнут в 2010 году. В 2011 году хорошим результатом считалась ошибка классификации 25 %. В 2012 году система глубокого обучения на основе свёрточной нейронной сети смогла достичь 16 % ошибки, а в следующие годы ошибка упала до нескольких процентов. В 2015 году исследователи констатировали, что программы в определённых задачах проекта ILSVRC превзошли человеческие способности. \n",
    "\n",
    "**Условия соревнования:**\n",
    "На каждом изображении может быть один или несколько предметов, относящихся к одному из **1000** классов.\n",
    "Для метрики *Тop5* алгоритм выдает метки 5 классов. Если предмет, относящийся к одному из этих классов, есть на изображении, то ответ засчитывается как верный.\n",
    "Для *Top1* соответственно принимается только метка одного класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/alexnet_citations.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы понять важность победы AlexNet в 2012г., достаточно посмотреть на количество ссылок на данную работу.\n",
    "\n",
    "Оно сравнимо с количеством цитирований основополагающих трудов в различных областях науки и продолжает расти.\n",
    "\n",
    "• Клод Шеннон “Математическая теория связи” — позволила решить основные задачи теории информации;\n",
    "\n",
    "• Фрэнсис Криком и Джеймсом Д. Уотсон  “Молекулярная структура нуклеиновых кислот: структура дезоксирибонуклеиновой кислоты” - первая статья, в которой было опубликовано описание открытия двойной спирали структуры ДНК;\n",
    "\n",
    "• Обнаружение бозона Хиггса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "**Количество Цитирований**\n",
    "\n",
    "Ч. Дарвин, \"О происхождении видов\", 1859: **50,007**\n",
    "\n",
    "К. Шеннон, “Математическая теория связи”, 1953: **69,351**\n",
    "\n",
    "Д. Уотсон и Ф. Крик, “Молекулярная структура нуклеиновых кислот”, 1953: **13,111**\n",
    "\n",
    "ATLAS Collaboration, \"Наблюдение новой частицы в поисках Стандартной модели бозона Хиггса с детектором ATLAS на баке\", 2012: **14 429**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Сферы применения и технологии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Робототехника\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/robotics.jpg\"  width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросети широко применяются для решения задач технического зрения. Различным роботизированным  устройствам от таких, как беспилотные транспортные средства, до промышленных роботов или домашнего пылесоса, требуется определять своё местоположение в пространстве и/или местоположение окружающих объектов. \n",
    "\n",
    "Эту задачу можно решать путем обработки изображений с камер. Здесь очень эффективными оказались свёрточные нейросети, подобные AlexNet. \n",
    "\n",
    "Роботы присутствуют в нашей жизни в виде дронов, машин, пылесосов. Для использования в данных системах используется задача детекции, треккинга на видео, сегментации (связки с технологиями). Применение нейронных сетей в робототехнике — в частности это самоуправляемые автомобили, роботы на производстве, робот пылесос. \n",
    "\n",
    "Беспилотные автомобили Self-Driving Car и дроны. Промышленные и бытовые роботы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Детектирование (object detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/object_detection.jpg\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[КЛАССИФИКАЦИЯ](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8) + [РЕГРЕССИЯ](https://proglib.io/p/ml-regression) ~= [ДЕТЕКТИРОВАНИЕ](https://robocraft.ru/blog/computervision/3640.html/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Nvidia example: How Does a Self-Driving Car See?](https://blogs.nvidia.com/blog/2019/04/15/how-does-a-self-driving-car-see/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача поиска местоположения объекта в кадре — это задача детектирования. Она тесно связана с задачей классификации:\n",
    "\n",
    "Сначала обучается сеть, которая классифицирует изображения. То есть определяет, что на изображении присутствует человек. \n",
    "\n",
    "Затем к такой сети добавляются несколько слоев, которые предсказывают координаты объектов. То есть решают задачу регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знание координат объектов вокруг позволяет решать различные более сложные задачи: \n",
    "\n",
    "• Трекинг (отслеживание перемещения);\n",
    "\n",
    "• Предсказание действий;\n",
    "\n",
    "• SLAM (*simultaneous localization and mapping* — одновременная локализация и построение карты);\n",
    "\n",
    "• Оценка расстояний до объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic whale counting in satellite images with deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/counting_whales_nn.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот пример использования аналогичного подхода у биологов. Авторы [статьи](https://arxiv.org/pdf/1604.05605.pdf) обучили нейронную сеть искать на спутниковых снимках китов и подсчитывать их количество. \n",
    "\n",
    "Отдельно можно использовать классификатор для определения вида кита.\n",
    "\n",
    "Аналогичным образом можно обучить сеть искать объекты любых других категорий. Совсем не обязательно на изображениях в видимом диапазоне.\n",
    "\n",
    "[Репозиторий с реализацией](https://github.com/EGuirado/CNN-Whales-from-Space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Безопасность "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/security_video_analytics.png\"  width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видеоаналитика.\n",
    "\n",
    "Про системы распознавания лиц все вероятно слышали.\n",
    " Что скрывается “под капотом”?\n",
    "Несколько моделей. Одна ищет лицо на изображении. Кстати, с этим достаточно успешно справлялись и алгоритмы без применения глубокого обучения (ViolaJones 2001). \n",
    "Другая ищет ключевые точки, чтобы потом изображение выронить. \n",
    "\n",
    "Решаются те же две задачи (классификация + регрессия).\n",
    "\n",
    "Но количество людей, проходящих мимо камеры в метрополитене, огромно. И что хуже, их список заранее не известен. Поэтому мы не можем использовать классификатор, чтобы отличить лицо одного человека от другого. Нам просто неизвестно количество классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/clustering_face_recognition.jpg\" width=\"1100\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому при распознавании лиц применяется другая техника: по вырезанному и выравненному прямоугольнику с лицом строится вектор-признак “embedding” — некое компактное представление.\n",
    "\n",
    "По сути, сильно снижается размерность изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А дальше можно сравнить между собой полученные вектора, использовав любую метрику расстояния. \n",
    "\n",
    "То есть к классификации и регрессии добавляется 3-я базовая задача: **кластеризация**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ медицинских изображений "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/segmentation.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[U-Net: нейросеть для сегментации изображений](https://neurohive.io/ru/vidy-nejrosetej/u-net-image-segmentation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: поиск аномалий (опухолей) и определение их четких границ.\n",
    "\n",
    "Эта задача очень похожа на детектирование. Нужно найти, где находится объект. Но в данном случае нужно найти четкие границы. Желательно с точностью до пикселя.\n",
    "\n",
    "То есть для каждого пикселя нужно предсказать, к какому объекту он относится. \n",
    "\n",
    "**Получается попиксельный классификатор.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но проблема состоит в том, что пикселей много, и решать её в лоб — неэффективно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому при сегментации используется подход, подобный тому, что при **кластеризации лиц:**\n",
    "\n",
    "• Часть нейросети сжимает изображение — получается карта признаков (карта, потому что структура сохраняется);\n",
    "\n",
    "• На этой карте (см. выше) предсказываются границы объектов;\n",
    "\n",
    "• Вторая часть сети (симметрично первой восстанавливает размеры)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Это концепция энкодер - декодер.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/face_generation_gan.png\" width=\"1000\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На базе концепции энкодер - декодер появились так называемые генеративно-состязательные сети.\n",
    "Сжатое представление, которое получается на внутреннем слое сети, содержит какие-то ключевые признаки изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но не всю информацию об изображении и в зависимости от того как будет идти процедура восстановления мы можем получить разные вариации изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Почему состязательные?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку сеть генерирует совершенно новое изображение, у нас нет шаблона, с которым мы могли бы его сравнить и дать оценку работы модели.\n",
    "Поэтому для оценки качества работы первой сети (генератора) обучается вторая (дискриминатор), которая дает ответ на вопрос: похоже ли полученное изображение на настоящее или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/style_transfer_gan.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С результатами работы таких моделей вы все хорошо знакомы по соцсетям и мобильным приложениям.\n",
    "Помимо использования в развлекательных целях, эта технология широко используется и в научных работах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка изображений галактик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/delete_noise_gan.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения, полученные при помощи телескопов, оказываются зашумленными по причинам:\n",
    "- атмосферных помех;\n",
    "- шумам, которые даёт сенсор телескопа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классический способ борьбы с этой проблемой состоит в подборе сигнала похожего на суммарный шум: point spread function (PSF) и последующей сверке изображения с этим сигналом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[В данной работе](https://academic.oup.com/mnrasl/article/467/1/L110/2931732) для решения той же проблемы авторы статьи обучили GAN.\n",
    "В качестве входных данных использовались изображения галактик.\n",
    "\n",
    "*4550 galaxies from the Sloan Digital Sky Survey Data Release 12 (York et al. 2000; Alam et al. 2015)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/galaxys_after_gan.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения преобразовывались в RGB формат. И к ним искусственно добавлялись искажения, имитирующие шум от сенсора и размытие, возникающее за счёт потоков воздуха в атмосфере(PSF).\n",
    "Датасет состоял из пар зашумленных и чистых изображений.\n",
    "\n",
    "Генератор обучался на основе изображения с шумом генерировать чистое изображение, а дискриминатор отличал зашумленные изображения от чистых.\n",
    "\n",
    "На первый взгляд результат впечатляет. Однако авторы признают, что на фотографиях, где присутствуют объекты, редко появляющиеся в датасете, результат хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN & OneShot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/oneshot_learning_gan.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели, которые мы рассматривали, до сих обучаются на большом количестве данных. \n",
    "В ряде областей (например, в медицине) их может не хватать.\n",
    "\n",
    "Вот пример [статьи](https://indico.cern.ch/event/967970/contributions/4118959/attachments/2151681/3628080/Burnaev_Manifold_Knowledge_Transfer_v2.pdf), в которой авторы обучили GAN сегметировать МРТ снимках мозга с признаками рассеянного склероза, а затем использовали её для поиска опухолей, дообучив модель всего на 5 снимках.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Применение семантической сегментации МРТ в медицине:**\n",
    "\n",
    "• анализ и мониторинг опухолей (например, головного мозга, печени);\n",
    "\n",
    "• обнаружение бляшек рассеянного склероза;\n",
    "\n",
    "• обнаружение гиперестезии белого вещества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP & Speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/nlp_speech_recognition.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Область применения DL не ограничивается только изображениями. \n",
    "\n",
    "Они так же весьма эффективны для распознавания голоса и машинного перевода.\n",
    "В отличие от изображений, входные данные имеют другую структуру: это последовательность, длина которой заранее неизвестна.\n",
    "\n",
    "Для работы с такого рода данными используются сети другого типа — рекуррентные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/rnn_architecture.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные подаются последовательно.\n",
    "Каждый элемент данных может оказывать влияние на выход модели и менять ее состояние. \n",
    "\n",
    "[Статья](https://www.nature.com/articles/s41598-019-48909-4), в которой авторы использовали эту технологию для анализа сигналов, которыми общаются киты.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фолдинг белка "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/alphafold.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент существует важная задача — фолдинг белка. Белок синтезируются в клетке в виде соединённых последовательно аминокислот. Эта последовательность обычно известна и кодируется в геноме.\n",
    "\n",
    "Однако после цепочка будет складываться в сложные пространственные структуры и, в зависимости от того, как эта структура будет выглядеть, зависит то, как белок будет себя вести в дальнейшем. Соответственно, понимание его особенностей служит ключом для производства лекарств и интерпретации генетических аномалий. \n",
    "\n",
    "В геноме человека могут происходить мутации — ошибки в геноме, которые могут приводить к изменению аминокислотной последовательности белка. \n",
    "\n",
    "Далеко не все мутации, которые есть в геноме, приведут к проблемам в конечной структуре, и если мы заранее будем знать, что одна мутация белка с дефектом, а другая безопасная, мы сможем предсказать вероятность развития болезни. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку эти связи обусловлены достаточно сложными внутримолекулярными взаимодействиями, просчитать заранее, как будет выглядеть молекула, достаточно трудозатратно. На каждом этапе формирования действуют разные связи между аминокислотами (водородные связи, гидрофобные взаимодействия и пр.), тем самым образуя сложную структуру.\n",
    "\n",
    "Рассчитать аналитически структуру, которая образуется в ходе этих взаимодействий, сложно, но можно применить для этого нейросеть, подав ей аминокислотную последовательность белка. \n",
    "\n",
    "Автора AlphaFold2 обучают нейросеть, которая предсказывает расстояния и углы между атомами аминокислот в конечном белке, причем делает это итеративно, улучшая предсказание с предыдущего шага. Далее, специальный алгоритм преобразует это в набор координат атомов, что и является пространственной структурой белка. \n",
    "Этот трехмерный массив координат атомов можно визуализировать, и дальше структурные биологи могут делать вывод о том, получится конкретный белок дефектным или нет. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А эти знания уже применяются в области производства лекарств. Например, есть база веществ и известно, какая у них структура. Имея структуру белка, можно предсказать, в каком месте и с какой формой белка они могут и должны соединяться. Соответственно, по базе данных можно найти вещества, которые будут с этим белком связаны и уже подобрать из имеющихся “претендентов” тот, который наилучшим образом будет работать. \n",
    "\n",
    "Про мутации. Есть базы данных нормальных и мутагенных белков, и мы можем сравнить то, что получилось у нас в результате фолдинга с эталоном и посмотреть, насколько большая разница в структурах (опять же, для этого нужны структурные биологи, так как не все части структуры белка равнозначны). И на основе этого уже предсказать, насколько опасна будет та или иная мутация. \n",
    "\n",
    "\n",
    "\n",
    "[Заявление от deepmind](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)\n",
    "\n",
    "[Мнение структурных биологов](https://yakovlev.me/para-slov-za-alphafold2/?fbclid=IwAR23L8XigP7byPcx10o-4y5L3VTLRzDmuioqw99iKZ0SkPrauezrJJJayiM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/alphafold_nn.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Improved protein structure prediction](https://www.nature.com/articles/s41586-019-1923-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Причины успехов технологий на основе DL \n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/high_dL_perfomance.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему всё это произошло так внезапно?**\n",
    "\n",
    "1. Чтобы модель могла извлечь и запомнить все важные закономерности, все они должны присутствовать в данных. Доступные цифровые фотокамеры и быстрый интернет, обеспечивший исследователям доступ к данным и возможность коллаборативной разметки, стали появляться только в начале 2000-х годов.\n",
    "\n",
    "\n",
    "2. Вычислительные мощности:\n",
    "\n",
    "* Lenet обучали на Pentium2  это примерно 10^7 транзисторов;\n",
    "\n",
    "* AlexNet на двух GPU GTX580 это уже примерно 10^14;\n",
    "\n",
    "С данными у ученых дела обстоят не так хорошо.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ML — Подход к научным проблемам</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Извлечение закономерностей — закон Ньютона \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/newtons_law.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе наблюдений люди выявляют закономерности и делают обобщение, наблюдая за реальным миром.\n",
    "Результатом такой умственной деятельности является модель, описывающая некоторые процессы реального мира.\n",
    "\n",
    "Она может быть описана при помощи математических формул или алгоритмического языка.\n",
    "\n",
    "Сейчас появилась технология, которая может это делать вместо человека."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/newtons_law_and_nn.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Это ML**\n",
    "\n",
    "**ML** — это технология, которая позволяет выявлять закономерности в данных и обобщать их. \n",
    "\n",
    "Вы можете использовать её для поиска закономерностей, которые люди ещё не обнаружили и таким образом совершить открытие.\n",
    "Правда, результатом обучения такой модели будет не компактная формула, а набор весов. \n",
    "По сути это набор коэффициентов для некоторого математического выражения.\n",
    "\n",
    "Для этого нужно две вещи: **данные** и **валидация результата.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/predictions_by_nn.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как человеку, так и алгоритму машинного обучения требуется подготовка данных.\n",
    "\n",
    "Законы Ньютоны **не** сформулированы для яблок. Для описания закономерностей в науке используются абстракции: *сила, масса, ускорение.*\n",
    "\n",
    "Данные для **ML** моделей тоже должны быть подготовлены. Типичная форма такой абстракции — вектор или n-мерный массив чисел.\n",
    "\n",
    "Именно с такой формой представления данных работает большинство современных моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/nn_predict_patterns.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй элемент, который потребуется для процесса обучения —  разработка способа оценки результата (*валидации*).\n",
    "\n",
    "Вне зависимости от того, какой метод обучения используется — с учителем или без, требуется некий критерий, по которому будет оцениваться выход модели и впоследствии корректироваться веса.\n",
    "\n",
    "В базовом варианте: полученный результат сравнивают с эталонным и если разница велика — корректируют модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Поясним эту идею на конкретном примере. Допустим, у нас есть наручный шагомер, который фиксирует перемещения в пространстве. Скорее всего, в нем встроен акселерометр, который способен фиксировать перемещения по трем осям. На выходе мы получаем сигнал с нескольких(3-х) датчиков.\n",
    "\n",
    "Если задача состоит в том, чтобы подсчитать количество шагов, то к её решению можно подойти двумя способами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/accelerometer_task.jpg\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классический: напишем программу. \n",
    "Если появилось ускорение по одной из осей, которое больше определенного порога, то мы создаем то условие, которое срабатывает. Позже мы выясним, что подобные сигнатурные сигналы с датчика могут поступить и при других определенных движениях, не связанных с шагами, например, во время плавания.\n",
    " Добавляется дополнительное условие, которое фильтрует подобные ситуации. \n",
    "\n",
    "Находятся всё новые и новые исключения из общего правила, программа и ее алгоритмическая сложность будет расти.\n",
    "\n",
    "Программу будет сложнее поддерживать из-за большого объема кода в ней. \n",
    "Изменение в одной из частей потребует внесение правок в другой код  и.т.п."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/accelerometr_solution_standart.png\" width=\"700\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант №2\n",
    "\n",
    "\n",
    "С появлением машинного обучения мы можем применить принципиально другой подход. \n",
    "Не задумываясь о том, что значат показания каждого из акселерометров, мы можем просто собрать некоторый архив данных за определенное время (возможно разбив на более короткие промежутки времени). Всё, что нам потребуется помимо этих данных — это информация о том, сколько было сделано реальных шагов. После этого данные загружаются в модель, и она на этих данных учится. При достаточном количестве данных и адекватно подобранной модели (чем мы и будем заниматься) мы сможем научить ее решать конкретные задачи (в данном случае — считать шаги). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/accelerometr_solution_nn.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что по сути модели всё равно, что считать: шаги, сердечный ритм, количество калорий, ударов по клавиатуре и пр. Нет необходимости писать под каждый пример отдельную программу, достаточно собрать данные и мы сможем решить множество абсолютно разных задач. \n",
    "\n",
    "Важно лишь понимать, какую модель предпочтительнее выбрать. С этим мы и будем разбираться в ходе курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/different_type_of_tasks.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Базовые задачи ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/ml_basic_tasks.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[scikit-learn](https://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все многообразие практических задач базируются на трех базовых.\n",
    "\n",
    "* Регрессия — предсказание;\n",
    "* Классификация — разделение;\n",
    "* Кластеризация — разбиение на классы, когда их число заранее не известно. (близка к классификации, но не эквивалентна ей).\n",
    "\n",
    "Умея решать эти задачи, можно перейти почти к любой, рассматриваемой в примерах (детекции, сегментации и.т.п.)\n",
    "\n",
    "**Начнем с них.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/classification_task.png\" width=\"700\" >\n",
    "\n",
    "Решение задачи классификации является одним из важнейших способов применения нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача классификации представляет собой отнесение образца к одному из нескольких попарно не пересекающихся множеств.\n",
    "\n",
    "В качестве образов могут выступать различные по своей природе объекты: символы текста, изображения, образцы звуков и т. д. При обучении сети предлагаются различные образцы образов с указанием того, к какому классу они относятся. Образец, как правило, представляется как вектор значений признаков. При этом совокупность всех признаков должна однозначно определять класс, к которому относится образец. В случае, если признаков недостаточно, сеть может соотнести один и тот же образец с несколькими классами, что неверно. По окончании обучения сети ей можно предъявлять неизвестные ранее образы и получать ответ об их принадлежности к определённому классу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/regression_task.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Способности нейронной сети к прогнозированию напрямую следуют из её способности к обобщению и выделению скрытых зависимостей между входными и выходными данными. После обучения сеть способна предсказать будущее значение некой последовательности на основе нескольких предыдущих значений и (или) каких-то существующих в настоящий момент факторов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогнозирование возможно только тогда, когда предыдущие изменения действительно в какой-то степени предопределяют будущие. Например, прогнозирование котировок акций на основе котировок за прошлую неделю может оказаться успешным (а может и не оказаться), тогда как прогнозирование результатов завтрашней лотереи на основе данных за последние 50 лет почти наверняка не даст никаких результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/clustering_task.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многомерная статистическая процедура, выполняющая сбор данных, содержащих информацию о выборке объектов, и затем упорядочивающая объекты в сравнительно однородные группы. Задача кластеризации относится к статистической обработке, а также к широкому классу задач обучения без учителя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под кластеризацией понимается разбиение множества входных сигналов на классы, при том, что ни количество, ни признаки классов заранее не известны. После обучения модель способна определять, к какому классу относится входной сигнал. Модель также может сигнализировать о том, что входной сигнал не относится ни к одному из выделенных классов — это является признаком новых, отсутствующих в обучающей выборке, данных. Таким образом, подобная модель может выявлять новые, неизвестные ранее классы сигналов. Соответствие между классами, выделенными сетью, и классами, существующими в предметной области, устанавливается человеком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типы данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/types_of_data.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большинство процессов и объектов, с которыми научились работать ML/DL модели, можно отнести к одному из перечисленных типов. Наша задача будет состоять в том, как данные из вашей предметной области свести к одному из них и представить в виде набора чисел. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с различными типами данных используют разные типы моделей:\n",
    "\n",
    "**Табличный**  — классические ML модели либо полносвязанные NN;\n",
    "\n",
    " **Последовательности** — рекуррентные сети + свёртка;\n",
    " \n",
    " **Изображения/видео** — 2,3 .. ND свёрточные сети.\n",
    " \n",
    "\n",
    "\n",
    "В разных типах данных количество связей между элементами разное и зависит только от типа этих данных. Важно НЕ количество элементов, а СВЯЗИ между ними.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/connectivity_of_data_types.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Данные мы можем условно делить по степени связанности. Это степень взаимного влияния между соседними элементами. \n",
    "Например, в таблице, в которой есть определенные параметры (например: рост, вес) данные между собой связаны, но порядок столбцов значения не имеет.\n",
    "Если мы поменяем столбцы местами, то не потеряем никакой важной информации. \n",
    "\n",
    "Такие данные можно представить в виде вектора, но порядок элементов в нем не важен.\n",
    "\n",
    "При работе с изображениями нам становится важно, как связаны между собой пиксели и по горизонтали, и по вертикали. \n",
    "При добавлении цвета появляются 3 RGB канала, и значения в каждом канале также связаны между собой. Эту связь нельзя терять, если мы хотим корректно извлечь максимум информации из данных. Соответственно, если дано цветное изображение, то у нас уже есть три измерения, в которых мы должны эти связи учитывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/datasets_for_different_tasks.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dataset map](https://coggle.it/diagram/Xmcn5GVe0zfnM4aS/t/dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/imagenet_dataset.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На датасете [ImageNet](http://image-net.org/download) предобученны все модели для классификации, которые присутствуют в “зоопарке моделей” Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/dataset_coco.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Coco dataset](http://cocodataset.org) используется для обучения моделей, решающих задачи классификации, сегментации и детектирования. В нём намного меньше категорий объектов, чем в ImageNet, но присутствует разметка по bounding box и маскам.\n",
    "\n",
    "Cложные бытовые сцены предметов в их естественном контексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Набор данных MosMedData: COVID19_1110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/dataset_mosmeddata.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предыдущие два датасета были исследовательские. На них соревнуются, проверяют гипотезы,  качество работы новых моделей.\n",
    "Для них много примеров и хорошие описания.\n",
    "\n",
    "[Пример реального датасета](https://mosmed.ai/)\n",
    "\n",
    "Скорее всего разобраться с тем, как использовать эти данные, будет сложнее.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/dataset_mnist.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "База данных рукописных цифр [MNIST](http://yann.lecun.com/exdb/mnist/\n",
    ")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/dataset_cifar10.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) $-$ маленькие изображения в низком разрешении, разделённые на 10 классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10/100 и MNIST — это **учебные датасеты.**\n",
    "\n",
    "В них изображения размечены по нескольким классам. Чтобы загрузка и обучение проходили быстро, картинки имеют небольшое разрешение, а количество классов невелико.\n",
    "В остальном всё как у взрослых.\n",
    "\n",
    "И авторы статей, посвящённых разработке новых нейросетевых моделей, достаточно часто приводят результаты работы своих моделей на этих датасетах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Оценка результата "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/how_compute_model_accuracy.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая часть работы — это оценка точности. Нам нужно определиться с тем, как оценивать результат.\n",
    "Очень часто приходится слышать от заказчика вопрос со слайда.\n",
    "Чаще всего ответ “99%” их более чем устраивает. \n",
    "\n",
    "\n",
    "В большинстве случаев такой ответ воспринимается неверно, что в дальнейшем приводит к проблемам. Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/accuracy_problem_example.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/important_accuracy_factors.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Скорость перемещения  машины зависит от дороги: на дорогах бывают пробки, ограничивающие знаки, наконец, дороги бывают очень разного качества.\n",
    "\n",
    "Всё это влияет на скорость перемещения и порой радикально.\n",
    "\n",
    "Так же и точность наших моделей в первую очередь зависит от данных, на которых мы будем их оценивать. Модель, которая отлично работает на одном датасете, может намного хуже работать на другом или не работать вовсе. В том числе в силу технических причин (пример про Resnet и CIFAR10).\n",
    "\n",
    "2. Машина может быть подвергнута тюнингу. Например, внедорожный тюнинг поможет преодолеть участок бездорожья, на котором неподготовленный автомобиль застрянет. Но при этом скорость на дорогах общего пользования может снизиться. Так же и модель, как правило, имеет ряд параметров (гиперпараметров), от которых зависит её работа. Они могут подбираться в зависимости от задачи (ошибки первого и второго рода) и качества данных.\n",
    "\n",
    "3. Само понятие скорости допускает вариации: речь идет о средней или максимальной скорости? Аналогично и для оценки моделей существует несколько метрик, применение которых, опять же, зависит от целей заказчика и особенностей данных.\n",
    "\n",
    "Поэтому честный ответ на вопрос о точности должен звучать так: «На датасете X модель Y по метрике Z показала точность 99%».\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/simple_way_to_compute_accuracy.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ подсчёта точности модели — это деление количества правильно распознанных элементов на общее их количество.\n",
    "\n",
    "**Какие есть недостатки у такого способа?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/problem_of_simple_way_to_compute_accuracy.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy нельзя использовать, если данные не сбалансированы. То есть в одном из классов больше представителей, чем в другом.\n",
    "\n",
    "Также она не подойдет для задач сегментации и детектирования, если требуется не только определить наличие объекта на изображении, но и найти место, где он находится, то весьма желательно учитывать разницу в координатах.\n",
    "\n",
    "Сегодня же мы будем решать задачу классификации на учебных датасетах, где данные либо сбалансированы, либо дисбалансом можно пренебречь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Демонстрация работы с данными "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Табличные данные "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обзор инструментов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим примеры решения задач классификации на различных типах данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать библиотеки:\n",
    "\n",
    "* [numpy](https://numpy.org/);\n",
    "* [skilearn](https://scikit-learn.org/stable/) — ML алгоритмы, 'toy' — датасеты;\n",
    "* [pandas](https://pandas.pydata.org/) — Удобная работа с табличными данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [**Pytorch**](https://pytorch.org/) — Основной фреймворк машинного обучения, который будет использоваться на протяжении всего курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Познакомимся с инструментом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Tensorboard](https://www.tensorflow.org/tensorboard) — визуализация данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Загрузка данных  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример работы с табличными данными\n",
    "\n",
    "Пример работы с табличными данными. \n",
    "Классифицируем вина из [датасета](https://archive.ics.uci.edu/ml/machine-learning-databases/wine/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача будет состоять в том, чтобы по химическому составу определить производителя вина.\n",
    "\n",
    "Количество экземпляров, полученных на тест от каждого из трех производителей, не одинаково."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производитель №1 (class_1) 59 бутылок  \n",
    "Производитель №2 (class_2) 71 бутылка  \n",
    "Производитель №3 (class_3) 48 бутылок  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот датасет можно загрузить, используя модуль sklearn.datasets библиотеки [sklearn](https://scikit-learn.org/stable/), чем мы и воспользуемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.datasets import load_wine\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "\n",
    "# Download dataset\n",
    "dataset = load_wine(return_X_y = True) # also we can get data in Bunch (dictionary) or pandas DataFrame\n",
    "\n",
    "features = dataset[0] # array 178x13 (178 bottles each with 13 features)\n",
    "class_labels = dataset[1] # array of 178 elements, each element is a number the class: 0,1 2  \n",
    "print(\"features shape:\",features.shape)\n",
    "print(\"class_labels shape:\",class_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация данных  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Если параметр \n",
    "    \n",
    "    return_X_y == False\n",
    "\n",
    "то данные вернуться не в виде массива, а в объекте [Bunch](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch).\n",
    "\n",
    "Обращаться к нему можно, как к обычному словарю в Python. Кроме того, у него есть свойство, соответствующее каждому полю данных.\n",
    "\n",
    "Чтобы отобразить данные в виде таблицы, преобразуем их в формат pandas.DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library to work with tabular data: https://pandas.pydata.org/\n",
    "import pandas as pd \n",
    "\n",
    "dataset_bunch = load_wine(return_X_y = False)\n",
    "print(dataset_bunch.keys())\n",
    "\n",
    "df = pd.DataFrame(dataset_bunch.data, columns=dataset_bunch.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая строка в таблице может быть интерпретирована как вектор из 13 элементов. Можно интерпретировать такой вектор как координаты точки в 13-мерном пространстве. Именно с таким представлением работает большинство алгоритмов машинного обучения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализировать 13-мерное пространство не получится :(. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но можно визуализировать проекцию данных в трёхмерное пространство. Для этого воспользуемся инструментом projector из [tensorboard](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск Tensorboard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Локальный запуск\n",
    "Для локального запуска tensorboard:\n",
    "\n",
    "* Нужно установить [пакет](https://pypi.org/project/tensorboard/) ; \n",
    "\n",
    "* Затем выполнить команду:\n",
    "\n",
    "    `tensorboard --logdir <path> --port 6006`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "где <path> — путь к каталогу, в котором будут храниться файлы логов.\n",
    " В результате выполнения этой команды будет запущен локальный web-сервер на порту 6006.\n",
    "\n",
    "\n",
    "* Затем в браузере открыть адрес: localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск в Colab\n",
    "\n",
    "До некоторого времени запуск Tensorboard в Colab был сопряжен с некоторыми сложностями ввиду того, что виртуальная машина (docker-container), которую предоставляет нам Colab, не имеет постоянного IP адреса. И в интернете много устаревших инструкций по поводу того, как обойти эту проблему. \n",
    "Но в настоящее время этот инструмент встроили в Colab и для его запуска прямо в ячейке достаточно двух 'магических строк':\n",
    "\n",
    "\n",
    "```\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir {logs_base_dir}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но так как Tensorboard работает только с логами на диске, то периодически приходится их очищать, для чего рекомендуется использовать метод \n",
    "\n",
    "`reinit_tensorboard`\n",
    "\n",
    "из ячейки ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, если существует ячейка, в которой уже выполняется код (например, идёт процесс обучения), то другие ячейки блокируются. В том числе мы не сможем воспользоваться Tensorboard, если он запущен в другой ячейке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому, если требуется мониторинг блока кода, который исполняется долгое время, то можно создать Tensorboard в ячейке с этим блоком кода, добавив в конце вызов: `reinit_tensorboard(clear_log = False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# launching Tensorboard in Colab\n",
    "def reinit_tensorboard(clear_log = True):\n",
    "  # Log files are read from this directory: \n",
    "  logs_base_dir = \"runs\"\n",
    "  if clear_log:\n",
    "    # clear logs \n",
    "    #!rm -rfv {logs_base_dir}/*\n",
    "    shutil.rmtree(logs_base_dir, ignore_errors = True)\n",
    "    os.makedirs(logs_base_dir, exist_ok=True)\n",
    "  # Colab magic\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После загрузки Tensorboard измените значение опции \"Color by\" на \"label 3 colors\", чтобы объекты, принадлежащие к разным классам, отображались разными цветами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "import numpy\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "reinit_tensorboard()\n",
    "\n",
    "writer = SummaryWriter(comment = \"wine\")\n",
    "np_f = numpy.array(features)\n",
    "writer.add_embedding(mat=np_f, metadata=class_labels )\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что объекты классов 1 и 2 линейно неразделимы в 2-х измерениях. По этой причине так популярен переход к пространствам большей размерности. \n",
    "\n",
    "Обратите внимание, что данные центрированны около нуля — это результат нормализации, которой они подверглись в Tensorboard.\n",
    "\n",
    "Нам тоже потребуется нормализовывать данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация данных <a class=\"anchor\" id=\"demonstration_1_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, какие масштабы имеют значения разных признаков. \n",
    "\n",
    "\n",
    "Для начала отобразим два признака: malic_acid и alcalinity_of_ash. Их значения отличаются примерно на порядок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(10, 5), dpi=80)\n",
    "\n",
    "plt.title('Two features in differents scales')\n",
    "sns.histplot(features[:,1],color='#3bb54a', edgecolor='white',label='malic_acid',log_scale=True)\n",
    "sns.histplot(features[:,3],color='#27a9e1', edgecolor='white',label='alcalinity_of_ash',log_scale=True)\n",
    "plt.xlabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим ещё один признак, значения которого отличается от второго на 2 порядка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10, 5), dpi=80)\n",
    "\n",
    "plt.title('Three features in differents scales')\n",
    "sns.histplot(features[:,1],color='#3bb54a', edgecolor='white',label='malic_acid',log_scale=True)\n",
    "sns.histplot(features[:,3],color='#27a9e1', edgecolor='white',label='alcalinity_of_ash',log_scale=True)\n",
    "sns.histplot(features[:,12],color='#ffab40', edgecolor='white',label='proline', log_scale=True)\n",
    "plt.xlabel('Values, log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения в разных масштабах — модели будет сложно сравнивать их между собой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Max  нормализация\n",
    "\n",
    "Теперь нормализуем данные. Простейший способ — это Mini-Max нормализация. Вычтем минимальное значение и поделим на среднее.\n",
    "\n",
    "$$\\displaystyle X'  = \\frac{X-X_{min}}{X_{max} - X_{min}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# cast data to torch.Tensor \n",
    "tensor_f = torch.tensor(features)\n",
    "\n",
    "min_values, _  = tensor_f.min(dim=0,keepdim=True)  # shape = (1,13)\n",
    "max_values, _  = tensor_f.max(dim=0,keepdim=True)  # shape = (1,13)\n",
    "\n",
    "# Substract min\n",
    "min_max_centered = tensor_f - min_values # shape = (178,13)\n",
    "\n",
    "# Divide by mean\n",
    "min_max_normalized =  min_max_centered / (max_values - min_values) # shape = (1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "# Min_Max_Centered hist\n",
    "sns.histplot(min_max_centered[:,1],color='#3bb54a', edgecolor='white',label='malic_acid',ax=axes[0])\n",
    "sns.histplot(min_max_centered[:,3],color='#27a9e1', edgecolor='white',label='alcalinity_of_ash',ax=axes[0])\n",
    "# Min_Max_Normalized hist\n",
    "sns.histplot(min_max_normalized[:,1],color='#3bb54a', edgecolor='white',label='malic_acid',ax=axes[1])\n",
    "sns.histplot(min_max_normalized[:,3],color='#27a9e1', edgecolor='white',label='alcalinity_of_ash',ax=axes[1])\n",
    "\n",
    "axes[0].set(xlabel='Values')\n",
    "axes[0].set(title='Min_Max_Centered')\n",
    "axes[1].set(xlabel='Values')\n",
    "axes[1].set(title='Min_Max_Normalized')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что после центрирования значения сместились в сторону нуля, а после нормализации они сильно перекрываются, то есть данные перестали заметно отличаться по масштабу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стандартизация / Z-нормализация\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/z_normalization.png\" width=\"700\" >\n",
    "\n",
    "При Mini-Max нормализации остается проблема выбросов (см. 1-ую гистограмму). Если в данных есть даже единичные выбросы, то они займут значительную часть диапазона.\n",
    "\n",
    "Если делить не на среднее значение, а на стандартное отклонение, то эта проблема решается. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substract min\n",
    "centered = tensor_f - tensor_f.mean(dim=0)\n",
    "# Divide by standard deviation\n",
    "normalized = centered / tensor_f.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "# Z-centered hist\n",
    "sns.histplot(centered[:,1],color='#3bb54a', edgecolor='white',label='malic_acid',ax=axes[0])\n",
    "sns.histplot(centered[:,3],color='#27a9e1', edgecolor='white',label='alcalinity_of_ash',ax=axes[0])\n",
    "# Z-normalized hist\n",
    "sns.histplot(normalized[:,1],color='#3bb54a', edgecolor='white',label='malic_acid',ax=axes[1])\n",
    "sns.histplot(normalized[:,3],color='#27a9e1', edgecolor='white',label='alcalinity_of_ash',ax=axes[1])\n",
    "\n",
    "axes[0].set(xlabel='Values')\n",
    "axes[0].set(title='Z-Centered')\n",
    "axes[1].set(xlabel='Values')\n",
    "axes[1].set(title='Z-Normalized')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим значения признака `malic_acid` до и после нормализации MinMax и стандартизации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10, 5), dpi=80)\n",
    "\n",
    "plt.title('Original, MinMax, Z-normalize')\n",
    "sns.histplot(features[:,1],color='#3bb54a', edgecolor='white',label='Original')\n",
    "sns.histplot(min_max_normalized[:,1],color='#27a9e1', edgecolor='white',label='Min_Max_normalize')\n",
    "sns.histplot(normalized[:,1],color='#ffab40', edgecolor='white',label='Z-normalize')\n",
    "plt.xlabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Наглядное преимущество стандартизации перед Max-Min нормализацией.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Базовая документация](https://scikit-learn.org/stable/modules/svm.html)\n",
    "\n",
    "Используем простую модель, [пример](https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python) использования SVM классификатора\n",
    "\n",
    "Её устройство будет рассмотрено на следующих лекциях, сейчас будем считать модель чёрным ящиком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Разбиение данных на обучающую и тестовую выборки \n",
    "\n",
    "Самым простым способом научиться чему-либо является \"запомнить всё\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним \"Таблицу умножения\". Если мы хотим проверить умение умножать, то проверки примерами из таблицы умножения будет недостаточно, ведь она может быть полностью запомнена. Нужно давать новые примеры, которых не было в таблице умножения (обучающей выборке)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если модель \"запомнит всё\", то она будет идеально работать на данных, которые мы ей показали, но может вообще не работать на любых других данных.\n",
    "\n",
    "С практической точки зрения важно, как модель будет вести себя именно на незнакомых для неё данных. То есть насколько хорошо она научилась обобщать закономерности, которые в данных присутствовали (если они вообще существуют)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки этой способности набор данных разделяют на две, а иногда даже на три части:\n",
    "\n",
    "* train — Данные, на которых модель учится;\n",
    "* validation/test — Данные, на которых идет проверка.\n",
    "\n",
    "В `sklearn.model_selection` есть модель для разделения массива данных на тренировочную и тестовую часть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, class_labels, test_size=0.2) # 80% training and 20% test\n",
    "\n",
    "print(\"X_train shape\",X_train.shape)\n",
    "print(\"X_test shape\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А мы в дальнейшем будем пользоваться аналогичными инструментами библиотеки PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Обучим модель и посчитаем точность (Accuracy) \n",
    "\n",
    "Теперь можно запустить процесс обучения и посчитать точность работы модели на данном датасете.\n",
    "\n",
    "То есть понять, насколько хорошо по химическому составу модель определит винодела, поставившего это вино.\n",
    "\n",
    "accuracy = p/N\n",
    "\n",
    "где p — количество верных ответов, а N — общее число примеров, использовавшихся в тесте. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# create model\n",
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "# fit model at train data\n",
    "lin_clf.fit(X_train, Y_train)\n",
    "\n",
    "# get predict\n",
    "Y_pred = lin_clf.predict(X_test)\n",
    "\n",
    "print(\"Y_pred shape:\",Y_pred.shape)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "print(\"Predicted classes: \", Y_pred)\n",
    "print(\"Real classes:      \", Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аудиоданные "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным образом можно работать с различными типами данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Загрузка данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "В Pytorch есть три библиотеки для работы с разными типами данных:\n",
    "\n",
    "[torchvision](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "[torchaudio](https://pytorch.org/audio/stable/datasets.html)\n",
    "\n",
    "[torchtext](https://pytorch.org/text/stable/index.html)\n",
    "\n",
    "\n",
    "Для загрузки данных  используются классы [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) и [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). \n",
    "\n",
    "Они предоставляют единый интерфейс для доступа к данным различных типов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример загрузки аудио средствами Pytorch**\n",
    "\n",
    "Рассмотрим пример того, как можно загрузить аудиоданные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим библиотеку torch.audio (она не входит в список пакетов, доступных в colab по умолчанию)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech Commands:  [A Dataset for Limited-Vocabulary SpeechRecognition](https://arxiv.org/pdf/1804.03209.pdf)\n",
    "\n",
    "Он представляет из себя набор звуковых файлов в формате .wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в которых записан звук голоса разных людей, произносящих одно из 35 слов на английском языке. Часть слов таких как: \n",
    "\n",
    "- left;\n",
    "- right;\n",
    "- on;\n",
    "- off;\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также слова, не являющиеся командами:\n",
    "\n",
    "- cat;\n",
    "- bird;\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В сравнении с датасетами из torchvision, [этот датасет](https://pytorch.org/audio/stable/datasets.html#speechcommands) имеет более ограниченный функционал. В частности, в нём нет трансформаций и данные не выравнены. Благодаря этому появляется возможность продемонстрировать необходимость в операциях, которые в дальнейшем будут работать \"из  коробки\".*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "speech_commands_dataset = torchaudio.datasets.SPEECHCOMMANDS(\"sample_data\",download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После загрузки данные будут распакованы в папку sample_data.\n",
    "Откройте её, используя меню в правой панели Colab. Посмотрите, в каком виде они хранятся на диске.\n",
    "\n",
    "\n",
    "Объект speech_commands_dataset — это экземпляр класса, который является наследником  [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html). Это означает, что в нём реализованы методы: \n",
    "* __getitem__ \n",
    "* __len__\n",
    "\n",
    "Благодаря этому мы можем узнать количество элементов или получить произвольный элемент данных, обращаясь к объекту класса [Dataset](https://pytorch.org/docs/stable/data.html)  так же, как к обычному списку в python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num of elements {} \".format(len(speech_commands_dataset)))\n",
    "print(\"First element\",speech_commands_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что представляет из себя элемент аудио-данных?**  \n",
    "Обратимся к [документации](https://pytorch.org/audio/stable/datasets.html#speechcommands)\n",
    "\n",
    "... returns:\n",
    "\n",
    "    (waveform, sample_rate, label, speaker_id, utterance_number)\n",
    "\n",
    "utterance_number — номер повтора. Больше нуля, если один и тот же человек проговаривает одну и ту же фразу несколько раз. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate, label, speaker_id, utterance_number = speech_commands_dataset[1]\n",
    "print(\"Waveform: {}\\nSample rate: {}\\nLabel: {} \\nSpeaker_id: {} \\nutterance_number: {}\".format(waveform.shape, sample_rate, label,speaker_id,utterance_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Размеры тензора waveform:\n",
    "    \n",
    "    [1, 16000] \n",
    "\n",
    "1 — количество каналов, 16000 — количество измерений в секунду.\n",
    "\n",
    "Если частота дискретизации(sample_rate) равна 16000, то этот фрагмент занимает ровно 1 секунду .\n",
    "\n",
    "**Визуализируем их:**  \n",
    "x — время  \n",
    "y — давление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f'type waveform: {type(waveform)}')\n",
    "plt.figure(figsize=(10, 5), dpi=80)\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.plot(waveform.t().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Озвучим:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(waveform.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обзор контейнеров "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итерация по датасету**\n",
    "\n",
    "Запустим простую проверку: убедимся, что все записи одинаковой длины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему это важно**\n",
    "\n",
    "Мы будем работать с массивами 3 типов:\n",
    "\n",
    "* list — стандартный тип в Python\n",
    "* numpy — массив\n",
    "* torch.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим, чем они отличаются:\n",
    "\n",
    "### List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_list = ['a',15,123.8,[99,\"I love you\"],[True,True,False]]\n",
    "\n",
    "print(python_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В списке могут быть данные различных типов, в том числе подтипов произвольной длины.\n",
    "\n",
    "### Numpy\n",
    "\n",
    "* Массив может содержать данные только одного типа;   \n",
    "* Размер данных во всех измерениям кроме 0-го должен совпадать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "numpy_arr = np.array([[1,2,3],[4,5,6]],dtype = float)\n",
    "print(numpy_arr)\n",
    "\n",
    "# This code will cause an error\n",
    "# invalid_numpy_arr = np.array([[1,2,3],[4,5]],dtype = float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря этому над numpy-массивами можно выполнять различные математические операции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([1,0,0])\n",
    "row_diff = numpy_arr - vector\n",
    "print(\"Substract row from array\",row_diff)\n",
    "\n",
    "scalar_product = numpy_arr.dot(vector)\n",
    "print(\"Scalar product\",scalar_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch.Tensor\n",
    "\n",
    "\n",
    "      'is a multi-dimensional matrix containing elements of a single data type.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С точки зрения ограничений и функционала [torch.Tensor](https://pytorch.org/docs/stable/tensors.html) эквивалентен numpy-массиву.\n",
    "Но дополнительно этот объект поддерживает две важных операции:\n",
    "\n",
    "* Перенос данных на видеокарту (`my_tensor.to('cuda:0')`)\n",
    "* Автоматический расчет градиентов  (`my_tensor.backward()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти возможности понадобятся нам в дальнейшем. Поэтому надо разобраться, как  работать с данными в этом формате. Тем более, что torch.Tensor легко преобразуется в numpy-массив и обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "my_tensor = torch.tensor(numpy_arr)\n",
    "print(\"torch.Tensor\",my_tensor,\"shape = \",my_tensor.shape)\n",
    "\n",
    "squared_numpy = my_tensor.pow(2).numpy()\n",
    "print(\"Numpy \",squared_numpy,\"shape = \",squared_numpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим,  что все записи имеют одинаковую длину: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_length = 16000\n",
    "for i, sample in enumerate(speech_commands_dataset):\n",
    "  waveform, sample_rate, label, speaker_id, utterance_number = sample\n",
    "  if def_length != waveform.shape[1]: # [1, 16000]\n",
    "    print(f\"Length of object #{i} not equal {def_length}\")\n",
    "    print(f\"Waveform: {waveform.shape}\\nSample rate: {sample_rate}\\nLabel: {label}\\\n",
    "    \\nSpeaker_id: {speaker_id} \\nutterance_number: {utterance_number}\")\n",
    "    break\n",
    "  if not i% 10000 and i > 0 :\n",
    "    print(f\"Processed {i} objects\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных <a class=\"anchor\" id=\"demonstration_2_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если элементы имеют различную длину, то мы не сможем их сравнивать. И даже технически поместить в один массив. \n",
    "\n",
    "\n",
    "Необходимо их выровнять. \n",
    "\n",
    "Так как многие записи начинаются и заканчиваются тишиной, то просто дополним их нулями.\n",
    "\n",
    "\n",
    "Для этого применим концепцию трансформаций (transform), которая широко применяется в Pytorch и встраивается во многие датасеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined transform\n",
    "class PadWaveform(torch.nn.Module):\n",
    "  def __init__(self, desired_size = 16000):\n",
    "    self.desired_size = desired_size\n",
    "    super().__init__()\n",
    "\n",
    "  # in nn.Module forward method called inside __call__ method\n",
    "\n",
    "  def forward(self, waveform):\n",
    "    if waveform.shape[1] < self.desired_size:\n",
    "      # Calculate pad size\n",
    "      diff = self.desired_size - waveform.shape[1]\n",
    "      pad_left = diff // 2\n",
    "      pad_right = diff - pad_left\n",
    "      # Add zero pad to tensor\n",
    "      # https://pytorch.org/docs/stable/nn.functional.html#pad\n",
    "      return torch.nn.functional.pad(waveform,[pad_left, pad_right])\n",
    "    else:\n",
    "      # If size equal to desired size, do nothing\n",
    "      return waveform\n",
    "\n",
    "# Create custom dataset with transformations support \n",
    "# it's common practice in pytorch\n",
    "\n",
    "class customSpeechCommandsDataset(torchaudio.datasets.SPEECHCOMMANDS):\n",
    "  def __init__(self,transform,root = \"sample_data\"):\n",
    "    self.transform = transform\n",
    "    super().__init__(root)\n",
    "\n",
    "  # Override \n",
    "  def __getitem__(self,n):\n",
    "    # Get item\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\n",
    "    # Apply transform\n",
    "    transformed_waveform = self.transform(waveform)\n",
    "    # Return ransformed item\n",
    "    return (transformed_waveform, sample_rate, label, speaker_id, utterance_number)\n",
    "\n",
    "\n",
    "speech_commands_dataset = customSpeechCommandsDataset(transform = torch.nn.Sequential(PadWaveform(16000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно добавлять дополнительные трансформации. Например, уменьшить частоту дискретизации (sample_rate) чтобы данные занимали меньше места.\n",
    "\n",
    "Для этого в модуле\n",
    "[torchaudio.transforms](https://pytorch.org/audio/stable/transforms.html#resample)  уже есть готовая трансформация:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.transforms import Resample\n",
    "\n",
    "transform = torch.nn.Sequential(\n",
    "    Resample(16000,8000),\n",
    "    PadWaveform(8000))\n",
    "    \n",
    "speech_commands_dataset = customSpeechCommandsDataset(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пакетная обработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Визуализируем данные.**\n",
    "\n",
    "Датасет в архиве занимает > 2Gb и это далеко не предел. Поэтому работать с ним будем по частям. \n",
    "\n",
    "Для этой задачи в pytorch используется класс Dataloader. Одной из его функций является пакетная (batch) загрузка данных.\n",
    "\n",
    "Особенно она будет полезна при обучении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# launching Tensorboard in Colab\n",
    "def reinit_tensorboard(clear_log = True):\n",
    "  # Log files are read from this directory: \n",
    "  logs_base_dir = \"runs\"\n",
    "  if clear_log:\n",
    "    # clear logs \n",
    "    #!rm -rfv {logs_base_dir}/*\n",
    "    shutil.rmtree(logs_base_dir, ignore_errors = True)\n",
    "    os.makedirs(logs_base_dir, exist_ok=True)\n",
    "  # Colab magic\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Clear logs and launch Tensorboard\n",
    "reinit_tensorboard(False)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(speech_commands_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "writer = SummaryWriter(comment = \"commands\")\n",
    "\n",
    "for i, batch in enumerate(data_loader):\n",
    "  waveforms, sample_rates, labels, speaker_ids, utterance_numbers = batch\n",
    "  print(waveforms.shape)\n",
    "  print(labels)\n",
    "  # data transformed to tensors\n",
    "  # remove the 1st dimension remaining from the channel\n",
    "  writer.add_embedding(torch.squeeze(waveforms), metadata=labels )\n",
    "  break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Надо ли нормализовать эти данные?**\n",
    "\n",
    "Загрузим значения 2-х произвольных признаков в Tensorboard и проверим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment = \"commands\")\n",
    "for i, batch in enumerate(data_loader):\n",
    "  waveforms, sample_rates, labels, speaker_ids, utterance_numbers = batch\n",
    "  writer.add_histogram(\"waves\" ,torch.squeeze(waveforms)[:,100])\n",
    "  writer.add_histogram(\"waves\" ,torch.squeeze(waveforms)[:,200])\n",
    "  break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из гистограммы, данные уже центрированны вокруг нуля и имеют один масштаб. Отчасти это связанно с тем, что они имеют одну и ту же природу, отчасти с форматом хранения звука. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение \n",
    "\n",
    "Для обучения потребуются метки. Попутно избавимся от лишнего. Создадим очередную трансформацию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customSpeechCommandsDatasetFinal(customSpeechCommandsDataset):\n",
    "  def __init__(self,transform = torch.nn.Sequential(),root = \"sample_data\"):\n",
    "    super().__init__(transform,root)\n",
    "    self.labels = self.get_labels()\n",
    "\n",
    "  def get_labels(self):\n",
    "    # Collect all unique labels\n",
    "    labels = set()\n",
    "    for i in range(len(self)):\n",
    "      item = super(customSpeechCommandsDataset,self).__getitem__(i)\n",
    "      labels.add(item[2])\n",
    "     # Sort labels and return it as a list\n",
    "    return sorted(list(labels)) \n",
    "\n",
    "  # Override \n",
    "  def __getitem__(self,n):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\n",
    "    # Return only waveform and class_num\n",
    "    return (waveform[0],self.labels.index(label))\n",
    "\n",
    "transform = torch.nn.Sequential(\n",
    "    Resample(16000,8000),\n",
    "    PadWaveform(8000))\n",
    "\n",
    "speech_commands_dataset = customSpeechCommandsDatasetFinal(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes\",speech_commands_dataset.labels)\n",
    "print(\"Classes num\",len(speech_commands_dataset.labels))\n",
    "\n",
    "wave, cls_num = speech_commands_dataset[0]\n",
    "print(f'wave.shape: {wave.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и валидационную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(speech_commands_dataset )\n",
    "print(\"Total length\",total_len)\n",
    "\n",
    "# To speedup  use only 10% of data\n",
    "use_only = int(total_len*0.1)\n",
    "to_skip,to_use = torch.utils.data.random_split(speech_commands_dataset, [total_len - use_only, use_only])\n",
    "\n",
    "# Split to train and validation set\n",
    "val_len = int(len(to_use)*0.1)\n",
    "train_set, val_set = torch.utils.data.random_split(to_use, [len(to_use) - val_len, val_len])\n",
    "print(\"Train dataset length\",len(train_set))\n",
    "print(\"Validation dataset length\",len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# Another simple black-box model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "reinit_tensorboard(False)\n",
    "\n",
    "def validate(model):\n",
    "  data_loader = torch.utils.data.DataLoader(val_set, batch_size=256, shuffle=False)\n",
    "  accuracy = []\n",
    "  for batch in data_loader:\n",
    "    waveforms, class_nums  = batch \n",
    "    y_pred = model.predict(waveforms)\n",
    "    accuracy.append(metrics.accuracy_score(class_nums, y_pred))\n",
    "  print(\"Accuracy:\",np.array(accuracy).mean())\n",
    "  return np.array(accuracy).mean()\n",
    "\n",
    "model = SGDClassifier(loss='log')  \n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=1024, shuffle=True)\n",
    "\n",
    "for epoch in range(5):\n",
    "  for batch in data_loader:\n",
    "    waveforms, class_nums  = batch\n",
    "    model.partial_fit(waveforms, class_nums,range(35))\n",
    "  accuracy = validate(model)\n",
    "  writer.add_scalar(\"Accuracy\",accuracy,epoch)\n",
    "  writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Откройте вкладку \"SCALARS\".\n",
    "\n",
    "\n",
    "Модель не обучается. Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обзор видов связности данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Причины этого в количестве связей между элементами данных.\n",
    "Мы имеем дело с временным рядом. \n",
    "\n",
    "Аудиозапись — это набор измерений (давления на мембране микрофона), произведённых последовательно. \n",
    "\n",
    "То есть в каждый момент времени сигнал связан с предыдущим. \n",
    "Если мы перемешаем их, получится какофония. \n",
    "\n",
    "Так же, как если перемешать слова в предложении или буквы в слове."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/audio_data_type.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таких случаях мы тоже можем представить данные как вектор, но модель, которой мы подадим его на вход, должна учитывать связи между соседними элементами этого вектора.\n",
    "\n",
    "При работе с видео добавляется дополнительное «измерение» — время. \n",
    "\n",
    "Поскольку данные подаются в модель в виде многомерного массива чисел (тензора),  то при работе с видео меняется только размерность этого массива:  в нём появляется дополнительное измерение.\n",
    "\n",
    "С точки зрения PyTorch данные — это некоторый массив, у него может быть 1-2-3 измерения, но нам важно понимать, какие между ними существуют связи. От этого зависит, какой моделью мы будем их обрабатывать.\n",
    "\n",
    "Для работы с этими данными нужна модель, которая эти связи будет учитывать, например рекуррентная  или свёрточная сеть.\n",
    "С её помощью можно получить точность >85%:\n",
    "\n",
    "[Speech Command Recognition with torchaudio](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/d87597d0062580c9ec699193e951e3f4/speech_command_recognition_with_torchaudio.ipynb#scrollTo=tl9K6deU4S10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Работа с изображениями "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет CIFAR-10. Он состоит из 60000 цветных изображений размером 32x32. На картинках объекты 10 классов.\n",
    "\n",
    "Для его загрузки используем билиотеку torchvision.\n",
    "\n",
    "В отличие от torchaudio, пакет torchvision входит в число предустановленных в colab.\n",
    "\n",
    "Датасеты из torcvision изначально поддерживают механизм transforms \n",
    "и разбивку на тестовое и проверочные подмножества. Нам не придется добавлять их вручную.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_set = datasets.CIFAR10(\"content\", train = True,  download = True)\n",
    "val_set = datasets.CIFAR10(\"content\", train = False, download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем несколько картинок вместе с метками. Tensorboard имеет метод для вывода картинок:\n",
    "[torchvision.utils.make_grid](https://pytorch.org/vision/stable/utils.html)\n",
    "\n",
    "Однако он [не поддерживает метки](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjcxcStpNDtAhWllYsKHa7XDLoQFjAAegQIBBAC&url=https%3A%2F%2Fdiscuss.pytorch.org%2Ft%2Fadd-label-captions-to-make-grid%2F42863&usg=AOvVaw19bkv0_Q8VQxD7WBZ3pFR_).\n",
    "\n",
    "Поэтому воспользуемся matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# load labels names for visualization\n",
    "with open(\"content/cifar-10-batches-py/batches.meta\",'rb') as infile:\n",
    "  cifar_meta = pickle.load(infile)\n",
    "labels_name = cifar_meta['label_names']\n",
    "\n",
    "for j in range(10):\n",
    "  img, label = train_set[j]\n",
    "  plt.subplot(1, 10 ,j+1)\n",
    "  plt.imshow(img)\n",
    "  plt.axis('off')  \n",
    "  plt.title(labels_name[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, в каком виде хранятся картинки в памяти:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оказывается, в формате [PIL](https://pillow.readthedocs.io/en/stable/reference/Image.html).\n",
    "\n",
    "Чтобы обучать модель, нам придётся преобразовать их в тензоры. \n",
    "Используем для этого transforms и Dataloder.\n",
    "\n",
    "Выведем размеры получившихся тензоров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "val_set.transform = transforms.Compose([ transforms.ToTensor() ]) # PIL Image to Pytorch tensor\n",
    "val_loader = DataLoader(val_set, batch_size=8, shuffle=False)\n",
    "\n",
    "for batch in val_loader:\n",
    "  imgs, labels = batch\n",
    "  print(len(batch))\n",
    "  print(\"Images: \",imgs.shape)\n",
    "  print(\"Labels: \",labels.shape)\n",
    "  print(labels)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разберемся с размерностями:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На каждой итерации dataloader возвращает кортеж из двух элементов.\n",
    "* Первый элемент — это изображения;\n",
    "* Второй — метки классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество элементов в каждом равно batch_size, в данном примере — 8.\n",
    "\n",
    "Изображение:  \n",
    "3 - C, каналы (В отличие от PIL и OpenCV они идут сначала);  \n",
    "32 - H, высота;  \n",
    "32 - W, ширина.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки:  \n",
    "числа от 0 до 9 по количеству классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим модель-заглушку \n",
    "\n",
    "Она не будет ничего предсказывать, только возвращать случайный номер класса.\n",
    "\n",
    "В методе fit данные просто запоминаются. Этот фрагмент кода можно будет использовать при выполнении практического задания.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeModel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.train_data = None\n",
    "    self.train_labels = None\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    # Simple store all data\n",
    "    self.train_data = torch.vstack((self.train_data,x)) if self.train_data != None else x\n",
    "    self.train_labels = torch.hstack((self.train_labels,y)) if self.train_labels != None else y\n",
    "   \n",
    "  def forward(self,x):\n",
    "    # x is a batch, not a single sample!\n",
    "    # Return random number instead of predictions\n",
    "    class_count = torch.unique(self.train_labels).shape[0]\n",
    "    # https://pytorch.org/docs/stable/generated/torch.randint.html#torch-randint\n",
    "    # size is shape of output tensor\n",
    "    label = torch.randint(low = 0, high = class_count-1, size = (x.shape[0],)) \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Запустим процесс \"обучения\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.transform = transforms.Compose([ transforms.ToTensor(),  ]) # PIL Image to Pytorch tensor\n",
    "train_loader = DataLoader(train_set, batch_size=1024, shuffle=True)\n",
    "\n",
    "model = FakeModel()\n",
    "\n",
    "for img_batch, labels_batch in train_loader:\n",
    "  model.fit(img_batch, labels_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим работу модели на нескольких изображениях из тестового набора данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, label_batch = next(iter(val_loader))\n",
    "predicted_labels = model(img_batch)\n",
    "\n",
    "for i, predicted_label in enumerate(predicted_labels):\n",
    "  img = img_batch[i].permute(1,2,0).numpy()*255  \n",
    "  plt.subplot(1, len(predicted_labels),i+1)\n",
    "  plt.imshow(img.astype(int))\n",
    "  plt.axis('off')\n",
    "  plt.title(labels_name[int(predicted_label)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем точность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = []\n",
    "for img_batch, labels_batch in val_loader:\n",
    "  predicted = model(img_batch)\n",
    "  batch_accuracy = accuracy_score(labels_batch, predicted)\n",
    "  accuracy.append(batch_accuracy)\n",
    "\n",
    "print(\"Accuracy\",torch.tensor(accuracy).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем повышать точность. В ходе выполнения практического задания заменим заглушку в методе predict реальным алгоритмом. Используем алгоритм:\n",
    "\n",
    "[K- Nearest Neighbor](https://colab.research.google.com/drive/1_5tGxAoxrWulPmwK2Ht9BHGsS-EpxVo0?usp=sharing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Алгоритм k-nearest neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу классификации на примере CIFAR 10.\n",
    "В ходе нескольких первых лекций мы будем решать её неоднократно, используя различные модели и постепенно улучшая результат.\n",
    "\n",
    "Цель сегодняшней работы — разобраться с загрузкой данных и общим ходом обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/knn_on_cifar10.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое, что мы должны сделать — это представить данные в виде чисел.\n",
    "Но изображения уже хранится в памяти компьютера в виде массива пикселей. \n",
    "\n",
    "При этом соседние пиксели на изображении связаны между собой. Для анализа этих связей требуется относительно сложная логика, \n",
    "попробуем сегодня проигнорировать эти связи и рассматривать изображение просто как массив чисел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/img_to_array.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод ближайшего соседа**  \n",
    "Для классификации используем [Метод ближайшего соседа](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm), или k-ближайших соседей (в части 3, 4).\n",
    "\n",
    "Метод k-ближайших соседей (англ. k-nearest neighbors algorithm, k-NN) — метрический алгоритм для автоматической классификации объектов или регрессии.\n",
    "\n",
    "В случае использования метода для классификации объект присваивается тому классу, который является наиболее распространённым среди k соседей данного элемента, классы которых уже известны.\n",
    "\n",
    "Алгоритм может быть применим к выборкам с большим количеством атрибутов (многомерным). Для этого перед применением нужно определить функцию расстояния; классический вариант такой функции — евклидова метрика. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/knn_idea.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остается вопрос: как определить метрику близости для изображений?\n",
    "\n",
    "Раз изображения в памяти компьютера — это просто массив чисел, давайте поэлементно вычтем одно из другого. \n",
    "А затем оценим суммарную разницу. Для одинаковых изображений она будет нулевой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/compare_train_and_test_imgs.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако может возникнуть ситуация, когда разность для одной пары пикселей -100, а для другой — +100. Когда мы их сложим, получится ноль, хотя изображения очень разные.\n",
    "Чтобы избавиться от такого нежелательного эффекта, будем использовать модули разностей.\n",
    "И таким образом получим метрику расстояния L1. Она же — манхэттенское расстояние, метрика прямоугольного города, метрика городского квартала, метрика такси, метрика Манхэттена, прямоугольная метрика, метрика прямого угла.\n",
    "Если вместо модуля использовать возведение в квадрат, а затем из суммы извлекать корень — получим Евклидову метрику.\n",
    "\n",
    "Теперь алгоритм будет выглядеть так: \n",
    "\n",
    "1. На этапе обучения запоминаем все изображения тренировочной выборки;  \n",
    "2. Для определения класса нового изображения:  \n",
    "\n",
    "a. Считаем расстояние L1 от него до всех заученных изображений;\n",
    "\n",
    "b. Находим минимальное;\n",
    "\n",
    "c. Возвращаем метку класса для этого изображения, расстояние до которого оказалось минимальным.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/img_license/metric_to_compare_train_and_test_imgs.png\" >"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
