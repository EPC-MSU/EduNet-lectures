{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Введение в машинное обучение</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ML и DL и AI в Computer Science "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Место глубокого обучения и нейронных сетей в ИИ**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/ai_ml_dl.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует множество разных определений, однако большая часть из них завязана на человеко-машинном взаимодействии, то есть это алгоритмы или методы, которые либо имитируют поведение людей, либо позволяют машине вести себя аналогично людям (то есть проявлять некоторое интеллектуальное-разумное поведение). Область ИИ не ограничивается исключительно машинным обучением, которое состоит из обучения на примерах. В ИИ входит целый ряд алгоритмов, например многоагентные системы (расшифровка) или базы знаний, в которых люди создают связи между разными понятиями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Искусственный интеллект (AI/ИИ)**  ≈ область ИТ/Computer science, связанная с моделированием интеллектуальных или творческих видов человеческой деятельности.\n",
    "\n",
    "**Машинное обучение(ML)** — подраздел ИИ, связанный с обучением на данных, он не единственный. Например, базы знаний или многоагентные системы также относят к разделам ИИ. \n",
    "\n",
    "**Глубокое обучение (Deep Learning, DL)** ≈ Многослойная нейросеть (MLP = multi layer perceptron).\n",
    "\n",
    "Однако сейчас мы рассмотрим более узкую область, связанную с DL. Модели, которые имеют несколько слоёв, называются глубокими или нейросетевыми. Хотя, если мы возьмем один слой такой модели (например линейный классификатор, он же перцептрон), он перестанет быть глубокой моделью, хотя по факту он и является простейшей нейросетью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Области применения DL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/ai_ml_dl_cv_nlp_sr.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последнее время именно такого рода модели показывают высокую эффективность в тех областях, в которых влияние человека казалось превалирующим. В частности, это человеко-компьютерное зрение (Computer Vision, CV), распознавание естественного языка (NLP, извлечение смысла, машинный перевод) и речи. В рамках курса мы рассмотрим, как эта область может применяться на практических задачах и моделях, их решающих. Также мы познакомимся с результатами самых современных исследований по теме. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Связь DL с наукой "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/ai_ml_dl_cv_nlp_sr_science.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо прикладных задач существуют еще и научные исследования, результаты которых до известной степени непредсказуемы. Нельзя исключать, что методы машинного обучения окажутся применимы к решению новых задач, в том числе в областях, где технологии DL до сих пор активно не использовались. Поддержка такого рода исследований и есть основная задача нашего курса. \n",
    "\n",
    "В первую очередь для нас важны задачи аспирантов, на которых и будет построены дальнейшие исследования. И именно на основе ваших задач будут сделаны выводы о моделях, рекомендованных под конкретно ваш случай."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## История развития DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Впервые идея искусственных нейронных сетей была высказана публично более 50 лет назад."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/history_of_dl.png\"  width=\"700\"> >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике нейронные сети начали применять для решения прикладных задач лишь в последние 10 лет.\n",
    "\n",
    "Рассмотрим, какие ключевые события привели к взрывному росту популярности нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/perceptron_xor.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1957 году Фрэнк Розенблатт предложил идею перцептрона как модели восприятия информации живыми существами. Эта идея была реализована в виде машины \"Марк-1\" в 1960 году.\n",
    "\n",
    "Для обучения перцептрона был предложен метод коррекции ошибки: объекты обучающей выборки пропускаются через перцептрон, и ответы сравниваются с истинными. В случае, если ответ отличается от истинного, веса связей изменяются на единицу в сторону, противоположную знаку ошибки (если модель ошибается, выдавая заниженное значение, то веса повышаются, и наоборот). Если же ответ соответствует истинному, то веса не обновляются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перцептрон преподносился как решение множества вычислительных проблем. Однако в 1969 году вышла книга \"Perceptrons: an introduction to computational geometry\" Марвина Минского и Сеймура Паперта. В книге было показано, что перцептрон в его исходном понимании не способен решить некоторые тривиальные задачи, например, задачу \"исключающего или\" (XOR), а значит, и более сложные задачи.\n",
    "\n",
    "Эта публикация на много лет охладила мировой интерес к искусственным нейронным сетям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/hubel_and_wiesel_experiment.png\" width=\"800\">\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://www.wandouip.com/t5i93843/\">Introduction to Convolutional</a></p> </em></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1959 году было совершено открытие в области биологии, которое стало фундаментом для построения нейросетей для компьютерного зрения. В работе были изучены реакции определенных участков кошачьего мозга на определенные простые визуальные стимулы. Как и большая часть открытий, это выяснилось абсолютно случайно.\n",
    "\n",
    "В мозг кошке был вживлен электрод для того, чтобы определить, на какой рисунок будет реакция. В то время слайды переключались последовательным движением, и выяснилось, что активация исследуемой области мозга была максимальна именно при этом движении. Как только менялся слайд и по экрану проходила граница затвора - простая прямая линия, реакция передавалась и записывалась.\n",
    "\n",
    "После ряда экспериментов выяснилось, что существуют клетки, реагирующие на простые формы (линии и углы) и движение в определенном направлении. Слои этих клеток образуют определенного рода иерархию с увеличивающимся рецептивным полем. Именно эта идея лежит в основе современных нейросетевых методов работы с изображениями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1975 - Когнитрон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/cognitron_fukushima.png\" width=\"400\" >\n",
    "\n",
    "\n",
    "<center><em>1975 - Cognitron: A self-organizing multilayered neural network K.Fukushima</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1975 г. по прообразу модели зрения животных, описанной Хьюбелом и Визелем,  была предложена искусственная нейронная сеть когнитрон. В 1980 г. идея получила развитие - была предложена новая архитектура неокогнитрон. В ее основу положены следующие принципы:\n",
    "- многослойность\n",
    "- иерархическая структура\n",
    "- локальная связь внутри слоя\n",
    "- самоорганизация (обучение без учителя)\n",
    "\n",
    "Архитектура этих моделей имеет много общего с современными искусственными нейронными сетями. Но на момент описания не было ни вычислительных ресурсов, ни эффективного алгоритма обучения таких моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/backpropagation_galushkin.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод обратного распространения ошибки** (англ. backpropagation) — метод вычисления градиента функции потерь в пространстве весов модели. На сегодняшний день является основным методом обучения искусственных нейронных сетей.\n",
    "\n",
    "Впервые метод был описан в 1974 г. А.И. Галушкиным и (независимо и одновременно) П. Вербосом. Существенно развит в 1986 г. Д. Румельхартом.\n",
    "\n",
    "Метод обратного распространения ошибки применим в случае, когда **все** функции, из которых состоит нейронная сеть, **дифференцируемы**. Выполнение этого требования позволяет аналитически рассчитать градиент функции потерь в пространстве **всех** весов модели, то есть определить направление наискорейшего возрастания значения функции потерь. Пошаговое изменение весов в направлении антиградиента приводит к снижению потерь - в этом и заключается процесс обучения нейронной сети.\n",
    "\n",
    "Метод позволяет обучать многослойные нейронные сети, одновременно обновляя веса всех слоев сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/lenet_lecun.png\" width=\"700\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://arxiv.org/pdf/1806.07382.pdf\">In situ Tensorview: In situ Visualization of\n",
    "Convolutional Neural Networks</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появление алгоритма обратного распространения ошибки вкупе с возрастающими компьютерными мощностями позволило обучить многослойную нейронную сеть, которую можно было применять для решения практических задач.\n",
    "\n",
    "Архитектура такой сети была разработана в 1989 году Яном Ле Куном. \n",
    "Сеть имела **5** слоёв, из них **2** свёрточные.\n",
    "\n",
    "Применялась в США для распознавания рукописных букв на почтовых конвертах до начала 2000 года."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2012 - AlexNet, победа на соревновании ImageNet\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/imagenet_2012.png\" width=\"900\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 2012 году свёрточная нейронная сеть **[AlexNet](https://neurohive.io/ru/vidy-nejrosetej/alexnet-svjortochnaja-nejronnaja-set-dlja-raspoznavanija-izobrazhenij/)** (Alex Krizhevsky in collaboration with Ilya Sutskever and Geoffrey Hinton) выиграла конкурс по распознаванию изображений ImageNet LSVRC-2012 c большим отрывом от конкурентов.\n",
    "\n",
    "Архитектура AlexNet схожа с LeNet, но имеет больше слоев и фильтров.\n",
    "\n",
    "Это событие породило новую волну интереса к алгоритмам глубокого обучения и, в частности, к свёрточным нейронным сетям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ImageNet: Large Scale Visual Recognition Challenge (ILSVRC)**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/imagenet_ilsvrc.png\" width=\"700\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://image-net.org/challenges/LSVRC/\">ImageNet</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fei-Fei Li](https://en.wikipedia.org/wiki/Fei-Fei_Li)\n",
    "\n",
    "[Christiane Fellbaum](https://en.wikipedia.org/wiki/Christiane_Fellbaum)\n",
    "\n",
    "С 2010 года в рамках проекта ILSVRC проводятся соревнования между исследовательскими группами по классификации объектов. В 2011 году хорошим результатом считалась ошибка классификации 25 %. В 2012 году система глубокого обучения на основе свёрточной нейронной сети смогла достичь 16 % ошибки, а в следующие годы ошибка упала до нескольких процентов. В 2015 году исследователи констатировали, что программы в определённых задачах проекта ILSVRC превзошли человеческие способности.\n",
    "\n",
    "**Условия соревнования:**\n",
    "На каждом изображении может быть один или несколько предметов, относящихся к **одному из 1000** классов.\n",
    "Для метрики *Тop5* алгоритм выдает метки 5 классов. Если предмет, относящийся к одному из этих классов, есть на изображении, то ответ засчитывается как верный.\n",
    "Для *Top1* соответственно принимается только метка одного класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/alexnet_citations.png\" width=\"950\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xegzhJcAAAAJ&citation_for_view=xegzhJcAAAAJ:u5HHmVD_uO8C\">Google Scholar</a> (the number of citations is relevant for October 2022)</p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы понять важность победы AlexNet в 2012 году, достаточно посмотреть на количество ссылок на данную работу. Оно сравнимо с количеством цитирований основополагающих трудов в различных областях науки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Количество цитирований на 2022 год**\n",
    "\n",
    "A. Krizhevsky et al \"ImageNet Classification with Deep Convolutional Neural Networks\", 2012: **115 472**\n",
    "\n",
    "Ч. Дарвин, \"О происхождении видов\", 1859: **60 238**\n",
    "\n",
    "К. Шеннон, “Математическая теория связи”, 1953 (позволила решить основные задачи теории информации): **151 880**\n",
    "\n",
    "Д. Уотсон и Ф. Крик, “Молекулярная структура нуклеиновых кислот”, 1953 (первая статья, в которой было опубликовано описание открытия двойной спирали структуры ДНК): **16 974**\n",
    "\n",
    "ATLAS Collaboration, \"Наблюдение новой частицы в поисках Стандартной модели бозона Хиггса с помощью детектора ATLAS на БАК\", 2012 (обнаружение бозона Хиггса): **32 498**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Сферы применения и технологии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Робототехника\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/robotics.jpg\"  width=\"1000\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросети широко применяются для решения задач технического зрения. Различным роботизированным  устройствам от таких, как беспилотные транспортные средства, до промышленных роботов или домашнего пылесоса, требуется определять своё местоположение в пространстве и/или местоположение окружающих объектов. \n",
    "\n",
    "Эту задачу можно решать путем обработки изображений с камер. Здесь очень эффективными оказались свёрточные нейросети, подобные AlexNet. \n",
    "\n",
    "Роботы присутствуют в нашей жизни в виде дронов, машин, пылесосов. Для использования в данных системах используется задача детекции, треккинга на видео, сегментации (связки с технологиями). Применение нейронных сетей в робототехнике — в частности это самоуправляемые автомобили, роботы на производстве, робот пылесос. \n",
    "\n",
    "Беспилотные автомобили Self-Driving Car и дроны. Промышленные и бытовые роботы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Детектирование (object detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/object_detection.jpg\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[КЛАССИФИКАЦИЯ](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8) + [РЕГРЕССИЯ](https://proglib.io/p/ml-regression) ~= [ДЕТЕКТИРОВАНИЕ](https://neerc.ifmo.ru/wiki/index.php?title=%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BD%D0%B0%D1%85%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2_%D0%BD%D0%B0_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Nvidia example: How Does a Self-Driving Car See?](https://blogs.nvidia.com/blog/2019/04/15/how-does-a-self-driving-car-see/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача поиска местоположения объекта в кадре — это задача детектирования. Она тесно связана с задачей классификации:\n",
    "\n",
    "Сначала обучается сеть, которая классифицирует изображения. То есть определяет, что на изображении присутствует человек. \n",
    "\n",
    "Затем к такой сети добавляются несколько слоев, которые предсказывают координаты объектов. То есть решают задачу регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знание координат объектов вокруг позволяет решать различные более сложные задачи: \n",
    "\n",
    "• Трекинг (отслеживание перемещения);\n",
    "\n",
    "• Предсказание действий;\n",
    "\n",
    "• SLAM (*simultaneous localization and mapping* — одновременная локализация и построение карты);\n",
    "\n",
    "• Оценка расстояний до объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic whale counting in satellite images with deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/counting_whales_nn.png\" width=\"700\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://github.com/EGuirado/CNN-Whales-from-Space\">CNN-Whales-from-Space</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот пример использования аналогичного подхода у биологов. Авторы [статьи](https://arxiv.org/pdf/1604.05605.pdf) обучили нейронную сеть искать на спутниковых снимках китов и подсчитывать их количество. \n",
    "\n",
    "Отдельно можно использовать классификатор для определения вида кита.\n",
    "\n",
    "Аналогичным образом можно обучить сеть искать объекты любых других категорий. Совсем не обязательно на изображениях в видимом диапазоне.\n",
    "\n",
    "[Репозиторий с реализацией](https://github.com/EGuirado/CNN-Whales-from-Space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Безопасность "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/security_video_analytics.png\"  width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видеоаналитика.\n",
    "\n",
    "Про системы распознавания лиц все вероятно слышали.\n",
    " Что скрывается “под капотом”?\n",
    "Несколько моделей. Одна ищет лицо на изображении. Кстати, с этим достаточно успешно справлялись и алгоритмы без применения глубокого обучения (ViolaJones 2001). \n",
    "Другая, ищет ключевые точки, чтобы потом изображение выронить. \n",
    "\n",
    "Решаются те же две задачи (классификация + регрессия).\n",
    "\n",
    "Но количество людей, проходящих мимо камеры в метрополитене, огромно. И что хуже, их список заранее не известен. Поэтому мы не можем использовать классификатор, чтобы отличить лицо одного человека от другого. Нам просто неизвестно количество классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/clustering_face_recognition.jpg\" width=\"1100\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому при распознавании лиц применяется другая техника: по вырезанному и выравненному прямоугольнику с лицом строится вектор-признак “embedding” — некое компактное представление.\n",
    "\n",
    "По сути, сильно снижается размерность изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А дальше можно сравнить между собой полученные вектора, использовав любую метрику расстояния. \n",
    "\n",
    "То есть к классификации и регрессии добавляется 3-я базовая задача: **кластеризация**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ медицинских изображений "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/segmentation.png\" width=\"700\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[U-Net: нейросеть для сегментации изображений](https://neurohive.io/ru/vidy-nejrosetej/u-net-image-segmentation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: поиск аномалий (опухолей) и определение их четких границ.\n",
    "\n",
    "Эта задача очень похожа на детектирование. Нужно найти, где находится объект. Но в данном случае нужно найти четкие границы. Желательно с точностью до пикселя.\n",
    "\n",
    "То есть для каждого пикселя нужно предсказать, к какому объекту он относится. \n",
    "\n",
    "**Получается попиксельный классификатор.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но проблема состоит в том, что пикселей много, и решать её в лоб — неэффективно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому при сегментации используется подход, подобный тому, что при **кластеризации лиц:**\n",
    "\n",
    "• Часть нейросети сжимает изображение — получается карта признаков (карта, потому что структура сохраняется);\n",
    "\n",
    "• На этой карте (см. выше) предсказываются границы объектов;\n",
    "\n",
    "• Вторая часть сети (симметрично первой восстанавливает размеры)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Это концепция энкодер - декодер.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/face_generation_gan.png\" width=\"1000\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На базе концепции энкодер - декодер появились так называемые генеративно-состязательные сети.\n",
    "Сжатое представление, которое получается на внутреннем слое сети, содержит какие-то ключевые признаки изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но не всю информацию об изображении и в зависимости от того как будет идти процедура восстановления мы можем получить разные вариации изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Почему состязательные?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку сеть генерирует совершенно новое изображение, у нас нет шаблона, с которым мы могли бы его сравнить и дать оценку работы модели.\n",
    "Поэтому для оценки качества работы первой сети (генератора) обучается вторая (дискриминатор), которая дает ответ на вопрос: похоже ли полученное изображение на настоящее или нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/style_transfer_gan.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С результатами работы таких моделей вы все хорошо знакомы по соцсетям и мобильным приложениям.\n",
    "Помимо использования в развлекательных целях, эта технология широко используется и в научных работах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка изображений галактик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/delete_noise_gan.png\" width=\"700\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://academic.oup.com/mnrasl/article/467/1/L110/2931732?login=false\">Generative adversarial networks recover features in astrophysical images of galaxies beyond the deconvolution limit</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения, полученные при помощи телескопов, оказываются зашумленными по причинам:\n",
    "- атмосферных помех;\n",
    "- шумам, которые даёт сенсор телескопа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классический способ борьбы с этой проблемой состоит в подборе сигнала похожего на суммарный шум: point spread function (PSF) и последующей сверке изображения с этим сигналом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[В данной работе](https://academic.oup.com/mnrasl/article/467/1/L110/2931732) для решения той же проблемы авторы статьи обучили GAN.\n",
    "В качестве входных данных использовались изображения галактик.\n",
    "\n",
    "*4550 galaxies from the Sloan Digital Sky Survey Data Release 12 (York et al. 2000; Alam et al. 2015)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/galaxys_after_gan.png\" width=\"700\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://academic.oup.com/mnrasl/article/467/1/L110/2931732?login=false\">Generative adversarial networks recover features in astrophysical images of galaxies beyond the deconvolution limit</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения преобразовывались в RGB формат. И к ним искусственно добавлялись искажения, имитирующие шум от сенсора и размытие, возникающее за счёт потоков воздуха в атмосфере(PSF).\n",
    "Датасет состоял из пар зашумленных и чистых изображений.\n",
    "\n",
    "Генератор обучался на основе изображения с шумом генерировать чистое изображение, а дискриминатор отличал зашумленные изображения от чистых.\n",
    "\n",
    "На первый взгляд результат впечатляет. Однако авторы признают, что на фотографиях, где присутствуют объекты, редко появляющиеся в датасете, результат хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN & OneShot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/oneshot_learning_gan.png\" width=\"700\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://indico.cern.ch/event/967970/contributions/4118959/attachments/2151681/3628080/Burnaev_Manifold_Knowledge_Transfer_v2.pdf\">Deep Generative Models for\n",
    "Knowledge Transfer</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели, которые мы рассматривали, до сих обучаются на большом количестве данных. \n",
    "В ряде областей (например, в медицине) их может не хватать.\n",
    "\n",
    "Вот пример [статьи](https://indico.cern.ch/event/967970/contributions/4118959/attachments/2151681/3628080/Burnaev_Manifold_Knowledge_Transfer_v2.pdf), в которой авторы обучили GAN сегметировать МРТ снимках мозга с признаками рассеянного склероза, а затем использовали её для поиска опухолей, дообучив модель всего на 5 снимках.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Применение семантической сегментации МРТ в медицине:**\n",
    "\n",
    "• анализ и мониторинг опухолей (например, головного мозга, печени);\n",
    "\n",
    "• обнаружение бляшек рассеянного склероза;\n",
    "\n",
    "• обнаружение гиперестезии белого вещества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP & Speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/nlp_speech_recognition.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Область применения DL не ограничивается только изображениями. \n",
    "\n",
    "Они так же весьма эффективны для распознавания голоса и машинного перевода.\n",
    "В отличие от изображений, входные данные имеют другую структуру: это последовательность, длина которой заранее неизвестна.\n",
    "\n",
    "Для работы с такого рода данными используются сети другого типа — рекуррентные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/rnn_architecture.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные подаются последовательно.\n",
    "Каждый элемент данных может оказывать влияние на выход модели и менять ее состояние. \n",
    "\n",
    "[Статья](https://www.nature.com/articles/s41598-019-48909-4), в которой авторы использовали эту технологию для анализа сигналов, которыми общаются киты.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фолдинг белка "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/alphafold.png\" width=\"700\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://www.deepmind.com/blog/alphafold-using-ai-for-scientific-discovery-2020\">AlphaFold: Using AI for scientific discovery</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент существует важная задача — фолдинг белка. Белок синтезируются в клетке в виде соединённых последовательно аминокислот. Эта последовательность обычно известна и кодируется в геноме.\n",
    "\n",
    "Однако после цепочка будет складываться в сложные пространственные структуры и, в зависимости от того, как эта структура будет выглядеть, зависит то, как белок будет себя вести в дальнейшем. Соответственно, понимание его особенностей служит ключом для производства лекарств и интерпретации генетических аномалий. \n",
    "\n",
    "В геноме человека могут происходить мутации — ошибки в геноме, которые могут приводить к изменению аминокислотной последовательности белка. \n",
    "\n",
    "Далеко не все мутации, которые есть в геноме, приведут к проблемам в конечной структуре, и если мы заранее будем знать, что одна мутация белка с дефектом, а другая безопасная, мы сможем предсказать вероятность развития болезни. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку эти связи обусловлены достаточно сложными внутримолекулярными взаимодействиями, просчитать заранее, как будет выглядеть молекула, достаточно трудозатратно. На каждом этапе формирования действуют разные связи между аминокислотами (водородные связи, гидрофобные взаимодействия и пр.), тем самым образуя сложную структуру.\n",
    "\n",
    "Рассчитать аналитически структуру, которая образуется в ходе этих взаимодействий, сложно, но можно применить для этого нейросеть, подав ей аминокислотную последовательность белка. \n",
    "\n",
    "Автора AlphaFold2 обучают нейросеть, которая предсказывает расстояния и углы между атомами аминокислот в конечном белке, причем делает это итеративно, улучшая предсказание с предыдущего шага. Далее, специальный алгоритм преобразует это в набор координат атомов, что и является пространственной структурой белка. \n",
    "Этот трехмерный массив координат атомов можно визуализировать, и дальше структурные биологи могут делать вывод о том, получится конкретный белок дефектным или нет. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А эти знания уже применяются в области производства лекарств. Например, есть база веществ и известно, какая у них структура. Имея структуру белка, можно предсказать, в каком месте и с какой формой белка они могут и должны соединяться. Соответственно, по базе данных можно найти вещества, которые будут с этим белком связаны и уже подобрать из имеющихся “претендентов” тот, который наилучшим образом будет работать. \n",
    "\n",
    "Про мутации. Есть базы данных нормальных и мутагенных белков, и мы можем сравнить то, что получилось у нас в результате фолдинга с эталоном и посмотреть, насколько большая разница в структурах (опять же, для этого нужны структурные биологи, так как не все части структуры белка равнозначны). И на основе этого уже предсказать, насколько опасна будет та или иная мутация. \n",
    "\n",
    "\n",
    "\n",
    "[Заявление от deepmind](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)\n",
    "\n",
    "[Мнение структурных биологов](https://22century.ru/popular-science-publications/couple-of-words-on-alphafold2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/alphafold_nn.png\" width=\"700\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://www.deepmind.com/blog/alphafold-using-ai-for-scientific-discovery-2020\">AlphaFold: Using AI for scientific discovery</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Improved protein structure prediction](https://www.nature.com/articles/s41586-019-1923-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Причины успехов технологий на основе DL \n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/high_dL_perfomance.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему всё это произошло так внезапно?**\n",
    "\n",
    "1. Чтобы модель могла извлечь и запомнить все важные закономерности, все они должны присутствовать в данных. Доступные цифровые фотокамеры и быстрый интернет, обеспечивший исследователям доступ к данным и возможность коллаборативной разметки, стали появляться только в начале 2000-х годов.\n",
    "\n",
    "\n",
    "2. Вычислительные мощности:\n",
    "\n",
    "* Lenet обучали на Pentium2  это примерно 10^7 транзисторов;\n",
    "\n",
    "* AlexNet на двух GPU GTX580 это уже примерно 10^14;\n",
    "\n",
    "С данными у ученых дела обстоят не так хорошо.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ML — Подход к научным проблемам</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Извлечение закономерностей — закон Ньютона \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/newtons_law.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе наблюдений люди выявляют закономерности и делают обобщение, наблюдая за реальным миром.\n",
    "Результатом такой умственной деятельности является модель, описывающая некоторые процессы реального мира.\n",
    "\n",
    "Она может быть описана при помощи математических формул или алгоритмического языка.\n",
    "\n",
    "Сейчас появилась технология, которая может это делать вместо человека."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/newtons_law_and_nn.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Это ML**\n",
    "\n",
    "**ML** — это технология, которая позволяет выявлять закономерности в данных и обобщать их. \n",
    "\n",
    "Вы можете использовать её для поиска закономерностей, которые люди ещё не обнаружили и таким образом совершить открытие.\n",
    "Правда, результатом обучения такой модели будет не компактная формула, а набор весов. \n",
    "По сути это набор коэффициентов для некоторого математического выражения.\n",
    "\n",
    "Для этого нужно две вещи: **данные** и **валидация результата.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/predictions_by_nn.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как человеку, так и алгоритму машинного обучения требуется подготовка данных.\n",
    "\n",
    "Законы Ньютоны **не** сформулированы для яблок. Для описания закономерностей в науке используются абстракции: *сила, масса, ускорение.*\n",
    "\n",
    "Данные для **ML** моделей тоже должны быть подготовлены. Типичная форма такой абстракции — вектор или n-мерный массив чисел.\n",
    "\n",
    "Именно с такой формой представления данных работает большинство современных моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/nn_predict_patterns.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй элемент, который потребуется для процесса обучения —  разработка способа оценки результата (*валидации*).\n",
    "\n",
    "Вне зависимости от того, какой метод обучения используется — с учителем или без, требуется некий критерий, по которому будет оцениваться выход модели и впоследствии корректироваться веса.\n",
    "\n",
    "В базовом варианте: полученный результат сравнивают с эталонным и если разница велика — корректируют модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Поясним эту идею на конкретном примере. Допустим, у нас есть наручный шагомер, который фиксирует перемещения в пространстве. Скорее всего, в нем встроен акселерометр, который способен фиксировать перемещения по трем осям. На выходе мы получаем сигнал с нескольких(3-х) датчиков.\n",
    "\n",
    "Если задача состоит в том, чтобы подсчитать количество шагов, то к её решению можно подойти двумя способами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/accelerometer_task.jpg\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классический: напишем программу. \n",
    "Если появилось ускорение по одной из осей, которое больше определенного порога, то мы создаем то условие, которое срабатывает. Позже мы выясним, что подобные сигнатурные сигналы с датчика могут поступить и при других определенных движениях, не связанных с шагами, например, во время плавания.\n",
    " Добавляется дополнительное условие, которое фильтрует подобные ситуации. \n",
    "\n",
    "Находятся всё новые и новые исключения из общего правила, программа и ее алгоритмическая сложность будет расти.\n",
    "\n",
    "Программу будет сложнее поддерживать из-за большого объема кода в ней. \n",
    "Изменение в одной из частей потребует внесение правок в другой код  и.т.п."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/accelerometr_solution_standart.png\" width=\"700\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант №2\n",
    "\n",
    "\n",
    "С появлением машинного обучения мы можем применить принципиально другой подход. \n",
    "Не задумываясь о том, что значат показания каждого из акселерометров, мы можем просто собрать некоторый архив данных за определенное время (возможно разбив на более короткие промежутки времени). Всё, что нам потребуется помимо этих данных — это информация о том, сколько было сделано реальных шагов. После этого данные загружаются в модель, и она на этих данных учится. При достаточном количестве данных и адекватно подобранной модели (чем мы и будем заниматься) мы сможем научить ее решать конкретные задачи (в данном случае — считать шаги). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/accelerometr_solution_nn.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что по сути модели всё равно, что считать: шаги, сердечный ритм, количество калорий, ударов по клавиатуре и пр. Нет необходимости писать под каждый пример отдельную программу, достаточно собрать данные и мы сможем решить множество абсолютно разных задач. \n",
    "\n",
    "Важно лишь понимать, какую модель предпочтительнее выбрать. С этим мы и будем разбираться в ходе курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/different_type_of_tasks.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Базовые задачи ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/ml_basic_tasks.png\" width=\"700\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://scikit-learn.org/stable/\">scikit-learn</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все многообразие практических задач базируется на трех базовых:\n",
    "\n",
    "* Регрессия — предсказание;\n",
    "* Классификация — разделение;\n",
    "* Кластеризация — разбиение на классы, когда их число заранее не известно (близка к классификации, но не эквивалентна ей).\n",
    "\n",
    "Практически любую задачу машинного обучения (детекция, сегментация и т.д.) можно свести к одной из этих трех."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/classification_task.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация представляет собой отнесение объекта к одному из нескольких попарно не пересекающихся множеств (классов).\n",
    "\n",
    "Объекты в задачах машинного обучения могут представлять собой самые разные сущности: изображения, звуки, материальные предметы и т.д. Каждый объект представляют в виде набора чисел (вектор в пространстве признаков).\n",
    "\n",
    "Обучение модели заключается в том, что ей дается доступ к размеченной обучающей выборке - набору объектов, класс которых известен. В ходе обучения модель согласно алгоритму обучения находит закономерности в обучающей выборке и сохраняет внутри себя эти закономерности в виде чисел - обучаемых параметров модели.\n",
    "\n",
    "При использовании (инференсе) модель должна получить на вход признаки нового объекта и однозначно определить класс, к которому он относится.\n",
    "\n",
    "Классификация бывает бинарной и многоклассовой.\n",
    "\n",
    "Примеры задачи классификации:\n",
    "- болен ли пациент раком\n",
    "- к какой из десяти пород кошек принадлежит животное на изображении\n",
    "- присутствует ли ненормативная лексика на аудиозаписи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/regression_task.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача регрессии заключается в том, чтобы по признаковому описанию объекта предсказать его характеристику в виде вещественного числа. \n",
    "\n",
    "Примеры задач регрессии:\n",
    "- оценить стоимость дома\n",
    "- найти координаты пожара на спутниковой фотографии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/clustering_task.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация - задача объединения схожих объектов в группы. Принципиально отличается от задачи классификации тем, что группы, в отличие от классов, не могут быть определены заранее.\n",
    "\n",
    "При решении задачи кластеризации модель каким-либо методом определяет схожесть отдельных объектов или схожесть распределений множества объектов и принимает решение о группировке.\n",
    "\n",
    "Частный случай задачи кластеризации - поиск аномалий в данных.\n",
    "\n",
    "Примеры задач кластеризации:\n",
    "- группировка текстов по темам\n",
    "- определение непредвиденных сбоев в работе автоматизированных систем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типы данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/types_of_data.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большинство процессов и объектов, с которыми научились работать ML/DL модели, можно отнести к одному из перечисленных типов. Наша задача будет состоять в том, как данные из вашей предметной области свести к одному из них и представить в виде набора чисел. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с различными типами данных используют разные типы моделей:\n",
    "\n",
    "**Табличный**  — классические ML модели либо полносвязные нейронные сети\n",
    "\n",
    " **Последовательности** — рекуррентные или сверточные сети\n",
    " \n",
    " **Изображения/видео** — многомерные сверточные сети\n",
    "\n",
    "В разных типах данных количество связей между элементами разное и зависит только от типа этих данных. Важно НЕ количество элементов, а СВЯЗИ между ними."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/connectivity_of_data_types.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные можно условно делить по степени связанности. Это степень взаимного влияния между соседними элементами. \n",
    "\n",
    "Например, в таблице, в которой есть определенные параметры (например: рост, вес) данные между собой связаны, но порядок столбцов значения не имеет.\n",
    "Если мы поменяем столбцы местами, то не потеряем никакой важной информации. \n",
    "\n",
    "Такие данные можно представить в виде вектора, но порядок элементов в нем не важен.\n",
    "\n",
    "При работе с изображениями нам становится важно, как связаны между собой пиксели и по горизонтали, и по вертикали. \n",
    "\n",
    "При добавлении цвета появляются 3 RGB канала, и значения в каждом канале также связаны между собой. Эту связь нельзя терять, если мы хотим корректно извлечь максимум информации из данных. Соответственно, если дано цветное изображение, то у нас уже есть три измерения, в которых мы должны эти связи учитывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/datasets_for_different_tasks.png\" width=\"600\" >\n",
    "\n",
    "<center><p><em>Source: <a href=\"https://coggle.it/diagram/Xmcn5GVe0zfnM4aS/t/dataset\">Dataset map</a></p> </em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/imagenet_dataset.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На датасете [ImageNet](http://image-net.org/download) предобученны все модели для классификации, которые присутствуют в “зоопарке моделей” Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/dataset_coco.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Coco dataset](http://cocodataset.org) используется для обучения моделей, решающих задачи классификации, сегментации и детектирования. В нём намного меньше категорий объектов, чем в ImageNet, но присутствует разметка по bounding box и маскам.\n",
    "\n",
    "Cложные бытовые сцены предметов в их естественном контексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Набор данных MosMedData: COVID19_1110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/dataset_mosmeddata.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предыдущие два датасета, в отличие от MosMedData были исследовательские. На них соревнуются, проверяют гипотезы,  качество работы новых моделей.\n",
    "Для них много примеров и хорошие описания.\n",
    "\n",
    "[Пример реального датасета](https://mosmed.ai/datasets/)\n",
    "\n",
    "Скорее всего разобраться с тем, как использовать эти данные, будет сложнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/dataset_mnist.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "База данных рукописных цифр [MNIST](http://yann.lecun.com/exdb/mnist/\n",
    ")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/dataset_cifar10.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) $-$ маленькие изображения в низком разрешении, разделённые на 10 классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10/100 и MNIST — это **учебные датасеты.**\n",
    "\n",
    "В них изображения размечены по нескольким классам. Чтобы загрузка и обучение проходили быстро, картинки имеют небольшое разрешение, а количество классов невелико.\n",
    "В остальном всё как у взрослых.\n",
    "\n",
    "И авторы статей, посвящённых разработке новых нейросетевых моделей, достаточно часто приводят результаты работы своих моделей на этих датасетах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Оценка результата "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/how_compute_model_accuracy.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая часть работы — это оценка точности. Нам нужно определиться с тем, как оценивать результат.\n",
    "Очень часто приходится слышать от заказчика вопрос со слайда.\n",
    "Чаще всего ответ “99%” их более чем устраивает. \n",
    "\n",
    "\n",
    "В большинстве случаев такой ответ воспринимается неверно, что в дальнейшем приводит к проблемам. Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/accuracy_problem_example.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/important_accuracy_factors.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Скорость перемещения  машины зависит от дороги: на дорогах бывают пробки, ограничивающие знаки, наконец, дороги бывают очень разного качества.\n",
    "\n",
    "Всё это влияет на скорость перемещения и порой радикально.\n",
    "\n",
    "Так же и точность наших моделей в первую очередь зависит от данных, на которых мы будем их оценивать. Модель, которая отлично работает на одном датасете, может намного хуже работать на другом или не работать вовсе. В том числе в силу технических причин (пример про Resnet и CIFAR10).\n",
    "\n",
    "2. Машина может быть подвергнута тюнингу. Например, внедорожный тюнинг поможет преодолеть участок бездорожья, на котором неподготовленный автомобиль застрянет. Но при этом скорость на дорогах общего пользования может снизиться. Так же и модель, как правило, имеет ряд параметров (гиперпараметров), от которых зависит её работа. Они могут подбираться в зависимости от задачи (ошибки первого и второго рода) и качества данных.\n",
    "\n",
    "3. Само понятие скорости допускает вариации: речь идет о средней или максимальной скорости? Аналогично и для оценки моделей существует несколько метрик, применение которых, опять же, зависит от целей заказчика и особенностей данных.\n",
    "\n",
    "Поэтому честный ответ на вопрос о точности должен звучать так: «На датасете X модель Y по метрике Z показала точность 99%».\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L01/simple_way_to_compute_accuracy.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ подсчёта точности модели — это деление количества правильно распознанных элементов на общее их количество.\n",
    "\n",
    "**Какие есть недостатки у такого способа?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/problem_of_simple_way_to_compute_accuracy.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy нельзя использовать, если данные не сбалансированы. То есть в одном из классов больше представителей, чем в другом.\n",
    "\n",
    "Также она не подойдет для задач сегментации и детектирования, если требуется не только определить наличие объекта на изображении, но и найти место, где он находится, то весьма желательно учитывать разницу в координатах.\n",
    "\n",
    "Сегодня же мы будем решать задачу классификации на учебных датасетах, где данные либо сбалансированы, либо дисбалансом можно пренебречь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Демонстрация работы с данными "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Табличные данные "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обзор инструментов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим примеры решения задач классификации на различных типах данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать библиотеки:\n",
    "\n",
    "* [numpy](https://numpy.org/) — поддержка больших многомерных массивов и быстрых математических функций для операций с этими массивами.\n",
    "* [scikit-learn](https://scikit-learn.org/stable/) — ML алгоритмы, \"toy\" — датасеты;\n",
    "* [pandas](https://pandas.pydata.org/) — Удобная работа с табличными данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [**Pytorch**](https://pytorch.org/) — Основной фреймворк машинного обучения, который будет использоваться на протяжении всего курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Загрузка данных  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример работы с табличными данными\n",
    "\n",
    "Пример работы с табличными данными. \n",
    "Классифицируем вина из [датасета](https://archive.ics.uci.edu/ml/machine-learning-databases/wine/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача будет состоять в том, чтобы по химическому составу определить производителя вина.\n",
    "\n",
    "Количество экземпляров, полученных на тест от каждого из трех производителей, не одинаково."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производитель №1 (class_1) 59 бутылок  \n",
    "Производитель №2 (class_2) 71 бутылка  \n",
    "Производитель №3 (class_3) 48 бутылок  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот датасет можно загрузить, используя модуль sklearn.datasets библиотеки [sklearn](https://scikit-learn.org/stable/), чем мы и воспользуемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.datasets import load_wine\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "\n",
    "# Download dataset\n",
    "dataset = load_wine(return_X_y=True) # also we can get data in Bunch (dictionary) or pandas DataFrame\n",
    "\n",
    "features = dataset[0] # array 178x13 (178 bottles each with 13 features)\n",
    "class_labels = dataset[1] # array of 178 elements, each element is a number the class: 0,1 2  \n",
    "print(\"features shape:\",features.shape)\n",
    "print(\"class_labels shape:\",class_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация данных  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Если параметр \n",
    "    \n",
    "    return_X_y == False\n",
    "\n",
    "то данные вернутся не в виде массива, а в объекте [Bunch](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch).\n",
    "\n",
    "Обращаться к нему можно, как к обычному словарю в Python. Кроме того, у него есть свойство, соответствующее каждому полю данных.\n",
    "\n",
    "Чтобы отобразить данные в виде таблицы, преобразуем их в формат pandas.DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library to work with tabular data: https://pandas.pydata.org/\n",
    "import pandas as pd \n",
    "\n",
    "dataset_bunch = load_wine(return_X_y=False)\n",
    "print(dataset_bunch.keys())\n",
    "\n",
    "df = pd.DataFrame(dataset_bunch.data, columns=dataset_bunch.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая строка в таблице может быть интерпретирована как вектор из 13 элементов. Можно интерпретировать такой вектор как координаты точки в 13-мерном пространстве. Именно с таким представлением работает большинство алгоритмов машинного обучения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация данных <a class=\"anchor\" id=\"demonstration_1_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, какие масштабы имеют значения разных признаков. \n",
    "\n",
    "\n",
    "Для начала отобразим два признака: malic_acid и alcalinity_of_ash. Их значения отличаются примерно на порядок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 5), dpi=80)\n",
    "plt.title('Two features in differents scales')\n",
    "sns.histplot(features[:, 1], color='#3bb54a', edgecolor='white', \n",
    "             label='malic_acid', log_scale=True)\n",
    "sns.histplot(features[:, 3], color='#27a9e1', edgecolor='white',\n",
    "             label='alcalinity_of_ash', log_scale=True)\n",
    "plt.xlabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим ещё один признак, значения которого отличается от второго на 2 порядка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=80)\n",
    "\n",
    "plt.title('Three features in differents scales')\n",
    "sns.histplot(features[:, 1], color='#3bb54a', edgecolor='white',\n",
    "             label='malic_acid', log_scale=True)\n",
    "sns.histplot(features[:, 3], color='#27a9e1', edgecolor='white',\n",
    "             label='alcalinity_of_ash', log_scale=True)\n",
    "sns.histplot(features[:, 12], color='#ffab40', edgecolor='white',\n",
    "             label='proline', log_scale=True)\n",
    "plt.xlabel('Values, log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения в разных масштабах — модели будет сложно сравнивать их между собой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Max  нормализация\n",
    "\n",
    "Теперь нормализуем данные. Простейший способ — это Mini-Max нормализация. Вычтем минимальное значение и поделим на среднее.\n",
    "\n",
    "$$\\displaystyle X'  = \\frac{X-X_{min}}{X_{max} - X_{min}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# cast data to torch.Tensor \n",
    "tensor_f = torch.tensor(features)\n",
    "\n",
    "min_values, _  = tensor_f.min(dim=0, keepdim=True)  # shape = (1,13)\n",
    "max_values, _  = tensor_f.max(dim=0, keepdim=True)  # shape = (1,13)\n",
    "\n",
    "# Substract min\n",
    "min_max_centered = tensor_f - min_values # shape = (178,13)\n",
    "\n",
    "# Divide by mean\n",
    "min_max_normalized =  min_max_centered / (max_values - min_values) # shape = (1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "# Min_Max_Centered hist\n",
    "sns.histplot(min_max_centered[:, 1], color='#3bb54a', edgecolor='white', \n",
    "             label='malic_acid', ax=axes[0])\n",
    "sns.histplot(min_max_centered[:, 3], color='#27a9e1', edgecolor='white', \n",
    "             label='alcalinity_of_ash', ax=axes[0])\n",
    "# Min_Max_Normalized hist\n",
    "sns.histplot(min_max_normalized[:, 1], color='#3bb54a', edgecolor='white', \n",
    "             label='malic_acid', ax=axes[1])\n",
    "sns.histplot(min_max_normalized[:, 3], color='#27a9e1', edgecolor='white', \n",
    "             label='alcalinity_of_ash', ax=axes[1])\n",
    "\n",
    "axes[0].set(xlabel='Values')\n",
    "axes[0].set(title='Min_Max_Centered')\n",
    "axes[1].set(xlabel='Values')\n",
    "axes[1].set(title='Min_Max_Normalized')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что после центрирования значения сместились в сторону нуля, а после нормализации они сильно перекрываются, то есть данные перестали заметно отличаться по масштабу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стандартизация / Z-нормализация\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/z_normalization.png\" width=\"700\" >\n",
    "\n",
    "При Mini-Max нормализации остается проблема выбросов (см. 1-ую гистограмму). Если в данных есть даже единичные выбросы, то они займут значительную часть диапазона.\n",
    "\n",
    "Если делить не на среднее значение, а на стандартное отклонение, то эта проблема решается. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substract min\n",
    "centered = tensor_f - tensor_f.mean(dim=0)\n",
    "# Divide by standard deviation\n",
    "normalized = centered / tensor_f.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "# Z-centered hist\n",
    "sns.histplot(centered[:, 1], color='#3bb54a', edgecolor='white', \n",
    "             label='malic_acid', ax=axes[0])\n",
    "sns.histplot(centered[:, 3], color='#27a9e1', edgecolor='white', \n",
    "             label='alcalinity_of_ash', ax=axes[0])\n",
    "# Z-normalized hist\n",
    "sns.histplot(normalized[:, 1], color='#3bb54a', edgecolor='white', \n",
    "             label='malic_acid', ax=axes[1])\n",
    "sns.histplot(normalized[:, 3], color='#27a9e1', edgecolor='white', \n",
    "             label='alcalinity_of_ash', ax=axes[1])\n",
    "\n",
    "axes[0].set(xlabel='Values')\n",
    "axes[0].set(title='Z-Centered')\n",
    "axes[1].set(xlabel='Values')\n",
    "axes[1].set(title='Z-Normalized')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим значения признака `malic_acid` до и после нормализации MinMax и стандартизации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=80)\n",
    "\n",
    "plt.title('Original, MinMax, Z-normalize')\n",
    "sns.histplot(features[:, 1], color='#3bb54a', edgecolor='white', \n",
    "             label='Original')\n",
    "sns.histplot(min_max_normalized[:, 1], color='#27a9e1', edgecolor='white', \n",
    "             label='Min_Max_normalize')\n",
    "sns.histplot(normalized[:, 1], color='#ffab40', edgecolor='white', \n",
    "             label='Z-normalize')\n",
    "plt.xlabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Наглядное преимущество стандартизации перед Max-Min нормализацией.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Базовая документация](https://scikit-learn.org/stable/modules/svm.html)\n",
    "\n",
    "Используем простую модель, [пример](https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python) использования SVM классификатора\n",
    "\n",
    "Её устройство будет рассмотрено на следующих лекциях, сейчас будем считать модель чёрным ящиком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Разбиение данных на обучающую и тестовую выборки \n",
    "\n",
    "Самым простым способом научиться чему-либо является \"запомнить всё\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним \"Таблицу умножения\". Если мы хотим проверить умение умножать, то проверки примерами из таблицы умножения будет недостаточно, ведь она может быть полностью запомнена. Нужно давать новые примеры, которых не было в таблице умножения (обучающей выборке)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если модель \"запомнит всё\", то она будет идеально работать на данных, которые мы ей показали, но может вообще не работать на любых других данных.\n",
    "\n",
    "С практической точки зрения важно, как модель будет вести себя именно на незнакомых для неё данных. То есть насколько хорошо она научилась обобщать закономерности, которые в данных присутствовали (если они вообще существуют)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки этой способности набор данных разделяют на две, а иногда даже на три части:\n",
    "\n",
    "* train — Данные, на которых модель учится;\n",
    "* validation/test — Данные, на которых идет проверка.\n",
    "\n",
    "В `sklearn.model_selection` есть модель для разделения массива данных на тренировочную и тестовую часть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, class_labels, test_size=0.2) # 80% training and 20% test\n",
    "\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"x_test shape\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А мы в дальнейшем будем пользоваться аналогичными инструментами библиотеки PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Обучим модель и посчитаем точность (Accuracy) \n",
    "\n",
    "Теперь можно запустить процесс обучения и посчитать точность работы модели на данном датасете.\n",
    "\n",
    "То есть понять, насколько хорошо по химическому составу модель определит винодела, поставившего это вино.\n",
    "\n",
    "accuracy = p/N\n",
    "\n",
    "где p — количество верных ответов, а N — общее число примеров, использовавшихся в тесте. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# create model\n",
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "# fit model at train data\n",
    "lin_clf.fit(x_train, y_train)\n",
    "\n",
    "# get predict\n",
    "y_pred = lin_clf.predict(x_test)\n",
    "\n",
    "print(\"y_pred shape:\", y_pred.shape)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Predicted classes: \", y_pred)\n",
    "print(\"Real classes:      \", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аудиоданные "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным образом можно работать с различными типами данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Загрузка данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "В Pytorch есть три библиотеки для работы с разными типами данных:\n",
    "\n",
    "[torchvision](https://pytorch.org/vision/stable/datasets.html)\n",
    "\n",
    "[torchaudio](https://pytorch.org/audio/stable/datasets.html)\n",
    "\n",
    "[torchtext](https://pytorch.org/text/stable/index.html)\n",
    "\n",
    "\n",
    "Для загрузки данных  используются классы [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) и [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). \n",
    "\n",
    "Они предоставляют единый интерфейс для доступа к данным различных типов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример загрузки аудио средствами Pytorch**\n",
    "\n",
    "Рассмотрим пример того, как можно загрузить аудиоданные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим библиотеку torch.audio (она не входит в список пакетов, доступных в colab по умолчанию)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech Commands:  [A Dataset for Limited-Vocabulary SpeechRecognition](https://arxiv.org/pdf/1804.03209.pdf)\n",
    "\n",
    "Он представляет из себя набор звуковых файлов в формате .wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в которых записан звук голоса разных людей, произносящих одно из 35 слов на английском языке. Часть слов таких как: \n",
    "\n",
    "- left;\n",
    "- right;\n",
    "- on;\n",
    "- off;\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также слова, не являющиеся командами:\n",
    "\n",
    "- cat;\n",
    "- bird;\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В сравнении с датасетами из torchvision, [этот датасет](https://pytorch.org/audio/stable/datasets.html#speechcommands) имеет более ограниченный функционал. В частности, в нём нет трансформаций и данные не выравнены. Благодаря этому появляется возможность продемонстрировать необходимость в операциях, которые в дальнейшем будут работать \"из  коробки\".*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "speech_commands_dataset = torchaudio.datasets.SPEECHCOMMANDS(\"sample_data\", download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После загрузки данные будут распакованы в папку sample_data.\n",
    "Откройте её, используя меню в правой панели Colab. Посмотрите, в каком виде они хранятся на диске.\n",
    "\n",
    "\n",
    "Объект speech_commands_dataset — это экземпляр класса, который является наследником  [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html). Это означает, что в нём реализованы методы: \n",
    "* __getitem__ \n",
    "* __len__\n",
    "\n",
    "Благодаря этому мы можем узнать количество элементов или получить произвольный элемент данных, обращаясь к объекту класса [Dataset](https://pytorch.org/docs/stable/data.html)  так же, как к обычному списку в python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Num of elements {len(speech_commands_dataset)}\")\n",
    "print(f\"First element {speech_commands_dataset[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что представляет из себя элемент аудио-данных?**  \n",
    "Обратимся к [документации](https://pytorch.org/audio/stable/datasets.html#speechcommands)\n",
    "\n",
    "... returns:\n",
    "\n",
    "    (waveform, sample_rate, label, speaker_id, utterance_number)\n",
    "\n",
    "utterance_number — номер повтора. Больше нуля, если один и тот же человек проговаривает одну и ту же фразу несколько раз. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate, label, speaker_id, utterance_number = speech_commands_dataset[1]\n",
    "print(f\"Waveform: {waveform.shape}\\\n",
    "\\nSample rate: {sample_rate}\\\n",
    "\\nLabel: {label}\\\n",
    "\\nSpeaker_id: {speaker_id}\\\n",
    "\\nutterance_number: {utterance_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Размеры тензора waveform:\n",
    "    \n",
    "    [1, 16000] \n",
    "\n",
    "1 — количество каналов, 16000 — количество измерений в секунду.\n",
    "\n",
    "Если частота дискретизации(sample_rate) равна 16000, то этот фрагмент занимает ровно 1 секунду.\n",
    "\n",
    "**Визуализируем их:**  \n",
    "x — время  \n",
    "y — давление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'type waveform: {type(waveform)}')\n",
    "plt.figure(figsize=(10, 5), dpi=80)\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.plot(waveform.t().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Озвучим:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(waveform.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обзор контейнеров "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итерация по датасету**\n",
    "\n",
    "Запустим простую проверку: убедимся, что все записи одинаковой длины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почему это важно**\n",
    "\n",
    "Мы будем работать с массивами 3 типов:\n",
    "\n",
    "* list — стандартный тип в Python\n",
    "* numpy — массив\n",
    "* torch.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим, чем они отличаются:\n",
    "\n",
    "### List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_list = ['a', 15, 123.8, [99, \"I love you\"], [True, True, False]]\n",
    "\n",
    "print(python_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В списке могут быть данные различных типов, в том числе подтипов произвольной длины.\n",
    "\n",
    "### Numpy\n",
    "\n",
    "* Массив может содержать данные только одного типа;   \n",
    "* Размер данных во всех измерениям кроме 0-го должен совпадать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "numpy_arr = np.array([[1, 2, 3], [4, 5, 6]], dtype=float)\n",
    "print(numpy_arr)\n",
    "\n",
    "# This code will cause an error\n",
    "# invalid_numpy_arr = np.array([[1,2,3],[4,5]],dtype = float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря этому над numpy-массивами можно выполнять различные математические операции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([1, 0, 0])\n",
    "row_diff = numpy_arr - vector\n",
    "print(\"Substract row from array\", row_diff)\n",
    "\n",
    "scalar_product = numpy_arr.dot(vector)\n",
    "print(\"Scalar product\", scalar_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch.Tensor\n",
    "\n",
    "\n",
    "      'is a multi-dimensional matrix containing elements of a single data type.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С точки зрения ограничений и функционала [torch.Tensor](https://pytorch.org/docs/stable/tensors.html) эквивалентен numpy-массиву.\n",
    "Но дополнительно этот объект поддерживает две важных операции:\n",
    "\n",
    "* Перенос данных на видеокарту (`my_tensor.to('cuda:0')`)\n",
    "* Автоматический расчет градиентов  (`my_tensor.backward()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти возможности понадобятся нам в дальнейшем. Поэтому надо разобраться, как  работать с данными в этом формате. Тем более, что torch.Tensor легко преобразуется в numpy-массив и обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = torch.tensor(numpy_arr)\n",
    "print(\"torch.Tensor\\n\", my_tensor, \"shape =\", my_tensor.shape)\n",
    "\n",
    "squared_numpy = my_tensor.pow(2).numpy()\n",
    "print(\"Numpy\\n\", squared_numpy, \"shape =\", squared_numpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим,  что все записи имеют одинаковую длину: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_length = 16000\n",
    "for i, sample in enumerate(speech_commands_dataset):\n",
    "  waveform, sample_rate, label, speaker_id, utterance_number = sample\n",
    "  if def_length != waveform.shape[1]: # [1, 16000]\n",
    "    print(f\"Length of object #{i} not equal {def_length}\")\n",
    "    print(f\"Waveform: {waveform.shape}\\nSample rate: {sample_rate}\\nLabel: {label}\\\n",
    "    \\nSpeaker_id: {speaker_id} \\nutterance_number: {utterance_number}\")\n",
    "    break\n",
    "  if not i% 10000 and i > 0 :\n",
    "    print(f\"Processed {i} objects\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных <a class=\"anchor\" id=\"demonstration_2_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если элементы имеют различную длину, то мы не сможем их сравнивать. И даже технически поместить в один массив. \n",
    "\n",
    "\n",
    "Необходимо их выровнять. \n",
    "\n",
    "Так как многие записи начинаются и заканчиваются тишиной, то просто дополним их нулями.\n",
    "\n",
    "\n",
    "Для этого применим концепцию трансформаций (transform), которая широко применяется в Pytorch и встраивается во многие датасеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined transform\n",
    "class PadWaveform(torch.nn.Module):\n",
    "  def __init__(self, desired_size = 16000):\n",
    "    self.desired_size = desired_size\n",
    "    super().__init__()\n",
    "\n",
    "  # in nn.Module forward method called inside __call__ method\n",
    "\n",
    "  def forward(self, waveform):\n",
    "    if waveform.shape[1] < self.desired_size:\n",
    "      # Calculate pad size\n",
    "      diff = self.desired_size - waveform.shape[1]\n",
    "      pad_left = diff // 2\n",
    "      pad_right = diff - pad_left\n",
    "      # Add zero pad to tensor\n",
    "      # https://pytorch.org/docs/stable/nn.functional.html#pad\n",
    "      return torch.nn.functional.pad(waveform, [pad_left, pad_right])\n",
    "    else:\n",
    "      # If size equal to desired size, do nothing\n",
    "      return waveform\n",
    "\n",
    "# Create custom dataset with transformations support \n",
    "# it's common practice in pytorch\n",
    "\n",
    "class customSpeechCommandsDataset(torchaudio.datasets.SPEECHCOMMANDS):\n",
    "  def __init__(self, transform, root=\"sample_data\"):\n",
    "    self.transform = transform\n",
    "    super().__init__(root)\n",
    "\n",
    "  # Override \n",
    "  def __getitem__(self, n):\n",
    "    # Get item\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\n",
    "    # Apply transform\n",
    "    transformed_waveform = self.transform(waveform)\n",
    "    # Return ransformed item\n",
    "    return (transformed_waveform, sample_rate, label, speaker_id, utterance_number)\n",
    "\n",
    "\n",
    "speech_commands_dataset = customSpeechCommandsDataset(transform=torch.nn.Sequential(PadWaveform(16000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно добавлять дополнительные трансформации. Например, уменьшить частоту дискретизации (sample_rate) чтобы данные занимали меньше места.\n",
    "\n",
    "Для этого в модуле\n",
    "[torchaudio.transforms](https://pytorch.org/audio/stable/transforms.html#resample)  уже есть готовая трансформация:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.transforms import Resample\n",
    "\n",
    "transform = torch.nn.Sequential(\n",
    "    Resample(16000, 8000),\n",
    "    PadWaveform(8000))\n",
    "    \n",
    "speech_commands_dataset = customSpeechCommandsDataset(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пакетная обработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Визуализируем данные.**\n",
    "\n",
    "Датасет в архиве занимает > 2Gb и это далеко не предел. Поэтому работать с ним будем по частям. \n",
    "\n",
    "Для этой задачи в pytorch используется класс Dataloader. Одной из его функций является пакетная (batch) загрузка данных.\n",
    "\n",
    "Особенно она будет полезна при обучении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(speech_commands_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "for i, batch in enumerate(data_loader):\n",
    "  waveforms, sample_rates, labels, speaker_ids, utterance_numbers = batch\n",
    "  print(waveforms.shape)\n",
    "  print(labels)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Надо ли нормализовать эти данные?**\n",
    "\n",
    "Отрисуем значения 2-х произвольных признаков и проверим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(data_loader):\n",
    "    waveforms, sample_rates, labels, speaker_ids, utterance_numbers = batch\n",
    "    \n",
    "    plt.figure(figsize=(10, 5), dpi=80)\n",
    "    plt.hist(torch.squeeze(waveforms).numpy()[:, 100])\n",
    "    plt.hist(torch.squeeze(waveforms).numpy()[:, 200])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из гистограммы, данные уже центрированны вокруг нуля и имеют один масштаб. Отчасти это связанно с тем, что они имеют одну и ту же природу, отчасти с форматом хранения звука. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение \n",
    "\n",
    "Для обучения потребуются метки. Попутно избавимся от лишнего. Создадим очередную трансформацию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customSpeechCommandsDatasetFinal(customSpeechCommandsDataset):\n",
    "  def __init__(self, transform=torch.nn.Sequential(), root=\"sample_data\"):\n",
    "    super().__init__(transform, root)\n",
    "    self.labels = self.get_labels()\n",
    "\n",
    "  def get_labels(self):\n",
    "    # Collect all unique labels\n",
    "    labels = set()\n",
    "    for i in range(len(self)):\n",
    "      item = super(customSpeechCommandsDataset, self).__getitem__(i)\n",
    "      labels.add(item[2])\n",
    "     # Sort labels and return it as a list\n",
    "    return sorted(list(labels)) \n",
    "\n",
    "  # Override \n",
    "  def __getitem__(self, n):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\n",
    "    # Return only waveform and class_num\n",
    "    return (waveform[0], self.labels.index(label))\n",
    "\n",
    "transform = torch.nn.Sequential(\n",
    "    Resample(16000, 8000),\n",
    "    PadWaveform(8000))\n",
    "\n",
    "speech_commands_dataset = customSpeechCommandsDatasetFinal(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes\", speech_commands_dataset.labels)\n",
    "print(\"Classes num\", len(speech_commands_dataset.labels))\n",
    "\n",
    "wave, cls_num = speech_commands_dataset[0]\n",
    "print(f'wave.shape: {wave.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и валидационную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(speech_commands_dataset)\n",
    "print(\"Total length\", total_len)\n",
    "\n",
    "# To speedup  use only 10% of data\n",
    "use_only = int(total_len * 0.1)\n",
    "to_skip,to_use = torch.utils.data.random_split(speech_commands_dataset, [total_len - use_only, use_only])\n",
    "\n",
    "# Split to train and validation set\n",
    "val_len = int(len(to_use) * 0.1)\n",
    "train_set, val_set = torch.utils.data.random_split(to_use, [len(to_use) - val_len, val_len])\n",
    "print(\"Train dataset length\", len(train_set))\n",
    "print(\"Validation dataset length\", len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another simple black-box model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def validate(model):\n",
    "  data_loader = torch.utils.data.DataLoader(val_set, batch_size=256, shuffle=False)\n",
    "  accuracy = []\n",
    "  for batch in data_loader:\n",
    "    waveforms, class_nums  = batch \n",
    "    y_pred = model.predict(waveforms)\n",
    "    accuracy.append(metrics.accuracy_score(class_nums, y_pred))\n",
    "  print(\"Accuracy:\", np.array(accuracy).mean())\n",
    "  return np.array(accuracy).mean()\n",
    "\n",
    "model = SGDClassifier(loss='log')  \n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=1024, shuffle=True)\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(5):\n",
    "  for batch in data_loader:\n",
    "    waveforms, class_nums  = batch\n",
    "    model.partial_fit(waveforms, class_nums,range(35))\n",
    "  accuracy = validate(model)\n",
    "  accuracy_list.append(accuracy)\n",
    "\n",
    "plt.plot(accuracy_list)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], [1, 2, 3, 4, 5])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Модель не обучается. Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обзор видов связности данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Причины этого в количестве связей между элементами данных.\n",
    "Мы имеем дело с временным рядом. \n",
    "\n",
    "Аудиозапись — это набор измерений (давления на мембране микрофона), произведённых последовательно. \n",
    "\n",
    "То есть в каждый момент времени сигнал связан с предыдущим. \n",
    "Если мы перемешаем их, получится какофония. \n",
    "\n",
    "Так же, как если перемешать слова в предложении или буквы в слове."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/audio_data_type.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таких случаях мы тоже можем представить данные как вектор, но модель, которой мы подадим его на вход, должна учитывать связи между соседними элементами этого вектора.\n",
    "\n",
    "При работе с видео добавляется дополнительное «измерение» — время. \n",
    "\n",
    "Поскольку данные подаются в модель в виде многомерного массива чисел (тензора),  то при работе с видео меняется только размерность этого массива:  в нём появляется дополнительное измерение.\n",
    "\n",
    "С точки зрения PyTorch данные — это некоторый массив, у него может быть 1-2-3 измерения, но нам важно понимать, какие между ними существуют связи. От этого зависит, какой моделью мы будем их обрабатывать.\n",
    "\n",
    "Для работы с этими данными нужна модель, которая эти связи будет учитывать, например рекуррентная  или свёрточная сеть.\n",
    "С её помощью можно получить точность >85%:\n",
    "\n",
    "[Speech Command Recognition with torchaudio](https://pytorch.org/tutorials/intermediate/speech_command_classification_with_torchaudio_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Работа с изображениями "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет CIFAR-10. Он состоит из 60000 цветных изображений размером 32x32. На картинках объекты 10 классов.\n",
    "\n",
    "Для его загрузки используем библиотеку torchvision.\n",
    "\n",
    "В отличие от torchaudio, пакет torchvision входит в число предустановленных в colab.\n",
    "\n",
    "Датасеты из torcvision изначально поддерживают механизм transforms \n",
    "и разбивку на тестовые и проверочные подмножества. Нам не придется добавлять их вручную.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_set = datasets.CIFAR10(\"content\", train=True,  download=True)\n",
    "val_set = datasets.CIFAR10(\"content\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем несколько картинок вместе с метками. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "\n",
    "# load labels names for visualization\n",
    "with open(\"content/cifar-10-batches-py/batches.meta\", 'rb') as infile:\n",
    "  cifar_meta = pickle.load(infile)\n",
    "labels_name = cifar_meta['label_names']\n",
    "\n",
    "for j in range(10):\n",
    "  img, label = train_set[j]\n",
    "  plt.subplot(1, 10 ,j + 1)\n",
    "  plt.imshow(img)\n",
    "  plt.axis('off')  \n",
    "  plt.title(labels_name[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, в каком виде хранятся картинки в памяти:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оказывается, в формате [PIL](https://pillow.readthedocs.io/en/stable/reference/Image.html).\n",
    "\n",
    "Чтобы обучать модель, нам придётся преобразовать их в тензоры. \n",
    "Используем для этого transforms и Dataloder.\n",
    "\n",
    "Выведем размеры получившихся тензоров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "val_set.transform = transforms.Compose([transforms.ToTensor()]) # PIL Image to Pytorch tensor\n",
    "val_loader = DataLoader(val_set, batch_size=8, shuffle=False)\n",
    "\n",
    "for batch in val_loader:\n",
    "  imgs, labels = batch\n",
    "  print(len(batch))\n",
    "  print(\"Images: \", imgs.shape)\n",
    "  print(\"Labels: \", labels.shape)\n",
    "  print(labels)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разберемся с размерностями:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На каждой итерации dataloader возвращает кортеж из двух элементов.\n",
    "* Первый элемент — это изображения;\n",
    "* Второй — метки классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество элементов в каждом равно batch_size, в данном примере — 8.\n",
    "\n",
    "Изображение:  \n",
    "3 - C, каналы (В отличие от PIL и OpenCV они идут сначала);  \n",
    "32 - H, высота;  \n",
    "32 - W, ширина.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки:  \n",
    "числа от 0 до 9 по количеству классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим модель-заглушку \n",
    "\n",
    "Она не будет ничего предсказывать, только возвращать случайный номер класса.\n",
    "\n",
    "В методе fit данные просто запоминаются. Этот фрагмент кода можно будет использовать при выполнении практического задания.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeModel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.train_data = None\n",
    "    self.train_labels = None\n",
    "\n",
    "  def fit(self, x, y):\n",
    "    # Simple store all data\n",
    "    self.train_data = torch.vstack((self.train_data, x)) if self.train_data != None else x\n",
    "    self.train_labels = torch.hstack((self.train_labels, y)) if self.train_labels != None else y\n",
    "   \n",
    "  def forward(self, x):\n",
    "    # x is a batch, not a single sample!\n",
    "    # Return random number instead of predictions\n",
    "    class_count = torch.unique(self.train_labels).shape[0]\n",
    "    # https://pytorch.org/docs/stable/generated/torch.randint.html#torch-randint\n",
    "    # size is shape of output tensor\n",
    "    label = torch.randint(low=0, high=class_count - 1, size=(x.shape[0],)) \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Запустим процесс \"обучения\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.transform = transforms.Compose([transforms.ToTensor(),]) # PIL Image to Pytorch tensor\n",
    "train_loader = DataLoader(train_set, batch_size=1024, shuffle=True)\n",
    "\n",
    "model = FakeModel()\n",
    "\n",
    "for img_batch, labels_batch in train_loader:\n",
    "  model.fit(img_batch, labels_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим работу модели на нескольких изображениях из тестового набора данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, label_batch = next(iter(val_loader))\n",
    "predicted_labels = model(img_batch)\n",
    "\n",
    "for i, predicted_label in enumerate(predicted_labels):\n",
    "  img = img_batch[i].permute(1, 2, 0).numpy() * 255  \n",
    "  plt.subplot(1, len(predicted_labels), i + 1)\n",
    "  plt.imshow(img.astype(int))\n",
    "  plt.axis('off')\n",
    "  plt.title(labels_name[int(predicted_label)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем точность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = []\n",
    "for img_batch, labels_batch in val_loader:\n",
    "  predicted = model(img_batch)\n",
    "  batch_accuracy = accuracy_score(labels_batch, predicted)\n",
    "  accuracy.append(batch_accuracy)\n",
    "\n",
    "print(\"Accuracy\", torch.tensor(accuracy).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем повышать точность. В ходе выполнения практического задания заменим заглушку в методе predict реальным алгоритмом. Используем алгоритм:\n",
    "\n",
    "[K- Nearest Neighbor](https://colab.research.google.com/drive/1_5tGxAoxrWulPmwK2Ht9BHGsS-EpxVo0?usp=sharing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация изображений при помощи алгоритма k-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что мы работаем с тренировочным датасетом CIFAR 10 и хотим решить хрестоматийную задачу классификации: определить те картинки и тестового набора данных, которые относятся к классу cat. Эта задача является частным примером общей задачи классификации данных CIFAR 10, разные подходы к решению которой мы ещё неоднократно рассмотрим в ходе первых лекций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет CIFAR 10 содержит, как следует из названия, 10 различных классов изображений:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/knn_on_cifar10.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все изображения представляют собой матрицы чисел, которые кодируют цвета отдельных пикселей. Для изображений высоты $H$, ширины $W$ с $C$ цветовыми каналами получаем упорядоченный набор  $H \\times W \\times C$ чисел. В данном разделе пока не будем учитывать, что значения соседних пикселей изображения могут быть значительно связаны и будем решать задачу классификации для наивного представления изображения в виде точки в  $H \\times W \\times C$-мерном вещественном пространстве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/img_to_array.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет CIFAR 10 содержит цветные (трехцветные) изображения размером $32 \\times 32$ пикселя. Таким образом, каждое изображение из датасета является точкой в $3072$-мерном ($32 \\times 32 \\times 3 = 3072$) вещественном пространстве (подумайте, почему обратное соответствие не справедливо)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Близость изображений согласно определенной метрике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пара изображений будет выглядеть практически идентично, если значения цветов соответствующих пикселей будут похожи по величине. Другими словами, практически идентичным изображениям будут соответствовать **близкие** точки нашего многомерного вещественного пространства. Для численной характеристики **близости**, можно определить функцию подсчета расстояния между парой точек — метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известны различные способы задания [функции расстояния между парой точек](https://en.wikipedia.org/wiki/Metric_space). Простейшим примером является широко известная **Евклидова** ($L_2$) метрика:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L_2 (X, Y) = \\sqrt{\\sum_i (X_i - Y_i)^2,}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но, кроме неё, величина расстояния между парой точек может быть выражена рядом других функций.\n",
    "\n",
    "$L_1$-расстояние (манхэттенская метрика):\n",
    "$$L_1 (X, Y) = \\sum_i |X_i - Y_i|,$$\n",
    "\n",
    "угловое расстояние:\n",
    "$$ang (X, Y) = \\frac{1}{\\pi} \\arccos \\frac{\\sum_i X_i Y_i}{\\sqrt{\\sum_i X_i^2} \\sqrt{\\sum_i Y_i^2}} ,$$\n",
    "\n",
    "и многие другие. От выбора конкретной функции расстояния между точками будет явно зависеть представление о **близости** точек --- объекты, близкие по одной из метрик, вовсе не обязаны оказаться близкими по согласно другой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем вычислить $L_1$ расстояние между несколькими первыми изображениями из тестового набора данных CIFAR 10 с использованием реализованного пакете [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html#sklearn.metrics.DistanceMetric.get_metric) класса `sklearn.metrics.DistanceMetric`\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/metric_to_compare_train_and_test_imgs.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from torchvision.datasets\n",
    "\n",
    "train_set = datasets.CIFAR10(\"content\", train=True,  download=True)\n",
    "val_set = datasets.CIFAR10(\"content\", train=False, download=True)\n",
    "labels_names = train_set.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем три изображения из тестового набора данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = train_set.data[0]\n",
    "img_2 = train_set.data[1]\n",
    "img_3 = train_set.data[2]\n",
    "\n",
    "fix, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "ax[0].set_title('First image in CIFAR10 train data')\n",
    "ax[0].imshow(img_1)\n",
    "ax[1].set_title('Second image in CIFAR10 train data')\n",
    "ax[1].imshow(img_2)\n",
    "ax[2].set_title('Fird image in CIFAR10 train data')\n",
    "ax[2].imshow(img_3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся библиотечной реализацией $L_1$ метрики для вычисления матрицы попарных расстояний между данными изображениями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import DistanceMetric\n",
    "\n",
    "dist = DistanceMetric.get_metric('manhattan')\n",
    "pairwise_dist = dist.pairwise([img_1.flatten(), img_2.flatten(), img_3.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "im = ax.imshow(pairwise_dist)\n",
    "\n",
    "# Show all ticks and label them with the respective list entries\n",
    "ax.set_xticks(np.arange(len(pairwise_dist)))\n",
    "ax.set_yticks(np.arange(len(pairwise_dist)))\n",
    "ax.set_xticklabels([f'img{i}' for i in range(1, 4)])\n",
    "ax.set_yticklabels([f'img{i}' for i in range(1, 4)])\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(pairwise_dist)):\n",
    "    for j in range(len(pairwise_dist)):\n",
    "        text = ax.text(j, i, \"{:0.2f}\".format(pairwise_dist[i, j]),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "ax.set_title(\"Pairwise L_1 distance for first 3 images in CIFAR 10 \")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассматривая аналогичные примеры, можно выявить что $L_1$ расстояние между изображениями одного и того же класса может оказаться меньше, нежели чем расстояние между объектами разных классов. Действительно, давайте рассчитаем среднее расстояние между объектами разных классов для CIFAR 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "# in order to limit computational time\n",
    "index_limiter = 1000\n",
    "# convert all (32,32,4) images into (32*32*4) vectors\n",
    "flattened_images = val_set.data.reshape(val_set.data.shape[0], -1)[:index_limiter]\n",
    "\n",
    "classwise_distance = np.zeros((len(val_set.classes), len(val_set.classes)))\n",
    "\n",
    "# iterate over all pair of classes and slice their members\n",
    "for class_id_i, class_name_i in enumerate(val_set.classes):\n",
    "    class_i_mask = np.asarray(val_set.targets[:index_limiter]) == class_id_i\n",
    "    \n",
    "    for class_id_j, class_name_j in enumerate(val_set.classes):\n",
    "        class_j_mask = np.asarray(val_set.targets[:index_limiter]) == class_id_j\n",
    "        \n",
    "        #manhattan_distances returns pairwise distance matrix for samples \n",
    "        # so in order to get mean distance for classes one should calc mean \n",
    "        # value over its higher triangle part or simply calc mean over whole matrix \n",
    "        # and divide by 2.0\n",
    "        classwise_distance[class_id_i, class_id_j] = np.mean(manhattan_distances(\n",
    "            flattened_images[class_i_mask],\n",
    "            flattened_images[class_j_mask]\n",
    "        )) / 2.\n",
    "        \n",
    "fig, ax = plt.subplots(figsize = (7, 7))\n",
    "im = ax.imshow(classwise_distance)\n",
    "\n",
    "# Show all ticks and label them with the respective list entries\n",
    "ax.set_xticks(np.arange(len(val_set.classes)))\n",
    "ax.set_yticks(np.arange(len(val_set.classes)))\n",
    "ax.set_xticklabels(val_set.classes)\n",
    "ax.set_yticklabels(val_set.classes)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "ax.set_title(\"Mean class-wise Мanhattan distance for CIFAR 10\")\n",
    "fig.tight_layout()\n",
    "fig.colorbar(im);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, среди первых 1000 картинок тестовой части датасета CIFAR 10 есть значительное число обособленных классов, для которых выполняется описанное выше отношение близости. Например, это справедливо для классов кораблей, оленей и лягушек. Идея о том, что близость объектов по некоторой метрике и их принадлежность к одному определённому классу связаны, является основой известного алгоритма классификации и регрессии — K Nearest Neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-ближайших соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Метод k-ближайших соседей](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) (англ. k-nearest neighbors algorithm, k-NN) — метрический алгоритм для решения задач классификации или регрессии.\n",
    "\n",
    "Простейшая классификация методом k-NN выполняется следующим образом:\n",
    "\n",
    "1. Рассматриваются объекты из обучающей выборки, для которых известно, к какому классу они принадлежат.\n",
    "1. Между подлежащими классификации объектами и объектами тренировочной выборки вычисляется матрица попарных расстояний согласно выбранной метрике.\n",
    "1. На основе полученной матрицы расстояний для каждого из подлежащих классификации объектов определяется k ближайших объектов тренировочной выборки - k ближайших соседей.\n",
    "1. Подлежащим классификации объектам приписывается тот класс, который чаще всего встречается у их k ближайших соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/knn_idea.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера работы с алгоритмом k-NN классифицируем изображение корабля из тестовой выборки CIFAR 10 с использованием [реализации алгоритма в scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors_graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ship_img = val_set.data[18]\n",
    "\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "plt.imshow(sample_ship_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# in order to limit computational time\n",
    "index_limiter = 5000\n",
    "x = train_set.data.reshape(train_set.data.shape[0], -1)[:index_limiter]\n",
    "y = train_set.targets[:index_limiter]\n",
    "\n",
    "for metric_type in ['euclidean', 'manhattan', 'chebyshev']:\n",
    "    print()\n",
    "    for k in range(3, 7, 1):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric=metric_type)\n",
    "        knn.fit(x, y)\n",
    "        result_class_id = knn.predict([sample_ship_img.flatten()])[0]\n",
    "        result_class = train_set.classes[result_class_id]\n",
    "        print(f'{k}-NN with {metric_type} metric\\npredicted class is: {result_class}\\n' )"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
