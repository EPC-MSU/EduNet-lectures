{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение на реальных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С какими проблемами чаще всего сталкиваются люди, работающие с машинным обучением, в реальной жизни?\n",
    "- нехватка данных\n",
    "- недостаток размеченных данных\n",
    "- не качественная разметка\n",
    "- низкое качество изображений\n",
    "- не сбалансированность датасета\n",
    "- переобучение\n",
    "- **какие еще?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Как решить проблему малого количества данных?](https://towardsdatascience.com/breaking-the-curse-of-small-datasets-in-machine-learning-part-1-36f28b0c044d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ResNet (популярная архитектура для классификации изображений), заняла 1-е место в классификационном конкурсе ILSVRC 2015 с улучшением примерно на 50% по сравнению с предыдущим уровнем развития техники. ResNet не только имела очень сложную и глубокую архитектуру, но и была обучена на 1,2 млн изображений.\n",
    "\n",
    "Как в отрасли, так и в академических кругах хорошо известно, что при достаточно большом количестве данных, очень разные алгоритмы DL работают практически одинаково. Следует отметить, что большие данные должны содержать значимую информацию, а не просто шум, чтобы модель могла извлекать уроки из них. -->\n",
    "\n",
    "На рисунке показаны основные проблемы, с которыми приходится сталкиваться при работе с небольшими наборами данных, а также возможные подходы и методы их решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_33.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Работа с несбалансированным датасетом\n",
    "\n",
    "Сначала, давайте рассмотрим методы работы с датасетами в которых классы представлены не равномерно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем датасет"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns\n",
    "\n",
    "x, y = make_classification(n_samples=10000, n_features=10, n_classes=2)\n",
    "sns.displot(y, height=4)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь его испортим (изменим соотношение класса `0` и класса `1`)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_new = np.random.choice(y[y == 1], size=np.int(0.1 * len(y[y == 1])))\n",
    "y_new = np.hstack([y[y == 0], y_new])\n",
    "x_new = x[y_new]\n",
    "\n",
    "sns.displot(y_new, height=4)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Что можно сделать, что бы как-то улучшить ситуацию используя методы ML:\n",
    "\n",
    "- **Измените функцию потерь**: для задач классификации мы часто используем кросс-энтропийную потерю и редко используем среднюю абсолютную ошибку или среднеквадратичную ошибку для обучения и оптимизации нашей модели.\n",
    "\n",
    "- В случае несбалансированных данных, модель учится распознавать доминирующий класс чаще чем все остальные, соответственно, она выучивает статистическое распределение классов и считает что чем чаще она предсказывает этот класс - тем меньше она ошибается. Что бы как-то решить эту проблему - мы можем **добавить веса к потерям**, соответствующим различным классам, чтобы выровнять это смещение данных. Например, если у нас есть два класса в соотношении 4:1, мы можем применить веса в соотношении 1:4 к вычислению функции потерь, чтобы данные были сбалансированы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот метод помогает нам легко смягчить проблему несбалансированных данных и улучшить обобщение модели для разных классов. Например:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\"balanced\", np.unique(y_new), y_new)\n",
    "class_weights"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы также можем указать явные веса классов в соответствии с нашими требованиями.\n",
    "\n",
    "Дополнительные сведения смотри в документации Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Create decision tree classifer object\n",
    "# clf = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "\n",
    "# # Train model\n",
    "# model = clf.fit(x, y_new)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один способ решение проблемы несбалансированных данных - собственно их балансирование. Это может быть сделано либо за счет увеличения частоты класса меньшинства (_oversampling_), либо за счет уменьшения частоты класса большинства (_undersampling_) с помощью методов случайной или кластерной выборки.\n",
    "\n",
    "Обычно _oversampling_ предпочтителен, когда общий размер данных небольшой, а _undersampling_ полезен, когда у нас есть большой объем данных. Точно так же случайная или кластерная выборка определяется тем, насколько хорошо распределены данные.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_34.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот тут можно прочитать подробнее: [Imbalanced Data : How to handle Imbalanced Classification Problems](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/)\n",
    "\n",
    "`Resampling` может быть легко выполнен с помощью пакета [imbalanced-learn](https://pypi.org/project/imbalanced-learn/), как показано ниже:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(x_new, y_new)\n",
    "sns.displot(y_res, height=3)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Генерация синтетических данных: \n",
    "\n",
    "хотя `oversampling` или `undersampling` помогает сбалансировать данные, дублирование данных увеличивает вероятность переобучения.\n",
    "\n",
    "Другой подход к решению этой проблемы - создание синтетических данных с помощью данных о классе меньшинств.\n",
    "\n",
    "**Synthetic Minority Over-sampling Technique (SMOTE)** или **Modified- SMOTE** - два таких метода, которые генерируют синтетические данные. Проще говоря, SMOTE берет точки данных класса меньшинства и создает новые точки данных, которые лежат между любыми двумя ближайшими точками данных, соединенными прямой линией.\n",
    "\n",
    "Для этого алгоритм вычисляет расстояние между двумя точками данных в пространстве признаков, умножает расстояние на случайное число от 0 до 1 и помещает новую точку данных на этом новом расстоянии от одной из точек данных, используемых для определения расстояния.\n",
    "\n",
    "Обратите внимание, что количество ближайших соседей, учитываемых для генерации данных, также является гиперпараметром и может быть изменено в зависимости от требований."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_35.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M-SMOTE - это модифицированная версия SMOTE, которая также принимает во внимание базовое распределение класса меньшинства.\n",
    "\n",
    "Алгоритм классифицирует образцы классов меньшинств на 3 отдельные группы - образцы безопасности / безопасности, образцы границ и образцы скрытого шума.\n",
    "\n",
    "Это делается путем вычисления расстояний между выборками класса меньшинства и выборками обучающих данных.\n",
    "\n",
    "В отличие от SMOTE, алгоритм случайным образом выбирает точку данных из k ближайших соседей для выборки безопасности, выбирает ближайшего соседа из выборок границ и ничего не делает для устранения скрытого шума.\n",
    "\n",
    "Вот тут можно прочитать подробнее: [SMOTE explained for noobs - Synthetic Minority Over-sampling TEchnique line by line](https://rikunert.com/SMOTE_explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обнаружение аномалий / изменений\n",
    "\n",
    "В случае сильно несбалансированных наборов данных, таких как мошенничество или машинный сбой, стоит задуматься, могут ли такие примеры рассматриваться как аномалия (выброс) или нет. Если такое событие и впрямь может считаться аномальным, мы можем использовать такие модели, как `OneClassSVM`, методы кластеризации или методы обнаружения гауссовских аномалий.\n",
    "\n",
    "Эти методы требуют изменения способа мышления: мы будем рассматривать аномалии, как отдельный класс выбросов. Это может помочь нам найти новые способы разделения и классификации.\n",
    "\n",
    "Обнаружение изменений похоже на обнаружение аномалий, за исключением того, что мы ищем изменение или отличие, а не аномалию. Это могут быть изменения в поведении пользователя, наблюдаемые по шаблонам использования или банковским транзакциям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберем пример обнаружения аномалий с помощью `OneClassSVM` из библиотеки Sk-Learn (там же, можно найти еще множеество различных алгоритмов)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.datasets import make_blobs\n",
    "from numpy import quantile, where, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Создадим датасет\n",
    "random.seed(42)\n",
    "x, _ = make_blobs(n_samples=1000, centers=1, cluster_std=1.1, center_box=(0, 0))\n",
    "plt.scatter(x[:, 0], x[:, 1], alpha=0.25)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим наш детектор аномалий"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "svm = OneClassSVM(kernel=\"rbf\", gamma=0.01, nu=0.03)\n",
    "print(svm)\n",
    "svm.fit(x)\n",
    "pred = svm.predict(x)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продемонстрируем аномальные точки предсказанные детектором"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "anom_index = where(pred == -1)\n",
    "values = x[anom_index]\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1], alpha=0.25)\n",
    "plt.scatter(values[:, 0], values[:, 1], color=\"r\", marker=\"x\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Методы объединения (Ensembling Techniques): \n",
    "\n",
    "Помимо того, что бы делать что-то с данными, мы можем попробовать сделать что-то с самой моделью. \n",
    "Идея объединения нескольких слабых учеников / разных моделей показала отличные результаты при работе с несбалансированными наборами данных.\n",
    "\n",
    "`Bagging` и `Boosting` методы также показали отличные результаты при решении различных задач, и их следует изучить вместе с методами, описанными выше, для получения лучших результатов.\n",
    "\n",
    "Вот тут подробнее: [Imbalanced Data : How to handle Imbalanced Classification Problems](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "Мы рассмотрели несколько наиболее часто используемых методов работы с несбалансированными данными для традиционных алгоритмов машинного обучения.\n",
    "\n",
    "Один или многие из вышеперечисленных методов могут быть хорошей отправной точкой в ​​зависимости от конкретной бизнес-задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [8 тактик борьбы с несбалансированными классами в наборе данных машинного обучения](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Определите, можете ли вы собрать больше данных?**\n",
    "2. **Попробуйте изменить метрику оценки модели.**\n",
    "    Accuracy не является показателем, который следует использовать при работе с несбалансированным набором данных. [Есть метрики, которые были разработаны для работы с несбалансированными классами.](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/#:~:text=Classification%20Accuracy%20is%20Not%20Enough%3A%20More%20Performance%20Measures%20You%20Can%20Use,-By%20Jason%20Brownlee&text=When%20you%20build%20a%20model,This%20is%20the%20classification%20accuracy)\n",
    "\n",
    "3. **Применить `Resampling`** (см. выше)\n",
    "4. **Попробовать создать синтетические образцы данных**\n",
    "5. **Не следует использовать свой любимый алгоритм для каждой задачи.**\n",
    "    Необходимо проверять различные типы алгоритмов для решения конкретной проблемы. Например, `Random Forest` часто хорошо работает с несбалансированными наборами данных.\n",
    "6. **Попробуйте модели с санкциями**\n",
    "    Штрафная классификация накладывает дополнительные штрафы на модель за ошибки классификации в классе меньшинства во время обучения. Эти штрафы могут склонить модель к уделению большего внимания классу меньшинства.\n",
    "7. **Попробуйте другую точку зрения**\n",
    "    Есть области исследований, посвященные несбалансированным наборам данных. Двe, которые вы могли бы рассмотреть, - это [обнаружение аномалий](https://en.wikipedia.org/wiki/Anomaly_detection) и [обнаружение изменений](https://en.wikipedia.org/wiki/Change_detection).\n",
    "8. **[Попробуйте проявить творческий подход](https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set)**\n",
    "    По-настоящему залезьте внутрь своей проблемы и подумайте, как разбить ее на более мелкие проблемы, которые легче решить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перейдем к особенностям работы с несбалансированными классами в моделях нейронных сетей**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Аугментация](https://en.wikipedia.org/wiki/Data_augmentation)\n",
    "\n",
    "Сам термин пришел из музыки:\n",
    "\n",
    "**Аугмента́ция** (позднелат. augmentatio — увеличение, расширение) — [техника ритмической композиции в старинной музыке](https://ru.wikipedia.org/wiki/Аугментация).\n",
    "\n",
    "Сейчас такая работа с данными активно применяется в работе с изображениями, но ее можно использоваться и для сигналов, и, иногда, для табличных данных.\n",
    "\n",
    "Модели глубокого обучения обычно требуют большого количества данных для обучения. В целом, чем больше данных, тем лучше для обучения модели.\n",
    "\n",
    "Но получение огромных объемов данных сопряжено со своими проблемами.\n",
    "\n",
    "Вместо того, чтобы тратить дни на сбор данных вручную, мы можем использовать методы увеличения их числа путем генерации новых из уже имеющихся.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_12.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры аугументации в [TORCHVISION.TRANSFORMS](https://pytorch.org/vision/stable/transforms.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "os.chdir('/content')\n",
    "# скачаем необходимые файлы\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=11LBkRRlagM4ijHsXkytgSae4NJtW98sB' -O data.zip\n",
    "with ZipFile('data.zip', 'r') as folder: # Create a ZipFile Object and load sample.zip in it\n",
    "    folder.extractall() # Extract all the contents of zip file in current directory\n",
    "clear_output()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "os.chdir(\"/content/for_transforms.Compose\")\n",
    "img_list = os.listdir()\n",
    "img_list"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class AugmentationDataset(Dataset):\n",
    "    def __init__(self, image_list, transforms=None):\n",
    "        self.image_list = image_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = plt.imread(self.image_list[i])\n",
    "        img = Image.fromarray(img).convert(\"RGB\")\n",
    "        img = np.array(img).astype(np.uint8)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return torch.tensor(img, dtype=torch.float)\n",
    "\n",
    "\n",
    "def show_img(img):\n",
    "    plt.figure(figsize=(40, 38))\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует несколько методов аугментации изображений, и мы обсудим некоторые из наиболее распространенных и широко используемых.\n",
    "\n",
    "Вы можете попробовать другие методы в соответствии с вашими требованиями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Rotation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((164, 164)),\n",
    "        transforms.RandomRotation(50, expand=True),\n",
    "        transforms.Resize((164, 164)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "Augmentation_dataloader = DataLoader(\n",
    "    AugmentationDataset(img_list, transform), batch_size=8, shuffle=True\n",
    ")\n",
    "\n",
    "data = iter(Augmentation_dataloader)\n",
    "show_img(torchvision.utils.make_grid(data.next()))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cropping"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((164, 164)),\n",
    "        transforms.RandomCrop((120, 120)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "Augmentation_dataloader = DataLoader(\n",
    "    AugmentationDataset(img_list, transform), batch_size=8, shuffle=True\n",
    ")\n",
    "\n",
    "data = iter(Augmentation_dataloader)\n",
    "show_img(torchvision.utils.make_grid(data.next()))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Perspective"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((164, 164)),\n",
    "        transforms.RandomPerspective(distortion_scale=0.5, p=1.0),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "Augmentation_dataloader = DataLoader(\n",
    "    AugmentationDataset(img_list, transform), batch_size=8, shuffle=True\n",
    ")\n",
    "\n",
    "data = iter(Augmentation_dataloader)\n",
    "show_img(torchvision.utils.make_grid(data.next()))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((164, 164)),\n",
    "        transforms.GaussianBlur(7, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "Augmentation_dataloader = DataLoader(\n",
    "    AugmentationDataset(img_list, transform), batch_size=8, shuffle=True\n",
    ")\n",
    "\n",
    "data = iter(Augmentation_dataloader)\n",
    "show_img(torchvision.utils.make_grid(data.next()))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Erasing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((164, 164)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "Augmentation_dataloader = DataLoader(\n",
    "    AugmentationDataset(img_list, transform), batch_size=8, shuffle=True\n",
    ")\n",
    "\n",
    "data = iter(Augmentation_dataloader)\n",
    "show_img(torchvision.utils.make_grid(data.next()))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует и более сложные способы аугментации:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Mixup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_16.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Аугументация при помощи синтеза данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_17.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В домашнем задании Вам предстоит провести эксперимент: обучить нейронную сеть на датасете без аугментации, и после нее.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме методов, реализованных в Pytorch, существуют и специализированные библиотеки для аугментации изображений. \n",
    "\n",
    "Например:\n",
    "- [lbumentations](https://albumentations.ai)\n",
    "- [imgaug](https://imgaug.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "**При выборе методов аугментации имеет смысл использовать те, которые будут в реальной жизни. Например, нет смысла делать перевод изображения в черно-белое, если предполагается, что весь входящий поток будет цветным, или отражать человека вверх-ногами, если мы не предполагаем его таким распознавать.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning:\n",
    "----\n",
    "как быстро обучить нейросеть на своих данных, когда их мало\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для таких типовых задач, как классификация изображений, можно воспользоваться готовой архитектурой (AlexNet, VGG, Inception, ResNet и т.д.) и обучить нейросеть на своих данных. Реализации таких сетей с помощью различных фреймворков уже существуют, так что на данном этапе можно использовать одну из них как черный ящик, не вникая глубоко в принцип её работы.\n",
    "\n",
    "Однако, глубокие нейронные сети требовательны к большим объемам данных для сходимости обучения. И зачастую, в нашей частной задаче недостаточно данных для того, чтобы хорошо натренировать все слои нейросети. `Transfer Learning` решает эту проблему. Зачем обучать сеть заново, если можно использовать уже обученную на миллионе изображений и дообучить на свой датасет?\n",
    "\n",
    "В PyTorch есть много предобученных сетей: [TORCHVISION.MODELS](https://pytorch.org/vision/stable/models.html)\n",
    "\n",
    "- AlexNet\n",
    "- VGG\n",
    "- ResNet\n",
    "- SqueezeNet\n",
    "- DenseNet\n",
    "- Inception v3\n",
    "- GoogLeNet\n",
    "- ShuffleNet v2\n",
    "- MobileNetV2\n",
    "- MobileNetV3\n",
    "- ResNeXt\n",
    "- Wide ResNet\n",
    "- MNASNet\n",
    "\n",
    "Для этого,  нужно отключить какие-то промежуточные слои. Тогда можно использовать то, что называется `Fine turning` - не нужно обучать всю модель, а достаточно только ее новую часть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейронные сети, которые используются для классификации, как правило, содержат N выходных нейронов в последнем слое, где N — это количество классов. Такой выходной вектор трактуется как набор вероятностей принадлежности к классу. \n",
    "\n",
    "В реальных задачах распознавания изображений, количество классов может отличаться от того, которое было в исходном датасете. В таком случае нам придётся полностью выкинуть этот последний слой и поставить новый, с нужным количеством выходных нейронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_21.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зачастую в конце классификационных сетей используется полносвязный слой. Так как мы заменили этот слой, использовать предобученные веса для него уже не получится. Придется тренировать его с нуля, инициализировав его веса случайными значениями. Веса для всех остальных слоев мы загружаем из предобученной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют различные стратегии дообучения модели. Мы воспользуемся следующей: будем тренировать всю сеть из конца в конец (end-to-end), а предобученные веса не будем фиксировать, чтобы дать им немного скорректироваться и подстроиться под наши данные. Такой процесс называется тонкой настройкой (fine-tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Структурные компоненты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи нам понадобятся следующие компоненты:\n",
    "\n",
    "1. Описание модели нейросети\n",
    "2. Пайплайн обучения\n",
    "3. Инференс пайплайн\n",
    "4. Предобученные веса для этой модели\n",
    "5. Данные для обучения и валидации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/L11_1.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код обучения модели состоит из следующих шагов:\n",
    "\n",
    "1. Построение train/validation пайплайнов данных\n",
    "2. Построение train/validation графов (сетей)\n",
    "3. Надстраивание классификационной функция потерь (cross entropy loss) поверх train графа\n",
    "4. Код, необходимый для вычисления точности предсказания на валидационной выборке во время обучения\n",
    "5. Логика загрузки предобученных весов из снэпшота\n",
    "6. Создание различных структур для обучения\n",
    "7. Непосредственно сам цикл обучения (итерационная оптимизация)\n",
    "\n",
    "Последний слой графа конструируется с нужным нам количеством нейронов и исключается из списка параметров, загружаемых из предобученного снэпшота.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель\n",
    "\n",
    "Давайте рассмотрим пример практической реализации такого подхода ([код переработан из этой статьи](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "os.chdir('/content')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!wget 'https://download.pytorch.org/tutorial/hymenoptera_data.zip'\n",
    "!unzip hymenoptera_data.zip\n",
    "clear_output()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на аугментацию изображений нашего датасета!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/content/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "print(dataset_sizes)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас не так уж и много изображений!! Обычная нейронка справиться не должна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим предобученную ResNet с сохранением весов"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_ft = models.resnet18(pretrained=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку большинство параметров в нашей предварительно обученной модели уже обучены, мы сбрасываем значение поля requires_grad в значение false."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Freeze model parameters\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы заменяем последний слой модели Alexnet одним последовательным слоем с 4096 нейронами и который имеет `num_classes` выходов, соответствующих числу классов в нашем подмножестве.\n",
    "\n",
    "То есть мы \"сказали\" нашей модели распознавать не 1000, а только 2 класса."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы определяем функцию потерь и оптимизатор, который будет использоваться для обучения.\n",
    "\n",
    "Мы используем функцию Cross Entropy Loss, поскольку она полезна для классификации нескольких классов.\n",
    "\n",
    "И оптимизатор Adam - один из самых популярных оптимизаторов, потому что он может адаптировать скорость обучения для каждого параметра индивидуально."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define Optimizer and Loss Function\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "optimizer_ft"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тренировки и валидации нашей можели напишем отдельную функцию, которую итмеет смысл изучить подробнее."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import copy\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=6)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель настолько мощная, а данных так мало, что достаточно 5ти эпох, не смотря на аугментацию изображений.\n",
    "\n",
    "Теперь сделаем предикт на картинках, которые модель не видела"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "visualize_model(model_ft)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы только что увидели, как использовать предварительно обученную модель, обученную для 1000 классов ImageNet.\n",
    "\n",
    "Она очень эффективно классифицирует изображения, принадлежащие к 2 различным классам, которые нас интересуют. Обратите внимание, что горилла иногда очень похожа на медведя!\n",
    "\n",
    "Также мы убедидлись в эффективности такого подхода для обучении классификации на небольшом наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глубокие сверточные нейронные сети стали самыми современными методами для задач классификации изображений. Однако одно из самых больших ограничений - они требуют большого количества размеченных данных.\n",
    "\n",
    "Во многих приложениях иногда невозможно собрать такой объем данных и `One Shot Learning` направлен на решение этой проблемы.\n",
    "\n",
    "Предполагается, что при классификации по методу `One Shot Learning` нам требуется только один обучающий пример для каждого класса. Отсюда и название One Shot. Давайте попробуем разобраться на реальном практическом примере.\n",
    "\n",
    "Предположим, мы хотим создать систему распознавания лиц для небольшой организации, в которой всего 10 сотрудников (небольшое количество упрощает задачу).\n",
    "\n",
    "Используя традиционный подход к классификации, мы можем придумать систему, которая выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/OShL1.jpeg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблемы:\n",
    "\n",
    "а) Чтобы обучить такую ​​систему, нам сначала потребуется много разных изображений каждого из 10 человек в организации, что может оказаться невозможным. (Представьте, что вы делаете это для организации с тысячами сотрудников).\n",
    "\n",
    "б) Что делать, если новый человек присоединяется к организации или покидает ее? Вам нужно снова взять на себя боль сбора данных и заново обучить всю модель.\n",
    "\n",
    "Это практически невозможно, особенно для крупных организаций, где набор и увольнение происходит почти каждую неделю.\n",
    "\n",
    "Теперь давайте разберемся, как подойти к этой проблеме, используя классификацию по `One Shot Learning`, которая помогает решить обе указанные выше проблемы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо того, чтобы напрямую классифицировать входное (тестовое) изображение каждого из 10 человек в организации, эта сеть вместо этого принимает дополнительное эталонное изображение человека в качестве входных данных и будет производить оценку сходства, обозначающую шансы того, что два входных изображения принадлежат одному и тому же человеку.\n",
    "\n",
    "Обратите внимание, что эта сеть не учится классифицировать изображение напрямую по какому-либо из выходных классов. Скорее, он изучает функцию подобия, которая принимает два изображения в качестве входных данных и выражает, насколько они похожи.\n",
    "\n",
    "Как это решает две проблемы, о которых мы говорили выше?\n",
    "- Для обучения этой сети нам не требуется слишком много экземпляров класса, а для построения хорошей модели достаточно лишь нескольких экземпляров.\n",
    "- Но самое большое преимущество в простоте ее обучения в случае появления нового сотрудника.\n",
    "\n",
    "Теперь, чтобы сеть могла обнаружить его лицо, нам требуется только одно изображение его лица, которое будет сохранено в базе данных. Используя его в качестве эталонного изображения, сеть будет вычислять сходство для любого нового экземпляра,  представленного ей.\n",
    "\n",
    "Таким образом, мы говорим, что сеть предсказывает счет за `One Shot` (один выстрел)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код, который мы будем использовать, является реализацией методологии, описанной в этой [исследовательской статье](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf) Грегори Коха и др.\n",
    "\n",
    "Архитектура модели соответствует описанию в статье. Но прежде чем углубляться в детали, давайте разберемся с архитектурой на высоком уровне.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/OShL6.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две показанные выше сверточные нейронные сети не являются разными сетями, а представляют собой две копии одной и той же сети, отсюда и название Siamese Networks.\n",
    "\n",
    "В основном они имеют одинаковые параметры.\n",
    "\n",
    "Два входных изображения (x1 и x2) проходят через ConvNet, чтобы сгенерировать вектор признаков фиксированной длины для каждого (h (x1) и h (x2)).\n",
    "\n",
    "Предполагая, что модель нейронной сети обучена правильно, мы можем сделать следующую гипотезу: если два входных изображения принадлежат одному и тому же персонажу, то их векторы признаков также должны быть похожими, а если два входных изображения принадлежат разным символам, то их векторы признаков также будут разными.\n",
    "\n",
    "Таким образом, поэлементная абсолютная разница между двумя векторами признаков должна сильно отличаться в обоих вышеупомянутых случаях. И, следовательно, оценка сходства, генерируемая выходным сигмовидным слоем, также должна быть разной в этих двух случаях.\n",
    "\n",
    "Это центральная идея сиамских сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/OShL5.jpeg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet Loss\n",
    "\n",
    "Для распознавания лиц, мы будем использовать `Triplet loss`, то есть подавать три изображения вместо двух.\n",
    "\n",
    "Триплет состоит из анкора `anchor`, положительного и отрицательного образцов и в основном применяется для распознавания лиц."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/OShL10.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `Triplet loss` расстояние между анкором и положительной выборки минимизировано, а расстояние между анкором и отрицательной выборки максимально."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/OShL8.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L11_Transfer_learning/img/OShL9.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Но можно также использовать и `Contrastive Loss`\n",
    "\n",
    "о ней подробнее в статье [Dimensionality Reduction by Learning an Invariant Mapping](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример реализации сиамской сети\n",
    "---\n",
    "на примере датасета [Georgia Tech face database](http://www.anefian.com/research/face_reco.htm)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, glob, random\n",
    "import shutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as img_transf\n",
    "from torchvision import datasets as ds\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!rm -r data\n",
    "!rm -r GTdb_crop.zip\n",
    "!rm -r GTdb_crop\n",
    "!wget http://www.anefian.com/research/GTdb_crop.zip\n",
    "!unzip GTdb_crop.zip -d /content/GTdb_crop\n",
    "clear_output()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "os.mkdir(\"/content/data\")\n",
    "for i in range(1, 51):\n",
    "    pattern = \"s\" + str(i).zfill(2)\n",
    "    path = \"/content/data/\" + str(pattern)\n",
    "    f = sorted(\n",
    "        glob.glob(os.path.join(\"/content/GTdb_crop/cropped_faces/\", pattern + \"*\"))\n",
    "    )\n",
    "    os.mkdir(path)\n",
    "    [shutil.copy(i, path) for i in f]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "src = \"/content/data/\"\n",
    "d = os.listdir(\"/content/data\")\n",
    "for i in range(3):\n",
    "    r = random.choice(d)\n",
    "    shutil.copytree(src + r, \"/content/data/testing/\" + r)\n",
    "    d.remove(r)\n",
    "else:\n",
    "    for i in sorted(d):\n",
    "        shutil.copytree(src + i, \"/content/data/training/\" + i)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class SiaDataset(Dataset):\n",
    "    def __init__(self, imageDir, image_transforms=None):\n",
    "        self.imageDir = imageDir\n",
    "        self.classes = self.imageDir.classes\n",
    "        self.imgs = self.imageDir.imgs\n",
    "        self.transform = image_transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        self.target = np.random.randint(\n",
    "            0, 2\n",
    "        )  # Выберем либо положительную пару (0), либо отрицательную (1)\n",
    "\n",
    "        img1, label1 = self.imgs[index]  # Выберем первое изображение\n",
    "\n",
    "        new_imgs = list(\n",
    "            set(self.imgs) - set(self.imgs[index])\n",
    "        )  # Создадим новый индекс, что бы не повторять уже выбранное изображение\n",
    "        length = len(new_imgs)\n",
    "\n",
    "        if self.target == 1:\n",
    "            # Найдем отрицательный пример\n",
    "            label2 = label1\n",
    "            while label2 == label1:\n",
    "                choice = np.random.choice(length)\n",
    "                img2, label2 = new_imgs[choice]\n",
    "        else:\n",
    "            # Найдем положительный пример\n",
    "            label2 = label1 + 1\n",
    "            while label2 != label1:\n",
    "                choice = np.random.choice(length)\n",
    "                img2, label2 = new_imgs[choice]\n",
    "\n",
    "        img1 = Image.open(img1).convert(\"RGB\")\n",
    "        img2 = Image.open(img2).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return (img1, img2, self.target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class Siamese(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Siamese, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64 * 11 * 11, 4096), nn.Sigmoid(), nn.Linear(4096, 128)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(-1, 64 * 11 * 11)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        pos = (1 - label) * torch.pow(euclidean_distance, 2)\n",
    "        neg = (label) * torch.pow(\n",
    "            torch.clamp(self.margin - euclidean_distance, min=0.0), 2\n",
    "        )\n",
    "        loss_contrastive = torch.mean(pos + neg)\n",
    "        return loss_contrastive"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Вспомогательная функция\n",
    "def show(img, text=None):\n",
    "    img = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    plt.text(75, 120, text, fontweight=\"bold\")\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Применим аугментации для train\n",
    "im_trans_train = img_transf.Compose(\n",
    "    [\n",
    "        img_transf.Resize((105, 105)),\n",
    "        img_transf.RandomPerspective(),\n",
    "        img_transf.RandomRotation((-15, 15)),\n",
    "        img_transf.RandomHorizontalFlip(),\n",
    "        img_transf.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "        img_transf.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Применим аугментации для test\n",
    "im_trans_test = img_transf.Compose(\n",
    "    [img_transf.Resize((105, 105)), img_transf.ToTensor()]\n",
    ")\n",
    "\n",
    "folder_dataset = ds.ImageFolder(\"/content/data/training\")\n",
    "sia_dataset = SiaDataset(\n",
    "    imageDir=folder_dataset,\n",
    "    image_transforms=im_trans_train,\n",
    ")\n",
    "\n",
    "# Создадим случайную инициализацию seed, что бы каждый раз действительно выбирать новые изображения\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    sia_dataset,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "folder_dataset = ds.ImageFolder(\"/content/data/testing\")\n",
    "\n",
    "siatest_dataset = SiaDataset(\n",
    "    imageDir=folder_dataset,\n",
    "    image_transforms=im_trans_test,\n",
    ")\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    siatest_dataset,\n",
    "    num_workers=2,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    worker_init_fn=worker_init_fn,\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "net = Siamese().to(device)\n",
    "loss_fun = ContrastiveLoss(margin=1.5)\n",
    "optims = optim.Adam(net.parameters(), lr=3e-4)\n",
    "scheduler = ReduceLROnPlateau(optims, \"min\", verbose=True, factor=0.5, patience=3)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "net"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!mkdir saved_weight"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train(n_epoch, net, optims, scheduler, save=True, path=\"saved_weight\"):\n",
    "    counter = []\n",
    "    l = []\n",
    "\n",
    "    iter_num = 0\n",
    "\n",
    "    for epoch in range(0, n_epoch):\n",
    "        np.random.seed()\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            img0, img1, label = data\n",
    "            img0, img1, label = img0.to(device), img1.to(device), label.to(device)\n",
    "            optims.zero_grad()\n",
    "            out = net(img0, img1)\n",
    "            op1, op2 = net(img0, img1)\n",
    "            loss = loss_fun(op1, op2, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optims.step()\n",
    "\n",
    "            if i % 12 == 0:\n",
    "                print(\"Epoch {} with {} loss\".format(epoch, loss.item()))\n",
    "                iter_num += 5\n",
    "                counter.append(iter_num)\n",
    "                l.append(loss.item())\n",
    "                if save:  # будем сохранять все этапы обучения модели\n",
    "                    torch.save(net.state_dict(), path + \"/epoch_%i.pt\" % epoch)\n",
    "                scheduler.step(loss)  # используем подстройку lr при достижении \"плато\"\n",
    "    return counter, l"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "counter, l = train(30, net, optims, scheduler, save=True, path=\"saved_weight\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.plot(counter, l)\n",
    "plt.grid()\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_images(l, path=\"saved_weight\"):\n",
    "    distances_pos = []\n",
    "    distances_neg = []\n",
    "\n",
    "    net = Siamese().to(device)\n",
    "\n",
    "    best_epoch = np.argmin(l)\n",
    "    print(\"Лучшая эпоха: %i. Loss = %.3f\" % (best_epoch, l[best_epoch]))\n",
    "\n",
    "    # Загрузим лучушю эпоху из сохранения\n",
    "    net.load_state_dict(torch.load(path + \"/epoch_%i.pt\" % best_epoch))\n",
    "    net.eval()\n",
    "\n",
    "    for i, data in enumerate(test_dataloader, 0):\n",
    "        img0, img1, label = data\n",
    "        concatenated = torch.cat((img0, img1))\n",
    "        output1, output2 = net(Variable(img0).to(device), Variable(img1).to(device))\n",
    "        distance = F.pairwise_distance(output1, output2)\n",
    "        if label == 0:\n",
    "            distances_pos.append(distance.item())\n",
    "            if i % 50:\n",
    "                show(\n",
    "                    torchvision.utils.make_grid(concatenated),\n",
    "                    \"Один и тот же! Missmatch: {:.3f}\".format(distance.item()),\n",
    "                )\n",
    "        else:\n",
    "            distances_neg.append(distance.item())\n",
    "            if i % 50:\n",
    "                show(\n",
    "                    torchvision.utils.make_grid(concatenated),\n",
    "                    \"Другой человек! Missmatch: {:.3f}\".format(distance.item()),\n",
    "                )\n",
    "    return distances_pos, distances_neg\n",
    "\n",
    "\n",
    "distances_pos, distances_neg = plot_images(l)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так оценить работу сложно, давайте посмотрим на распределение расстояний по категориям"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "distnaces = {\"Один и тот же\": distances_pos, \"Другой человек\": distances_neg}\n",
    "\n",
    "ax = sns.displot(distnaces, kde=True, stat=\"density\")\n",
    "ax.set(xlabel=\"Pairwise distance\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оптимизация гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто, когда мы пишем и обучаем сети (будь то с нуля или с помощью transfer learning) мы вынуждены угадывать гиперпараметры (lr, betas и тд). В случае с learning rate нам есть от чего оттолкнуться (маленький lr для transfer learning), [константа Karpathy (3e-4)](https://twitter.com/karpathy/status/801621764144971776?lang=en) для Adam, но все же, такой подход не кажется оптимальным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оптимизации гиперпараметров существуют готовые решения, которые используют различные методы black-box оптимизации. Разберем одну из наиболее популярных библиотек - [**Optuna**](https://optuna.org/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install --quiet optuna"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте оптимизируем наш learning rate"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import optuna\n",
    "\n",
    "# Определим функицю которую будем оптимизировать\n",
    "def objective(trial):\n",
    "    # Создадим границы для \"предположений\" оптимизатора\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "\n",
    "    # Будем каждый раз пересоздавать нашу сеть и все ее парамеры\n",
    "    net = Siamese().to(device)\n",
    "    loss_fun = ContrastiveLoss(margin=1.5)\n",
    "    optims = optim.Adam(\n",
    "        net.parameters(), lr=lr\n",
    "    )  # Теперь lr предлагает optuna в пределах заданых границ\n",
    "    scheduler = ReduceLROnPlateau(optims, \"min\", verbose=True, factor=0.5, patience=3)\n",
    "\n",
    "    # Для экономии времени возьмем только 3 эпохи\n",
    "    counter, l = train(3, net, optims, scheduler, save=False)\n",
    "    return l[-1]\n",
    "\n",
    "\n",
    "# Создадим \"исследование\",\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"Optimal lr\")\n",
    "\n",
    "#\n",
    "study.optimize(\n",
    "    objective, n_trials=15\n",
    ")  # Чем больше итераций - тем выше шансы словить самые оптимальные гиперпараметры"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Посмотрим на лучшие параметры\n",
    "study.best_params"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно же, можно оптимизировать сразу несколько параметров за раз, а еще в качестве параметров можеть быть сама архитектура сети (например количесвто слоев и каналов). Это можно легко сделать по анологии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на историю оптимизации нашего lr"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ж, проверим а станет ли реально лучше"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!mkdir 'optimal_weight'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "net = Siamese().to(device)\n",
    "loss_fun = ContrastiveLoss(margin=1.5)\n",
    "optims = optim.Adam(\n",
    "    net.parameters(), lr=study.best_params[\"lr\"]\n",
    ")  # Возьмем lr, который нам предлагает Optuna\n",
    "scheduler = ReduceLROnPlateau(optims, \"min\", verbose=True, factor=0.5, patience=3)\n",
    "\n",
    "counter, l_optim = train(30, net, optims, scheduler, save=True, path=\"optimal_weight\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.plot(counter, l, label=\"no optimization\")\n",
    "plt.plot(counter, l_optim, label=\"optimal params\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "distances_pos, distances_neg = plot_images(l_optim)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "distnaces_optim = {\"Один и тот же\": distances_pos, \"Другой человек\": distances_neg}\n",
    "\n",
    "ax_0 = sns.displot(distnaces, kde=True, stat=\"density\", alpha=0.5)\n",
    "ax_1 = sns.displot(distnaces_optim, kde=True, stat=\"density\", alpha=0.5)\n",
    "ax_0.set(xlabel=\"Pairwise distance\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "---\n",
    "\n",
    "На этом уроке мы затронули проблемы, которые возникают при обучени на реальных данных.\n",
    "\n",
    "Одна из основных проблем - малые датасеты. Для того, чтобы обучить нейронку на небольшом датасете можно использовать:\n",
    "- `аугментацию`\n",
    "- `Tranfer learning`\n",
    "Однако необходимо помнить, что ни один из этих методов не защитит от ситуации, когда реальные данные будут сильно отличаться от тренировочных.\n",
    "\n",
    "В случае, когда у нас не только мало данных, но и еще и очень большое (возможно, неизвестное) число классов, можно воспользоваться `One-shot Learning`. В этом случае нейронка обучается не классифицировать изображения, а, наоборот, находить различия между классом и новыми данными. Для этого используются нейронные сети, относящиеся к классу сиамских нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же мы разобрали автоматическую оптимизацию гиперпараметров с помощью Optuna и показали, что это эффективный способ сделать нейросеть лучше малой ценой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Литература\n",
    "---\n",
    "\n",
    "### Augmentation\n",
    "\n",
    "[TORCHVISION.TRANSFORMS](https://pytorch.org/vision/stable/transforms.html)\n",
    "\n",
    "[A survey on Image Data Augmentation for Deep Learning](https://link.springer.com/article/10.1186/s40537-019-0197-0)\n",
    "\n",
    "[Data augmentation for improving deep learning in image classification problem](https://www.researchgate.net/publication/325920702_Data_augmentation_for_improving_deep_learning_in_image_classification_problem)\n",
    "\n",
    "[Albumentations](https://github.com/albumentations-team/albumentations)\n",
    "\n",
    "\n",
    "\n",
    "### Transfer Learning\n",
    "[How To Do Transfer Learning For Computer Vision | PyTorch Tutorial](https://www.youtube.com/watch?v=6nQlxJvcTr0)\n",
    "\n",
    "[TRANSFER LEARNING FOR COMPUTER VISION TUTORIAL](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "\n",
    "[Python Pytorch Tutorials # 2 Transfer Learning : Inference with ImageNet Models](https://www.youtube.com/watch?v=Upw4RaERZic)\n",
    "\n",
    "[PyTorch - The Basics of Transfer Learning with TorchVision and AlexNet](https://www.youtube.com/watch?v=8etkVC93yU4)\n",
    "\n",
    "### One-shot Learning\n",
    "\n",
    "[One Shot Learning with Siamese Networks using Keras](https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d)\n",
    "\n",
    "[One-shot image classification by meta learning](https://medium.com/nerd-for-tech/one-shot-learning-fe1087533585)\n",
    "\n",
    "[Siamese Neural Networks for One-shot Image Recognition](http://www.cs.toronto.edu/~rsalakhu/papers/oneshot1.pdf)\n",
    "\n",
    "[One-shot learning (Part 1/2): Definitions and fundamental techniques](https://heartbeat.fritz.ai/one-shot-learning-part-1-2-definitions-and-fundamental-techniques-1df944e5836a)\n",
    "\n",
    "[One-Shot Learning (Part 2/2): Facial Recognition Using a Siamese Network](https://heartbeat.fritz.ai/one-shot-learning-part-2-2-facial-recognition-using-a-siamese-network-5aee53196255)\n",
    "\n",
    "[FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)\n",
    "\n",
    "[One shot learning explained using FaceNet](https://medium.com/intro-to-artificial-intelligence/one-shot-learning-explained-using-facenet-dff5ad52bd38)\n",
    "\n",
    "\n",
    "### Hyperparameter optimization\n",
    "[Tuning Hyperparameters with Optuna](https://towardsdatascience.com/tuning-hyperparameters-with-optuna-af342facc549)"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {}
}
