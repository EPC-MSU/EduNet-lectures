{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Линейные модели</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня мы познакомимся с линейными моделями. Это - простые модели, которые являются частью многих сложных моделей, которые мы будем рассказывать на нашем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В основе линейных моделей лежит линейная функция\n",
    "$$f(\\vec x) = (\\vec w, \\vec x) +b $$\n",
    "где $(\\vec w, \\vec x)$  - скалярное произведение:\n",
    "\n",
    "$$(\\vec w, \\vec x) = \\sum_{i=1}^n{w_ix_i} = w_1x_1+w_2x_2+...+w_ix_i+ ... + w_nx_n$$\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/scalar_product_ways_to_use.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшем мы будем проходить **модель нейрона головного мозга**, которая ляжет в основу всех **нейронных сетей** от полносвязных и сверточных сетей, до сложных генеративных моделей и трансформеров. В ней мы встретимся с **линейным слоем**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Регрессия** — это одна из трех базовых задач машинного обучения (классификация, регрессия, кластеризация).\n",
    "\n",
    "В задаче **регрессии** мы используем входные **признаки**, чтобы предсказать **целевые значения**. Например, чтобы предсказать цену жилья по его характеристикам (площадь, этаж, год постройки дома, высота потолков, район, ...). **Линейная регрессия** сводится к тому, чтобы провести “**линию наилучшего соответствия**” через набор точек данных. Она является простым предшественником нелинейных методов, которые используются для обучения нейронных сетей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Модель и ее параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель линейной регрессии — **поиск линии, которая наилучшим образом соответствует заданным точкам**. Напомним, что общее уравнение для прямой есть\n",
    "\n",
    "$$f(x) = w⋅x + b,$$\n",
    "\n",
    "где $w$ — характеризует наклон линии (в будущем мы будем называть значения $w$ весом, weight) а $b$ — её сдвиг по $y$ (bias). Таким образом, решение линейной регрессии определяет значения для $w$ и $b$ так, что $f (x)$ приближается как можно ближе к $y$. $w$ и $b$ — **параметры модели**.\n",
    "\n",
    "\n",
    "Отобразим на графике случайные точки, расположенные в окрестности $y = 3⋅x + 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = 2 + 3 * x + (np.random.rand(100, 1) - 0.5)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что нам неизвестны параметры наклона и сдвига $w$ и $b$. Для их определения мы бы могли рассмотреть всевозможные прямые вида $f(x) = w⋅x + b$ и выбрать среди семейства прямых такую, которая лучше всего приближает имеющиеся данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(x, y, s=10)\n",
    "for w in np.arange(-5.0, 7.0, 1):\n",
    "    for b in [-1, 0, 1, 2, 3]:\n",
    "        y_predicted = b + w * x\n",
    "        plt.plot(x, y_predicted, color=\"r\", alpha=0.3)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Модель** $f(x) = w⋅x + b$ задаёт параметрическое семейство функций, а **выбор \"правильного\" представителя** из **параметрического семейства** и называется **обучением** модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(x, y, s=10)\n",
    "for w in np.arange(-5.0, 7.0, 1):\n",
    "    for b in [-1, 0, 1, 2, 3]:\n",
    "        y_predicted = b + w * x\n",
    "        plt.plot(x, y_predicted, color=\"r\", alpha=0.3)\n",
    "plt.plot(x, 2 + 3 * x, color=\"g\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция потерь\n",
    "\n",
    "Как выбрать параметры?\n",
    "\n",
    "**Функция потерь**  позволяет вычислить меру количества ошибок. Для задачи **регрессии** такой мерой может быть **расстояние** между предсказанным значением $f(х)$ и его фактическим значением. Распространенной функцией потерь является **средняя квадратичная ошибка** (MSE). Чтобы вычислить MSE, мы просто берем все значения ошибок, считаем квадраты их длин и усредняем.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть мы определяем ошибку модели на одном объекте как квадрат расстояния между предсказанием и истинным значением, а общая функция потерь будет задана выражением:\n",
    "\n",
    "$$l_i =|y_i - f(x_i)| $$\n",
    "\n",
    "$$ Loss = \\sum l_i^2 = \\frac{1}{N} \\sum (y_i - f(x_i))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для прямой с параметрами $w=4$, $b = 2$ и $w=3$, $b = 2$ (верные значения):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_delta_line(ax, x, y, w, b, color=\"r\"):\n",
    "    y_predicted = w * x + b\n",
    "    # line\n",
    "    ax.plot(x, y_predicted, color=color, alpha=0.5, label=f\"f(x)={w}x+{b}\")\n",
    "    # delta\n",
    "    for x_i, y_i, f_x in zip(x, y, y_predicted):\n",
    "        ax.vlines(x=x_i, ymin=min(f_x, y_i), ymax=max(f_x, y_i), ls=\"--\", alpha=0.3)\n",
    "    # MSE\n",
    "    loss = np.sum((y - (w * x + b)) ** 2) / (len(x))\n",
    "    ax.set_title(f\"MSE = {loss:.3f}\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(11, 4))\n",
    "\n",
    "# plot x_i y_i (dots)\n",
    "for ax in axs:\n",
    "    ax.scatter(x, y, s=10)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([2, 6])\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "\n",
    "plot_delta_line(axs[0], x, y, w=4, b=2, color=\"r\")\n",
    "plot_delta_line(axs[1], x, y, w=3, b=2, color=\"g\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача **поиска оптимальных параметров** модели сводится к задаче **поиска минимума функции потерь**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск локального минимума"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как будет выглядеть ландшафт функции потерь для нашей задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.arange(-10, 30, 1)\n",
    "b = np.arange(-10, 10, 1)\n",
    "\n",
    "w, b = np.meshgrid(w, b)\n",
    "\n",
    "loss = np.zeros_like(w)\n",
    "for i in range(w.shape[0]):\n",
    "    for j in range(w.shape[1]):\n",
    "        loss[i, j] = np.sum((y - (w[i, j] * x + b[i, j])) ** 2) / (len(x))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "surf = ax.plot_surface(w, b, loss, cmap=plt.cm.RdYlGn_r, alpha=0.5)\n",
    "\n",
    "ax.contourf(w, b, loss, zdir=\"z\", offset=-1, cmap=\"RdYlGn_r\", alpha=0.5)\n",
    "ax.set_zlim(0, 20)\n",
    "\n",
    "ax.set_xlabel(\"w\")\n",
    "ax.set_ylabel(\"b\")\n",
    "ax.set_title(\"MSE\")\n",
    "\n",
    "fig.colorbar(surf, location=\"left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимым (но недостаточным) [условием локального минимума](http://school-collection.edu.ru/catalog/res/a8dc6578-4819-4297-ab14-95ffab6fe8b6/view/#:~:text=%D0%B5%D1%81%D0%BB%D0%B8%20%D0%BF%D1%80%D0%B8%20%D0%BF%D0%B5%D1%80%D0%B5%D1%85%D0%BE%D0%B4%D0%B5%20%D1%87%D0%B5%D1%80%D0%B5%D0%B7%20%D1%82%D0%BE%D1%87%D0%BA%D1%83%20%D1%850%20%D0%BF%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%BE%D0%B4%D0%BD%D0%B0%D1%8F%20%D0%BC%D0%B5%D0%BD%D1%8F%D0%B5%D1%82%20%D1%81%D0%B2%D0%BE%D0%B9,%D1%82%D0%BE%D1%87%D0%BA%D0%B5%20%D1%850%20%D0%BD%D0%B5%D1%82%20%D1%8D%D0%BA%D1%81%D1%82%D1%80%D0%B5%D0%BC%D1%83%D0%BC%D0%B0.) дифференцируемой функции является равенство нулю частных производных:\n",
    "\n",
    "$$\t\\begin{equation*}\n",
    " \\begin{cases}\n",
    "   \\frac{\\partial Loss}{\\partial w}=0,\n",
    "   \\\\\n",
    "   \\frac{\\partial Loss}{\\partial b}=0.\n",
    " \\end{cases}\n",
    "\\end{equation*} $$\n",
    "\n",
    "Т.к. MSE для линейной регрессии - полином второй степени относительно $w$ и $b$, а полином второй степени не может иметь больше одного экстремума, то локальный минимум будет глобальным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Метод наименьших квадратов\n",
    "\n",
    "Реализуем простейшую модель линейной регрессии с использованием библиотеки NumPy на датасете, определённом выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем метод наименьших квадратов: [МНК простейшие частные случаи](https://ru.wikipedia.org/wiki/Метод_наименьших_квадратов#Простейшие_частные_случаи).\n",
    "\n",
    "$$w = \\frac{n\\sum_{i=1}^nx_iy_i - (\\sum_{i=1}^nx_i)(\\sum_{i=1}^ny_i)}{n\\sum_{i=1}^nx_t^2 - (\\sum_{i=1}^n x_t)^2};$$\n",
    "\n",
    "$$b = \\frac{\\sum_{i=1}^ny_i - w(\\sum_{i=1}^nx_i)}{n}.$$\n",
    "\n",
    "По сути метод наименьших квадратов - это решение системы уравнений выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_coef(x, y):\n",
    "    n = len(x)\n",
    "    w = (n * sum(np.multiply(x, y)) - sum(x) * sum(y)) / (\n",
    "        n * sum(np.multiply(x, x)) - sum(x) ** 2\n",
    "    )\n",
    "    b = (sum(y) - w * sum(x)) / n\n",
    "    return w, b\n",
    "\n",
    "\n",
    "w, b = estimate_coef(x, y)\n",
    "\n",
    "y_predicted = w * x + b\n",
    "\n",
    "print(f\"Estimated coefficients:\\nb = {b[0]:.3f} \\nw = {w[0]:.3f}\")\n",
    "print(f\"Final equation: \\ny = {w[0]:.3f}x +{b[0]:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.plot(x, y_predicted, color=\"g\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученное решение близко к исходной  зависимости $y=3\\cdot x + 2$.\n",
    "\n",
    "Для многомерного случая МНК [можно записать](https://sun.tsu.ru/mminfo/2016/Dombrovski/book/chapter-3/chapter-3-2.htm) решение в матричном виде:  \n",
    "$$\\vec w = (X^TX)^{-1}X^T\\vec y$$\n",
    "где $\\vec w$ - где\n",
    "вектор параметров модели, включающий $b$ (при записи этого решения используется трюк “столбец единиц”, о котором мы поговорим чуть позже),\n",
    "$X$ - матрица входных признаков (с единичным столбцом),\n",
    "$\\vec y$ - вектор предсказываемых значений.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С одной из метрик регрессии мы уже познакомились: это  — $MSE$, которую мы минимизировали в методе наименьших квадратов. Стоит отметить что $MSE$ имеет [размерность](https://ru.wikipedia.org/wiki/%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8) квадрата размерности предсказываемого значения.\n",
    "\n",
    "$$ MSE  = \\frac{1}{N} \\sum (y_i - f(x_i))^2$$\n",
    "\n",
    "Чтобы получить оценку ошибки той же размерности можно взять корень (root) от $MSE$. Это метрика $RMSE$:\n",
    "\n",
    "$$ RMSE = \\sqrt{\\frac{1}{N} \\sum (y_i - f(x_i))^2}$$\n",
    "\n",
    "Или посчитать среднюю абсолютную ошибку $MAE$:\n",
    "\n",
    "$$ MAE = \\frac{1}{N} \\sum |y_i - f(x_i)|$$\n",
    "\n",
    "Существуют и более специфичные метрики, например $R^2$, которая принимает значения от $(-\\inf, 1]$, где $1$  —  наилучший вариант. $R^2$  называется [коэффициентом детерминации](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%8D%D1%84%D1%84%D0%B8%D1%86%D0%B8%D0%B5%D0%BD%D1%82_%D0%B4%D0%B5%D1%82%D0%B5%D1%80%D0%BC%D0%B8%D0%BD%D0%B0%D1%86%D0%B8%D0%B8) и характеризуют долю дисперсии целевого значения, которую объясняет модель.\n",
    "\n",
    "$$R^2 = 1 - \\frac{MSE}{\\sigma^2}=1 - \\frac{\\sum {(y_i-f(x_i))^2}}{\\sum{(y_i-\\bar{y})^2}}$$\n",
    "\n",
    "$$\\bar{y} = \\frac{1}{N}\\sum {y_i}$$\n",
    "\n",
    "где $\\sigma^2$ - дисперсия.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Когда $R^2$ около нуля - модель плохо объясняет данные.</center>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L02/linear_regression.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em> Source: https://xkcd.com/1725</em></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def print_metrics(y_true, y_predicted):\n",
    "    print(f\"Mean squared error: {mean_squared_error(y_true, y_predicted):.3f}\")\n",
    "    print(\n",
    "        \"Root mean squared error: \",\n",
    "        f\"{mean_squared_error(y_true, y_predicted, squared=False):.3f}\",\n",
    "    )\n",
    "    print(f\"Mean absolute error: {mean_absolute_error(y_true, y_predicted):.3f}\")\n",
    "    print(f\"R2 score: {r2_score(y_true, y_predicted):.3f}\")\n",
    "\n",
    "\n",
    "print_metrics(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее про метрики можно почитать: [тут](https://academy.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii). Там же вы можете найти информацию об относительных ошибках, выражаемых в процентах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель линейной регрессии из библиотеки scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Свою линейную регрессию мы написали, теперь изучим как работать с моделью из sklearn.\n",
    "\n",
    "Рассмотрим следующую задачу. Пусть мы хотим построить модель предсказания успеваемости студента на основе информации о величине потраченного им на изучение материала количества времени в часах. Это пример простейшей задачи линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет. Датасет содержит два числовых значения — часы и результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/student_scores.csv\"\n",
    ")\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график зависимости одного от другого, а также отобразим распределения каждой из переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.jointplot(data=dataset, x=\"Hours\", y=\"Scores\", height=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наши данные на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = dataset.iloc[:, :-1].values  # column Hours\n",
    "y = dataset.iloc[:, 1].values  # column Score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае сложного, многомодового распределения значений целевой переменной в задаче регрессии, может быть полезно задуматься о стратификации данных. Стратификация данных для задачи регрессии специфична и не реализована в `sklearn`, о ней можно почитать в [статье](https://www.jstor.org/stable/2336525?seq=1), пример кода найти на [форуме](https://datascience.stackexchange.com/questions/33140/stratify-on-regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим модель для линейной регрессии. Чтобы не писать с нуля, воспользуемся готовой моделью из библиотеки `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И обучим ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_points = np.linspace(min(x_train), max(x_train), 100)  # 100 dots at min to max\n",
    "y_pred = regressor.predict(x_points)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(x_train, y_train, \"o\", label=\"Scores\")\n",
    "plt.plot(\n",
    "    x_points,\n",
    "    y_pred,\n",
    "    label=\"y = %.2fx+%.2f\" % (regressor.coef_[0], regressor.intercept_),\n",
    ")\n",
    "plt.title(\"Hours vs Percentage\", size=12)\n",
    "plt.xlabel(\"Hours Studied\", size=12)\n",
    "plt.ylabel(\"Percentage Score\", size=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сделаем предсказание для тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "x_points = np.linspace(min(x_test), max(x_test), 100)\n",
    "y_pred = regressor.predict(x_points)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(x_test, y_test, \"o\", label=\"Scores\")\n",
    "plt.plot(\n",
    "    x_points,\n",
    "    y_pred,\n",
    "    label=\"y = %.2fx+%.2f\" % (regressor.coef_[0], regressor.intercept_),\n",
    ")\n",
    "plt.title(\"Hours vs Percentage\", size=12)\n",
    "plt.xlabel(\"Hours Studied\", size=12)\n",
    "plt.ylabel(\"Percentage Score\", size=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит неплохо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем метрики для наших значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x_test)\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будьте осторожнее: модели отражают только те закономерности, которые видели в данных. Вероятность того, что студент, потративший на подготовку 20 часов получит больше максимального балла мала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L02/extrapolating.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em> Source: https://xkcd.com/605</em></center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод градиентного спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы решали задачу линейной регрессии аналитически (МНК), но это не всегда возможно по нескольким причинам:\n",
    "* Для аналитического решения нужно считать обратную матрицу, это вычислительно сложно и матрица бывает плохо определенной.\n",
    "* Данных может быть слишком много для того, чтобы их можно было одновременно положить в память для расчета обратной матрицы.\n",
    "* Модели могут быть слишком сложными для поиска аналитического решения. Более того, для сложных моделей ландшафт функции потерь может иметь сложный рельеф с несколькими локальными минимумами.\n",
    "\n",
    "Давайте поговорим о том, что делать в таком случае."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод, который мы будем использовать, называется **“метод градиентного спуска”**. Для начала вспомним, что такое **градиент**. Возьмем функцию двух переменных:\n",
    "\n",
    "$$\\large f(x, y) = \\sin(x\\cdot y)$$\n",
    "\n",
    "Она будет отличаться от функции потерь, которую мы визуализировали, тем, что у нее не будет одного экстремума. Рассчитаем ее на диапазоне значений от $0$ до $4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = lambda x, y: np.sin(x * y)\n",
    "\n",
    "x = np.linspace(0, 4, 1000)\n",
    "y = np.linspace(0, 4, 1000)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "zz = f(xx, yy)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "\n",
    "def show_3d(xx, yy, zz, fig):\n",
    "    ax = fig.add_subplot(121, projection=\"3d\")\n",
    "    surf = ax.plot_surface(xx, yy, zz, cmap=plt.cm.RdYlGn_r)\n",
    "\n",
    "    ax.contourf(xx, yy, zz, zdir=\"zz\", offset=-2, cmap=\"RdYlGn_r\")\n",
    "    ax.set_zlim(-2, 2)\n",
    "\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_title(\"sin(xy)\")\n",
    "    fig.colorbar(surf, location=\"left\")\n",
    "\n",
    "\n",
    "show_3d(xx, yy, zz, fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eсли $\\varphi = \\varphi(\\vec{x})=\\varphi(x_1 \\dots x_n)$ — функция $n$ переменных, то её градиентом называется $n$-мерный вектор:\n",
    "$$\n",
    "\\nabla \\varphi(\\vec{x})=\n",
    "\\begin{bmatrix}\n",
    "\\displaystyle\\frac{\\partial\\varphi}{\\partial x_1}\\\\\n",
    "\\displaystyle\\frac{\\partial\\varphi}{\\partial x_2}\\\\\n",
    "...\\\\\n",
    "\\displaystyle\\frac{\\partial\\varphi}{\\partial x_n}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем градиент нашей функции $f(x, y)$. Для этого воспользуемся [**таблицей производных**](https://ru.wikipedia.org/wiki/%D0%A2%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0_%D0%BF%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%BE%D0%B4%D0%BD%D1%8B%D1%85) и правилом вычисления [**производной сложной функции**](https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D1%84%D1%84%D0%B5%D1%80%D0%B5%D0%BD%D1%86%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D1%81%D0%BB%D0%BE%D0%B6%D0%BD%D0%BE%D0%B9_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%B8) (Chain-rule):\n",
    "$$\\frac {\\partial f} {\\partial x} = \\frac {\\partial f} {\\partial t} \\cdot \\frac {\\partial t} {\\partial x}$$\n",
    "\n",
    "Это правило очень нам пригодится в будущем.\n",
    "\n",
    "$$\\nabla f(x, y)=\\begin{bmatrix}\n",
    "\\displaystyle\\frac{\\partial f}{\\partial x}\\\\\n",
    "\\displaystyle\\frac{\\partial f}{\\partial y}\\\\\n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "\\displaystyle\\frac{\\partial\\sin(xy)}{\\partial(xy)}\\cdot\\frac{\\partial(xy)}{\\partial x}\\\\\n",
    "\\displaystyle\\frac{\\partial\\sin(xy)}{\\partial(xy)}\\cdot\\frac{\\partial(xy)}{\\partial y}\\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "\\cos(xy)\\cdot y\\\\\n",
    "\\cos(xy)\\cdot x\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Посчитаем градиент на том же диапазоне (сетка реже, т.к. мы будем рисовать не точки, а стрелочки):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradf = lambda x, y: (np.cos(x * y) * y, np.cos(x * y) * x)\n",
    "\n",
    "xsmall = np.linspace(0, 4, 15)\n",
    "ysmall = np.linspace(0, 4, 15)\n",
    "xxsmall, yysmall = np.meshgrid(xsmall, ysmall)\n",
    "gradx, grady = gradf(xxsmall, yysmall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как **значение градиента в точке** — это вектор, мы можем говорить о его **величине** и **направлении**. Так как значение градиента в точке — это вектор, мы можем говорить о его величине и направлении. Визуализируем наши расчеты: посмотрим на ландшафт функции $f(x, y)$ и направления градиентов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "show_3d(xx, yy, zz, fig)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.imshow(\n",
    "    zz,\n",
    "    extent=(np.min(x), np.max(x), np.min(y), np.max(y)),\n",
    "    cmap=\"RdYlGn_r\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "\n",
    "ax.quiver(xxsmall, yysmall, gradx, grady)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке выше значения градиента в точке обозначены чёрными стрелочками. Можно заметить, что длина стрелок в  районе максимальных и минимальных значений функции **почти нулевая**, стрелки направлены в направлении возрастания значения функции, и наиболее длинные стрелки находятся в области наиболее резкого изменения значений функции.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это проявление **свойств градиента**:\n",
    "* Направление $\\frac{\\nabla f}{||\\nabla f||}$ — сообщает нам направление максимального роста функции.\n",
    "\n",
    "*  Величина $||\\nabla f||$ — характеризует мгновенную скорость изменения значений функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идея градиентного спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим еще раз данные с зависимостью оценок студентов от времени подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/student_scores.csv\"\n",
    ")\n",
    "\n",
    "x = dataset.iloc[:, :-1].values  # column Hours\n",
    "y = dataset.iloc[:, 1].values  # column Score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем **код для интерактивной визуализации**. Он нужен только для объяснения и **не пригодится вам в работе**. Его разбирать мы не будем. Eсли интересно, можно изучить самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title *Code for interactive visual\n",
    "# source: https://github.com/TomasBeuzen/deep-learning-with-pytorch\n",
    "\n",
    "!wget -qN https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.0/L02/interactive_visualization.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты рассмотрим одномерный случай. Будем подбирать только $w$, значение $b$ зафиксируем на уровне $2.83$. Визуализируем ошибку и значения $\\displaystyle \\frac{\\partial Loss}{\\partial w}$ для MSE Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactive_visualization import plot_grid_search\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "slopes = np.arange(5, 15, 0.5)\n",
    "prediction = {f\"{w}\": w * x_train[:, 0] + 2.83 for w in slopes}\n",
    "mse = np.array([mean_squared_error(y_train, w * x_train[:, 0] + 2.83) for w in slopes])\n",
    "dmse_dw = np.array(\n",
    "    [(2 * x_train[:, 0] * (w * x_train[:, 0] + 2.83 - y_train)).mean() for w in slopes]\n",
    ")\n",
    "plot_grid_search(x_train[:, 0], y_train, slopes, prediction, mse, dmse_dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Видно, что оптимальное значение наклона соответствует минимуму MSE и нулю частной производной $\\displaystyle\\frac{\\partial Loss}{\\partial w}$. Аналогично будет, если мы возьмем в качестве Loss MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "slopes = np.arange(5, 15, 0.5)\n",
    "prediction = {f\"{w}\": w * x_train[:, 0] + 2.83 for w in slopes}\n",
    "mae = np.array([mean_absolute_error(y_train, w * x_train[:, 0] + 2.83) for w in slopes])\n",
    "dmae_dw = np.array(\n",
    "    [\n",
    "        (x_train[:, 0] * np.sign(w * x_train[:, 0] + 2.83 - y_train)).mean()\n",
    "        for w in slopes\n",
    "    ]\n",
    ")\n",
    "plot_grid_search(x_train[:, 0], y_train, slopes, prediction, mae, dmae_dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, т.к. градиент указывает направления наибольшего возрастания функции:\n",
    "\n",
    "* если $\\displaystyle\\frac{\\partial Loss}{\\partial w} < 0$, то нам имеет смысл “идти” в сторону возрастания $\\displaystyle\\frac{\\partial Loss}{\\partial w}$;\n",
    "\n",
    "* если $\\displaystyle\\frac{\\partial Loss}{\\partial w} > 0$ — в сторону убывания.\n",
    "\n",
    "**Метод градиентного спуска** — итеративный метод, идея которого заключается в том, чтобы небольшими шажками “идти” в **обратную от градиента сторону**:\n",
    "\n",
    "$$\\large \\vec w_{n+1} = \\vec w_{n} - α \\cdot \\nabla_{\\vec w_{n}} Loss,$$\n",
    "где $α$ — скорость обучения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/update_weghts_values.png\" width=\"450\"></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем реализовать это в коде (для простоты только для $w$ при $b=2.83$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x, y, w, b):\n",
    "    return 2 * (x * (w * x + b - y)).mean()\n",
    "\n",
    "\n",
    "def gradient_descent(x_train, y_train, x_test, y_test, w, alpha, b=2.83, iteration=10):\n",
    "    \"\"\"Gradient descent for optimizing slope in simple linear regression\"\"\"\n",
    "    # history\n",
    "    ws = [w]\n",
    "    mse_train = [mean_squared_error(y_train, w * x_train + b)]\n",
    "    dmse_train = []\n",
    "    mse_test = [mean_squared_error(y_test, w * x_test + b)]\n",
    "    prediction = {w: w * x_train + b}\n",
    "    print(\n",
    "        f\"Iteration 0: w = {w:.2f}, Loss_train = {mse_train[0]:.2f}, \"\n",
    "        f\"Loss_test = {mse_test[0]:.2f}.\"\n",
    "    )\n",
    "    for i in range(iteration):\n",
    "        # adjust w based on gradient * learning rate\n",
    "        grad = gradient(x_train, y_train, w, b)\n",
    "        w -= alpha * grad  # adjust w based on gradient * learning rate\n",
    "        # history\n",
    "        ws.append(w)\n",
    "        mse_train.append(mean_squared_error(y_train, w * x_train + b))\n",
    "        dmse_train.append(grad)\n",
    "        mse_test.append(mean_squared_error(y_test, w * x_test + b))\n",
    "        prediction[w] = w * x_train + b\n",
    "        print(\n",
    "            f\"Iteration {i+1}: w = {w:.2f}, Loss_train = {mse_train[i]:.2f}, \"\n",
    "            f\"Loss_test = {mse_test[i]:3.2f}.\"\n",
    "        )\n",
    "    return ws, prediction, mse_train, dmse_train, mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим нашу модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes, prediction, mse_train, dmse_train, mse_test = gradient_descent(\n",
    "    x_train[:, 0], y_train, x_test[:, 0], y_test, w=5, alpha=0.01, iteration=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем процесс обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactive_visualization import plot_gradient_descent\n",
    "\n",
    "plot_gradient_descent(x_train[:, 0], y_train, slopes, prediction, mse_train, dmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что за $7$ эпох мы получили то же значение $w$, что получали при использовании [`LinearRegression`](https://colab.research.google.com/drive/1QoqgO4nSSQcxKP6arDEcedw7I_XFq4zs#scrollTo=9E8205Ic5ujC). При этом мы пришли в минимум $\\text{MSE}$ и ноль градиента.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реальности мы будем работать с функциями многих переменных, поэтому смотреть на сходимость по одной переменной — не самый оптимальный вариант. Более эффективно будет посмотреть на зависимость Loss от количества эпох для train и test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mse(mse_train, mse_test):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.plot(mse_train, label=\"train\")\n",
    "    plt.plot(mse_test, label=\"test\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel(\"iterations\", fontsize=12)\n",
    "    plt.ylabel(\"MSE Loss\", fontsize=12)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такие графики называют кривыми обучения.Посмотрим на кривые обучения для нашей скорости обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mse(mse_train, mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что **Loss падает** как на **train**, так и на **test** выборке. Также мы можем сказать, что **сеть обучалась**: train и test **графики вышли на плато**. При этом не произошло **переобучение**: ошибка на **test** выборке **не начала расти** (про переобучение поговорим позже).\n",
    "\n",
    "В полученных графиках есть особенность, которая бросается в глаза опытному в обучении моделей человеку: **Loss на test выборке меньше, чем на train**. Это показатель того, что **с данными что-то не так**. Так бывает при утечке данных (об утечке данных вы подробнее узнаете в следующих лекциях) или если, как в данном случае, test выборка слишком мала, чтобы отражать генеральную совокупность (всего 5 студентов, доверительный интервал для такого маленького количества объектов будет широкий)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор скорости обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Скорость (шаг) обучения** — некоторый коэффициент, как правило, небольшой, который не позволяет нам двигаться слишком быстро. У нас есть точка, в которую мы хотим попасть. Если мы сделаем слишком большой шаг, то мы ее перескочим (график справа), поэтому надо подобрать шаг, который не позволит ее перескочить, но в то же время такой, чтобы тот же процесс не шел слишком медленно (как на графике слева)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/learning_rate_optimal_value.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на скорость обучения на нашем примере. При **маленькой скорости обучения** мы будем очень медленно сходиться к минимуму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes, prediction, mse_train, dmse_train, mse_test = gradient_descent(\n",
    "    x_train[:, 0], y_train, x_test[:, 0], y_test, w=5, alpha=0.0005, iteration=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent(x_train[:, 0], y_train, slopes, prediction, mse_train, dmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спустя 30 итераций оранжевая прямая плохо отражает генеральную совокупность. Мы не достигли минимума MSE и нуля градиента.\n",
    "\n",
    "Посмотрим, как выглядят кривые обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mse(mse_train, mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель недообучена — значения Loss не вышли на плато.\n",
    "\n",
    "Посмотрим на **достаточно большую скорость обучения**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes, prediction, mse_train, dmse_train, mse_test = gradient_descent(\n",
    "    x_train[:, 0], y_train, x_test[:, 0], y_test, w=5, alpha=0.027, iteration=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent(x_train[:, 0], y_train, slopes, prediction, mse_train, dmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаг, получаемый умножением градиента на скорость обучения, получается достаточно большим, чтобы “перескочить” локальный минимум, но при этом модель все-таки попадает в него. Кривые обучения при этом успешно выходят на плато."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mse(mse_train, mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В финале посмотрим на **очень большую скорость обучения**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes, prediction, mse_train, dmse_train, mse_test = gradient_descent(\n",
    "    x_train[:, 0],\n",
    "    y_train,\n",
    "    x_test[:, 0],\n",
    "    y_test,\n",
    "    w=5,\n",
    "    alpha=0.034,\n",
    "    iteration=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаг, который мы делаем, слишком большой. Мы не попадаем в локальный минимум."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent(x_train[:, 0], y_train, slopes, prediction, mse_train, dmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "По кривым обучения видно, что модель не сошлась: ошибка растет.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mse(mse_train, mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор скорости обучения будет зависеть от модели и данных. В 7 лекции вы познакомитесь с различными модификациями метода градиентного спуска и узнаете больше о выборе скорости обучения, а пока ориентируйтесь на кривые обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Единый подход к учету смещения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока мы настраивали только одну переменную, но даже в случае предсказания оценки по времени подготовки у нас две переменные: вес $w$ и смещение $b$.\n",
    "\n",
    "Когда признаков станет больше, у нас получится “лапша” из слагаемых:\n",
    "$$y = b + w_1\\cdot x_1 + w_2\\cdot x_2 + w_3\\cdot x_3 + w_4\\cdot x_4 + w_5\\cdot x_5 + ... + w_n\\cdot x_n$$\n",
    "\n",
    "Нам бы хотелось записать их компактно, чтобы не усложнять код и использовать один и тот же код для данных с разным количеством признаков.  Для этого мы будем использовать матричное перемножение и трюк **“столбец единиц”**, который реализует **единый подход к учету смещения**.\n",
    "\n",
    "Обозначим вектор-столбец из настраиваемых параметров:\n",
    "$$\\vec w = \\begin{bmatrix}\n",
    "b \\\\ w \\\\\n",
    "\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[0.5], [5]])\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К матрице (в нашем случае был только один признак, поэтому у нас будет вектор-столбец) признаков слева \"дорисуем\" столбец единиц:\n",
    "$$X = \\begin{bmatrix}\n",
    "1 & X \\\\\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "1 & 2.7 \\\\\n",
    "1 & 3.3 \\\\\n",
    "... & ...\\\\\n",
    "1 & 9.2 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "**Предупреждение:** добавлять столбец единиц нужно, только если вы сами пишете модель. **Если вы пользуетесь готовыми моделями, в этом нет необходимости.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.hstack((np.ones((x_train.shape[0], 1)), x_train))\n",
    "x_test = np.hstack((np.ones((x_test.shape[0], 1)), x_test))\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрицу $X$ можно матрично перемножить со столбцом $\\vec w$, т.к количество столбцов $X$ совпадает с количеством строк в $\\vec w$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем случае:\n",
    "\n",
    "$$\\large \\vec y = b + w_1\\cdot x_1 + w_2\\cdot x_2 + w_3\\cdot x_3 + w_4\\cdot x_4 + w_5\\cdot x_5 + ... + w_n\\cdot x_n = X\\vec w $$  \n",
    "\n",
    "Эту формулу можно свести к нескольким символам кода (`@` — матричное умножение):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x_test @ w\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Необходимость нормализации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем многомерный градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.expand_dims(y_train, axis=1)\n",
    "y_test = np.expand_dims(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x, y, w):\n",
    "    \"\"\"Gradient of mean squared error.\"\"\"\n",
    "    return 2 * (x.T @ (x @ w) - x.T @ y) / len(x)\n",
    "\n",
    "\n",
    "def gradient_descent(x_train, y_train, x_test, y_test, w, alpha, iteration=10):\n",
    "    \"\"\"Gradient descent for optimizing slope in simple linear regression\"\"\"\n",
    "    # history\n",
    "    ws = np.zeros((iteration + 1, 2))\n",
    "    ws[0] = w[:, 0]\n",
    "    mse_train = [mean_squared_error(y_train, x_train @ w)]\n",
    "    dmse_train = []\n",
    "    mse_test = [mean_squared_error(y_test, x_test @ w)]\n",
    "    prediction = {(w[0][0], w[1][0]): x_train @ w}\n",
    "\n",
    "    print(\n",
    "        f\"Iteration 0: b = {w[0][0]:.2f}, w = {w[1][0]:.2f}, \"\n",
    "        f\"Loss_train = {mse_train[0]:.2f}, \"\n",
    "        f\"Loss_test = {mse_test[0]:.2f}.\"\n",
    "    )\n",
    "\n",
    "    for i in range(iteration):\n",
    "        # adjust w based on gradient * learning rate\n",
    "        grad = gradient(x_train, y_train, w)\n",
    "        w -= alpha * grad  # adjust w based on gradient * learning rate\n",
    "        # history\n",
    "        ws[i + 1] = w[:, 0]\n",
    "        mse_train.append(mean_squared_error(y_train, x_train @ w))\n",
    "        dmse_train.append(grad)\n",
    "        mse_test.append(mean_squared_error(y_test, x_test @ w))\n",
    "        prediction[(w[0][0], w[1][0])] = x_train @ w\n",
    "\n",
    "        print(\n",
    "            f\"Iteration {i+1}: b = {w[0][0]:.2f}, w = {w[1][0]:.2f}, \"\n",
    "            f\"Loss_train = {mse_train[i]:.2f}, \"\n",
    "            f\"Loss_test = {mse_test[i]:3.2f}.\"\n",
    "        )\n",
    "    return ws, prediction, mse_train, dmse_train, mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[0.5], [5]])\n",
    "ws, prediction, mse_train, dmse_train, mse_test = gradient_descent(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    w,\n",
    "    0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы не дошли до оптимальной прямой $y = 9.68x+2.83$ ([вычисляли выше](https://colab.research.google.com/drive/1QoqgO4nSSQcxKP6arDEcedw7I_XFq4zs#scrollTo=DR5zQvUm5ujD&line=1&uniqifier=1)).\n",
    "\n",
    "При этом график Loss выглядит неплохо:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mse(mse_train, mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такое поведение связано с ландшафтом функции потерь: значение ошибки по оси $b$ изменяется намного медленнее, чем по оси $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactive_visualization import plot_grid_search_2d\n",
    "\n",
    "intercepts = np.arange(-7.5, 12.5, 0.1)  # b\n",
    "slopes = np.arange(5, 15, 0.1)  # w\n",
    "plot_grid_search_2d(x_train[:, 1], y_train, slopes, intercepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому основное изменение значений происходит вдоль оси $w$, а $b$ меняется слабо (значение $b$ далеко от ожидаемого)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactive_visualization import plot_gradient_descent_2d\n",
    "\n",
    "plot_gradient_descent_2d(\n",
    "    x_train[:, 1],\n",
    "    y_train[:, 0],\n",
    "    ws,\n",
    "    slopes,\n",
    "    intercepts,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы исправить ситуацию, применим `StandardScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(np.expand_dims(x_train[:, 1], axis=1)).flatten()\n",
    "x_test_scaled = scaler.transform(np.expand_dims(x_test[:, 1], axis=1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepts = np.arange(40, 60, 0.1)  # b\n",
    "slopes = np.arange(15, 35, 0.1)  # w\n",
    "\n",
    "plot_grid_search_2d(x_train_scaled, y_train, slopes, intercepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = np.hstack(\n",
    "    (np.ones((len(x_train_scaled), 1)), np.expand_dims(x_train_scaled, axis=1)),\n",
    ")\n",
    "\n",
    "x_test_scaled = np.hstack(\n",
    "    (np.ones((len(x_test_scaled), 1)), np.expand_dims(x_test_scaled, axis=1)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. диапазоны x изменились, значения $w$ и $b$ тоже изменятся.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[57.0], [33.0]])\n",
    "ws, prediction, mse_train, dmse_train, mse_test = gradient_descent(\n",
    "    x_train_scaled, y_train, x_test_scaled, y_test, w, 0.35, iteration=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mse(mse_train, mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что после нормализации мы сходимся к $y = 9.68x + 2.83$.  Для этого используем данные о матожидании и дисперсии из `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ws[-1][0] - ws[-1][1] * scaler.mean_ / (scaler.var_) ** 0.5\n",
    "w = ws[-1][1] / (scaler.var_) ** 0.5\n",
    "\n",
    "print(f\"y = {w[0]:.2f}x + {b[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По визуализации видно, что $w$ и $b$ изменяются во время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient_descent_2d(\n",
    "    x_train_scaled[:, 1],\n",
    "    y_train[:, 0],\n",
    "    ws,\n",
    "    slopes,\n",
    "    intercepts,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cтохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Блог-пост о стохастическом градиентом спуске](https://www.tomasbeuzen.com/deep-learning-with-pytorch/chapters/chapter2_stochastic-gradient-descent.html#motivation-for-stochastic-gradient-descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого мы обучали модель, рассчитывая градиент по **всей train выборке**. Это не всегда возможно:\n",
    "- данных может быть слишком много, чтобы загрузить их в память одновременно и рассчитать градиент,\n",
    "- мы можем хотеть дообучать модель на свежепришедших данных, которых может быть немного.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому появляется идея **стохастического градиентного спуска**: мы можем делать шаг обучения, рассчитывая градиент не по всей выборке (**batch**), а по нескольким случайно выбранным объектам (**mini-batch**) или даже по одному случайно выбранному объекту (**stochastic**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/define_size_of_batch.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно [показать](https://academy.yandex.ru/handbook/ml/article/shodimost-sgd), что **стохастический** (с размером $\\text{batch}=1$) **градиентный спуск сходится к минимуму (глобальному или локальному) функции потерь** с конечной точностью. Важным условием является **стохастичность**. Если мы будем использовать одну и ту же последовательность выборок, это приведет к накоплению ошибки и смещению результата.\n",
    "\n",
    "Добавим создание подвыборки к нашему алгоритму:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    w,\n",
    "    alpha,\n",
    "    iteration=10,\n",
    "    batch_size=None,\n",
    "):\n",
    "    \"\"\"Gradient descent for optimizing slope in simple linear regression\"\"\"\n",
    "    # history\n",
    "    ws = np.zeros((iteration + 1, 2))\n",
    "    ws[0] = w[:, 0]\n",
    "    mse_train = [mean_squared_error(y_train, x_train @ w)]\n",
    "    dmse_train = []\n",
    "    mse_test = [mean_squared_error(y_test, x_test @ w)]\n",
    "    prediction = {(w[0][0], w[1][0]): x_train @ w}\n",
    "\n",
    "    print(\n",
    "        f\"Iteration 0: b = {w[0][0]:.2f}, w = {w[1][0]:.2f}, \"\n",
    "        f\"Loss_train = {mse_train[0]:.2f}, \"\n",
    "        f\"Loss_test = {mse_test[0]:.2f}.\"\n",
    "    )\n",
    "\n",
    "    for i in range(iteration):\n",
    "        if not batch_size:\n",
    "            x_sample = x_train\n",
    "            y_sample = y_train\n",
    "        else:\n",
    "            indxs = np.random.choice(x_train.shape[0], batch_size)\n",
    "            x_sample = x_train[indxs, :]\n",
    "            y_sample = y_train[indxs, :]\n",
    "\n",
    "        # adjust w based on gradient * learning rate\n",
    "        grad = gradient(x_sample, y_sample, w)\n",
    "        w -= alpha * grad  # adjust w based on gradient * learning rate\n",
    "        # history\n",
    "        ws[i + 1] = w[:, 0]\n",
    "        mse_train.append(mean_squared_error(y_train, x_train @ w))\n",
    "        dmse_train.append(grad)\n",
    "        mse_test.append(mean_squared_error(y_test, x_test @ w))\n",
    "        prediction[(w[0][0], w[1][0])] = x_train @ w\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(\n",
    "                f\"Iteration {i+1}: b = {w[0][0]:.2f}, w = {w[1][0]:.2f}, \"\n",
    "                f\"Loss_train = {mse_train[i]:.2f}, \"\n",
    "                f\"Loss_test = {mse_test[i]:3.2f}.\"\n",
    "            )\n",
    "    return ws, prediction, mse_train, dmse_train, mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сравнить результаты, будем использовать одни и те же количество итераций и скорость обучения. Чтобы компенсировать стохастичность, возьмем маленькое значение $\\alpha$ и $100$ итераций.\n",
    "\n",
    "Для всего train сета мы посчитаем градиент для $20\\cdot100 = 2000$ точек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[57.0], [33.0]])\n",
    "ws, prediction, mse_train, dmse_train, mse_test = stochastic_gradient_descent(\n",
    "    x_train_scaled,\n",
    "    y_train,\n",
    "    x_test_scaled,\n",
    "    y_test,\n",
    "    w,\n",
    "    0.02,\n",
    "    iteration=100,\n",
    "    batch_size=None,\n",
    ")\n",
    "\n",
    "f1 = plot_gradient_descent_2d(\n",
    "    x_train_scaled[:, 1],\n",
    "    y_train[:, 0],\n",
    "    ws,\n",
    "    slopes,\n",
    "    intercepts,\n",
    "    mode=\"lines\",\n",
    "    title=\"Batch gradient descent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для стохастического градиентного спуска (размер $\\text{batch}=1$) мы посчитаем градиент для $1\\cdot100 = 100$ точек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.array([[57.0], [33.0]])\n",
    "ws_stohastic, prediction, mse_train, dmse_train, mse_test = stochastic_gradient_descent(\n",
    "    x_train_scaled,\n",
    "    y_train,\n",
    "    x_test_scaled,\n",
    "    y_test,\n",
    "    w,\n",
    "    0.02,\n",
    "    iteration=100,\n",
    "    batch_size=1,\n",
    ")\n",
    "f2 = plot_gradient_descent_2d(\n",
    "    x_train_scaled[:, 1],\n",
    "    y_train[:, 0],\n",
    "    ws_stohastic,\n",
    "    slopes,\n",
    "    intercepts,\n",
    "    mode=\"lines\",\n",
    "    title=\"Stochastic gradient descent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для стохастического спуска с $\\text{mini-batch}=5$ мы посчитаем градиент для $5\\cdot100=500$ точек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.array([[57.0], [33.0]])\n",
    "(\n",
    "    ws_mini_batch,\n",
    "    prediction,\n",
    "    mse_train,\n",
    "    dmse_train,\n",
    "    mse_test,\n",
    ") = stochastic_gradient_descent(\n",
    "    x_train_scaled,\n",
    "    y_train,\n",
    "    x_test_scaled,\n",
    "    y_test,\n",
    "    w,\n",
    "    0.02,\n",
    "    iteration=100,\n",
    "    batch_size=5,\n",
    ")\n",
    "f3 = plot_gradient_descent_2d(\n",
    "    x_train_scaled[:, 1],\n",
    "    y_train[:, 0],\n",
    "    ws_mini_batch,\n",
    "    slopes,\n",
    "    intercepts,\n",
    "    mode=\"lines\",\n",
    "    title=\"Mini-batch gradient descent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы ищем минимум для всех данных.\n",
    "- Градиент, рассчитанный по одному объекту, будет специфичен. Трек обучения  в случае стохастического градиентного спуска будет запутанным, а итоговая ошибка будет расти с увеличением скорости обучения (мы взяли низкую скорость).\n",
    "- Градиент, рассчитанный по нескольким объектам будет давать лучшую оценку градиента для всех данных. Трек будет менее сложным.\n",
    "- Градиент, рассчитанный по всей выборке, будет давать наиболее точное направление."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactive_visualization import plot_panel\n",
    "\n",
    "plot_panel(f1, f2, f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для **ускорения расчетов** рекомендовано использовать **максимальный размер mini-batch**, который помещается в память, но это не всегда дает лучший результат. На 7 лекции вы увидите, что для сложных моделей стохастичность, связанная с небольшим размером батча, может помочь выбраться из локального минимума и найти более глубокий.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hinge loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем разобраться, что делать в случае классификации.\n",
    "\n",
    "Рассмотрим задачу классификации на два класса. Например, у нас есть данные о лабораторных мышах. Часть из них имеет нормальную массу тела, а часть — мыши с ожирением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/svm_mouse_example.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак:\n",
    "1. У нас есть набор данных из $N$ объектов (мышей).\n",
    "2. Для каждого из объектов (мышей) нам известно признаковое описание объекта в виде набора вещественных чисел (вес, длина от носа до кончика хвоста, возраст и т.д.). То есть объекту под номером $i$ соответствует вектор $\\vec x_i$.\n",
    "3. Также для каждого объекта нам известна истинная метка класса. Мы знаем, что объекту с признаковым описанием $\\vec x_i$ соответствует метка класса $y_i$. Будем считать, что метки классов принимают значения:\n",
    "$$y_i =\n",
    "\\begin{cases}\n",
    "    +1, & \\text{для пухляшей}, \\\\\n",
    "    -1, & \\text{для всех остальных}.\n",
    "\\end{cases}$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "В задаче регрессии мы использовали метрику $MSE$ в качестве функции потерь. Здесь мы можем сделать что-то подобное.\n",
    "\n",
    "Мы можем ввести пороговое решающее правило: определять метку класса по знаку линейной функции (случай $x = 0$ можем отнести к любому классу):\n",
    "\n",
    "$$\\large y_i^{pred} = sign(\\vec{w}\\vec{x_i}+b)$$\n",
    "\n",
    "где $sign$ — сигнум-функция (функция знака).\n",
    "\n",
    "$$sign(x) =\n",
    "\\begin{cases}\n",
    "    +1, & x>0, \\\\\n",
    "    0 & x=0,\\\\\n",
    "    -1, & x<0.\n",
    "\\end{cases}$$\n",
    "\n",
    "Используя такое решающее правило, мы можем посчитать метрику $accuracy$:\n",
    "\n",
    "$$accuracy=\\frac{\\sum_{i=1}^N [sign(\\vec{w}\\vec{x_i}+b)==y_i]}{N}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно максимизировать $accuracy$, а значит минимизировать $1-accuracy$. Действуя по аналогии с задачей регрессии, мы могли бы задать функцию потерь следующим образом:\n",
    "$$Loss = 1-accuracy =  \\frac{\\sum_{i=1}^N \\overline{[sign(\\vec{w}\\vec{x_i}+b)==y_i]}}{N} = \\frac{\\sum_{i=1}^N l_i}{N}$$\n",
    "\n",
    "$$l_i = \\overline{[sign(\\vec{w}\\vec{x_i}+b)==y_i]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция $l_i$ будет представлять собой ступеньку (1 — там, где мы ошиблись, и 0 — где класс определен правильно). Это плохо, т.к производная такой функции будет равна нулю почти везде, а это значит, что у нас будут проблемы с поиском минимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/hinge_loss.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем модифицировать функцию потерь, задав оценку сверху для $l_i$, полученного из $accuracy$:\n",
    "\n",
    "$$\\large l_i = \\max(0, 1 - y_i ((\\vec w, \\vec x_i) + b ))$$\n",
    "\n",
    "Данная модификация входит в [Hinge loss](https://en.wikipedia.org/wiki/Hinge_loss):\n",
    "$$\\large Loss = \\frac{1}{2}||w||^2 + C\\frac{\\sum_{i=1}^N l_i}{N} $$\n",
    "\n",
    "где $C$ — обратный коэффициент регуляризации, гиперпараметр, значение по умолчанию в `sklearn`: `C=1.0`.\n",
    "\n",
    "Пока не очень понятно, почему появился член с $w^2$, но он очень важен. Чтобы понять его назначение, рассмотрим задачу геометрически."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1D классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим **одномерный пример**. У нас есть данные только по **массе мышей**. Часть из них определена как мыши с нормальной массой тела, а часть — как мыши с ожирением.\n",
    "\n",
    "Чтобы их отделить друг от друга, нам достаточно одного критерия. Мы можем посмотреть на график и визуально определить предельную массу, после которой мышки будут жирненькими."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "custom_cmap = ListedColormap([\"#B8E1EC\", \"#bea6ff\", \"#FEE7D0\"])\n",
    "\n",
    "\n",
    "def generate_data(total_len=40):\n",
    "    x = np.hstack(\n",
    "        [\n",
    "            np.random.uniform(14, 21, total_len // 2),\n",
    "            np.random.uniform(24, 33, total_len // 2),\n",
    "        ]\n",
    "    )\n",
    "    y = np.hstack([np.zeros(total_len // 2), np.ones(total_len // 2)])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def plot_data_1d(\n",
    "    x,\n",
    "    y,\n",
    "    total_len=40,\n",
    "    s=50,\n",
    "    threshold=None,\n",
    "    margin=None,\n",
    "    legend=[\"Normal\", \"Obese\"],\n",
    "    marker=\"o\",\n",
    "):\n",
    "    ax = sns.scatterplot(x=x, y=np.zeros(len(x)), hue=y, s=s, marker=marker)\n",
    "    if threshold:\n",
    "        x_lim, y_lim = ax.get_xlim(), ax.get_ylim()\n",
    "        XX, YY = np.meshgrid(\n",
    "            np.linspace(x_lim[0], x_lim[1], 100), np.linspace(y_lim[0], y_lim[1], 100)\n",
    "        )\n",
    "        pred = np.sign(XX - threshold)\n",
    "        plt.contourf(XX, YY, pred, alpha=0.3, cmap=custom_cmap)\n",
    "        ax.axvline(threshold, color=\"grey\")\n",
    "    if margin:\n",
    "        for line in margin:\n",
    "            ax.axvline(line, color=\"grey\", ls=\"dashed\")\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, legend)\n",
    "    ax.set(xlabel=\"Mass, g\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "total_len = 40\n",
    "np.random.seed(42)\n",
    "x, y = generate_data(total_len=total_len)\n",
    "plt.figure(figsize=(5, 3))\n",
    "ax = plot_data_1d(x, y, threshold=21.5, total_len=total_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, пользуясь нашим простым критерием, попробуем классифицировать каких-то новых (тестовых) мышей $\\color{orange}{✭}$ $\\color{blue}{✭}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.random.uniform(14, 30, 5)\n",
    "\n",
    "\n",
    "def classify(x, threshold=21.5):\n",
    "    y = np.zeros_like(x)\n",
    "    y[x > threshold] = 1\n",
    "    return y\n",
    "\n",
    "\n",
    "total_len = 40\n",
    "threshold = 21.5\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "ax = plot_data_1d(x, y, threshold=threshold, total_len=total_len)\n",
    "ax = plot_data_1d(\n",
    "    x_test, classify(x_test, threshold), total_len=total_len, s=500, marker=\"*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из тестовых мышей была классифицирована, как толстенькая ($\\color{orange}{✭}$ на границе), хотя она ближе по массе к мышам без ожирения из обучающей выборки $\\color{blue}{●}$. Не порядок!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Margin Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вооружившись этим новым знанием, попробуем классифицировать наших отъевшихся мышек по-умному. Возьмем крайние точки в каждом кластере. И в качестве порогового значения будем использовать среднее между ними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_limit = x[y == 0].max()  # extreme point for 'normal'\n",
    "obese_limit = x[y == 1].min()  # extreme point for 'obese'\n",
    "\n",
    "threshold = np.mean([normal_limit, obese_limit])  # separated with mean value\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "ax = plot_data_1d(\n",
    "    x, y, total_len=total_len, threshold=threshold, margin=[normal_limit, obese_limit]\n",
    ")\n",
    "ax = plot_data_1d(\n",
    "    x_test,\n",
    "    classify(x_test, threshold=threshold),\n",
    "    total_len=total_len,\n",
    "    s=500,\n",
    "    marker=\"*\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем посчитать, насколько наша мышь близка к тому, чтобы оказаться в другом классе. Такое расстояние называется **margin**. И оно считается как $\\mathrm{margin} = |\\mathrm{threshold} - \\mathrm{observation}|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins = np.abs(x_test - threshold)\n",
    "print(margins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответственно, если мы посчитаем margins для наших крайних точек `normal_limit` и `obese_limit`, мы найдем самое большое возможное значение margin для нашего классификатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_0 = np.abs(normal_limit - threshold)\n",
    "margin_1 = np.abs(obese_limit - threshold)\n",
    "print(margin_0, margin_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой классификатор мы называем **Maximum Margin Classifier**. Он хорошо работает в случае, когда классы не пересекаются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь рассмотрим пример, где мы измерили не только вес мышей, но и их длину от хвоста до носа. Теперь не очевидно, какие точки кластеров у нас являются крайними и как провести разделяющую прямую, чтобы классы были максимально разнесены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "def generate_2d_data(total_len=40):\n",
    "    x, y = make_blobs(n_samples=total_len, centers=2, random_state=42)\n",
    "    x[:, 0] += 10\n",
    "    x[:, 1] += 20\n",
    "    return x, y\n",
    "\n",
    "\n",
    "total_len = 40\n",
    "x, y = generate_2d_data(total_len=total_len)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = sns.scatterplot(x=x[:, 0], y=x[:, 1], hue=y, s=50)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, [\"Normal\", \"Obese\"])\n",
    "ax.set(xlabel=\"Mass, g\", ylabel=\"Length, cm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM: Hard and Soft Margin Classifier\n",
    "\n",
    "Попробуем подойти к задаче с другой стороны (мы немного упростили визуализацию для удобства восприятия, но с мышками будет так же)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы хотим провести разделяющую гиперплоскость таким образом, чтобы:\n",
    "1. Плюсы и минусы лежали по разные стороны от этой плоскости.\n",
    "2. Ближайшие к плоскости объекты были от нее как можно дальше.\n",
    "\n",
    "Второе условие дает нам максимальный зазор (*margin*), который мы тривиально находили в одномерном случае.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/svm_hard_margin.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперплоскость однозначно задается вектором нормали $\\vec w$ и смещением $b$. Мы ищем решение в виде $(\\vec w, \\vec x) + b$, где $(\\vec w, \\vec x)$ — это скалярное произведение, $\\vec w$ — вектор весов, а $b$ — смещение. Скалярное произведение вектора признаков на вектор нормали будет давать проекцию вектора признаков на вектор нормали.  Мы не будем делать вектор $\\vec w$ единичным, вместо этого мы зафиксируем margin на проекции.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого:\n",
    "1. Мы хотим подобрать такие $\\vec  w$ и $b$, чтобы можно было провести такие гиперплоскости:\n",
    "$$\\large (\\vec w, \\vec x) + b  = 1$$\n",
    "\n",
    "- **Лежащие на этой плоскости и выше объекты относятся к классу $+1$:** $\\large (\\vec w, \\vec x_+) + b  \\ge 1$\n",
    "\n",
    "$$\\large (\\vec w, \\vec x) + b  = -1$$\n",
    "\n",
    "- **Лежащие на этой плоскости и ниже объекты относятся к классу $-1$:** $\\large (\\vec w, \\vec x_-) + b  \\le -1$\n",
    "\n",
    "\n",
    "2. Мы хотим разнести эти плоскости как можно дальше. Расстояние между двумя этими **жесткими** границами можно расписать через проекции **опорных** (лежащих на плоскости) **векторов**: $$(\\vec x_{sv+} - \\vec x_{sv-})\\frac{\\vec w}{||\\vec w||} = \\frac{2}{||\\vec w||}$$\n",
    "\n",
    "Метод, использующий **проекции опорных векторов для определения разделяющей гиперплоскости**, называется **SVM** (*support vector machine*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условие того, что  $i$-й объект лежит по правильную сторону от разделяющих поверхностей, можно записать в совместно:\n",
    "\n",
    "$$\\large y_i ((\\vec w, \\vec x_i) + b )\\ge 1,$$\n",
    "\n",
    "которое должно выполняться для всех объектов $1 \\le i \\le N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди всех решений $\\vec w$ и $b$, которые удовлетворяют условию выше, мы хотим подобрать такое, при котором пороговые разделяющие поверхности будут находится дальше всего. Так как расстояние между ними равно $\\displaystyle\\frac{2}{||\\vec w||}$, мы приходим к следующей задаче на экстремум:\n",
    "\n",
    "$$max \\frac{2}{||\\vec w||} \\Leftrightarrow min \\frac{1}{2} ||\\vec w||^2$$\n",
    "\n",
    "при условии:\n",
    "$$\\large y_i ((\\vec w, \\vec x_i) + b )\\ge 1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подобная задача на условный экстремум для линейно разделимых классов может быть решена аналитически при помощи [метода множителей Лагранжа](https://en.wikipedia.org/wiki/Lagrange_multiplier):\n",
    "\n",
    "Найти $\\alpha_i$, $\\vec w$ и $b$, которые реализуют минимум функции потерь:\n",
    "\n",
    "$$\\large L =  \\frac{1}{2} ||\\vec w||^2 + \\sum_i \\alpha_i [y_i ((\\vec w, \\vec x_i) + b) - 1]$$\n",
    "\n",
    "$\\alpha_i\\geq0$ — множитель Лагранжа. Он будет не равен нулю только для **опорных векторов**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае неразделимости классов написанная выше формула переходит в **Hinge Loss**, $\\displaystyle\\frac{1}{2} ||\\vec w||^2$ в котором отвечает за максимальное разнесение классов. **SVM** c **Hinge Loss** называют **Soft Margin Classifier**.\n",
    "\n",
    "Применим к мышкам метод `svm` из библиотеки `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Code for illustration, later we will understand how it works\n",
    "# fit the model, don't regularize for illustration purposes\n",
    "clf = svm.SVC(kernel=\"linear\", C=1000)\n",
    "clf.fit(x, y)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "# first fig\n",
    "sns.scatterplot(x=x[:, 0], y=x[:, 1], hue=y, s=50, ax=axs[0])\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "axs[0].legend(handles, [\"Normal\", \"Obese\"])\n",
    "axs[0].set(xlabel=\"Mass, g\", ylabel=\"Length, cm\")\n",
    "\n",
    "# plot the decision function\n",
    "delta = 0.5\n",
    "# create grid to evaluate model\n",
    "YY, XX = np.meshgrid(\n",
    "    np.linspace(x[:, 1].min() - delta, x[:, 1].max() + delta, 30),\n",
    "    np.linspace(x[:, 0].min() - delta, x[:, 0].max() + delta, 30),\n",
    ")\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "pred = np.sign(Z)\n",
    "axs[0].contourf(XX, YY, pred, alpha=0.3, cmap=custom_cmap)\n",
    "\n",
    "# plot decision boget_xlimundary and margins\n",
    "axs[0].contour(\n",
    "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
    ")\n",
    "# plot support vectors\n",
    "axs[0].scatter(\n",
    "    clf.support_vectors_[:, 0],\n",
    "    clf.support_vectors_[:, 1],\n",
    "    s=100,\n",
    "    linewidth=1,\n",
    "    facecolors=\"none\",\n",
    "    edgecolors=\"k\",\n",
    ")\n",
    "\n",
    "# second fig\n",
    "dec_val = clf.decision_function(x)\n",
    "sns.scatterplot(x=dec_val, y=np.zeros(len(x)), hue=y, ax=axs[1])\n",
    "\n",
    "x_lim, y_lim = axs[1].get_xlim(), axs[1].get_ylim()\n",
    "XX, YY = np.meshgrid(\n",
    "    np.linspace(x_lim[0], x_lim[1], 100), np.linspace(y_lim[0], y_lim[1], 100)\n",
    ")\n",
    "pred = np.sign(XX)\n",
    "axs[1].contourf(XX, YY, pred, alpha=0.3, cmap=custom_cmap)\n",
    "\n",
    "axs[1].axvline(0, color=\"grey\")\n",
    "axs[1].axvline(-1, color=\"grey\", ls=\"dashed\")\n",
    "axs[1].axvline(1, color=\"grey\", ls=\"dashed\")\n",
    "handles, labels = axs[1].get_legend_handles_labels()\n",
    "axs[1].legend(handles, [\"Normal\", \"Obese\"])\n",
    "axs[1].set(xlabel=\"wx+b\")\n",
    "\n",
    "sv = clf.decision_function(clf.support_vectors_)\n",
    "axs[1].scatter(\n",
    "    sv, np.zeros_like(sv), s=100, linewidth=1, facecolors=\"none\", edgecolors=\"k\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видео с хорошим объяснением [SVM](https://youtu.be/_PwhiWxHK8o)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы добавим еще одно измерение — возраст, мы обнаружим, что наши данные стали трехмерными, а разделяет их теперь не линия, а плоскость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3d_data(total_len=40):\n",
    "    x, y = make_blobs(n_samples=total_len, centers=2, random_state=42, n_features=3)\n",
    "    x[:, 0] += 10\n",
    "    x[:, 1] += 20\n",
    "    x[:, 2] += 10\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def plot_data(x, y, total_len=40, s=50, threshold=21.5):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.scatter(\n",
    "        xs=x[:, 0], ys=x[:, 1], zs=x[:, 2], c=y, s=s, cmap=\"tab10\", vmin=0, vmax=9\n",
    "    )\n",
    "    # plot the decision function\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    # create grid to evaluate model\n",
    "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    ax.plot_surface(XX, YY, XX * YY * 0.2, alpha=0.2)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.set(xlabel=\"Mass, g\", ylabel=\"Length, cm\", zlabel=\"Age, days\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "total_len = 40\n",
    "x, y = generate_3d_data(total_len=total_len)\n",
    "ax = plot_data(x, y, total_len=total_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответственно, если бы у нас было 4 измерения и больше (например: вес, длина, возраст, кровяное давление), то многомерная плоскость, которая бы разделяла наши классы, называлась бы **гиперплоскость** (рисовать мы ее, конечно же, не будем). Чисто технически, и точка, и линия — тоже гиперплоскости. Но все же гиперплоскостью принято называть то, что нельзя нарисовать на бумаге."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Многоклассовая классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение задачи SVM, которое мы рассматривали, касалось задачи бинарной классификации. Мы часто будем работать с несколькими классами.\n",
    "\n",
    "Есть две основные стратегии расширения задачи SVM классификации с двух классов на несколько:\n",
    "* **one vs rest** (один против всех): каждый класс отделяется от всех других одной прямой (гиперплоскостью).\n",
    "* **one vs one** (один против одного): классы попарно отделяются друг от друга прямыми (гиперплоскостями)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датасет из 4 классов для демонстрации отличий между этими способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = [[1, 1], [1, -1], [-1, -1], [-1, 1]]\n",
    "\n",
    "x, y = make_blobs(n_samples=300, centers=centers, cluster_std=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_colors = [\"#1B1464\", \"#0961A5\", \"#754C24\", \"#006837\"]\n",
    "bright_colors = [\"#5D5DA6\", \"#2DA9E1\", \"#F9B041\", \"#4AAE4D\"]\n",
    "dull_cmap = ListedColormap([\"#D1D5ED\", \"#B8E1EC\", \"#FEE7D0\", \"#C9E3C8\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# first fig\n",
    "sns.scatterplot(\n",
    "    x=x[:, 0], y=x[:, 1], hue=y, s=50, ax=ax, palette=sns.color_palette(bright_colors)\n",
    ")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, [\"0\", \"1\", \"2\", \"3\"])\n",
    "ax.set(xlabel=\"feature 1\", ylabel=\"feature 2\")\n",
    "\n",
    "plt.xlim([-2.5, 2.5])\n",
    "plt.ylim([-2.5, 2.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация **one vs rest** реализована в `sklearn` в классе `svm.LinearSVC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC()\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядят разделяющие прямые и нормали к ним для нашей задачи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    x,\n",
    "    response_method=\"predict\",\n",
    "    cmap=dull_cmap,\n",
    "    alpha=0.8,\n",
    "    xlabel=\"feature 1\",\n",
    "    ylabel=\"feature 2\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Plot the training points\n",
    "sns.scatterplot(\n",
    "    x=x[:, 0], y=x[:, 1], hue=y, s=50, ax=ax, palette=sns.color_palette(bright_colors)\n",
    ")\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(-2.5, 2.5)\n",
    "# for visualization\n",
    "arrow_xs = [0.5, 0.5, -0.5, -0.5]\n",
    "for i in range(clf.coef_.shape[0]):\n",
    "    coef = clf.coef_[i]\n",
    "    w = -coef[0] / coef[1]\n",
    "    b = -clf.intercept_[0] / coef[1]\n",
    "    yy = w * xx + b\n",
    "    # normal\n",
    "    plt.arrow(\n",
    "        arrow_xs[i],\n",
    "        w * arrow_xs[i] + b,\n",
    "        coef[0] / 4,\n",
    "        coef[1] / 4,\n",
    "        edgecolor=dark_colors[i],\n",
    "        facecolor=bright_colors[i],\n",
    "        width=0.04,\n",
    "    )\n",
    "    # dividing line\n",
    "    plt.plot(xx, yy, dark_colors[i])\n",
    "\n",
    "plt.xlim([-2.5, 2.5])\n",
    "plt.ylim([-2.5, 2.5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициенты `clf.coef_` возвращают вектор нормали. С помощью `clf.coef_` и `clf.intercept_` можно записать уравнение разделяющей прямой.\n",
    "\n",
    "Для 4 классов стратегия **one vs rest** даст 4 разделяющие прямые (гиперплоскости). Количество разделяющих прямых равно количеству классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует множество модификаций SVM Loss для решения многоклассовой классификации. В литературе (и в задании) вы можете встретить следующую формулировку Loss для SVM задачи:\n",
    "\n",
    "$$ Loss = \\frac{1}{2} ||\\vec w||^2 + {1 \\over N}\\sum_iL_i(f(x_i,W),y_i),$$\n",
    "\n",
    "$$L_i = \\sum_{j\\neq y_i}\\begin{cases}\n",
    "  0,  & \\mbox{если } s_{y_i}\\geq s_j+1\\mbox{} \\\\\n",
    "  s_j-s_{y_i}+1, & \\mbox{если наоборот, то} \\mbox{}\n",
    "\\end{cases}=\\sum_{j\\neq y_i}max(0,s_j-s_{y_i}+1)$$\n",
    "\n",
    "где $s_j = f(x_i, W)_j$ — уравнение для $j$-го класса, $s_{y_i}$ — значение уравнения для истинного класса.\n",
    "\n",
    "Идея данной формулы аналогична **one vs rest**, но вместо абсолютных значений используется разница между предсказаниями для различных классов.\n",
    "\n",
    "Это формулировка появилась в [статье Weston and C. Watkins 1999 года](https://www.esann.org/sites/default/files/proceedings/legacy/es1999-461.pdf) и стала популярной благодаря [cтендфорскому курсу](https://cs231n.github.io/linear-classify/#svm), но для нее нет реализации в `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стратегия **one vs rest** позволяет обучать меньшее количество классификаторов, чем **one vs one**, но при **большом количестве классов** могут появляться проблемы, связанные с **сильным дисбалансом классов** при решении задачи “один против всех”. При большом количестве классов лучше использовать **one vs one** стратегию.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй стратегией многоклассовой классификации для SVM является **one vs one**, в которой классы разделяются попарно. Эта стратегия реализована в классе `svm.SVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    x,\n",
    "    response_method=\"predict\",\n",
    "    cmap=dull_cmap,\n",
    "    alpha=0.8,\n",
    "    xlabel=\"feature 1\",\n",
    "    ylabel=\"feature 2\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Plot the training points\n",
    "sns.scatterplot(\n",
    "    x=x[:, 0], y=x[:, 1], hue=y, s=50, ax=ax, palette=sns.color_palette(bright_colors)\n",
    ")\n",
    "\n",
    "# for visualization\n",
    "arrow_xs = [1, -0.1, 0, -0.17, -0.17, -1]\n",
    "colors_list = [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n",
    "range_list = [(0, 2.5), (-0.3, 0.1), (-0.1, 0.5), (-1, -0.12), (-0.4, 0), (-2.5, 0)]\n",
    "\n",
    "for i in range(clf.coef_.shape[0]):\n",
    "    xx = np.linspace(*range_list[i])\n",
    "    coef = clf.coef_[i]\n",
    "    w = -coef[0] / coef[1]\n",
    "    b = -clf.intercept_[0] / coef[1]\n",
    "    yy = w * xx + b\n",
    "    # normal\n",
    "    plt.arrow(\n",
    "        arrow_xs[i],\n",
    "        w * arrow_xs[i] + b,\n",
    "        coef[0] / 4,\n",
    "        coef[1] / 4,\n",
    "        edgecolor=dark_colors[colors_list[i][0]],\n",
    "        facecolor=bright_colors[colors_list[i][0]],\n",
    "        width=0.04,\n",
    "    )\n",
    "    # dividing line\n",
    "    plt.plot(xx, yy, dark_colors[colors_list[i][1]])\n",
    "\n",
    "plt.xlim([-2.5, 2.5])\n",
    "plt.ylim([-2.5, 2.5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для 4 классов стратегия **one vs one** даст 6 разделяющих прямых (гиперплоскости). Количество разделяющих прямыx:\n",
    "$$ \\frac{n_{classes}\\cdot (n_{classes}-1)}{2},$$\n",
    "гдe $n_{classes}$ — количество классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Практические советы по использованию SVM:**\n",
    "\n",
    "* SVM делает **геометрическое разделение данных**, поэтому для адекватной работы модели важна **нормализация**.\n",
    "* В случае **дисбаланса классов** полезно использовать параметры `class_weight` и  `sample_weight`, подробнее об этом можно почитать [по ссылке](https://scikit-learn.org/stable/modules/svm.html#unbalanced-problems).\n",
    "* SVM может давать хорошее решение при небольшом количестве данных, в этом случае стоит попробовать **различные ядра** (про ядра вы узнаете ниже)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обобщенные линейные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полиномиальная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные не всегда могут быть **хорошо разделены (гипер)плоскостью**. Например, рассмотрим следующее: у нас есть данные по дозировке лекарства и 2 класса — пациенты, которые поправились, и те, которым лучше не стало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_patients_data(total_len=40):\n",
    "    x = np.random.uniform(0, 50, total_len)\n",
    "    y = np.zeros_like(x)\n",
    "    y[(x > 15) & (x < 35)] = 1\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def plot_data(x, y, total_len=40, s=50):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    ax = sns.scatterplot(x=x, y=np.zeros(len(x)), hue=y, s=s)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, [\"Sick\", \"Recover\"])\n",
    "    ax.set(xlabel=\"dose, mg\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "total_len = 40\n",
    "x, y = generate_patients_data(total_len=total_len)\n",
    "ax = plot_data(x, y, total_len=total_len)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответственно, мы не можем найти такое пороговое значение, которое будет разделять наши классы на больных и здоровых, а, следовательно, и Support Vector Classifier работать тоже не будет.  Для начала давайте преобразуем наши данные таким образом, чтобы они стали 2-хмерными. В качестве значений по оси Y будем использовать дозу, возведенную в квадрат (**доза**$^2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x, y, total_len=40, s=50):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    ax = sns.scatterplot(x=x[0, :], y=x[1, :], hue=y, s=s)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, [\"Sick\", \"Recover\"])\n",
    "    ax.set(xlabel=\"Dose, mg\")\n",
    "    ax.set(ylabel=\"Dose$^2$\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "total_len = 40\n",
    "x_1, y = generate_patients_data(total_len=total_len)\n",
    "x_2 = x_1**2\n",
    "x = np.vstack([x_1, x_2])\n",
    "\n",
    "plot_data(x, y, total_len=40, s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем вновь использовать Support Vector Classifier для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(x, y, total_len=40, s=50)\n",
    "\n",
    "x_arr = np.linspace(0, 50, 50)\n",
    "xs = [x[0, :][y == 1].min(), x[0, :][y == 1].max()]\n",
    "ys = [x[1, :][y == 1].min(), x[1, :][y == 1].max()]\n",
    "\n",
    "# Calculate the coefficients.\n",
    "coefficients = np.polyfit(xs, ys, 1)\n",
    "\n",
    "# Let's compute the values of the line...\n",
    "polynomial = np.poly1d(coefficients)\n",
    "y_axis = polynomial(x_arr)\n",
    "\n",
    "# ...and plot the points and the line\n",
    "plt.plot(x_arr, y_axis, \"r--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея **Kernel SVM** состоит в том, что **мы можем перейти в пространство большей размерности, в котором данные будут линейно разделимы**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но тут возникает резонный вопрос: **почему мы решили возвести в квадрат**? Почему не в куб? Или, наоборот, не извлечь корень? Как нам решить, какое преобразование использовать?\n",
    "\n",
    "И у нас есть вторая проблема — а если перейти надо в **пространство очень большой размерности**? В этом случае наши данные очень сильно **увеличатся в размере**.\n",
    "\n",
    "Комбинация двух проблем дает нам много сложности: надо **перебирать большое число возможных пространств большей размерности**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Обоснование Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако основная фишка **Support Vector Machine** состоит в том, что внутри он работает на скалярных произведениях. И можно эти **скалярные произведения** считать, **не переходя в пространство большей размерности**.\n",
    "\n",
    "Для этого SVM использует **Kernel Function**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/svm_kernel_function.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше мы ввели $Loss$ для **Hard Margin Classifier**:\n",
    "\n",
    "$$\\large Loss =  \\frac{1}{2} ||\\vec w||^2 + \\sum_i \\alpha_i [y_i ((\\vec w, \\vec x_i) + b) - 1],$$\n",
    "\n",
    "где $\\alpha_i\\geq0$ — множитель Лагранжа. Он будет не равен нулю только для **опорных векторов**.\n",
    "\n",
    "С добавлением некоторых математических ограничений эту формулу можно [переписать](https://www.geeksforgeeks.org/dual-support-vector-machine/) в **дуальной форме**:\n",
    "\n",
    "$$\\large Loss =  \\sum_i \\alpha_i+ \\sum_i \\sum_j \\alpha_i \\alpha_j\n",
    "y_i y_j (\\vec x_i, \\vec x_j) = \\sum_i \\alpha_i+ \\sum_i \\sum_j \\alpha_i \\alpha_j\n",
    "y_i y_j K(\\vec x_i, \\vec x_j),$$\n",
    "где $(\\vec x_i, \\vec x_j)$ — скалярное произведение.\n",
    "\n",
    "Для получения дуальной формы приравнивают нулю производные $\\displaystyle\\frac {\\partial Loss} {\\partial w}$ и $\\displaystyle\\frac {\\partial Loss} {\\partial b}$ и подставляют их в исходную формулу.\n",
    "\n",
    "В этой формуле можно сделать **kernel trick** — заменить **скалярное произведение** на некоторую функцию от двух векторов, которую мы будем называть **Kernel function**.\n",
    "\n",
    "Важно заметить, что  **дуальная форма** записи для **многоклассовой классификации** возможна только в случае **one vs one**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры ядер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для демонстрации возможностей Kernel SVM создадим датасет, который не разделяется линейными моделями. Для этого воспользуемся функцией `sklearn.datasets.make_circles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "x, y = make_circles(n_samples=500, factor=0.3, noise=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный датасет представляет собой две окружности с разными радиусами и общим центром, относящиеся к разным классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=x[:, 0],\n",
    "    y=x[:, 1],\n",
    "    hue=y,\n",
    "    s=50,\n",
    "    ax=ax,\n",
    "    palette=sns.color_palette([\"#2DA9E1\", \"#F9B041\"]),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию визуализации разделяющего правила для SVM модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "\n",
    "def plot_svm(x, y, clf):\n",
    "    dull_cmap = ListedColormap([\"#B8E1EC\", \"#FEE7D0\"])\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        x,\n",
    "        response_method=\"predict\",\n",
    "        cmap=dull_cmap,\n",
    "        alpha=0.8,\n",
    "        xlabel=\"feature 1\",\n",
    "        ylabel=\"feature 2\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=x[:, 0],\n",
    "        y=x[:, 1],\n",
    "        hue=y,\n",
    "        s=50,\n",
    "        ax=ax,\n",
    "        palette=sns.color_palette([\"#2DA9E1\", \"#F9B041\"]),\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое ядро, которое мы рассмотрим, линейное. Оно задается формулой:\n",
    "$$\\large K(\\vec x_i, \\vec x_j) = (\\vec x_i, \\vec x_j)$$\n",
    "\n",
    "Линейным ядром является скалярное произведение векторов.\n",
    "\n",
    "Линейное ядро не способно справиться с такой задачей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(x, y)\n",
    "plot_svm(x, y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующее ядро, реализованное в библиотеке `sklearn` — полиномиальное, оно задается формулой:\n",
    "$$K(\\vec x_i, \\vec x_j) = (\\gamma (\\vec x_i, \\vec x_j)+r)^d,$$\n",
    "где $d$ — настраиваемый параметр: степень полинома `degree`.\n",
    "\n",
    "Попробуем применить полиномиальное ядро к нашим данным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"poly\")\n",
    "clf.fit(x, y)\n",
    "plot_svm(x, y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полиномиальное ядро действует не совсем как полиномиальная модель:\n",
    "$$\\large f(\\vec wX +b) = (\\vec wX +b)^2 = (\\vec wX)^2 +2b \\vec wX + b^2$$\n",
    "\n",
    "Kernel SVM не создает новых весов, а перераспределяет веса, которые были у линейной модели.\n",
    "\n",
    "У модели не получилось разделить данные. Это связано с тем, что значение `degree` по умолчанию равно 3 (хотя если бы мы взяли \"честную” полиномиальную модель, нам бы хватило 2-й степени).\n",
    "\n",
    "Попробуем увеличить степень полинома:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"poly\", degree=4)\n",
    "clf.fit(x, y)\n",
    "plot_svm(x, y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод который тут стоит сделать: для получения **оптимального результата** бывает полезным **настроить параметры ядра** с учетом даных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самым  популярным ядром SVM является ядро радиальных базисных функций RBF, или гауссово ядро. Оно получено из гауссова  распределения, а гауссово распределение характерно для большого количества измеряемых величин. Данное ядро задается формулой:\n",
    "\n",
    "$$\\large K(\\vec x_i, \\vec x_j) = e^{-\\gamma{||\\vec x_i - \\vec x_j||^2}}$$\n",
    "\n",
    "Настраиваемыми параметрами модели являются `C` и `gamma`. `C` определяет степень гладкости поверхности принятия решений: чем больше `C`, тем сложнее поверхность и **выше вероятность переобучения** (про переобучение поговорим ниже). `gamma` определяет  влияние одного обучающего примера [подробнее](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel).\n",
    "\n",
    "SVM может проверять пространства признаков бесконечного размера, если для такого пространства существует kernel function. RFB ядро как раз [соответствует](https://pages.cs.wisc.edu/~matthewb/pages/notes/pdf/svms/RBFKernel.pdf) такому случаю бесконечномерного пространства признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"rbf\")\n",
    "clf.fit(x, y)\n",
    "plot_svm(x, y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в `sklearn` реализовано `sigma` ядро. Оно интересно больше с исторической точки зрения, т.к. эквивалентно модели нейрона — Перцептрону, о котором вы узнаете на 5-й лекции. [На практике](https://home.work.caltech.edu/~htlin/publication/doc/tanh.pdf) оно в большинстве случаев проигрывает RBF ядру.\n",
    "\n",
    "$$\\large K(\\vec x_i, \\vec x_j) = tanh (\\gamma(\\vec x_i, \\vec x_j)+r)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практические особенности работы с линейными моделями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже обсудили, зачем нужна нормализация данных для линейной модели. В данном разделе мы обсудим виды нормализации более подробно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет с образцами здоровой и раковой ткани. Датасет состоит из 569 примеров, где каждой строчке из 30 признаков соответствует класс `1` злокачественной (*malignant*) или `0` доброкачественной (*benign*) ткани. Задача состоит в том, чтобы по 30-ти признакам обучить модель определять тип ткани (злокачественная или доброкачественная).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "cancer = sklearn.datasets.load_breast_cancer()  # load data\n",
    "\n",
    "x = cancer.data  # features\n",
    "y = cancer.target  # labels(classes)\n",
    "print(f\"x shape: {x.shape}, y shape: {y.shape}\")\n",
    "print(f\"x[0]: \\n {x[0]}\")\n",
    "print(f\"y[0]: \\n {y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Быстрее и удобнее можно посмотреть на данные, используя pandas. К тому же Colab добавил возможность визуализации данных (для этого можно тыкнуть синий значок диаграммы ▆ █ ▄  под таблицей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cancer_df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
    "cancer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colab делает не полную визуализацию признаков, но и на данных изображениях можно найти полезную **информацию о выбросах** (из графика **Values**), **плотности распределений** (из графика **Distributions**) и о наличии **зависимости между переменными** (из графика **2-d distributions**). Например, мы можем увидеть, что значения признаков *mean area* и *mean perimeter* имеют зависимость, близкую к линейной, что не очень хорошо (почему, обсудим позже).\n",
    "\n",
    "Кроме того, можно тыкнуть на рисунок, посмотреть и скопировать код визуализации, чтобы применить к другим данным или изменить под свои нужды."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте посмотрим на сами данные. У нас есть 569 строк, в каждой из которой по 30 колонок. Такие колонки называют признаками или *features*. Попробуем математически описать все эти признаки (mean, std, min и тд)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое, но в виде графика. Видно, что у фич совершенно разные диапазоны  значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "ax = sns.boxenplot(\n",
    "    data=cancer_df,\n",
    "    orient=\"h\",\n",
    "    palette=\"Set2\",\n",
    "    linewidth=0.4,\n",
    "    flier_kws={\"marker\": \"o\", \"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    ")\n",
    "ax.set(xscale=\"log\", xlim=(1e-4, 1e4), xlabel=\"Values\", ylabel=\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная модель представляет собой **сумму взвешенных признаков**. Если мы приведем признаки к **единому масштабу**, мы сможем **оценить их вклад в модель** по значениям весов. Кроме того, работать с признаками в одном диапазоне вычислительно удобно. Для этого будем использовать нормализацию.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нормализацией** называется процедура приведения входных данных к **общим значениям математических статистик**.\n",
    "\n",
    "Нормализация строит **взаимно однозначное соответствие** между некоторыми размерными величинами (которые измеряются в метрах, килограммах, годах и т. п.) и их безразмерными аналогами. Исходные значения **можно восстановить**, зная статистики оригинальных данных и правило, по которому делалась нормализация.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто используют следующие варианты нормализации:  **`MinMaxScaler`**, **`StandardScaler`**, **`RobustScaler`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея **`MinMaxScaler`** заключается в том, что он преобразует данные из имеющегося диапазона значений в диапазон от $0$ до $1$. Может быть полезно, если нужно выполнить преобразование, в котором отрицательные значения не допускаются (например, масштабирование RGB пикселей)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$z_i=\\frac{X_i-X_{min}}{X_{max}-X_{min}},$$\n",
    "\n",
    "где $z_i$ — масштабированное значение, $X_i$ — текущее значение, $X_{min}$ и $X_{max}$ — минимальное и максимальное значения имеющихся данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея **`StandardScaler`** заключается в том, что он преобразует данные таким образом, что распределение будет иметь среднее значение $0$ и стандартное отклонение $1$. Большинство значений будет находиться в диапазоне от $-1$ до $1$. Это стандартная трансформация, и она применима во многих ситуациях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$z_i=\\frac{X_i-u}{s},$$\n",
    "\n",
    "где $u$ — среднее значение (или $0$ при `with_mean=False`), $s$ — стандартное отклонение (или $0$ при `with_std=False`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И `StandardScaler`, и `MinMaxScaler` чувствительны к наличию выбросов. **`RobustScaler`** использует медиану и основан на *процентилях*. k-й процентиль — это величина, равная или не превосходящая k процентов чисел во всём имеющемся распределении. Например, 50-й процентиль (медиана) распределения таков, что 50% чисел из распределения не меньше данного числа.\n",
    "\n",
    "Соответственно, `RobustScaler` не зависит от небольшого числа очень больших предельных выбросов (outliers). Следовательно, результирующий диапазон преобразованных значений признаков больше, чем для предыдущих скэйлеров и, что более важно, примерно одинаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$z_i=\\frac{X_i-X_{median}}{IQR},$$\n",
    "\n",
    "где $X_{median}$ — значение медианы, $IQR$ — межквартильный диапазон, равный разнице между 75-ым и 25-ым процентилями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним `MinMaxScaler`, `StandardScaler`, `RobustScaler` для случайного набора признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "random_names = random.sample(list(cancer.feature_names), 8)\n",
    "cut_df = cancer_df[random_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "\n",
    "\n",
    "def plot_norm(df, ax, title):\n",
    "    sns.boxenplot(\n",
    "        df,\n",
    "        orient=\"h\",\n",
    "        palette=\"Set2\",\n",
    "        ax=ax,\n",
    "        linewidth=0.2,\n",
    "        flier_kws={\"marker\": \"o\", \"s\": 5},\n",
    "        line_kws={\"linewidth\": 1},\n",
    "    )\n",
    "    ax.set(xlabel=\"Values\", title=title)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 7))\n",
    "\n",
    "plot_norm(cut_df, axs[0][0], \"Original\")\n",
    "axs[0][0].set(xscale=\"log\", xlim=(1e-4, 1e4))\n",
    "\n",
    "min_max_x = MinMaxScaler().fit_transform(cut_df)\n",
    "plot_norm(pd.DataFrame(min_max_x, columns=random_names), axs[0][1], \"MinMax\")\n",
    "\n",
    "std_x = StandardScaler().fit_transform(cut_df)\n",
    "plot_norm(pd.DataFrame(std_x, columns=random_names), axs[1][0], \"Standard\")\n",
    "\n",
    "rob_x = RobustScaler().fit_transform(cut_df)\n",
    "plot_norm(pd.DataFrame(rob_x, columns=random_names), axs[1][1], \"Robust\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.55, hspace=0.35)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед выбором нормализации важно разобраться с природой выбросов. Для этого на выбросы нужно посмотреть с точки зрения эксперта и попробовать определить, являются ли выбросы ошибкой при сборе данных или редкими случаями, которые необходимо сохранить.\n",
    "\n",
    "Мы не являемся экспертами в медицине и мало знаем о данных, поэтому мы будем считать, что наши признаки имеют распределение, близкое к нормальному (мы можем сделать такое предположение из центральной предельной теоремы в теории вероятности). Поэтому мы будем использовать `StandardScaler`. `StandardScaler` часто используют как нормировку по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = StandardScaler().fit_transform(cancer_df)  # scaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что они стали намного более сравнимы между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_norm, columns=cancer.feature_names).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "ax = sns.boxenplot(\n",
    "    data=pd.DataFrame(x_norm, columns=cancer.feature_names),\n",
    "    orient=\"h\",\n",
    "    palette=\"Set2\",\n",
    "    linewidth=0.4,\n",
    "    flier_kws={\"marker\": \"o\", \"s\": 3},\n",
    "    line_kws={\"linewidth\": 1},\n",
    ")\n",
    "ax.set(xlabel=\"Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проблема корреляции признаков  в случае линейных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто может оказаться, что признаковое описание объекта избыточно и между различными признаками имеются связи. Для устойчивости работы линейных моделей важно, чтобы среди признаков не было скоррелированных пар.\n",
    "\n",
    "Например, если мы будем решать задачу регрессии на наборе признаков $x_1 \\dots x_n$, среди которых есть связь $x_2 = 5 x_1$, и возьмём линейную модель вида\n",
    "$$\\large y = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + b,$$\n",
    "то с учётом данной связи мы можем записать:\n",
    "$$\\large y = w_1 x_1 + w_2 (5x_1) + \\dots + w_n x_n + b = (w_1 + 5 w_2) x_1 +  w_3 x_3 + \\dots + w_n x_n + b.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, наша модель теперь учитывает признак $x_1$ с одним \"общим\" весом $(w_1 + 5 w_2)$, несмотря на то, что он закодирован двумя независимыми параметрами. Решение, то есть набор весовых коэффициентов $w_i$, перестало быть единственным, так как мы теперь можем делать произвольные преобразования с числами $w_1$ и $w_2$ до тех пор, пока $(w_1 + 5 w_2)$ остаётся неизменным:\n",
    "\n",
    "$$(w_1 + 5 w_2) = \\{w_1 \\rightarrow  w_1 + 5000 ,\\, w_2 \\rightarrow  w_2 - 1000 \\} $$\n",
    "$$(w_1 + 5 w_2) = \\{w_1 \\rightarrow  w_1 + 5000000 ,\\, w_2 \\rightarrow  w_2 - 1000000 \\} $$\n",
    "$$(w_1 + 5 w_2) = \\{w_1 \\rightarrow  w_1 + 5000000000 ,\\, w_2 \\rightarrow  w_2 - 1000000000 \\} $$\n",
    "$$(w_1 + 5 w_2) = \\{w_1 \\rightarrow  w_1 + 5000000000000 ,\\, w_2 \\rightarrow  w_2 - 1000000000000 \\} $$\n",
    "$$(w_1 + 5 w_2) = \\{w_1 \\rightarrow  w_1 + Nan ,\\, w_2 \\rightarrow  w_2 + Nan\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Чем это плохо?**\n",
    "\n",
    "В случае корреляции признаков задача не имеет единственного решения и не существует обратной матрицы, обеспечивающей аналитическое решение. Мы можем использовать градиентные методы (поговорим позже) для поиска решения, но\n",
    "при этом веса модели могут неконтролируемо расти. При этом **суммарный вклад** признаков может быть **мал**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/carrelation_problem1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем оценивать **важность признаков в линейной модели**, используя **веса** перед ними (признаки должны быть нормализованы). Чем больше модуль веса, тем больше вклад. Для коррелированных признаков важность будет переоценена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/carrelation_problem2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, нужно помнить, что диапазоны числовых переменных ограничены. При неконтролируемом росте весов значение может выйти за диапазон и превратиться в ~~тыкву~~ `Nan`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/carrelation_problem3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что делать?**\n",
    "\n",
    "Визуализировать подобные зависимости можно при помощи построения матрицы попарных корреляций признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cancer_df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = cancer_df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В наших данных сильно скоррелированы данные о размерах опухоли (мы могли видеть это выше при визуализации 2-d distributions).\n",
    "\n",
    "В случае корреляции можно:\n",
    "- **добавить регуляризацию** (о том, что такое регуляризация, мы поговорим дальше);\n",
    "- **оставить один признак**;\n",
    "- если есть сомнения, что при удалении признаков часть информации будет потеряна, можно оставить **один признак** неизменным и вычесть его из остальных (оставить только **разницу**). Неинформативные шумовые признаки можно удалить (как это делать, вы узнаете на 4-й лекции).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Сложность модели__ (*model complexity*) — важный гиперпараметр. В частности, для линейных моделей сложность может быть представлена количеством параметров, для полиномиальных моделей — степенью полинома, для деревьев решений — глубиной дерева и т.д.\n",
    "\n",
    "Сложность модели тесно связана с __ошибкой обобщения__ (_generalization error_). Ошибка обобщения отличается от ошибки обучения, измеряемой на тренировочных данных, тем, что позволяет оценить обобщающую способность модели, приобретенную в процессе обучения, давать точные ответы на неизвестных ей объектах. Cлишком простой модели не будет хватать мощности для обобщения сложной закономерности в данных, что приводит к большой ошибке обобщения. С другой стороны, слишком сложная модель также приводит к большой ошибке обобщения за счет того, что в силу своей сложности модель начинает пытаться искать закономерности в шуме, добиваясь большей точности на тренировочных данных, теряя при этом часть обобщающей способности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/model_complexity.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/l2_regularization.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры модели задают некоторую **аппроксимацию целевой функции**. Аппроксимировать целевую функцию можно несколькими способами, например:\n",
    "1. Использовать все имеющиеся данные и провести ее строго **через все точки**, которые нам известны ($f1$ на картинке);\n",
    "2. Использовать более простую функцию (в данном случае, линейную), которая не попадет точно во все данные, но зато будет соответствовать некоторым **общим закономерностям**, которые у них есть ($f2$ на картинке).\n",
    "\n",
    "Характерной чертой переобучения является первый сценарий, и сопровождается он, как правило, **большими весами**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проиллюстрируем описанное явление на примере полиномиальной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2 * np.pi, 10)\n",
    "y = np.sin(x) + np.random.normal(scale=0.25, size=len(x))\n",
    "x_true = np.linspace(0, 2 * np.pi, 200)\n",
    "y_true = np.sin(x_true)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(x, y, s=50, facecolors=\"none\", edgecolors=\"b\", label=\"noisy data\")\n",
    "plt.plot(x_true, y_true, c=\"lime\", label=\"ground truth\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем аппроксимировать имеющуюся зависимость с помощью полиномиальной модели, используя шумные данные в качестве тренировочных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "x_train = x.reshape(-1, 1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i, degree in enumerate([0, 1, 3, 9]):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "\n",
    "    model.fit(x_train, y)\n",
    "    y_plot = model.predict(x_true.reshape(-1, 1))\n",
    "\n",
    "    fig.add_subplot(2, 2, i + 1)\n",
    "    plt.plot(x_true, y_plot, c=\"red\", label=f\"M={degree}\")\n",
    "    plt.scatter(x, y, s=50, facecolors=\"none\", edgecolors=\"b\")\n",
    "    plt.plot(x_true, y_true, c=\"lime\")\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что модель может переобучаться, подстраиваясь под тренировочную выборку. В полиноме степень, и, как следствие, количество весов — это гиперпараметр, который можно подбирать на кросс-валидации, однако когда мы таким образом подбираем сложность модели, мы накладываем довольно грубое ограничение на обобщающую способность модели в целом. Вместо этого более разумным было бы оставить модель сложной, но использовать некий ограничитель (__регуляризатор__), который будет заставлять модель отдавать предпочтение выбору более простого обобщения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(9), LinearRegression())\n",
    "model_ridge = make_pipeline(PolynomialFeatures(9), Ridge(alpha=0.1))\n",
    "\n",
    "model.fit(x_train, y)\n",
    "y_plot = model.predict(x_true.reshape(-1, 1))\n",
    "\n",
    "model_ridge.fit(x_train, y)\n",
    "y_plot_ridge = model_ridge.predict(x_true.reshape(-1, 1))\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(x_true, y_plot, c=\"red\", label=f\"M={degree}\")\n",
    "plt.plot(x_true, y_plot_ridge, c=\"black\", label=f\"M={degree}, alpha=0.1\")\n",
    "plt.scatter(x, y, s=50, facecolors=\"none\", edgecolors=\"b\")\n",
    "plt.plot(x_true, y_true, c=\"lime\", label=\"ground truth\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "poly_coef = model[1].coef_\n",
    "\n",
    "eq = f\"y = {round(poly_coef[0], 2)}+{round(poly_coef[1], 2)}*x\"\n",
    "for i in range(2, 10):\n",
    "    eq += f\"+{round(poly_coef[i], 2)}*x^{i}\"\n",
    "\n",
    "print(\"Without regularization: \", eq)\n",
    "\n",
    "poly_coef = model_ridge[1].coef_\n",
    "\n",
    "eq = f\"y = {round(poly_coef[0], 2)}+{round(poly_coef[1], 2)}*x\"\n",
    "for i in range(2, 10):\n",
    "    eq += f\"+{round(poly_coef[i], 2)}*x^{i}\"\n",
    "\n",
    "print(\"With regularization: \", eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что одним из \"симптомов\" переобучения являются аномально большие веса. Модель Ridge Regression, показанная в примере выше, использует L2-регуляризацию для борьбы с этим явлением:\n",
    "\n",
    "$$L_2 = \\alpha \\sum_i w_i^2,$$\n",
    "где $\\alpha$ — это коэффициент регуляризации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Введение **L2-регуляризации** приводит к тому, что **большие веса больше штрафуются** и предпочтение отдается решениям, использующим **малые значения весов**. При этом модель будет **сохранять скоррелированные и неважные признаки с маленькими весами**.\n",
    "\n",
    "Это связано с градиентом $L_2$:\n",
    "$$L'_2 = 2\\alpha \\sum_i |w_i|$$\n",
    "Он будет “тянуть” модель в сторону маленьких весов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/l1_and_l2_regularization.gif\" alt=\"alttext\" width=\"550\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для отбора признаков можно использовать L1-регуляризацию, она больше штрафует маленькие веса.\n",
    "$$L_1 = \\alpha \\sum_i |w_i|$$\n",
    "$$L_1' = \\sum_i\\alpha, \\text{  где } w_i\\neq 0$$\n",
    "\n",
    "L1 одинаково \"штрафует\" модель за любые ненулевые веса.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения интуиции, что L1-регуляризация позволяет отбирать признаки, обычно используют картинку ниже.\n",
    "\n",
    "Голубая область — ограничение на значения весов, которое дает регуляризация.\n",
    "Для **L2** это **окружность**. Черная точка — это минимальное значение для функции Loss с регуляризацией. Для **L2** она будет лежать **на касательной к окружности**. Для **L1** ограничения на значения весов будут иметь **форму ромба**. При этом минимальное значение для функции Loss с регуляризацией будет чаще попадать в **угол ромба**, что соответствует **обнулению веса** одного из признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/l1_l2_regularization.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вероятностный подход в задаче классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наивный Байесовский классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно построить модель классификации, которая будет напрямую оценивать вероятность принадлежности объекта к интересующему нас классу просто на основе информации о распределении объектов по классам в обучающей выборке. Базовую идею такого примера легко продемонстрировать на следующем примере данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Табличные данные: датасет Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим `DataFrame` датасета [Wine](https://archive.ics.uci.edu/ml/datasets/wine), который являлся примером табличных данных в нашей первой лекции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "\n",
    "# Download dataset\n",
    "features, class_labels = load_wine(\n",
    "    return_X_y=True, as_frame=True\n",
    ")  # also we can get data in Bunch (dictionary) or pandas DataFrame\n",
    "\n",
    "wine_dataset = features\n",
    "wine_dataset[\"target\"] = class_labels\n",
    "\n",
    "wine_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет содержит объекты 3 различных классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dataset.target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём первый признак `alcohol`. По имеющийся таблице с данными легко построить функцию распределения $f(x)$, которая будет задавать вероятность $p(\\text{alcohol} = x)$, и найти среди наших данных бутылку вина с параметром `alcohol`, равным $x$ (рисунок слева).\n",
    "\n",
    "Т.к. у нас три класса, мы можем построить распределение объектов в обучающей выборке по признаку `alcohol` отдельно для каждого из этих трёх классов. Эти распределения зададут нам условную вероятность $p(\\text{alcohol} = x |\\text{target} = i)$ того, что объект имеет значение признака `alcohol`, равное $x$, при условии, что он относится к одному из классов с номером $i$ (рисунок справа)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.kdeplot(wine_dataset, x=\"alcohol\", fill=True, ax=axes[0])\n",
    "axes[0].set_title(\"p(alcohol=x)\")\n",
    "\n",
    "sns.kdeplot(\n",
    "    wine_dataset,\n",
    "    x=\"alcohol\",\n",
    "    hue=\"target\",\n",
    "    palette=sns.color_palette([\"#5D5DA6\", \"#2DA9E1\", \"#F9B041\"]),\n",
    "    fill=True,\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title(\"p(alcohol=x|target=i)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрев на плотности распределений по классам (рисунок справа), мы можем предположить, что бутылка с значением $alcohol=11.3$ будет относиться к 1 классу.\n",
    "\n",
    "На языке формул наш “метод пристального вглядывания” можно записать с помощью формулы для условной вероятности по [теореме Байеса](https://en.wikipedia.org/wiki/Bayes'_theorem):\n",
    "\n",
    "$$\\large p(\\text{target} = i | \\text{alcohol} = x) = \\frac{p(\\text{alcohol} = x | \\text{target} = i )p(\\text{target} = i )}{p(\\text{alcohol} = x)},$$\n",
    "\n",
    "где $p(\\text{target} = i | \\text{alcohol} = X)$ — вероятность того, что объект принадлежит классу $i$ при условии того, что признак `alcohol` у него принимает значение $X$, а $p(\\text{target} = i)$ — как часто в датасете встречаются объекты класса $i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы поняли, откуда в названии метода **Байес**, теперь разберемся, **почему он “наивный”**.\n",
    "\n",
    "Мы использовали только один признак: `alcohol`. Всего же у нас 13 признаков.\n",
    "\n",
    "$$\\large p(\\text{target} = i |\\text{features} = \\vec x ) = \\frac{p(\\text{features} = \\vec x | \\text{target} = i )p(\\text{target} = i )}{p(\\text{features} = \\vec x)}$$\n",
    "\n",
    "**“Наивность”** Байеса состоит в том, что эта модель будет рассматривать признаки как **независимые случайные величины**:\n",
    "$$\\large p(\\text{features} = \\vec x)=p(\\text{feature}_1 = x_1)\\cdotp(\\text{feature}_2 = x_2)...(\\text{feature}_n = x_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы решаем задачу классификации на $k$ классов, то для объекта с набором признаком $\\vec x$ по формуле выше мы получим $k$ чисел, характеризующих вероятность принадлежности данного объекта к различным классам. Для финального принятия решения нам останется выбрать тот класс, для которого вероятность принадлежности наивысшая:\n",
    "\n",
    "$$\\large \\text{prediction} = \\underset{i}{\\text{argmax}}{\\left(p(\\text{target} = i |\\text{features} = \\vec x )\\right)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернёмся к нашему датасету Wine и попробуем решить задачу классификации для него при помощи предложенного алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как обычно, разделим наш датасет на тренировочную и валидационную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features.values, class_labels.values, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём реализацию Наивного Байесовского классификатора из [библиотеки sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB). Обучим её на тренировочном датасете и измерим качество на отложенной валидационной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Train the model\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Calculate F1_score\n",
    "pred = model.predict(x_test)\n",
    "f1_score(y_test, pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря простоте модельного датасета Wine наша наивная статистическая модель показала отличное качество работы. Это связано с “простотой” датасета — признаки классов имеют унимодальные распределения (один пик на плотности распределения), для более сложных данных (многомодальные распределения) такого не будет.\n",
    "\n",
    "Тем не менее, подход к решению задачи классификации, связанный с построением модели предсказания принадлежности объекта к имеющимся классам, оказался конструктивным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP: задача определения спама"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наивный Байесовский классификатор часто используют в задаче обнаружения спама, и пример его использования в такой задаче может показаться ещё более наглядным.\n",
    "\n",
    "В рамках данной задачи у нас имеются:\n",
    "- Датасет из текстов сообщений с некоторым фиксированным словарём возможных слов.\n",
    "- Два класса сообщений: спам и нормальное.\n",
    "- Признаковое описание для каждого сообщения, характеризующее количество вхождений каждого из слов словаря в текст сообщения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе этой информации нам нужно научиться отделять нормальные письма от спама. Все письма состоят из 4-х слов: **‘Добрый’, ‘День’, ‘Гости’, ‘Деньги’**. При этом мы уже посчитали, сколько раз каждое слово встречается в каждом классе.\n",
    "\n",
    "Мы можем посчитать вероятность встретить слово **‘Добрый’** в нормальном письме: берем количество слов **‘Добрый’** и делим на количество слов во всех нормальных письмах (с повторениями). Аналогично для других слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/naive_bayes_1.png\" alt=\"alttext\" width=900/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем то же самое для слов из спама."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/naive_bayes_2.png\" alt=\"alttext\" width=900/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем вероятность того, чтобы письмо было нормальным. Для этого количество нормальных писем делим на общее количество писем. Аналогично для спама. Это $p(\\text{target} = i)$ в формуле выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/naive_bayes_3.png\" alt=\"alttext\" width=900/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить вероятность нормального письма с фразой **‘Добрый День’** в \"наивном\" предположении, мы можем перемножить вероятности нормального письма со словом **‘Добрый’** и нормального письма со словом **‘День’**. Это произведение будет $p(\\text{target} = i | \\text{Features} = \\vec X)$ в формуле выше.\n",
    "\n",
    "Считаем $p(\\text{Features} = \\vec X|\\text{target} = i) p(\\text{target} = i)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/naive_bayes_3_5.png\" alt=\"alttext\" width=900/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы работаете с NLP, советуем ознакомиться с Latent Dirichlet Allocation [ссылка](https://youtu.be/T05t-SqKArY?si=6i8SYNccGuJmFG-f) [ссылка](https://youtu.be/BaM1uiCpj_E?si=7VWJ_s6lyUms3tb4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-энтропия как общая функция потерь для задач классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переход к вероятностям\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ####  Sigmoid\n",
    "Начнем с задачи бинарной классификации. Линейная модель задается уравнением:\n",
    "$$s = f(\\vec x) = (\\vec{w}, \\vec{x}) + b$$\n",
    "\n",
    "Выходы такой модели принимают значения от $-∞$ до $+∞$.\n",
    "\n",
    "Нам бы хотелось получить на выходе вероятность того, что объект принадлежит к классу 1. Вероятность принимает значения от 0 до 1. Нам нужна функция которая спроектирует диапазон $(-∞,+∞)$ в диапазон $[0, 1]$.\n",
    "\n",
    "Такой функцией является сигмоида:\n",
    "$$p = \\sigma(s) = \\frac{1}{1+e^{-s}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При $s→-∞$, $p→0$. При $s→+∞$, $p→1$. При $s=0$, $p=0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/scores_to_probability.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения $s$ (score) также называют [logit-ом](https://en.wikipedia.org/wiki/Logit) (пер. “это логарифм”), это связано с тем, что если выразить logit $s$ через вероятность $p$, получится формула:\n",
    "$$s(p) = log \\left(\\frac{p}{1-p}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####SoftMax\n",
    "\n",
    "[Видео от StatQuest, которое объясняет SoftMax](https://www.youtube.com/watch?v=KpKog-L9veg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае многоклассовой классификации мы будем считать по logit-у для каждого класса:\n",
    "$$\\begin{matrix} s_1 = (\\vec{w_1}, \\vec{x}) + b_1\\\\ s_2 = (\\vec{w_2}, \\vec{x}) + b_2\\\\ ... \\\\ s_n = (\\vec{w_n}, \\vec{x}) + b_n \\end{matrix}$$\n",
    "\n",
    "Для непересекающихся классов, результатом классификации будет класс, отвечающий наибольшему logit-у.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что наша модель выдала следующие значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = [\n",
    "    5.1,  # cat\n",
    "    3.2,  # car\n",
    "    -1.7,  # frog\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда, чтобы узнать какой класс наша сеть предсказала, мы могли бы просто взять `argmax` от наших `logits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Predicted class = %i (Cat)\" % (np.argmax(logits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От argmax нельзя посчитать градиент, так как производная от константы равна 0. Соответственно, если бы мы вставили производную от argmax в градиентный спуск, мы бы получили везде нули, и соответственно, наша модель бы вообще ничему не научилась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, мы бы хотели получить не logit’ы, а настоящую вероятность $p$ на выходе модели. Да еще и таким образом, чтобы от наших вероятностей можно было посчитать градиент. Для этого мы можем применить к нашим логитам функцию **SoftMax**:\n",
    "$$p(y=k|x=x_i) = \\frac{e^{s_k(x_i)}}{\\sum_{j=1}^ne^{s_j(x_i)}}$$\n",
    "\n",
    "где $x_i$ - набор признаков, характеризующий один объект из выборки,\n",
    "$s_j(x_i)$ - logit для j-го класса для объекта $x_i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Вероятности всегда неотрицательны**. Отобразим наши logit’ы на значения $[0, +∞)$.\n",
    "\n",
    "> Для этого возведем **экспоненту** (число Эйлера 2.71828) **в степень логита**. В результате, мы получим вектор гарантированно неотрицательных чисел (положительное число, возведенное в степень, даже отрицательную, даст положительное значение).\n",
    "\n",
    "2.Классы не пересекаются, **сумма вероятностей** по всем классам **равна единице**.\n",
    "\n",
    ">  Мы должны их **нормализовать**, то есть поделить на сумму.\n",
    "\n",
    "Это преобразование называется **SoftMax функцией**. **Получаются вероятности**, то есть числа, которые можно интерпретировать, как вероятности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/linear_classifier_softmax.png\" width=\"1024\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{SoftMax}_\\text{кошка} = \\frac{e^{5.1}}{e^{5.1} + e^{3.2} + e^{-1.7}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    return np.exp(logits) / np.sum(np.exp(logits))\n",
    "\n",
    "\n",
    "print(softmax(logits))\n",
    "print(\"Sum = %.2f\" % np.sum(softmax(logits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно обратить внимание, что SoftMax никоим образом не поменял порядок значений. Самому большому logit'у соответствует самая большая вероятность, а самому маленькому, соответственно, самая маленькая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Практическое вычисление SoftMax\n",
    "\n",
    "При вычислении экспоненты от выходов модели могут получиться очень большие числа в силу очень высокой скорости роста экспоненты. Этот факт необходимо учитывать, чтобы вычисления SoftMax были численно стабильны:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "f = np.array([123, 456, 789])\n",
    "p = np.exp(f) / np.sum(np.exp(f))\n",
    "print(f\"logits = {f},\\nprobabilities = {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы регуляризовать вычисление, нам следует предварительно упростить возникающую в вычислении дробь. Для этого мы можем вычесть из каждого $s_i$ положительную константу, чтобы уменьшить значения экспонент. В качестве константы можно выбрать максимальный элемент этого вектора, тогда у нас гарантированно не будет очень больших чисел, и такой способ будет работать более стабильно.\n",
    "\n",
    "$$M = \\max_j s_{j}(x_i)$$\n",
    "$$s^{new}_{j}(x_i)  = s_{j}(x_i) - M $$\n",
    "\n",
    "$$ \\dfrac {e^{s^{new}_{k}(x_i)}} {\\sum_j e^{s^{new}_{j}(x_i)}}  = \\dfrac {e^{s_{k}(x_i) - M }} {\\sum_j e^{s_{j}(x_i) - M }} = \\dfrac {e^{s_{k}(x_i)}e ^ {-M}} {\\sum_j e^{s_{j}(x_i)} e ^ {-M}} = \\dfrac {e ^ {-M} e^{s_{k}(x_i)}} {e ^ {-M} \\sum_j e^{s_{j}(x_i)} } = \\dfrac { e^{s_{k}(x_i)}} { \\sum_j e^{s_{j}(x_i)} }$$\n",
    "\n",
    "где $x_i$ - набор признаков, характеризующий один объект из выборки,\n",
    "$s_j(x_i)$ - logit для j-го класса для объекта $x_i$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([123, 456, 789])\n",
    "f -= f.max()\n",
    "p = np.exp(f) / np.sum(np.exp(f))\n",
    "print(f\"new logits = {f},\\nprobabilities = {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам нужно решить какую функцию потерь использовать. **Вероятности** принимают значения **от 0 до 1**. Если мы будем использовать **Hinge loss** или **MSE**, **максимальным значением ошибки** на указанном диапазоне будет **1**. А нам хочется **максимально штрафовать** модель, если она выдает **неправильный класс с вероятностью 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-entropy / log loss**\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/cross_entropy_plot_loss_with_probability.png\" width=\"800\">\n",
    "\n",
    "\n",
    "Преимуществом Cross-Entropy loss (зеленый) по сравнению с кусочно-гладкой Hinge Loss (ораньжевый) является:\n",
    "- гладкость и отсутствие участка с плато (не имеет нулевых производных или неопределенных точек),\n",
    "- большой градиент для большого Loss, маленький вблизи 100% точности (для кусочно гладкой функции градиент ноль или константа).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Расстояние (дивергенция) Кульбака — Лейблера:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы понять откуда взялась Cross-Entropy, рассмотрим сначала расстояние Кульбака — Лейблера.\n",
    "\n",
    "В математической статистике и теории информации в мерой расхождения между двумя вероятностными распределениями $P$ и $Q$ является расстояние (дивергенция) Кульбака — Лейблера, вычисляемое по формуле\n",
    "$$D_{KL}(P||Q) = ∑_i P(i)\\log\\frac{P(i)}{Q(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем разобраться, что значит эта формула на примере двух монеток:\n",
    "- настоящей с вероятностями орла и решки 0.5 и 0.5 соответственно,\n",
    "- фальшивой с вероятностями орла и решки 0.2 и 0.8 соответственно.\n",
    "\n",
    "Возьмем настоящую монету и произведем 10 бросков (выборок). Получили последовательность $\\color{blue}{О О} \\color{green}{Р} \\color{blue}{О О} \\color{green}{Р} \\color{blue}{О О О} \\color{green}{Р}$, где $\\color{blue}{O}$ - это орел, $\\color{green}{Р}$ - это решка.\n",
    "Посчитаем вероятности выбросить такую последовательность для настоящей и фальшивой монеты. Броски независимые, поэтому значения вероятностей перемножаются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/kl_divergence_1.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем пропорцию вероятностей данной комбинации для настоящей монетки и для фальшивой (независимые случайные величины, вероятности перемножаются). Для заданных значений вероятностей пропорция будет примерно $149:1$. При пропорции $1:1$ монетки будут идентичны.\n",
    "\n",
    "$$\\frac{\\color{blue}{p_1^{N_о}}\\color{green}{p_2^{N_р}}}\n",
    "{\\color{blue}{q_1^{N_о}}\\color{green}{q_2^{N_р}}}=\n",
    "\\frac{\\color{blue}{\\left(\\frac{1}{2}\\right)^{7}}\\color{green}{\\left(\\frac{1}{2}\\right)^{3}}}\n",
    "{\\color{blue}{\\left(\\frac{1}{5}\\right)^{7}}\\color{green}{\\left(\\frac{4}{5}\\right)^{3}}}\\approx \\frac{149}{1}$$\n",
    "\n",
    "Возьмем логарифм от этого значения (это позволит нам избавиться от степеней и заменить умножение сложением) и нормируем на количество бросков монетки $N=\\color{blue}{N_о}+\\color{green}{N_р}$.\n",
    "\n",
    "$$\\frac{\\color{blue}{N_о}}{N}\\log{\\color{blue}{p_1}}+\n",
    "\\frac{\\color{green}{N_р}}{N}\\log{\\color{green}{p_2}}-\n",
    "\\frac{\\color{blue}{N_о}}{N}\\log{\\color{blue}{q_1}}-\n",
    "\\frac{\\color{green}{N_р}}{N}\\log{\\color{green}{q_2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При увеличении количества бросков $N\\to∞$, так как мы бросали настоящую монетку\n",
    "\n",
    "$$\\frac{\\color{blue}{N_о}}{N} \\to \\color{blue}{p1}, \\frac{\\color{green}{N_р}}{N} \\to \\color{green}{p2} .$$\n",
    "\n",
    "Получаем расстояние Кульбака — Лейблера.\n",
    "\n",
    "$$D_{KL}(P||Q) = \\color{blue}{p_1} \\log{\\color{blue}{p_1}}\n",
    "+ \\color{green}{p_2}\\log{\\color{green}{p_2}}\n",
    "- \\color{blue}{p_1}\\log{\\color{blue}{q_1}}\n",
    "- \\color{green}{p_2}\\log{\\color{green}{q_2}}$$\n",
    "\n",
    "$$ = \\color{blue}{p_1} \\log{\\color{blue}{\\frac{p_1}{q_1}}}\n",
    "+ \\color{green}{p_2} \\log{\\color{green}{\\frac{p_2}{q_2}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на разные фальшивые монетки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_dist(q1, q2, p1=0.5, p2=0.5):\n",
    "    return p1 * np.log(p1 / q1) + p2 * np.log(p2 / q2)\n",
    "\n",
    "\n",
    "print(f\"q1 = 0.1, q2 = 0.9, Dkl = {KL_dist(0.1, 0.9):0.3f}\")\n",
    "print(f\"q1 = 0.2, q2 = 0.8, Dkl = {KL_dist(0.2, 0.8):0.3f}\")\n",
    "print(f\"q1 = 0.3, q2 = 0.7, Dkl = {KL_dist(0.3, 0.7):0.3f}\")\n",
    "print(f\"q1 = 0.4, q2 = 0.6, Dkl = {KL_dist(0.4, 0.6):0.3f}\")\n",
    "print(f\"q1 = 0.5, q2 = 0.5, Dkl = {KL_dist(0.5, 0.5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание, что если $P=Q$, то\n",
    "\n",
    "$$D_{KL}(P||Q) = ∑_i P(i)\\log\\frac{P(i)}{Q(i)} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Переход к оценке модели\n",
    "\n",
    "Мы научились определять близость двух распределений. Как это поможет нам оценить качество модели, если мы знаем, какие метки классов должны получиться?\n",
    "\n",
    "Пусть $P$ — вероятности истинных меток классов для объекта (1 для правильного класса, 0 для остальных), $Q(\\theta)$ — вероятности классов для объекта, предсказанные моделью с обучаемыми параметрами $\\theta$.\n",
    "\n",
    "Расстояние Кульбака — Лейблера между истинными и предсказанными значениями\n",
    "\n",
    "$$D_{KL}(P||Q(\\theta)) = ∑_i P(i)\\log\\frac{P(i)}{Q(i| \\theta)} $$\n",
    "\n",
    "$$ = ∑_i P(i)\\log{P(i))} -  ∑_i P(i)\\log{Q(i|\\theta)} $$\n",
    "\n",
    "$$ = - H(P) + H(P|Q(\\theta))$$\n",
    "\n",
    "Мы разбили сумму на две части, первая из которых называется **энтропией** $H(P)$ и не будет зависеть от модели, а вторая называется **кросс-энтропией** $H(P|Q(\\theta))$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Энтропия и кросс-энтропия\n",
    "\n",
    "Понятие энтропии пришло из теории связи. Для расчета энтропии можно использовать формулу Шеннона:\n",
    "\n",
    "$$H(P)=-\\sum^C_{i=1}P(i)\\cdot log_{2}(P(i)),$$\n",
    "где C &mdash; количество классов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В формуле Шеннона не случайно используется логарифм по основанию 2. Она рассчитывает, **сколько бит информации минимально необходимо для передачи одного значения**, например, одного исхода броска монетки.\n",
    "\n",
    "Если монетка **всегда выдает орел**, то нам нет смысла передавать информацию, чтобы предсказать исход\n",
    "\n",
    "$$H(\\color{blue}{p_1 = 1}, \\color{green}{p_2 = 0}) = 0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для настоящей монетки необходимо будет передавать 1 бит информации на бросок\n",
    "$$H(\\color{blue}{p_1 = 0.5},  \\color{green}{p_2 = 0.5})= log_{2}(2) = 1,$$\n",
    "\n",
    "А вот с поддельной монеткой получается интереснее: если сделать много бросков, можно выявить закономерность что решка выпадет чаще (вероятность трех решек подряд будет больше вероятности одного орла) и за счет этого сократить количество передаваемой информации так, чтобы на один бросок получалось меньше 1 бита. Как это сделать — отдельная область теории информации, называемая **кодирование источника**.\n",
    "$$H(\\color{blue}{q_1 = 0.2}, \\color{green}{q_2 = 0.8}) = 0.722$$\n",
    "\n",
    "__Энтропия__ — мера неуверенности, связанная с распределением $P$.\n",
    "Зная истинное распределение случайной величины, мы можем рассчитать его энтропию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы попытаемся использовать статистические данные, полученные для фальшивой монеты $Q$, для настоящей $P$, мы не получим выигрыш в количестве передаваемой информации:\n",
    "\n",
    "$$H(P||Q) = - \\sum^C_{i=1}P(i)\\cdot log_2(Q(i)) = 1.322$$\n",
    "\n",
    "Формула выше называется **кросс-энтропия**.\n",
    "\n",
    "**Кросс-энтропия** позволяет оценить ситуацию, когда мы аппроксимируем истинное распределение $P$ предсказанным распределением $Q$. Чем больше значения кросс-энтропии, тем больше расхождение между распределениями. Поэтому кросс-энтропию используют в качестве **функции потерь**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы показали выше, **кросс-энтропия** связана с **энтропией** и **расстоянием Кульбака — Лейблера**\n",
    "$$H(P||Q) = D_{KL}(P||Q) + H(P).$$\n",
    "\n",
    "Посчитаем значения для наших монеток с помощью кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal coin\n",
    "p1 = 0.5\n",
    "p2 = 0.5\n",
    "\n",
    "# fake coin\n",
    "q1 = 0.2\n",
    "q2 = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kullback–Leibler divergence\n",
    "div_kl = p1 * np.log2(p1 / q1) + p2 * np.log2(p2 / q2)\n",
    "print(f\"Dkl(P||Q) = {div_kl:.3f}\")\n",
    "\n",
    "# Entropy normal coin\n",
    "h_p = -p1 * np.log2(p1) - p2 * np.log2(p2)\n",
    "print(f\"H(P) = {h_p:.3f}\")\n",
    "\n",
    "# Entropy fake coin\n",
    "h_q = -q1 * np.log2(q1) - q2 * np.log2(q2)\n",
    "print(f\"H(Q) = {h_q:.3f}\")\n",
    "\n",
    "# Cross-entropy\n",
    "h_p_q = -p1 * np.log2(q1) - p2 * np.log2(q2)\n",
    "print(f\"H(P||Q) = {h_p_q:.3f}\")\n",
    "print(f\"H(P||Q) = Dkl(P||Q) + H(P) = {h_p+div_kl:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расчет функции потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернемся к задаче классификации изображения. Рассчитаем для предсказания модели Cross-Entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/logits_to_scores_to_probabilitys.png\" width=\"900\">\n",
    "\n",
    "На картинке на входе был изображен кот. Метки классов преобразуются следующим образом:\n",
    "$$ y_i = \\begin{cases} 1 & \\text{для i=k, где k - номер истинного класса}, \\\\0 & \\text{для любого } i\\neq k.\n",
    " \\end{cases}$$\n",
    "Таким образом\n",
    "$$ y = [1, 0, 0]$$\n",
    "\n",
    "То есть **в расчете Loss** мы будем использовать только **вероятность истинного класса**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В расчетах выше мы использовали логарифм по основанию 2, что приближало нас к теории информации. Мы можем считать кросс-энтропию по натуральному логарифму, она будет отличаться умножением на константу.\n",
    "\n",
    "$$H(P||Q)= - \\sum^C_{i=1}y_i\\cdot log(p_i) = -1⋅\\log{0.87}-0\\cdot\\log{0.13}-0\\cdot\\log{0.001} = - log(p_{cat}) = log{0.87} \\approx0.14$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(pred_prob, true_prob):\n",
    "    return -np.dot(true_prob, np.log(pred_prob))\n",
    "\n",
    "\n",
    "print(f\"Logits = {logits}\")\n",
    "\n",
    "pred_prob = softmax(logits)\n",
    "print(f\"Predicted Probabilities = {pred_prob}\")\n",
    "\n",
    "true_prob = [1.0, 0.0, 0.0]\n",
    "print(f\"True Probabilities = {true_prob}\")\n",
    "\n",
    "print(f\"Cross-entropy loss = {cross_entropy_loss(pred_prob, true_prob):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиент функции потерь. Кросс-энтропия\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая последовательность преобразований будет выглядеть так:\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.0/L02/out/linear_model_probability_pipeline.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Cross Entropy Loss](https://wandb.ai/wandb_fc/russian/reports/---VmlldzoxNDI4NjAw#:~:text=%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F%20%D0%BF%D0%BE%D1%82%D0%B5%D1%80%D1%8C%20%D0%BF%D0%B5%D1%80%D0%B5%D0%BA%D1%80%D0%B5%D1%81%D1%82%D0%BD%D0%BE%D0%B9%20%D1%8D%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D0%B8%20%E2%80%93%20%D1%8D%D1%82%D0%BE,%2C%20%D0%B3%D0%B4%D0%B5%200%20%E2%80%93%20%D0%B8%D0%B4%D0%B5%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем производную от функции ошибок. Функция ошибок:\n",
    "\n",
    "$$ L = - \\sum_i y_i \\log p_i = -\\sum_i y_i \\log(\\dfrac {e^{s_{y_i}}} {\\sum_j e^{s_{y_j}}})$$\n",
    "\n",
    "где я $s_{y_i}$ - это логиты классов, получаемые из линейной модели:\n",
    "\n",
    "$$s_{y_i} = w_i x$$\n",
    "\n",
    "Для расчета градиента будем использовать chain rule:\n",
    "\n",
    "$$ \\dfrac {\\partial L} {\\partial w_i} = \\dfrac {\\partial L} {\\partial s_{y_i}} \\dfrac {\\partial s_{y_i}} {\\partial w_i} $$\n",
    "\n",
    "Градиент логитов по весам:\n",
    "\n",
    "$$\\dfrac {\\partial s_{y_i}} {\\partial w_i} = x$$\n",
    "\n",
    "У нас только одна истинная метка класса $y_k = 1$, для $i\\neq k$ $y_i=0$\n",
    "\n",
    "$$ L = -y_k \\log p_k = - \\log(\\dfrac {e^{s_{y_k}}} {\\sum_j e^{s_{y_j}}})$$\n",
    "\n",
    "У нас два случая:\n",
    "1. **производная по истинному логиту** (значение логита входит в числитель и знаменатель дроби)\n",
    "2. **производная по остальным логитам** (значение логита входит только в знаменатель дроби).\n",
    "\n",
    "Начнем с истинного логита:\n",
    "1. Производная по $s_{y_k}$. Вынесем минус, чтобы не потерять:\n",
    "\n",
    "$$ -L = \\log(\\dfrac {e^{s_{y_k}}} {\\sum_j e^{s_{y_j}}}) = \\log e^{s_{y_k}} - \\log  \\sum_j e^{s_{y_j}}  = s_{y_k} - \\log  \\sum_j e^{s_{y_j}}$$\n",
    "\n",
    "$$\\dfrac {\\partial -L} {\\partial s_{y_k}} = 1 - \\dfrac 1 {\\sum_j e^{s_{y_j}}} \\cdot \\dfrac {\\partial {\\sum_j e^{s_{y_j}}}} {\\partial s_{y_k}} = 1 - \\dfrac 1 {\\sum_j e^{s_{y_j}}} \\cdot \\dfrac {\\partial e^{s_{y_k}}} {\\partial s_{y_k}} = 1 - \\dfrac {e^{s_{y_i}}} {\\sum_j e^{s_{y_j}}} = 1 - p_i$$\n",
    "\n",
    "Вспомним про минус:\n",
    "\n",
    "$$\\dfrac {\\partial L} {\\partial s_{y_j}} = p_i - 1 $$\n",
    "\n",
    "2. Для остальных логитов $i \\neq k$. Вынесем минус, чтобы не потерять:\n",
    "\n",
    "$$ -L = \\log(\\dfrac {e^{s_{y_i}}} {\\sum_j e^{s_{y_j}}}) = \\log e^{s_{y_k}} - \\log  \\sum_j e^{s_{y_j}}  = s_{y_k} - \\log  \\sum_j e^{s_{y_j}}$$\n",
    "\n",
    "$$\\dfrac {\\partial -L} {\\partial s_{y_i}} = - \\dfrac 1 {\\sum_j e^{s_{y_j}}} \\cdot \\dfrac {\\partial {\\sum_j e^{s_{y_j}}}} {\\partial s_{y_i}} =  \\dfrac 1 {\\sum_j e^{s_{y_i}}} \\cdot \\dfrac {\\partial e^{s_{y_i}}} {\\partial s_{y_i}} = \\dfrac {e^{s_{y_i}}} {\\sum_j e^{s_{y_j}}} = - p_i$$\n",
    "\n",
    "Вспомним про минус:\n",
    "\n",
    "$$\\dfrac {\\partial L} {\\partial s_{y_j}} = p_i $$\n",
    "\n",
    "Получаем:\n",
    "$$ \\dfrac {\\partial L} {\\partial s_{y_i}}  =  \\begin{cases} p_i - 1 & \\text{для i=k, где k - номер истинного класса}, \\\\p_i & \\text{для любого } i\\neq k.\n",
    " \\end{cases} $$\n",
    "\n",
    "Применим **chain rule**:\n",
    "\n",
    "$$ \\dfrac {\\partial L} {\\partial w_i}  = \\dfrac {\\partial L} {\\partial s_{y_i}} \\dfrac {\\partial s_{y_i}} {\\partial w_i}  =  \\begin{cases}(p_i - 1)x & \\text{для i=k, где k - номер истинного класса}, \\\\p_ix & \\text{для любого } i\\neq k.\n",
    "\\end{cases} $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде это будет выглядеть вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input batch of 2 vector with 4 elements\n",
    "x = np.array([[1, 2, 3, 4], [1, -2, 0, 0]])\n",
    "# Weights\n",
    "W = np.random.randn(3, 4)  # 3 class\n",
    "\n",
    "# model output\n",
    "logits = x.dot(W.T)\n",
    "print(\"Scores(Logits) \\n\", logits, \"\\n\")\n",
    "\n",
    "# Probabilities\n",
    "probs = softmax(logits)  # defined before\n",
    "print(\"Probs \\n\", probs, \"\\n\")\n",
    "\n",
    "# Ground true classes\n",
    "y = [0, 1]\n",
    "\n",
    "# Derivative\n",
    "probs[np.arange(2), y] = -1  # substract one from true class prob\n",
    "dW = x.T.dot(probs)  # dot product with input\n",
    "\n",
    "print(\"Grads dL/dW \\n\", dW)  # have same shape as W"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
