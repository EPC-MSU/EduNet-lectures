{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Архитектуры CNN\n",
    "\n",
    "Технологии компьютерного зрения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_1.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_2.png\"  width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_3.png\"  width=\"850\">\n",
    "\n",
    "https://neurohive.io/ru/vidy-nejrosetej/alexnet-svjortochnaja-nejronnaja-set-dlja-raspoznavanija-izobrazhenij/\n",
    "\n",
    "https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n",
    "\n",
    "ImageNet Classification with Deep ConvolutionalNeural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_4.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_5.png\"  width=\"850\">\n",
    "\n",
    "Matthew D. Zeilerzeiler@cs.nyu.eduDept. of Computer Science, Courant Institute, New York UniversityRob Fergusfergus@cs.nyu.eduDept. of Computer Science, Courant Institute, New York Universit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_6.png\"  width=\"850\">\n",
    "\n",
    "Karen Simonyan and Andrew Zisserman\n",
    "\n",
    "Visual Geometry Group - Oxford\n",
    "\n",
    "https://www.robots.ox.ac.uk/~vgg/research/very_deep/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_7.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_8.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_9.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_10.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_11.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_12.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_13.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_14.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_15.png\"  width=\"850\">\n",
    "\n",
    "Alternatively, interpret it as applying the same FC layer on each input pixel preserves spatial dimensions, reduces depth!\n",
    "Projects depth to lower dimension (combination of feature maps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_16.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_17.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_18.png\"  width=\"850\">\n",
    "\n",
    "<a href=\"https://arxiv.org/pdf/1312.4400.pdf\">2014 Network In Network</a>\n",
    "\n",
    "https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_19.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_20.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_21.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/pdf/1512.03385.pdf\">2015 Deep Residual Learning for Image Recognition</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_22.png\"  width=\"850\">\n",
    "\n",
    "https://arxiv.org/pdf/1512.03385.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_23.png\"  width=\"850\">\n",
    "\n",
    "identity =  Тождественное отображение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_24.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_25.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_26.png\"  width=\"850\">\n",
    "\n",
    "https://pytorch.org/docs/stable/_modules/torchvision/models/resnet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_27.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1901.09321\">2019 Fixup Initialization: Residual Learning Without Normalization</a>\n",
    "\n",
    "https://towardsdatascience.com/understanding-fixup-initialization-6bf08d41b427"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_28.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_29.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_30.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_31.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_32.png\"  width=\"850\">\n",
    "\n",
    "https://arxiv.org/pdf/1810.00736.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_33.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_34.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1611.05431\">2016 Aggregated Residual Transformations for Deep Neural Networks</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_35.png\"  width=\"850\">\n",
    "\n",
    "https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_36.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_37.png\"  width=\"850\">\n",
    "\n",
    "https://towardsdatascience.com/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_38.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1605.07146\">2016 Wide Residual Networks</a>\n",
    "\n",
    "dropout внутри блоков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_39.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1709.01507\">2017 Squeeze-and-Excitation Networks</a>\n",
    "\n",
    "https://towardsdatascience.com/squeeze-and-excitation-networks-9ef5e71eacd7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_40.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_41.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_42.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_43.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_44.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_45.png\"  width=\"850\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/2006.03677\">2020 Visual Transformers: Token-based Image Representation and Processing for Computer Vision</a>\n",
    "\n",
    "\n",
    "old version: https://syncedreview.com/2020/06/12/facebook-and-uc-berkeley-boost-cv-performance-and-lower-compute-cost-with-visual-transformers/\n",
    "\n",
    "MAC (multiply and accumulate operations) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L09_CNN_Architectures/img/L09_CNN_Architectures_46.png\"  width=\"850\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
