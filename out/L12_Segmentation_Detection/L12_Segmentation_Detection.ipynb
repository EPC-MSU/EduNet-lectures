{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCwYy1CWdauI"
   },
   "source": [
    "### Computer vision task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In5ldMKUQX2v"
   },
   "source": [
    " ## COCO\n",
    "- один из наиболее популярных датасатов содержащий данные для сегментации и детектирования.\n",
    "\n",
    "- categoryes\n",
    "- masks\n",
    "- bounding boxes\n",
    "- captions\n",
    "- person_keypoints\n",
    "...\n",
    "\n",
    "https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoDemo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AdGMnQwQY_V"
   },
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHXV3kO8WCuF"
   },
   "source": [
    "Для работы с датасетом используется пакет `pycocotools`\n",
    "\n",
    "В COCO 90 категорий объектов\n",
    "\n",
    "https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5abXyerDTNdE"
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "coco=COCO('annotations/instances_val2017.json')\n",
    "\n",
    "cat_ids = coco.getCatIds()\n",
    "print(\"Categories count\",len(cat_ids))\n",
    "print(cat_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWU2rsgGWKIi"
   },
   "source": [
    "0 - не используется в качестве номера категории. Обычно его используют для обозначения класса фона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUzMGpdyUqxR"
   },
   "outputs": [],
   "source": [
    "# display COCO categories and supercategories\n",
    "\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "\n",
    "nms=[str(cat['id']) + \":\"  + cat['name'] for cat in cats]\n",
    "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08Re-0mQWbKj"
   },
   "source": [
    "Есть так же суперкатегории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSVZjzJXU3kp"
   },
   "outputs": [],
   "source": [
    "print(cats[2])\n",
    "print(cats[3])\n",
    "\n",
    "\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBbsFsT_W2US"
   },
   "source": [
    "Датесет большой, поэтому удобно выгружать данные частями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvFbQwCCW-po"
   },
   "outputs": [],
   "source": [
    "# get all images containing given categories, select one at random\n",
    "catIds = coco.getCatIds(catNms=['person','cat']); # person and cat\n",
    "imgIds = coco.getImgIds(catIds=catIds );\n",
    "#imgIds = coco.getImgIds() #imgIds = [324158]\n",
    "print(\"Total images with person and cat \",len(imgIds))\n",
    "print(imgIds)\n",
    "img_list = coco.loadImgs(imgIds[0])\n",
    "img = img_list[0]\n",
    "print(\"Image data\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKViu19eHz33"
   },
   "source": [
    "Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iv7WBDvVH13e"
   },
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "I = io.imread(img['coco_url'])\n",
    "plt.axis('off')\n",
    "plt.imshow(I)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vU16f6RBIsjT"
   },
   "source": [
    "Конвертация в PIL формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xTqZnEcI5m4"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "response = requests.get(img['coco_url'])\n",
    "pil_img = Image.open(BytesIO(response.content))\n",
    "plt.imshow(pil_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkYH1oG9J36h"
   },
   "source": [
    "Информация о разметке\n",
    "\n",
    "https://cocodataset.org/#format-data\n",
    "\n",
    "\n",
    "```\n",
    "  \"segmentation\" : RLE or [polygon],\n",
    "  \"area\" : float,\n",
    "  \"bbox\" : [x,y,width,height],\n",
    "  \"iscrowd\" : 0 or 1,\n",
    "```\n",
    "\n",
    "Полигон это набор координат [x1,y1, x2,y2 ... ]\n",
    "\n",
    "объект может описываться несколькими полигонами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cddQBoKWJ6z_"
   },
   "outputs": [],
   "source": [
    "# load and display instance annotations\n",
    "plt.imshow(I); plt.axis('off')\n",
    "annIds = coco.getAnnIds(imgIds=img['id'])\n",
    "anns = coco.loadAnns(annIds)\n",
    "\n",
    "def dump_anns(anns):\n",
    "  for i, a in enumerate(anns):\n",
    "    print(f\"#{i}\")\n",
    "    for k in a.keys():\n",
    "      print(k,\": \",a[k])\n",
    "dump_anns(anns)\n",
    "coco.showAnns(anns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-ywQiAcMZv-"
   },
   "source": [
    "Что такое [RLE](https://en.wikipedia.org/wiki/Run-length_encoding) ?\n",
    "\n",
    "run-length encoding\n",
    "\n",
    "https://www.youtube.com/watch?v=h6s61a_pqfM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8b8DiNvMfaC"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (160,80)\n",
    "print(catIds)\n",
    "annIds = coco.getAnnIds(catIds=catIds, iscrowd = True)\n",
    "anns = coco.loadAnns(annIds[0:1])\n",
    "\n",
    "dump_anns(anns)\n",
    "\n",
    "img = coco.loadImgs(anns[0]['image_id'])[0]\n",
    "I = io.imread(img['coco_url'])\n",
    "plt.imshow(I); #plt.axis('off')\n",
    "coco.showAnns(anns) # People in the stands \n",
    "seg = anns[0]['segmentation']\n",
    "\n",
    "print('Counts',len(seg['counts']))\n",
    "print('Size',seg['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7lnz4idJ2Zv"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "au5L2EaKJts8"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3tHdZL4QAkw"
   },
   "source": [
    "FCN\n",
    "\n",
    "https://pytorch.org/hub/pytorch_vision_fcn_resnet101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AfjUfUeQAQG"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "torchvision.models.segmentation.fcn_resnet50(pretrained=False, progress=True, num_classes=21, aux_loss=None, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrAVWsYIPl8F"
   },
   "source": [
    "DeepLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAyPbe1JPo2b"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZk05YL8Iy2p"
   },
   "source": [
    "COCO mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPqceGxQdauf"
   },
   "source": [
    "Поговорим о зрении человека. Поскольку зрение относится к области искусственного интеллекта, значит, наиболее известный эталон – зрение человека. По оценкам, 25% мозга занято решением задачи зрения. С помощью глаз мы извлекаем визуальные подсказки, какие-то характеристики реальных объектов, сопоставляем их с наши априорными знаниями об устройстве окружающего мира и делаем выводы.\n",
    "\n",
    "Мы можем распознать объекты на изображении, используя следующие подсказки:\n",
    "1) Цвет\n",
    "\n",
    "2) Контур\n",
    "\n",
    "3) Текстура\n",
    "\n",
    "4) Тени и освещение\n",
    "\n",
    "5) Контекст (окружение объекта) \n",
    "\n",
    "К априорным знаниям об объекте можно отнести следующее:\n",
    "1) Размеры\n",
    "\n",
    "2) Контекст\n",
    "\n",
    "3) Типичный диапазон распределения конкретной характеристики\n",
    "\n",
    "4) Эталонные примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAgfB6GLd5Bn"
   },
   "source": [
    "## Чулан"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lobBjNVLdauj"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-005.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojhoqJ9xdaum"
   },
   "source": [
    "### Semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_ebUSEkdaun"
   },
   "source": [
    "ЗАдача сегментации - понять где именно на изображении располагаются объекты. С одной стороны может быть интересно где находится объект (область в границе) в грубом приближении. С другой стороны есть задача - выделить гарницы объхекта более четко, где нас интересует не область, а пиксельная маска. \n",
    "\n",
    "В общем случае задача сегментации – разделить изображение на фрагменты (группы пикселей) по некоторому общему критерию. В зависимости от критерия получаются разные задачи сегментации изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AX1QxgNdaup"
   },
   "source": [
    "1. Извлечение объекта – выделение конкретного произвольного объекта, указанного пользователем или по-другому заданного. Например, пользователь может выделить объект ограничивающим прямоугольником или нарисовать контур объекта.\n",
    "2. Сегментация без учителя – разделение изображения на регионы, однородные по своим визуальным характеристикам и отличающиеся от соседних регионов. Например, нужно выделить области, соответствующие разным фрагментам фотографии котика (земля, небо, котик)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPnDixczdaus"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-006.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH1cUAoSdauu"
   },
   "source": [
    "Поскольку такие методы разбивают объекты обычно на несколько сегментов, то их еще называют методами пересегментации, потому что мы сегментируем чрезмерно по сравнению с тем, как хотелось бы. Другой вариант – семантическая сегментация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaMdnRKndauw"
   },
   "source": [
    "Семантическая сегментация – попиксельная разметка изображения, где каждая метка соответствует определенному объекту. \n",
    "\n",
    "При этом:\n",
    "* Разные пиксели одного объекта существенно отличаются друг от друга по признакам (яркости, цвету, текстуре окрестности)\n",
    "* Единственное, что у них общее – «семантика»\n",
    "* Поэтому задача сегментации тесно связана с задачей распознавания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YFBjFdVdauy"
   },
   "source": [
    "### The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyxjLJmedauz"
   },
   "source": [
    "**Оценка точности сегментации**\n",
    "\n",
    "Как оценивается точность сегментации? Во-первых, есть попиксельные метрики, то есть мы оцениваем долю правильно отсегментированных пикселей на изображении независимо от того, какую задачу мы рассматриваем. Если метка пикселя верна – это\n",
    "хорошо, и рассматриваем долю верных меток пикселей по отношению ко всем пикселям.\n",
    "\n",
    "\n",
    "Второй вариант оценки примерно такой же, как мы использовали в детектировании объектов, то есть у нас имеется множество сегментов, мы сопоставляем сегменты друг другу и считаем критерий IOU (intersection over union) (рис. 98). Мы для всех сегментов считаем долю правильно классифицированных пикселей по отношению к комбинации правильно классифицированных, ложно позитивных срабатываний и ложноотрицательных срабатываний для каждого рассматриваемого класса объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFH_9cZidau3"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-115.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ph7TdHOwdau4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-007.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ci3INCLgdau5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-009.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oE354Vjdau5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-010.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FwpVkwtdau6"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-012.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4vtFQzOdau7"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-013.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FkodSA1dau8"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-015.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8q_4z1zdau9"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-017.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmhqG7nYdavU"
   },
   "source": [
    "### In-Network upsampling: Max Unpooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvkdbq6QdavW"
   },
   "source": [
    "Одним из направлений было исследование новых способов повышения разрешения карт признаков с использованием какой-то дополнительной информацией. Так получился слой max unpooling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SftpfJGidavY"
   },
   "source": [
    "Вспомним, что при понижении разрешения изображения мы обычно используем max pooling, например, с шагом 2х2, то есть из каждого блока 2х2 пикселя мы сохраняем только одно максимальное значение. Запомним индекс, из которого было получено максимальное значение, поскольку нам важно знать, где именно в картинке было это максимальное значение. Если мы запомним этот индекс, тогда сможем выполнить операцию повышения разрешения, которая будет не просто делать пиксели с равномерным шагом, а заносить целевой пиксель именно туда, откуда мы взяли изначально максимальное значение. Уже после этого будем проходиться по этой карте\n",
    "набором сверток, которые будут интерполировать промежуточные значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hx-lg8FqdavY"
   },
   "source": [
    "* Сохраняем индексы каждого max pooling слоя\n",
    "* При повышении разрешения копируем значения из выхода max pooling слоя с учетом запомненных индексов, применяем обученные свертки для сглаживания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBcKGr_CdavZ"
   },
   "source": [
    "С помощью операции unpooling появилась архитектура для сегментации изображения, фактически для декодирования признаков, Encoder-Decoder with Max Unpooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1bfmSYBdavZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-119.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8jWBMDrdava"
   },
   "source": [
    "Здесь между соответствующими словами кодировщика и декодировщика передаётся информация в виде индексов операции max-pooling, то есть не вся информация со слоев высокого разрешения теряется, она сохраняется и передается на декодировщик. Эта архитектура оказалась точнее предыдущей.\n",
    "\n",
    "В одной из работ эту архитектуру довели до абсолюта, то есть построили такой кодировщик, который превращает картинку в вектор 1х1 пикселя (из картинки сохраняется только контекст). Используя сохраненные max-pooling индексы, повышаем разрешение до исходного, предсказывая карту разметки. Как показали эксперименты, контекст вообще можно проигнорировать и заменить вектор на константный, так как в индексах операции max-pooling хранится достаточно информации для того, чтобы предсказать карту сегментации для исходного изображения. Поскольку свертки связаны с визуальными образами, информации о том, где свертка дала максимальное значение, достаточно, чтобы детектировать объект. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PO4_zjtvdavb"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-019.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMoP9SCsdavb"
   },
   "source": [
    "### Learnable upsampling: Transpose convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mC_Sw8gdavc"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-020.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lMYTBoidavc"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-021.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_gbHG7Udavd"
   },
   "source": [
    "### Learnable upsampling: 1D example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLWvdmHCdavd"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-031.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNcgLNlQdave"
   },
   "source": [
    "### Convolution as matrix multiplication (1D example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7yr_7ZOdavf"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-033.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6eC_Zk7davi"
   },
   "source": [
    "### Semantic segmentation idea: fully convolutional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RV2xF02Ldavi"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-034.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Pm_W9kzdavj"
   },
   "source": [
    "### Semantic segmentation: summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ebIFNH_davj"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-035.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFhem4pfdavk"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-036.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqV33lV0davk"
   },
   "source": [
    "### Object detection: single object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-P1ix1nJdavl"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-039.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1uQibmYdavl"
   },
   "source": [
    "### Object detection: multiple objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WX6Pg__7davm"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-042.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-PNWB0Xdavm"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-044.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1-_PNFZdavm"
   },
   "source": [
    "### Cropping features: Rol Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoQUULyYdavm"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-064.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKIBuux-davn"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-048.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUQ4t8O4davn"
   },
   "source": [
    "### Instant segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AKKebVndavo"
   },
   "source": [
    "Следующая постановка задачи – сегментация экземпляров (Instance segmentation). Мы фиксируем классы объектов, которые хотим выделить и каждый экземпляр заданных классов мы помечаем своей меткой. Задача сегментации экземпляров – это дальнейшее развитие задачи детектирования объектов. Если в обычной задаче детектирования мы локализовывали объекты, например, типа «автомобили» и\n",
    "показывали, где они расположены с помощью прямоугольной рамки, то здесь нужно указать точную область, которую занимает каждый конкретный экземпляр."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POf0syEVdavo"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-093.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aec1afl5davp"
   },
   "source": [
    "В задаче сегментации экземпляров мы выделяем объекты типа things, которые хорошо локализованы в пространстве. В задаче семантической сегментации мы можем пометить области, которые соответствуют другой категории объектов, таких как небо и\n",
    "дорога. Разумеется, возникает задача, в которой и семантическая сегментация, и сегментация экземпляров являются подзадачами, такая задача получила название паноптическая сегментация (panoptic segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsUulKsWdavq"
   },
   "source": [
    "### Instant segmentation: mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3VzpNzQdavq"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-095.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Za4FeiSGdavq"
   },
   "source": [
    "### Recap: lots of computer vision taska"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cD8vmHQxdavr"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-005.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihTfdvX7davs"
   },
   "source": [
    "### Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oVok0pndavs"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-037.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfg4LLYkdavu"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-038.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9HBeveXdavu"
   },
   "source": [
    "### Region proposal: selective search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8OG8P0Udavv"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-049.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P79Vo6Qsdavv"
   },
   "source": [
    "### R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhIT-XFUdavv"
   },
   "source": [
    "Первая нейросеть на основе каскада – Region-based convolution networks (R-CNN), по сути двухэтапный каскад (рис.77). Мы используем какой-то внешний алгоритм как генератор гипотезы объектов, с помощью него генерируем заданное количество гипотез, чтобы обеспечить достаточно высокую полноту. Затем каждую из этих гипотез мы вырезаем из изображения и подаем на вход классификатору."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPLMHYdNdavw"
   },
   "source": [
    "Метод генерации гипотез, который использовался в R-CNN (регионально сверточных сетях), - один из методов иерархической сегментации, то есть этот метод последовательно разбивает изображение на однородные сегменты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzVtYURBdavw"
   },
   "source": [
    "### Обучение R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laeHLcgkdavx"
   },
   "source": [
    "Поскольку нейросети на тот момент принимали на вход только квадратные изображения фиксированного разрешения, а сегменты, которые находил метод были произвольных пропорций, то нам нужно было их преобразовывать. При этом в тот\n",
    "момент эталонные коллекции для обучения были не очень большими по сравнению с теми коллекциями, ан которых обучались для задачи классификации. \n",
    "\n",
    "Поэтому примеров в этих коллекциях было недостаточно для того, чтобы обучить нейросеть с нуля. Поэтому нейросеть использовали только как метод извлечения признаков, брали выход одного из слоев, обычно полносвязного, и подавали его на вход методу опорных векторов. Фактически взяли метод HOG+CVN, но вместо того, чтобы использовать гистограмму ориентированных градиентов как признаки, брались нейросетевые признаки с сети классификатора. Это было достаточно сложно и медленно, но точность высокая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1j-95cWdavy"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-116.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjvKJIeldavy"
   },
   "source": [
    "При этом очень сильно повысить точность помогла еще одна идея – уточнение ограничивающего прямоугольника или регрессия bbox.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-117.png\" width=\"700\">\n",
    "\n",
    "Суть идеи заключается в следующем:\n",
    "\n",
    "* Исходные гипотезы bbox могут быть очень неточными, поскольку мы получаем их от внешнего метода и не знаем насколько точно они локализованы. За счет того, что нейросетевой метод устойчив к положению объектов внутри этого ограничивающего прямоугольника, даже если локализация не очень точная, он все равно выдаст правильный ответ: есть объект или нет\n",
    "\n",
    "* Чтобы повысить точность локализации, вместо классификатора на тех же самых признаках обучим линейную регрессию, то есть мы будем находить сдвиг ограничивающего прямоугольника относительно исходного, где именно должен располагаться объект\n",
    "\n",
    "* Такую регрессию можно легко обучить, и она существенно улучшает точность классификации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRr1zAt9davy"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-118.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4OU4Iakdavz"
   },
   "source": [
    "Таким образом, метод регрессии bbox позволяет взять неточную гипотезу и уточнить ее. Такого не было до нейросетевых методов, до этого мы полагались на ограничивающий прямоугольник и для него только предсказывали метку: он или не он.\n",
    "\n",
    "Теперь мы можем не только предсказывать метку, но и уточнять ее, за счет этого мы можем просматривать гораздо меньше прямоугольников, чем раньше. Теперь мы можем брать прямоугольники, фрагменты с достаточно большим шагом на меньшем\n",
    "числе масштабов за счет того, что мы будем уточнять наши изначальные гипотезы значительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWlMACLCdavz"
   },
   "source": [
    "У R-CNN было много недостатков:\n",
    "\n",
    "1. Вычисляем нейросетевые признаки независимо для каждого окна-гипотезы. Поскольку они пересекаются, это ведет к избыточным вычислениям\n",
    "\n",
    "2. Нужно масштабировать фрагменты-гипотез до нужного разрешения \n",
    "\n",
    "3. Сложная процедура обучения\n",
    "\n",
    "4. Зависимость от внешнего алгоритма генерации гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljt0mDAwdavz"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-055.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5k7E7Afdav0"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-056.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gerxEPedav0"
   },
   "source": [
    "### Slow R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31YBKMLNdav0"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-057.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OtCVIkfdav1"
   },
   "source": [
    "### Fast R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMqTbNb8dav1"
   },
   "source": [
    "На основании ROI-pooling сделали модификацию метода R-CNN – Fast R-CNN.\n",
    "\n",
    "**Основные идеи этого метода:**\n",
    "\n",
    "Вычислять сверточные признаки по всему изображению, извлекать из конкретных гипотез вектор-признаки с помощью слоя ROI-pooling. И за тем вместо того, чтобы подавать их на вход SVM, подавать их на вход обычным полносвязным слоям нейросетевого классификатора и одновременно по этим признакам делать и классификацию с помощью soft max, и регрессию bbox. При этом мы можем обучать нашу сеть в режиме многоцелевого обучения. Таким образом, мы можем и дообучить и обучить сверточные признаки, которые мы вычисляем по всему изображению. Для того, чтобы использовать особенность этого метода, которая заключается в том, что он\n",
    "не требует повторного вычисления признаков, нам нужно с каждого изображения брать много гипотез. Гипотезой в нашем случае будет какое-то окно интересов, потому что мы вычислим для этого окна интересов ошибку, затем применим обратное распространение ошибки для получения градиента по всей нейросети. Соответственно одним элементом у нас является именно регион конкретного изображения (регион интересов).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpuyWM5Hdav1"
   },
   "source": [
    "Градиенты от всей нейросети занимают много места в памяти, поэтому обычно берут малое количество изображений в одном mini-batch, но с одного изображения собирают много гипотез. Из-за огромного размера современных нейросетей сейчас mini-batch может состоять из одной картинки и нескольких десятков гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZTOISq9dav3"
   },
   "source": [
    "Чтобы обеспечить сбалансированность выборки, нужно брать примерно одинаковое количество положительных и отрицательных гипотез внутри изображения. Если, например, мы можем в каждом изображении взять 64 гипотезы, нам нужно, чтобы 32 гипотезы из этой выборки были положительными и 32- отрицательными. Отрицательные гипотезы могут быть разными по качеству, поэтому на этом этапе\n",
    "можем применить процедуру, похожую на процедуру поиска сложных примеров для обучения нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3oThwfhdav3"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-063.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rL8Wb64dav3"
   },
   "source": [
    "### R-CNN vs Fast R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YgLEGJ5dav4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-077.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27GOBi5cdav4"
   },
   "source": [
    "### Fast-ER R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaQRAsKpdav4"
   },
   "source": [
    "Следующий шаг, который нужно было сделать для улучшения сети – избавиться от внешнего генератора гипотез. Так появилась Faster R-CNN. Faster R-CNN – пример нейросетевой архитектуры, которая используется до сих пор. По сути Faster R-CNN = Fast R-CNN + RPN (нейросетевого генератора гипотез). \n",
    "\n",
    "Нейросетевой генератор гипотез – маленькая нейросеть, которая по тем же самым сверточным признакам генерирует гипотезы. Наиболее вероятные гипотезы подаются на вход ROI-pooling слою и затем классифицируются более мощным классификатором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvfawoFidav4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-078.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIFPLM2ndav4"
   },
   "source": [
    "### Region proposal network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR3wf8nldav5"
   },
   "source": [
    "* Маленькое скользящее окно по карте признаков (feature map)\n",
    "* Маленькая нейросеть для\n",
    "    - Классификации объект/не объект\n",
    "    - Регрессии bbox\n",
    "* Позиция окна показывает локализацию объекта относительно изображения\n",
    "* Регрессия bbox показывает положение bbox относительно положения скользящего окна "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJz13TMrdav5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-080.gif\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFZ-So8kdav5"
   },
   "source": [
    "### Fast-ER R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFw11S4vdav5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-085.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6m3NJUmddav6"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-086.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsOhuBe5dav6"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-087.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31h2zkCldav6"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-089.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_ce8-QVdav7"
   },
   "source": [
    "### Single-stage Object detection: YOLO/SSD/RetinaNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-2jIAVjdav7"
   },
   "source": [
    "Метод Faster R-CNN достаточно мощный, но зачастую нам нужны методы побыстрее. Самое медленное в этом методе – классификация гипотез с помощью полносвязного классификатора (второй этап).\n",
    "\n",
    "Поэтому родилась следующая идея: выкинуть второй этап и сделать одностадийный метод. Для этого нужно усилить RPN. Так появились одностадийные детекторы, которые работают быстрее, но менее точно, чем Faster R-CNN. Одним из таких детекторов является YOLO (сокращение от названия статьи You Only Look Once). \n",
    "\n",
    "Как устроен этот детектор?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCtt-VXVdav7"
   },
   "source": [
    "Разобьем изображение сеткой и сделаем такую нейросеть, которая будет для каждой ячейки предсказывать, есть ли объект, ограничивающий прямоугольник которого - центр данной ячейки. Фактически, разбив изображение сеткой 7х7, мы сделаем 49 гипотез. Поскольку объекты бывают разных размеров и предсказывать их одним классификатором неудобно, мы воспользуемся похожей на якори идеей и будем в каждой ячейки выдвигать 2 гипотезы: одну маленькую, а другую большую. \n",
    "\n",
    "В сумме наши 49 ячеек сделают 98 гипотез. Параллельно каждую ячейку заставим предсказывать класс объекта. Для каждой гипотезы у нас есть вероятность классификатора. Применим метод подавления немаксимумов жадного подавления гипотез и оставшиеся гипотезы обрезаем по порогу по степени уверенности. Если говорить о параметризации ответа (что мы хотим получить на выходе сети), то на\n",
    "выходе мы хотим получить трехмерную матрицу размера 7 х 7 х (2 х 5 + 20) = 7 х 7 х 30, так как"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb9Hv2sYdav7"
   },
   "source": [
    "Сетка 7 х 7, 2 гипотезы объектов, 20 классов. То есть сеть на вход берет изображение. А на выходе предсказывает 7 х 7 параметров. Эта сеть называется DarkNet.\n",
    "\n",
    "DarkNet устроен следующим образом: он состоит из сверточных слоев таким образом, что в конце у нас появляется матрица размером 7 х 7 х 1024. Далее эту матрицу преобразуют в один полносвязный слой длиной 4096, этот слой содержит всю информацию про изображение. Из этого полносвязного слоя генерируется ответ 7 х 7 х 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXzZA0uDdav8"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-090.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n19aF0ZSdav8"
   },
   "source": [
    "Есть другой вариант, который был предложен в Google – Single Shot Detector (SSD). \n",
    "\n",
    "В отличие от детектора YOLO в нем нет этапа преобразования в полносвязный слой, в нем генерируются гипотезы для объектов по признакам, собранным со сверточных слоев. И в отличие от детектора YOLO, который делал одну сетку для всего изображения, в детекторе SSD генерировалось несколько масштабов, несколько разбиений изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95nC6Hhedav9"
   },
   "source": [
    "Объединив идеи одностадийного алгоритма детектирования объектов, построения пирамиды признаков и применение RPN сети по этим признакам, состоящей из 4 слоев 3 х 3 пикселей, сделали архитектуру Retina Net, которая является одной из наиболее точных архитектур для детектирования объектов в настоящее время.\n",
    "\n",
    "\n",
    "RetinaNet = SSD + FPN + FocalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAIm7t04dav-"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-020.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSFmvve3dawD"
   },
   "source": [
    "В отличие от детектора YOLO в нем нет этапа преобразования в полносвязный слой, в нем генерируются гипотезы для объектов по признакам, собранным со сверточных слоев. И в отличие от детектора YOLO, который делал одну сетку для всего изображения, в детекторе SSD генерировалось несколько масштабов, несколько разбиений изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS-AoswndawE"
   },
   "source": [
    "### Object detection: Lots of variables..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-weVHnXJdawE"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-091.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDjzssOmdawE"
   },
   "source": [
    "### Object detection: faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_YyxgHSdawE"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-094.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0sVy2AwdawF"
   },
   "source": [
    "### Mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6XwyhzkdawF"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-096.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XU_M99edawF"
   },
   "source": [
    "### Mask R-CNN: example mask training targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CDnXez1dawF"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-100.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiEOUCifdawG"
   },
   "source": [
    "### Mask R-CNN: very good results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LybQABc7dawG"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-101.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7Hwn7ZQdawG"
   },
   "source": [
    "### Mask R-CNN: also does pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCnczn5ddawG"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-102.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIFuf468dawG"
   },
   "source": [
    "### Beyond 2D object detection.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y--awY-0dawG"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-104.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DFxKip4dawH"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-105.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCfnkq4IdawH"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-106.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EExvAgwdawH"
   },
   "source": [
    "### Dense video captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PHGYD31dawH"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-107.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5HcExUrdawI"
   },
   "source": [
    "### Objects+relationships = scene graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9EYRlHVdawI"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-108.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSc6J390dawI"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-108.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTjtTSh6dawI"
   },
   "source": [
    "### Scene graph prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZCa8tVudawJ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-109.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1rYC5NVdawJ"
   },
   "source": [
    "### 3D object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEo029fHdawJ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-110.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9YOvzF-dawJ"
   },
   "source": [
    "### 3D object detection: simple camera model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmXfeyJcdawJ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-111.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2SuPQhDdawK"
   },
   "source": [
    "### 3D object detection: monocular camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tz0WgCjxdawK"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-112.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOPPL8PVdawK"
   },
   "source": [
    "### 3D shape protection: mesh R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtza6tdQdawK"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/lecture_12-113.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgRH9ArLdawL"
   },
   "source": [
    "## Картинки по лекции 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAAOxF30dawM"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-03.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUs5NJmHdawM"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-07.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnH9B_--dawM"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-08.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwgwsxA9dawN"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-09.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSA58U6zdawN"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-10.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glXi8q9kdawN"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-11.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWZlLye0dawO"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-12.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpWnETp0dawP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-14.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fnAj1bBdawP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-15.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLGCOoSJdawP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-16.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T09JWj9NdawQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-17.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_6IShlQdawQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-19.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2zLfC9GdawR"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-20.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi8ZOkPndawR"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-21.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZOm5yRpdawR"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-22.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3DSWlopdawS"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-23.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGdjqnXUdawS"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-24.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoWbsn0bdawS"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-25.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ--2Ql9dawT"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-26.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "casoXnJqdawT"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-27.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ygl7vJ7cdawU"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-28.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVXHRwL7dawU"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-29.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVvJuRa0dawU"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-30.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu-DK9GRdawU"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L8-32.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diF2ZoaPdawV"
   },
   "source": [
    "## Картинки по лекции 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0EtF0ladawV"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-02.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZo8TZHfdawV"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-03.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_ZdkC0UdawV"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-05.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sDbRKh4dawV"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-06.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7F3LerZdawW"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-07.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cy1LcEetdawW"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-08.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tnd1y9yFdawW"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-09.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixOhO6RzdawX"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-10.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5qX0Hf6dawX"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-11.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtLsotu_dawX"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-12.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95JV40S7dawX"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-13.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wO74JX9ydawY"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-14.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Sjt5QkpdawY"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-18.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8FSEVPpdawY"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-20.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bNOnpvjdawY"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-21.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLSjr3gOdawZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-22.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayrxv57BdawZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-23.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiXhwfOmdawZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-24.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6SLmgcXdawZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-25.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWJN3DOkdawZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-26.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxX9ByJSdawa"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-27.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kiYjyuqdawa"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-28.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7B3qPusMdawa"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-29.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYXc9g5Xdawa"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-30.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKB28l9Tdawa"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-31.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iViR89iTdawb"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-32.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J8J_dURdawc"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-34.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0c0MQzLdawc"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-35.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YddXOdljdawc"
   },
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-1-1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8ho3Jahdawc"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-1-2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hX_NuATdawd"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-42.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH6CTunBdawd"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-43.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gSx-cgjdawd"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-44.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKRPL3IKdawe"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-45.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkx9XEDqdawe"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-46.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38zmjPk2dawf"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-47.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJw2LDGldawf"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-48.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cyk6QLaVdawg"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-49.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmJT0mOedawg"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-50.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgp914Iidawh"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-51.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18t3fOlVdawh"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-52.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEUxR2I8dawi"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-54.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4U5x9vTdawi"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-55.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYEoxbZWdawj"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-56.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d56lMiINdawj"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-57.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go7SjEsSdawk"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L12_Segmentation_Detection/img/L9-58.png\" width=\"700\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "colab": {
   "name": "L12_Segmentation_Detection.ipynb",
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
