{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Removed.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLbdHiyXFaVu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gslED373K7ac"
      },
      "source": [
        "# DINO — Self-supervised representation learning (with segmentation capabilities)\n",
        "[Emerging Properties in Self-Supervised Vision Transformers (Caron et al., 2021)](https://arxiv.org/abs/2104.14294)\n",
        "\n",
        "[Отличное видео объяснение статьи](https://www.youtube.com/watch?v=h3ij3F3cPIk)\n",
        "\n",
        "[vision_transformer](https://github.com/google-research/vision_transformer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWc0UolNK7ad"
      },
      "source": [
        "Для начала подгрузим модель DINO (self-**DI**stillation with **NO** labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Zfoi_Q0K7ad"
      },
      "outputs": [],
      "source": [
        "# fix random_seed\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Compute on cpu or gpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AjCQJHcK7ad"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/facebookresearch/dino.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw5FSjSzK7ae"
      },
      "source": [
        "## Сегментация изображений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAvVkGEcK7ae"
      },
      "source": [
        "Теперь загрузим случайную картинку (можно выбрать любую, просто замените ссылку на свою)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dICP4lmgK7ae"
      },
      "outputs": [],
      "source": [
        "URL = 'https://edunet.kea.su/repo/EduNet-web_dependencies/L12/capybara_image.jpg'\n",
        "!wget $URL -qO test.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfiVQC7gK7af"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "input_img = Image.open('/content/test.jpg')\n",
        "input_img.resize((400,300))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyTz0E4JK7af"
      },
      "source": [
        "Получим результат с помощью DINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8xM1tvgK7ag"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!python /content/dino/visualize_attention.py --image_path /content/test.jpg \n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VQDsOHgK7ag"
      },
      "source": [
        "Посмотрим на картинки, которые генерирует DINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRm_eO0gK7ag"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "def img_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "    fig,ax = plt.subplots(nrows=rows, ncols=cols, figsize=(28,8))\n",
        "    for num, img in enumerate(imgs):\n",
        "        img_PIL = Image.open(img)\n",
        "        ax[num].imshow(img_PIL)\n",
        "        ax[num].set_xticks([])\n",
        "        ax[num].set_yticks([])\n",
        "    plt.subplots_adjust(hspace=0, wspace=0)\n",
        "\n",
        "img_grid(imgs=sorted(glob('*.png'))[::-1], rows=1, cols=7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXX1oJkbK7ah"
      },
      "source": [
        "Мы видим 6 карт внимания (self-attention maps - веса слоя self-attention) на 6 головах Visual Transformer. В результате self-supervised обучения по методике DINO, трансформер САМОСТОЯТЕЛЬНО придумал обращать внимание на различные части изображения, таким образом, производя семантическую сегментацию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neGdueyZK7ah"
      },
      "source": [
        "Мы можем все эти карты внимания объединить в одно изображение, и просто назначить каждой карте свой цвет, а в качестве прозрачности использовать интенсивность"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrOUrMKXK7ah"
      },
      "outputs": [],
      "source": [
        "import matplotlib.colors as mcolors\n",
        "from matplotlib import cm\n",
        "\n",
        "def overlay(img, segmentations):\n",
        "    img_PIL = Image.open(img)\n",
        "    fig, ax = plt.subplots(ncols=2, figsize=(10,10))\n",
        "    ax[0].imshow(img_PIL)\n",
        "    ax[0].set_xticks([])\n",
        "    ax[0].set_yticks([])\n",
        "    \n",
        "    ax[1].imshow(img_PIL.convert('LA'), alpha=0.5)\n",
        "    for num, img in enumerate(segmentations):\n",
        "        segment_PIL = Image.open(img).convert('LA')\n",
        "        segment_arr = np.array(segment_PIL)\n",
        "        colors = [(*cm.tab10(num)[:-1], c) for c in np.linspace(0,0.75,100)]\n",
        "        cmap = mcolors.LinearSegmentedColormap.from_list('mycmap', colors, N=5)\n",
        "        ax[1].imshow(segment_arr[:,:,0], cmap=cmap)\n",
        "    ax[1].set_facecolor('black')\n",
        "    ax[1].set_xticks([])\n",
        "    ax[1].set_yticks([])\n",
        "    plt.subplots_adjust(hspace=0, wspace=0)\n",
        "\n",
        "overlay('/content/img.png', sorted(glob('*.png'))[:-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnhov4DMK7ah"
      },
      "source": [
        "Видим, что DINO сегментирует разные части нашей картинки на разные семантические группы. В случае с капибарой - это голова, лицо (нос, глаза) и тело."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtNCO78hK7aj"
      },
      "source": [
        "## Сегментация видео"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ih1l6icK7ak"
      },
      "source": [
        "Вы думали, что на этом все? Нет, DINO может еще удивить. Например, она умеет сегментировать видео"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA0W8YXbK7ak"
      },
      "outputs": [],
      "source": [
        "!sudo pip install --upgrade youtube_dl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Is2P4CK7ak"
      },
      "source": [
        "Скачаем видео (можно любое)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ-3-VGoK7al"
      },
      "outputs": [],
      "source": [
        "URL = 'https://edunet.kea.su/repo/EduNet-web_dependencies/L12/cheetah_video.mp4'\n",
        "!youtube-dl -o video.mp4 $URL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4kypkQ0K7am"
      },
      "source": [
        "И сгенерируем сегментированное видео"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-Nj3DXRK7an"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!python /content/dino/video_generation.py --input_path /content/video.mp4 --output_path  /content/video_segmented --resize 360 640\n",
        "!ffmpeg -i /content/video.mp4 -vf scale=640:360 /content/video_scaled.mp4\n",
        "!ffmpeg \\\n",
        "  -i /content/video_scaled.mp4 \\\n",
        "  -i /content/video_segmented/video.mp4 \\\n",
        "  -filter_complex '[0:v]pad=iw*2:ih[int];[int][1:v]overlay=W/2:0[vid]' \\\n",
        "  -map '[vid]' \\\n",
        "  -c:v libx264 \\\n",
        "  -crf 23 \\\n",
        "  -preset veryfast \\\n",
        "  output.mp4\n",
        "\n",
        "clear_output()\n",
        "print('Complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut8lvmb0K7ao"
      },
      "source": [
        "Посмотрим, что получилось. Обратите внимание, эта сеть обучалась в режиме self-supervision!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuVyKcphK7ap"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/output.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=800 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYGheTWpK7ap"
      },
      "source": [
        "## Кластеризация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_7-_BAKK7ap"
      },
      "source": [
        "А еще DINO умеет кластеризовать изображения. Выполнять не будем, так как процесс не быстрый, но можем посмотреть на результаты из их статьи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr3Qw1OxK7aq"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L12/clustering_dino.gif\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_27nkoQiK7aq"
      },
      "source": [
        "[Advancing the state of the art in computer vision with self-supervised Transformers and 10x more efficient training](https://ai.facebook.com/blog/dino-paws-computer-vision-with-self-supervised-transformers-and-10x-more-efficient-training/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TEdNPirHFuha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGQeqS5TK7Xh"
      },
      "source": [
        "#### Pixel-wise cross entropy loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOh9IgHdK7Xj"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L12/img_license/pixel_wise_cross_entropy_loss.png\" width=\"800\">"
      ]
    }
  ]
}