{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import clear_output\r\n",
    "import torch\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "print(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Общая идея\n",
    "\n",
    "Модели машинного обучения представляют собой черный ящик."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img_licence/blackbox.png\" alt=\"alttext\" width=400/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Иногда это становится препятствием для внедрения моделей.\n",
    "\n",
    "Есть как минимум три причины по которым нас может интересовать объяснение предсказаний модели."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Поиск ошибок.\n",
    "\n",
    "Модель может использовать совсем не те признаки, которые соответствуют реальным объектам.\n",
    "\n",
    "Например ориентироваться на фон или водяной знак, а не на реальные свойства объекта.\n",
    "\n",
    "Пример из статьи [\"Why Should I Trust You?\"](https://arxiv.org/abs/1602.04938) \n",
    "Авторы обучили классификатор волков и эскимосских собак (хаски). Исследователи на изображениях, отобранных так, чтобы на всех фотографиях волков на фоне был снег, а на фотографиях хаски — нет."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/2_bad_models_prediction.png\" alt=\"alttext\" width=400/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[\"Why Should I Trust You?\"](https://arxiv.org/abs/1602.04938) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Доверие пользователей"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img_licence/nuclear.jpg\" alt=\"alttext\" width=750/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Нельзя остановить ядерную электростанцию или назначить пациенту опасное лечение на основании предсказания «черного ящика». \n",
    "Даже маловероятная ошибка в таких случаях будет иметь тяжелые последствия. Поэтому, человек принимающий решение должен понимать на основе каких признаков или симптомов сделанно предсказание."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Публикации в научных журналах\n",
    "\n",
    "\n",
    "Вероятность публикации статьи значительно повышается, если автор смог объяснить происхождение результатов своего исследования."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img_licence/scopus.png\" alt=\"alttext\" width=750/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explainability & Interpretability\n",
    "В англоязычной литературе можно встретить два термина связанных с темой доверия: Explainability и Interpretability\n",
    "\n",
    "**Explainability** &mdash; методики позволяющие объяснить механизм функционирования модели. \n",
    "\n",
    "Например, для линейной регрссии это анализ коэффицентов при параметрах.\n",
    "\n",
    "\n",
    "**Interpretability** &mdash; Анализ того как изменение входов модели влияеи на ее выходы.\n",
    "\n",
    "Например, закрашивая часть пикселей изображения, можно выяснит какие из них повлияют на предсказания (пример с хаски и волками).\n",
    "\n",
    "\n",
    "В данном блокноте будем приемущественно рассматривать методы второго типа.\n",
    "\n",
    "[Machine Learning Explainability vs Interpretability: Two concepts that could help restore trust in AI](https://www.kdnuggets.com/2018/12/machine-learning-explainability-interpretability-ai.html)\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### $\\color{brown}{\\text{Допольнительная информация}}$\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Машинное обучение лежит в основе многих последних достижений в области науки и технологии.\n",
    "\n",
    "Когда компьютеры победили профессионалов в таких играх, как Go, многие люди начали спрашивать: могут ли машины стать лучшими водителями или даже лучшими врачами?\n",
    "\n",
    "Во многих приложениях машинного обучения пользователей просят доверять модели, которая поможет им принимать решения. Врач определенно не станет оперировать пациента просто потому, что «так сказала модель».\n",
    "\n",
    "Даже в ситуациях с более низкими рисками, принять неправильное решение на основании предсказания модели — например, при выборе фильма для просмотра в Netflix, требуется определенная степень доверия.\n",
    "\n",
    "Несмотря на то, что многие модели машинного обучения представляют собой черный ящик, понимание причин, лежащих в основе прогнозов модели, безусловно, поможет пользователям решить, когда им доверять, а когда нет."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "К сожалению, компьютеры обычно не объясняют своих прогнозов. \n",
    "И это становится препятствием для внедрения моделей машинного обучения.\n",
    "А если пользователи не доверяют модели или прогнозу, то они будут с опаской использовать их на практике.\n",
    "\n",
    "Поэтому вопрос в том, как помочь пользователям доверять результатам, полученным с помощью моделей машинного или глубокого обучения.\n",
    "\n",
    "Важно различать два разных (но связанных) определения доверия: \n",
    "1. Доверие к предсказанию, то есть доверяет ли пользователь отдельному предсказанию настолько, чтобы предпринять какие-то действия на его основе?\n",
    "2. Доверие к модели, то есть доверяет ли пользователь модели так, чтобы применять ее на практике?\n",
    "\n",
    "Оба напрямую подвержены влиянию того, насколько человек понимает поведение модели, чтобы не рассматривать ее как черный ящик. \n",
    "\n",
    "Определение доверия к индивидуальным прогнозам является важной задачей, когда модель используется для принятия решений. Ведь, например, при медицинской диагностике или обнаружении террористов предсказания не могут быть выполнены бездумно, так как последствия могут быть катастрофическими.\n",
    "\n",
    "Помимо доверия индивидуальным предсказаниям, необходимо доверять модели \"в целом\". Чтобы принять это решение, пользователи должны быть уверены, что модель будет хорошо работать на реальных данных согласно интересующим метрикам. Реальные данные часто значительно отличаются, и, кроме того, метрика оценки может не указывать на цель продукта. Изучение индивидуальных прогнозов и их объяснение — важная задача, которая может помочь пользователям, особенно для больших наборов данных."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/impact_assessment.png\" alt=\"alttext\" width=600/> "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Explain Your Model with the SHAP Values](https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Практики часто **переоценивают точность своих моделей**. Примером тому может послужить известный случай с моделью, обученной отличать хаски от волка.\n",
    "\n",
    "Часто **артефакты сбора данных могут вызвать нежелательные корреляции**, которые классификаторы улавливают во время обучения. Эти проблемы может быть очень трудно определить, просто взглянув на необработанные данные и прогнозы.\n",
    "\n",
    "Пример идеально решенной задачи, не применимой на практике — задача различить на фотографиях волков и эскимосских собак (хаски). Исследователи обучили классификатор логистической регрессии из 20 изображений, отобранных вручную так, чтобы на всех фотографиях волков на фоне был снег, а на фотографиях хаски — нет.\n",
    "\n",
    "Этот эксперимент демонстрирует полезность объяснения отдельных визуальных признаков для понимания работы классификаторов перед тем, как принять решения о доверии к ним."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/2_bad_models_prediction.png\" alt=\"alttext\" width=400/>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[\"Why Should I Trust You?\"](https://arxiv.org/abs/1602.04938) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Критерии, которым должны отвечать Интерпретаторы\r\n",
    "\r\n",
    "1. **Результат должен быть интерпретируемым**, т. е. обеспечивать качественное понимание взаимосвязи между входными переменными и ответом. Отметим, что интерпретируемость должна учитывать ограничения пользователя. Объяснения должны быть легкими для понимания, не обязательно соответствовать функциям, используемым моделью. Ну и конечно, понятие интерпретируемости зависит от целевой аудитории.\r\n",
    "\r\n",
    "Например, возможное интерпретируемое представление для классификации текста — это двоичный вектор, обозначающий наличие или отсутствие слова, даже если классификатор может использовать более сложные (и непонятные) функции, такие как вложения слов. Аналогичным образом для классификации изображений, интерпретируемое представление может быть двоичным вектором, указывающим «наличие» или «отсутствие» смежного участка аналогичных пикселей (суперпиксель), тогда как классификатор может представлять изображение в виде тензора с тремя цветовыми каналами на пиксель.\r\n",
    "\r\n",
    "2. Еще один важный критерий — **локальная точность**. Чтобы иметь смысл, обьяснение должно соответствовать тому, как модель ведет себя конкретно для предсказываемого случая.\r\n",
    "\r\n",
    "Отметим, что локальная точность не подразумевает глобальной точности: факторы, которые важны в глобальном масштабе, могут не иметь значения на местном контексте, и наоборот. \r\n",
    "В то время как глобальная точность не всегда будет означать локальную, выделяя глобально достоверные объяснения сложных моделей, которые сложно интерпретировать для конкретного примера.\r\n",
    "\r\n",
    "\r\n",
    "Некоторые метрики, такие как accuracy, **часто могут быть неподходящей метрикой для оценки модели**. Например, когда речь идет о несбалансированных датасетах.\r\n",
    "\r\n",
    "Другой пример: модель прогнозирования оттока клиентов: модель может сказать вам, что конкретный клиент с вероятностью 90% откажется от услуг, но без четкого понимания причины не ясно, что можно сделать, чтобы предотвратить отток.\r\n",
    "\r\n",
    "Самая точная модель в мире бесполезна, если она не используется для принятия решений и действий.\r\n",
    "\r\n",
    "Поэтому крайне важно сделать модель максимально прозрачной и понятной для заинтересованных сторон, чтобы ее можно было использовать и действовать соответствующим образом.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Таким образом в процесс обучения обучения добавляется пункт **Оценка результата**\n",
    "\n",
    "\n",
    "Для этой задачи существуют специальные библиотеки (LIME, SHAP)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img_licence/3_1_structure.png\" alt=\"alttext\" width=850/>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Оценка важности признаков в простых случаях"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import clear_output\r\n",
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В случае с линейными моделями нам было сравнительно легко определить, какие признаки модель считает важными $-$ если модель присваивает какому-то признаку большой вес, то скорее всего это признак достаточно \"хороший\".\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для примера скачаем датасет жилья Бостона (boston_dataset), в котором проанализируем зависимость цены на жилье от параметров жилья и района, в котором оно находится."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.datasets import load_boston\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# load dataset\r\n",
    "boston_dataset = load_boston()\r\n",
    "X = pd.DataFrame(data=boston_dataset['data'], columns=boston_dataset['feature_names'])\r\n",
    "y = boston_dataset['target']\r\n",
    "\r\n",
    "# Можно посмотреть детальное описание датасета\r\n",
    "print(boston_dataset.DESCR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучим модель"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = LinearRegression()\r\n",
    "model.fit(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выведем коэффициенты признаков"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.coef_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame({\"name\": X.columns, \"coef\": model.coef_})\r\n",
    "\r\n",
    "plt.figure(figsize=(8,8))\r\n",
    "sns.barplot(data=df, y=\"name\", x=\"coef\", color=\"blue\", orient = 'h')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка важности признака для дерева\n",
    "\n",
    "В случае же с деревьями всё далеко не так очевидно: дерево не знает такой концепции как \"вес признака\".\n",
    "\n",
    "Универсального критерия значимости для деревьев у нас нет, и в зависимости от задачи и от того, как эти признаки устроены, ответы могут быть разными.\n",
    "\n",
    "Первый из способов посчитать, насколько тот или иной признак значим для дерева это Gini Impurity measure $-$ показывает, насколько хорошо переменная помогает нам разбивать данные. По сути перекликается с Impurity decrease, который мы использовали при построении  самого дерева."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/pdd/Giny_impurity1.png\" alt=\"alttext\" width=600/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Логика такая: если часто признак у нас присутствует на верхних уровнях дерева, то есть он помогает на маленьких глубинах разбивать выборку, то он более значим, чем признаки, которые используются на более поздних этапах.\n",
    "\n",
    "Но при этом не учитывается, насколько помогло такое начальное разбиение (вспомним пример с XOR). Хорошо было бы учитывать еще и насколько улучшается качество при таком разбиении. Тут нам поможет дополнительно учитывать как раз impurity decrease."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Такая метрика встроена в любое дерево решений. Для случайного леса (и других ансамблей) просто выдается среднее по деревьям.\n",
    "\n",
    "Однако, у нее есть один существенный **недостаток**: чем больше переменная может принимать значений, тем больше у нас возможных порогов разбиений, следовательно, тем больше вероятность получить \"хорошее\" разбиение. \n",
    "Таким образом из двух одинаково неинформативных признаков преимущество будет получать тот, у которого возможных разбиений больше.\n",
    "\n",
    "Бинарные признаки и маломерные вещественные в любом случае будут получать заниженное качество по сравнению с вещественными, даже если те дают худшее разбиение."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/pdd/Giny_impurity2.png\" alt=\"alttext\" width=600/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "\r\n",
    "rng = np.random.RandomState(42)\r\n",
    "model = RandomForestRegressor(random_state=rng)\r\n",
    "model.fit(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.feature_importances_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame({\"name\": X.columns, \"imp\": model.feature_importances_})\r\n",
    "\r\n",
    "plt.figure(figsize=(8,8))\r\n",
    "sns.barplot(data=df, y=\"name\", x=\"imp\", color=\"blue\", orient = 'h')\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Randomization/Permutation\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Мы можем перемешать значения нашей переменной. За счет этого она станет бессмысенной. По падению качества мы можем оценить, каков был вклад переменной до изменения: если качество упало сильно, то признак был значимым."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Можно считать качество на OOB $-$ **Out-of-bag samples**: объектах, которые были выброшены при бутстрепе и которые модель таким образом еще не видела: таким образом, нам не надо делать отдельную валидацию. По очереди пермешиваем значения каждой переменной в OOB и смотрим, как падает качество.\n",
    "В sklearn это реализовано как <a href=\"https://scikit-learn.org/stable/modules/permutation_importance.html\">отдельный класс</a>. \n",
    "\n",
    "Однако, такой подход в чистом виде приведет к завышению важности для коррелирующих признаков.\n",
    "\n",
    "[[Paper] Please Stop Permuting Features](https://blog.ceshine.net/post/please-stop-permuting-features/)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для дерева решений это объясняется следующим образом: линейная регрессия от двух сильно скоррелированных признаков (один линейно выражается через другой) по сути представляет собой регрессию от одного признака. \n",
    "\n",
    "Дерево решений пытается разбить пространство плоскостями, и в областях, где объектов нет, оно по сути занимается угадыванием. Если x1 и x2 на картинке ниже линейно зависимы, то не может возникнуть ситуация, при которой x1 = 0, а x2 = 1. А как раз при перемешивании такая ситуация возникнет, и точки начнут попадать в \"проблемные\" области, в которых дерево решений плохо предсказывает.\n",
    "\n",
    "В результате получаем завышенную важность."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/pdd/figure-4.png\" alt=\"alttext\" width=800/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[[arxiv] Please Stop Permuting Features: An Explanation and Alternatives](https://arxiv.org/abs/1905.03151)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Второй вариант $-$ тоже считать качество на OOB, но при этом при каждом перемешивании тренировать модель **заново**. Это работает адекватно, но очень долго."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "А еще можно пытаться перемешивать так, чтобы не разрушать связи между скоррелированными признаками. В этом случае мы не будем часто попадать в регионы, на которых у нас заведомо не может быть объектов. Также можно добавить сюда переучивание модели каждый раз.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.inspection import permutation_importance\r\n",
    "\r\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=rng)\r\n",
    "model = RandomForestRegressor(random_state=rng)\r\n",
    "model.fit(X_train, y_train)\r\n",
    "\r\n",
    "r = permutation_importance(model, X_val, y_val, n_repeats=100, random_state=rng)\r\n",
    "r.importances_mean"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame({\"name\": X.columns, \"imp\": r.importances_mean})\r\n",
    "\r\n",
    "plt.figure(figsize=(8, 8))\r\n",
    "sns.barplot(data=df, y=\"name\", x=\"imp\", color=\"blue\", orient = 'h')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropped variable importance\n",
    "\n",
    "Редко используемый метод, заключающийся в том, что мы просто выбрасываем переменную и смотрим как упало качество по сравнению с \"полной\" моделью.\n",
    "\n",
    "Это не очень хорошо как минимум потому, что многие гиперпараметры зависят от числа признаков $-$ модель будет работать хуже еще и поэтому. Опять же между признаками могут быть сложные взаимодействия."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Библиотеки для реализации explanation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Мы рассмотрим две библиотеки: SHAP и LIME.\r\n",
    "\r\n",
    "**SHAP (SHapley Additive exPlanations)** &mdash; подход к объяснению моделей машинного обучения, основанный на теории игр. Интерпретация результатов модели SHAP основана на оценке локальной точности признаков (local importance) для каждого объекта, которая определяется [значением Шепли](https://en.wikipedia.org/wiki/Shapley_value). Значения Шепли можно интерпретировать как важность признака для качества предсказания модели, включающей данный признак, по сравнению с моделью, не включающей его, для каждой комбинации признаков.\r\n",
    "\r\n",
    "SHAP учитыват все возможные комбинации признаков, таким образом, SHAP представляет собой единый подход, обеспечивающий глобальную и локальную согласованность и интерпретируемость.\r\n",
    "\r\n",
    "Однако его цена — время, так как алгоритму нужно вычислить все комбинации, чтобы получить результаты.\r\n",
    "\r\n",
    "Напротив, **LIME (Local Interpretable Model-agnostic Explanations)** строит дискретные линейные модели вокруг индивидуального прогноза в его локальной окрестности. LIME на самом деле является подмножеством SHAP, но не имеет тех же свойств.\r\n",
    "\r\n",
    "**Преимущество LIME — скорость**.\r\n",
    "Алгоритм LIME изменяет данные вокруг отдельного прогноза для построения модели, в то время как SHAP должен вычислять все перестановки глобально, чтобы получить локальную точность. Кроме того, модуль SHAP Python пока еще не имеет специально оптимизированных алгоритмов для всех типов алгоритмов (таких как KNN)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [SHAP (SHapley Additive exPlanations)](https://christophm.github.io/interpretable-ml-book/shap.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img_licence/4_shap_diagram.png\" alt=\"alttext\" width=700/>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Цель SHAP — объяснить предсказание объекта $x$ путем вычисления вклада каждого признака в предсказание. Для этого вычисляются SHAP значения, основанные на значениях Шепли из теории игр. \r\n",
    "\r\n",
    "SHAP рассматривает объясняемую модель как игру, а признаки, используемые в обучении, как коалицию игроков. SHAP значения говорят нам, как справедливо распределить \"выигрыш\" между игроками &mdash; это вклад, который каждый игрок вносит в предсказание модели. SHAP основывается на анализе локальной точности признаков, соответственно \"выигрыш\" &mdash; это предсказание, сделанное моделью для одного образца. \r\n",
    "\r\n",
    "При этом игрок не обязательно должен быть индивидуальным признаком, он может состоять из группы признаков. Например, для моделей, работающих с изображениями, пиксели могут быть сгруппированы в суперпиксели, а \"выигрыш\" распределяется между ними. \r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Итак, каким образом можно определить вклад признака в предсказание, сделанное моделью? Предположим у нас есть модель, которая предсказывает доход человека на основании его возраста, пола и профессии. Для определения вклада каждого признака рассмотрим все возможные комбинации $f$ признаков в модели ($f$ от 0 до 3) и представим их в виде графа:\r\n",
    "\r\n",
    "<img src=\"https://miro.medium.com/max/3000/1*GOwxZ1ApAidTIDoa2l98ew.png\" alt=\"alttext\" width=700/>\r\n",
    "\r\n",
    "[SHAP Values Explained Exactly How You Wished Someone Explained to You](https://towardsdatascience.com/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30)\r\n",
    "\r\n",
    "Здесь каждая вершина изображает коалицию признаков, а каждое ребро &mdash; добавление нового признака в коалицию"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее SHAP обучает модель на каждой коалиции признаков в графе (сохраняя гиперпараметры модели и набор тренировочных объектов)\r\n",
    "\r\n",
    "Предположим, что мы обучили модель на всех имеющихся коалициях признаков и сделали предсказание зарплаты для объекта $x_0$.\r\n",
    "\r\n",
    "Нулевая модель делает самое простое \"предсказание\" &mdash; усредняет зарплату, не учитывая никакие признаки (точность соотвествующая).\r\n",
    "Дальше мы можем использовать по однуму признаку, более сложные модели базируются на нескольких признаках.\r\n",
    "\r\n",
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img_licence/shap1.png\" alt=\"alttext\" width=700/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь в вершинах графа находятся предсказания, сделанные соответствующей моделью для объекта $x_0$. \r\n",
    "\r\n",
    "Зная предсказания всех возможных моделей для одного объекта, мы можем посчитать вклад каждого признака в предсказание. Вклад признака в предсказание высчитывается на основании его *предельных вкладов (marginal contribution)*. Предельный вклад признака &mdash; это разница между предсказанием модели, обученной на коалиции, включающей данный признак, и модели, обученной на той же коалиции, за исключениемданного признака. В данном случае можно рассчитать предельный вклад для признака как разницу предсказаний, моделей, соединенных ребром в графе, а само ребро и будет являться предельным вкладом.\r\n",
    "\r\n",
    "Например, предельный вклад для признака Age в предсказание нулевой модели для объекта $x_0$ рассчитывается следующим образом:\r\n",
    "\r\n",
    "$$MC_{Age,\\{Age\\}}(x_0)=Predict_{\\{Age\\}}(x_0)-Predict_{\\emptyset}(x_0)=40k\\$-50k\\$=-10k\\$$$\r\n",
    "\r\n",
    "Для того, чтобы оценить вклад признака в предсказание модели, нужно учесть его предельные вклады, во все модели, где этот признак присутствует (в графе выделены соответствующие ребра):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img_licence/shap2.png\" alt=\"alttext\" width=800/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SHAP значение является общим вкладом признака в предсказание и вычисляется как взвешенная сумма предельных вкладов:\r\n",
    "$$SHAP_{Age}(x_0)=w_1\\cdot MC_{Age,\\{Age\\}}(x_0)+w_2\\cdot MC_{Age,\\{Age, Gender\\}}(x_0)+w_3\\cdot MC_{Age,\\{Age, Job\\}}(x_0)+w_4\\cdot MC_{Age,\\{Age, Gender, Job\\}}(x_0)$$\r\n",
    ",где $w_1+w_2+w_3+w_4=1$\r\n",
    "\r\n",
    "Веса определяются согласно следующим правилам:\r\n",
    "* Для каждого числа признаков в коалиции $f$, cумма весов предельных вкладов в модели, обученные на коалиции из $f$ признаков, должна быть равной, то есть в нашем случае: $$w_1=w_2+w_3=w_4$$\r\n",
    "* Для каждого числа признаков в коалиции $f$, веса предельных вкладов в модели, обученные на коалиции из $f$ признаков, должны быть равными, то есть в нашем случае: $$w_2=w_3$$\r\n",
    "\r\n",
    "Таким образом, нетрудно рассчитать веса предельных вкладов признака Age: $$w_1=w_4=\\frac{1}{3}, \\; w_2=w_3=\\frac{1}{6}$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В общем случае вес предельного вклада в модель, обученную на коалиции из $f$ признаков, обратно пропорционален числу предельных вкладов во все модели, обученные на коалиции из $f$ признаков.\r\n",
    "\r\n",
    "Число предельных вкладов во все модели, обученные на коалиции из $f$ признаков может быть рассчитано как:$f\\cdot \\binom{F}{f}$, где F &mdash; количество признокв"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img_licence/shap3.png\" alt=\"alttext\" width=800/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Итак, давайте рассчитаем SHAP значение признака Age в предсказание модели для объекта $x_0$:\r\n",
    "$$SHAP_{Age}(x_0)=w_1\\cdot MC_{Age,\\{Age\\}}(x_0)\\\\+w_2\\cdot MC_{Age,\\{Age, Gender\\}}(x_0)\\\\+w_3\\cdot MC_{Age,\\{Age, Job\\}}(x_0)\\\\+w_4\\cdot MC_{Age,\\{Age, Gender, Job\\}}(x_0)=\\\\=[(1\\cdot \\binom{3}{1})]^{-1}\\cdot MC_{Age,\\{Age\\}}(x_0)\\\\+[(2\\cdot \\binom{3}{2})]^{-1}\\cdot MC_{Age,\\{Age,Gender\\}}(x_0)\\\\+[(2\\cdot \\binom{3}{2})]^{-1}\\cdot MC_{Age,\\{Age,Job\\}}(x_0)\\\\+[(3\\cdot \\binom{3}{3})]^{-1}\\cdot MC_{Age,\\{Age,Gender,Job\\}}(x_0)=\\\\=\\frac{1}{3}\\cdot(-10k\\$)+\\frac{1}{6}\\cdot(-9k\\$)+\\frac{1}{6}\\cdot(-15k\\$)+\\frac{1}{3}\\cdot(-12k\\$)=-11.33k\\$$$\r\n",
    "\r\n",
    "В общем случае SHAP значение для некого признака будет вычисляться следующим образом:\r\n",
    "$$SHAP_{feature}(x)=\\sum_{set:feature\\in set}[|set|\\cdot \\binom{F}{|set|}]^{-1}(Predict_{set}(x)-Predict_{set\\backslash feature}(x))$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/pdd/shap4.png\" alt=\"alttext\" width=600/>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Такие SHAP значения можно легко посчитать для каждого признака для каждого объекта и, например, усреднить по объектам какой-то группы. \r\n",
    "\r\n",
    "Например, можно взять все объекты, которые модель скорит высоко, и посмотреть значимые дли них признаки. Либо, если у нас есть какая-то особенная группа объектов, можем контролировать, что для них модель выучивает именно важные признаки, а не какой-то мусор."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Посмотрим, как реализуется этот подход в NLP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import clear_output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Установим пакета SHAP "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install shap\r\n",
    "clear_output()\r\n",
    "\r\n",
    "import shap"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Пример обьяснения перевода с английского на русский\n",
    "Рассмотрим пример интерпретации модели для предварительно обученной модели машинного перевода\n",
    "[Machine Translation Example](https://shap.readthedocs.io/en/stable/example_notebooks/text_examples/translation/Machine%20Translation%20Explanation%20Demo.html). И, раз уж мы будем для перевода использовать предобученную модель-транформер, то переведем начало статьи [How Transformers Work](https://towardsdatascience.com/transformers-141e32e69591)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### $\\color{brown}{\\text{Допольнительная информация}}$\n",
    "\n",
    "О трансформерах"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attention"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-020.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Self - attention"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-070.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Реккурентность не нужна, можем обрабатывать данные параллельно.\n",
    "\n",
    "Transformer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-092.png\" width=\"700\">\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NLP модель"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Используем одну из моделей [huggingface ](https://github.com/huggingface/transformers)\n",
    "\n",
    "\n",
    "Модель: [Language Technology in Helsinki](https://blogs.helsinki.fi/language-technology/)\n",
    "\n",
    "\n",
    "[Language Technology Research Group at the University of Helsinki](https://huggingface.co/Helsinki-NLP)\n",
    "\n",
    "\n",
    "[Helsinki-NLP/opus-mt-en-ru](https://huggingface.co/Helsinki-NLP/opus-mt-en-ru)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install sentencepiece\r\n",
    "!pip install transformers\r\n",
    "clear_output()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загружаем модель.\n",
    "\n",
    "Для этого используется класс-фабрика, на вход которому передается имя модели, а возвращается он объект соответствующего класса."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "from transformers import  AutoModelForSeq2SeqLM\r\n",
    "import sentencepiece\r\n",
    "lang = \"en\"\r\n",
    "target_lang = \"ru\"\r\n",
    "model_name = f'Helsinki-NLP/opus-mt-{lang}-{target_lang}'\r\n",
    "\r\n",
    "# Download the model and the tokenizer\r\n",
    "# Можно попробовать перевод и разными предобученными моделями\r\n",
    "\r\n",
    "\r\n",
    "# It's a Factory pattern\r\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\r\n",
    "model.to(device)\r\n",
    "clear_output()\r\n",
    "print(type(model))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В данном случае нам вернулся объект типа [MarianMT](https://huggingface.co/transformers/model_doc/marian.html)\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь создадим [токенайзер](https://huggingface.co/transformers/main_classes/tokenizer.html).\n",
    "\n",
    "Как мы уже обсуждали, токенайзер преобразует слова и знаки препинания в исходного текста в токены которые можно подать на вход модели. В данном случае возвращаются id. При этом не всегда одно слово преобразуется в один токен, иногода слово разбивается по слогам на несколько токенов.\n",
    "\n",
    "\n",
    "Создается токенайзер так же фабрикой, по имени модели.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer\r\n",
    "\r\n",
    "\r\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\r\n",
    "print(type(tokenizer))\r\n",
    "\r\n",
    "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\r\n",
    "print(inputs)\r\n",
    "\r\n",
    "translated = model.generate(**tokenizer(\"Hello world!\", return_tensors=\"pt\").to(device))\r\n",
    " # ** -  is dictionary unpack operator\r\n",
    " # https://towardsdatascience.com/unpacking-operators-in-python-306ae44cd480"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь переведем целую фразу. \n",
    "\n",
    "И проанализируем как выход модели связан со входом.\n",
    "\n",
    "Для этого создадим объект [shap.Explaner](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html)\n",
    "\n",
    "Который в данном случае инициализируется экземпляром модели и экземпляром токенайзера*.\n",
    "\n",
    "\n",
    "Вместо того что бы запускать саму модель, мы запускаем Explainer (неявно вызывая его метод __call__). \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* В действительности вторым параметром конструктора shap.Explainer не обязательно должен быть токенайзер. shap.Explainer принимает объект поддерживающий интерфейс masker:\n",
    "\n",
    "masked_args = masker(*model_args, mask=mask)\n",
    "\n",
    "Он используется для исключения части аргументов и токенайзеры поддерживают этот интерфейс (shap.TokenMasker). Благодаря такому подходу shap может работать с k.,с различными моделями как с \"черным ящиком\", \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import shap\r\n",
    "# define the input sentences we want to translate\r\n",
    "data = [\r\n",
    "    \"Transformers are a type of neural network architecture that have been gaining popularity. Transformers were developed to solve the problem of sequence transduction, or neural machine translation. That means any task that transforms an input sequence to an output sequence. This includes speech recognition, text-to-speech transformation, etc..\"\r\n",
    "]\r\n",
    "\r\n",
    "# we build an explainer by passing the model we want to explain and\r\n",
    "# the tokenizer we want to use to break up the input strings\r\n",
    "explainer = shap.Explainer(model, tokenizer)\r\n",
    "\r\n",
    "# explainers are callable, just like models\r\n",
    "explanation = explainer(data, fixed_context=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вместо того что бы запускать саму модель, мы запускаем экземпляр Explainer (неявно вызывая его метод call). \n",
    "\n",
    "На выходе получаем объект класса [shap.Explanation](https://shap.readthedocs.io/en/latest/generated/shap.Explanation.html#shap-explanation)\n",
    "\n",
    "\n",
    "Который содержит значения Шепли для каждого токена."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Data\", explanation.data)\r\n",
    "print(\"Shap values\", explanation.values)\r\n",
    "print(\"Shape\", explanation.shape) # 1, in, out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Теперь используя магию shap можно визуализировать результат."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shap.plots.text(explanation)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LIME\n",
    "\n",
    "Local Interpretable Model-agnostic Explanations\n",
    "\n",
    "Поскольку мы хотим быть независимыми от модели, то следующее, что мы можем сделать, чтобы изучить поведение базовой модели — это изменить входные данные и посмотреть, как меняются прогнозы.\n",
    "\n",
    "Это оказывается преимуществом с точки зрения интерпретируемости, потому что мы можем изменять компоненты на входе, которые имеют смысл для людей (например, слова или части изображения), даже если модель использует гораздо более сложные компоненты в качестве функций (например, word embeddings).\n",
    "\n",
    "LIME генерирует объяснение, аппроксимируя базовую модель интерпретируемой (например, линейной моделью с несколькими ненулевыми коэффициентами), изученной при возмущениях исходной модели (например, удалении слов или скрытии частей изображения).\n",
    "\n",
    "Ключевая идея, лежащая в основе LIME, заключается в том, что гораздо проще аппроксимировать модель черного ящика простой моделью локально, чем пытаться обьяснить модель целиком (глобально).\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Принцип работы:\n",
    "\n",
    "\n",
    "1.   Делаем предсказание для целевого объекта\n",
    "2.   Убираем часть признаков* у объекта и делаем новое предсказание\n",
    "3.   Шаг 2 повторяем несколько раз, все предсказания сохраняем\n",
    "4.   Из полученных данных формируем датасет, на котором обучаем линейную модель.\n",
    "5.   Коэффициенты линейной модели используем для оценки важности признаков.\n",
    "\n",
    "Первоисточник: [Why should I trust you?](https://arxiv.org/abs/1602.04938)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Как маскировать признаки?\n",
    "\n",
    "Зависит от типа данных:\n",
    "*  Для табличных данных достаточно заменить значения признака на None.\n",
    "*  В текстах можно просто удалить слово. \n",
    "*  Для изображений делят картинку на области (суперпиксели) и поочередно закрашивают их одним и тем же цветом (средним)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ограничения\n",
    "\n",
    "Описанный подход не позволит интерпретировать поведение модели только в некоторой области вблизи интересующего нас экземпляра.\n",
    "На практике этого может быть достаточно. И в отличие от SHAP этот подход работает быстрее так как не требует перебора всех комбинаций признаков."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L10_Explainability/img_licence/lime.png\" width=\"600\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Модель f &mdash; нелинейная функция, представленная в виде разделяющей поверхности между розовым и голубым фоном.\n",
    "* Объект, для которого планируеьтся сделать интерпретацию предсказаний модели, обозначен жирным красным крестом\n",
    "* Сгенерированные объекты обозначены кругами и крестами в зависимости от класса\n",
    "* Размер объектов отражает их близость к исходному (по некоторой метрике расстояния)\n",
    "* Пунктир &mdash; граница которую выучила линейная модель"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Пример обьяснения классфикации статей по религиозному принципу"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/5_christian_or_atheist_2.png\" alt=\"alttext\" width=900/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](https://arxiv.org/abs/1602.04938)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Используем датасет [fetch_20newsgroups](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html): \n",
    "\n",
    "Данные [«The 20 Newsgroups»](http://qwone.com/~jason/20Newsgroups/) — это коллекция примерно из 20000 новостных документов, разделенная (приблизительно) равномерно между 20 различными категориями. Изначально она собиралась Кеном Ленгом (Ken Lang), возможно, для его работы «Newsweeder: Learning to filter netnews» («Новостной обозреватель: учимся фильтровать новости из сети»).\n",
    "\n",
    "Коллекция «The 20 newsgroups» стала популярным набором данных для экспериментов с техниками машинного обучения для текстовых приложений, таких как классификация текста или его кластеризация.\n",
    "\n",
    "[[code] Fetching data, training a classifier](https://marcotcr.github.io/lime/tutorials/Lime%20-%20multiclass.html)\n",
    "\n",
    "В данном примере мы будем использовать [Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomial%20naive%20bayes#sklearn.naive_bayes.MultinomialNB) для классификации."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sklearn\r\n",
    "from sklearn.datasets import fetch_20newsgroups\r\n",
    "\r\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\r\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\r\n",
    "# making class names shorter\r\n",
    "class_names = [x.split('.')[-1] if 'misc' not in x else '.'.join(x.split('.')[-2:]) for x in newsgroups_train.target_names]\r\n",
    "class_names[3] = 'pc.hardware'\r\n",
    "class_names[4] = 'mac.hardware'\r\n",
    "\r\n",
    "print(class_names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "LIME используется для объяснения множества классификаторов (таких как RandomForest или SVM и нейронные сети) при анализе моделей NLP и CV.\n",
    "\n",
    "Знаменитый набор данных из 20 групп новостей является эталоном и использовался для сравнения различных моделей в нескольких статьях.\n",
    "\n",
    "Мы берем два класса, которые трудно различить, потому что в них много схожих слов: христианство и атеизм.\n",
    "\n",
    "Обучая модель, мы получаем точность тестового набора 83,5%, что является удивительно высоким показателем. Если бы точность была нашим единственным мерилом доверия, мы бы точно доверились этому классификатору.\n",
    "\n",
    "Однако давайте посмотрим на объяснение на рисунке для произвольного экземпляра в тестовом наборе:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "import sklearn.metrics\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "\r\n",
    "# Again, let's use the tfidf vectorizer, commonly used for text.\r\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\r\n",
    "train_vectors = vectorizer.fit_transform(newsgroups_train.data)\r\n",
    "test_vectors = vectorizer.transform(newsgroups_test.data)\r\n",
    "\r\n",
    "# Train the model\r\n",
    "nb = MultinomialNB(alpha=.01)\r\n",
    "nb.fit(train_vectors, newsgroups_train.target)\r\n",
    "\r\n",
    "# Calculate F1_score\r\n",
    "pred = nb.predict(test_vectors)\r\n",
    "sklearn.metrics.f1_score(newsgroups_test.target, pred, average='weighted')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(train_vectors.shape)\r\n",
    "print(type(train_vectors[0]), train_vectors[0].shape)\r\n",
    "print(vectorizer.get_feature_names())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как видно из кода, текст подается на вход модели не в сыром виде, а после предобработки объектом vectorizer. \n",
    "\n",
    "[LimeTextExplainer](https://lime-ml.readthedocs.io/en/latest/lime.html#lime.lime_text.LimeTextExplainer)  ждет на вход данные и класс модели:\n",
    "\n",
    "\n",
    "```\n",
    "explain_instance(text_instance, classifier_fn, labels=(1, ), top_labels=None, num_features=10, num_samples=5000, distance_metric='cosine', model_regressor=None)\n",
    "```\n",
    "\n",
    "**classifier_fn** *– classifier prediction probability function, which takes a list of d strings and outputs a (d, k) numpy array with prediction probabilities, where k is the number of classes. For ScikitClassifiers , this is classifier.predict_proba.*\n",
    "\n",
    "\n",
    "\n",
    " Что поэтому в примере используется обертка над классом преобразовывающем данные и моделью:\n",
    "\n",
    " [sklearn.pipeline.make_pipeline](#https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.pipeline import make_pipeline\r\n",
    "\r\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html\r\n",
    "model_with_preprocessing = make_pipeline(vectorizer, nb)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Мы видим, что этот классификатор имеет очень высокий F1_score. Руководство sklearn для 20 newsgroups указывает, что Multinomial Naive Bayes переучивается на этом наборе данных, изучая нерелевантные взаимосвязи, такие как заголовки.\n",
    "\n",
    "Теперь мы используем LIME для объяснения индивидуальных прогнозов...\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В случае мультикласса мы должны определить, для каких меток хотим получим объяснения с помощью параметра «labels». Сгенерируем пояснения для меток 0 и 17:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install lime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import lime\r\n",
    "from lime.lime_text import LimeTextExplainer\r\n",
    "explainer = LimeTextExplainer(class_names=class_names, random_state=rng)\r\n",
    "idx = 1340\r\n",
    "exp = explainer.explain_instance(newsgroups_test.data[idx],\r\n",
    "                                 model_with_preprocessing.predict_proba,\r\n",
    "                                 num_features=6,\r\n",
    "                                 labels=[0,\r\n",
    "                                         17\r\n",
    "                                         ])\r\n",
    "print('Document id: %d' % idx)\r\n",
    "print('Predicted class =', class_names[nb.predict(test_vectors[idx]).reshape(1,-1)[0,0]])\r\n",
    "print('True class: %s' % class_names[newsgroups_test.target[idx]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Возвращается как и в случае с SHAP специальный объект класса [Explanation](https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=Explanation#lime.explanation.Explanation)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Попросим LIME сгенерировать метки для K=2 классов. Чтобы увидеть, какие ярлыки имеют объяснения, используйте функцию available_labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "idx = 1340\r\n",
    "exp = explainer.explain_instance(newsgroups_test.data[idx],\r\n",
    "                                 model_with_preprocessing.predict_proba,\r\n",
    "                                 num_features=6,\r\n",
    "                                 top_labels=2)\r\n",
    "print(exp.available_labels())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(exp.as_list(label = 0))\r\n",
    "print(exp.as_list(label = 15))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обратите внимание, что положительный и отрицательный знаки относятся к конкретной метке — так что слова, отрицательные по отношению к классу 0, могут быть положительными по отношению к классу 15, и наоборот."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp.show_in_notebook(text=newsgroups_test.data[idx], labels=(0,))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь давайте посмотрим на визуализацию объяснений.\n",
    "Обратите внимание, что для каждого класса слова в правой части строки являются «положительными», а слова в левой части — «отрицательными» для обьясняемого класса.\n",
    "\n",
    "Также видно, что в классификаторе используются как разумные слова (такие как «геноцид», «Лютер», «семитский» и т. д.), так и неразумные («рис», «сова»).\n",
    "\n",
    "Давайте увеличим масштаб и просто посмотрим на объяснения класса «атеизм»."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "exp.show_in_notebook(text=newsgroups_test.data[idx], labels=(15,))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Глядя на этот пример, можно увидеть, что в заголовке или кавычках может быть и полезный сигнал, который будет помогать обобщению (например,  в строке «Тема»).\n",
    "\n",
    "А есть и слова, которые нельзя обобщать (например, адреса электронной почты и названия учреждений)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### $\\color{brown}{\\text{Допольнительная информация}}$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### TF-IDF:\n",
    "\n",
    "\n",
    "[[wiki] TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF)\n",
    "\n",
    "[[code] sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "\n",
    "[[medium] TF-IDF Vectorizer scikit-learn](https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " ###### Multinomial Naive Bayes\n",
    "\n",
    "[[code] sklearn.naive_bayes.MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomial%20naive%20bayes#sklearn.naive_bayes.MultinomialNB)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Другие библиотеки"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[[git] DEN](https://github.com/isaacrob/DEN) : основан на новом режиме обучения сиамской нейронной сети без учителя и функции потерь, который называется Differentiating EmbeddingNetworks (DEN).\n",
    "\n",
    "Сиамская нейронная сеть находит отличительные или похожие черты между конкретными парами образцов в наборе данных и использует эти функции, чтобы встроить набор данных в пространство более низкой размерности, где он может быть визуализирован.\n",
    "\n",
    "В отличие от существующих алгоритмов визуализации, таких как UMAP ort-SNE, DEN является параметрическим, то есть его можно интерпретировать такими методами, как SHAP.\n",
    "\n",
    "[[towardsdatascience] XAI](https://towardsdatascience.com/xai-build-your-own-deep-learning-interpretation-algorithm-6e471b59af7) \n",
    "\n",
    "[[git] Boruta](https://github.com/scikit-learn-contrib/boruta_py) — это метод выбора всех релевантных функций, изобретенный Витольдом Р. Рудницки и разработанный Мироном Б. Курса из ICM UW.\n",
    "\n",
    "Boruta выбирает все необходимые признаки, в то время как другие являются не оптимальными. Метод пытается найти все признаки, несущие информацию, используемую для прогнозирования, вместо того, чтобы находить компактное подмножество признаков, по которым некоторый классификатор имеет минимальную ошибку.\n",
    "\n",
    "Зачем беспокоиться о выборе всех необходимых признаков?\n",
    "\n",
    "Когда вы пытаетесь понять феномен, создавший ваши данные, вы должны заботиться о тех факторах, которые способствуют этому, а не только о самых грубых признаках этого в контексте вашей методологии. Но помните, что минимальный оптимальный набор признаков по определению зависит от вашего выбора классификатора. В примере ниже можно увеличить число слоев и, отвергнутые ранее признаки окажутся востребованными моделью.\n",
    "\n",
    "[[towardsdatascience] Boruta Feature Selection](https://towardsdatascience.com/simple-example-using-boruta-feature-selection-in-python-8b96925d5d7a) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boruta \n",
    "\n",
    "Автоматический отбор признаков на github [boruta_py](https://github.com/scikit-learn-contrib/boruta_py)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Попробуем \"раздуть\" наш датасет, добавив в него \"теневые признаки\" $-$ перемешанные реальные. Таким образом наш датасет точно будет содержать хорошие признаки (мы ничего не удаляем). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Идея"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/pdd/boruta1.png\" alt=\"alttext\" width=600/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "После этого обучаем модель и отбираем те признаки, которые по качеству лучше теневых. Успех? Не совсем, ведь перемешивание это случаный процесс. Надо повторить процедуру несколько раз для того чтобы удалить случайные скачки качества.\n",
    "\n",
    "Таким образом для каждого признака мы будем знать сколько раз мы его отобрали. Получаем распределение. Самая большая неопределенность будет в середине (вероятность отобрать = 0.5):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/pdd/boruta_bell.png\" alt=\"alttext\" width=700/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Boruta Explained Exactly How You Wished Someone Explained to You](https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Набор (в нашем случае из 20) испытаний Бернулли это биномиальное распределение. поступаем просто. Со значимостью допустим 0.05 берем все из хорошего хвоста и отбрасываем из плохого хвоста. С признаками из середины колокола ничего особо не сделаешь, увеличение числа итераций приведет к ужатию колокола но глобально не поможет.\n",
    "\n",
    "Если нам нужна хорошо интерпретируемая модель то надо брать только \"точно хорошие\" признаки. А если мы готовы поднабрать мусорных признаков то можем отбросить только плохой хвост.\n",
    "\n",
    "Классическая Борута работает с Gini Impurity, но есть и реализации с SHAP. В этом плане она универсальна. В принципе ее можно применять и для градиентного бустинга тоже."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Применение"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import clear_output\r\n",
    "!pip install boruta\r\n",
    "clear_output()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Питоновская реализация Boruta соответствует  API sklearn и может использоваться как в конвейере, так и самостоятельно.\n",
    "\n",
    "[[towardsdatascience] Boruta Feature Selection (an Example in Python)](https://towardsdatascience.com/simple-example-using-boruta-feature-selection-in-python-8b96925d5d7a)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузка датасета"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.datasets import load_boston\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# load dataset\r\n",
    "datasets = load_boston()\r\n",
    "X = pd.DataFrame(datasets['data'], columns = datasets['feature_names'])\r\n",
    "y = pd.Series(datasets['target'], name = 'target_values')\r\n",
    "X[:2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X.shape, type(X), y.shape, type(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разобьем датасет на обучающую и тестовую выборки"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "def split_data(X,y):\r\n",
    "  global X_train, X_test, y_train, y_test\r\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
    "\r\n",
    "  X_train = X_train.values\r\n",
    "  X_test = X_test.values\r\n",
    "  y_train = y_train.values\r\n",
    "  y_test = y_test.values\r\n",
    "\r\n",
    "  print(\"X_train\",X_train.shape)\r\n",
    "  print(\"X_test\", X_test.shape)\r\n",
    "  print(\"y_train\", y_train.shape)\r\n",
    "  print(\"y_test\", y_test.shape)\r\n",
    "  print(\"type of y_test\", type(y_test))\r\n",
    "\r\n",
    "split_data(X,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучим модель"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "def evaluate():\r\n",
    "  # define random forest regressor\r\n",
    "  forest = RandomForestRegressor(n_jobs=-1,  max_depth=4,random_state = 42)\r\n",
    "  forest.fit(X_train, y_train)\r\n",
    "  r2 = forest.score(X_test, y_test)\r\n",
    "  # R2 is coefficient of determination \r\n",
    "  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\r\n",
    "  print(f'R2 score {r2:.4f}')\r\n",
    "  return forest\r\n",
    "forest = evaluate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проведем оценку признаков при помощи Boruta.\n",
    "P.S. Потребуется около 30 сек."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from boruta import BorutaPy\r\n",
    "\r\n",
    "# define Boruta feature selection method\r\n",
    "feat_selector = BorutaPy(forest, n_estimators='auto', verbose=2, random_state=42)\r\n",
    "\r\n",
    "# find all relevant features\r\n",
    "feat_selector.fit(X_train, y_train)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выведем признаки с оценкой их важности и очистим датасет от маловажных признаков"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# zip my names, ranks, and decisions in a single iterable\r\n",
    "feature_ranks = list(zip(datasets.feature_names, \r\n",
    "                         feat_selector.ranking_, \r\n",
    "                         feat_selector.support_))\r\n",
    "\r\n",
    "# iterate through print out the results and remove features with low rank\r\n",
    "for feat in feature_ranks:\r\n",
    "    print('Feature: {:<25} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\r\n",
    "    if feat[2] == False: del X[feat[0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Датасет без \"лишних\" по мнению Boruta признаков"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X[:2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучение на признаках, отобранных Boruta\n",
    "Давайте проверим, можем ли мы добиться такого же результата, если проанализируем и уберем «лишние» данные?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " split_data(X,y)\r\n",
    " _ = evaluate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Удалив 4 признака мы не потеряли в точности."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Примеры explanations для разных видов данных"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tabular examples"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для примера скачаем датасет жилья Бостона (boston_dataset), в котором проанализируем зависимость цены на жилье от параметров жилья и района, в котором оно находится."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import clear_output\r\n",
    "!pip install shap\r\n",
    "clear_output()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.datasets import load_boston\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import shap\r\n",
    "\r\n",
    "# load dataset\r\n",
    "boston_dataset = load_boston()\r\n",
    "X = pd.DataFrame(data=boston_dataset['data'], columns=boston_dataset['feature_names'])\r\n",
    "y = boston_dataset['target']\r\n",
    "\r\n",
    "# Split the data into train and test data\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\r\n",
    "\r\n",
    "# Build the model with the random forest regression algorithm\r\n",
    "rng = np.random.RandomState(42)\r\n",
    "model = RandomForestRegressor(n_estimators=10, max_depth=6, random_state=rng)\r\n",
    "model.fit(X_train, y_train)\r\n",
    "\r\n",
    "# explain the model's predictions using SHAP\r\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\r\n",
    "explainer = shap.TreeExplainer(model)\r\n",
    "shap_values = explainer.shap_values(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Можно посмотреть детальное описание датасета\r\n",
    "print(boston_dataset.DESCR)\r\n",
    "print(type(shap_values)) # numpy.ndarray"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Force plots** \n",
    "\n",
    "Хороший способ визуализировать вклад каждого фактора в конкретный прогноз — использовать график сил.\n",
    "\n",
    "В приведенном ниже примере показан график силы для 2-го случая в тестовом наборе данных."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load JS visualization code to notebook\r\n",
    "shap.initjs()\r\n",
    "# visualize the first prediction’s explanation\r\n",
    "shap.force_plot(explainer.expected_value, shap_values[1, :], X.iloc[1, :])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* $f(x)$ &mdash; это прогноз модели по анализируемому обьекту недвижимости. А base_value - это средний прогноз по всему набору тестовых данных. Или, другими словами, это значение, которое можно было бы спрогнозировать, если бы мы не знали никаких характеристик текущего примера.\r\n",
    "\r\n",
    "* Элементы, которые способствуют увеличению цены, показаны красным, а те, которые уменьшают — синим."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Waterfall_plot**\n",
    "\n",
    "Другой способ понимания влияния факторов для конкретного примера:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# visualize the first prediction's explanation using waterfall\r\n",
    "i = 1 # смотрим влияние факторов для 2го примера\r\n",
    "features = list(X.columns) # формируем список признаков\r\n",
    "class ShapObject:\r\n",
    "    def __init__(self, base_values, data, values, feature_names):\r\n",
    "        self.base_values = base_values # Single value\r\n",
    "        self.data = data # Raw feature values for 1 row of data\r\n",
    "        self.values = values # SHAP values for the same row of data\r\n",
    "        self.feature_names = feature_names # Column names\r\n",
    "        \r\n",
    "shap_object = ShapObject(base_values = explainer.expected_value[0],\r\n",
    "                         values = shap_values[i,:],\r\n",
    "                         feature_names = features,\r\n",
    "                         data = X[features].iloc[i,:])\r\n",
    "\r\n",
    "shap.waterfall_plot(shap_object)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Этот график обьясняет движущие силы конкретного прогноза:\n",
    "\n",
    "Влияние каждой отдельной функции (менее значимые функции объединяются в одну группу) представлено стрелками, которые перемещают логарифмическое отношение шансов влево и вправо, начиная с базового значения.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Приведенный выше пример приведен только для одного случая.\n",
    "\n",
    "Если мы возьмем много пояснений Force plots, повернем их на 90 градусов, а затем сложим их по горизонтали, мы сможем увидеть объяснения для всего набора данных (в notebook этот график является интерактивным):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load JS visualization code to notebook\r\n",
    "shap.initjs()\r\n",
    "# visualize the training set predictions\r\n",
    "shap.force_plot(explainer.expected_value, shap_values, X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "df = pd.DataFrame(shap_values, columns=X.columns)\r\n",
    "sns.clustermap(df)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Summary plot**\n",
    "\n",
    "Сводный график с plot_type = 'bar' даст нам график важности переменной.\n",
    "\n",
    "Функции с высокой предсказательной способностью показаны вверху, а с низкой предсказательной силой — внизу."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shap.summary_plot(shap_values, X_train, plot_type='bar')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Здесь мы только что рассмотрели алгоритм TreeExplainer для интерпретации модели.\n",
    "\n",
    "Вы можете изучить остальные алгоритмы — DeepExplainer, kernelExplainer, LinearExplainer и GradientExplainer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NLP: Пример абстрактного обобщения текста \n",
    "\n",
    "потребуется время"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[[text] plot](https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/text.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В этом примере интерпретируется модель генерации объяснений для предварительно обученной модели для составления краткого резюме статьи.\n",
    "\n",
    "Используется датасет Extreme Summarization [XSum](https://huggingface.co/sshleifer/distilbart-xsum-12-6)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install datasets\r\n",
    "!pip install transformers\r\n",
    "clear_output()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import shap\r\n",
    "from datasets import load_dataset\r\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\r\n",
    "import torch\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-xsum-12-6\")\r\n",
    "model =  AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-xsum-12-6\").to(device) \r\n",
    "\r\n",
    " \r\n",
    "dataset = load_dataset('xsum', split='train') # загружаем датасет\r\n",
    "s = dataset['document'][0:1]                 # slice inputs from dataset to run model inference on\r\n",
    "explainer = shap.Explainer(model, tokenizer)  # create an explainer object\r\n",
    "explanation = explainer(s)                   # Compute shap values\r\n",
    "clear_output()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shap.initjs()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shap.plots.text(explanation)                 # Visualize shap explanations"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Изображения"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LIME\n",
    "[Local Interpretable Model-Agnostic Explanations (LIME): An Introduction](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)\n",
    "\n",
    "[[git] Using Lime with Pytorch](https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20images%20-%20Pytorch.ipynb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Идея\n",
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/7_Google_Inception_neural_network.png\" alt=\"alttext\" width=820/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[\"Why Should I Trust You?\"](https://arxiv.org/abs/1602.04938) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте разберемся, как работает такое эффектное представление областей, по которым нейронная сеть осуществляет предсказание класса.\n",
    "\n",
    "На рисунке ниже показан пример того, как LIME работает для классификации изображений.\n",
    "\n",
    "Представьте, что мы хотим объяснить классификатор, который предсказывает, насколько вероятно, что изображение содержит древесную лягушку.\n",
    "\n",
    "Мы берем изображение слева и делим его на интерпретируемые компоненты (смежные [суперпиксели](https://darshita1405.medium.com/superpixels-and-slic-6b2d8a6e4f08))."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/l10_figure3.jpg\" alt=\"alttext\" width=550/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее мы отключаем некоторые из суперпикселей (закрашиваем серым).\n",
    "\n",
    "Для каждой такой картинки мы получаем вероятность того, что на изображении есть древесная лягушка и формируем из датасет из частично закрашенных картинок и предсказаний.\n",
    "\n",
    "Затем мы обучаем линейную модель на этом наборе данных, веса соответствующие суперпикселю будут объяснять его вклад в передсказание."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/l10_figure4.jpg\" alt=\"alttext\" width=750/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проанализируем предсказание сверточной сети Google Inception. Посмотрим, почему ее классификатор предсказывает «древесную лягушку» как наиболее вероятный класс, за которым следуют «бильярдный стол» и «воздушный шар» с более низкими вероятностями.\n",
    "\n",
    "Мы видим, что классификатор в первую очередь фокусируется на морде лягушки как на объяснении предсказанного класса.\n",
    "\n",
    "Это также проливает свет на то, почему «бильярдный стол» имеет ненулевую вероятность: руки и глаза лягушки напоминают бильярдные шары, особенно на зеленом фоне. Точно так же сердце похоже на красный воздушный шар.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"http://edunet.kea.su/repo/src/L10_Explainability/img/l10_figure6.jpg\" alt=\"alttext\" width=750/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[[medium] LIME - Local Interpretable Model-Agnostic Explanation](https://medium.com/intel-student-ambassadors/local-interpretable-model-agnostic-explanations-lime-the-eli5-way-b4fd61363a5e)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Анализ ResNet18"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import clear_output\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from PIL import Image\r\n",
    "import torch.nn as nn\r\n",
    "#import numpy as np\r\n",
    "import os, json\r\n",
    "\r\n",
    "#import torch\r\n",
    "from torchvision import models, transforms\r\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!wget --no-check-certificate 'http://edunet.kea.su/repo/src/L10_Explainability/data/cat_and_dog1.jpg' -O cat_and_dog1.jpg\r\n",
    "!wget --no-check-certificate 'http://edunet.kea.su/repo/src/L10_Explainability/data/cat_and_dog2.png' -O cat_and_dog2.png\r\n",
    "!wget --no-check-certificate 'http://edunet.kea.su/repo/src/L10_Explainability/data/imagenet_class_index.json' -O imagenet_class_index.json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_image(path):\r\n",
    "    with open(os.path.abspath(path), 'rb') as f:\r\n",
    "        with Image.open(f) as img:\r\n",
    "            return img.convert('RGB') \r\n",
    "        \r\n",
    "img = get_image('cat_and_dog1.jpg')\r\n",
    "plt.imshow(img)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь нам нужно преобразовать это изображение в тензор Pytorch, а также его нормализовать для использорвания в нашей предварительно обученной модели."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# resize & normalize\r\n",
    "def get_input_transform():\r\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n",
    "                                    std=[0.229, 0.224, 0.225])       \r\n",
    "    transf = transforms.Compose([\r\n",
    "        transforms.Resize((256, 256)),\r\n",
    "        transforms.CenterCrop((224, 224)),\r\n",
    "        transforms.ToTensor(),\r\n",
    "        normalize])    \r\n",
    "    return transf\r\n",
    "\r\n",
    "def get_input_tensors(img):\r\n",
    "    transf = get_input_transform()\r\n",
    "    # unsqeeze converts single image to batch of 1\r\n",
    "    return transf(img).unsqueeze(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Загрузим предобученную модель Resnet18, доступную в Pytorch и классы изображений из ImageNet."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = models.resnet18(pretrained=True)\r\n",
    "\r\n",
    "idx2label, cls2label, cls2idx = [], {}, {}\r\n",
    "with open(os.path.abspath('/content/imagenet_class_index.json'), 'r') as read_file:\r\n",
    "    class_idx = json.load(read_file)\r\n",
    "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\r\n",
    "    cls2label = {class_idx[str(k)][0]: class_idx[str(k)][1] for k in range(len(class_idx))}\r\n",
    "    cls2idx = {class_idx[str(k)][0]: k for k in range(len(class_idx))}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получим предсказание. А после этого полученные нами прогнозы (логиты), пропустим это через softmax, чтобы получить вероятности и метки классов для 5 лучших прогнозов."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_t = get_input_tensors(img)\r\n",
    "model.eval()\r\n",
    "logits = model(img_t)\r\n",
    "\r\n",
    "probs = F.softmax(logits, dim=1)\r\n",
    "probs5 = probs.topk(5)\r\n",
    "plt.imshow(img)\r\n",
    "tuple((p,c, idx2label[c]) for p, c in zip(probs5[0][0].detach().numpy(), probs5[1][0].detach().numpy()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(tabby - это тоже кошка.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Применим LIME"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install lime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lime генерирует массив изображений из исходного входного изображения с помощью алгоритма пертубации.\n",
    "\n",
    "Таким образом, нам нужно предоставить конструктору :\n",
    "1. Исходное изображение в виде массива numpy\n",
    "2. Функцию классификации, которая будет принимать массив искаженных изображений в качестве входных данных и генерировать вероятности для каждого класса для каждого изображения в качестве выходных.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Поэтому потребуется вспомогательная функция для обработки пакета изображений, в соответствии с API LIME."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import numpy as np\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "def batch_predict(images): # images are numpy arrays\r\n",
    "    model.eval()\r\n",
    "    transf = get_input_transform()\r\n",
    "    batch = torch.stack(tuple(transf(Image.fromarray(i)) for i in images), dim=0)\r\n",
    "\r\n",
    "    model.to(device)\r\n",
    "    batch = batch.to(device)\r\n",
    "    \r\n",
    "    logits = model(batch)\r\n",
    "    probs = F.softmax(logits, dim=1)\r\n",
    "    return probs.detach().cpu().numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создадим экзепляр ImageExplainer и сгенерируем объект explanation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import lime\r\n",
    "import numpy as np\r\n",
    "from lime import lime_image\r\n",
    "\r\n",
    "explainer = lime_image.LimeImageExplainer(random_state= 42)\r\n",
    "explanation = explainer.explain_instance(np.array(img.resize((224,224))), # Lime assume that input is a numpy array :(\r\n",
    "                                         batch_predict, # classification function\r\n",
    "                                         top_labels=5, \r\n",
    "                                         hide_color=0, \r\n",
    "                                         num_samples=1000,  # number of images that will be sent to classification function\r\n",
    "                                         random_seed = 42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выведем top5 предсказаний сделанных через LIME.\n",
    "\n",
    "P.S. Они не обязанны совпадать с предсказаниями для картинки без изменений."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, id in enumerate(explanation.top_labels):\r\n",
    "  print(i,idx2label[id])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Воспользуемся маской на изображении и посмотрим области, которые дают лучший прогноз."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 10))\r\n",
    "from skimage.segmentation import mark_boundaries\r\n",
    "for i, id in enumerate(explanation.top_labels[:2]):\r\n",
    "  temp, mask = explanation.get_image_and_mask(id, positive_only=False, num_features=5, hide_rest=False)\r\n",
    "  img_boundry = mark_boundaries(temp, mask)\r\n",
    "  ax[i].imshow(img_boundry)\r\n",
    "  ax[i].set_title(idx2label[id])\r\n",
    "  # количество кластеров, которые нужно показать на рисунке: num_features=5\r\n",
    "  # показать или нет отрицательно влияющие кластеры: positive_only=False \r\n",
    "  # cреди первых 5-ти отрицательных может не оказаться"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Зеленым цветом обозначена область наивысшего прогноза и оранжевым — области, которые меньше всего соответствуют нашему прогнозу. При `positive_only=False` будут показанны только границы."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "И другое изображение:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img2 = get_image('cat_and_dog2.png')\r\n",
    "plt.imshow(img2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Запуск Lime"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "explainer = lime_image.LimeImageExplainer()\r\n",
    "explanation = explainer.explain_instance(np.array(img2.resize((224,224))), \r\n",
    "                                         batch_predict, # classification function\r\n",
    "                                         top_labels=5, \r\n",
    "                                         hide_color=0, \r\n",
    "                                         num_samples=1000) # number of images that will be sent to classification function\r\n",
    "# Display top labels\r\n",
    "for i, id in enumerate(explanation.top_labels):\r\n",
    "  print(i,idx2label[id])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выведем сегменты наиболее повлиявшие на каждое предсказание"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(50, 10))\r\n",
    "from skimage.segmentation import mark_boundaries\r\n",
    "for i, id in enumerate(explanation.top_labels):\r\n",
    "  temp, mask = explanation.get_image_and_mask(id, positive_only=False, num_features=5, hide_rest=False)\r\n",
    "  img_boundry = mark_boundaries(temp, mask)\r\n",
    "  ax[i].imshow(img_boundry)\r\n",
    "  ax[i].set_title(idx2label[id])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В то время как большинство методов, описанных в первом сообщении блога, являются глобальными методами, LIME — это метод, имеющий локальную область применения.\n",
    "\n",
    "Таким образом, LIME позволяет нам объяснить конкретные прогнозы любого классификатора.\n",
    "\n",
    "Структура LIME является гибкой в ​​том смысле, что любую интерпретируемую модель можно использовать для объяснения прогнозов.\n",
    "\n",
    "Кроме того, концепция интерпретируемых компонентов позволяет применять LIME для обьяснения данных большой размерности, таких как классификация изображений или текста."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### $\\color{brown}{\\text{Допольнительная информация}}$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Shap.PartitionExplainer  \n",
    "\n",
    "В Shap есть класс аналогичный LimeImageExplainer: \n",
    "\n",
    "\n",
    "[[shap] PartitionExplainer](https://shap-lrjball.readthedocs.io/en/latest/generated/shap.PartitionExplainer.html)\n",
    "\n",
    "Однако его запуск с Pytorch моделями приводит к ошибке:\n",
    "\n",
    "[[git] AssertionError when only explaining one image](https://github.com/slundberg/shap/issues/1969)\n",
    "\n",
    "\n",
    "которая не была устраненна на момент составления блокнота. Код которым он должен запу"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install shap"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import shap\r\n",
    "\r\n",
    "# define a masker that is used to mask out partitions of the input image. \r\n",
    "masker = shap.maskers.Image(\"inpaint_telea\", (224,224,3))\r\n",
    "\r\n",
    "# create an explainer with model and image masker \r\n",
    "explainer = shap.Explainer(batch_predict, masker, output_names=list(cls2label.values())) \r\n",
    "\r\n",
    "\r\n",
    "# Here we explain one images using 5 evaluations of the underlying model to estimate the SHAP values\r\n",
    "explanation = explainer([np.array(img.resize((224,224)))], max_evals=5, batch_size=2, outputs=shap.Explanation.argsort.flip[:1])#, outputs=shap.Explanation.argsort.flip[:2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Код вниже ызывает exception \"Labels must have same row count as shap_values arrays!\"\n",
    "\n",
    "[[git] AssertionError when only explaining one image](https://github.com/slundberg/shap/issues/1969)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shap.image_plot(explanation)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Ascent\n",
    "\n",
    "Имея информацию о структуре модели, можно использовать градиент что бы понять как входы связанны с выходом.\n",
    "\n",
    "\n",
    "Вместо того что бы случайным образом закрашивать части изображения и много раз запускать модель, мы можем один раз посчитать градиент по входному изображению, и понять какие пикселы оказали наибольшее влияние на предсказание модели."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L06_CNN/img/L06-17.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Воспользуемся изображением из предидущего примера"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_t.requires_grad = True # Tell pytorch to compute grads w.r.t. inputs too\r\n",
    "logits = model(img_t.to(device)) # [1,1000] batch of one element, 1000 class scores\r\n",
    "top_score, top_idx = logits[0].topk(1) # Get id of class with best score\r\n",
    "id = top_idx[0].item()\r\n",
    "print(id, idx2label[id]) # Print the label this class \r\n",
    "score = logits[0][id] # Model output for paticular class\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для выхода модели соответствующему нашему классу рассчитываем градиент."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Compute gradients\r\n",
    "\r\n",
    "score.backward(retain_graph=True) \r\n",
    "\r\n",
    "# retain_grad = True is not nessesary\r\n",
    "# But if we run this code second time, we got a torch error without it\r\n",
    "# because pytorch want to accumulate gradients explicitly \r\n",
    "\r\n",
    "print(img_t.grad.shape)\r\n",
    "print(img_t.grad[0,:3,:3]) # Show some parts d_Image/d_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "У входного тензора (изображения) появился градиент который указывает на то как каждый элемент повлиял на выход модели. Отобразим этот градиент."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from matplotlib.pyplot import imshow\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\r\n",
    "\r\n",
    "# Helper method to display grad\r\n",
    "def grad_to_image(raw_grads):\r\n",
    "    grad_of_first_batch_element = raw_grads[0]\r\n",
    "    # Summ grads of RGB channes\r\n",
    "    smap = torch.sum(grad_of_first_batch_element, dim=0) \r\n",
    "    # Translate raw grad values to byte [0 .. 255] for displaying\r\n",
    "    max_val = smap.max()\r\n",
    "    img = (smap / max_val) * 255\r\n",
    "    # Filter using threshold to make image sharp\r\n",
    "    img[img < 0] = 0 \r\n",
    "    img[img > 50] = 255\r\n",
    "    return img.numpy().astype(int)\r\n",
    "\r\n",
    "sailency_map = grad_to_image(img_t.grad)\r\n",
    "\r\n",
    "plt.subplot(1, 2, 1)\r\n",
    "imshow(img )\r\n",
    "plt.subplot(1, 2, 2)\r\n",
    "imshow(sailency_map)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### $\\color{brown}{\\text{Допольнительная информация}}$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Adversarial attacks\n",
    "\n",
    "Принцип взятия градиента по входу используется при состязательных атаках (adversarial attacks).\n",
    "\n",
    "Если не просто визуализировать градиент, а с его помощью менять изображение, то можно обмануть сеть и заставить ее неверно классифицировать картинку незначительно поменяв ее."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L10_Explainability/img/gan/adv_attack.jpg\" width=\"700\">\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Подробнее:\n",
    "[[wiki] Adversarial machine learning](https://en.wikipedia.org/wiki/Adversarial_machine_learning)\n",
    "\n",
    "[The Intuition behind Adversarial Attacks on Neural Networks](https://blog.mlreview.com/the-intuition-behind-adversarial-attacks-on-neural-networks-71fdd427a33b)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пиксели получившие большой градиент находится именно в том месте где изображенна собака - это хорошо. \n",
    "\n",
    "При этом есть группы пикселей вверху изображения которые тоже подсвеченны, но относятся к фону  - это плохо. Значит модель может ошибаться из-за такого рода фона.\n",
    "\n",
    "\n",
    "На этом принципе посторен модуль [shap.DeepExplainer](https://shap-lrjball.readthedocs.io/en/latest/generated/shap.DeepExplainer.html).\n",
    "\n",
    "Он уже не зависим от модели(not Model agnostic) так как использует градиенты, зато позволяет оценить связи более точно.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SHAP Deep Explainer\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "DeepExplainer релизует алгоритм [DeepLift](https://arxiv.org/abs/1704.02685) который базируется на идее GradientAscending но не ограничивается ей. Алгоритм использует надобор произвольных изображений из датасета.  \n",
    "\n",
    "Для сетей обученных на ImageNet авторы предлагают имспользовать `shap.datasets.magenet50` :\n",
    "\n",
    "`The point is to have a random sample of ImageNet for use as a background distribution for explaining models trained on ImageNet data.`\n",
    "\n",
    "что мы и сделаем.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_t = get_input_tensors(img)\r\n",
    "model.eval()\r\n",
    "logits = model(img_t)\r\n",
    "\r\n",
    "probs = F.softmax(logits, dim=1)\r\n",
    "probs5 = probs.topk(5)\r\n",
    "plt.imshow(img)\r\n",
    "tuple((p,c, idx2label[c]) for p, c in zip(probs5[0][0].detach().numpy(), probs5[1][0].detach().numpy()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install shap"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В SHAP есть встроенный фрагмент датасета ImageNet (50 изображений) воспользуемся им.\n",
    "\n",
    "Метки не корректны:\n",
    "[[code] API Reference](https://shap-lrjball.readthedocs.io/en/latest/api.html?highlight=datasets.imagenet50#shap.datasets.imagenet50)\n",
    "\n",
    "поэтому проигнорируем их"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import shap\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import json\r\n",
    "\r\n",
    "imagenet_50, broken_targets = shap.datasets.imagenet50()\r\n",
    "\r\n",
    "print(\"Data shape\", imagenet_50.shape,type(X))\r\n",
    "# Show first image\r\n",
    "plt.imshow(imagenet_50[0].astype('int')) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Можно взглянуть и на остальные картинки"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=10, figsize=(25, 10))\r\n",
    "for i,img in enumerate(X):\r\n",
    "  row = i // 5\r\n",
    "  col = i % 5\r\n",
    "  ax[col,row].imshow(img.astype('int'))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for performance reason use as background only 10 images in PyTroch format\r\n",
    "background = torch.tensor(imagenet_50[0:10]).permute(0,3,1,2).to(device)/255 \r\n",
    "\r\n",
    "# https://shap-lrjball.readthedocs.io/en/latest/generated/shap.DeepExplainer.html\r\n",
    "explainer = shap.DeepExplainer(model.to(device), background)\r\n",
    "shap_values = explainer.shap_values(img_t) # List"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "По умолчанию возвращаются shap индексы для каждого класса, для каждого пикселя "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Classes\", len(shap_values)) \r\n",
    "print(\"Valuse\",shap_values[0].shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для отображения результатов используем метод [shap.image_plot](https://shap-lrjball.readthedocs.io/en/latest/generated/shap.image_plot.html?highlight=image_plot)\n",
    "\n",
    "его API ждет данные в виде списков numpy - массивов, поэтому нам потребуется преобразовать данные.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "# Get indexes of top5 classes predicted by model\r\n",
    "top5_indexes = probs5.indices.squeeze(0).numpy().astype('int')\r\n",
    "\r\n",
    "# Get shap vlues for this classes\r\n",
    "shap_values_for_top_results = np.array(shap_values)[top5_indexes]\r\n",
    "\r\n",
    "# Move color channels back for numpy compability (...,3,224,224 ) - > (...,224,224,3)\r\n",
    "shap_values_for_top_results = np.swapaxes(shap_values_for_top_results, 4, 2)  # swapaxes is do the same thing as torch.permute\r\n",
    "\r\n",
    "# Convert first dim of numpy.aray back to pythol list as required sahp.image_plot api\r\n",
    "shap_values_for_top_results = list(shap_values_for_top_results[:])\r\n",
    "\r\n",
    "# Prepare test image\r\n",
    "test_image = np.array(img.resize((224,224))) # resize to size of shap values\r\n",
    "test_image = test_image[np.newaxis, ...]/255\r\n",
    "\r\n",
    "\r\n",
    "# Get lagels for top5 classes\r\n",
    "\r\n",
    "shap_labels = np.array(idx2label)[top5_indexes]\r\n",
    "shap_labels = [list(shap_labels)] # One list for sample\r\n",
    "\r\n",
    "print(\"Len of shap_values list\",len(shap_values_for_top_results)) # number of classes to explain\r\n",
    "print(\"Shape of one value\",shap_values_for_top_results[0].shape) # n_samples, H,W,C\r\n",
    "print(shap_labels) # n_samples, number of classes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь визуализируем результаты:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shap.image_plot(shap_values_for_top_results, test_image,labels = shap_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "На практике чаще всего интересны объяснения только для нескольких классов с максимальной уверенностью.\n",
    "\n",
    "И в документации описан параметр который позволяет возвращать объяснения только для этих классов.\n",
    "\n",
    "[[doc] shap.DeepExplaine](https://shap-lrjball.readthedocs.io/en/latest/generated/shap.DeepExplainer.html)\n",
    "\n",
    "`ranked_outputs = 5, output_rank_order ='max'`\n",
    "\n",
    "При этом возвращается кортеж:\n",
    "shap_values и индексы классов для которых получено объяснение.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shape_values_for_best_pred , indexes = explainer.shap_values(img_t,ranked_outputs = 5, output_rank_order ='max') # List"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Результаты снова надо преобразовать их Pytorch формата"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert shap val frop PyTorch format\r\n",
    "shape_values_for_best_pred = np.swapaxes(np.array(shape_values_for_best_pred), 4, 2)\r\n",
    "shape_values_for_best_pred = list(shape_values_for_best_pred[:])\r\n",
    "\r\n",
    "# Get names for returned indexes\r\n",
    "shap_labels = np.array(idx2label)[indexes.cpu()[0]]\r\n",
    "shap_labels = [list(shap_labels)] # One list for sample\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Визуализируем результат"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "shap.image_plot(shape_values_for_best_pred , test_image, labels = shap_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Список литературы"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Статьи\n",
    "\n",
    "[How to Interpret Machine Learning Models with SHAP](https://www.youtube.com/watch?v=ylytZegK--I)\n",
    "\n",
    "[Бесплатный курс от Kaggle: Machine Learning Explainability](https://www.kaggle.com/learn/machine-learning-explainability)\n",
    "\n",
    "[EXPLAINABLE AI IN CREDIT RISK MANAGEMENT](https://arxiv.org/pdf/2103.00949v1.pdf)\n",
    "\n",
    "[Predicting Driver Fatigue in Automated Driving with Explainability](https://arxiv.org/pdf/2103.02162v1.pdf)\n",
    "\n",
    "[Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods](https://arxiv.org/pdf/1911.02508v2.pdf)\n",
    "\n",
    "[Interpretable Machine Learning]\n",
    "(https://christophm.github.io/interpretable-ml-book/intro.html)\n",
    "\n",
    "### SHAP\n",
    "[Welcome to the SHAP documentation](https://shap.readthedocs.io/en/stable/index.html)\n",
    "\n",
    "[Git](https://github.com/slundberg/shap)\n",
    "\n",
    "[A Unified Approach to Interpreting Model Predictions](https://arxiv.org/pdf/1705.07874v2.pdf)\n",
    "\n",
    "[SHAP (SHapley Additive exPlanations)](https://christophm.github.io/interpretable-ml-book/shap.html)\n",
    "\n",
    "### LIME\n",
    "\n",
    "[“Why Should I Trust You?” Explaining the Predictions of Any Classifier](https://arxiv.org/pdf/1602.04938.pdf)\n",
    "\n",
    "[What does LIME really see in images?](https://arxiv.org/pdf/2102.06307v1.pdf)\n",
    "\n",
    "[Git](https://github.com/marcotcr/lime)\n",
    "\n",
    "### BORUTA\n",
    "[Feature Selection with the Boruta Package](https://www.jstatsoft.org/index.php/jss/article/view/v036i11/v36i11.pdf)\n",
    "\n",
    "[Boruta Explained Exactly How You Wished Someone Explained to You](https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Заключение:\n",
    "---\n",
    "* В ходе урока мы убедились в важнности интерпретации работы моделей Искусственного Интеллекта.\n",
    "* Рассмотрели основные библиотеки, которые используются для интерпретирования: SHAP и LIME. А также библиотеку BORUTA, которая позволяет проводить анализ влияния признаков датасета на качество обучения. И дает рекомендации по исключению тех, которые влияют на результата отрицательно.\n",
    "* Рассмотрели применение бибилиотек на примерах:\n",
    "    - Табличные данные\n",
    "    - NLP (машинный перевод текста, создание резюме статьи и классификации текстов)\n",
    "    - CV\n",
    "\n",
    "Пренебрежение обьяснением того, почему модель дала тот или иной результат, ведет к недоверию не только к самой модели, но и к конкретным прогнозам. А, следовательно, является существенным препятствием для дальнейшего введения Вашей идеи в production.\n",
    "\n",
    "\n",
    "### Помните об этом!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 1
}
