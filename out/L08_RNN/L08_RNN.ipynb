{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "L08_RNN.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUjdn9w559n1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5uaWgqR59n8"
      },
      "source": [
        "##  Особенности\n",
        "\n",
        "Если стандартные методы машинного обучения работают с так называемыми структурированными типами данных, с объектами, у которых фиксировано признаковое описание, которые подаются на вход моделям, то рекуррентные нейронные сети используются с неструктурированными данными. Например, в распознавании речи, генерации музыки, машинном переводе. Данные в таких задачах представляют собой текст без предобработки, звуковой ряд и другие данные, не имеющие признаковых описаний. Давайте обсудим, каков принцип работы нейронной сети, и как именно таким нейронным сетям удается работать с неструктурированными данными.\n",
        "\n",
        "Мы имеем возможность сохранять информацию, сформированную при обработке одного слова, и использовать ее, когда мы анализируем дальнейшие слова. Видно, что при рассмотрении каждого слова происходят одни и те же процедуры. Нейронная сеть получает очередное слово, учитывает предыдущую активацию, формирует ответ. Это действие, происходящее в рамках одной ячейки нейронной сети. Так как вся сеть представляет собой объединение однотипных ячеек, то нейронная сеть называется рекуррентной. Рекуррентные нейронные сети не ограничиваются случаем, когда мы каждому входу нейронной сети должны сопоставить некоторый ответ, после чего анализировать следующий вход."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qh05-Lj68rI"
      },
      "source": [
        "## Задачи\n",
        "\n",
        "**Анализ временных рядов**\n",
        "- Статистические данные\n",
        "- Аннотирование изображений и видео (Image/Video captioning)\n",
        "- Машинный перевод\n",
        "- Распознавание текста\n",
        "- Распознавание речи\n",
        "\n",
        "**Генеративные модели**\n",
        "- Генерация текста/речи (чат - боты)\n",
        "- Генерация изображений\n",
        "\n",
        "**Классификация**\n",
        "- Изображения\n",
        "- Блоки текста (Sentiment analysis)\n",
        "\n",
        "Большинство этих задачь подрузамевают наличие контекста ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHnc-cB959n-"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-011.png\" width=\"700\">\n",
        "\n",
        "Существует множество типов рекуррентных нейронных сетей. Простейший случай рекуррентной сети — «one to one», когда у нас есть всего один вход и один выход нейронной сети. Более сложной является реализация «one to many», когда у нас есть всего один вход и нам необходимо сформировать несколько выходов. Такой тип нейронной сети актуален, когда мы говорим о генерации музыки или текстов. Мы задаем начальное слово или начальный звук, а дальше модель начинает самостоятельно генерировать выходы, в качестве входа к очередной ячейке рассматривая выход с прошлой ячейки нейронной сети. Если мы рассматриваем задачу классификации, то актуальна схема «many to one». Мы должны проанализировать все входы нейронной сети и только в конце определиться с классом. Схему «many to many», когда количество выходов равно количеству входов нейронной сети, мы рассмотрели на примере с определением части речи. Такой вид используется также в задачах NER, которые мы обсудим в следующем видео. Ну и последней разновидностью нейронных сетей является сеть вида «many to many», когда количество выходов нейронной сети не равно количеству входов. Это актуально, к примеру, в машинном переводе, когда одна и та же фраза может иметь разное количество слов в разных языках (т.е. это реализует схему энкодер-декодер). Энкодер получает данные различной длины — например, предложение на английском языке. С помощью скрытых состояний он формирует из исходных данных вектор, который затем передаётся в декодер. Последний, в свою очередь, генерирует из полученного вектора выходные данные — исходную фразу, переведённую на другой язык."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5BFCtTX-DlK"
      },
      "source": [
        "## Базовый RNN блок"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYb68Asu59oC"
      },
      "source": [
        "Попробуем подробнее разобраться, что же происходит в загадочном зелёном прямоугольнике с надписью RNN. Внутри него мы вычисляем рекуррентное соотношение с помощью функции f, которая зависит от весов w. Чтобы найти новое состояние ht, мы берём предыдущее скрытое состояние $ h_{t-1} $, а также текущий ввод xt. Когда мы отправляем в модель следующие входные данные, полученное нами скрытое состояние $ h_t $ передаётся в эту же функцию, и весь процесс повторяется.\n",
        "\n",
        "Чтобы генерировать вывод в каждый момент времени, в модель добавляются полносвязные слои, которые постоянно обрабатывают состояния $ h_t $ и выдают основанные на них прогнозы. При этом функция f и веса w остаются неизменными.\n",
        "\n",
        "Самая простая реализация рекуррентной сети будет выглядеть следующим образом (Тангенс здесь используется для введения нелинейности в систему):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0GQ61EU59oD"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-017.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFZYpkzIa1Su"
      },
      "source": [
        "#### Наивная реализация базового RNN блока"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efP5fBTU-Zzg"
      },
      "source": [
        "import torch\n",
        "# Simple RNN without a bias\n",
        "# https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
        "class SimpleRNN: \n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    # hidden_size ~ number of neurons\n",
        "    self.W_xh = torch.randn((input_size,hidden_size))*0.001\n",
        "    self.W_hh = torch.randn((hidden_size, hidden_size)) * 0.001\n",
        "    \n",
        "    #self.W_hy = torch.randn((100,256))*0.001\n",
        "    self.h = torch.zeros(hidden_size,1)\n",
        "  \n",
        "  def step(self,x):\n",
        "    # update the hidden state\n",
        "    #https://pytorch.org/docs/stable/generated/torch.mm.html\n",
        "    tmp1 = torch.mm(self.h,self.W_hh)\n",
        "    print(x.shape)\n",
        "    tmp2 =  torch.mm(x.unsqueeze(0),self.W_xh)  # ~= np.dot [4x1] * [4x1]\n",
        "    print(tmp1.shape,tmp2.shape)\n",
        "    self.h = torch.tanh(tmp1+tmp2)\n",
        "    #self.h = torch.tanh(self.W_hh.matmul(self.h) + self.W_xh.matmul(x))\n",
        "    print(self.h.shape)\n",
        "    # compute the output vector\n",
        "    #y = self.W_hy.matmul(self.h)\n",
        "    return self.h\n",
        "\n",
        "simple_rnn = SimpleRNN(input_size = 4, hidden_size = 2)\n",
        "#dummy_input = torch.randn((4))\n",
        "#X0_batch = torch.tensor([[0,1,2,0], [3,4,5,0]],\n",
        "\n",
        "out = simple_rnn.step(torch.tensor([0,1,2,0],dtype = torch.float))\n",
        "print(out,out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndIE9O_c59oH"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-023.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5N0mu_SKQIp"
      },
      "source": [
        "https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibrnPohqa_C2"
      },
      "source": [
        "#### RNN блок в Pytorch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a69ZYyFm59ob"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add1.png\" width=\"700\">\n",
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add2.png\" width=\"700\">\n",
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add3.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz2S95LW59ob"
      },
      "source": [
        "import torch\n",
        "\n",
        "input_size = 10\n",
        "hidden_size = 2\n",
        "model = torch.nn.RNN(input_size = 4, hidden_size = hidden_size )\n",
        "\n",
        "# (seq_len, batches, input)\n",
        "\n",
        "input = torch.randn((1, 1, 4))\n",
        "\n",
        "all_seq, last_h = model(input)\n",
        "print(all_seq.shape)\n",
        "print(last_h.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kNJOMGY59od"
      },
      "source": [
        "Давайте добавим выходные веса. Для этого придется программировать"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDIRNLms59od"
      },
      "source": [
        "# Let's add output weights\n",
        "\n",
        "class RNN_for_many_to_one(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden, output_size):\n",
        "        super().__init__()\n",
        "        self.rnn = torch.nn.RNN(input_size, hidden)\n",
        "        self.fc1 = torch.nn.Linear(hidden, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x, hidden = self.rnn(x)\n",
        "        \n",
        "        # we need only last output\n",
        "        return self.fc1(x[-1])\n",
        "\n",
        "    \n",
        "model2 = RNN_for_many_to_one(input_size, 20, 50)\n",
        "res = model2(input)\n",
        "# 30 - batch, 50 - output_size\n",
        "print(res.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxXw4l47_fkA"
      },
      "source": [
        "##Обратное распространение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgYzq8wyBopK"
      },
      "source": [
        "### Пакеты\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukDHDbQY59oK"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-046.png\" width=\"700\">\n",
        "\n",
        "Поэтому снова возникает потребность в обработке по батчам."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyhGiMB_59oL"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-047.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsExayEz59oL"
      },
      "source": [
        "Скрытые состояния при этом сохраняются."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVgLEpJa59oo"
      },
      "source": [
        "* Rnn обеспечивает большую гибкость в архитектурном проектировании\n",
        "* Vanilla RNN намного проще, однако работают не очень хорошо\n",
        "* LSTM или GRU: аддитивное взаимодействие улучшает градиентный поток\n",
        "* Обратный поток градиентов в RNN делает explode или vanish\n",
        "\n",
        "explode управляется с помощью градиентного отсечения\n",
        "\n",
        "vanish - это контролируемые аддитивные взаимодействия (LSTM)\n",
        "\n",
        "* Лучшие/более простые архитектуры являются актуальной темой текущих исследований\n",
        "* Необходимо лучшее понимание (как теоретическое, так и эмпирическое)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMIvXTNz59of"
      },
      "source": [
        "## Обработка временных рядов\n",
        "---\n",
        "- [A Gentle Introduction to Handling a Non-Stationary Time Series in Python](https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/)\n",
        "- [A comprehensive beginner’s guide to create a Time Series Forecast](https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/)\n",
        "- [Detecting stationarity in time series data](https://towardsdatascience.com/detecting-stationarity-in-time-series-data-d29e0a21e638)\n",
        "- [Most useful Python functions for Time Series Analysis](https://towardsdatascience.com/most-useful-python-functions-for-time-series-analysis-ed1a9cb3aa8b)\n",
        "- [Data transformations and forecasting models: what to use and whenData transformations and forecasting models: what to use and when](https://people.duke.edu/~rnau/whatuse.htmhttps://people.duke.edu/~rnau/whatuse.htm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbl3t16p59of"
      },
      "source": [
        "Что общего у прогнозирования потребления электроэнергии домохозяйствами, оценки трафика на дорогах в определенные периоды, прогнозировании паводков и прогнозировании цены, по которой акции будут торговаться на фондовой бирже?\n",
        "\n",
        "Все они подпадают под понятие данных временных рядов! Вы не можете точно предсказать любой из этих результатов без компонента «время». И по мере того, как в мире вокруг нас генерируется все больше и больше данных, прогнозирование временных рядов становится все более важной областью применения методов ML и DL.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Lz3ZtNd59og"
      },
      "source": [
        "## Сделаем предикт с помощью Deep Learning (PyTorch LSTM)\n",
        "----\n",
        "[Time Series Prediction with LSTM Using PyTorchTime Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n",
        "\n",
        "- Dataloading\n",
        "- Скалирование\n",
        "- Формирование ансамблей данных \n",
        "- LSTM Mode\n",
        "- Traning\n",
        "- Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y7DJe3ac-In"
      },
      "source": [
        "### Загрузка данных\n",
        "\n",
        "Air Passengers per month. \n",
        "https://www.kaggle.com/rakannimer/air-passengers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVkY1FwndGZ4"
      },
      "source": [
        "# Dataloading\n",
        "import pandas as pd\n",
        "\n",
        "!if test -f ./airline-passengers.csv; then echo \"Already downloaded\"; else wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv; fi\n",
        "\n",
        "dataset = pd.read_csv('airline-passengers.csv')\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnDdggLdexBU"
      },
      "source": [
        "training_data = dataset.iloc[:,1:2].values # перевели dataframe в numpy.array\n",
        "# plotting\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(training_set, label = 'Airline Passangers Data')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_skdvumfAxP"
      },
      "source": [
        "### Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQyTvaeUfRHq"
      },
      "source": [
        "# Min - Max normalization\n",
        "td_min = training_data.min()\n",
        "td_max = training_data.max()\n",
        "training_data -= td_min\n",
        "training_data = training_data / td_max\n",
        "print(training_data[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha6Nfaxc59oi"
      },
      "source": [
        "### Формирование ансамблей данных\n",
        "\n",
        "Поскольку мы хотим научиться предсказывать следующие значение на основе предидущих нам нужно подготовить данные соответствующим образом.\n",
        "\n",
        "Разобьем весь массив данных на фрагменты вида\n",
        "\n",
        "x -> y\n",
        "\n",
        "где х - это подпоследовательность, например строки с 1-й по 8ю, а y - это значение из 9-й строки, то самое которое мы хотим предсказать\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrhmfmgc59oj"
      },
      "source": [
        "# функция создания \"ансамблей\" данных\n",
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)] # seq_len * elements\n",
        "        _y = data[i+seq_length] # one element\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYCagBZv59oj"
      },
      "source": [
        "# установка длины ансамбля. от нее практически всегда зависит точность предикта и быстродействие\n",
        "seq_length = 8 # сравните 2 и 32\n",
        "x, y = sliding_windows(training_data, seq_length)\n",
        "x[0], y[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUPh4eMti5S1"
      },
      "source": [
        "Благодаря такому подходу мы можем работать с RNN моделью так же как работали со сверточными."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mprYZVYR59oj"
      },
      "source": [
        "Что мы сделали? Мы подали в нейронку ансамбль `ensemble` данных, в которых попросили ее найти зависимость y(t) от ансамбля данных y(t-1), ... y(t-seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyB4eoMajlrq"
      },
      "source": [
        "### Разобьем на train и test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "338EIQMJ59ok"
      },
      "source": [
        "train_size = int(len(y) * 0.8)\n",
        "test_size = len(y) - train_size\n",
        "\n",
        "dataX = torch.Tensor(np.array(x))\n",
        "dataY = torch.Tensor(np.array(y))\n",
        "\n",
        "trainX = torch.Tensor(np.array(x[0:train_size]))\n",
        "trainY = torch.Tensor(np.array(y[0:train_size]))\n",
        "\n",
        "testX = torch.Tensor(np.array(x[train_size:len(x)]))\n",
        "testY = torch.Tensor(np.array(y[train_size:len(y)]))\n",
        "\n",
        "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5y4gFxl59og"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT4nRe0x59ok"
      },
      "source": [
        "### Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT_IVh6r59ol"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AirTrafficPredictor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        out, h = self.rnn(x)\n",
        "        \n",
        "        print(out.shape) # 108 x 8 x 8\n",
        "        #out = out.contiguous().view(-1, self.rnn.hidden_size)\n",
        "        print(out.shape) \n",
        "        #print(h.shape) # 1 x 108 x 8\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofkSecNA59ol"
      },
      "source": [
        "### Traning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He8S8WcG59om"
      },
      "source": [
        "num_epochs = 2000\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 1\n",
        "# Сложность нейронки должна быть адекватна датасету !!!\n",
        "hidden_size = seq_length # а можно попробовать 400 - в чем разница?\n",
        "#num_layers = 1\n",
        "#num_classes = 1\n",
        "\n",
        "rnn = AirTrafficPredictor(input_size, hidden_size)\n",
        "\n",
        "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = rnn(trainX)\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # obtain the loss function\n",
        "    loss = criterion(outputs, trainY)\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwEYSCy659om"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz1nb1b559on"
      },
      "source": [
        "rnn.eval()\n",
        "train_predict = rnn(dataX)\n",
        "\n",
        "data_predict = train_predict.data.numpy()\n",
        "dataY_plot = dataY.data.numpy()\n",
        "print(dataY_plot.shape)\n",
        "\n",
        "print(data_predict.shape)\n",
        "print(td_max)\n",
        "data_predict = data_predict[0] *td_max + td_min\n",
        "dataY_plot = xScaler.inverse_transform(dataY_plot)\n",
        "print(data_predict[:15])\n",
        "\n",
        "# Ploitting\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.axvline(x=train_size, c='r', linestyle='--')\n",
        "\n",
        "plt.plot(dataY_plot)\n",
        "plt.plot(data_predict)\n",
        "plt.suptitle('Time-Series Prediction')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfG9GDwO59on"
      },
      "source": [
        "### Выводы:\n",
        "---\n",
        "1. Использование LSTM слоев при прогнозировании нестационарных временных рядов - отличное решение, тк нейронка способна самостоятельно выденить динамики изменениях составляющих временного ряда. Правда, в более сложных случаях (трейдинге, например, или чтении и расшивровки волн мозга) приходится прибегать к feature ingineering\n",
        "2. Сложость нейронной сети должна быть адекватна сложности подаваемых в нее данных. С ростом ансамбля и числа нейронов увеличивается заучивание тренировочной выборки и теряется способность к обощению\n",
        "3. Предварительный анализ цикличности в данных (если она есть) помогает понять оптимальный размер ансамбля (тут видно, что цикл в среднем составляет 8 интервалов)\n",
        "4. Также результат может зависеть от типа скалирования, который Вы применяете. Нужно знать принципы работы скаллеров и не стесняться экспериментировать с ними. См. статьи: [Data Preprocessing with Scikit-Learn: Standardization and Scaling](https://towardsdatascience.com/data-preprocessing-with-scikit-learn-standardization-and-scaling-cfb695280412) и [Gradient Descent, the Learning Rate, and the importance of Feature Scaling](https://towardsdatascience.com/gradient-descent-the-learning-rate-and-the-importance-of-feature-scaling-6c0b416596e1)\n",
        "5. При всей выгодности приненении нейронных сетей, необходимо быть осторожным с автокорреляцией (см статью [Avoiding the pitfalls](https://towardsdatascience.com/how-not-to-use-machine-learning-for-time-series-forecasting-avoiding-the-pitfalls-19f9d7adf424))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bliO8bXE59oo"
      },
      "source": [
        "## Подводя итоги\n",
        "\n",
        "* Rnn allows a lot of flexibility in architecture design\n",
        "* Vanilla RNNs are simple, but don't work very well\n",
        "* Common to use LSTM or GRU: additive interaction improve gradient flow\n",
        "* Backward flow of gradients in RNN are explode or vanish\n",
        "\n",
        "exploding is controlled with gradient clipping\n",
        "\n",
        "vanishing is controlled additive interactions (LSTM)\n",
        "\n",
        "* * Better/simpler architectures are hot topic of current research \n",
        "* Better understanding (both theoretical and empirical) is needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRZNReIybbXg"
      },
      "source": [
        "## Типы RNN архитектур"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_IaZjQmbbOA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQHoaLt559oH"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-026.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlgvu5y_59oI"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-028.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnjYN9ew59oI"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-030.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOnYVBCa59oJ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-045.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuFR9ZRy59oK"
      },
      "source": [
        "Теоритетески можно было бы сразу пропустить все данные через сеть и затем вычислить градиент.\n",
        "\n",
        "Но:\n",
        " - Большие последовательности не поместятся в памяти\n",
        " - Возникнут проблеммы исчезновения/взрыва градиента, так как цепочка будет очень длинной\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccHuwngi59oo"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhxqkk9-59oo"
      },
      "source": [
        "### Sequence-to-Sequence with RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-m81sAv59oo"
      },
      "source": [
        "* Сейчас мы пытаемся решить задачу sequence to sequence\n",
        "* Орабатывая входную последовательность, мы хотим обобщить всю информацию, которая в ней содержится в некий вектор С\n",
        "* Далее мы передаем этот вектор во вторую RNN, которая является декодером\n",
        "\n",
        "\n",
        "Мы используем вектор С для передачи информации между энкодером и декодером, также мы предполагаем, что вектор С обощает всю информацию, которая небходима декодеру для генерации выходных последовательности.\n",
        "\n",
        "Однако использование единственного вектора для предоставления информации может работать только для последовательностей малой длины (неразумно предполагать, что информация с длинной последовательностью можно сжать в один вектор) \n",
        "\n",
        "Именно поэтому нам нужен некий механизм, который будет обходить \"бутылочное горлышко\" и не сжимать всю информацию в один вектор С. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UniGfQyd59oo"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-011.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5DhWpu559op"
      },
      "source": [
        "### Sequence-to-Sequence with RNNs and Attention mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRkkR8SZ59op"
      },
      "source": [
        "Давайте позволим нашему декодеру, используя context vector, фокусироваться на определенных выходах энкодера. \n",
        "\n",
        "Для этого будем вычислять context vector и вводим некую фцию $F_{att}$ , котрая будет вычислять alignment score (функцию похожести) между внутренними состояниями декодера и энкодера.\n",
        "\n",
        "После этого, вычисленные alignment scores мы пропускаем через softmax для нормализации. Таким образом мы получаем веса, которые говорят о том, насколько сильно мы хотим сфокусироваться на соответствующим им выходам энкодера.\n",
        "\n",
        "Затем мы просто берем взевенную сумму внутренних состояний энкодера и передаем ее на вход декодеру. Данный алгоритм выполняем на каждом шаге декодера.\n",
        "\n",
        "Функция $F_{att}$ может являться небольшой нейросетью или неким линейным преобразованием. Однако это не так важно, идея заключается в том, что мы не говорим явно на чем функция должна сосредотачиваться в конкретной задаче. Применив к ней back propagation, ее веса сами настроятся на необходимые точки фокусировки.\n",
        "\n",
        "**То есть функция сама разберется на чем фокусироваться**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyG0KoFH59op"
      },
      "source": [
        "\n",
        "\n",
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-017.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpgIoECt59oq"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-020.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLY_hB_b59oq"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-021.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAcPBwcg59os"
      },
      "source": [
        "Давайте посмотрим как фокусировка работает на примере перевода с английского на французский \n",
        "\n",
        "Как мы знаем, на каждом шаге генерируется набор весов, которые отвечают за фокусировку на том или ином месте входной последовательности. Как мы видим, английское предложение имеет иной порядок слов относительно французского. Например, в английском варианте словосочетание **European Economic Area**, в то время как во французском **zone économique européenne**. \n",
        "\n",
        "В английском прилагательные идут перед существительным, в то время как во французском языке наоборот. \n",
        "\n",
        "Таким образом, благодаря гибкости модели, мы можем обрабатывать и учитывать разный порядок слов в разных языках."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw4t5HPd59ot"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-025.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmb-3wYS59ot"
      },
      "source": [
        "* Механизм внимания не обязательно должен принимать на вход последовательность. \n",
        "\n",
        "* Мы можем применять его, в том числе для генерации подписей для картинок. Входом в данном случае будет являться сетка признаков, которая была получена при применении сверточной сети к картинке. \n",
        "\n",
        "* Далее по этой сетке мы считаем веса внимания и делаем аналогично первому примеру."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLNqB-PI59ot"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-028.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sibhw8259ot"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-031.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xtknlAv59ou"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-036.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eFIraJd59ou"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-037.png\" width=\"700\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpIecJji59ou"
      },
      "source": [
        "### Image Captioning with RNNs and Attention\n",
        "\n",
        "Модели, основанные на внимании (attention) намного более продвинутые, нежели обычные нейросети. Они могут концентрироваться на отдельных частях изображения, что позволяет избежать зашумления данных.\n",
        "\n",
        "Идея состоит в том, что свёрточная сеть теперь будет генерировать не один вектор, описывающий всё изображение, а набор векторов для нескольких участков исходного снимка. В дополнение к работе со словарём на каждом временном шаге модель также производит распределение по точкам на изображении, которые она обрабатывает в данный момент. Это позволяет ей научиться находить наиболее важные участки, на которых необходимо фокусироваться.\n",
        "\n",
        "После обучения модели можно увидеть, что она как бы переносит своё внимание по изображению для каждого генерируемого слова."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JALrz2tO59ov"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-038.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aSmxI1R59ov"
      },
      "source": [
        "Существуют также понятия мягкого и жёсткого внимания (soft and hard attention). При мягком внимании мы берём взвешенную комбинацию признаков по всему изображению, тогда как в случае жёсткого внимания мы заставляем модель выбирать только один небольшой участок для обработки на каждом временном шаге. При этом жёсткое внимание, строго говоря, не является дифференцируемой функцией. Поэтому для обучения такой модели необходимо использовать более изощрённые приёмы, чем обычное обратное распространение ошибки.\n",
        "\n",
        "Также нейросети, основанные на внимании, повсеместно используются для ответов на визуальные вопросы (Visual Question Answering). Цель этой задачи — обучить модель отвечать на вопрос по изображению. Например, она должна уметь не только называть сами объекты на фотографии, но и считать их, распознавать цвета и оценивать расположение относительно друг друга. Мы уже рассказывали о подобных архитектурах в статье о том, как такие нейросети могут помочь незрячим людям и о нейро-символическом мышлении.\n",
        "\n",
        "ссылка https://www.reg.ru/blog/nejroset-opisyvaet-mir-nezryachim-lyudyam/ ссылка https://www.reg.ru/blog/uchim-nejroseti-rassuzhdat-o-tom-chto-oni-vidyat/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REy44gHf59ov"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-039.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWwY-sf759ov"
      },
      "source": [
        "### X, Attend, and Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXRjvSbC59ow"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-044.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcSCLFif59ow"
      },
      "source": [
        "### Attention Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlK7xfpv59ow"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-045.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2WJsTwl59ow"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-048.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJs3X1zz59ow"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-050.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lxnIjkH59ox"
      },
      "source": [
        "Давайте обобщим наш attention слой. \n",
        "\n",
        "* Во-первых, заменим фцию $F_{att}$ на скалярное произведение.\n",
        "\n",
        "* В предыдущем примере мы использовали только один вектор для поиска совпадений (query вектор), который являлся внутренним состоянием декодера. Давайте вместо этого дадим возможность нашей модели использовать сразу нессколько query-векторов. Благодаря этому мы будем получать несколько распределений весов на выходе (по 1 для каждого query-вектора).\n",
        "\n",
        "* Обратим внимание, что мы используем входной вектор Х дважды: при вычислении похожести с query-вектором и при вычислении конечного выходного взвешенного решения. Для большей гибкости давайте разделим их и будем отдельно вычислять key-вектора и отдельно value-вектора. key-вектора мы будем использовать для поиска схожести с value-векторами. А они в свою очередь, будут использоваться для вычисления конечного выходного взевешенного значения. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zfjsz6L59ox"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-056.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlBwWCRr59ox"
      },
      "source": [
        "### Self-Attention Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q_zsJ7D59ox"
      },
      "source": [
        "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
        "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
        "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
        "textual entailment and learning task-independent sentence representations\n",
        "\n",
        "Self-attention, также иногда называемый intra-attention - это механизм , связывающий различные позиции одной последовательности для вычисления представления последовательности. \n",
        "\n",
        "Self-attention успешно используется в различных задачах, включая понимание прочитанного (reading comprehension), абстрактное обобщение, текстовое влечение (entailment) и обучение независимым от задачи представлениям предложений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJYA2Wz059oy"
      },
      "source": [
        "Возникает вопрос, как это сделать наилучшим образом. \n",
        "\n",
        "Допустим, при обработке временных рядов используют некую сглаживающую функцию, например gaussian. \n",
        "\n",
        "Однако при обработке предложений очевидно, что неправильно считать рядом стоящие слова как наиболее близкие\n",
        "друг к другу по контексту."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYB9FYoa59oy"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_4-1.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fepb5WPM59oy"
      },
      "source": [
        "Основная идея заключается в том, что мы рассчитываем и query, и input, и key на основе input-векторов. \n",
        "\n",
        "Таким образом мы будем сравнивать каждый наш входной вектор со всеми остальными входными векторами входного множества. \n",
        "\n",
        "Для расчета query-векторов мы добавляем матрицу $W_Q$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNT1qOsq59oy"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-063.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heBX1DEU59oz"
      },
      "source": [
        "Свой self attention инвариантен относительно порядка входных последовательностей. \n",
        "\n",
        "Таким образом мы получили новый тип слоев нейронной сети, который **не** использует информацию о порядке входной последовательности и оперирует только на множестве входных векторов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO_ePNO059oz"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-070.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6z8UFvo59oz"
      },
      "source": [
        "Иногда нам хочется чтобы порядок учитывался, например при переводе и генерации описания картинок (caption). \n",
        "\n",
        "Для этого мы добавляем информацию на входы о порядке наших элементов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2OnmQSq59oz"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-072.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REQ_ja_J59o0"
      },
      "source": [
        "### Masked Self-Attention Layer - совместить"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GunDUprh59o0"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-073.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF7bz0_c59o0"
      },
      "source": [
        "#### Multihead Self-Attention Layer\n",
        "\n",
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_7-1.png\" width=\"700\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAC9-akL59o1"
      },
      "source": [
        "Давайте посмотрим на то, к каким словам предложения gave может иметь отношение. В общим случае глагол может иметь связку со многоми частями предложения. Как, например, к подлежащему, так и к причастиям.\n",
        "\n",
        "В идеале, нам бы хотелось обратить внимние функции (attention) на все эти взаимосвязи.\n",
        "\n",
        "**Для этого небходимо ввести несколько механизмов внимания, как это показано на картинке**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2VtCBK959o2"
      },
      "source": [
        " <img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_6-1.png\" width=\"700\"> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIAqIl6R59o2"
      },
      "source": [
        "* Чтобы осуществить задуманное, вместо одного набора query, будем использовать несколько независимых наборов. \n",
        "\n",
        "* Причем каждый набор будет считаться уникальной матрицей. \n",
        "\n",
        "* Аналогично сделаем для keys и values. Количество таких наборов внутри keys, queries, values должно быть **одинаковым**. \n",
        "\n",
        "* Обозначим это число как h - head, далее производим аналогичные манипуляции, при этом введем в параллель h таких функций attention\n",
        "* На последнем шаге мы их соединяем (конкатинируем)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzEfe51759o2"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-075.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viQtPZtX59o3"
      },
      "source": [
        "### Three Ways of Processing Sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKYLb7vj59o3"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_1_1.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeIz1iXL59o3"
      },
      "source": [
        "\n",
        "Модель attention позволяет обрабатывать последовательности параллельно в отличие от моделей основанных на RNN, это позволяет данную модель в большей мере использовать возможности использования параллельных вычислений на GPU \n",
        "\n",
        "RNN:\n",
        "**Преимущества** \n",
        "\n",
        "• Возможность обработки входных данных любой длины\n",
        "\n",
        "• Размер модели не увеличивается с размером входного сигнала\n",
        "\n",
        "• Расчет учитывает историческую информацию\n",
        "\n",
        "• Веса распределяются во времени \n",
        "\n",
        "**Недостатки**\n",
        "\n",
        "• Вычисление происходит медленно\n",
        "\n",
        "• Трудность доступа к информации, полученной давным-давно\n",
        "\n",
        "• Не может учитывать какие-либо будущие входные данные для текущего состояния"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EAMsm1Z59o4"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-084.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h_YGPDf59o4"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-085.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFc19_Hb59o4"
      },
      "source": [
        "### The Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPn2WdXC59o4"
      },
      "source": [
        "Раньше мы передавали информацию по из блока attention в RNN для ее последующего применения, однако в 2017 году вышла статья под названием Attention is all you need. В ней говорилось о том, что для обработки последовательностей можно ограничиться только блоком внимания. Данная модель получила название Transformer. \n",
        "\n",
        "По сути это базовый блок, который основывается только на self-attention при работе с входными векорами. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EC9uGpV59o4"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-092.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4d2AC7K59o5"
      },
      "source": [
        "Блок устроен следующим образом: входные вектора мы запускаем в блок self-attention и используем residual connection как обходной путь вокруг self-attention, затем мы их складываем. \n",
        "\n",
        "После - применяем слой нормализации, затем - слой feat forward сетей, плюс обходной путь вокруг feat forward. \n",
        "\n",
        "Складываем их и выполняем нормализацию. \n",
        "\n",
        "Это один блок-трансформер. \n",
        "\n",
        "В реальных моделях эти слои стекируют друг с другом и получается большая трансформер-модель. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU3V6_2m59o5"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-094.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZTw34C059o5"
      },
      "source": [
        "Although this achieves parallelization, it is still computationally expensive. The number of operations per layer incurred by RNNs and CNNs is way more unreasonable as compared to the quality of results they offer. The original Transformer paper has put forth a comparison of these parameters for the competent models:\n",
        "\n",
        "Хотя таким образом (свертками) достигается распараллеливание, однако это вычислительно дорого. Количество операций на слой, выполняемых RNN и CNN, гораздо более необоснованно по сравнению с качеством результатов, которые они предлагают.\n",
        "\n",
        "В одной из статей про Трансформеры было предложено сравнение этих параметров для компетентных моделей:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqo6qPKt59o5"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/L08_trans.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3dIUoFn59o5"
      },
      "source": [
        "Here, d (or d_model) is the representation dimension or embedding dimension of a word (usually in the range 128–512), n is the sequence length (usually in the range 40–70), k is the kernel size of the convolution and r is the attention window-size for restricted self-attention. From the table, we can infer the following:\n",
        "\n",
        "* Clearly, the per-layer computational complexity of self-attention is way less than that of others.\n",
        "* With respect to sequential operations, except RNNs, all other approaches offer parallelization, hence their complexity is O(1).\n",
        "* The final metric is maximum path length, which superficially means the complexity for attending long-term dependencies or distant words. Since convolutional models use hierarchical representations, their complexity is nlog(n), while self-attention models attend all the words at the same step, hence their complexity is O(1).\n",
        "\n",
        "\n",
        "The Transformer uses the self-attention mechanism where attention weights are calculated using all the words in the input sequence at once, hence it facilitates parallelization. In addition to that, since the per-layer operations in the Transformer are among words of the same sequence, the complexity does not exceed O(n²d). Hence, the transformer proves to be effective (since it uses attention) and at the same time, a computationally efficient model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lZyd0eG59o5"
      },
      "source": [
        "Здесь d (или *d_model*) - размер выборки или embedding вложения слова (обычно в диапазоне 128-512), n-длина последовательности (обычно в диапазоне 40-70), k-размер ядра свертки, а r-размер окна внимания для ограниченного self-attention. Из таблицы мы можем сделать следующие выводы:\n",
        "\n",
        "* Очевидно, что вычислительная сложность каждого слоя self-attention намного меньше, чем у других.\n",
        "* Что касается последовательных операций, то, за исключением RNN, все другие подходы предлагают параллельность действий, поэтому их сложность составляет O(1).\n",
        "* Конечная метрика - максимальная длина пути, которая поверхностно означает сложность для посещения долгосрочных зависимостей или отдаленных слов. Поскольку сверточные модели используют иерархические представления, их сложность равна nlog(n), в то время как модели самосознания посещают все слова на одном и том же шаге, следовательно, их сложность равна O(1).\n",
        "\n",
        "\n",
        "Трансформер использует механизм само-внимания, где веса внимания вычисляются с использованием всех слов во входной последовательности сразу, следовательно, это облегчает распараллеливание. Кроме того, поскольку операции на каждом слое в трансформерах относятся к словам одной и той же последовательности, сложность не превышает O($n^2d$). Следовательно, трансформер оказывается эффективной (поскольку она использует attention) и в то же время вычислительно качественной моделью."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwB7bdWU59o6"
      },
      "source": [
        "статья: https://towardsdatascience.com/transformers-explained-65454c0f3fa7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR0xMl5059o6"
      },
      "source": [
        "### The Transformer: Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RboS0TmY59o6"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-095.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BosmoQ659o6"
      },
      "source": [
        "В 2020 практически все успехи машинного обучения были связаны с применением трансформеров. На сегодняшний день - это самая передовая модель для обработки последовательностей. \n",
        "\n",
        "Стоит отметить, что модели трансформеров имеют огромное кличество параметров, как следствие - требуются большие вычислительные мощности для их обучения. В связи с этим, обучение данных моделей с нуля, преимущественно доступны только развитым государствам и крупным компаниям. \n",
        "\n",
        "Большая часть предприятий может расчитывать только на дообучене этих моделей для своих задач, что все равно показывает хорошие результаты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpLNXC5d59o6"
      },
      "source": [
        "### The Transformer: Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovXsjPT059o7"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-100.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkrPQkVp59o7"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-104.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj1I0Tw359o7"
      },
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmZ3lokD59o8"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-105.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h36-uz26f-2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQG42Lo__-ir"
      },
      "source": [
        "## Посимвольная генерация текстов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo3dp1No59oJ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-037.gif\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVimIAxn59oM"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-050.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXVtreJf59oM"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-054.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiNFe9iU59oN"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-055.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up7JNs5k59oO"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-058.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OytMng1j59oO"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-059.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PugAiQp59oP"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-061.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbUYi24c59oP"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-063.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr0fyK1EAJQU"
      },
      "source": [
        "### Explaination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E_aXSMz59oP"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-064.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W3YSrKW59oQ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-065.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS2ggUPi59oQ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-066.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNYnYTA859oQ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-067.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jno-Vn6E59oQ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-068.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yS5OYvg59oQ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-069.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V6riLqE59oQ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-059.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Q9aGnz59oQ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-061.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nnYGHkn59oR"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-063.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoLFrsjT59oR"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-064.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m49ZLKus59oR"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-065.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfyZSlXE59oS"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-066.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n9O14Ir59oS"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-067.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpBpcC5n59oS"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-068.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XM5n1xR59oT"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-069.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eU8X0gE_PU9"
      },
      "source": [
        "## Image Captioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KV0EPcP59oT"
      },
      "source": [
        "\n",
        "\n",
        "Суть этой задачи заключается в том, чтобы нейросеть составила текстовое описание фотографии. Для этого необходимо сначала классифицировать объекты на изображении, а затем передать результат (одну или несколько меток) в языковую рекуррентную модель, которая сможет составить из них осмысленную фразу. При этом мы действуем точно так же, как в случае с обычной языковой моделью: преобразуем метку изображения в вектор, который обрабатывается декодером.\n",
        "\n",
        "Чтобы рекуррентная сеть понимала, где именно начинается предложение, во время обучения на её вход подаётся стартовый опознавательный знак ( token $ <start>$ ). Для построения фразы используется заранее подготовленный словарь, например, из английских слов — и он может быть довольно большим.\n",
        "\n",
        "При переходе на каждое следующее скрытое состояние мы сохраняем как уже сгенерированные слова, так и информацию об изображении. В конце предложения в нейросеть отправляется финальный токен ( $ <end> $). Во время тестирования модель уже самостоятельно определяет, где должно начинаться и заканчиваться описание изображения.\n",
        "\n",
        "Обычно подобные архитектуры создаются с помощью контролируемого обучения (supervized learning) — это означает, что в обучающих датасетах уже присутствуют как изображения, так и описания для них. Наиболее популярным и самым большим набором данных является Microsoft COCO. Помимо image captioning он также применяется для сегментации, поиска ключевых точек и даже построения трёхмерной модели человека на основе его позы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9aGMzgA59oU"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-071.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iupsVOP59oV"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-079.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJH3l3mi59oW"
      },
      "source": [
        "Мы добавили в словарь две специальные команды $ <start> $ и $ <end> $ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6Ali4xU59oX"
      },
      "source": [
        "Иногда дает очень хорошие описания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSXCH04459oY"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-080.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo7MxLry59oZ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-083.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLFByMFy59oZ"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-086.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovx8AUFe59oa"
      },
      "source": [
        "Исчезающий/взрывающийся градиент (Vanishing/exploding gradient) - явления исчезающего и взрывающегося градиента часто встречаются в контексте RNN. Причина, по которой они происходят, заключается в том, что трудно уловить долгосрочные зависимости из-за мультипликативного градиента, который может экспоненциально уменьшаться/увеличиваться по отношению к числу слоев.\n",
        "\n",
        "Градиентное отсечение (Gradient clipping) - метод, используемый для решения проблемы взрывающегося градиента, иногда возникающей при выполнении обратного распространения. Ограничивая максимальное значение градиента, это явление контролируется на практике."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6QIH71l59ob"
      },
      "source": [
        "<img src =\"../../src/L08_RNN/img/gradient-clipping.png\" width=\"700\">\n",
        "\n",
        "<img src =\"../../src/L08_RNN/img/gradient-vanishing-exploding.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CQPFl5wAeyX"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z71j3Zcp59od"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-090.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTYGjknp59od"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-094.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrE47hqt59od"
      },
      "source": [
        "Но нам все равно не нужно распространять через веса (потенциально это может вызвать проблемы)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWmtWwGM59oe"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-095.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMfwNI5L59oe"
      },
      "source": [
        "Если в Vanilla RNN был только один путь, то в LSTM есть highway для сокращения информации  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw06xnTr59oe"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-098.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6RAefDNHFoq"
      },
      "source": [
        "## Пример машинного перевода"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAJnLL5m59oE"
      },
      "source": [
        "\n",
        "\n",
        "Подробнее о том, как выглядят нейросети для машинного перевода и, в частности, Google-переводчик, можно прочитать в статье Google преодолевает барьер между человеческим и машинным переводом. А мы вернёмся к распознаванию изображений и поговорим об image captioning.\n",
        "\n",
        "ссылка https://www.reg.ru/blog/google-preodolevaet-barer-mezhdu-chelovecheskim-i-mashinnym-perevodom/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4dPL9ywAydU"
      },
      "source": [
        "## GRU (Gated reccurent unit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9bJukJb59oe"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-101.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfj-AChX59of"
      },
      "source": [
        "Были предприняты попытки с помощью эволюционного поиска найти более оптимальный юнит для RNN. \n",
        "\n",
        "*Поиск шел в пространстве формул для обновления состояний*\n",
        "\n",
        "Тем не менее, никакого значительного улучшения качва достигнуто не было относительно LSTM, именно поэтому LSTM является оптимальой архитектурой."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQTkOpV-A7g1"
      },
      "source": [
        "## Architecture search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi_IGUXQ59of"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-102.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mliHGFlI6jag"
      },
      "source": [
        "# Применение RNN для генерации данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ4AZMyH59n_"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-012.gif\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nj9L4rj59n_"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-013.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrxAnrgC59oA"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-013-1.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeS-8zpj59oB"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-014.gif\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mv05SGQ60Be"
      },
      "source": [
        "# Чулан"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laj7_a0v59n6"
      },
      "source": [
        "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/L08_14.png\" width=\"800\">"
      ]
    }
  ]
}