{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекуррентные нейронные сети (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Особенности\n",
    "\n",
    "До этого мы работали с методами машинного обучения, которые работают с  признаковы описанием фиксированной длины.\n",
    "\n",
    "Это верно про табличные данные - обычно каждый объект в таких данных описан фиксированным набором признаков и новые признаки не могут появиться \"вдруг\". Мы точно знаем, что на вход нам приходит объект размера 100, а на выходе мы должны для него предсказать 1 число. \n",
    "\n",
    "Верно это и про данные с фотографий - обычно наша нейросеть учится на изображениях определенного разрешения. Да, иногда мы делаем нейросеть, которая способна работать с изоюражением почти любого разрешения, но добиваемся мы этого за счет вставки слоев global pooling, которые просто приводят любое признаковое описание, полученнное нашей нейросетью, а точнее, ее сверточной частью, ранее, к фиксированному размеру. \n",
    "\n",
    "Однако многие данные такой структурой не обладают. К примеру - тексты. Возьмем все абзацы из Войны и Мира. Какие-то будут больше, какие-то меньше. И обрезать их как-то нельзя. Аналогично будет и для текстов из твиттера и тд. И что делать, если мы хотим предсказывать, например, эмоциональную окрашенность текста? \n",
    "\n",
    "Более того, а что делать, если, к примеру, на основе абзаца текста нам необходимо сгенерировать его краткое содержание? То есть и выход у нас может быть разной длины. Аналогично - мы хотим по данным о курсе валюты за прошлый год спрогнозировать курс валюты на следующий месяц по дням. \n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/types3.png\" >\n",
    "\n",
    "\n",
    "Таким образом, у нас есть целый набор задач, для которых необходима особая структура нейросети, позволяющая так или иначе принимать данные разного размера. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типы задач\n",
    "\n",
    "**Анализ временных рядов**\n",
    "- Табличные данные\n",
    "- Аннотирование изображений и видео (Image/Video captioning)\n",
    "- Машинный перевод\n",
    "- Распознавание текста\n",
    "- Распознавание речи\n",
    "\n",
    "**Генеративные модели**\n",
    "- Генерация текста/речи (чат - боты)\n",
    "- Генерация изображений\n",
    "\n",
    "**Классификация**\n",
    "- Изображения\n",
    "- Блоки текста (Sentiment analysis)\n",
    "\n",
    "\n",
    "Общее для задач - мы имеем возможность сохранять информацию, сформированную при обработке одного слова, и использовать ее, когда мы анализируем дальнейшие слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "До прихода нейронных сетей предложения пытались описать при помощи набора правил - грамматик, которые довольно успешно могли генерировать новые осмысленные предложения. Так выглядит разбор при помощи грамматик простого предложения \n",
    "\n",
    "![alttext](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/ParseTree.svg/1200px-ParseTree.svg.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако грамматики плохо учитывали более глобальные связи. Например, очень тяжело было добиться того, чтобы в абзаце текста:\n",
    "\n",
    "\"Леша пришел домой. Он будет есть рыбу\"\n",
    "\n",
    "компьютер понял, что во втором предложении \"Он\" сооттветствует \"Леше\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Основная идея, которая стоит заключается в RNN состоит в следующем - а давайте возьмем и всю последовательность пропустим через одну и туже нейросеть. \n",
    "Но при этом сама нейросеть кроме следующего элемента последовательности (например, слова в тексте), будет принимать еще один параметр - некий v, который в начале будет, например, вектором из нулей, а далее - значением, которое выдает сама нейросеть после обработки очередного элемента последовательности (**токена**)\n",
    "\n",
    "В этом v (чаще обозначается h - будет храниться hidden state, состояние, учитывающее и локальный, и глобальный контекст)\n",
    "\n",
    "\n",
    "\n",
    "![alttext](https://miro.medium.com/max/4136/1*SKGAqkVVzT6co-sZ29ze-g.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом наша нейросеть может выдавать некий ответ на каждом шаге, но мы можем:\n",
    "\n",
    " 1. использовать только выданное на последнем (если нам нужно предсказать одно значение) - many-to-one\n",
    "\n",
    " 2. мы можем подавать в наше нейросетку токены (когда кончился исходный сигнал - подаем нулевые токены), пока она не сгенеирует сигнал стоп (many-to-many, one-to-many)\n",
    "\n",
    " 3. можем делать различные комбинации, игнорируя выходы нейросети в начале, например"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-011.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-to-one - обычная нейронная сеть, RNN здесь не нужно\n",
    "\n",
    "Более сложной является реализация «one to many», когда у нас есть всего один вход и нам необходимо сформировать несколько выходов. Такой тип нейронной сети актуален, когда мы говорим о генерации музыки или текстов Мы задаем начальное слово или начальный звук, а дальше модель начинает самостоятельно генерировать выходы, в качестве входа к очередной ячейке рассматривая выход с прошлой ячейки нейронной сети.\n",
    "\n",
    " Если мы рассматриваем задачу классификации, то актуальна схема «many to one». Мы должны проанализировать все входы нейронной сети и только в конце определиться с классом.\n",
    " \n",
    "  Схему «many to many», когда количество выходов равно количеству входов нейронной сети, мы рассмотрели на примере с определением части речи. Такой вид используется также в задачах NER, которые мы обсудим в следующем видео. \n",
    "  \n",
    "Ну и последней разновидностью нейронных сетей является сеть вида «many to many», когда количество выходов нейронной сети не равно количеству входов. Это актуально, к примеру, в машинном переводе, когда одна и та же фраза может иметь разное количество слов в разных языках (т.е. это реализует схему энкодер-декодер). Энкодер получает данные различной длины — например, предложение на английском языке. С помощью скрытых состояний он формирует из исходных данных вектор, который затем передаётся в декодер. Последний, в свою очередь, генерирует из полученного вектора выходные данные — исходную фразу, переведённую на другой язык."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-011.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно объединять разные подходы. Сначала генерируем некий $h$, который содержит сжатую информацию о том, что было подано в нейросеть, а затем подаем его в нейросеть one-to-many, которая генерирует, к примеру, перевод того, текста, что был подан первой части нейросети. \n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-030.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовый RNN блок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подробнее разобраться, что же происходит в загадочном зелёном прямоугольнике с надписью RNN. Внутри него мы вычисляем рекуррентное соотношение с помощью функции f, которая зависит от весов w. Чтобы найти новое состояние ht, мы берём предыдущее скрытое состояние $ h_{t-1} $, а также текущий ввод xt. Когда мы отправляем в модель следующие входные данные, полученное нами скрытое состояние $ h_t $ передаётся в эту же функцию, и весь процесс повторяется.\n",
    "\n",
    "Чтобы генерировать вывод в каждый момент времени, в модель добавляются полносвязные слои, которые постоянно обрабатывают состояния $ h_t $ и выдают основанные на них прогнозы. При этом функция f и веса w остаются неизменными.\n",
    "\n",
    "Самая простая реализация рекуррентной сети будет выглядеть следующим образом (Тангенс здесь используется для введения нелинейности в систему):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-017.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важное отличие от слоев с которыми мы уже сталкивались, сотоит в том что на выходе мы получаем два объекта Y и H.\n",
    "\n",
    "**Y** - предсказание в текущий момент времени, например метка класса.\n",
    "\n",
    "**H** - контекст в котором предсказание было сделанно. Он может использоваться для дальнейших предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNNCell\n",
    "\n",
    "В Pytorch для вычисления h_t используется модуль [RNNCell](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html)  \n",
    "\n",
    "y_t в нем не вычисляется, предполагается что для его получения в модель должен быть добавлен дополнительный линейный слой.\n",
    "\n",
    "**input_size** -  рамер элемента последовательности.\n",
    "\n",
    "В отличие от сверточных, это всегда вектор а не тензор, поэтому input_size -  скаляр.\n",
    "\n",
    "**hidden_size** - тоже скаляр. Он задает размер скрытого состояния которое тоже является вектором. Фактически это количество нейронов в слое.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "rnn_cell = torch.nn.RNNCell(input_size = 3, hidden_size = 2)\n",
    "dummy_sequence = torch.randn((1,3)) # batch, input_size\n",
    "h = rnn_cell(dummy_sequence) \n",
    "print(\"Out = h\\n\",h.shape,\"\\n\",h) # hidden state "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно следующее:\n",
    "Для понятности в данном примере опущена батчевая обработка."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# Simple RNNcell without a bias and batch support\n",
    "class SimplifiedRNNCell(nn.Module): \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    # Init weight matrix, for simplicity omit bias\n",
    "    self.W_hx = np.random.randn(input_size, hidden_size) * 0.0001 # hidden_size == number of neurons\n",
    "    self.W_hh = np.random.randn(hidden_size, hidden_size) * 0.0001 # naive initialization\n",
    "    self.h0 = np.zeros((hidden_size)) # Initial hidden state\n",
    "  \n",
    "  def forward(self,x,h = None): # Without a batch dimension\n",
    "    if h is None:\n",
    "      h = self.h0\n",
    "    h = np.tanh(self.W_hx.T.dot(x)+self.W_hh.T.dot(h))\n",
    "    return h \n",
    "  \n",
    "simple_rnn_cell = SimplifiedRNNCell(input_size = 3, hidden_size = 2)\n",
    "h = simple_rnn_cell(dummy_sequence[0]) # No batch \n",
    "print(\"Out = h\\n\",h.shape,\"\\n\",h) \n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-023.png\" width=\"700\">\n",
    "\n",
    "Однако в последовательности всегда несколько элементов. И надо применить алгоритм к каждому.\n",
    "\n",
    "\n",
    " Поэтому RNNCell напрямую не используется. Для него есть обертка: [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) который обеспечивает последовательный вызов RNNCell для всех элементов последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN блок в Pytorch \n",
    "\n",
    "**Warning: batch dim is second!**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torch import nn\n",
    "rnn = torch.nn.RNN(input_size = 3, hidden_size = 2) # batch_first = True\n",
    "dummy_batched_seq = torch.randn((2,1,3)) # seq_len, batch , input_size\n",
    "out, h = rnn(dummy_batched_seq) \n",
    "print(\"Out = \\n\",out.shape,\"\\n\",out) # hidden state for each element of sequence\n",
    "print(\"h = \\n\",h.shape,\"\\n\",h) # hidden state for last element of sequence"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внутри происходит примерно следующее"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Simple RNN without batching\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "class SimplifiedRNNLayer(nn.Module): \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    self.rnn_cell = SimplifiedRNNCell(input_size, hidden_size)\n",
    "\n",
    "  # Without a batch dimension x have sahape seq_len * input_size\n",
    "  def forward(self,x, h = None):\n",
    "    all_h = []\n",
    "    for i in range(x.shape[0]):\n",
    "      h = self.rnn_cell(x[i],h)\n",
    "      all_h.append(h) \n",
    "    return  np.stack(all_h), h\n",
    "\n",
    "simple_rnn = SimplifiedRNNLayer(input_size = 4, hidden_size = 2)\n",
    "sequence = np.array([[0,1,2,0], [3,4,5,0]]) # batch with one sequence of two elements \n",
    "\n",
    "out, h = simple_rnn(sequence)\n",
    "print(\"Out \\n\",out.shape,out) \n",
    "print(\"h \\n\", h.shape, h)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберемся.\n",
    "\n",
    "К данным добаляется еще одно измерение размер последовательности. Таким образом batch из 6 последовательностей по 5 элементов в каждой будет выглядеть так:\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/rnn_batch.jpeg\" width=\"600\">\n",
    "\n",
    "P.S. Размер самого элемента == 3\n",
    "\n",
    "Внутри RNN модуля элеменым последовательности обрабатываются последовательно:\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/rnn_unrolled.jpeg\" width=\"1000\">\n",
    "\n",
    "Веса при этом используются одни и те же."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn((2,1,3)) #  seq_len, batch, input_size\n",
    "\n",
    "print(\"RNNCell\")\n",
    "rnn_cell = torch.nn.RNNCell(3,2)\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "cell_out = rnn_cell(dummy_input[0,:,:]) # take first element from sequence \n",
    "print(\"Out = h\",cell_out) # one hidden state\n",
    "\n",
    "print(\"RNN\")\n",
    "rnn = torch.nn.RNN(3,2)\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out\", out) # h for all sequence element \n",
    "print(\"h\", h) # h for last element "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого RNN блок имеет еще ряд настроек:\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add1.png\" width=\"700\">\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add2.png\" width=\"700\">\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{brown}{\\text{*Stacked RNNs}}$\n",
    "\n",
    "https://discuss.pytorch.org/t/what-is-num-layers-in-rnn-module/9843/2\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/layers.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h - справа, out - сверху"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn((2,1,3)) #  seq_len,  batch, input_size\n",
    "rnn = torch.nn.RNN(3,2,num_layers=3)\n",
    "\n",
    "# Weights matrix sizes not changed!\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out\", out.shape, out) # Hidden states for all elements from top layer\n",
    "print(\"h\", h.shape, h) # Hidden states for last element for all layers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{brown}{\\text{*Bidirectional}}$\n",
    "Последовательность можно пропустить через сетьдва раза в прямом и обратном направлении.\n",
    "\n",
    "https://medium.com/analytics-vidhya/understanding-rnn-implementation-in-pytorch-eefdfdb4afdb\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/bidirectional.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s штрих 0 - инициаизируется"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn((2,1,3)) #   seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3,2,bidirectional=True,num_layers=1)\n",
    "\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out\", out) # Concatenated Hidden states from both layers\n",
    "print(\"h\", h) # Hidden states last element from  both : 2*num_layers*hidden_state"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{brown}{\\text{*Добавление выходных весов (y_t)}}$\n",
    "Давайте добавим выходные веса. Для этого придется программировать.Воспользуемся параметром batch_first = True что бы batch измерение оказалось на привычном нам месте."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "# Let's add output weights\n",
    "\n",
    "class RNN_for_many_to_one(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden, batch_first = True)\n",
    "        self.fc1 = torch.nn.Linear(hidden, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, hidden = self.rnn(x)\n",
    "        print(x.shape) # h for each element\n",
    "        print(hidden.shape) \n",
    "        # we need only last output\n",
    "        #return self.fc1(x[-1])\n",
    "        return self.fc1(hidden)\n",
    "    \n",
    "model2 = RNN_for_many_to_one(28, 128, 10) # input_size, hidden_dim, classes\n",
    "dummy_input = torch.randn((8,28,28)) #  batch , seq_len  , element_size\n",
    "res = model2(dummy_input)\n",
    "# 30 - batch, 50 - output_size\n",
    "print(res.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию batch_first =  False и batch измерение становится вторым!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример обработки временного ряда\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что общего у прогнозирования потребления электроэнергии домохозяйствами, оценки трафика на дорогах в определенные периоды, прогнозировании паводков и прогнозировании цены, по которой акции будут торговаться на фондовой бирже?\n",
    "\n",
    "Все они подпадают под понятие данных временных рядов! Вы не можете точно предсказать любой из этих результатов без компонента «время». И по мере того, как в мире вокруг нас генерируется все больше и больше данных, прогнозирование временных рядов становится все более важной областью применения методов ML и DL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных\n",
    "\n",
    "Air Passengers per month. \n",
    "https://www.kaggle.com/rakannimer/air-passengers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dataloading\n",
    "import pandas as pd\n",
    "\n",
    "!if test -f ./airline-passengers.csv; then echo \"Already downloaded\"; else wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv; fi\n",
    "\n",
    "dataset = pd.read_csv('airline-passengers.csv')\n",
    "dataset.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_data = dataset.iloc[:,1:2].values # перевели dataframe в numpy.array\n",
    "# plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data, label = 'Airline Passangers Data')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Min - Max normalization\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "training_data -= td_min\n",
    "training_data = training_data / td_max\n",
    "print(training_data[:5])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных\n",
    "\n",
    "Поскольку мы хотим научиться предсказывать следующие значение на основе предидущих нам нужно подготовить данные соответствующим образом.\n",
    "\n",
    "Разобьем весь массив данных на фрагменты вида\n",
    "\n",
    "x -> y\n",
    "\n",
    "где х - это подпоследовательность, например строки с 1-й по 8ю, а y - это значение из 9-й строки, то самое которое мы хотим предсказать\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# функция создания \"ансамблей\" данных\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)] # seq_len * elements\n",
    "        _y = data[i+seq_length] # one element\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)\n",
    "    \n",
    "# установка длины ансамбля. от нее практически всегда зависит точность предикта и быстродействие\n",
    "seq_length = 8 # сравните 2 и 32\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "x[0], y[0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря такому подходу мы можем работать с RNN моделью так же как работали со сверточными моделями. Подавая на вход такую подпоследовательность + результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разобьем на train и test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_size = int(len(y) * 0.8)\n",
    "test_size = len(y) - train_size\n",
    "\n",
    "dataX = torch.Tensor(np.array(x))\n",
    "dataY = torch.Tensor(np.array(y))\n",
    "\n",
    "trainX = torch.Tensor(np.array(x[0:train_size]))\n",
    "trainY = torch.Tensor(np.array(y[0:train_size]))\n",
    "\n",
    "testX = torch.Tensor(np.array(x[train_size:len(x)]))\n",
    "testY = torch.Tensor(np.array(y[train_size:len(y)]))\n",
    "\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class AirTrafficPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons \n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"x: \",x.shape) # 108 x 8 x 1 : [batch_size, seq_len, input_size] \n",
    "        out, h = self.rnn(x) \n",
    "        #print(\"out: \", out.shape) # 108 x 8 x 4 : [batch_size, seq_len, hidden_size] Useless!\n",
    "        #print(\"h : \", h.shape) # 1 x 108 x 4 [ num_layers, batch_size, hidden_size]\n",
    "        y = self.fc(h)\n",
    "        #print(\"y\",y.shape) # 1 x 108 x 1\n",
    "        return y, h"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение\n",
    "\n",
    "Благодаря подготовке данных процесс обучения не будет отличаться от того что мы использовали на прошедших занятиях.\n",
    "\n",
    "В силу того что датасет маленький, все данные поместились в один batch, итерирования по batch-ам в явном виде здесь не происходит."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def time_series_train(model):\n",
    "  num_epochs = 2000\n",
    "  learning_rate = 0.01\n",
    "\n",
    "  criterion = torch.nn.MSELoss() # mean-squared error for regression\n",
    "  optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Train the model\n",
    "  for epoch in range(num_epochs):\n",
    "      outputs, h = model(trainX) # we don't use h there, but we can!\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      # obtain the loss function\n",
    "      loss = criterion(outputs, trainY)\n",
    "      loss.backward()\n",
    "      \n",
    "      optimizer.step()\n",
    "      if epoch % 100 == 0:\n",
    "          print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 4 \n",
    "rnn = AirTrafficPredictor(input_size, hidden_size)\n",
    "time_series_train(rnn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def time_series_plot(train_predict):\n",
    "  data_predict = train_predict.data.numpy()\n",
    "  dataY_plot = dataY.data.numpy()\n",
    "\n",
    "  # Denormalize\n",
    "  data_predict = data_predict[0] *td_max + td_min\n",
    "  dataY_plot = dataY_plot *td_max + td_min \n",
    "  #print(data_predict[:15])\n",
    "\n",
    "  # Ploitting\n",
    "  plt.figure(figsize=(12, 4))\n",
    "  plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "  plt.plot(dataY_plot)\n",
    "  plt.plot(data_predict)\n",
    "  plt.suptitle('Time-Series Prediction')\n",
    "  plt.show()\n",
    "\n",
    "rnn.eval()\n",
    "train_predict, h = rnn(dataX)\n",
    "time_series_plot(train_predict)\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Time Series Prediction with LSTM Using PyTorchTime Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посимвольная генерация текстов\n",
    "\n",
    "https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb\n",
    "\n",
    "Одним из основных направлений использования рекуррентных сетей является работа с текстами:\n",
    "- генерация (Language modeling)\n",
    "и \n",
    "- перевод (Machine Translation)\n",
    "\n",
    "Давайте посмотрим как решаются такого рода задачи.\n",
    "\n",
    "Начнем с относительно простой - посимвольной генерации текста.\n",
    "\n",
    "Постановка задачи:\n",
    "\n",
    "предсказать следующий символ в последовательности.\n",
    "\n",
    "- исходный текст:\n",
    "'hey how are you'\n",
    "\n",
    "- искаженный текст:\n",
    "\n",
    "'hey how are yo'\n",
    "\n",
    "- Верное предсказание:\n",
    "'u'\n",
    "\n",
    "\n",
    "Теоретически эту технику можно использовать для генерации подсказок при наборе текстов, исправления ошибок или восстановления частично утраченного текста.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-037.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка данных\n",
    "\n",
    "1. Зафиксировать словарь\n",
    "2. Разбить данные\n",
    "3. Кодирование символов "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "text = ['hey how are you','good i am fine','have a nice day']\n",
    "\n",
    "# Join all the sentences together and extract the unique characters from the combined sentences\n",
    "chars = set(''.join(text))\n",
    "\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}\n",
    "\n",
    "print(char2int)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо ascii символа, каждой букве мы сопоставили номер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выравнивание данных (Padding)\n",
    "\n",
    "RNN допускают работу с данными переменной длины. Но что бы поместить предложения в batch надо их выровнять.\n",
    "\n",
    "\n",
    "Обычно размер батча делают равным самому длинному предложению, а остальные просто дополняют пробелами до этого размера."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "maxlen = len(max(text, key=len))\n",
    "print(\"The longest string has {} characters\".format(maxlen))\n",
    "\n",
    "# A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "for i in range(len(text)):\n",
    "    while len(text[i])<maxlen:\n",
    "        text[i] += ' '\n",
    "\n",
    "print(text)\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных\n",
    "\n",
    "\n",
    "\n",
    "В качестве входа будем использовать предложение без последнего символа:\n",
    "\n",
    "**'hey how are yo'**\n",
    "\n",
    ", а в качестве результата - предложение в котором он сгенерирован.\n",
    "\n",
    "**'ey how are you'**\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "    \n",
    "    # Remove firsts character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "    print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим вравнивание служит здесь плохую службу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодирование\n",
    "\n",
    "Теперь символы надо перевести в числа. Для этого мы уже построили словарь.\n",
    "\n",
    "P.S. Запускать блок только один раз."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "print(\"Input\",input_seq)\n",
    "print(\"Target\",input_seq)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot-encoding(!)\n",
    "\n",
    "Теперь из чисел надо сделать вектора. \n",
    "\n",
    "\n",
    "Почему бы не оставить числа?\n",
    "В прошлом примере модель хорошо с ними работала.\n",
    "\n",
    "В прошлом примере использовася MSE и на выходе было число.\n",
    "\n",
    "Если бы мы определили отношение порядка над номерами букв, то что-то подобное можно было бы сделать.\n",
    "\n",
    "Однако сейчас мы предсказываем класс буквы.\n",
    "Поэтому на входе и на выходе должен быть вектор.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/softmax_1.png\" width=\"200\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(text)\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    \n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features\n",
    "\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
    "print(\"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(input_seq.shape))\n",
    "print(input_seq[0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый символ закодировали вектором.\n",
    "Не слишьком экономно, зато удобно умножать на матрицу весов.\n",
    "\n",
    "P.S. Запускать только один раз"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert data to tensor\n",
    "input_seq = torch.Tensor(input_seq)\n",
    "target_seq = torch.Tensor(target_seq)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class NextCharacterGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size = hidden_dim, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden_0 = torch.zeros(1, batch_size, self.rnn.hidden_size) # 1 correspond to number of layers\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden_0)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # Need Only if n_layers > 1\n",
    "        out = out.contiguous().view(-1, self.rnn.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = NextCharacterGenerator(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training Run\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "    \n",
    "    out, hidden = model(character)\n",
    "    #print(out.shape)\n",
    "    #print(out)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden\n",
    "\n",
    "def sample(model, out_len, start='hey'):\n",
    "    model.eval() # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)\n",
    "\n",
    "sample(model, 15, 'good')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/softmax_2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{brown}{\\text{*Примеры применения}}$\n",
    "\n",
    "Результаты которые удается получить при помощи моделей обученных на больших объемах данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-050.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-054.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-055.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-058.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-059.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-061.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-063.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{brown}{\\text{*Explanation}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-064.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-065.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-066.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-067.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-068.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-069.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-068.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-069.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{brown}{\\text{*Как пропускать через градиент}}$\n",
    "\n",
    "В случае с реккурентными сетями есть проблема с распространением градиента - если последовательность большая, то потребуется очень много времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-045.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоритетески можно было бы сразу пропустить все данные через сеть и затем вычислить градиент.\n",
    "\n",
    "Но:\n",
    " - Большие последовательности не поместятся в памяти\n",
    " - Возникнут проблеммы исчезновения/взрыва градиента, так как цепочка будет очень длинной\n",
    " - Контекст затирается (по аналогии с ResNet)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потому иногда делают пропускание градиента только через части последовательности, окнами. За счет этого получается меньшие затраты по памяти\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-046.png\" width=\"700\">\n",
    "\n",
    "Или можно пропускать только на сколько-то позиций от выхода - тоже можно, веса одни и те же используются, потому вполне возможно, что поправки от последних действий хватит, чтобы выправить нейросеть в целом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-047.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скрытые состояния при этом сохраняются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-083.png\" width=\"700\">\n",
    "\n",
    "Градиент в рекуррентных сетях затухает так же быстро. И при большой длине последовательности это становится критичным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-086.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исчезающий/взрывающийся градиент (Vanishing/exploding gradient) - явления исчезающего и взрывающегося градиента часто встречаются в контексте RNN. Причина, по которой они происходят, заключается в том, что трудно уловить долгосрочные зависимости из-за мультипликативного градиента, который может экспоненциально уменьшаться/увеличиваться по отношению к числу слоев.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-023.png\" width=\"700\">\n",
    "\n",
    "Градиентное отсечение (Gradient clipping) - метод, используемый для решения проблемы взрывающегося градиента, иногда возникающей при выполнении обратного распространения. Ограничивая максимальное значение градиента, это явление контролируется на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gradient-clipping.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gradient-vanishing-exploding.png\" width=\"700\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "import torch.\n",
    "\n",
    "threshold = 100 # Must be found empirically\n",
    "\n",
    "for sequences, labels in train_loader:\n",
    "        optimizer.zero_grad() \n",
    "        output = model(sequences)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward() \n",
    "        # Add clippeng after backward\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), threshold)\n",
    "        # Before step\n",
    "        optimizer.step()\n",
    "```\n",
    "\n",
    "https://stackoverflow.com/questions/54716377/how-to-do-gradient-clipping-in-pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ванильное RNN имело множество проблем, в том числе, в нем очень быстро затухала информация о предыдущих словах в предложении. Помимо этого, были проблемы с затухением/взрывом самого градиента. \n",
    "\n",
    "Эти проблемы были частично решены в LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-090.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в Vanilla RNN был только один путь, то в LSTM есть highway для сокращения информации  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/lstm.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была предложена концепция gate \"врат\", в которых решается, какая информация и как будет добавлена к главному потоку - $c$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* i = Input - преобразуем результат обработки текущего объекта и состояния h в сигнал от 0 до 1\n",
    "* g = Gate - решаем, на основе результатов же обработки текущего объекта и состояния h, какую часть из преобразованной информации добавим/вычтем из потока c.  \n",
    "* f = Forget - опять же, на основе результатов обработки текущего объекта  и состояния h решаем, какую часть информации из c можно забыть \n",
    "* o = Output - формируем на основе нового c и результатов обработки текущего объекта  и состояния h новое состояние h\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Конкатенируем x и h_t-1\n",
    "2. Умножаем на веса\n",
    "3. Результат делим на 4 части (shape = hidden_size) к каждой применяем свою функцию активации\n",
    "4. Далее комбинируем их с входами и выходами\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-094.png\" width=\"700\">\n",
    "\n",
    " i = Input  f = Forget  o = Output  g = Gate\n",
    "\n",
    " Операция \"кружек с точкой\" - это поэлементной умножение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом мы получили магистраль для градиента аналогично ResNet.\n",
    "\n",
    "Однако надо отметить что статья вышла в 1997г(!)\n",
    "\n",
    "https://www.bioinf.jku.at/publications/older/2604.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMCell\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html\n",
    "\n",
    "Интерфейс отличается от RNNCell количеством входов и выходов\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "lstm_cell = torch.nn.LSTMCell(input_size = 3, hidden_size = 4)\n",
    "dummy_input = torch.randn(1,3) # batch, input_size\n",
    "h_0 = torch.randn(1,4)\n",
    "c_0 = torch.randn(1,4)\n",
    "h, c = lstm_cell(dummy_input, (h_0,c_0)) # second arg is tuple\n",
    "print(\"h\",h.shape,h) # batch, hidden_size\n",
    "print(\"c\",c.shape,c) # batch, hidden_size\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM in Pytorch\n",
    "\n",
    "Отличие состоит в том что возвращается кроме h возвращается еще и c. Но можно использовать только output. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "lstm = nn.LSTM(input_size = 3, hidden_size = 3)\n",
    "dummy_input = torch.randn(2,1,3) # seq_len, batch, input_size\n",
    "out, (h, c) = lstm(dummy_input) # h and c returned in tuple\n",
    "print(\"out\",out.shape,out) # seq_len, batch, hidden_size : h for each element\n",
    "print(\"h\",h.shape,h) # batch, hidden_size\n",
    "print(\"c\",c.shape,c) # batch, hidden_size"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример использования \n",
    "\n",
    "Что бы убедиться в работоспособности конструкции заменим RNN блок на LSTM в задаче предсказания временного ряда."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define new LSTM based model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMAirTrafficPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons \n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h,c) = self.lstm(x) \n",
    "        y = self.fc(h)\n",
    "        return y\n",
    "\n",
    "lstm =  LSTMAirTrafficPredictor(input_size =1 , hidden_size =4 )\n",
    "di = torch.randn((108,8,1))\n",
    "out = lstm(di)\n",
    "print(out.shape)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lstm.train()\n",
    "\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = torch.nn.MSELoss() # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    " # Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(trainX) \n",
    "    optimizer.zero_grad()\n",
    "    #print(outputs.shape)\n",
    "    loss = criterion(outputs, trainY.unsqueeze(0))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lstm.eval()\n",
    "train_predict = lstm(dataX)\n",
    "time_series_plot(train_predict)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU (Gated reccurent unit)\n",
    "\n",
    "LSTM выглядела очень громоздко. Потому решили искать более  компактную структуру. Так получили GRU\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/gru1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "rnn = torch.nn.GRU(input_size = 4, hidden_size =3)\n",
    "input = torch.randn(2, 1, 4) #seq_len, batch, input_size\n",
    "h0 = torch.randn(1, 1, 3)\n",
    "output, h = rnn(input, h0)\n",
    "\n",
    "print(\"Out\",output.shape,\"\\n\",output) # seq_len = 2\n",
    "print(\"h\",h.shape,\"\\n\",h) # last h\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда лучше работает GRU, иногда - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-Sequence with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Сейчас мы пытаемся решить задачу sequence to sequence\n",
    "* Орабатывая входную последовательность, мы хотим обобщить всю информацию, которая в ней содержится в некий вектор С\n",
    "* Далее мы передаем этот вектор во вторую RNN, которая является декодером\n",
    "\n",
    "\n",
    "Мы используем вектор С для передачи информации между энкодером и декодером, также мы предполагаем, что вектор С обощает всю информацию, которая небходима декодеру для генерации выходных последовательности.\n",
    "\n",
    "Однако использование единственного вектора для предоставления информации может работать только для последовательностей малой длины (неразумно предполагать, что информация с длинной последовательностью можно сжать в один вектор) \n",
    "\n",
    "Именно поэтому нам нужен некий механизм, который будет обходить \"бутылочное горлышко\" и не сжимать всю информацию в один вектор С. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-011.png\" width=\"700\">\n",
    "\n",
    "В качестве С и So может использоваться просто h_4 (последнее скрытое состояние)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Машинный перевод\n",
    "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "дополнительно:\n",
    "https://pytorch.org/tutorials/beginner/torchtext_translation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!wget https://download.pytorch.org/tutorial/data.zip\n",
    "!unzip data.zip\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "! sed -n 200,210p  data/eng-fra.txt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс для хранения слов. Работает аналогично символам:\n",
    "Создается словарь из всех слов и таким образом каждое слово получает свой индекс (номер).  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательные методы для загрузки пар фраз из файла."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import random\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(file_name):\n",
    "  print(\"Reading lines...\")\n",
    "\n",
    "  # Read the file and split into lines\n",
    "  lines = open(file_name, encoding='utf-8').\\\n",
    "      read().strip().split('\\n')\n",
    "\n",
    "  # Split every line into pairs and normalize\n",
    "  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "  # Make Lang instances\n",
    "  input_lang = Lang('en')\n",
    "  output_lang = Lang('fr')\n",
    "\n",
    "  return input_lang, output_lang, pairs\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[0].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(file_name):\n",
    "    input_lang, output_lang, pairs = readLangs(file_name)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('data/eng-fra.txt')\n",
    "for i in range(5):\n",
    "  print(random.choice(pairs))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь в нашем распоряжении есть два словаря и набор пар строк.\n",
    "Определим структуру модели."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torch import nn\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        print(input_size)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden = None):\n",
    "        embedded = self.embedding(input)\n",
    "        print(\"Embedding: \",embedded.shape)\n",
    "        output, hidden = self.gru(embedded.view(1, 1, -1), hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "\n",
    "training_pair = pairs[0]\n",
    "\n",
    "input_tensor = training_pair[0]\n",
    "target_tensor = training_pair[1]\n",
    "\n",
    "input_tensor = tensorFromSentence(input_lang, input_tensor)\n",
    "target_tensor = tensorFromSentence(output_lang, target_tensor)\n",
    "\n",
    "print(\"Input tensor\",input_tensor.shape,input_tensor)\n",
    "\n",
    "encoder_hidden = encoder.initHidden()\n",
    "encoder_outputs, hidden = encoder(input_tensor[0])\n",
    "\n",
    "print(\"Out\",encoder_outputs.shape)\n",
    "print(\"Hidden\",hidden.shape)\n",
    "#dummy_input = torch_randn()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо one_hot - векторов, используются эмбеддинги размером 1x256 (hidden size)\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size ):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "decoder = DecoderRNN(output_lang.n_words, hidden_size) # hidden state must have the same sizes\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "# Use encoder last state as decoder init\n",
    "decoder_hidden = encoder_hidden\n",
    "\n",
    "decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden )\n",
    "print(\"Output: \", decoder_output.shape)\n",
    "#https://pytorch.org/docs/stable/generated/torch.topk.html\n",
    "top_val, top_index = decoder_output.topk(1) # Returns the k largest elements of the given input tensor\n",
    "\n",
    "generated_word = output_lang.index2word[top_index.item()]\n",
    "print(\"Word: \", generated_word, \"index \", top_index.item())\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение\n",
    "\n",
    "В на вход модели будем подавать индексы слов для первой части пары из одного словаря, а на выходе ожидать индексы для соответствующей пары из другого. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "target_length = target_tensor.size(0)\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "for di in range(target_length):\n",
    "  decoder_output, decoder_hidden, = decoder( decoder_input, decoder_hidden)\n",
    "  topv, topi = decoder_output.topk(1)\n",
    "  decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "  #loss += criterion(decoder_output, target_tensor[di])\n",
    "  generated_word = output_lang.index2word[decoder_input.item()]\n",
    "  print(\"Word: \", generated_word, \"index \", decoder_input)\n",
    "\n",
    "  if decoder_input.item() == EOS_token:\n",
    "      break\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С подходом, разобранным ранее есть большая проблема\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-011.png\" width=\"700\">\n",
    "\n",
    "Чтобы понять, что надо сгенерировать слово estamos в начале, нашей нейросети надо сохранить информации о we во всех состояниях от $h_1$ до $h_4$\n",
    "А что если нам надо перевести абзац текста? \n",
    "При этом длина вектора, в котором нам надо хранить информацию обо всей последовательности - постоянна. Понятно, что начиная с какого-то момента информацию всю мы сохранить в нем не сможем. Более того, при генерации, скажем, последнего слова, мы должны в векторе того же размера сохранить информацию о этом последнем слове и о том, что другие уже сгенерены - иначе модель может зациклиться или не сгенерировать часть слов.\n",
    "\n",
    "Все эти проблемы реальны и возникают в обычной Seq2Seq модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence-to-Sequence with RNNs and Attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте не будем делать состояние $c$ фиксированным. Пусть на каждом этапе, при генерации нового слова, наш декодер имеет возможность сформировать новое $c$, на основе всех скрытых состояний $h_i$ енкодера. \n",
    "Для простоты - пусть он подбирает веса, суммирующиеся в единицу, с которыми сложить эти представления, чтобы получить новое $c$.\n",
    "Таким образом, в каждый момент времени наш декодер имеет доступ ко всему исходному предложению (представлению каждого слова) и может акцентировать внимание на конкретно нужных в данный момент словах. \n",
    "\n",
    "Говоря немного мудрено - теперь длина пути, который надо преодолеть информации от места ее появления до места, где она может пригодиться - 1, а раньше она была пропорциональна длине исходного предложения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-017.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-020.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-021.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "MAX_LENGTH = 17\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size,  max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        # ****** Attention ***************************************************\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        # ********************************************************************\n",
    "\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "\n",
    "        # ****** Attention ***************************************************\n",
    "        att_inputs = torch.cat((embedded[0], hidden[0]), 1) # S0 + Start token (Y0)\n",
    "        print(\"att_inputs\",att_inputs.shape,\"256 + 256\") # 256 + 256\n",
    "        e = self.attn(att_inputs) \n",
    "        print(\"e \",e.shape) # MAX_INPUT == number of hidden states\n",
    "        attn_weights = F.softmax( e, dim=1) \n",
    "        print(\"a (attn_weights) \",attn_weights.shape) # MAX_INPUT\n",
    "        print(\"H (encoder_outputs)\",encoder_outputs.unsqueeze(0).shape)\n",
    "        # bmm is matrix product wark as elemet-wise multiplication + sum\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        print(\"C Attn_applied\",attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        print(\"C with YO\",output.shape)\n",
    "\n",
    "        # *********************************************************************\n",
    "        \n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "# Fake hidden states from encoder\n",
    "encoder_outputs = torch.randn(MAX_LENGTH, encoder.hidden_size, device=device)\n",
    "\n",
    "att_rnn_decoder = AttnDecoderRNN(output_lang.n_words, hidden_size ) # output_size == word count in target dictionary\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "decoder_hidden = encoder_hidden\n",
    "\n",
    "output, hidden, attn_weights = att_rnn_decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим как фокусировка работает на примере перевода с английского на французский \n",
    "\n",
    "Как мы знаем, на каждом шаге генерируется набор весов, которые отвечают за фокусировку на том или ином месте входной последовательности. Как мы видим, английское предложение имеет иной порядок слов относительно французского. Например, в английском варианте словосочетание **European Economic Area**, в то время как во французском **zone économique européenne**. \n",
    "\n",
    "В английском прилагательные идут перед существительным, в то время как во французском языке наоборот. \n",
    "\n",
    "Таким образом, благодаря гибкости модели, мы можем обрабатывать и учитывать разный порядок слов в разных языках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-025.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Механизм внимания не обязательно должен принимать на вход последовательность. \n",
    "\n",
    "* Мы можем применять его, в том числе для генерации подписей для картинок. Входом в данном случае будет являться сетка признаков, которая была получена при применении сверточной сети к картинке. \n",
    "\n",
    "* Далее по этой сетке мы считаем веса внимания и делаем аналогично первому примеру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим шагом будет также заметить, что для достаточно длинного предложения наша модель может забыть и то, что она генерирует. Потому мы можем сделать два attention - один на представления исходного предложения, а второе - на представление того, что уже сгенерировано (что еще не сгенерировано - заменяем нулями)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проблема attention\n",
    "\n",
    "Очевидно, у этого подхода есть свои минусы. \n",
    "\n",
    "Самый важный из них - ваша модель должна уметь предсказывать веса для каждого слова в исходном предложении. И обычные подходы принуждают нас фиксировать размер этого вектора весов. \n",
    "\n",
    "За счет этого у нас возникло ограничение, от которого мы избавлялись - модель не может принимать (и, если используем attention на то, что сгенерировано, генерировать) предложения больше определенного размера. С другой стороны, ничто не мешает поставить этот максимальный размер достаточно большим, чтобы для бОльшей части предложений это работало. \n",
    "\n",
    "Почему это не сильный проигрыш в сравненении с LSTM - так оно все равно было ограничено в длине предложения, просто неявно, что даже хуже - лучше иметь модель, которая на длине предложения 45 падает, а не генерирует лабуду. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Captioning with RNNs and Attention\n",
    "\n",
    "Модели, основанные на внимании (attention) намного более продвинутые, нежели обычные нейросети. Они могут концентрироваться на отдельных частях изображения, что позволяет избежать зашумления данных.\n",
    "\n",
    "Идея состоит в том, что свёрточная сеть теперь будет генерировать не один вектор, описывающий всё изображение, а набор векторов для нескольких участков исходного снимка. В дополнение к работе со словарём на каждом временном шаге модель также производит распределение по точкам на изображении, которые она обрабатывает в данный момент. Это позволяет ей научиться находить наиболее важные участки, на которых необходимо фокусироваться.\n",
    "\n",
    "После обучения модели можно увидеть, что она как бы переносит своё внимание по изображению для каждого генерируемого слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-028.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-031.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-036.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-037.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-038.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Также нейросети, основанные на внимании, повсеместно используются для ответов на визуальные вопросы (Visual Question Answering). Цель этой задачи — обучить модель отвечать на вопрос по изображению. Например, она должна уметь не только называть сами объекты на фотографии, но и считать их, распознавать цвета и оценивать расположение относительно друг друга. Мы уже рассказывали о подобных архитектурах в статье о том, как такие нейросети могут помочь незрячим людям и о нейро-символическом мышлении.\n",
    "\n",
    "ссылка https://www.reg.ru/blog/nejroset-opisyvaet-mir-nezryachim-lyudyam/ ссылка https://www.reg.ru/blog/uchim-nejroseti-rassuzhdat-o-tom-chto-oni-vidyat/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-039.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Layer\n",
    "\n",
    "В ходе дальнейшей эволюции метода attention, пришли к такой форме.\n",
    "\n",
    "У нас есть некий изначальный набор X - слова в нашем предложении. \n",
    "\n",
    "Мы можем их преобразовать как-то, чтобы получить более удобные для дальнейшей цели K - предполагается, что они лучше помогают сравнивать между собой слова. \n",
    "В простейшем случае некое линейное преобразование $K = XW_K$\n",
    "\n",
    "Далее у нас есть значения, V, которые тоже получаются из X путем какого-то преобразования, которое делает их более применимыми для работы модели (важные признаки и тд), например $V = XW_Q$\n",
    "\n",
    "Далее к нам приходят запросы Q, которые находятся в том же пространстве, что и ключи. \n",
    "Мы сравниваем эти запросы с ключами - считаем просто попарные косинусные расстояние между каждым ключом $K_i$ и запросом $Q_j$. Получаем похожесть каждого ключа на запрос, нормируем ее на корень из размерности представления нашего ключа. \n",
    "\n",
    "$E = \\dfrac {QK^T} {\\sqrt{D}} $\n",
    "\n",
    "Получили матрицу похожестей $E$, где $E_{ij}$ - похожесть ключа $K_i$ на запрос $Q_j$\n",
    "\n",
    "Далее мы применяем к похожестям $E$ softmax, беря его по каждомуу ключу отдельно (по каждому столбцу матрицы E). Теперь у нас похожести каждого запроса складываются в единицу. \n",
    "\n",
    "$A = softmax(E, dim=1)$\n",
    "\n",
    "Получили для каждого запроса его \"разложение\" в виде ключей. \n",
    "\n",
    "Далее, чтобы получить значения, соответствующие каждому запросу, складываем значения с весами соответствующих ключей\n",
    "\n",
    "$Y_j = \\sum_iA_i V_i$\n",
    "\n",
    "$Y = AV$\n",
    "\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-056.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что мы таким образом получили? Фактически, мы получили дифференцируемый аналог словаря в Python. Только этот словарь еще умеет делать неточный поиск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention Layer\n",
    "\n",
    "А теперь сделаем такой слой\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-063.png\" width=\"700\">\n",
    "\n",
    "Что изменилось? \n",
    "\n",
    "Теперь X участвует и в производстве K, и в производстве V, и в производстве Q. Потому и self-attention - предложение состоящее из слов X_i, ищет само себя в нашем дифференцируемом словаре. Почему это не приводит к тому, что мы просто получим вектор V?\n",
    "Потому что значения X_i модифицируются и K != Q.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В чем смысл этого? \n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_4-1.png\" width=\"700\">\n",
    "\n",
    "Каждое слово нашего предложение может посмотреть на другие слова. Что это дает? Вместо того, чтобы всегда кодировать she одинаковым способом, теперь she может кодироваться с учетом того, что she - это еще и cat, и еще и Noa. \n",
    "Мы в прямом виде решаем проблему, которая была у ранних подходов на основе грамматик - мы автоматически меняем she на более богатое представление\n",
    "\n",
    "Аналогично - слово $annoying$ теперь не просто $annoying$, а еще информация о том, что кошка именно бывает такой, и что это некритично\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional encoding\n",
    "\n",
    "Единственный возможный минус - наша нейросеть не учитывает порядка слов в предложении при составлении embedding. Это может нам мешать. Например, если в предложении два it, то они часто относятся к разным словам. Потому хотим ууметь учитывать информацию о позиции. Для этого к X при составлении Q добавляется информация о позиции. \n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-072.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Self-Attention Layer\n",
    "\n",
    "\n",
    "Если у нас стоит проблема, что мы не должны видеть часть слов в предложении - например, при генерации текста (по текущим словам предсказать следующее)\n",
    "\n",
    "В этом случае мы можем просто на соответствующих местах матрицы E поставить минус бесконечности - тогда в ембедингах слов, которые не должны знать о каких-то словах, информации об этих словах не будет. \n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-073.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Multihead Self-Attention Layer\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_7-1.png\" width=\"700\">\n",
    "\n",
    "\n",
    "\n",
    "Давайте посмотрим на то, к каким словам предложения gave может иметь отношение. В общим случае глагол может иметь связку со многоми частями предложения. Как, например, к подлежащему, так и к причастиям.\n",
    "\n",
    "В идеале, нам бы хотелось обратить внимние функции (attention) на все эти взаимосвязи. Для этого нам просто надо поставить несколько attention слоев парралельно. В идеале каждый будет учить что-нибудь свое - аналогия с конволюциями. \n",
    "\n",
    "* Чтобы осуществить задуманное, вместо одного набора query, будем использовать несколько независимых наборов. \n",
    "\n",
    "* Причем каждый набор будет считаться уникальной матрицей. \n",
    "\n",
    "* Аналогично сделаем для keys и values. Количество таких наборов внутри keys, queries, values должно быть **одинаковым**. \n",
    "\n",
    "* Обозначим это число как h - head, далее производим аналогичные манипуляции, при этом введем в параллель h таких функций attention\n",
    "* На последнем шаге мы их соединяем (конкатинируем)\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-075.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Attention is all you need\n",
    "\n",
    "Оказывается, этот подход работает сам по себе. Не нужно добавлять никаких реккурентных слоев - просто делаем много attention layers. \n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-085.png\" width=\"700\">\n",
    "\n",
    "Раньше мы передавали информацию по из блока attention в RNN для ее последующего применения, однако в 2017 году вышла статья под названием Attention is all you need. В ней говорилось о том, что для обработки последовательностей можно ограничиться только блоком внимания. Данная модель получила название Transformer. \n",
    "\n",
    "По сути это базовый блок, который основывается только на self-attention при работе с входными векорами. \n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-092.png\" width=\"700\">\n",
    "\n",
    "Блок устроен следующим образом: входные вектора мы запускаем в блок self-attention и используем residual connection как обходной путь вокруг self-attention, затем мы их складываем. \n",
    "\n",
    "После - применяем слой нормализации, затем - слой feed forward сетей, плюс обходной путь вокруг feat forward. \n",
    "\n",
    "Складываем их и выполняем нормализацию. \n",
    "\n",
    "Это один блок-трансформер. \n",
    "\n",
    "В реальных моделях эти слои стекируют друг с другом и получается большая трансформер-модель. \n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-094.png\" width=\"700\">\n",
    "\n",
    "\n",
    "\n",
    "В 2020 практически все успехи машинного обучения были связаны с применением трансформеров. На сегодняшний день - это самая передовая модель для обработки последовательностей. \n",
    "\n",
    "Стоит отметить, что модели трансформеров имеют огромное кличество параметров, как следствие - требуются большие вычислительные мощности для их обучения. В связи с этим, обучение данных моделей с нуля, преимущественно доступны только развитым государствам и крупным компаниям. \n",
    "\n",
    "\n",
    "### The Transformer: Transfer Learning\n",
    "\n",
    "На данный момент трансформеры применяются во всех возможных задачах - анализ изображений, анализ текстов, биологии и т.д. \n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-100.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-104.png\" width=\"700\">\n",
    "\n",
    "\n",
    "### Talk-to-transformer\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-105.png\" width=\"700\">"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {}
}
