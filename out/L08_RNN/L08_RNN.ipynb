{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUjdn9w559n1"
   },
   "source": [
    "# Рекуррентные нейронные сети (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5uaWgqR59n8"
   },
   "source": [
    "##  Особенности\n",
    "\n",
    "Если стандартные методы машинного обучения работают с так называемыми структурированными типами данных, с объектами, у которых фиксировано признаковое описание, которые подаются на вход моделям, то рекуррентные нейронные сети используются с неструктурированными данными. Например, в распознавании речи, генерации музыки, машинном переводе. Данные в таких задачах представляют собой текст без предобработки, звуковой ряд и другие данные, не имеющие признаковых описаний. Давайте обсудим, каков принцип работы нейронной сети, и как именно таким нейронным сетям удается работать с неструктурированными данными.\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/types3.png\" >\n",
    "\n",
    "\n",
    "\n",
    "Мы имеем возможность сохранять информацию, сформированную при обработке одного слова, и использовать ее, когда мы анализируем дальнейшие слова. Видно, что при рассмотрении каждого слова происходят одни и те же процедуры. Нейронная сеть получает очередное слово, учитывает предыдущую активацию, формирует ответ. Это действие, происходящее в рамках одной ячейки нейронной сети. Так как вся сеть представляет собой объединение однотипных ячеек, то нейронная сеть называется рекуррентной. Рекуррентные нейронные сети не ограничиваются случаем, когда мы каждому входу нейронной сети должны сопоставить некоторый ответ, после чего анализировать следующий вход."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Qh05-Lj68rI"
   },
   "source": [
    "## Типы задач\n",
    "\n",
    "**Анализ временных рядов**\n",
    "- Табличные данные\n",
    "- Аннотирование изображений и видео (Image/Video captioning)\n",
    "- Машинный перевод\n",
    "- Распознавание текста\n",
    "- Распознавание речи\n",
    "\n",
    "**Генеративные модели**\n",
    "- Генерация текста/речи (чат - боты)\n",
    "- Генерация изображений\n",
    "\n",
    "**Классификация**\n",
    "- Изображения\n",
    "- Блоки текста (Sentiment analysis)\n",
    "\n",
    "Большинство этих задачь подрузамевают наличие контекста ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHnc-cB959n-"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-011.png\" width=\"1000\">\n",
    "\n",
    "Существует множество типов рекуррентных нейронных сетей. Простейший случай рекуррентной сети — «one to one», когда у нас есть всего один вход и один выход нейронной сети. Более сложной является реализация «one to many», когда у нас есть всего один вход и нам необходимо сформировать несколько выходов. Такой тип нейронной сети актуален, когда мы говорим о генерации музыки или текстов. Мы задаем начальное слово или начальный звук, а дальше модель начинает самостоятельно генерировать выходы, в качестве входа к очередной ячейке рассматривая выход с прошлой ячейки нейронной сети. Если мы рассматриваем задачу классификации, то актуальна схема «many to one». Мы должны проанализировать все входы нейронной сети и только в конце определиться с классом. Схему «many to many», когда количество выходов равно количеству входов нейронной сети, мы рассмотрели на примере с определением части речи. Такой вид используется также в задачах NER, которые мы обсудим в следующем видео. Ну и последней разновидностью нейронных сетей является сеть вида «many to many», когда количество выходов нейронной сети не равно количеству входов. Это актуально, к примеру, в машинном переводе, когда одна и та же фраза может иметь разное количество слов в разных языках (т.е. это реализует схему энкодер-декодер). Энкодер получает данные различной длины — например, предложение на английском языке. С помощью скрытых состояний он формирует из исходных данных вектор, который затем передаётся в декодер. Последний, в свою очередь, генерирует из полученного вектора выходные данные — исходную фразу, переведённую на другой язык."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5BFCtTX-DlK"
   },
   "source": [
    "## Базовый RNN блок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYb68Asu59oC"
   },
   "source": [
    "Попробуем подробнее разобраться, что же происходит в загадочном зелёном прямоугольнике с надписью RNN. Внутри него мы вычисляем рекуррентное соотношение с помощью функции f, которая зависит от весов w. Чтобы найти новое состояние ht, мы берём предыдущее скрытое состояние $ h_{t-1} $, а также текущий ввод xt. Когда мы отправляем в модель следующие входные данные, полученное нами скрытое состояние $ h_t $ передаётся в эту же функцию, и весь процесс повторяется.\n",
    "\n",
    "Чтобы генерировать вывод в каждый момент времени, в модель добавляются полносвязные слои, которые постоянно обрабатывают состояния $ h_t $ и выдают основанные на них прогнозы. При этом функция f и веса w остаются неизменными.\n",
    "\n",
    "Самая простая реализация рекуррентной сети будет выглядеть следующим образом (Тангенс здесь используется для введения нелинейности в систему):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0GQ61EU59oD"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-017.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1r03xVhA7Fq"
   },
   "source": [
    "Важное отличие от слоев с которыми мы уже сталкивались, сотоит в том что на выходе мы получаем два объекта Y и H.\n",
    "\n",
    "**Y** - предсказание в текущий момент времени, например метка класса.\n",
    "\n",
    "**H** - контекст в котором предсказание было сделанно. Он может использоваться для дальнейших предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFZYpkzIa1Su"
   },
   "source": [
    "#### RNNCell\n",
    "\n",
    "В Pytorch для вычисления h_t используется модуль [RNNCell](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html)  \n",
    "\n",
    "y_t в нем не вычисляется, предполагается что для его получения в модель должен быть добавлен дополнительный линейный слой.\n",
    "\n",
    "**input_size** -  рамер элемента последовательности.\n",
    "\n",
    "В отличие от сверточных, это всегда вектор а не тензор, поэтому input_size -  скаляр.\n",
    "\n",
    "**hidden_size** - тоже скаляр. Он задает размер скрытого состояния которое тоже является вектором. Фактически это количество нейронов в слое.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXIIpuXM6TNQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "rnn_cell = torch.nn.RNNCell(input_size = 3, hidden_size = 2)\n",
    "dummy_sequence = torch.randn((1,3)) # batch, input_size\n",
    "h = rnn_cell(dummy_sequence) \n",
    "print(\"Out = h\\n\",h.shape,\"\\n\",h) # hidden state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EP3JBVYm7rKr"
   },
   "source": [
    "Внутри происходит примерно следующее:\n",
    "Для понятности в данном примере опущена батчевая обработка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9Bu76IZ7zd2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# Simple RNNcell without a bias and batch support\n",
    "class SimplifiedRNNCell(nn.Module): \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    # Init weight matrix, for simplicity omit bias\n",
    "    self.W_hx = np.random.randn(input_size, hidden_size) * 0.0001 # hidden_size == number of neurons\n",
    "    self.W_hh = np.random.randn(hidden_size, hidden_size) * 0.0001 # naive initialization\n",
    "    self.h0 = np.zeros((hidden_size)) # Initial hidden state\n",
    "  \n",
    "  def forward(self,x,h = None): # Without a batch dimension\n",
    "    if h is None:\n",
    "      h = self.h0\n",
    "    h = np.tanh(self.W_hx.T.dot(x)+self.W_hh.T.dot(h))\n",
    "    return h \n",
    "  \n",
    "simple_rnn_cell = SimplifiedRNNCell(input_size = 3, hidden_size = 2)\n",
    "h = simple_rnn_cell(dummy_sequence[0]) # No batch \n",
    "print(\"Out = h\\n\",h.shape,\"\\n\",h) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyAWauv_9t-J"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndIE9O_c59oH"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-023.png\" width=\"700\">\n",
    "\n",
    "Однако в последовательности всегда несколько элементов. И надо применить алгоритм к каждому.\n",
    "\n",
    "\n",
    " Поэтому RNNCell напрямую не используется. Для него есть обертка: [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) который обеспечивает последовательный вызов RNNCell для всех элементов последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibrnPohqa_C2"
   },
   "source": [
    "### RNN блок в Pytorch \n",
    "\n",
    "**Warning: batch dim is second!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvfG0kC9_-ci"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "rnn = torch.nn.RNN(input_size = 3, hidden_size = 2) # batch_first = True\n",
    "dummy_batched_seq = torch.randn((2,1,3)) # seq_len, batch , input_size\n",
    "out, h = rnn(dummy_batched_seq) \n",
    "print(\"Out = \\n\",out.shape,\"\\n\",out) # hidden state for each element of sequence\n",
    "print(\"h = \\n\",h.shape,\"\\n\",h) # hidden state for last element of sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqoE_24lBA5H"
   },
   "source": [
    "Внутри происходит примено следующее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efP5fBTU-Zzg"
   },
   "outputs": [],
   "source": [
    "# Simple RNN without batching\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "class SimplifiedRNNLayer(nn.Module): \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    self.rnn_cell = SimplifiedRNNCell(input_size, hidden_size)\n",
    "\n",
    "  # Without a batch dimension x have sahape seq_len * input_size\n",
    "  def forward(self,x, h = None):\n",
    "    all_h = []\n",
    "    for i in range(x.shape[0]):\n",
    "      h = self.rnn_cell(x[i],h)\n",
    "      all_h.append(h) \n",
    "    return  np.stack(all_h), h\n",
    "\n",
    "simple_rnn = SimplifiedRNNLayer(input_size = 4, hidden_size = 2)\n",
    "sequence = np.array([[0,1,2,0], [3,4,5,0]]) # batch with one sequence of two elements \n",
    "\n",
    "out, h = simple_rnn(sequence)\n",
    "print(\"Out \\n\",out.shape,out) \n",
    "print(\"h \\n\", h.shape, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zGyq8c_EsR1"
   },
   "source": [
    "Давайте разберемся.\n",
    "\n",
    "К данным добаляется еще одно измерение размер последовательности. Таким образом batch из 6 последовательностей по 5 элементов в каждой будет выглядеть так:\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/rnn_batch.jpeg\" width=\"600\">\n",
    "\n",
    "P.S. Размер самого элемента == 3\n",
    "\n",
    "Внутри RNN модуля элеменым последовательности обрабатываются последовательно:\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/rnn_unrolled.jpeg\" width=\"1000\">\n",
    "\n",
    "Веса при этом используются одни и те же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28-hQXxd7Wgz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn((2,1,3)) #  seq_len, batch, input_size\n",
    "\n",
    "print(\"RNNCell\")\n",
    "rnn_cell = torch.nn.RNNCell(3,2)\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "cell_out = rnn_cell(dummy_input[0,:,:]) # take first element from sequence \n",
    "print(\"Out = h\",cell_out) # one hidden state\n",
    "\n",
    "print(\"RNN\")\n",
    "rnn = torch.nn.RNN(3,2)\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out\", out) # h for all sequence element \n",
    "print(\"h\", h) # h for last element "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a69ZYyFm59ob"
   },
   "source": [
    "Кроме этого RNN блок имеет еще ряд настроек:\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add1.png\" width=\"700\">\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add2.png\" width=\"700\">\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aD9hdsRDYBvp"
   },
   "source": [
    "### Слои (Stacked RNNs)\n",
    "\n",
    "https://discuss.pytorch.org/t/what-is-num-layers-in-rnn-module/9843/2\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/layers.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dh4rE4zcgL3q"
   },
   "source": [
    "h - справа, out - сверху"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMgXuUQePV-D"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn((2,1,3)) #  seq_len,  batch, input_size\n",
    "rnn = torch.nn.RNN(3,2,num_layers=3)\n",
    "\n",
    "# Weights matrix sizes not changed!\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out\", out.shape, out) # Hidden states for all elements from top layer\n",
    "print(\"h\", h.shape, h) # Hidden states for last element for all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5N0mu_SKQIp"
   },
   "source": [
    "https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAc8sNT-b5FJ"
   },
   "source": [
    "### Bidirectional\n",
    "\n",
    "Последовательность можно пропустить через сетьдва раза в прямом и обратном направлении.\n",
    "\n",
    "https://medium.com/analytics-vidhya/understanding-rnn-implementation-in-pytorch-eefdfdb4afdb\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/bidirectional.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15B8_PN3guIt"
   },
   "source": [
    "s штрих 0 - инициаизируется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miU37kF-LGKT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn((2,1,3)) #   seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3,2,bidirectional=True,num_layers=1)\n",
    "\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out\", out) # Concatenated Hidden states from both layers\n",
    "print(\"h\", h) # Hidden states last element from  both : 2*num_layers*hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kNJOMGY59od"
   },
   "source": [
    "### Добавление выходных весов (y_t)\n",
    "\n",
    "Давайте добавим выходные веса. Для этого придется программировать.Воспользуемся параметром batch_first = True что бы batch измерение оказалось на привычном нам месте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDIRNLms59od"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# Let's add output weights\n",
    "\n",
    "class RNN_for_many_to_one(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden, batch_first = True)\n",
    "        self.fc1 = torch.nn.Linear(hidden, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, hidden = self.rnn(x)\n",
    "        print(x.shape) # h for each element\n",
    "        print(hidden.shape) \n",
    "        # we need only last output\n",
    "        #return self.fc1(x[-1])\n",
    "        return self.fc1(hidden)\n",
    "    \n",
    "model2 = RNN_for_many_to_one(28, 128, 10) # input_size, hidden_dim, classes\n",
    "dummy_input = torch.randn((8,28,28)) #  batch , seq_len  , element_size\n",
    "res = model2(dummy_input)\n",
    "# 30 - batch, 50 - output_size\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4P5VAdlPBFP"
   },
   "source": [
    "По умолчанию batch_first =  False и batch измерение становится вторым!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odsB_yAaMSQ5"
   },
   "source": [
    "## Many to one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMIvXTNz59of"
   },
   "source": [
    "## Пример обработки временного ряда\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbl3t16p59of"
   },
   "source": [
    "Что общего у прогнозирования потребления электроэнергии домохозяйствами, оценки трафика на дорогах в определенные периоды, прогнозировании паводков и прогнозировании цены, по которой акции будут торговаться на фондовой бирже?\n",
    "\n",
    "Все они подпадают под понятие данных временных рядов! Вы не можете точно предсказать любой из этих результатов без компонента «время». И по мере того, как в мире вокруг нас генерируется все больше и больше данных, прогнозирование временных рядов становится все более важной областью применения методов ML и DL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0y7DJe3ac-In"
   },
   "source": [
    "### Загрузка данных\n",
    "\n",
    "Air Passengers per month. \n",
    "https://www.kaggle.com/rakannimer/air-passengers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVkY1FwndGZ4"
   },
   "outputs": [],
   "source": [
    "# Dataloading\n",
    "import pandas as pd\n",
    "\n",
    "!if test -f ./airline-passengers.csv; then echo \"Already downloaded\"; else wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv; fi\n",
    "\n",
    "dataset = pd.read_csv('airline-passengers.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnDdggLdexBU"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_data = dataset.iloc[:,1:2].values # перевели dataframe в numpy.array\n",
    "# plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data, label = 'Airline Passangers Data')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_skdvumfAxP"
   },
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQyTvaeUfRHq"
   },
   "outputs": [],
   "source": [
    "# Min - Max normalization\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "training_data -= td_min\n",
    "training_data = training_data / td_max\n",
    "print(training_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha6Nfaxc59oi"
   },
   "source": [
    "### Подготовка данных\n",
    "\n",
    "Поскольку мы хотим научиться предсказывать следующие значение на основе предидущих нам нужно подготовить данные соответствующим образом.\n",
    "\n",
    "Разобьем весь массив данных на фрагменты вида\n",
    "\n",
    "x -> y\n",
    "\n",
    "где х - это подпоследовательность, например строки с 1-й по 8ю, а y - это значение из 9-й строки, то самое которое мы хотим предсказать\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrhmfmgc59oj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# функция создания \"ансамблей\" данных\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)] # seq_len * elements\n",
    "        _y = data[i+seq_length] # one element\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)\n",
    "    \n",
    "# установка длины ансамбля. от нее практически всегда зависит точность предикта и быстродействие\n",
    "seq_length = 8 # сравните 2 и 32\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUPh4eMti5S1"
   },
   "source": [
    "Благодаря такому подходу мы можем работать с RNN моделью так же как работали со сверточными моделями. Подавая на вход такую подпоследовательность + результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyB4eoMajlrq"
   },
   "source": [
    "### Разобьем на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "338EIQMJ59ok"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(y) * 0.8)\n",
    "test_size = len(y) - train_size\n",
    "\n",
    "dataX = torch.Tensor(np.array(x))\n",
    "dataY = torch.Tensor(np.array(y))\n",
    "\n",
    "trainX = torch.Tensor(np.array(x[0:train_size]))\n",
    "trainY = torch.Tensor(np.array(y[0:train_size]))\n",
    "\n",
    "testX = torch.Tensor(np.array(x[train_size:len(x)]))\n",
    "testY = torch.Tensor(np.array(y[train_size:len(y)]))\n",
    "\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT4nRe0x59ok"
   },
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JT_IVh6r59ol"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AirTrafficPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons \n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"x: \",x.shape) # 108 x 8 x 1 : [batch_size, seq_len, input_size] \n",
    "        out, h = self.rnn(x) \n",
    "        #print(\"out: \", out.shape) # 108 x 8 x 4 : [batch_size, seq_len, hidden_size] Useless!\n",
    "        #print(\"h : \", h.shape) # 1 x 108 x 4 [ num_layers, batch_size, hidden_size]\n",
    "        y = self.fc(h)\n",
    "        #print(\"y\",y.shape) # 1 x 108 x 1\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofkSecNA59ol"
   },
   "source": [
    "### Обучение\n",
    "\n",
    "Благодаря подготовке данных процесс обучения не будет отличаться от того что мы использовали на прошедших занятиях.\n",
    "\n",
    "В силу того что датасет маленький, все данные поместились в один batch, итерирования по batch-ам в явном виде здесь не происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "He8S8WcG59om"
   },
   "outputs": [],
   "source": [
    "def time_series_train(model):\n",
    "  num_epochs = 2000\n",
    "  learning_rate = 0.01\n",
    "\n",
    "  criterion = torch.nn.MSELoss() # mean-squared error for regression\n",
    "  optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Train the model\n",
    "  for epoch in range(num_epochs):\n",
    "      outputs, h = model(trainX) # we don't use h there, but we can!\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      # obtain the loss function\n",
    "      loss = criterion(outputs, trainY)\n",
    "      loss.backward()\n",
    "      \n",
    "      optimizer.step()\n",
    "      if epoch % 100 == 0:\n",
    "          print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 4 \n",
    "rnn = AirTrafficPredictor(input_size, hidden_size)\n",
    "time_series_train(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwEYSCy659om"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wz1nb1b559on"
   },
   "outputs": [],
   "source": [
    "def time_series_plot(train_predict):\n",
    "  data_predict = train_predict.data.numpy()\n",
    "  dataY_plot = dataY.data.numpy()\n",
    "\n",
    "  # Denormalize\n",
    "  data_predict = data_predict[0] *td_max + td_min\n",
    "  dataY_plot = dataY_plot *td_max + td_min \n",
    "  #print(data_predict[:15])\n",
    "\n",
    "  # Ploitting\n",
    "  plt.figure(figsize=(12, 4))\n",
    "  plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "  plt.plot(dataY_plot)\n",
    "  plt.plot(data_predict)\n",
    "  plt.suptitle('Time-Series Prediction')\n",
    "  plt.show()\n",
    "\n",
    "rnn.eval()\n",
    "train_predict, h = rnn(dataX)\n",
    "time_series_plot(train_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Lz3ZtNd59og"
   },
   "source": [
    "\n",
    "[Time Series Prediction with LSTM Using PyTorchTime Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQG42Lo__-ir"
   },
   "source": [
    "## Посимвольная генерация текстов\n",
    "\n",
    "https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb\n",
    "\n",
    "Одним из основных направлений использования рекуррентных сетей является работа с текстами:\n",
    "- генерация (Language modeling)\n",
    "и \n",
    "- перевод (Machine Translation)\n",
    "\n",
    "Давайте посмотрим как решаются такого рода задачи.\n",
    "\n",
    "Начнем с относительно простой - посимвольной генерации текста.\n",
    "\n",
    "Постановка задачи:\n",
    "\n",
    "предсказать следующий символ в последовательности.\n",
    "\n",
    "- исходный текст:\n",
    "'hey how are you'\n",
    "\n",
    "- искаженный текст:\n",
    "\n",
    "'hey how are yo'\n",
    "\n",
    "- Верное предсказание:\n",
    "'u'\n",
    "\n",
    "\n",
    "Теоретически эту технику можно использовать для генерации подсказок при наборе текстов, исправления ошибок или восстановления частично утраченного текста.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo3dp1No59oJ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-037.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXFlh4YHQdZT"
   },
   "source": [
    "#### Подготовка данных\n",
    "\n",
    "1. Зафиксировать словарь\n",
    "2. Разбить данные\n",
    "3. Кодирование символов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caGY808uQ_gT"
   },
   "outputs": [],
   "source": [
    "text = ['hey how are you','good i am fine','have a nice day']\n",
    "\n",
    "# Join all the sentences together and extract the unique characters from the combined sentences\n",
    "chars = set(''.join(text))\n",
    "\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}\n",
    "\n",
    "print(char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSXa_rTrRMFA"
   },
   "source": [
    "Вместо ascii символа, каждой букве мы сопоставили номер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFoHx59zRiMR"
   },
   "source": [
    "### Выравнивание данных (Padding)\n",
    "\n",
    "RNN допускают работу с данными переменной длины. Но что бы поместить предложения в batch надо их выровнять.\n",
    "\n",
    "\n",
    "Обычно размер батча делают равным самому длинному предложению, а остальные просто дополняют пробелами до этого размера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJp9MLFDSTVz"
   },
   "outputs": [],
   "source": [
    "maxlen = len(max(text, key=len))\n",
    "print(\"The longest string has {} characters\".format(maxlen))\n",
    "\n",
    "# A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "for i in range(len(text)):\n",
    "    while len(text[i])<maxlen:\n",
    "        text[i] += ' '\n",
    "\n",
    "print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uw4MiqEbTD8J"
   },
   "source": [
    "### Разбиение данных\n",
    "\n",
    "\n",
    "\n",
    "В качестве входа будем использовать предложение без последнего символа:\n",
    "\n",
    "**'hey how are yo'**\n",
    "\n",
    ", а в качестве результата - предложение в котором он сгенерирован.\n",
    "\n",
    "**'ey how are you'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ysz6hn9vTClx"
   },
   "outputs": [],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "    \n",
    "    # Remove firsts character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "    print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-_FVzAuVGyt"
   },
   "source": [
    "Как видим вравнивание служит здесь плохую службу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJQSb9x1U8S_"
   },
   "source": [
    "### Кодирование\n",
    "\n",
    "Теперь символы надо перевести в числа. Для этого мы уже построили словарь.\n",
    "\n",
    "P.S. Запускать блок только один раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZtNcmkiVNsG"
   },
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "print(\"Input\",input_seq)\n",
    "print(\"Target\",input_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZV0pm0rWL28"
   },
   "source": [
    "#### One-hot-encoding(!)\n",
    "\n",
    "Теперь из чисел надо сделать вектора. \n",
    "\n",
    "\n",
    "Почему бы не оставить числа?\n",
    "В прошлом примере модель хорошо с ними работала.\n",
    "\n",
    "В прошлом примере использовася MSE и на выходе было число.\n",
    "\n",
    "Если бы мы определили отношение порядка над номерами букв, то что-то подобное можно было бы сделать.\n",
    "\n",
    "Однако сейчас мы предсказываем класс буквы.\n",
    "Поэтому на входе и на выходе должен быть вектор.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/softmax_1.png\" width=\"200\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcReT5zlW72p"
   },
   "outputs": [],
   "source": [
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(text)\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    \n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features\n",
    "\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
    "print(\"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(input_seq.shape))\n",
    "print(input_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuDdiK9gX3Vq"
   },
   "source": [
    "Каждый символ закодировали вектором.\n",
    "Не слишьком экономно, зато удобно умножать на матрицу весов.\n",
    "\n",
    "P.S. Запускать только один раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DlI5x6Vddal"
   },
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "input_seq = torch.Tensor(input_seq)\n",
    "target_seq = torch.Tensor(target_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPRUjTiXYclC"
   },
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gn9VLynTYa4q"
   },
   "outputs": [],
   "source": [
    "class NextCharacterGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size = hidden_dim, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden_0 = torch.zeros(1, batch_size, self.rnn.hidden_size) # 1 correspond to number of layers\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden_0)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # Need Only if n_layers > 1\n",
    "        out = out.contiguous().view(-1, self.rnn.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZluFC1jcuIX"
   },
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYOcJMbOcXyT"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = NextCharacterGenerator(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training Run\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4bEcFbiejyQ"
   },
   "source": [
    "Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGrhj5xrembN"
   },
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "    \n",
    "    out, hidden = model(character)\n",
    "    #print(out.shape)\n",
    "    #print(out)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden\n",
    "\n",
    "def sample(model, out_len, start='hey'):\n",
    "    model.eval() # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)\n",
    "\n",
    "sample(model, 15, 'good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6JlfkOnprsa"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/softmax_2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPHmL7KAQPks"
   },
   "source": [
    "Результаты которые удается получить при помощи моделей обученных на больших объемах данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVimIAxn59oM"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-050.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXVtreJf59oM"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-054.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiNFe9iU59oN"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-055.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up7JNs5k59oO"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-058.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OytMng1j59oO"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-059.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PugAiQp59oP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-061.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbUYi24c59oP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-063.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qr0fyK1EAJQU"
   },
   "source": [
    "### Explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0E_aXSMz59oP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-064.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W3YSrKW59oQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-065.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS2ggUPi59oQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-066.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNYnYTA859oQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-067.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jno-Vn6E59oQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-068.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yS5OYvg59oQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-069.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpBpcC5n59oS"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-068.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XM5n1xR59oT"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-069.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxXw4l47_fkA"
   },
   "source": [
    "##Обратное распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOnYVBCa59oJ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-045.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuFR9ZRy59oK"
   },
   "source": [
    "Теоритетески можно было бы сразу пропустить все данные через сеть и затем вычислить градиент.\n",
    "\n",
    "Но:\n",
    " - Большие последовательности не поместятся в памяти\n",
    " - Возникнут проблеммы исчезновения/взрыва градиента, так как цепочка будет очень длинной\n",
    " - Контекст затирается (по аналогии с ResNet)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgYzq8wyBopK"
   },
   "source": [
    "### Пакеты\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukDHDbQY59oK"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-046.png\" width=\"700\">\n",
    "\n",
    "Поэтому снова возникает потребность в обработке по батчам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyhGiMB_59oL"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-047.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnjYN9ew59oI"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-030.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsExayEz59oL"
   },
   "source": [
    "Скрытые состояния при этом сохраняются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo7MxLry59oZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-083.png\" width=\"700\">\n",
    "\n",
    "Градиент в рекуррентных сетях затухает так же быстро. И при большой длине последовательности это становится критичным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLFByMFy59oZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-086.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ovx8AUFe59oa"
   },
   "source": [
    "Исчезающий/взрывающийся градиент (Vanishing/exploding gradient) - явления исчезающего и взрывающегося градиента часто встречаются в контексте RNN. Причина, по которой они происходят, заключается в том, что трудно уловить долгосрочные зависимости из-за мультипликативного градиента, который может экспоненциально уменьшаться/увеличиваться по отношению к числу слоев.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-023.png\" width=\"700\">\n",
    "\n",
    "Градиентное отсечение (Gradient clipping) - метод, используемый для решения проблемы взрывающегося градиента, иногда возникающей при выполнении обратного распространения. Ограничивая максимальное значение градиента, это явление контролируется на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6QIH71l59ob"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gradient-clipping.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gradient-vanishing-exploding.png\" width=\"700\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "import torch.\n",
    "\n",
    "threshold = 100 # Must be found empirically\n",
    "\n",
    "for sequences, labels in train_loader:\n",
    "        optimizer.zero_grad() \n",
    "        output = model(sequences)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward() \n",
    "        # Add clippeng after backward\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), threshold)\n",
    "        # Before step\n",
    "        optimizer.step()\n",
    "```\n",
    "\n",
    "https://stackoverflow.com/questions/54716377/how-to-do-gradient-clipping-in-pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CQPFl5wAeyX"
   },
   "source": [
    "## LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z71j3Zcp59od"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-090.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMfwNI5L59oe"
   },
   "source": [
    "Если в Vanilla RNN был только один путь, то в LSTM есть highway для сокращения информации  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pw06xnTr59oe"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/lstm.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh3uu10ic7Bh"
   },
   "source": [
    "* i = Input\n",
    "* f = Forget\n",
    "* o = Output\n",
    "* g = Gate\n",
    "\n",
    "\n",
    "\n",
    "1. Конкатенируем x и h_t-1\n",
    "2. Умножаем на веса\n",
    "3. Результат делим на 4 части (shape = hidden_size) к каждой применяем свою функцию активации\n",
    "4. Далее комбинируем их с входами и выходами\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTYGjknp59od"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-094.png\" width=\"700\">\n",
    "\n",
    " i = Input  f = Forget  o = Output  g = Gate\n",
    "\n",
    " Операция \"кружек с точкой\" - это поэлементной умножение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iB11OMKSykRc"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrE47hqt59od"
   },
   "source": [
    "Таким образом мы получили магистраль для градиента аналогично ResNet.\n",
    "\n",
    "Однако надо отметить что статья вышла в 1997г(!)\n",
    "\n",
    "https://www.bioinf.jku.at/publications/older/2604.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWmtWwGM59oe"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-095.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJM_DYI1hQcX"
   },
   "source": [
    "### LSTMCell\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html\n",
    "\n",
    "Интерфейс отличается от RNNCell количеством входов и выходов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96XURiOhhHkQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lstm_cell = torch.nn.LSTMCell(input_size = 3, hidden_size = 4)\n",
    "dummy_input = torch.randn(1,3) # batch, input_size\n",
    "h_0 = torch.randn(1,4)\n",
    "c_0 = torch.randn(1,4)\n",
    "h, c = lstm_cell(dummy_input, (h_0,c_0)) # second arg is tuple\n",
    "print(\"h\",h.shape,h) # batch, hidden_size\n",
    "print(\"c\",c.shape,c) # batch, hidden_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17bRYkF-jvgW"
   },
   "source": [
    "### LSTM in Pytorch\n",
    "\n",
    "Отличие состоит в том что возвращается кроме h возвращается еще и c. Но можно использовать только output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1Agfg5Yj86z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "lstm = nn.LSTM(input_size = 3, hidden_size = 3)\n",
    "dummy_input = torch.randn(2,1,3) # seq_len, batch, input_size\n",
    "out, (h, c) = lstm(dummy_input) # h and c returned in tuple\n",
    "print(\"out\",out.shape,out) # seq_len, batch, hidden_size : h for each element\n",
    "print(\"h\",h.shape,h) # batch, hidden_size\n",
    "print(\"c\",c.shape,c) # batch, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwMyhNRIlc5c"
   },
   "source": [
    "### Пример использования \n",
    "\n",
    "Что бы убедиться в работоспособности конструкции заменим RNN блок на LSTM в задаче предсказания временного ряда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fJX5httmI4N"
   },
   "outputs": [],
   "source": [
    "# Define new LSTM based model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMAirTrafficPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons \n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h,c) = self.lstm(x) \n",
    "        y = self.fc(h)\n",
    "        return y\n",
    "\n",
    "lstm =  LSTMAirTrafficPredictor(input_size =1 , hidden_size =4 )\n",
    "di = torch.randn((108,8,1))\n",
    "out = lstm(di)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMCZ7g1qqiAT"
   },
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCSwQKKMnIlN"
   },
   "outputs": [],
   "source": [
    "lstm.train()\n",
    "\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = torch.nn.MSELoss() # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    " # Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(trainX) \n",
    "    optimizer.zero_grad()\n",
    "    #print(outputs.shape)\n",
    "    loss = criterion(outputs, trainY.unsqueeze(0))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsxTqfCnq16V"
   },
   "outputs": [],
   "source": [
    "lstm.eval()\n",
    "train_predict = lstm(dataX)\n",
    "time_series_plot(train_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4dPL9ywAydU"
   },
   "source": [
    "## GRU (Gated reccurent unit)\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/gru1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLQmr9Vv3CNI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "rnn = torch.nn.GRU(input_size = 4, hidden_size =3)\n",
    "input = torch.randn(2, 1, 4) #seq_len, batch, input_size\n",
    "h0 = torch.randn(1, 1, 3)\n",
    "output, h = rnn(input, h0)\n",
    "\n",
    "print(\"Out\",output.shape,\"\\n\",output) # seq_len = 2\n",
    "print(\"h\",h.shape,\"\\n\",h) # last h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9bJukJb59oe"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-101.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfj-AChX59of"
   },
   "source": [
    "Были предприняты попытки с помощью эволюционного поиска найти более оптимальный юнит для RNN. \n",
    "\n",
    "*Поиск шел в пространстве формул для обновления состояний*\n",
    "\n",
    "Тем не менее, никакого значительного улучшения качва достигнуто не было относительно LSTM, именно поэтому LSTM является оптимальой архитектурой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQTkOpV-A7g1"
   },
   "source": [
    "## Architecture search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fi_IGUXQ59of"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-102.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhxqkk9-59oo"
   },
   "source": [
    "## Sequence-to-Sequence with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-m81sAv59oo"
   },
   "source": [
    "* Сейчас мы пытаемся решить задачу sequence to sequence\n",
    "* Орабатывая входную последовательность, мы хотим обобщить всю информацию, которая в ней содержится в некий вектор С\n",
    "* Далее мы передаем этот вектор во вторую RNN, которая является декодером\n",
    "\n",
    "\n",
    "Мы используем вектор С для передачи информации между энкодером и декодером, также мы предполагаем, что вектор С обощает всю информацию, которая небходима декодеру для генерации выходных последовательности.\n",
    "\n",
    "Однако использование единственного вектора для предоставления информации может работать только для последовательностей малой длины (неразумно предполагать, что информация с длинной последовательностью можно сжать в один вектор) \n",
    "\n",
    "Именно поэтому нам нужен некий механизм, который будет обходить \"бутылочное горлышко\" и не сжимать всю информацию в один вектор С. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UniGfQyd59oo"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-011.png\" width=\"700\">\n",
    "\n",
    "В качестве С и So может использоваться просто h_4 (последнее скрытое состояние)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4GGJkYNcFmK"
   },
   "source": [
    "### Машинный перевод\n",
    "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "дополнительно:\n",
    "https://pytorch.org/tutorials/beginner/torchtext_translation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3OMe0bxeU3-"
   },
   "source": [
    "#### Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBrmBanHcCZU"
   },
   "outputs": [],
   "source": [
    "!wget https://download.pytorch.org/tutorial/data.zip\n",
    "!unzip data.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UP_Ol3nee1pn"
   },
   "outputs": [],
   "source": [
    "! sed -n 200,210p  data/eng-fra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSnieQNAct6i"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKbOzPIilLNM"
   },
   "source": [
    "Класс для хранения слов. Работает аналогично символам:\n",
    "Создается словарь из всех слов и таким образом каждое слово получает свой индекс (номер).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_wyBRlSlIpE"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lc3nEENTlOzh"
   },
   "source": [
    "Вспомогательные методы для загрузки пар фраз из файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiYK9wgtlaS3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(file_name):\n",
    "  print(\"Reading lines...\")\n",
    "\n",
    "  # Read the file and split into lines\n",
    "  lines = open(file_name, encoding='utf-8').\\\n",
    "      read().strip().split('\\n')\n",
    "\n",
    "  # Split every line into pairs and normalize\n",
    "  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "  # Make Lang instances\n",
    "  input_lang = Lang('en')\n",
    "  output_lang = Lang('fr')\n",
    "\n",
    "  return input_lang, output_lang, pairs\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[0].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(file_name):\n",
    "    input_lang, output_lang, pairs = readLangs(file_name)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('data/eng-fra.txt')\n",
    "for i in range(5):\n",
    "  print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJ4_tr_KFdfv"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkYZaI3_odHQ"
   },
   "source": [
    "Теперь в нашем распоряжении есть два словаря и набор пар строк.\n",
    "Определим структуру модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_WonT3xo834"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        print(input_size)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden = None):\n",
    "        embedded = self.embedding(input)\n",
    "        print(\"Embedding: \",embedded.shape)\n",
    "        output, hidden = self.gru(embedded.view(1, 1, -1), hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "\n",
    "training_pair = pairs[0]\n",
    "\n",
    "input_tensor = training_pair[0]\n",
    "target_tensor = training_pair[1]\n",
    "\n",
    "input_tensor = tensorFromSentence(input_lang, input_tensor)\n",
    "target_tensor = tensorFromSentence(output_lang, target_tensor)\n",
    "\n",
    "print(\"Input tensor\",input_tensor.shape,input_tensor)\n",
    "\n",
    "encoder_hidden = encoder.initHidden()\n",
    "encoder_outputs, hidden = encoder(input_tensor[0])\n",
    "\n",
    "print(\"Out\",encoder_outputs.shape)\n",
    "print(\"Hidden\",hidden.shape)\n",
    "#dummy_input = torch_randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyn-omIH5eTY"
   },
   "source": [
    "Вместо one_hot - векторов, используются эмбеддинги размером 1x256 (hidden size)\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5r6G9Sxxpm63"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size ):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "decoder = DecoderRNN(output_lang.n_words, hidden_size) # hidden state must have the same sizes\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "# Use encoder last state as decoder init\n",
    "decoder_hidden = encoder_hidden\n",
    "\n",
    "decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden )\n",
    "print(\"Output: \", decoder_output.shape)\n",
    "#https://pytorch.org/docs/stable/generated/torch.topk.html\n",
    "top_val, top_index = decoder_output.topk(1) # Returns the k largest elements of the given input tensor\n",
    "\n",
    "generated_word = output_lang.index2word[top_index.item()]\n",
    "print(\"Word: \", generated_word, \"index \", top_index.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d4tfnVHp1Se"
   },
   "source": [
    "#### Обучение\n",
    "\n",
    "В на вход модели будем подавать индексы слов для первой части пары из одного словаря, а на выходе ожидать индексы для соответствующей пары из другого. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZC4OfBGo9nbo"
   },
   "outputs": [],
   "source": [
    "target_length = target_tensor.size(0)\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "for di in range(target_length):\n",
    "  decoder_output, decoder_hidden, = decoder( decoder_input, decoder_hidden)\n",
    "  topv, topi = decoder_output.topk(1)\n",
    "  decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "  #loss += criterion(decoder_output, target_tensor[di])\n",
    "  generated_word = output_lang.index2word[decoder_input.item()]\n",
    "  print(\"Word: \", generated_word, \"index \", decoder_input)\n",
    "\n",
    "  if decoder_input.item() == EOS_token:\n",
    "      break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccHuwngi59oo"
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5DhWpu559op"
   },
   "source": [
    "### Sequence-to-Sequence with RNNs and Attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRkkR8SZ59op"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-011.png\" width=\"700\">\n",
    "\n",
    "Давайте позволим нашему декодеру, используя context vector, фокусироваться на определенных выходах энкодера. \n",
    "\n",
    "Для этого будем вычислять context vector и вводим некую фцию $F_{att}$ , котрая будет вычислять alignment score (функцию похожести) между внутренними состояниями декодера и энкодера.\n",
    "\n",
    "После этого, вычисленные alignment scores мы пропускаем через softmax для нормализации. Таким образом мы получаем веса, которые говорят о том, насколько сильно мы хотим сфокусироваться на соответствующим им выходам энкодера.\n",
    "\n",
    "Затем мы просто берем взевенную сумму внутренних состояний энкодера и передаем ее на вход декодеру. Данный алгоритм выполняем на каждом шаге декодера.\n",
    "\n",
    "Функция $F_{att}$ может являться небольшой нейросетью или неким линейным преобразованием. Однако это не так важно, идея заключается в том, что мы не говорим явно на чем функция должна сосредотачиваться в конкретной задаче. Применив к ней back propagation, ее веса сами настроятся на необходимые точки фокусировки.\n",
    "\n",
    "**То есть функция сама разберется на чем фокусироваться**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyG0KoFH59op"
   },
   "source": [
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-017.png\" width=\"700\">\n",
    "\n",
    "Веса a_i,j - это числа от 0 до 1 \n",
    "\n",
    "каждое h_i поэлементно умножается на свой вес, затем все h_i суммируются"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpgIoECt59oq"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-020.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLY_hB_b59oq"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-021.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWSJNWnJCfHr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "MAX_LENGTH = 17\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size,  max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        # ****** Attention ***************************************************\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        # ********************************************************************\n",
    "\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "\n",
    "        # ****** Attention ***************************************************\n",
    "        att_inputs = torch.cat((embedded[0], hidden[0]), 1) # S0 + Start token (Y0)\n",
    "        print(\"att_inputs\",att_inputs.shape,\"256 + 256\") # 256 + 256\n",
    "        e = self.attn(att_inputs) \n",
    "        print(\"e \",e.shape) # MAX_INPUT == number of hidden states\n",
    "        attn_weights = F.softmax( e, dim=1) \n",
    "        print(\"a (attn_weights) \",attn_weights.shape) # MAX_INPUT\n",
    "        print(\"H (encoder_outputs)\",encoder_outputs.unsqueeze(0).shape)\n",
    "        # bmm is matrix product wark as elemet-wise multiplication + sum\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        print(\"C Attn_applied\",attn_applied.shape)\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        print(\"C with YO\",output.shape)\n",
    "\n",
    "        # *********************************************************************\n",
    "        \n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "# Fake hidden states from encoder\n",
    "encoder_outputs = torch.randn(MAX_LENGTH, encoder.hidden_size, device=device)\n",
    "\n",
    "att_rnn_decoder = AttnDecoderRNN(output_lang.n_words, hidden_size ) # output_size == word count in target dictionary\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "decoder_hidden = encoder_hidden\n",
    "\n",
    "output, hidden, attn_weights = att_rnn_decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAcPBwcg59os"
   },
   "source": [
    "Давайте посмотрим как фокусировка работает на примере перевода с английского на французский \n",
    "\n",
    "Как мы знаем, на каждом шаге генерируется набор весов, которые отвечают за фокусировку на том или ином месте входной последовательности. Как мы видим, английское предложение имеет иной порядок слов относительно французского. Например, в английском варианте словосочетание **European Economic Area**, в то время как во французском **zone économique européenne**. \n",
    "\n",
    "В английском прилагательные идут перед существительным, в то время как во французском языке наоборот. \n",
    "\n",
    "Таким образом, благодаря гибкости модели, мы можем обрабатывать и учитывать разный порядок слов в разных языках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw4t5HPd59ot"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-025.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mmb-3wYS59ot"
   },
   "source": [
    "* Механизм внимания не обязательно должен принимать на вход последовательность. \n",
    "\n",
    "* Мы можем применять его, в том числе для генерации подписей для картинок. Входом в данном случае будет являться сетка признаков, которая была получена при применении сверточной сети к картинке. \n",
    "\n",
    "* Далее по этой сетке мы считаем веса внимания и делаем аналогично первому примеру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpIecJji59ou"
   },
   "source": [
    "### Image Captioning with RNNs and Attention\n",
    "\n",
    "Модели, основанные на внимании (attention) намного более продвинутые, нежели обычные нейросети. Они могут концентрироваться на отдельных частях изображения, что позволяет избежать зашумления данных.\n",
    "\n",
    "Идея состоит в том, что свёрточная сеть теперь будет генерировать не один вектор, описывающий всё изображение, а набор векторов для нескольких участков исходного снимка. В дополнение к работе со словарём на каждом временном шаге модель также производит распределение по точкам на изображении, которые она обрабатывает в данный момент. Это позволяет ей научиться находить наиболее важные участки, на которых необходимо фокусироваться.\n",
    "\n",
    "После обучения модели можно увидеть, что она как бы переносит своё внимание по изображению для каждого генерируемого слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLNqB-PI59ot"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-028.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sibhw8259ot"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-031.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xtknlAv59ou"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-036.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eFIraJd59ou"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-037.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JALrz2tO59ov"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-038.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aSmxI1R59ov"
   },
   "source": [
    "\n",
    "Также нейросети, основанные на внимании, повсеместно используются для ответов на визуальные вопросы (Visual Question Answering). Цель этой задачи — обучить модель отвечать на вопрос по изображению. Например, она должна уметь не только называть сами объекты на фотографии, но и считать их, распознавать цвета и оценивать расположение относительно друг друга. Мы уже рассказывали о подобных архитектурах в статье о том, как такие нейросети могут помочь незрячим людям и о нейро-символическом мышлении.\n",
    "\n",
    "ссылка https://www.reg.ru/blog/nejroset-opisyvaet-mir-nezryachim-lyudyam/ ссылка https://www.reg.ru/blog/uchim-nejroseti-rassuzhdat-o-tom-chto-oni-vidyat/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REy44gHf59ov"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-039.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWwY-sf759ov"
   },
   "source": [
    "### X, Attend, and Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXRjvSbC59ow"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-044.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmZ3lokD59o8"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-105.png\" width=\"700\">\n",
    "\n",
    "\n",
    "Идея Attention фактически убила рекуррентные сети.\n",
    "На идее Attention появились такие слои как SelfAttention и Transformer.\n",
    "\n",
    "Они принамают на вход последовательность целиком.\n",
    "\n",
    "Основные успехи в области NLP в последние пару лет связанны уже с ними."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpLNXC5d59o6"
   },
   "source": [
    "### The Transformer: Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovXsjPT059o7"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-100.png\" width=\"700\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "colab": {
   "name": "L08_RNN.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "EJQSb9x1U8S_",
    "lZV0pm0rWL28"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
