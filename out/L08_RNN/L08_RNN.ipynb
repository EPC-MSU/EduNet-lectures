{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Рекуррентные нейронные сети (RNN)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Особенности\r\n",
    "\r\n",
    "До этого мы работали с методами машинного обучения, которые работают с признаковым описанием фиксированной длины.\r\n",
    "\r\n",
    "Это верно про табличные данные &mdash; обычно каждый объект в таких данных описан фиксированным набором признаков, и новые признаки не могут появиться \"вдруг\". Мы точно знаем, что на вход нам приходит объект размера 100, а на выходе мы должны для него предсказать 1 число. \r\n",
    "\r\n",
    "Верно это и про данные с фотографий &mdash; обычно наша нейросеть учится на изображениях определенного разрешения. Да, иногда мы делаем нейросеть, которая способна работать с изображением почти любого разрешения, но добиваемся мы этого за счет вставки слоев global pooling, которые просто приводят любое признаковое описание, полученнное нашей нейросетью, а точнее, ее сверточной частью, ранее, к фиксированному размеру. \r\n",
    "\r\n",
    "Однако многие данные такой структурой не обладают. К примеру &mdash; тексты. Возьмем все абзацы из \"Войны и Мира\". Какие-то будут больше, какие-то меньше. И обрезать их как-то нельзя. Аналогично будет и для текстов из твиттера и тд. И что делать, если мы хотим предсказывать, например, эмоциональную окрашенность текста? \r\n",
    "\r\n",
    "Более того, а что делать, если, к примеру, на основе абзаца текста нам необходимо сгенерировать его краткое содержание? То есть и выход у нас может быть разной длины. Аналогично &mdash; мы хотим по данным о курсе валюты за прошлый год спрогнозировать курс валюты на следующий месяц по дням. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"https://edunet.kea.su/repo/src/L01_Intro/img/mp/types3.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Таким образом, у нас есть целый набор задач, для которых необходима особая структура нейросети, позволяющая так или иначе принимать данные разного размера. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Типы задач\n",
    "\n",
    "**Анализ временных рядов**\n",
    "- Табличные данные\n",
    "- Аннотирование изображений и видео (Image/Video captioning)\n",
    "- Машинный перевод\n",
    "- Распознавание текста\n",
    "- Распознавание речи\n",
    "\n",
    "**Генеративные модели**\n",
    "- Генерация текста/речи (чат - боты)\n",
    "- Генерация изображений\n",
    "\n",
    "**Классификация**\n",
    "- Изображения\n",
    "- Блоки текста (Sentiment analysis)\n",
    "\n",
    "\n",
    "Общее для задач - мы имеем возможность сохранять информацию, сформированную при обработке одного слова, и использовать ее, когда мы анализируем дальнейшие слова."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "До прихода нейронных сетей предложения пытались описать при помощи набора правил - грамматик, которые довольно успешно могли генерировать новые осмысленные предложения. Так выглядит разбор при помощи грамматик простого предложения \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/1200px-ParseTree.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Однако грамматики плохо учитывали более глобальные связи. Например, очень тяжело было добиться того, чтобы в абзаце текста:\n",
    "\n",
    "\"Леша пришел домой. Он будет есть рыбу\"\n",
    "\n",
    "компьютер понял, что во втором предложении \"Он\" сооттветствует \"Леше\". \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Основная идея, которая заключается в RNN состоит в следующем &mdash; а давайте возьмем и всю последовательность пропустим через одну и туже нейросеть. \r\n",
    "Но при этом сама нейросеть кроме следующего элемента последовательности (например, слова в тексте), будет принимать еще один параметр &mdash; некий $h$, который в начале будет, например, вектором из нулей, а далее &mdash; значением, которое выдает сама нейросеть после обработки очередного элемента последовательности (**токена**)\r\n",
    "\r\n",
    "В этом $h$ будет храниться hidden state, скрытое состояние, учитывающее и локальный, и глобальный контекст."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/1_SKGAqkVVzT6co-sZ29ze-g.png\" width=\"800\">\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](https://en.wikipedia.org/wiki/Recurrent_neural_network)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "При этом наша нейросеть может выдавать некий ответ на каждом шаге, но мы можем:\r\n",
    "\r\n",
    " 1. использовать только выданное на последнем (если нам нужно предсказать одно значение) &mdash; many-to-one\r\n",
    "\r\n",
    " 2. мы можем подавать в наше нейросетку токены (когда кончился исходный сигнал &mdash; подаем нулевые токены), пока она не сгенеирует сигнал стоп (many-to-many, one-to-many)\r\n",
    "\r\n",
    " 3. можем делать различные комбинации, игнорируя выходы нейросети в начале"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В зависимости от структуры входов и выходов, можно выделить несколько типов рекуррентных нейронных сетей:\r\n",
    "\r\n",
    "One-to-one &mdash; обычная нейронная сеть, RNN здесь не нужно\r\n",
    "\r\n",
    "Более сложной является реализация «one to many», когда у нас есть всего один вход и нам необходимо сформировать несколько выходов. Такой тип нейронной сети актуален, когда мы говорим о генерации музыки или текстов Мы задаем начальное слово или начальный звук, а дальше модель начинает самостоятельно генерировать выходы, в качестве входа к очередной ячейке рассматривая выход с прошлой ячейки нейронной сети.\r\n",
    "\r\n",
    " Если мы рассматриваем задачу классификации, то актуальна схема «many to one». Мы должны проанализировать все входы нейронной сети и только в конце определиться с классом.\r\n",
    " \r\n",
    "  Схему «many to many», когда количество выходов равно количеству входов нейронной сети, мы рассмотрели на примере с определением части речи. Такой вид используется также в задачах NER, которые мы обсудим в следующем видео. \r\n",
    "  \r\n",
    "Ну и последней разновидностью нейронных сетей является сеть вида «many to many», когда количество выходов нейронной сети не равно количеству входов. Это актуально, к примеру, в машинном переводе, когда одна и та же фраза может иметь разное количество слов в разных языках (т.е. это реализует схему энкодер-декодер). Энкодер получает данные различной длины &mdash; например, предложение на английском языке. С помощью скрытых состояний он формирует из исходных данных вектор, который затем передаётся в декодер. Последний, в свою очередь, генерирует из полученного вектора выходные данные &mdash; исходную фразу, переведённую на другой язык."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-011-1.png\" width=\"1000\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Можно объединять разные подходы. Сначала генерируем некий $h$, который содержит сжатую информацию о том, что было подано в нейросеть, а затем подаем его в нейросеть one-to-many, которая генерирует, к примеру, перевод того, текста, что был подан первой части нейросети. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"https://camo.githubusercontent.com/784aa789a413acf72ff98ab1ae6c2e984a871a35/687474703a2f2f6564756e65742e6b65612e73752f7265706f2f7372632f4c30385f524e4e2f696d672f3439385f4641323031395f6c65637475726531322d3033302e706e67\" width=\"1000\">\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Базовый RNN блок"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Попробуем подробнее разобраться, что же происходит в загадочном зелёном прямоугольнике с надписью RNN. Внутри него мы вычисляем рекуррентное соотношение с помощью функции $f$, которая зависит от весов $w$. Чтобы найти новое состояние $h_t$, мы берём предыдущее скрытое состояние $ h_{t-1} $, а также текущий ввод xt. Когда мы отправляем в модель следующие входные данные, полученное нами скрытое состояние $ h_t $ передаётся в эту же функцию, и весь процесс повторяется.\r\n",
    "\r\n",
    "Чтобы генерировать вывод в каждый момент времени, в модель добавляются полносвязные слои, которые постоянно обрабатывают состояния $ h_t $ и выдают основанные на них прогнозы. При этом функция $f$ и веса $w$ остаются неизменными.\r\n",
    "\r\n",
    "Самая простая реализация рекуррентной сети будет выглядеть следующим образом (Тангенс здесь используется для введения нелинейности в систему):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-017.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Важное отличие от слоев с которыми мы уже сталкивались, сотоит в том что на выходе мы получаем два объекта Y и H.\n",
    "\n",
    "**Y** - предсказание в текущий момент времени, например метка класса.\n",
    "\n",
    "**H** - контекст в котором предсказание было сделанно. Он может использоваться для дальнейших предсказаний."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### RNNCell\r\n",
    "\r\n",
    "В Pytorch для вычисления $h_t$ используется модуль [RNNCell](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html)  \r\n",
    "\r\n",
    "$y_t$ в нем не вычисляется, предполагается что для его получения в модель должен быть добавлен дополнительный линейный слой.\r\n",
    "\r\n",
    "**`input_size`** &mdash;  рамер элемента последовательности.\r\n",
    "\r\n",
    "В отличие от сверточных, это всегда вектор а не тензор, поэтому `input_size` &mdash;  скаляр.\r\n",
    "\r\n",
    "**`hidden_size`** &mdash; тоже скаляр. Он задает размер скрытого состояния которое тоже является вектором. Фактически это количество нейронов в слое.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "\r\n",
    "rnn_cell = torch.nn.RNNCell(input_size = 3, hidden_size = 2)\r\n",
    "dummy_sequence = torch.randn((1, 3)) # batch, input_size\r\n",
    "h = rnn_cell(dummy_sequence) \r\n",
    "print(f\"Out = h\\n{h.shape} \\n{h}\")  # hidden state "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Внутри происходит примерно следующее:\n",
    "Для понятности в данном примере опущена батчевая обработка."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "from torch import nn\r\n",
    "\r\n",
    "# Simple RNNcell without a bias and batch support\r\n",
    "class SimplifiedRNNCell(nn.Module): \r\n",
    "  def __init__(self, input_size, hidden_size):\r\n",
    "    super().__init__()\r\n",
    "    # Init weight matrix, for simplicity omit bias\r\n",
    "    self.W_hx = np.random.randn(input_size, hidden_size) * 0.0001 # hidden_size == number of neurons\r\n",
    "    self.W_hh = np.random.randn(hidden_size, hidden_size) * 0.0001 # naive initialization\r\n",
    "    self.h0 = np.zeros((hidden_size)) # Initial hidden state\r\n",
    "  \r\n",
    "  def forward(self,x,h = None): # Without a batch dimension\r\n",
    "    if h is None:\r\n",
    "      h = self.h0\r\n",
    "    h = np.tanh(self.W_hx.T.dot(x)+self.W_hh.T.dot(h))\r\n",
    "    return h \r\n",
    "  \r\n",
    "simple_rnn_cell = SimplifiedRNNCell(input_size = 3, hidden_size = 2)\r\n",
    "h = simple_rnn_cell(dummy_sequence[0]) # No batch \r\n",
    "print(f\"Out = h\\n{h.shape} \\n{h}\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-023.png\" width=\"900\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Однако в последовательности всегда несколько элементов. И надо применить алгоритм к каждому.\n",
    "\n",
    "\n",
    " Поэтому RNNCell напрямую не используется. Для него есть обертка: [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) который обеспечивает последовательный вызов RNNCell для всех элементов последовательности."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RNN блок в Pytorch \n",
    "\n",
    "**Warning: batch dim is second!**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch import nn\r\n",
    "rnn = torch.nn.RNN(input_size = 3, hidden_size = 2) # batch_first = True\r\n",
    "dummy_batched_seq = torch.randn((2, 1, 3)) # seq_len, batch , input_size\r\n",
    "out, h = rnn(dummy_batched_seq) \r\n",
    "print(\"Out = \\n\", out.shape,\"\\n\", out) # hidden state for each element of sequence\r\n",
    "print(\"h = \\n\", h.shape, \"\\n\", h) # hidden state for last element of sequence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Внутри происходит примерно следующее"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Simple RNN without batching\r\n",
    "import numpy as np\r\n",
    "from torch import nn\r\n",
    "\r\n",
    "class SimplifiedRNNLayer(nn.Module): \r\n",
    "  def __init__(self, input_size, hidden_size):\r\n",
    "    super().__init__()\r\n",
    "    self.rnn_cell = SimplifiedRNNCell(input_size, hidden_size)\r\n",
    "\r\n",
    "  # Without a batch dimension x have sahape seq_len * input_size\r\n",
    "  def forward(self,x, h = None):\r\n",
    "    all_h = []\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "      h = self.rnn_cell(x[i],h)\r\n",
    "      all_h.append(h) \r\n",
    "    return  np.stack(all_h), h\r\n",
    "\r\n",
    "simple_rnn = SimplifiedRNNLayer(input_size = 4, hidden_size = 2)\r\n",
    "sequence = np.array([[0,1,2,0], [3,4,5,0]]) # batch with one sequence of two elements \r\n",
    "\r\n",
    "out, h = simple_rnn(sequence)\r\n",
    "print(\"Out \\n\",out.shape,out) \r\n",
    "print(\"h \\n\", h.shape, h)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте разберемся.\n",
    "\n",
    "К данным добаляется еще одно измерение размер последовательности. Таким образом batch из 6 последовательностей по 5 элементов в каждой будет выглядеть так:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/rnn_batch.png\" width=\"600\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "P.S. Размер самого элемента == 3\n",
    "\n",
    "Внутри RNN модуля элеменым последовательности обрабатываются последовательно:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/rnn_unrolled.jpeg\" width=\"1000\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка]()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Веса при этом используются одни и те же."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "\r\n",
    "dummy_input = torch.randn((2,1,3)) #  seq_len, batch, input_size\r\n",
    "\r\n",
    "print(\"RNNCell\")\r\n",
    "rnn_cell = torch.nn.RNNCell(3,2)\r\n",
    "for t, p in rnn_cell.named_parameters():\r\n",
    "  print(t, p.shape) \r\n",
    "\r\n",
    "cell_out = rnn_cell(dummy_input[0,:,:]) # take first element from sequence \r\n",
    "print(\"Out = h\", cell_out) # one hidden state\r\n",
    "\r\n",
    "print(\"RNN\")\r\n",
    "rnn = torch.nn.RNN(3,2)\r\n",
    "for t, p in rnn_cell.named_parameters():\r\n",
    "  print(t, p.shape) \r\n",
    "\r\n",
    "out, h = rnn(dummy_input)\r\n",
    "\r\n",
    "print(\"Out\", out) # h for all sequence element \r\n",
    "print(\"h\", h) # h for last element "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### $\\color{brown}{\\text{*Stacked RNNs}}$\n",
    "\n",
    "[Ссылка на статью What is num_layers in RNN module?](https://discuss.pytorch.org/t/what-is-num-layers-in-rnn-module/9843/2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/layers.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "h - справа, out - сверху"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "\r\n",
    "dummy_input = torch.randn((2,1,3)) #  seq_len,  batch, input_size\r\n",
    "rnn = torch.nn.RNN(3,2,num_layers=3)\r\n",
    "\r\n",
    "# Weights matrix sizes not changed!\r\n",
    "for t, p in rnn_cell.named_parameters():\r\n",
    "  print(t, p.shape) \r\n",
    "\r\n",
    "out, h = rnn(dummy_input)\r\n",
    "\r\n",
    "print(\"Out\", out.shape, out) # Hidden states for all elements from top layer\r\n",
    "print(\"h\", h.shape, h) # Hidden states for last element for all layers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### $\\color{brown}{\\text{*Bidirectional}}$\n",
    "Последовательность можно пропустить через сетьдва раза в прямом и обратном направлении.\n",
    "\n",
    "[Cсылка на статью Understanding RNN implementation in PyTorch](https://medium.com/analytics-vidhya/understanding-rnn-implementation-in-pytorch-eefdfdb4afdb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/bidirectional.png\" width=\"850\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$s'_0$ - инициаизируется"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "\r\n",
    "dummy_input = torch.randn((2, 1, 3)) #   seq_len, batch, input_size\r\n",
    "rnn = torch.nn.RNN(3, 2, bidirectional=True, num_layers=1)\r\n",
    "\r\n",
    "for t, p in rnn_cell.named_parameters():\r\n",
    "  print(t, p.shape) \r\n",
    "\r\n",
    "out, h = rnn(dummy_input)\r\n",
    "\r\n",
    "print(\"Out\", out) # Concatenated Hidden states from both layers\r\n",
    "print(\"h\", h) # Hidden states last element from  both : 2*num_layers*hidden_state"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### $\\color{brown}{\\text{*Добавление выходных весов (y_t)}}$\n",
    "Давайте добавим выходные веса. Для этого придется программировать.Воспользуемся параметром batch_first = True что бы batch измерение оказалось на привычном нам месте."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "# Let's add output weights\r\n",
    "\r\n",
    "class RNN_for_many_to_one(torch.nn.Module):\r\n",
    "    def __init__(self, input_size, hidden, output_size):\r\n",
    "        super().__init__()\r\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden, batch_first = True)\r\n",
    "        self.fc1 = torch.nn.Linear(hidden, output_size)\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        x, hidden = self.rnn(x)\r\n",
    "        print(x.shape) # h for each element\r\n",
    "        print(hidden.shape) \r\n",
    "        # we need only last output\r\n",
    "        return self.fc1(hidden) # get last output equivalent to self.fc1(x[:,-1,:])\r\n",
    "    \r\n",
    "model2 = RNN_for_many_to_one(28, 128, 10) # input_size, hidden_dim, classes\r\n",
    "dummy_input = torch.randn((8, 28, 28)) #  batch, seq_len, element_size\r\n",
    "res = model2(dummy_input)\r\n",
    "# 30 - batch, 50 - output_size\r\n",
    "print(res.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "По умолчанию `batch_first=False` и batch измерение становится вторым!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Пример обработки временного ряда\n",
    "\n",
    "---\n",
    "- [A Gentle Introduction to Handling a Non-Stationary Time Series in Python](https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/)\n",
    "- [A comprehensive beginner’s guide to create a Time Series Forecast](https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/)\n",
    "- [Detecting stationarity in time series data](https://towardsdatascience.com/detecting-stationarity-in-time-series-data-d29e0a21e638)\n",
    "- [Most useful Python functions for Time Series Analysis](https://towardsdatascience.com/most-useful-python-functions-for-time-series-analysis-ed1a9cb3aa8b)\n",
    "- [Data transformations and forecasting models: what to use and whenData transformations and forecasting models: what to use and when](https://people.duke.edu/~rnau/whatuse.htmhttps://people.duke.edu/~rnau/whatuse.htm)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Что общего у прогнозирования потребления электроэнергии домохозяйствами, оценки трафика на дорогах в определенные периоды, прогнозировании паводков и прогнозировании цены, по которой акции будут торговаться на фондовой бирже?\n",
    "\n",
    "Все они подпадают под понятие данных временных рядов! Вы не можете точно предсказать любой из этих результатов без компонента «время». И по мере того, как в мире вокруг нас генерируется все больше и больше данных, прогнозирование временных рядов становится все более важной областью применения методов ML и DL.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Сделаем предикт с помощью Deep Learning\r\n",
    "----\r\n",
    "\r\n",
    "[Time Series Prediction with LSTM Using PyTorchTime Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\r\n",
    "\r\n",
    "- Загрузка данных\r\n",
    "- Шкалирование\r\n",
    "- Формирование ансамблей данных \r\n",
    "- Traning\r\n",
    "- Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Загрузка данных\n",
    "\n",
    "Air Passengers per month. \n",
    "[Dataset Air Passengers Number of air passengers per month](https://www.kaggle.com/rakannimer/air-passengers)\n",
    "\n",
    "\n",
    "[Time Series Prediction with LSTM Using PyTorchTime Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dataloading\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "!if test -f ./airline-passengers.csv; then echo \"Already downloaded\"; else wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv; fi\r\n",
    "\r\n",
    "dataset = pd.read_csv('airline-passengers.csv')\r\n",
    "dataset.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "training_data = dataset.iloc[:,1:2].values # перевели dataframe в numpy.array\r\n",
    "# plotting\r\n",
    "plt.figure(figsize=(12, 4))\r\n",
    "plt.plot(training_data, label = 'Airline Passangers Data')\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Шкалирование данных"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Min - Max normalization\r\n",
    "td_min = training_data.min()\r\n",
    "td_max = training_data.max()\r\n",
    "training_data -= td_min\r\n",
    "training_data = training_data / td_max\r\n",
    "print(training_data[:5])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Формирование ансамблей данных\r\n",
    "\r\n",
    "Поскольку мы хотим научиться предсказывать следующие значение на основе предидущих нам нужно подготовить данные соответствующим образом.\r\n",
    "\r\n",
    "Разобьем весь массив данных на фрагменты вида\r\n",
    "\r\n",
    "x -> y\r\n",
    "\r\n",
    "где х - это подпоследовательность, например строки с 1-й по 8-ю, а y - это значение из 9-й строки, то самое которое мы хотим предсказать\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "# функция создания \"ансамблей\" данных\r\n",
    "def sliding_windows(data, seq_length):\r\n",
    "    x = []\r\n",
    "    y = []\r\n",
    "\r\n",
    "    for i in range(len(data)-seq_length-1):\r\n",
    "        _x = data[i:(i+seq_length)] # seq_len * elements\r\n",
    "        _y = data[i+seq_length] # one element\r\n",
    "        x.append(_x)\r\n",
    "        y.append(_y)\r\n",
    "\r\n",
    "    return np.array(x),np.array(y)\r\n",
    "    \r\n",
    "# установка длины ансамбля. от нее практически всегда зависит точность предикта и быстродействие\r\n",
    "seq_length = 8 # сравните 2 и 32\r\n",
    "x, y = sliding_windows(training_data, seq_length)\r\n",
    "x[0], y[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Благодаря такому подходу мы можем работать с RNN моделью так же как работали со сверточными моделями. Подавая на вход такую подпоследовательность + результат."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Разобьем на train и test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_size = int(len(y) * 0.8)\r\n",
    "test_size = len(y) - train_size\r\n",
    "\r\n",
    "dataX = torch.Tensor(np.array(x))\r\n",
    "dataY = torch.Tensor(np.array(y))\r\n",
    "\r\n",
    "trainX = torch.Tensor(np.array(x[0:train_size]))\r\n",
    "trainY = torch.Tensor(np.array(y[0:train_size]))\r\n",
    "\r\n",
    "testX = torch.Tensor(np.array(x[train_size:len(x)]))\r\n",
    "testY = torch.Tensor(np.array(y[train_size:len(y)]))\r\n",
    "\r\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class AirTrafficPredictor(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self, input_size, hidden_size):\r\n",
    "        # hidden_size == number of neurons \r\n",
    "        super().__init__()\r\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first = True)\r\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        #print(\"x: \",x.shape) # 108 x 8 x 1 : [batch_size, seq_len, input_size] \r\n",
    "        out, h = self.rnn(x) \r\n",
    "        #print(\"out: \", out.shape) # 108 x 8 x 4 : [batch_size, seq_len, hidden_size] Useless!\r\n",
    "        #print(\"h : \", h.shape) # 1 x 108 x 4 [ num_layers, batch_size, hidden_size]\r\n",
    "        y = self.fc(h)\r\n",
    "        #print(\"y\",y.shape) # 1 x 108 x 1\r\n",
    "        return y, h"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Обучение\n",
    "\n",
    "Благодаря подготовке данных процесс обучения не будет отличаться от того что мы использовали на прошедших занятиях.\n",
    "\n",
    "В силу того что датасет маленький, все данные поместились в один batch, итерирования по batch-ам в явном виде здесь не происходит."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def time_series_train(model):\r\n",
    "  num_epochs = 2000\r\n",
    "  learning_rate = 0.01\r\n",
    "\r\n",
    "  criterion = torch.nn.MSELoss() # mean-squared error for regression\r\n",
    "  optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\r\n",
    "\r\n",
    "  # Train the model\r\n",
    "  for epoch in range(num_epochs):\r\n",
    "      outputs, h = model(trainX) # we don't use h there, but we can!\r\n",
    "      optimizer.zero_grad()\r\n",
    "      \r\n",
    "      # obtain the loss function\r\n",
    "      loss = criterion(outputs, trainY)\r\n",
    "      loss.backward()\r\n",
    "      \r\n",
    "      optimizer.step()\r\n",
    "      if epoch % 100 == 0:\r\n",
    "          print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\r\n",
    "\r\n",
    "input_size = 1\r\n",
    "hidden_size = 4 \r\n",
    "rnn = AirTrafficPredictor(input_size, hidden_size)\r\n",
    "time_series_train(rnn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def time_series_plot(train_predict):\r\n",
    "  data_predict = train_predict.data.numpy()\r\n",
    "  dataY_plot = dataY.data.numpy()\r\n",
    "\r\n",
    "  # Denormalize\r\n",
    "  data_predict = data_predict[0] *td_max + td_min\r\n",
    "  dataY_plot = dataY_plot *td_max + td_min \r\n",
    "  #print(data_predict[:15])\r\n",
    "\r\n",
    "  # Ploitting\r\n",
    "  plt.figure(figsize=(12, 4))\r\n",
    "  plt.axvline(x=train_size, c='r', linestyle='--')\r\n",
    "\r\n",
    "  plt.plot(dataY_plot)\r\n",
    "  plt.plot(data_predict)\r\n",
    "  plt.suptitle('Time-Series Prediction')\r\n",
    "  plt.show()\r\n",
    "\r\n",
    "rnn.eval()\r\n",
    "train_predict, h = rnn(dataX)\r\n",
    "time_series_plot(train_predict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "[Time Series Prediction with LSTM Using PyTorchTime Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Посимвольная генерация текстов\n",
    "\n",
    "[Github RNN-walkthrough/main.ipynb](https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb)\n",
    "\n",
    "Одним из основных направлений использования рекуррентных сетей является работа с текстами:\n",
    "- генерация (Language modeling)\n",
    "и \n",
    "- перевод (Machine Translation)\n",
    "\n",
    "Давайте посмотрим как решаются такого рода задачи.\n",
    "\n",
    "Начнем с относительно простой - посимвольной генерации текста.\n",
    "\n",
    "Постановка задачи:\n",
    "\n",
    "предсказать следующий символ в последовательности.\n",
    "\n",
    "- исходный текст:\n",
    "'hey how are you'\n",
    "\n",
    "- искаженный текст:\n",
    "\n",
    "'hey how are yo'\n",
    "\n",
    "- Верное предсказание:\n",
    "'u'\n",
    "\n",
    "\n",
    "Теоретически эту технику можно использовать для генерации подсказок при наборе текстов, исправления ошибок или восстановления частично утраченного текста.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-037.gif\" width=\"400\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Подготовка данных\n",
    "\n",
    "1. Зафиксировать словарь\n",
    "2. Разбить данные\n",
    "3. Кодирование символов "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "text = ['hey how are you','good i am fine','have a nice day']\r\n",
    "\r\n",
    "# Join all the sentences together and extract the unique characters from the combined sentences\r\n",
    "chars = set(''.join(text))\r\n",
    "\r\n",
    "# Creating a dictionary that maps integers to the characters\r\n",
    "int2char = dict(enumerate(chars))\r\n",
    "\r\n",
    "# Creating another dictionary that maps characters to integers\r\n",
    "char2int = {char: ind for ind, char in int2char.items()}\r\n",
    "\r\n",
    "print(char2int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вместо ASCII символа, каждой букве мы сопоставили номер."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Выравнивание данных (Padding)\n",
    "\n",
    "RNN допускают работу с данными переменной длины. Но что бы поместить предложения в batch надо их выровнять.\n",
    "\n",
    "\n",
    "Обычно размер батча делают равным самому длинному предложению, а остальные просто дополняют пробелами до этого размера."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "maxlen = len(max(text, key=len))\r\n",
    "print(\"The longest string has {} characters\".format(maxlen))\r\n",
    "\r\n",
    "# A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of the sentence matches\r\n",
    "# the length of the longest sentence\r\n",
    "for i in range(len(text)):\r\n",
    "    while len(text[i])<maxlen:\r\n",
    "        text[i] += ' '\r\n",
    "\r\n",
    "print(text)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Разбиение данных\n",
    "\n",
    "\n",
    "\n",
    "В качестве входа будем использовать предложение без последнего символа:\n",
    "\n",
    "**'hey how are yo'**\n",
    "\n",
    ", а в качестве результата - предложение в котором он сгенерирован.\n",
    "\n",
    "**'ey how are you'**\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creating lists that will hold our input and target sequences\r\n",
    "input_seq = []\r\n",
    "target_seq = []\r\n",
    "\r\n",
    "for i in range(len(text)):\r\n",
    "    # Remove last character for input sequence\r\n",
    "    input_seq.append(text[i][:-1])\r\n",
    "    \r\n",
    "    # Remove firsts character for target sequence\r\n",
    "    target_seq.append(text[i][1:])\r\n",
    "    print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как видим вравнивание служит здесь плохую службу."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Кодирование\n",
    "\n",
    "Теперь символы надо перевести в числа. Для этого мы уже построили словарь.\n",
    "\n",
    "P.S. Запускать блок только один раз."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(len(text)):\r\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\r\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\r\n",
    "\r\n",
    "print(\"Input\",input_seq)\r\n",
    "print(\"Target\",input_seq)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### One-hot-encoding(!)\n",
    "\n",
    "Теперь из чисел надо сделать вектора. \n",
    "\n",
    "\n",
    "Почему бы не оставить числа?\n",
    "В прошлом примере модель хорошо с ними работала.\n",
    "\n",
    "В прошлом примере использовася MSE и на выходе было число.\n",
    "\n",
    "Если бы мы определили отношение порядка над номерами букв, то что-то подобное можно было бы сделать.\n",
    "\n",
    "Однако сейчас мы предсказываем класс буквы.\n",
    "Поэтому на входе и на выходе должен быть вектор."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/softmax_1.png\" width=\"250\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dict_size = len(char2int)\r\n",
    "seq_len = maxlen - 1\r\n",
    "batch_size = len(text)\r\n",
    "\r\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\r\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\r\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\r\n",
    "    \r\n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\r\n",
    "    for i in range(batch_size):\r\n",
    "        for u in range(seq_len):\r\n",
    "            features[i, u, sequence[i][u]] = 1\r\n",
    "    return features\r\n",
    "\r\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\r\n",
    "print(\"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(input_seq.shape))\r\n",
    "print(input_seq[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Каждый символ закодировали вектором.\n",
    "Не слишьком экономно, зато удобно умножать на матрицу весов.\n",
    "\n",
    "P.S. Запускать только один раз"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert data to tensor\r\n",
    "input_seq = torch.Tensor(input_seq)\r\n",
    "target_seq = torch.Tensor(target_seq)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Модель"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class NextCharacterGenerator(nn.Module):\r\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        # RNN Layer\r\n",
    "        self.rnn = nn.RNN(input_size, hidden_size = hidden_dim, batch_first=True)   \r\n",
    "        # Fully connected layer\r\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        batch_size = x.size(0)\r\n",
    "        #Initializing hidden state for first input using method defined below\r\n",
    "        hidden_0 = torch.zeros(1, batch_size, self.rnn.hidden_size) # 1 correspond to number of layers\r\n",
    "\r\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\r\n",
    "        out, hidden = self.rnn(x, hidden_0)\r\n",
    "        \r\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\r\n",
    "        # Need Only if n_layers > 1\r\n",
    "        out = out.contiguous().view(-1, self.rnn.hidden_size)\r\n",
    "        out = self.fc(out)\r\n",
    "        \r\n",
    "        return out, hidden"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Обучение"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Instantiate the model with hyperparameters\r\n",
    "model = NextCharacterGenerator(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\r\n",
    "\r\n",
    "# Define hyperparameters\r\n",
    "n_epochs = 100\r\n",
    "\r\n",
    "# Define Loss, Optimizer\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\r\n",
    "\r\n",
    "# Training Run\r\n",
    "for epoch in range(1, n_epochs + 1):\r\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\r\n",
    "    output, hidden = model(input_seq)\r\n",
    "    loss = criterion(output, target_seq.view(-1).long())\r\n",
    "    loss.backward() # Does backpropagation and calculates gradients\r\n",
    "    optimizer.step() # Updates the weights accordingly\r\n",
    "    \r\n",
    "    if epoch%10 == 0:\r\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\r\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Тест"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predict(model, character):\r\n",
    "    # One-hot encoding our input to fit into the model\r\n",
    "    character = np.array([[char2int[c] for c in character]])\r\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\r\n",
    "    character = torch.from_numpy(character)\r\n",
    "    \r\n",
    "    out, hidden = model(character)\r\n",
    "    #print(out.shape)\r\n",
    "    #print(out)\r\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\r\n",
    "    # Taking the class with the highest probability score from the output\r\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\r\n",
    "\r\n",
    "    return int2char[char_ind], hidden\r\n",
    "\r\n",
    "def sample(model, out_len, start='hey'):\r\n",
    "    model.eval() # eval mode\r\n",
    "    start = start.lower()\r\n",
    "    # First off, run through the starting characters\r\n",
    "    chars = [ch for ch in start]\r\n",
    "    size = out_len - len(chars)\r\n",
    "    # Now pass in the previous characters and get a new one\r\n",
    "    for ii in range(size):\r\n",
    "        char, h = predict(model, chars)\r\n",
    "        chars.append(char)\r\n",
    "\r\n",
    "    return ''.join(chars)\r\n",
    "\r\n",
    "sample(model, 15, 'good')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/softmax_2.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## $\\color{brown}{\\text{*Примеры применения}}$\n",
    "\n",
    "Результаты которые удается получить при помощи моделей обученных на больших объемах данных."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-050.png\" width=\"750\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-054.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-055.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-058.png\" width=\"850\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-059.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-059-1.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](https://github.com/torvalds/linux)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-061.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-063.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### $\\color{brown}{\\text{*Explanation}}$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-064.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-065.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-066.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-067.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-068.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-069.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-068.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-069.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](https://arxiv.org/abs/1506.02078)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## $\\color{brown}{\\text{*Как пропускать градиент через RNN}}$\r\n",
    "\r\n",
    "В случае с реккурентными сетями есть проблема с распространением градиента - если последовательность большая, то потребуется очень много времени"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-045.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теоритетески можно было бы сразу пропустить все данные через сеть и затем вычислить градиент.\n",
    "\n",
    "Но:\n",
    " - Большие последовательности не поместятся в памяти\n",
    " - Возникнут проблеммы исчезновения/взрыва градиента, так как цепочка будет очень длинной\n",
    " - Контекст затирается (по аналогии с ResNet)\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Потому иногда делают пропускание градиента только через части последовательности, окнами. За счет этого получается меньшие затраты по памяти\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-046.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Или можно пропускать только на сколько-то позиций от выхода - тоже можно, веса одни и те же используются, потому вполне возможно, что поправки от последних действий хватит, чтобы выправить нейросеть в целом"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Также градиент в рекуррентных сетях быстро затухает. И при большой длине последовательности это становится критичным."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-047.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Скрытые состояния при этом сохраняются."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-083.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-086.png\" width=\"1000\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Исчезающий/взрывающийся градиент (Vanishing/exploding gradient) &mdash; явления исчезающего и взрывающегося градиента часто встречаются в контексте RNN. Причина, по которой они происходят, заключается в том, что трудно уловить долгосрочные зависимости из-за мультипликативного градиента, который может экспоненциально уменьшаться/увеличиваться по отношению к числу слоев."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture12-023.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Градиентное отсечение (Gradient clipping) &mdash; метод, используемый для решения проблемы взрывающегося градиента, иногда возникающей при выполнении обратного распространения. Ограничивая максимальное значение градиента, это явление контролируется на практике."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gradient-clipping.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gradient-vanishing-exploding.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "import torch.\n",
    "\n",
    "threshold = 100 # Must be found empirically\n",
    "\n",
    "for sequences, labels in train_loader:\n",
    "        optimizer.zero_grad() \n",
    "        output = model(sequences)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward() \n",
    "        # Add clippeng after backward\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), threshold)\n",
    "        # Before step\n",
    "        optimizer.step()\n",
    "```\n",
    "\n",
    "[stackoverflow How to do gradient clipping in pytorch?](https://stackoverflow.com/questions/54716377/how-to-do-gradient-clipping-in-pytorch)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ванильное RNN имело множество проблем, в том числе, в нем очень быстро затухала информация о предыдущих словах в предложении. Помимо этого, были проблемы с затухением/взрывом самого градиента. \n",
    "\n",
    "Эти проблемы были частично решены в LSTM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-090.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Если в Vanilla RNN был только один путь, то в LSTM есть highway для сокращения информации  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/lstm.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Была предложена концепция gate \"врат\", в которых решается, какая информация и как будет добавлена к главному потоку - $c$\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* i = Input - преобразуем результат обработки текущего объекта и состояния h в сигнал от 0 до 1\n",
    "* g = Gate - решаем, на основе результатов же обработки текущего объекта и состояния h, какую часть из преобразованной информации добавим/вычтем из потока c.  \n",
    "* f = Forget - опять же, на основе результатов обработки текущего объекта  и состояния h решаем, какую часть информации из c можно забыть \n",
    "* o = Output - формируем на основе нового c и результатов обработки текущего объекта  и состояния h новое состояние h\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Конкатенируем x и h_t-1\n",
    "2. Умножаем на веса\n",
    "3. Результат делим на 4 части (shape = hidden_size) к каждой применяем свою функцию активации\n",
    "4. Далее комбинируем их с входами и выходами\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-094.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](https://medium.com/@saurabh.rathor092/simple-rnn-vs-gru-vs-lstm-difference-lies-in-more-flexible-control-5f33e07b1e57)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " i = Input  f = Forget  o = Output  g = Gate\n",
    "\n",
    " Операция \"кружек с точкой\" - это поэлементной умножение."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Таким образом мы получили магистраль для градиента аналогично ResNet.\n",
    "\n",
    "Однако надо отметить что статья вышла в 1997г(!)\n",
    "\n",
    "\n",
    "[Long short-term memory](https://www.bioinf.jku.at/publications/older/2604.pdf)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTMCell\n",
    "\n",
    "[pytorch LSTMCELL](https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
    "\n",
    "Интерфейс отличается от RNNCell количеством входов и выходов\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "\r\n",
    "lstm_cell = torch.nn.LSTMCell(input_size = 3, hidden_size = 4)\r\n",
    "dummy_input = torch.randn(1,3) # batch, input_size\r\n",
    "h_0 = torch.randn(1,4)\r\n",
    "c_0 = torch.randn(1,4)\r\n",
    "h, c = lstm_cell(dummy_input, (h_0,c_0)) # second arg is tuple\r\n",
    "print(\"h\",h.shape,h) # batch, hidden_size\r\n",
    "print(\"c\",c.shape,c) # batch, hidden_size\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM in Pytorch\n",
    "\n",
    "Отличие состоит в том что возвращается кроме h возвращается еще и c. Но можно использовать только output. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "lstm = nn.LSTM(input_size = 3, hidden_size = 3)\r\n",
    "dummy_input = torch.randn(2,1,3) # seq_len, batch, input_size\r\n",
    "out, (h, c) = lstm(dummy_input) # h and c returned in tuple\r\n",
    "print(\"out\",out.shape,out) # seq_len, batch, hidden_size : h for each element\r\n",
    "print(\"h\",h.shape,h) # batch, hidden_size\r\n",
    "print(\"c\",c.shape,c) # batch, hidden_size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Пример использования \n",
    "\n",
    "Что бы убедиться в работоспособности конструкции заменим RNN блок на LSTM в задаче предсказания временного ряда."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define new LSTM based model\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "class LSTMAirTrafficPredictor(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self, input_size, hidden_size):\r\n",
    "        # hidden_size == number of neurons \r\n",
    "        super().__init__()\r\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first = True)\r\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out, (h,c) = self.lstm(x) \r\n",
    "        y = self.fc(h)\r\n",
    "        return y\r\n",
    "\r\n",
    "lstm =  LSTMAirTrafficPredictor(input_size =1 , hidden_size =4 )\r\n",
    "di = torch.randn((108,8,1))\r\n",
    "out = lstm(di)\r\n",
    "print(out.shape)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lstm.train()\r\n",
    "\r\n",
    "num_epochs = 2000\r\n",
    "learning_rate = 0.01\r\n",
    "\r\n",
    "criterion = torch.nn.MSELoss() # mean-squared error for regression\r\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\r\n",
    "\r\n",
    " # Train the model\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    outputs = lstm(trainX) \r\n",
    "    optimizer.zero_grad()\r\n",
    "    #print(outputs.shape)\r\n",
    "    loss = criterion(outputs, trainY.unsqueeze(0))\r\n",
    "    loss.backward()\r\n",
    "    \r\n",
    "    optimizer.step()\r\n",
    "    if epoch % 100 == 0:\r\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lstm.eval()\r\n",
    "train_predict = lstm(dataX)\r\n",
    "time_series_plot(train_predict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Выводы:\r\n",
    "---\r\n",
    "1. Использование LSTM слоев при прогнозировании нестационарных временных рядов - отличное решение, тк нейронка способна самостоятельно выденить динамики изменениях составляющих временного ряда. Правда, в более сложных случаях (трейдинге, например, или чтении и расшивровки волн мозга) приходится прибегать к feature ingineering\r\n",
    "2. Сложость нейронной сети должна быть адекватна сложности подаваемых в нее данных. С ростом ансамбля и числа нейронов увеличивается заучивание тренировочной выборки и теряется способность к обощению\r\n",
    "3. Предварительный анализ цикличности в данных (если она есть) помогает понять оптимальный размер ансамбля (тут видно, что цикл в среднем составляет 8 интервалов)\r\n",
    "4. Также результат может зависеть от типа скалирования, который Вы применяете. Нужно знать принципы работы скаллеров и не стесняться экспериментировать с ними. См. статьи: [Data Preprocessing with Scikit-Learn: Standardization and Scaling](https://towardsdatascience.com/data-preprocessing-with-scikit-learn-standardization-and-scaling-cfb695280412) и [Gradient Descent, the Learning Rate, and the importance of Feature Scaling](https://towardsdatascience.com/gradient-descent-the-learning-rate-and-the-importance-of-feature-scaling-6c0b416596e1)\r\n",
    "5. При всей выгодности приненении нейронных сетей, необходимо быть осторожным с автокорреляцией (см статью [Avoiding the pitfalls](https://towardsdatascience.com/how-not-to-use-machine-learning-for-time-series-forecasting-avoiding-the-pitfalls-19f9d7adf424))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GRU (Gated reccurent unit)\n",
    "\n",
    "LSTM выглядела очень громоздко. Потому решили искать более  компактную структуру. Так получили GRU"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/gru1.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](https://medium.com/@saurabh.rathor092/simple-rnn-vs-gru-vs-lstm-difference-lies-in-more-flexible-control-5f33e07b1e57)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "rnn = torch.nn.GRU(input_size = 4, hidden_size =3)\r\n",
    "input = torch.randn(2, 1, 4) #seq_len, batch, input_size\r\n",
    "h0 = torch.randn(1, 1, 3)\r\n",
    "output, h = rnn(input, h0)\r\n",
    "\r\n",
    "print(\"Out\",output.shape,\"\\n\",output) # seq_len = 2\r\n",
    "print(\"h\",h.shape,\"\\n\",h) # last h\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Иногда лучше работает GRU, иногда &mdash; LSTM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sequence-to-Sequence with RNNs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Сейчас мы пытаемся решить задачу sequence to sequence\n",
    "* Орабатывая входную последовательность, мы хотим обобщить всю информацию, которая в ней содержится в некий вектор С\n",
    "* Далее мы передаем этот вектор во вторую RNN, которая является декодером\n",
    "\n",
    "\n",
    "Мы используем вектор С для передачи информации между энкодером и декодером, также мы предполагаем, что вектор С обощает всю информацию, которая небходима декодеру для генерации выходных последовательности."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture13-011.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В качестве С и So может использоваться просто h_4 (последнее скрытое состояние)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Машинный перевод\n",
    "[pytorch NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "\n",
    "дополнительно:\n",
    "[pytorch LANGUAGE TRANSLATION WITH TORCHTEXT](https://pytorch.org/tutorials/beginner/torchtext_translation.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Загрузка и предобработка данных"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!wget https://download.pytorch.org/tutorial/data.zip\r\n",
    "!unzip data.zip"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! sed -n 200,210p  data/eng-fra.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from __future__ import unicode_literals, print_function, division\r\n",
    "from io import open\r\n",
    "import unicodedata\r\n",
    "import string\r\n",
    "import re\r\n",
    "import random\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch import optim\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Класс для хранения слов. Работает аналогично символам:\n",
    "Создается словарь из всех слов и таким образом каждое слово получает свой индекс (номер).  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "SOS_token = 0\r\n",
    "EOS_token = 1\r\n",
    "\r\n",
    "\r\n",
    "class Lang:\r\n",
    "    def __init__(self, name):\r\n",
    "        self.name = name\r\n",
    "        self.word2index = {}\r\n",
    "        self.word2count = {}\r\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n",
    "        self.n_words = 2  # Count SOS and EOS\r\n",
    "\r\n",
    "    def addSentence(self, sentence):\r\n",
    "        for word in sentence.split(' '):\r\n",
    "            self.addWord(word)\r\n",
    "\r\n",
    "    def addWord(self, word):\r\n",
    "        if word not in self.word2index:\r\n",
    "            self.word2index[word] = self.n_words\r\n",
    "            self.word2count[word] = 1\r\n",
    "            self.index2word[self.n_words] = word\r\n",
    "            self.n_words += 1\r\n",
    "        else:\r\n",
    "            self.word2count[word] += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вспомогательные методы для загрузки пар фраз из файла."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\r\n",
    "\r\n",
    "# Turn a Unicode string to plain ASCII, thanks to\r\n",
    "# https://stackoverflow.com/a/518232/2809427\r\n",
    "def unicodeToAscii(s):\r\n",
    "    return ''.join(\r\n",
    "        c for c in unicodedata.normalize('NFD', s)\r\n",
    "        if unicodedata.category(c) != 'Mn'\r\n",
    "    )\r\n",
    "\r\n",
    "# Lowercase, trim, and remove non-letter characters\r\n",
    "def normalizeString(s):\r\n",
    "    s = unicodeToAscii(s.lower().strip())\r\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\r\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n",
    "    return s\r\n",
    "\r\n",
    "def readLangs(file_name):\r\n",
    "  print(\"Reading lines...\")\r\n",
    "\r\n",
    "  # Read the file and split into lines\r\n",
    "  lines = open(file_name, encoding='utf-8').\\\r\n",
    "      read().strip().split('\\n')\r\n",
    "\r\n",
    "  # Split every line into pairs and normalize\r\n",
    "  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\r\n",
    "\r\n",
    "  # Make Lang instances\r\n",
    "  input_lang = Lang('en')\r\n",
    "  output_lang = Lang('fr')\r\n",
    "\r\n",
    "  return input_lang, output_lang, pairs\r\n",
    "\r\n",
    "MAX_LENGTH = 10\r\n",
    "\r\n",
    "eng_prefixes = (\r\n",
    "    \"i am \", \"i m \",\r\n",
    "    \"he is\", \"he s \",\r\n",
    "    \"she is\", \"she s \",\r\n",
    "    \"you are\", \"you re \",\r\n",
    "    \"we are\", \"we re \",\r\n",
    "    \"they are\", \"they re \"\r\n",
    ")\r\n",
    "\r\n",
    "def filterPair(p):\r\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\r\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\r\n",
    "        p[0].startswith(eng_prefixes)\r\n",
    "\r\n",
    "def filterPairs(pairs):\r\n",
    "    return [pair for pair in pairs if filterPair(pair)]\r\n",
    "\r\n",
    "def prepareData(file_name):\r\n",
    "    input_lang, output_lang, pairs = readLangs(file_name)\r\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\r\n",
    "    pairs = filterPairs(pairs)\r\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\r\n",
    "    print(\"Counting words...\")\r\n",
    "    for pair in pairs:\r\n",
    "        input_lang.addSentence(pair[0])\r\n",
    "        output_lang.addSentence(pair[1])\r\n",
    "    print(\"Counted words:\")\r\n",
    "    print(input_lang.name, input_lang.n_words)\r\n",
    "    print(output_lang.name, output_lang.n_words)\r\n",
    "    return input_lang, output_lang, pairs\r\n",
    "\r\n",
    "\r\n",
    "input_lang, output_lang, pairs = prepareData('data/eng-fra.txt')\r\n",
    "for i in range(5):\r\n",
    "  print(random.choice(pairs))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def indexesFromSentence(lang, sentence):\r\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\r\n",
    "\r\n",
    "\r\n",
    "def tensorFromSentence(lang, sentence):\r\n",
    "    indexes = indexesFromSentence(lang, sentence)\r\n",
    "    indexes.append(EOS_token)\r\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\r\n",
    "\r\n",
    "\r\n",
    "def tensorsFromPair(pair):\r\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\r\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\r\n",
    "    return (input_tensor, target_tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь в нашем распоряжении есть два словаря и набор пар строк.\n",
    "Определим структуру модели."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch import nn\r\n",
    "class EncoderRNN(nn.Module):\r\n",
    "    def __init__(self, input_size, hidden_size):\r\n",
    "        super(EncoderRNN, self).__init__()\r\n",
    "        print(input_size)\r\n",
    "        self.hidden_size = hidden_size\r\n",
    "\r\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\r\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\r\n",
    "\r\n",
    "    def forward(self, input, hidden = None):\r\n",
    "        embedded = self.embedding(input)\r\n",
    "        print(\"Embedding: \",embedded.shape)\r\n",
    "        output, hidden = self.gru(embedded.view(1, 1, -1), hidden)\r\n",
    "        return output, hidden\r\n",
    "\r\n",
    "    def initHidden(self):\r\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n",
    "\r\n",
    "\r\n",
    "hidden_size = 256\r\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\r\n",
    "\r\n",
    "training_pair = pairs[0]\r\n",
    "\r\n",
    "input_tensor = training_pair[0]\r\n",
    "target_tensor = training_pair[1]\r\n",
    "\r\n",
    "input_tensor = tensorFromSentence(input_lang, input_tensor)\r\n",
    "target_tensor = tensorFromSentence(output_lang, target_tensor)\r\n",
    "\r\n",
    "print(\"Input tensor\",input_tensor.shape,input_tensor)\r\n",
    "\r\n",
    "encoder_hidden = encoder.initHidden()\r\n",
    "encoder_outputs, hidden = encoder(input_tensor[0])\r\n",
    "\r\n",
    "print(\"Out\",encoder_outputs.shape)\r\n",
    "print(\"Hidden\",hidden.shape)\r\n",
    "#dummy_input = torch_randn()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вместо one_hot - векторов, используются эмбеддинги размером 1x256 (hidden size)\n",
    "\n",
    "[pytorch WORD EMBEDDINGS: ENCODING LEXICAL SEMANTICS](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DecoderRNN(nn.Module):\r\n",
    "    def __init__(self, output_size, hidden_size ):\r\n",
    "        super(DecoderRNN, self).__init__()\r\n",
    "        self.hidden_size = hidden_size\r\n",
    "\r\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\r\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\r\n",
    "        self.out = nn.Linear(hidden_size, output_size)\r\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\r\n",
    "\r\n",
    "    def forward(self, input, hidden):\r\n",
    "        output = self.embedding(input).view(1, 1, -1)\r\n",
    "        output = F.relu(output)\r\n",
    "        output, hidden = self.gru(output, hidden)\r\n",
    "        output = self.softmax(self.out(output[0]))\r\n",
    "        return output, hidden\r\n",
    "\r\n",
    "    def initHidden(self):\r\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n",
    "\r\n",
    "decoder = DecoderRNN(output_lang.n_words, hidden_size) # hidden state must have the same sizes\r\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\r\n",
    "\r\n",
    "# Use encoder last state as decoder init\r\n",
    "decoder_hidden = encoder_hidden\r\n",
    "\r\n",
    "decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden )\r\n",
    "print(\"Output: \", decoder_output.shape)\r\n",
    "#https://pytorch.org/docs/stable/generated/torch.topk.html\r\n",
    "top_val, top_index = decoder_output.topk(1) # Returns the k largest elements of the given input tensor\r\n",
    "\r\n",
    "generated_word = output_lang.index2word[top_index.item()]\r\n",
    "print(\"Word: \", generated_word, \"index \", top_index.item())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Обучение\n",
    "\n",
    "В на вход модели будем подавать индексы слов для первой части пары из одного словаря, а на выходе ожидать индексы для соответствующей пары из другого. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "target_length = target_tensor.size(0)\r\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\r\n",
    "for di in range(target_length):\r\n",
    "  decoder_output, decoder_hidden, = decoder( decoder_input, decoder_hidden)\r\n",
    "  topv, topi = decoder_output.topk(1)\r\n",
    "  decoder_input = topi.squeeze().detach()  # detach from history as input\r\n",
    "\r\n",
    "  #loss += criterion(decoder_output, target_tensor[di])\r\n",
    "  generated_word = output_lang.index2word[decoder_input.item()]\r\n",
    "  print(\"Word: \", generated_word, \"index \", decoder_input)\r\n",
    "\r\n",
    "  if decoder_input.item() == EOS_token:\r\n",
    "      break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attention\n",
    "\n",
    "С подходом, разобранным ранее есть большая проблема"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/498_FA2019_lecture13-011.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Использование единственного вектора для предоставления информации может работать только для последовательностей малой длины (неразумно предполагать, что информация с длинной последовательностью можно сжать в один вектор) \r\n",
    "\r\n",
    "Чтобы понять, что надо сгенерировать слово estamos в начале, нашей нейросети надо сохранить информации о we во всех состояниях от $h_1$ до $h_4$\r\n",
    "А что если нам надо перевести абзац текста? \r\n",
    "При этом длина вектора, в котором нам надо хранить информацию обо всей последовательности - постоянна. Понятно, что начиная с какого-то момента информацию всю мы сохранить в нем не сможем. Более того, при генерации, скажем, последнего слова, мы должны в векторе того же размера сохранить информацию о этом последнем слове и о том, что другие уже сгенерены - иначе модель может зациклиться или не сгенерировать часть слов.\r\n",
    "\r\n",
    "Все эти проблемы реальны и возникают в обычной Seq2Seq модели.\r\n",
    "\r\n",
    "Нам нужен некий механизм, который будет обходить \"бутылочное горлышко\" и не сжимать всю информацию в один вектор С. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sequence-to-Sequence with RNNs and Attention mechanism"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте не будем делать состояние $c$ фиксированным. Пусть на каждом этапе, при генерации нового слова, наш декодер имеет возможность сформировать новое $c$, на основе всех скрытых состояний $h_i$ енкодера. \n",
    "Для простоты - пусть он подбирает веса, суммирующиеся в единицу, с которыми сложить эти представления, чтобы получить новое $c$.\n",
    "Таким образом, в каждый момент времени наш декодер имеет доступ ко всему исходному предложению (представлению каждого слова) и может акцентировать внимание на конкретно нужных в данный момент словах. \n",
    "\n",
    "Говоря немного мудрено - теперь длина пути, который надо преодолеть информации от места ее появления до места, где она может пригодиться - 1, а раньше она была пропорциональна длине исходного предложения. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-017.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-020.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-021.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "\r\n",
    "MAX_LENGTH = 17\r\n",
    "\r\n",
    "class AttnDecoderRNN(nn.Module):\r\n",
    "    def __init__(self, output_size, hidden_size,  max_length=MAX_LENGTH):\r\n",
    "        super().__init__()\r\n",
    "        self.hidden_size = hidden_size\r\n",
    "        self.output_size = output_size\r\n",
    "        self.max_length = max_length\r\n",
    "\r\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n",
    "        # ****** Attention ***************************************************\r\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\r\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n",
    "        # ********************************************************************\r\n",
    "\r\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\r\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\r\n",
    "\r\n",
    "    def forward(self, input, hidden, encoder_outputs):\r\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\r\n",
    "\r\n",
    "        # ****** Attention ***************************************************\r\n",
    "        att_inputs = torch.cat((embedded[0], hidden[0]), 1) # S0 + Start token (Y0)\r\n",
    "        print(\"att_inputs\",att_inputs.shape,\"256 + 256\") # 256 + 256\r\n",
    "        e = self.attn(att_inputs) \r\n",
    "        print(\"e \",e.shape) # MAX_INPUT == number of hidden states\r\n",
    "        attn_weights = F.softmax( e, dim=1) \r\n",
    "        print(\"a (attn_weights) \",attn_weights.shape) # MAX_INPUT\r\n",
    "        print(\"H (encoder_outputs)\",encoder_outputs.unsqueeze(0).shape)\r\n",
    "        # bmm is matrix product wark as elemet-wise multiplication + sum\r\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\r\n",
    "        print(\"C Attn_applied\",attn_applied.shape)\r\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\r\n",
    "        output = self.attn_combine(output).unsqueeze(0)\r\n",
    "        print(\"C with YO\",output.shape)\r\n",
    "\r\n",
    "        # *********************************************************************\r\n",
    "        \r\n",
    "\r\n",
    "        output = F.relu(output)\r\n",
    "        output, hidden = self.gru(output, hidden)\r\n",
    "\r\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\r\n",
    "        return output, hidden, attn_weights\r\n",
    "\r\n",
    "    def initHidden(self):\r\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\r\n",
    "\r\n",
    "# Fake hidden states from encoder\r\n",
    "encoder_outputs = torch.randn(MAX_LENGTH, encoder.hidden_size, device=device)\r\n",
    "\r\n",
    "att_rnn_decoder = AttnDecoderRNN(output_lang.n_words, hidden_size ) # output_size == word count in target dictionary\r\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\r\n",
    "decoder_hidden = encoder_hidden\r\n",
    "\r\n",
    "output, hidden, attn_weights = att_rnn_decoder(decoder_input, decoder_hidden, encoder_outputs)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте посмотрим как фокусировка работает на примере перевода с английского на французский \n",
    "\n",
    "Как мы знаем, на каждом шаге генерируется набор весов, которые отвечают за фокусировку на том или ином месте входной последовательности. Как мы видим, английское предложение имеет иной порядок слов относительно французского. Например, в английском варианте словосочетание **European Economic Area**, в то время как во французском **zone économique européenne**. \n",
    "\n",
    "В английском прилагательные идут перед существительным, в то время как во французском языке наоборот. \n",
    "\n",
    "Таким образом, благодаря гибкости модели, мы можем обрабатывать и учитывать разный порядок слов в разных языках."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-025.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Механизм внимания не обязательно должен принимать на вход последовательность. \n",
    "\n",
    "* Мы можем применять его, в том числе для генерации подписей для картинок. Входом в данном случае будет являться сетка признаков, которая была получена при применении сверточной сети к картинке. \n",
    "\n",
    "* Далее по этой сетке мы считаем веса внимания и делаем аналогично первому примеру."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Следующим шагом будет также заметить, что для достаточно длинного предложения наша модель может забыть и то, что она генерирует. Потому мы можем сделать два attention - один на представления исходного предложения, а второе - на представление того, что уже сгенерировано (что еще не сгенерировано - заменяем нулями)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Проблема attention\n",
    "\n",
    "Очевидно, у этого подхода есть свои минусы. \n",
    "\n",
    "Самый важный из них - ваша модель должна уметь предсказывать веса для каждого слова в исходном предложении. И обычные подходы принуждают нас фиксировать размер этого вектора весов. \n",
    "\n",
    "За счет этого у нас возникло ограничение, от которого мы избавлялись - модель не может принимать (и, если используем attention на то, что сгенерировано, генерировать) предложения больше определенного размера. С другой стороны, ничто не мешает поставить этот максимальный размер достаточно большим, чтобы для бОльшей части предложений это работало. \n",
    "\n",
    "Почему это не сильный проигрыш в сравненении с LSTM - так оно все равно было ограничено в длине предложения, просто неявно, что даже хуже - лучше иметь модель, которая на длине предложения 45 падает, а не генерирует лабуду. \n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image Captioning with RNNs and Attention\n",
    "\n",
    "Модели, основанные на внимании (attention) намного более продвинутые, нежели обычные нейросети. Они могут концентрироваться на отдельных частях изображения, что позволяет избежать зашумления данных.\n",
    "\n",
    "Идея состоит в том, что свёрточная сеть теперь будет генерировать не один вектор, описывающий всё изображение, а набор векторов для нескольких участков исходного снимка. В дополнение к работе со словарём на каждом временном шаге модель также производит распределение по точкам на изображении, которые она обрабатывает в данный момент. Это позволяет ей научиться находить наиболее важные участки, на которых необходимо фокусироваться.\n",
    "\n",
    "После обучения модели можно увидеть, что она как бы переносит своё внимание по изображению для каждого генерируемого слова."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-028.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-031.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-036.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-037.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](http://cs231n.stanford.edu/slides/2017/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-038.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Также нейросети, основанные на внимании, повсеместно используются для ответов на визуальные вопросы (Visual Question Answering). Цель этой задачи — обучить модель отвечать на вопрос по изображению. Например, она должна уметь не только называть сами объекты на фотографии, но и считать их, распознавать цвета и оценивать расположение относительно друг друга. Мы уже рассказывали о подобных архитектурах в статье о том, как такие нейросети могут помочь незрячим людям и о нейро-символическом мышлении.\n",
    "\n",
    "[ссылка на исследование](https://www.reg.ru/blog/nejroset-opisyvaet-mir-nezryachim-lyudyam/) \n",
    "и еще [одна ссылка](https://www.reg.ru/blog/uchim-nejroseti-rassuzhdat-o-tom-chto-oni-vidyat/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-039.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Key, query, value \n",
    "\n",
    "Мы можем формализовать процедуру attention через введение концепций key, query \n",
    "и value. \n",
    "\n",
    "К примеру, у нас есть картинка. На этой картинки у нас есть области, которые можно описать одним словом - key. Например - фонарь/девушка/... \n",
    "\n",
    "Сами эти области - это value, которые введенным key соответствуют. \n",
    "\n",
    "Далее нам приходит query - например, running. Мы можем посчитать похожесть каждого из ключей, которые у нас есть на query. \n",
    "\n",
    "И далее выдать информацию только по value, похожим на наш query. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/1_EC04ZMiCnLBT3IG0tdU33g.jpg\" width=\"800\">\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Послезная статья про NLP — BERT & Transformer, откуда взяты картинки по теме](https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "По сути мы описали то, как будем делать при помощи нейронок питоновский словарь. С той разницей, что питоновский словарь может выдавать значения для только тех ключей, что в нем есть, а наш словарь выдает ответ для любого ключа-запроса, основываясь на его похожести на ключи словаря"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Keq, Query, Value на примере текста \n",
    "\n",
    "Разобьем наше предложение на токены (в данном случае - просто слова). Получим представление каждого токена"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/sentence_kqv.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Каждое слово будет являться одновременно и key, и value. \n",
    "\n",
    "Теперь можно подать любой query, например - вода, и в случае, если у нас эмбединги слов хорошие, что нам \"подсветятся\" слова, связанные с водой"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attention Layer\n",
    "\n",
    "Эту идею реализует attention layer. \n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Что мы таким образом получили? Фактически, мы получили дифференцируемый аналог словаря в Python. Только этот словарь еще умеет делать неточный поиск"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "У нас есть некий изначальный набор X - слова в нашем предложении. \n",
    "\n",
    "Мы можем их преобразовать как-то, чтобы получить более удобные для дальнейшей цели K - предполагается, что они лучше помогают сравнивать между собой слова. \n",
    "В простейшем случае некое линейное преобразование $K = XW_K$\n",
    "\n",
    "Далее у нас есть значения, V, которые тоже получаются из X путем какого-то преобразования, которое делает их более применимыми для работы модели (важные признаки и тд), например $V = XW_Q$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее к нам приходят запросы Q, которые находятся в том же пространстве, что и ключи. Фактически - наша нейросеть пытается вытащить из данных интересующую ее информацию. К примеру - ей нужно найти всех животных и все растения - тогда Q= {\"животные\", \"растения\"} \n",
    "\n",
    "\n",
    "Мы сравниваем эти запросы с ключами - считаем просто попарные косинусные расстояние между каждым ключом $K_i$ и запросом $Q_j$. Получаем похожесть каждого ключа на запрос, нормируем ее на корень из размерности представления нашего ключа. \n",
    "\n",
    "$E = \\dfrac {QK^T} {\\sqrt{D}} $\n",
    "\n",
    "Получили матрицу похожестей $E$, где $E_{ij}$ - похожесть ключа $K_i$ на запрос $Q_j$\n",
    "\n",
    "Далее мы применяем к похожестям $E$ softmax, беря его по каждомуу ключу отдельно (по каждому столбцу матрицы E). Теперь у нас похожести каждого запроса складываются в единицу. \n",
    "\n",
    "$A = softmax(E, dim=1)$\n",
    "\n",
    "Получили для каждого запроса его \"разложение\" в виде ключей. \n",
    "\n",
    "Далее, чтобы получить значения, соответствующие каждому запросу, складываем значения с весами соответствующих ключей\n",
    "\n",
    "$Y_j = \\sum_iA_i V_i$\n",
    "\n",
    "$Y = AV$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-056.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](http://cs231n.stanford.edu/slides/2017/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Softmax normalization \n",
    "\n",
    "Вы могли заметить, что в формуле для E мы делим на корень из размерности представления ключа. Зачем это? \n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте сгенерируем вектор из многомерного нормального распределения"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np \r\n",
    "import matplotlib.pyplot as plt \r\n",
    "\r\n",
    "a = np.random.normal(0,100,size=(10000))\r\n",
    "plt.hist(a)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "И посмотрим, что будет с распределением значений этого вектора, если к нему применить softmax"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.special import softmax \r\n",
    "\r\n",
    "plt.plot(softmax(a))\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Почти все значения 0 и одно (по случайным причинам), стало 1. \n",
    "Мы получили так называемое вырожденное распределение - у него вся плотность сосредоточена в одной точке. \n",
    "\n",
    "И получили на абсолютно случайных данных. \n",
    "\n",
    "Это приведет к затуханию градиента - мы будем распространять ошибку только для 1 значения из 10000. Учиться сеть будет плохо"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Но этого можно избежать - давайте просто отнормируем наши данные "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "std = np.random.normal(0,100,size=(10000))\r\n",
    "\r\n",
    "unit_std = std/100\r\n",
    "\r\n",
    "plt.hist(std)\r\n",
    "plt.show()\r\n",
    "plt.hist(unit_std)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "По сути в распределении ничего не поменялось - только масштаб. Но теперь softmax работает нормально "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.hist(std)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Остается только понять, а как нормировать наши данные в нашем слое? Считать налету, наверное, не лучшая идея. \n",
    "\n",
    "Наш слой делает сколярное произведение между двумя векторами, предположим, нормально распределенными"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c = []\r\n",
    "for i in range(100):\r\n",
    "\t    a = np.random.normal(0,1,size=(100))\r\n",
    "\t    b = np.random.normal(0,1,size=(100))\r\n",
    "\t    c.append(np.dot(a,b))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(np.mean(c))\r\n",
    "\r\n",
    "print(np.std(c))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видим, что среднее не сильно отличается от 0 (можно показать, что в среднем оно равно 0 для произведения нормально распределенных величин). \n",
    "\n",
    "А вот стандартное отклонение растет. И, можно предположить, что растет оно как корень из размерности вектора. Так и есть. Потому и появляется именно такой нормировочный множитель в attention"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Keq, Query, Value на примере текста. Второй заход\n",
    "\n",
    "Хорошо, у нас есть предложение, мы его разбили на токены, допустим, мы хорошо умеем кодировать эти токены. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/sentence_kqv.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Но каждый токен закодирован на основе самого себя, и только, например, слово bank встречается в тексте два раза, и будет закодировано одинаково, хотя несет разные значения (берег и, собственно, банк). \n",
    "\n",
    "Как нейросети их отличать? Ну, если мы попытаемся на основе только одного токена что-то сделать - никак. \n",
    "\n",
    "А как улучшить кодирование каждого токена, чтобы два \"банка\" отличались? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сделаем следующее - каждый токен подадим в нейросеть **и в качестве query**. \n",
    "\n",
    "И будем аггрегировать полученную информацию, получая токен, который будет содержать более конкретную информацию"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/sentence_kqv2.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Например, bank, который банк, будет содержать информацию о том, что он не просто bank, а \"Bank of America\", который нужно найти (find).\n",
    "\n",
    "Такой подход - когда key, query и value формируются на основе одного и того же входа нейросети называется self-attention\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Self-Attention Layer\n",
    "\n",
    "Сделаем это все в виде слоя"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-063.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](http://cs231n.stanford.edu/slides/2017/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Что изменилось? \n",
    "\n",
    "Теперь X участвует и в производстве K, и в производстве V, и в производстве Q. Потому и self-attention - предложение состоящее из слов X_i, ищет само себя в нашем дифференцируемом словаре. Почему это не приводит к тому, что мы просто получим вектор V?\n",
    "Потому что значения X_i модифицируются и K != Q."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Еще один пример проблемы с текстом, который обычные методы решали плохо\n",
    "\n",
    "Многие из нас знают Первый Закон Робототехники\n",
    "\n",
    "**Second Law of Robotics**\n",
    "\n",
    "\n",
    "A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\n",
    "\n",
    "Представим, что машина хочет понять, что здесь написано. И ей нужно понять, что имеется ввиду под it. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Первым делом она формирует на основе каждого слова key и value. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/self-attention-example-folders-3.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Затем она смотрит, какие ключи похожи на Query, полученный из it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/self-attention-example-folders-scores-3.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Чтобы получить, что же на самом деле значит it, машина считает взвешенную сумму values, где  веса определяются похожестью query на value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/gpt2-value-vector-sum.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Ссылка на оригтнальную статью про GPT-2 с более подробными объяснениями как оно работает.](https://jalammar.github.io/illustrated-gpt2/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В итоге получается, что it представляет собой \"a robot\" (ну и само себя). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Positional encoding\n",
    "\n",
    "Единственный возможный минус - наша нейросеть не учитывает порядка слов в предложении при составлении embedding. Это может нам мешать. Например, если в предложении два it, то они часто относятся к разным словам. Потому хотим ууметь учитывать информацию о позиции. Для этого к X при составлении Q добавляется информация о позиции. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-072.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](http://cs231n.stanford.edu/slides/2017/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Делается это хитрым образом - мы берем и добавляем к каждому значению исходного вектора токенов некую комбинацию sin и cos с разными параметрами. \n",
    "\n",
    "Вектор PE, который мы будем добавлять к X будет определяться по следующей формуле"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$PE_{pos, 2i} = \\sin {\\dfrac {pos} {10000^{2i/d}}}$$\n",
    "\n",
    "$$PE_{pos, 2i+1} = \\cos {\\dfrac {pos} {10000^{2i/d}}}$$\n",
    "\n",
    "$pos$ - это позиция токена\n",
    "\n",
    "$i$ - iя размерность токена"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch \r\n",
    "import math\r\n",
    "import torch.nn as nn\r\n",
    "class PositionalEncoding(nn.Module):\r\n",
    "    \"Implement the PE function.\"\r\n",
    "    def __init__(self, d_model, max_len=5000):\r\n",
    "        super(PositionalEncoding, self).__init__()\r\n",
    "        \r\n",
    "        # Compute the positional encodings once in log space.\r\n",
    "        pe = torch.zeros(max_len, d_model)\r\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\r\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\r\n",
    "                             -(math.log(10000.0) / d_model))\r\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\r\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\r\n",
    "        pe = pe.unsqueeze(0)\r\n",
    "        self.register_buffer('pe', pe)\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        x = x + self.pe[:, :x.size(1)].detach() \r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pe = PositionalEncoding(20)\r\n",
    "y = pe(torch.zeros(1, 100, 20)) # последовательность размера 100, каждый токен последовательности имеет размерность 20 "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "plt.figure(figsize=(15, 5))\r\n",
    "plt.plot(np.arange(100), y[0, :, 0:4].data.numpy())\r\n",
    "plt.legend([\"dim %d\"%p for p in [1,2,3,4]])\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(15, 5))\r\n",
    "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\r\n",
    "plt.legend([\"dim %d\"%p for p in [4,5,6,7]])\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Это помогает трснформеру достаточно уникальным образом определять каждую позицию и понимать относительное расстояние между разными токенами"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Masked Self-Attention Layer\n",
    "\n",
    "\n",
    "Если у нас стоит проблема, что мы не должны видеть часть слов в предложении - например, при генерации текста (по текущим словам предсказать следующее). Например, хотим сгенерировать фразу \"robot must obey orders\" на основе только первого слова. \n",
    "\n",
    "Если мы скормим в трансформер во время обучения сразу все предложение, которое хотим генерировать, то у нас в первых словах будет \"протекать\" информация о предыдущих."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/queries-keys-attention-mask.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В этом случае мы можем просто на соответствующих местах матрицы E поставить минус бесконечности - тогда в ембедингах слов, которые не должны знать о каких-то словах, информации об этих словах не будет."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/transformer-attention-mask.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В результате мы сможем, после softmax \"лишния\" информация не будет использоваться при генерации ответа на query"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/transformer-attention-masked-scores-softmax.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Благодаря этому трюку, у нас получается обучать transfomer по-прежнему как простую single-pass нейросеть, а не \"скатываться\" в RNN, где у нас возникнут проблемы с градиентами и временем работы "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multihead Self-Attention Layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_7-1.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте посмотрим на то, к каким словам предложения gave может иметь отношение. В общим случае глагол может иметь связку со многоми частями предложения. Как, например, к подлежащему, так и к причастиям.\n",
    "\n",
    "В идеале, нам бы хотелось обратить внимние функции (attention) на все эти взаимосвязи. Для этого нам просто надо поставить несколько attention слоев парралельно. В идеале каждый будет учить что-нибудь свое - аналогия с конволюциями. \n",
    "\n",
    "* Чтобы осуществить задуманное, вместо одного набора query, будем использовать несколько независимых наборов. \n",
    "\n",
    "* Причем каждый набор будет считаться уникальной матрицей. \n",
    "\n",
    "* Аналогично сделаем для keys и values. Количество таких наборов внутри keys, queries, values должно быть **одинаковым**. \n",
    "\n",
    "* Обозначим это число как h - head, далее производим аналогичные манипуляции, при этом введем в параллель h таких функций attention\n",
    "* На последнем шаге мы их соединяем (конкатинируем)\n",
    "\n",
    "* При этом, можно заметить, что таком подходе на каждом шаге размерность токена будет увеличиваться (если, например, в качестве и key, и value, и query мы подаем одно и тоже предсталение токена). Если хотим сохранять управлять размерностью токена, то придется получать по меньшей мере value путем домножения на матрицу, размерность которой по второй оси меньше - **выполнять проекцию наших токенов в пространство меньшей размерности**\n",
    "\n",
    "* В частности, можно подобрать размерность этого пространства таким образом, чтобы при конкатенации размерность полученного токена равнялась исходной. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/Multihead.png\" width=\"900\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attention is all you need\n",
    "\n",
    "Оказывается, этот подход работает сам по себе. Не нужно добавлять никаких реккурентных слоев - просто делаем много правильно соединенных attention layers. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-085.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Базовый блок "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-092.png\" width=\"700\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](http://cs231n.stanford.edu/slides/2017/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Блок устроен следующим образом: входные вектора мы запускаем в блок self-attention и используем residual connection как обходной путь вокруг self-attention, затем мы их складываем. Так как обычно используют multi head self-attention, тут нам и пригождается возможность подобрать параметры так, чтобы размерности входных и выходных токенов не отличались. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "После - применяем слой нормализации, затем - слой feed forward (MLP), плюс обходной путь вокруг feed forward. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/mlp_transformer.png\" width=\"900\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Складываем выход MLP-части с residual connection и выполняем нормализацию.\n",
    "\n",
    "Нормализация везде нужна для того, чтобы нейросеть нормально обучалась. \n",
    "\n",
    "Заводим ли разный MLP на каждый токен (по позиции) - конечно нет. К каждому токену применяются MLP с одними и теми же весами. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "В реальных моделях эти слои стекируют друг с другом и получается большая трансформер-модель. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/mlp_transformer2.png\" width=\"600\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Это пример Encoder-модели. Такова рассматриваемая далее BERT. В такой модели на выходе мы получаем некое хорошее представление исходного предложения. \n",
    "\n",
    "Но что если мы хотим сделать задачу перевода с одного языка на другой? Нужен еще Decoder\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decoder \n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Первая стадия\n",
    "\n",
    "На первой стадии то, как работает Decoder не так сильно отличается от работы Encoder. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/1_R6_u8qGXKUyyGaHb9-mMDw.jpg\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Тем не менее, есть один важный нюанс -  мы используем Masked Attention - наша нейросеть не должна видеть слов, которые еще не сгенерировала. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "На основе первого этапа у нас формируются только query - наша нейросеть на основе того, что она уже сгенерировала решает, какая информация ей нужна дальше "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Вторая стадия\n",
    "\n",
    "Теперь мы используем для K, V информацию, полученную из энкодера и получаем предсказание. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/1_HKyS_RuocFun1LUubSf-jQ.jpg\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Примеры применений Transformer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Перевод текста \n",
    "\n",
    "Непосредственное применение разобранной архитектуры Encoder-Decodee"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/transformer-encoder-decoder.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](https://jalammar.github.io/illustrated-bert/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BERT \r\n",
    "\r\n",
    "В случае BERT используется только Encoder часть\r\n",
    "\r\n",
    "Это нейросеть, предобученная на огромном корпусе английского текста. \r\n",
    "\r\n",
    "Перед ней ставили следующие задачи:\r\n",
    "\r\n",
    "1. На вход дается предложение - в нем выбрано 15% токенов, из которых:\r\n",
    "    1. 80% замаскированы\r\n",
    "    2. 10% заменены случайным\r\n",
    "    3. 10% оставлены без изменений\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. На вход даются два предложения - сказать, идет ли второе непосредственно за первым в тексте, или нет (просто случайное предложение из корпуса)\n",
    "\n",
    "\n",
    "В результате на вход подается все в таком виде:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/1_D0_sVWpmOSaGCvm6gk9aHA.jpg\" width=\"800\">\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ссылка](https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$CLS$ токен нужен для того, чтобы нейросети было, куда класть информацию обо всем предложении в целом. \n",
    "\n",
    "$SEP$ нужен просто для того, чтобы разделять два предложения (если мы подаем их два) и для того, чтобы отмечать окончание. Использование $SEP$ с двумя целями позволяет подавать в уже обученную нейросеть только одно предложение. \n",
    "\n",
    "\n",
    "Выход нейросети во время обучения выглядит таким образом: \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Masked Language Model\n",
    "\n",
    "Для первой задачи используем Encoder-Decoder \n",
    "\n",
    "То есть у нас есть **Encoder**, который получает богатые представления и добавленный только на время обучения **Decoder** (не attention, просто MLP).\n",
    "\n",
    "Именно Decoder отвечает за то, чтобы предсказывать пропущенные/замененные токены. Ошибка считается только по тем 15% токенов, для которых могло произойти изменения, а не по всему предложению.\n",
    "\n",
    "Как гарантируется, что модель не заменяет имевшиеся в предложение слова на другие? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/1_yTk92fAvqPDlabJJqkM4rw.png\" width=\"800\">\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Next Sentence Prediction \n",
    "\n",
    "Для второй задачи - Classifier. \n",
    "\n",
    "При этом на вход ему подается только сам CLS токен \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/1_UvFUs9afyoIGKj9F5qTIxw.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Обе задачи тренируем одновременно. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transfer learning с BERT \n",
    "\n",
    "Нейросеть, обученную на таких задачах, можно было далее использовать при помощи transfer learning для решения целого спектра задач.\n",
    "\n",
    "Обученную таким образом модель (оставляем только encoder), можно использовать для огромного числа других задач \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/1_71lj0YoM5fkZB229XKAFrA.jpg\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Zero-shot learning \n",
    "\n",
    "Более того, есть BERT, тренированная на большом числе разных языков.\n",
    "\n",
    "Это позволяет, например, сравнивать предложения из разных языков, хотя мы этому даже не учились. Поиграть можно [здесь](https://colab.research.google.com/github/deepmipt/dp_tutorials/blob/master/Tutorial_2_DeepPavlov_BERT_transfer_learning.ipynb#scrollTo=S1iqGcxUINyU). Веса будут грузиться ДОЛГО"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/BERT_multilingual.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Специализированные аналоги BERT\n",
    "\n",
    "Более того, можно тренировать BERT под строго определенные задачи - например, анализ текстов научных статей "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/0_svTduALJlF5JOD7x.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPT (Generative Pretrained Transformer )\n",
    "\n",
    "В случае GPT используется только Decoder часть. Но теперь во всех частях используются masked attention "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/gpt2-self-attention-qkv-1-2.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Это нейросеть обширно используется для, например, задачи генерации текста,"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Работает она следующим образом - даем ей в качестве исходного входа какую-то затравку. Можно просто SOS-токен. Она дает какой-то выход. Подаем этот выход нейросети как вход. \n",
    "Делаем так до тех пор, пока не надоест/не достигнем максимальной длины предложения/не встретим символ окончания генерации"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/gpt-2-autoregression-2.gif\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как ее обучали - на самом деле, тоже unsupervised. Но теперь перед моделью ставится задача предсказывать по предыдущим словам в предложении текущее.\n",
    "\n",
    "Понятно, что такую модель можно сразу же идти и использовать для генерации. \n",
    "\n",
    "Однако затем ее можно применять для многих других задач (опять же, путем transfer learning):\n",
    "\n",
    "\n",
    "1. Классификации - подаем сразу все предложение, полученное представление используем для предсказания\n",
    "\n",
    "2. Entailment (Определение логического следования) - даем изначальные данные, гипотезу, надо оценить, следует ли гипотеза из данных\n",
    "\n",
    "3. Similarity - можем оценивать похожесть предложений. Так как это мы определяем порядок предложений, то чтобы не было произволо скормим будем использовать результат пропускания через нейросеть обоих возможных порядков. \n",
    "\n",
    "4. Выбор варианта ответа на вопросы - может обучить нейросеть отвечать на вопросы с множественным выбором. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/Screen_Shot_2020-05-27_at_12.41.44_PM.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Также можно научить нейросеть отвечать на вопросы и т.д. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Строго говоря, мы можем даже текст переводить с помощью GPT. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/decoder-only-transformer-translation.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Просто подаем предложение с токеном в конце, определяющим, на какой язык переводим"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "По аналогичной схеме можем научить нашу сеть делать summary текста"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img_license/decoder-only-summarization.png\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[А тут можно ознакомиться с полной статьей How NLP Cracked Transfer Learning](https://miro.medium.com/max/933/1*71lj0YoM5fkZB229XKAFrA.jpeg) , из которой взяты изображеня для блоков Masked Language Model, Next Sentence Prediction, Transfer learning с BERT, Zero-shot learning, Специализированные аналоги BERT и GPT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Здесь](https://6b.eleuther.ai/) можно поиграть с open-source GPT-J\n",
    "\n",
    "А [здесь](https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb#scrollTo=e-NKauYvgTNG) - поиграть, но уже в Collab"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Хорошие источники \n",
    "\n",
    "[Про трансформеры](https://www.notion.so/Transformers-969f4b27c48147778c1e2dbda0c83ce0)\n",
    "\n",
    "[Аннотированный трансформер](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\n",
    "\n",
    "[Код множества моделей с красивыами комментариями](https://nn.labml.ai/)\n",
    "\n",
    "[BERT](https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c)\n",
    "\n",
    "[Зоопарк BERT](https://ai.plainenglish.io/so-how-is-bert-different-ad43a42cab48)\n",
    "\n",
    "[От NLP до Transformer](https://jonathan-hui.medium.com/nlp-bert-transformer-7f0ac397f524)\n",
    "\n",
    "[Illustrated transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "[Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/)\n",
    "\n",
    "[Open-source реализация GPT-3](https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/)\n",
    "\n",
    "[Transformer для русского языка](https://github.com/vlarine/transformers-ru)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 1
}
