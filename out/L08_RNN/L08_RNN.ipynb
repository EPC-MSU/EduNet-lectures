{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUjdn9w559n1"
   },
   "source": [
    "# Рекуррентные нейронные сети (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5uaWgqR59n8"
   },
   "source": [
    "##  Особенности\n",
    "\n",
    "Если стандартные методы машинного обучения работают с так называемыми структурированными типами данных, с объектами, у которых фиксировано признаковое описание, которые подаются на вход моделям, то рекуррентные нейронные сети используются с неструктурированными данными. Например, в распознавании речи, генерации музыки, машинном переводе. Данные в таких задачах представляют собой текст без предобработки, звуковой ряд и другие данные, не имеющие признаковых описаний. Давайте обсудим, каков принцип работы нейронной сети, и как именно таким нейронным сетям удается работать с неструктурированными данными.\n",
    "\n",
    "Мы имеем возможность сохранять информацию, сформированную при обработке одного слова, и использовать ее, когда мы анализируем дальнейшие слова. Видно, что при рассмотрении каждого слова происходят одни и те же процедуры. Нейронная сеть получает очередное слово, учитывает предыдущую активацию, формирует ответ. Это действие, происходящее в рамках одной ячейки нейронной сети. Так как вся сеть представляет собой объединение однотипных ячеек, то нейронная сеть называется рекуррентной. Рекуррентные нейронные сети не ограничиваются случаем, когда мы каждому входу нейронной сети должны сопоставить некоторый ответ, после чего анализировать следующий вход."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Qh05-Lj68rI"
   },
   "source": [
    "## Задачи\n",
    "\n",
    "**Анализ временных рядов**\n",
    "- Статистические данные\n",
    "- Аннотирование изображений и видео (Image/Video captioning)\n",
    "- Машинный перевод\n",
    "- Распознавание текста\n",
    "- Распознавание речи\n",
    "\n",
    "**Генеративные модели**\n",
    "- Генерация текста/речи (чат - боты)\n",
    "- Генерация изображений\n",
    "\n",
    "**Классификация**\n",
    "- Изображения\n",
    "- Блоки текста (Sentiment analysis)\n",
    "\n",
    "Большинство этих задачь подрузамевают наличие контекста ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHnc-cB959n-"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-011.png\" width=\"700\">\n",
    "\n",
    "Существует множество типов рекуррентных нейронных сетей. Простейший случай рекуррентной сети — «one to one», когда у нас есть всего один вход и один выход нейронной сети. Более сложной является реализация «one to many», когда у нас есть всего один вход и нам необходимо сформировать несколько выходов. Такой тип нейронной сети актуален, когда мы говорим о генерации музыки или текстов. Мы задаем начальное слово или начальный звук, а дальше модель начинает самостоятельно генерировать выходы, в качестве входа к очередной ячейке рассматривая выход с прошлой ячейки нейронной сети. Если мы рассматриваем задачу классификации, то актуальна схема «many to one». Мы должны проанализировать все входы нейронной сети и только в конце определиться с классом. Схему «many to many», когда количество выходов равно количеству входов нейронной сети, мы рассмотрели на примере с определением части речи. Такой вид используется также в задачах NER, которые мы обсудим в следующем видео. Ну и последней разновидностью нейронных сетей является сеть вида «many to many», когда количество выходов нейронной сети не равно количеству входов. Это актуально, к примеру, в машинном переводе, когда одна и та же фраза может иметь разное количество слов в разных языках (т.е. это реализует схему энкодер-декодер). Энкодер получает данные различной длины — например, предложение на английском языке. С помощью скрытых состояний он формирует из исходных данных вектор, который затем передаётся в декодер. Последний, в свою очередь, генерирует из полученного вектора выходные данные — исходную фразу, переведённую на другой язык."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5BFCtTX-DlK"
   },
   "source": [
    "## Базовый RNN блок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYb68Asu59oC"
   },
   "source": [
    "Попробуем подробнее разобраться, что же происходит в загадочном зелёном прямоугольнике с надписью RNN. Внутри него мы вычисляем рекуррентное соотношение с помощью функции f, которая зависит от весов w. Чтобы найти новое состояние ht, мы берём предыдущее скрытое состояние $ h_{t-1} $, а также текущий ввод xt. Когда мы отправляем в модель следующие входные данные, полученное нами скрытое состояние $ h_t $ передаётся в эту же функцию, и весь процесс повторяется.\n",
    "\n",
    "Чтобы генерировать вывод в каждый момент времени, в модель добавляются полносвязные слои, которые постоянно обрабатывают состояния $ h_t $ и выдают основанные на них прогнозы. При этом функция f и веса w остаются неизменными.\n",
    "\n",
    "Самая простая реализация рекуррентной сети будет выглядеть следующим образом (Тангенс здесь используется для введения нелинейности в систему):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0GQ61EU59oD"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-017.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1r03xVhA7Fq"
   },
   "source": [
    "Важное отличие от слоев с которыми мы уже сталкивались, сотоит в том что на выходе мы получаем два объекта Y и H.\n",
    "\n",
    "**Y** - предсказание в текущий момент времени, например метка класса.\n",
    "\n",
    "**H** - контекст в котором предсказание было сделанно. Он может использоваться для дальнейших предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFZYpkzIa1Su"
   },
   "source": [
    "#### RNNCell\n",
    "\n",
    "В Pytorch для вычисления h_t используется модуль [RNNCell](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html)  \n",
    "\n",
    "y_t в нем не вычисляется, предполагается что для его получения в модель должен быть добавлен дополнительный линейный слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXIIpuXM6TNQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "rnn_cell = torch.nn.RNNCell(input_size = 3, hidden_size = 2)\n",
    "dummy_sequence = torch.randn((1,3)) # batch, input_size\n",
    "h = rnn_cell(dummy_sequence) \n",
    "print(\"Out = h\\n\",h.shape,\"\\n\",h) # hidden state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EP3JBVYm7rKr"
   },
   "source": [
    "Внутри происходит примерно следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9Bu76IZ7zd2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# Simple RNNcell without a bias and batch support\n",
    "class SimplifiedRNNCell(nn.Module): \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    # hidden_size == number of neurons\n",
    "    self.W_hx = np.random.randn(input_size, hidden_size) * 0.0001 # without bias\n",
    "    self.W_hh = np.random.randn(hidden_size, hidden_size) * 0.0001 # without bias\n",
    "    self.h0 = np.zeros((hidden_size))\n",
    "  \n",
    "  def forward(self,x,h = None): # Without a batch dimension\n",
    "    if h is None:\n",
    "      h = self.h0\n",
    "    h = np.tanh(self.W_hx.T.dot(x)+self.W_hh.T.dot(h))\n",
    "    return h \n",
    "  \n",
    "simple_rnn_cell = SimplifiedRNNCell(input_size = 3, hidden_size = 2)\n",
    "h = simple_rnn_cell(dummy_sequence[0]) # No batch \n",
    "print(\"Out = h\\n\",h.shape,\"\\n\",h) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyAWauv_9t-J"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndIE9O_c59oH"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-023.png\" width=\"700\">\n",
    "\n",
    "Однако в последовательности всегда несколько элементов. И надо применить алгоритм к каждому.\n",
    "\n",
    "\n",
    " Поэтому RNNCell напрямую не используется. Для него есть обертка: [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) который обеспечивает последовательный вызов RNNCell для всех элементов последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibrnPohqa_C2"
   },
   "source": [
    "### RNN блок в Pytorch \n",
    "\n",
    "**Warning: batch dim is second!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvfG0kC9_-ci"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "rnn = torch.nn.RNN(input_size = 3, hidden_size = 2) #batch_first = True\n",
    "dummy_batched_seq = torch.randn((2,1,3)) #   seq_len, batch , input_size\n",
    "out, h = rnn(dummy_batched_seq) \n",
    "print(\"Out = \\n\",out.shape,\"\\n\",out) # hidden state for each element of sequence\n",
    "print(\"h = \\n\",h.shape,\"\\n\",h) # hidden state for last element of sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqoE_24lBA5H"
   },
   "source": [
    "Внутри происходит примено следующее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efP5fBTU-Zzg"
   },
   "outputs": [],
   "source": [
    "# Simple RNN without batching\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "class SimplifiedRNNLayer(nn.Module): \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    self.rnn_cell = SimplifiedRNNCell(input_size, hidden_size)\n",
    "\n",
    "  # Without a batch dimension x have sahpe seq_len * input_size\n",
    "  def forward(self,x, h = None):\n",
    "    all_h = []\n",
    "    for i in range(x.shape[0]):\n",
    "      h = self.rnn_cell(x[i],h)\n",
    "      all_h.append(h) \n",
    "    return  np.stack(all_h), h\n",
    "\n",
    "simple_rnn = SimplifiedRNNLayer(input_size = 4, hidden_size = 2)\n",
    "sequence = np.array([[0,1,2,0], [3,4,5,0]]) # batch of one sequence of two elements \n",
    "\n",
    "out, h = simple_rnn(sequence)\n",
    "print(\"Out \\n\",out.shape,out) \n",
    "print(\"h \\n\", h.shape, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zGyq8c_EsR1"
   },
   "source": [
    "Давайте разберемся.\n",
    "\n",
    "К данным добаляется еще одно измерение размер последовательности. Таким образом batch из 6 последовательностей по 5 элементов в каждой будет выглядеть так:\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/rnn_batch.jpeg\" width=\"600\">\n",
    "\n",
    "P.S. Размер самого элемента == 3\n",
    "\n",
    "Внутри RNN модуля элеменым последовательности обрабатываются последовательно:\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/rnn_unrolled.jpeg\" width=\"1000\">\n",
    "\n",
    "Веса при этом используются одни и те же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28-hQXxd7Wgz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn((2,1,3)) #  seq_len, batch, , input_size\n",
    "\n",
    "print(\"RNNCell\")\n",
    "rnn_cell = torch.nn.RNNCell(3,2)\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "cell_out = rnn_cell(dummy_input[0,:,:]) # take first element from sequence \n",
    "print(\"Out = h\",cell_out) # one hidden state\n",
    "\n",
    "print(\"RNN\")\n",
    "rnn = torch.nn.RNN(3,2)\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out\", out) # h for all sequence element \n",
    "print(\"h\", h) # h for last element "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a69ZYyFm59ob"
   },
   "source": [
    "Кроме этого RNN блок имеет еще ряд настроек:\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add1.png\" width=\"700\">\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add2.png\" width=\"700\">\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_add3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aD9hdsRDYBvp"
   },
   "source": [
    "### Слои (Stacked RNNs)\n",
    "\n",
    "https://discuss.pytorch.org/t/what-is-num-layers-in-rnn-module/9843/2\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/layers.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMgXuUQePV-D"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn((2,1,3)) #  seq_len,  batch, input_size\n",
    "rnn = torch.nn.RNN(3,2,num_layers=3)\n",
    "\n",
    "# Weights matrix sizes not changed!\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out\", out) # Hidden states for all elements from top layer\n",
    "print(\"h\", h) # Hidden states for last element for all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5N0mu_SKQIp"
   },
   "source": [
    "https://medium.com/dair-ai/building-rnns-is-fun-with-pytorch-and-google-colab-3903ea9a3a79j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAc8sNT-b5FJ"
   },
   "source": [
    "### Bidirectional\n",
    "\n",
    "Последовательность можно пропустить через сетьдва раза в прямом и обратном направлении.\n",
    "\n",
    "https://medium.com/analytics-vidhya/understanding-rnn-implementation-in-pytorch-eefdfdb4afdb\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/bidirectional.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miU37kF-LGKT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dummy_input = torch.randn((2,1,3)) #   seq_len, batch, input_size\n",
    "rnn = torch.nn.RNN(3,2,bidirectional=True,num_layers=1)\n",
    "\n",
    "for t, p in rnn_cell.named_parameters():\n",
    "  print(t, p.shape) \n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print(\"Out\", out) # Concatenated Hidden states from both layers\n",
    "print(\"h\", h) # Hidden states last element from  both : 2*num_layers*hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kNJOMGY59od"
   },
   "source": [
    "### Добавление выходных весов (y_t)\n",
    "\n",
    "Давайте добавим выходные веса. Для этого придется программировать.Воспользуемся параметром batch_first = True что бы batch измерение оказалось на привычном нам месте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDIRNLms59od"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# Let's add output weights\n",
    "\n",
    "class RNN_for_many_to_one(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden, batch_first = True)\n",
    "        self.fc1 = torch.nn.Linear(hidden, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, hidden = self.rnn(x)\n",
    "        print(x.shape) # h for each element\n",
    "        print(hidden.shape) \n",
    "        # we need only last output\n",
    "        #return self.fc1(x[-1])\n",
    "        return self.fc1(hidden)\n",
    "    \n",
    "model2 = RNN_for_many_to_one(28, 128, 10) # input_size, hidden_dim, classes\n",
    "dummy_input = torch.randn((8,28,28)) #  seq_len , batch, element_size\n",
    "res = model2(dummy_input)\n",
    "# 30 - batch, 50 - output_size\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4P5VAdlPBFP"
   },
   "source": [
    "По умолчанию batch_first =  False и batch измерение становится вторым!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odsB_yAaMSQ5"
   },
   "source": [
    "## Many to one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMIvXTNz59of"
   },
   "source": [
    "## Пример обработки временного ряда\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbl3t16p59of"
   },
   "source": [
    "Что общего у прогнозирования потребления электроэнергии домохозяйствами, оценки трафика на дорогах в определенные периоды, прогнозировании паводков и прогнозировании цены, по которой акции будут торговаться на фондовой бирже?\n",
    "\n",
    "Все они подпадают под понятие данных временных рядов! Вы не можете точно предсказать любой из этих результатов без компонента «время». И по мере того, как в мире вокруг нас генерируется все больше и больше данных, прогнозирование временных рядов становится все более важной областью применения методов ML и DL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0y7DJe3ac-In"
   },
   "source": [
    "### Загрузка данных\n",
    "\n",
    "Air Passengers per month. \n",
    "https://www.kaggle.com/rakannimer/air-passengers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVkY1FwndGZ4"
   },
   "outputs": [],
   "source": [
    "# Dataloading\n",
    "import pandas as pd\n",
    "\n",
    "!if test -f ./airline-passengers.csv; then echo \"Already downloaded\"; else wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv; fi\n",
    "\n",
    "dataset = pd.read_csv('airline-passengers.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnDdggLdexBU"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_data = dataset.iloc[:,1:2].values # перевели dataframe в numpy.array\n",
    "# plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data, label = 'Airline Passangers Data')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_skdvumfAxP"
   },
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQyTvaeUfRHq"
   },
   "outputs": [],
   "source": [
    "# Min - Max normalization\n",
    "td_min = training_data.min()\n",
    "td_max = training_data.max()\n",
    "training_data -= td_min\n",
    "training_data = training_data / td_max\n",
    "print(training_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha6Nfaxc59oi"
   },
   "source": [
    "### Подготовка данных\n",
    "\n",
    "Поскольку мы хотим научиться предсказывать следующие значение на основе предидущих нам нужно подготовить данные соответствующим образом.\n",
    "\n",
    "Разобьем весь массив данных на фрагменты вида\n",
    "\n",
    "x -> y\n",
    "\n",
    "где х - это подпоследовательность, например строки с 1-й по 8ю, а y - это значение из 9-й строки, то самое которое мы хотим предсказать\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrhmfmgc59oj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# функция создания \"ансамблей\" данных\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)] # seq_len * elements\n",
    "        _y = data[i+seq_length] # one element\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)\n",
    "    \n",
    "# установка длины ансамбля. от нее практически всегда зависит точность предикта и быстродействие\n",
    "seq_length = 8 # сравните 2 и 32\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUPh4eMti5S1"
   },
   "source": [
    "Благодаря такому подходу мы можем работать с RNN моделью так же как работали со сверточными моделями. Подавая на вход такую подпоследовательность + результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyB4eoMajlrq"
   },
   "source": [
    "### Разобьем на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "338EIQMJ59ok"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(y) * 0.8)\n",
    "test_size = len(y) - train_size\n",
    "\n",
    "dataX = torch.Tensor(np.array(x))\n",
    "dataY = torch.Tensor(np.array(y))\n",
    "\n",
    "trainX = torch.Tensor(np.array(x[0:train_size]))\n",
    "trainY = torch.Tensor(np.array(y[0:train_size]))\n",
    "\n",
    "testX = torch.Tensor(np.array(x[train_size:len(x)]))\n",
    "testY = torch.Tensor(np.array(y[train_size:len(y)]))\n",
    "\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT4nRe0x59ok"
   },
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JT_IVh6r59ol"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AirTrafficPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons \n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"x: \",x.shape) # 108 x 8 x 1 : [batch_size, seq_len, input_size] \n",
    "        out, h = self.rnn(x) \n",
    "        #print(\"out: \", out.shape) # 108 x 8 x 4 : [batch_size, seq_len, hidden_size] Useless!\n",
    "        #print(\"h : \", h.shape) # 1 x 108 x 4 [ num_layers, batch_size, hidden_size]\n",
    "        y = self.fc(h)\n",
    "        #print(\"y\",y.shape) # 1 x 108 x 1\n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofkSecNA59ol"
   },
   "source": [
    "### Обучение\n",
    "\n",
    "Благодаря подготовке данных процесс обучения не будет отличаться от того что мы использовали на прошедших занятиях.\n",
    "\n",
    "В силу того что датасет маленький, все данные поместились в один batch, итерирования по batch-ам в явном виде здесь не происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "He8S8WcG59om"
   },
   "outputs": [],
   "source": [
    "def time_series_train(model):\n",
    "  num_epochs = 2000\n",
    "  learning_rate = 0.01\n",
    "  \n",
    "\n",
    "  criterion = torch.nn.MSELoss() # mean-squared error for regression\n",
    "  optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Train the model\n",
    "  for epoch in range(num_epochs):\n",
    "      outputs, h = model(trainX) # we don't use h there, but we can!\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      # obtain the loss function\n",
    "      loss = criterion(outputs, trainY)\n",
    "      loss.backward()\n",
    "      \n",
    "      optimizer.step()\n",
    "      if epoch % 100 == 0:\n",
    "          print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 4 \n",
    "rnn = AirTrafficPredictor(input_size, hidden_size)\n",
    "time_series_train(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwEYSCy659om"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wz1nb1b559on"
   },
   "outputs": [],
   "source": [
    "def time_series_plot(train_predict):\n",
    "  data_predict = train_predict.data.numpy()\n",
    "  dataY_plot = dataY.data.numpy()\n",
    "\n",
    "  # Denormalize\n",
    "  data_predict = data_predict[0] *td_max + td_min\n",
    "  dataY_plot = dataY_plot *td_max + td_min \n",
    "  #print(data_predict[:15])\n",
    "\n",
    "  # Ploitting\n",
    "  plt.figure(figsize=(12, 4))\n",
    "  plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "  plt.plot(dataY_plot)\n",
    "  plt.plot(data_predict)\n",
    "  plt.suptitle('Time-Series Prediction')\n",
    "  plt.show()\n",
    "\n",
    "rnn.eval()\n",
    "train_predict, h = rnn(dataX)\n",
    "time_series_plot(train_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Lz3ZtNd59og"
   },
   "source": [
    "\n",
    "[Time Series Prediction with LSTM Using PyTorchTime Series Prediction with LSTM Using PyTorch](https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=NabsV8O5BBd5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRZNReIybbXg"
   },
   "source": [
    "## Типы RNN архитектур"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_IaZjQmbbOA"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQHoaLt559oH"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-026.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlgvu5y_59oI"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-028.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnjYN9ew59oI"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-030.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQG42Lo__-ir"
   },
   "source": [
    "## Посимвольная генерация текстов\n",
    "\n",
    "https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb\n",
    "\n",
    "Одним из основных направлений использования рекуррентных сетей является работа с текстами:\n",
    "- генерация (Language modeling)\n",
    "и \n",
    "- перевод (Machine Translation)\n",
    "\n",
    "Давайте посмотрим как решаются такого рода задачи.\n",
    "\n",
    "Начнем с относительно простой - посимвольной генерации текста.\n",
    "\n",
    "Постановка задачи:\n",
    "\n",
    "предсказать следующий символ в последовательности.\n",
    "\n",
    "- исходный текст:\n",
    "'hey how are you'\n",
    "\n",
    "- искаженный текст:\n",
    "\n",
    "'hey how are yo'\n",
    "\n",
    "- Верное предсказание:\n",
    "'u'\n",
    "\n",
    "\n",
    "Теоретически эту технику можно использовать для генерации подсказок при наборе текстов, исправления ошибок или восстановления частично утраченного текста.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo3dp1No59oJ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-037.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXFlh4YHQdZT"
   },
   "source": [
    "#### Подготовка данных\n",
    "\n",
    "1. Зафиксировать словарь\n",
    "2. Разбить данные\n",
    "3. Кодирование символов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caGY808uQ_gT"
   },
   "outputs": [],
   "source": [
    "text = ['hey how are you','good i am fine','have a nice day']\n",
    "\n",
    "# Join all the sentences together and extract the unique characters from the combined sentences\n",
    "chars = set(''.join(text))\n",
    "\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}\n",
    "\n",
    "print(char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSXa_rTrRMFA"
   },
   "source": [
    "Вместо ascii символа, каждой букве мы сопоставили номер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFoHx59zRiMR"
   },
   "source": [
    "### Выравнивание данных (Padding)\n",
    "\n",
    "RNN допускают работу с данными переменной длины. Но что бы поместить предложения в batch надо их выровнять.\n",
    "\n",
    "\n",
    "Обычно размер батча делают равным самому длинному предложению, а остальные просто дополняют пробелами до этого размера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJp9MLFDSTVz"
   },
   "outputs": [],
   "source": [
    "maxlen = len(max(text, key=len))\n",
    "print(\"The longest string has {} characters\".format(maxlen))\n",
    "\n",
    "# A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "for i in range(len(text)):\n",
    "    while len(text[i])<maxlen:\n",
    "        text[i] += ' '\n",
    "\n",
    "print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uw4MiqEbTD8J"
   },
   "source": [
    "### Разбиение данных\n",
    "\n",
    "Можно как в случае с временым рядом предсказывать отдельный символ (many_to_one).\n",
    "\n",
    "Но мы используем many_to_many что бы увидеть как иначе можно обработать данные.\n",
    "\n",
    "В качестве входа будем использовать предложение без последнего символа:\n",
    "\n",
    "**'hey how are yo'**\n",
    "\n",
    ", а в качестве результата - предложение в котором он сгенерирован.\n",
    "\n",
    "**'ey how are you'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ysz6hn9vTClx"
   },
   "outputs": [],
   "source": [
    "# Creating lists that will hold our input and target sequences\n",
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "    \n",
    "    # Remove firsts character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "    print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-_FVzAuVGyt"
   },
   "source": [
    "Как видим выавнивание служит здесь плохую службу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJQSb9x1U8S_"
   },
   "source": [
    "### Кодирование\n",
    "\n",
    "Теперь символы надо перевести в числа. Для этого мы уже построили словарь.\n",
    "\n",
    "P.S. Запускать блок только один раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZtNcmkiVNsG"
   },
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "print(\"Input\",input_seq)\n",
    "print(\"Target\",input_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZV0pm0rWL28"
   },
   "source": [
    "#### One-hot-encoding(!)\n",
    "\n",
    "Теперь из чисел надо сделать вектора. \n",
    "\n",
    "\n",
    "Почему бы не оставить числа?\n",
    "В прошлом примере модель хорошо с ними работала.\n",
    "\n",
    "В прошлом примере использовася MSE и на выходе было число.\n",
    "\n",
    "Если бы мы определили отношение порядка над номерами букв, то что-то подобное можно было бы сделать.\n",
    "\n",
    "Однако сейчас мы предсказываем класс буквы.\n",
    "Поэтому на входе и на выходе должен быть вектор.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/softmax_1.png\" width=\"200\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcReT5zlW72p"
   },
   "outputs": [],
   "source": [
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(text)\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    \n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features\n",
    "\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
    "print(\"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(input_seq.shape))\n",
    "print(input_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuDdiK9gX3Vq"
   },
   "source": [
    "Каждый символ закодировали вектором.\n",
    "Не слишьком экономно, зато удобно умножать на матрицу весов.\n",
    "\n",
    "P.S. Запускать только один раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DlI5x6Vddal"
   },
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "input_seq = torch.from_numpy(input_seq)\n",
    "target_seq = torch.Tensor(target_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPRUjTiXYclC"
   },
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gn9VLynTYa4q"
   },
   "outputs": [],
   "source": [
    "class NextCharacterGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "        #self.n_layers = n_layers\n",
    "\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size = hidden_dim, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden_0 = torch.zeros(1, batch_size, self.rnn.hidden_size) # 1 correspond to number of layers\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden_0)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        # Only if n_layers > 1\n",
    "        out = out.contiguous().view(-1, self.rnn.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZluFC1jcuIX"
   },
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYOcJMbOcXyT"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = NextCharacterGenerator(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training Run\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    output, hidden = model(input_seq)\n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4bEcFbiejyQ"
   },
   "source": [
    "Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGrhj5xrembN"
   },
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "    \n",
    "    out, hidden = model(character)\n",
    "    print(out.shape)\n",
    "    #print(out)\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden\n",
    "\n",
    "def sample(model, out_len, start='hey'):\n",
    "    model.eval() # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)\n",
    "\n",
    "sample(model, 15, 'good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6JlfkOnprsa"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/softmax_2.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPHmL7KAQPks"
   },
   "source": [
    "Результаты которые удается получить при помощи моделей обученных на больших объемах данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVimIAxn59oM"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-050.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXVtreJf59oM"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-054.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiNFe9iU59oN"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-055.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up7JNs5k59oO"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-058.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OytMng1j59oO"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-059.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PugAiQp59oP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-061.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbUYi24c59oP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-063.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qr0fyK1EAJQU"
   },
   "source": [
    "### Explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0E_aXSMz59oP"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-064.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W3YSrKW59oQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-065.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS2ggUPi59oQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-066.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNYnYTA859oQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-067.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jno-Vn6E59oQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-068.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yS5OYvg59oQ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-069.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpBpcC5n59oS"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-068.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XM5n1xR59oT"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-069.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxXw4l47_fkA"
   },
   "source": [
    "##Обратное распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOnYVBCa59oJ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-045.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuFR9ZRy59oK"
   },
   "source": [
    "Теоритетески можно было бы сразу пропустить все данные через сеть и затем вычислить градиент.\n",
    "\n",
    "Но:\n",
    " - Большие последовательности не поместятся в памяти\n",
    " - Возникнут проблеммы исчезновения/взрыва градиента, так как цепочка будет очень длинной\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgYzq8wyBopK"
   },
   "source": [
    "### Пакеты\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukDHDbQY59oK"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-046.png\" width=\"700\">\n",
    "\n",
    "Поэтому снова возникает потребность в обработке по батчам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyhGiMB_59oL"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-047.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsExayEz59oL"
   },
   "source": [
    "Скрытые состояния при этом сохраняются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo7MxLry59oZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-083.png\" width=\"700\">\n",
    "\n",
    "Градиент в рекуррентных сетях затухает так же быстро. И при большой длине последовательности это становится критичным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLFByMFy59oZ"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-086.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ovx8AUFe59oa"
   },
   "source": [
    "Исчезающий/взрывающийся градиент (Vanishing/exploding gradient) - явления исчезающего и взрывающегося градиента часто встречаются в контексте RNN. Причина, по которой они происходят, заключается в том, что трудно уловить долгосрочные зависимости из-за мультипликативного градиента, который может экспоненциально уменьшаться/увеличиваться по отношению к числу слоев.\n",
    "\n",
    "Градиентное отсечение (Gradient clipping) - метод, используемый для решения проблемы взрывающегося градиента, иногда возникающей при выполнении обратного распространения. Ограничивая максимальное значение градиента, это явление контролируется на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6QIH71l59ob"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gradient-clipping.png\" width=\"700\">\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gradient-vanishing-exploding.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CQPFl5wAeyX"
   },
   "source": [
    "## LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z71j3Zcp59od"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-090.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMfwNI5L59oe"
   },
   "source": [
    "Если в Vanilla RNN был только один путь, то в LSTM есть highway для сокращения информации  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pw06xnTr59oe"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/gan/lstm.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh3uu10ic7Bh"
   },
   "source": [
    "i = Input\n",
    "f = Forget\n",
    "o = Output\n",
    "g = Gate\n",
    "\n",
    "\n",
    "\n",
    "1. Конкатенируем x и h_t-1\n",
    "2. Умножаем на веса\n",
    "3. Результат делим на 4 части (shape = hidden_size) к каждой применяем свою функцию активации\n",
    "4. Далее комбинируем их с входами и выходами\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTYGjknp59od"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-094.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrE47hqt59od"
   },
   "source": [
    "Но нам все равно не нужно распространять через веса (потенциально это может вызвать проблемы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWmtWwGM59oe"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-095.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJM_DYI1hQcX"
   },
   "source": [
    "### LSTMCell\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html\n",
    "\n",
    "Интерфейс отличается от RNNCell количеством входов и выходов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96XURiOhhHkQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lstm_cell = torch.nn.LSTMCell(input_size = 3, hidden_size = 4)\n",
    "dummy_input = torch.randn(1,3) # batch, input_size\n",
    "h_0 = torch.randn(1,4)\n",
    "c_0 = torch.randn(1,4)\n",
    "h, c = lstm_cell(dummy_input, (h_0,c_0)) # second arg is tuple\n",
    "print(\"h\",h.shape,h) # batch, hidden_size\n",
    "print(\"c\",c.shape,c) # batch, hidden_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17bRYkF-jvgW"
   },
   "source": [
    "### LSTM in Pytorch\n",
    "\n",
    "Отличие состоит в том что возвращается кроме h возвращается еще и c. Но можно использовать только output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1Agfg5Yj86z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "lstm = nn.LSTM(input_size = 3, hidden_size = 3)\n",
    "dummy_input = torch.randn(2,1,3) # seq_len, batch, input_size\n",
    "out, (h, c) = lstm(dummy_input) # h and c returned in tuple\n",
    "print(\"out\",out.shape,out) # seq_len, batch, hidden_size : h for each element\n",
    "print(\"h\",h.shape,h) # batch, hidden_size\n",
    "print(\"c\",c.shape,c) # batch, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwMyhNRIlc5c"
   },
   "source": [
    "### Пример использования \n",
    "\n",
    "Что бы убедиться в работоспособности конструкции заменим RNN блок на LSTM в задаче предсказания временного ряда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fJX5httmI4N"
   },
   "outputs": [],
   "source": [
    "# Define new LSTM based model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMAirTrafficPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # hidden_size == number of neurons \n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1) # Predict only one value\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h,c) = self.lstm(x) \n",
    "        y = self.fc(h)\n",
    "        return y\n",
    "\n",
    "lstm =  LSTMAirTrafficPredictor(input_size =1 , hidden_size =4 )\n",
    "di = torch.randn((108,8,1))\n",
    "out = lstm(di)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMCZ7g1qqiAT"
   },
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCSwQKKMnIlN"
   },
   "outputs": [],
   "source": [
    "lstm.train()\n",
    "\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = torch.nn.MSELoss() # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    " # Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(trainX) \n",
    "    optimizer.zero_grad()\n",
    "    #print(outputs.shape)\n",
    "    loss = criterion(outputs, trainY.unsqueeze(0))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsxTqfCnq16V"
   },
   "outputs": [],
   "source": [
    "lstm.eval()\n",
    "train_predict = lstm(dataX)\n",
    "time_series_plot(train_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4dPL9ywAydU"
   },
   "source": [
    "## GRU (Gated reccurent unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9bJukJb59oe"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-101.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfj-AChX59of"
   },
   "source": [
    "Были предприняты попытки с помощью эволюционного поиска найти более оптимальный юнит для RNN. \n",
    "\n",
    "*Поиск шел в пространстве формул для обновления состояний*\n",
    "\n",
    "Тем не менее, никакого значительного улучшения качва достигнуто не было относительно LSTM, именно поэтому LSTM является оптимальой архитектурой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQTkOpV-A7g1"
   },
   "source": [
    "## Architecture search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fi_IGUXQ59of"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-102.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhxqkk9-59oo"
   },
   "source": [
    "## Sequence-to-Sequence with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-m81sAv59oo"
   },
   "source": [
    "* Сейчас мы пытаемся решить задачу sequence to sequence\n",
    "* Орабатывая входную последовательность, мы хотим обобщить всю информацию, которая в ней содержится в некий вектор С\n",
    "* Далее мы передаем этот вектор во вторую RNN, которая является декодером\n",
    "\n",
    "\n",
    "Мы используем вектор С для передачи информации между энкодером и декодером, также мы предполагаем, что вектор С обощает всю информацию, которая небходима декодеру для генерации выходных последовательности.\n",
    "\n",
    "Однако использование единственного вектора для предоставления информации может работать только для последовательностей малой длины (неразумно предполагать, что информация с длинной последовательностью можно сжать в один вектор) \n",
    "\n",
    "Именно поэтому нам нужен некий механизм, который будет обходить \"бутылочное горлышко\" и не сжимать всю информацию в один вектор С. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UniGfQyd59oo"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-011.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccHuwngi59oo"
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5DhWpu559op"
   },
   "source": [
    "### Sequence-to-Sequence with RNNs and Attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRkkR8SZ59op"
   },
   "source": [
    "Давайте позволим нашему декодеру, используя context vector, фокусироваться на определенных выходах энкодера. \n",
    "\n",
    "Для этого будем вычислять context vector и вводим некую фцию $F_{att}$ , котрая будет вычислять alignment score (функцию похожести) между внутренними состояниями декодера и энкодера.\n",
    "\n",
    "После этого, вычисленные alignment scores мы пропускаем через softmax для нормализации. Таким образом мы получаем веса, которые говорят о том, насколько сильно мы хотим сфокусироваться на соответствующим им выходам энкодера.\n",
    "\n",
    "Затем мы просто берем взевенную сумму внутренних состояний энкодера и передаем ее на вход декодеру. Данный алгоритм выполняем на каждом шаге декодера.\n",
    "\n",
    "Функция $F_{att}$ может являться небольшой нейросетью или неким линейным преобразованием. Однако это не так важно, идея заключается в том, что мы не говорим явно на чем функция должна сосредотачиваться в конкретной задаче. Применив к ней back propagation, ее веса сами настроятся на необходимые точки фокусировки.\n",
    "\n",
    "**То есть функция сама разберется на чем фокусироваться**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyG0KoFH59op"
   },
   "source": [
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-017.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpgIoECt59oq"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-020.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLY_hB_b59oq"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-021.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAcPBwcg59os"
   },
   "source": [
    "Давайте посмотрим как фокусировка работает на примере перевода с английского на французский \n",
    "\n",
    "Как мы знаем, на каждом шаге генерируется набор весов, которые отвечают за фокусировку на том или ином месте входной последовательности. Как мы видим, английское предложение имеет иной порядок слов относительно французского. Например, в английском варианте словосочетание **European Economic Area**, в то время как во французском **zone économique européenne**. \n",
    "\n",
    "В английском прилагательные идут перед существительным, в то время как во французском языке наоборот. \n",
    "\n",
    "Таким образом, благодаря гибкости модели, мы можем обрабатывать и учитывать разный порядок слов в разных языках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw4t5HPd59ot"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-025.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mmb-3wYS59ot"
   },
   "source": [
    "* Механизм внимания не обязательно должен принимать на вход последовательность. \n",
    "\n",
    "* Мы можем применять его, в том числе для генерации подписей для картинок. Входом в данном случае будет являться сетка признаков, которая была получена при применении сверточной сети к картинке. \n",
    "\n",
    "* Далее по этой сетке мы считаем веса внимания и делаем аналогично первому примеру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpIecJji59ou"
   },
   "source": [
    "### Image Captioning with RNNs and Attention\n",
    "\n",
    "Модели, основанные на внимании (attention) намного более продвинутые, нежели обычные нейросети. Они могут концентрироваться на отдельных частях изображения, что позволяет избежать зашумления данных.\n",
    "\n",
    "Идея состоит в том, что свёрточная сеть теперь будет генерировать не один вектор, описывающий всё изображение, а набор векторов для нескольких участков исходного снимка. В дополнение к работе со словарём на каждом временном шаге модель также производит распределение по точкам на изображении, которые она обрабатывает в данный момент. Это позволяет ей научиться находить наиболее важные участки, на которых необходимо фокусироваться.\n",
    "\n",
    "После обучения модели можно увидеть, что она как бы переносит своё внимание по изображению для каждого генерируемого слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLNqB-PI59ot"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-028.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sibhw8259ot"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-031.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xtknlAv59ou"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-036.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eFIraJd59ou"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-037.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JALrz2tO59ov"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-038.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aSmxI1R59ov"
   },
   "source": [
    "Существуют также понятия мягкого и жёсткого внимания (soft and hard attention). При мягком внимании мы берём взвешенную комбинацию признаков по всему изображению, тогда как в случае жёсткого внимания мы заставляем модель выбирать только один небольшой участок для обработки на каждом временном шаге. При этом жёсткое внимание, строго говоря, не является дифференцируемой функцией. Поэтому для обучения такой модели необходимо использовать более изощрённые приёмы, чем обычное обратное распространение ошибки.\n",
    "\n",
    "Также нейросети, основанные на внимании, повсеместно используются для ответов на визуальные вопросы (Visual Question Answering). Цель этой задачи — обучить модель отвечать на вопрос по изображению. Например, она должна уметь не только называть сами объекты на фотографии, но и считать их, распознавать цвета и оценивать расположение относительно друг друга. Мы уже рассказывали о подобных архитектурах в статье о том, как такие нейросети могут помочь незрячим людям и о нейро-символическом мышлении.\n",
    "\n",
    "ссылка https://www.reg.ru/blog/nejroset-opisyvaet-mir-nezryachim-lyudyam/ ссылка https://www.reg.ru/blog/uchim-nejroseti-rassuzhdat-o-tom-chto-oni-vidyat/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REy44gHf59ov"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-039.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWwY-sf759ov"
   },
   "source": [
    "### X, Attend, and Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXRjvSbC59ow"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-044.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcSCLFif59ow"
   },
   "source": [
    "### Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlK7xfpv59ow"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-045.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2WJsTwl59ow"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-048.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJs3X1zz59ow"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-050.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lxnIjkH59ox"
   },
   "source": [
    "Давайте обобщим наш attention слой. \n",
    "\n",
    "* Во-первых, заменим фцию $F_{att}$ на скалярное произведение.\n",
    "\n",
    "* В предыдущем примере мы использовали только один вектор для поиска совпадений (query вектор), который являлся внутренним состоянием декодера. Давайте вместо этого дадим возможность нашей модели использовать сразу нессколько query-векторов. Благодаря этому мы будем получать несколько распределений весов на выходе (по 1 для каждого query-вектора).\n",
    "\n",
    "* Обратим внимание, что мы используем входной вектор Х дважды: при вычислении похожести с query-вектором и при вычислении конечного выходного взвешенного решения. Для большей гибкости давайте разделим их и будем отдельно вычислять key-вектора и отдельно value-вектора. key-вектора мы будем использовать для поиска схожести с value-векторами. А они в свою очередь, будут использоваться для вычисления конечного выходного взевешенного значения. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zfjsz6L59ox"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-056.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlBwWCRr59ox"
   },
   "source": [
    "### Self-Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q_zsJ7D59ox"
   },
   "source": [
    "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
    "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
    "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
    "textual entailment and learning task-independent sentence representations\n",
    "\n",
    "Self-attention, также иногда называемый intra-attention - это механизм , связывающий различные позиции одной последовательности для вычисления представления последовательности. \n",
    "\n",
    "Self-attention успешно используется в различных задачах, включая понимание прочитанного (reading comprehension), абстрактное обобщение, текстовое влечение (entailment) и обучение независимым от задачи представлениям предложений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJYA2Wz059oy"
   },
   "source": [
    "Возникает вопрос, как это сделать наилучшим образом. \n",
    "\n",
    "Допустим, при обработке временных рядов используют некую сглаживающую функцию, например gaussian. \n",
    "\n",
    "Однако при обработке предложений очевидно, что неправильно считать рядом стоящие слова как наиболее близкие\n",
    "друг к другу по контексту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYB9FYoa59oy"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_4-1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fepb5WPM59oy"
   },
   "source": [
    "Основная идея заключается в том, что мы рассчитываем и query, и input, и key на основе input-векторов. \n",
    "\n",
    "Таким образом мы будем сравнивать каждый наш входной вектор со всеми остальными входными векторами входного множества. \n",
    "\n",
    "Для расчета query-векторов мы добавляем матрицу $W_Q$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNT1qOsq59oy"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-063.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heBX1DEU59oz"
   },
   "source": [
    "Свой self attention инвариантен относительно порядка входных последовательностей. \n",
    "\n",
    "Таким образом мы получили новый тип слоев нейронной сети, который **не** использует информацию о порядке входной последовательности и оперирует только на множестве входных векторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jO_ePNO059oz"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-070.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6z8UFvo59oz"
   },
   "source": [
    "Иногда нам хочется чтобы порядок учитывался, например при переводе и генерации описания картинок (caption). \n",
    "\n",
    "Для этого мы добавляем информацию на входы о порядке наших элементов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2OnmQSq59oz"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-072.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REQ_ja_J59o0"
   },
   "source": [
    "### Masked Self-Attention Layer - совместить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GunDUprh59o0"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-073.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UF7bz0_c59o0"
   },
   "source": [
    "#### Multihead Self-Attention Layer\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_7-1.png\" width=\"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAC9-akL59o1"
   },
   "source": [
    "Давайте посмотрим на то, к каким словам предложения gave может иметь отношение. В общим случае глагол может иметь связку со многоми частями предложения. Как, например, к подлежащему, так и к причастиям.\n",
    "\n",
    "В идеале, нам бы хотелось обратить внимние функции (attention) на все эти взаимосвязи.\n",
    "\n",
    "**Для этого небходимо ввести несколько механизмов внимания, как это показано на картинке**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2VtCBK959o2"
   },
   "source": [
    " <img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_6-1.png\" width=\"700\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIAqIl6R59o2"
   },
   "source": [
    "* Чтобы осуществить задуманное, вместо одного набора query, будем использовать несколько независимых наборов. \n",
    "\n",
    "* Причем каждый набор будет считаться уникальной матрицей. \n",
    "\n",
    "* Аналогично сделаем для keys и values. Количество таких наборов внутри keys, queries, values должно быть **одинаковым**. \n",
    "\n",
    "* Обозначим это число как h - head, далее производим аналогичные манипуляции, при этом введем в параллель h таких функций attention\n",
    "* На последнем шаге мы их соединяем (конкатинируем)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzEfe51759o2"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-075.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viQtPZtX59o3"
   },
   "source": [
    "### Three Ways of Processing Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKYLb7vj59o3"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/l08_1_1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeIz1iXL59o3"
   },
   "source": [
    "\n",
    "Модель attention позволяет обрабатывать последовательности параллельно в отличие от моделей основанных на RNN, это позволяет данную модель в большей мере использовать возможности использования параллельных вычислений на GPU \n",
    "\n",
    "RNN:\n",
    "**Преимущества** \n",
    "\n",
    "• Возможность обработки входных данных любой длины\n",
    "\n",
    "• Размер модели не увеличивается с размером входного сигнала\n",
    "\n",
    "• Расчет учитывает историческую информацию\n",
    "\n",
    "• Веса распределяются во времени \n",
    "\n",
    "**Недостатки**\n",
    "\n",
    "• Вычисление происходит медленно\n",
    "\n",
    "• Трудность доступа к информации, полученной давным-давно\n",
    "\n",
    "• Не может учитывать какие-либо будущие входные данные для текущего состояния"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EAMsm1Z59o4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-084.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7h_YGPDf59o4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-085.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFc19_Hb59o4"
   },
   "source": [
    "### The Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPn2WdXC59o4"
   },
   "source": [
    "Раньше мы передавали информацию из блока attention в RNN для ее последующего применения, однако в 2017 году вышла статья под названием Attention is all you need. В ней говорилось о том, что для обработки последовательностей можно ограничиться только блоком внимания. Данная модель получила название Transformer. \n",
    "\n",
    "По сути это базовый блок, который основывается только на self-attention при работе с входными векорами. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EC9uGpV59o4"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-092.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4d2AC7K59o5"
   },
   "source": [
    "Блок устроен следующим образом: входные вектора мы запускаем в блок self-attention и используем residual connection как обходной путь вокруг self-attention, затем мы их складываем. \n",
    "\n",
    "После - применяем слой нормализации, затем - слой feat forward сетей, плюс обходной путь вокруг feat forward. \n",
    "\n",
    "Складываем их и выполняем нормализацию. \n",
    "\n",
    "Это один блок-трансформер. \n",
    "\n",
    "В реальных моделях эти слои стекируют друг с другом и получается большая трансформер-модель. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YU3V6_2m59o5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-094.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZTw34C059o5"
   },
   "source": [
    "Although this achieves parallelization, it is still computationally expensive. The number of operations per layer incurred by RNNs and CNNs is way more unreasonable as compared to the quality of results they offer. The original Transformer paper has put forth a comparison of these parameters for the competent models:\n",
    "\n",
    "Хотя таким образом (свертками) достигается распараллеливание, однако это вычислительно дорого. Количество операций на слой, выполняемых RNN и CNN, гораздо более необоснованно по сравнению с качеством результатов, которые они предлагают.\n",
    "\n",
    "В одной из статей про Трансформеры было предложено сравнение этих параметров для компетентных моделей:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqo6qPKt59o5"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/L08_trans.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3dIUoFn59o5"
   },
   "source": [
    "Here, d (or d_model) is the representation dimension or embedding dimension of a word (usually in the range 128–512), n is the sequence length (usually in the range 40–70), k is the kernel size of the convolution and r is the attention window-size for restricted self-attention. From the table, we can infer the following:\n",
    "\n",
    "* Clearly, the per-layer computational complexity of self-attention is way less than that of others.\n",
    "* With respect to sequential operations, except RNNs, all other approaches offer parallelization, hence their complexity is O(1).\n",
    "* The final metric is maximum path length, which superficially means the complexity for attending long-term dependencies or distant words. Since convolutional models use hierarchical representations, their complexity is nlog(n), while self-attention models attend all the words at the same step, hence their complexity is O(1).\n",
    "\n",
    "\n",
    "The Transformer uses the self-attention mechanism where attention weights are calculated using all the words in the input sequence at once, hence it facilitates parallelization. In addition to that, since the per-layer operations in the Transformer are among words of the same sequence, the complexity does not exceed O(n²d). Hence, the transformer proves to be effective (since it uses attention) and at the same time, a computationally efficient model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lZyd0eG59o5"
   },
   "source": [
    "Здесь d (или *d_model*) - размер выборки или embedding вложения слова (обычно в диапазоне 128-512), n-длина последовательности (обычно в диапазоне 40-70), k-размер ядра свертки, а r-размер окна внимания для ограниченного self-attention. Из таблицы мы можем сделать следующие выводы:\n",
    "\n",
    "* Очевидно, что вычислительная сложность каждого слоя self-attention намного меньше, чем у других.\n",
    "* Что касается последовательных операций, то, за исключением RNN, все другие подходы предлагают параллельность действий, поэтому их сложность составляет O(1).\n",
    "* Конечная метрика - максимальная длина пути, которая поверхностно означает сложность для посещения долгосрочных зависимостей или отдаленных слов. Поскольку сверточные модели используют иерархические представления, их сложность равна nlog(n), в то время как модели самосознания посещают все слова на одном и том же шаге, следовательно, их сложность равна O(1).\n",
    "\n",
    "\n",
    "Трансформер использует механизм само-внимания, где веса внимания вычисляются с использованием всех слов во входной последовательности сразу, следовательно, это облегчает распараллеливание. Кроме того, поскольку операции на каждом слое в трансформерах относятся к словам одной и той же последовательности, сложность не превышает O($n^2d$). Следовательно, трансформер оказывается эффективной (поскольку она использует attention) и в то же время вычислительно качественной моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwB7bdWU59o6"
   },
   "source": [
    "статья: https://towardsdatascience.com/transformers-explained-65454c0f3fa7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tR0xMl5059o6"
   },
   "source": [
    "### The Transformer: Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RboS0TmY59o6"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-095.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BosmoQ659o6"
   },
   "source": [
    "В 2020 практически все успехи машинного обучения были связаны с применением трансформеров. На сегодняшний день - это самая передовая модель для обработки последовательностей. \n",
    "\n",
    "Стоит отметить, что модели трансформеров имеют огромное кличество параметров, как следствие - требуются большие вычислительные мощности для их обучения. В связи с этим, обучение данных моделей с нуля, преимущественно доступны только развитым государствам и крупным компаниям. \n",
    "\n",
    "Большая часть предприятий может расчитывать только на дообучене этих моделей для своих задач, что все равно показывает хорошие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpLNXC5d59o6"
   },
   "source": [
    "### The Transformer: Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovXsjPT059o7"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-100.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkrPQkVp59o7"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-104.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj1I0Tw359o7"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmZ3lokD59o8"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture13-105.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9h36-uz26f-2"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eU8X0gE_PU9"
   },
   "source": [
    "## Image Captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KV0EPcP59oT"
   },
   "source": [
    "\n",
    "\n",
    "Суть этой задачи заключается в том, чтобы нейросеть составила текстовое описание фотографии. Для этого необходимо сначала классифицировать объекты на изображении, а затем передать результат (одну или несколько меток) в языковую рекуррентную модель, которая сможет составить из них осмысленную фразу. При этом мы действуем точно так же, как в случае с обычной языковой моделью: преобразуем метку изображения в вектор, который обрабатывается декодером.\n",
    "\n",
    "Чтобы рекуррентная сеть понимала, где именно начинается предложение, во время обучения на её вход подаётся стартовый опознавательный знак ( token $ <start>$ ). Для построения фразы используется заранее подготовленный словарь, например, из английских слов — и он может быть довольно большим.\n",
    "\n",
    "При переходе на каждое следующее скрытое состояние мы сохраняем как уже сгенерированные слова, так и информацию об изображении. В конце предложения в нейросеть отправляется финальный токен ( $ <end> $). Во время тестирования модель уже самостоятельно определяет, где должно начинаться и заканчиваться описание изображения.\n",
    "\n",
    "Обычно подобные архитектуры создаются с помощью контролируемого обучения (supervized learning) — это означает, что в обучающих датасетах уже присутствуют как изображения, так и описания для них. Наиболее популярным и самым большим набором данных является Microsoft COCO. Помимо image captioning он также применяется для сегментации, поиска ключевых точек и даже построения трёхмерной модели человека на основе его позы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9aGMzgA59oU"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-071.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iupsVOP59oV"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-079.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJH3l3mi59oW"
   },
   "source": [
    "Мы добавили в словарь две специальные команды $ <start> $ и $ <end> $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6Ali4xU59oX"
   },
   "source": [
    "Иногда дает очень хорошие описания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSXCH04459oY"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-080.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6RAefDNHFoq"
   },
   "source": [
    "# Пример машинного перевода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAJnLL5m59oE"
   },
   "source": [
    "\n",
    "\n",
    "Подробнее о том, как выглядят нейросети для машинного перевода и, в частности, Google-переводчик, можно прочитать в статье Google преодолевает барьер между человеческим и машинным переводом. А мы вернёмся к распознаванию изображений и поговорим об image captioning.\n",
    "\n",
    "ссылка https://www.reg.ru/blog/google-preodolevaet-barer-mezhdu-chelovecheskim-i-mashinnym-perevodom/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mliHGFlI6jag"
   },
   "source": [
    "# Применение RNN для генерации данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ4AZMyH59n_"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-012.gif\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Nj9L4rj59n_"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-013.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrxAnrgC59oA"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-013-1.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeS-8zpj59oB"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/498_FA2019_lecture12-014.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Mv05SGQ60Be"
   },
   "source": [
    "# Чулан"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laj7_a0v59n6"
   },
   "source": [
    "<img src =\"http://edunet.kea.su/repo/src/L08_RNN/img/L08_14.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVgLEpJa59oo"
   },
   "source": [
    "* Rnn обеспечивает большую гибкость в архитектурном проектировании\n",
    "* Vanilla RNN намного проще, однако работают не очень хорошо\n",
    "* LSTM или GRU: аддитивное взаимодействие улучшает градиентный поток\n",
    "* Обратный поток градиентов в RNN делает explode или vanish\n",
    "\n",
    "explode управляется с помощью градиентного отсечения\n",
    "\n",
    "vanish - это контролируемые аддитивные взаимодействия (LSTM)\n",
    "\n",
    "* Лучшие/более простые архитектуры являются актуальной темой текущих исследований\n",
    "* Необходимо лучшее понимание (как теоретическое, так и эмпирическое)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "colab": {
   "name": "L08_RNN.ipynb",
   "provenance": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
